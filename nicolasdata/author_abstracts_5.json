{
  "input_authors": [
    "8R35rCwAAAAJ",
    "bh-uRFMAAAAJ",
    "a4unsk4AAAAJ",
    "84WzBlYAAAAJ",
    "a_dbdxAAAAAJ",
    "aO8KpGcAAAAJ",
    "LKv32bgAAAAJ",
    "vtwH6GkAAAAJ",
    "B96GkdgAAAAJ",
    "_pv1sEcAAAAJ",
    "Wi25oKoAAAAJ",
    "B847xq8AAAAJ",
    "_tNCgxMAAAAJ",
    "UgHB5oAAAAAJ"
  ],
  "author_names": {
    "8R35rCwAAAAJ": "Sergey Levine",
    "vfPE6hgAAAAJ": "Chelsea Finn",
    "vtwH6GkAAAAJ": "Pieter Abbeel",
    "zBUwaGkAAAAJ": "Aviral Kumar",
    "1wLVDP4AAAAJ": "Abhishek Gupta",
    "yy0UFOwAAAAJ": "Karol Hausman",
    "DRnOvU8AAAAJ": "Benjamin Eysenbach",
    "B8wslVsAAAAJ": "Shixiang Shane Gu",
    "-gJkPHIAAAAJ": "George Tucker",
    "ADkiClQAAAAJ": "Yevgen Chebotar",
    "T9To2C0AAAAJ": "Justin Fu",
    "l-la0GQAAAAJ": "Julian Ibarz",
    "1O83J5MAAAAJ": "Aurick Zhou",
    "5VaXUQsAAAAJ": "Tianhe Yu",
    "FwxfQosAAAAJ": "Xue Bin Peng",
    "VT7peyEAAAAJ": "Tuomas Haarnoja",
    "bh-uRFMAAAAJ": "Trevor Darrell",
    "NSWI3OwAAAAJ": "Quan Vuong",
    "d5y4iKAAAAAJ": "Dhruv Shah",
    "BsOkXDsAAAAJ": "Ashvin Nair",
    "OFlBL2kAAAAJ": "Frederik Ebert",
    "UgHB5oAAAAAJ": "Anca D Dragan",
    "neGbgzYAAAAJ": "Jie Tan",
    "vYougn0AAAAJ": "Xinyang Geng",
    "aOklxsQAAAAJ": "Jitendra MALIK",
    "6uIhh6MAAAAJ": "Rowan McAllister",
    "jERkdhIAAAAJ": "Gregory Kahn",
    "xUGZX_MAAAAJ": "Nicholas Rhinehart",
    "znnl0kwAAAAJ": "Dibya Ghosh",
    "yxUduqMAAAAJ": "Michael I. Jordan",
    "7ShMBcwAAAAJ": "Marvin Zhang",
    "ITZ1e7MAAAAJ": "Ruslan Salakhutdinov",
    "fA0rYxMAAAAJ": "Roberto Calandra",
    "PTS2AOgAAAAJ": "Ilya Kostrikov",
    "-WZcuuwAAAAJ": "Glen Berseth",
    "BIwrJuQAAAAJ": "Vitchyr H. Pong",
    "Ivot3fkAAAAJ": "Coline Devin",
    "DMTuJzAAAAAJ": "Mrinal Kalakrishnan",
    "kg4bCpgAAAAJ": "Vladlen Koltun",
    "C-ZlBWMAAAAJ": "Ofir Nachum",
    "0nPi5YYAAAAJ": "Pierre Sermanet",
    "zvz6LIYAAAAJ": "Michael Janner",
    "itSa94cAAAAJ": "John Schulman",
    "U_Jw8DUAAAAJ": "Jonathan Tompson",
    "pqP5_PgAAAAJ": "Fei Xia",
    "3Y4egcYAAAAJ": "Mohammad Babaeizadeh",
    "Vzr1RukAAAAJ": "Igor Mordatch",
    "wfGiqXEAAAAJ": "Dumitru Erhan",
    "eVYhlDQAAAAJ": "Kristian Hartikainen",
    "Q6F3O0sAAAAJ": "Sehoon Ha",
    "2DBmo-wAAAAJ": "Dmitry Kalashnikov",
    "QxLpghAAAAAJ": "Dinesh Jayaraman",
    "DkUUhXEAAAAJ": "Anusha Nagabandi",
    "_EJrRVAAAAAJ": "Aravind Rajeswaran",
    "BOAOkNQAAAAJ": "Laura Smith",
    "sgsLkM0AAAAJ": "Oier Mees",
    "ZWH5jCwAAAAJ": "Homer Walke",
    "T7uctwYAAAAJ": "Vincent Vanhoucke",
    "NpOg5soAAAAJ": "Sudeep Dasari",
    "_ws9LLgAAAAJ": "Peter Pastor",
    "8-p9CLsAAAAJ": "Alex X. Lee",
    "jrfFYAIAAAAJ": "Alexander Herzog",
    "7GSWYLQAAAAJ": "Siddharth Reddy",
    "qlwwdfEAAAAJ": "Qiyang Li",
    "GyoKzFwAAAAJ": "Kelvin Xu",
    "C2_ZXdcAAAAJ": "Avi Singh",
    "YGQs1AYAAAAJ": "Stefan Schaal",
    "UAwKvEsAAAAJ": "Thomas L. Griffiths",
    "kukA0LcAAAAJ": "Yoshua Bengio",
    "uA0kNBUAAAAJ": "Ronald S. FEARING",
    "UpZmJI0AAAAJ": "Pulkit Agrawal",
    "xBH73TYAAAAJ": "John D Co-Reyes",
    "pouyVyUAAAAJ": "Percy Liang",
    "fmSHtE8AAAAJ": "Honglak Lee",
    "krrh6OUAAAAJ": "Anirudh Goyal",
    "BZBkjNYAAAAJ": "Kuan Fang",
    "xegzhJcAAAAJ": "Alex Krizhevsky",
    "wtRVnsYAAAAJ": "Konstantinos Bousmalis",
    "OI7zFmwAAAAJ": "Yao Lu",
    "bdHgGgEAAAAJ": "Shikhar Bahl",
    "e1P1rNkAAAAJ": "Kate Rakelly",
    "fpVf9QkAAAAJ": "Seohong Park",
    "ZaJEZpYAAAAJ": "Dorsa Sadigh",
    "vgfGtykAAAAJ": "Michael B. Chang",
    "SiBVfPUAAAAJ": "Joey Hong",
    "PpzsjioAAAAJ": "Kyle Stachowicz",
    "wCRav7EAAAAJ": "Ajay Sridhar",
    "0Qr2IGwAAAAJ": "Zoran Popovic",
    "B96GkdgAAAAJ": "Joseph E. Gonzalez",
    "vS8b6GwAAAAJ": "Fereshteh Sadeghi",
    "78WTKm4AAAAJ": "Yuexiang Zhai",
    "xuLKJboAAAAJ": "Masatoshi Uehara",
    "zUJus70AAAAJ": "Yu Xuan Liu",
    "1HO5UacAAAAJ": "Saurabh Gupta",
    "8iCb2TwAAAAJ": "Natasha Jaques",
    "5NGAbT4AAAAJ": "Vivek Myers",
    "rRJ9wTJMUB8C": "Joshua B. Tenenbaum",
    "2oy3OXYAAAAJ": "Stuart Russell",
    "-5_ksIkAAAAJ": "Claire Tomlin",
    "QCBdB7AAAAAJ": "Emo Todorov",
    "wb-DKCIAAAAJ": "Sham M Kakade",
    "d97bGd8AAAAJ": "Alexei A. Efros",
    "dD7EpwQAAAAJ": "Charlie Snell",
    "FWp7728AAAAJ": "Katerina Fragkiadaki",
    "iYN86KEAAAAJ": "Ian Goodfellow",
    "i7V1kJgAAAAJ": "Amrith Setlur",
    "0uTu7fYAAAAJ": "Zoubin Ghahramani",
    "ckZ7q_gAAAAJ": "You Liang Tan",
    "T6PbwPIAAAAJ": "Alexander Toshev",
    "SgST3LkAAAAJ": "Eric Wallace",
    "Ci-_QYIAAAAJ": "Angjoo Kanazawa",
    "j_xavDQAAAAJ": "Haoran Tang",
    "Uly5spMAAAAJ": "Russell Mendonca",
    "x04W_mMAAAAJ": "Ilya Sutskever",
    "yABlzrsAAAAJ": "Ignasi Clavera",
    "dnZ8udEAAAAJ": "Jacob Andreas",
    "84WzBlYAAAAJ": "Dawn Song",
    "9xDADY4AAAAJ": "Kate Saenko",
    "JWmiQR0AAAAJ": "Łukasz Kaiser",
    "i38QlUwAAAAJ": "Tengyu MA",
    "CP5x1yEAAAAJ": "Michael Equi",
    "wIDVzroAAAAJ": "Mitsuhiko Nakamoto",
    "DZ-fHPgAAAAJ": "Bernhard Schölkopf",
    "t2X4Mg8AAAAJ": "Marc Toussaint",
    "kppa2vgAAAAJ": "Aviv Tamar",
    "mnAk4HIAAAAJ": "Kristofer PISTER",
    "bslhbWgAAAAJ": "Annie S. Chen",
    "f2NAF7QAAAAJ": "Zheyuan Hu",
    "KCdL5B0AAAAJ": "Kyle Hsu",
    "tcfl2hUAAAAJ": "Arnav Gudibande",
    "EMDboA4AAAAJ": "Yan Duan",
    "_QlCijoAAAAJ": "Allan Jabri",
    "ZKRs0oEAAAAJ": "Moo Jin Kim",
    "5bc-9A4AAAAJ": "Catherine Rose Glossop",
    "7c1B_fIAAAAJ": "Sherry Yang",
    "todsDfQAAAAJ": "Edward H Adelson",
    "lRUi-A8AAAAJ": "Gaurav Sukhatme",
    "lJwPbcUAAAAJ": "Michiel van de Panne",
    "UAWfBEoAAAAJ": "Jonathan Heewon Yang",
    "U89FHq4AAAAJ": "Hugo Larochelle",
    "wMjQdBcAAAAJ": "Jakub Grudzien Kuba",
    "nGUcGrYAAAAJ": "Balaraman Ravindran",
    "zFNvU34AAAAJ": "Marwa Abdulhai",
    "eM916YMAAAAJ": "Matthew Botvinick",
    "-QopmQoAAAAJ": "Yi Su",
    "OSg3D9MAAAAJ": "Erin Grant",
    "mqpjAt4AAAAJ": "Judy Hoffman",
    "bQowYEYAAAAJ": "Pranav Atreya",
    "yyIoQu4AAAAJ": "Diederik P. Kingma",
    "8fztli4AAAAJ": "Ken Goldberg",
    "xaQuPloAAAAJ": "Dale Schuurmans",
    "YTO4ex4AAAAJ": "Andre He",
    "B7oP0bIAAAAJ": "Paul Christiano",
    "eIWg8NMAAAAJ": "Christian Theobalt",
    "Wd8_fOcAAAAJ": "Kumar Krishna Agrawal",
    "CUlqK5EAAAAJ": "Sanja Fidler",
    "HaN8b2YAAAAJ": "Emma Brunskill",
    "n7hxT4oAAAAJ": "Jędrzej Orbik",
    "a3K-f2YAAAAJ": "Jovan Popović",
    "dzOd2hgAAAAJ": "Philipp Krähenbühl",
    "q-buMEoAAAAJ": "Sebastian Thrun",
    "Vdu_sqwAAAAJ": "Amir Yazdanbakhsh",
    "BAAZ_ysAAAAJ": "Yoonho Lee",
    "no_BfYgAAAAJ": "Aldo Pacchiano",
    "jH_7A6gAAAAJ": "Jeffrey Wu",
    "BDmtLHsAAAAJ": "Florian Shkurti",
    "zp8V7ZMAAAAJ": "Animesh Garg",
    "grQ_GBgAAAAJ": "Ryan P. Adams",
    "aO8KpGcAAAAJ": "Jiantao Jiao",
    "wMcPTbEAAAAJ": "Zipeng Fu",
    "uemlfQYAAAAJ": "Keerthana Gopalakrishnan",
    "Rne0FzEAAAAJ": "Ziyu Wang",
    "LAv0HTEAAAAJ": "John Canny",
    "i28fU0MAAAAJ": "C. Karen Liu",
    "gQpYbRsAAAAJ": "Amy X. Lu",
    "Ctp3igcAAAAJ": "Jathushan Rajasegaran",
    "wxnzyjwAAAAJ": "Danny Driess",
    "42m4tGIAAAAJ": "Nilah Monnier Ioannidis",
    "axX7PCwAAAAJ": "Kevin Black",
    "FUOEBDUAAAAJ": "Vijay Kumar",
    "bMZFLZ_V4goC": "Ching-An Cheng",
    "xEWgxBsAAAAJ": "Andrey Kolobov",
    "lS96SqoAAAAJ": "Vikash Kumar",
    "V42yp08AAAAJ": "Aly Lidayan",
    "UfbuDH8AAAAJ": "Jeff Donahue",
    "-ltRSM0AAAAJ": "Evan Shelhamer",
    "W8VIEZgAAAAJ": "Ross Girshick",
    "P4nfoKYAAAAJ": "Alex `Sandy' Pentland",
    "GHpxNQIAAAAJ": "Anna Rohrbach",
    "mu5Y2rYAAAAJ": "Yangqing Jia",
    "3kDtybgAAAAJ": "Marcus Rohrbach",
    "nABXo3sAAAAJ": "Eric Tzeng",
    "pvyI8GkAAAAJ": "Lisa Anne M Hendricks",
    "AEsPCAUAAAAJ": "Deepak Pathak",
    "-XCiamcAAAAJ": "Fisher Yu",
    "7OTD-LEAAAAJ": "Zhuang Liu",
    "gYiCq88AAAAJ": "Sergio Guadarrama",
    "ijmuZ0wAAAAJ": "Sergey Karayev",
    "APgaFK0AAAAJ": "Louis-Philippe Morency",
    "YLOz1kgAAAAJ": "Greg Shakhnarovich",
    "4V1nNm4AAAAJ": "Mario Fritz",
    "DplAah0AAAAJ": "Ning Zhang",
    "e9gUdKwAAAAJ": "Xin Wang",
    "Jp6Mz1sAAAAJ": "Kristen Grauman",
    "ID9QePIAAAAJ": "Kurt Keutzer",
    "wRyjJfMAAAAJ": "Sayna Ebrahimi",
    "rTw-pq0AAAAJ": "Ronghang Hu",
    "OZ7PjVoAAAAJ": "Dequan Wang",
    "TmWYBeEAAAAJ": "Subhashini Venugopalan",
    "12uhMdIAAAAJ": "Gaile Gordon",
    "bo0P2qYAAAAJ": "Gao Yang",
    "jQl9RtkAAAAJ": "Zeynep Akata",
    "6Q-289IAAAAJ": "Roei Herzig",
    "jyxO2akAAAAJ": "Raquel Urtasun",
    "izZZAegAAAAJ": "John W. Fisher III",
    "t9HPFawAAAAJ": "Huazhe Xu",
    "D1okUccAAAAJ": "Ariadna Quattoni",
    "XXUsEjsAAAAJ": "Ali Rahimi",
    "okcbLqoAAAAJ": "Brian Kulis",
    "_kJ-zUYAAAAJ": "Seth Dong Huk Park",
    "zXhuhtwAAAAJ": "Christopher R. Wren",
    "X0EXfT8AAAAJ": "Samaneh Azadi",
    "5MTY7-wAAAAJ": "Konrad Tollmar",
    "mDNhPjAAAAAJ": "Tom Yeh",
    "NkzyCvUAAAAJ": "Oriol Vinyals",
    "eml8HfQAAAAJ": "Huijuan Xu",
    "Y8O9N_0AAAAJ": "Xiaolong Wang",
    "5JserkUAAAAJ": "Amir Globerson",
    "p9RsPG4AAAAJ": "Raymond Mooney",
    "2ItLnFgAAAAJ": "Erik Rodner",
    "oOwNKsAAAAAJ": "Piotr Indyk",
    "r81Ss1cAAAAJ": "Pattie Maes",
    "B_FTboQAAAAJ": "Eli Shechtman",
    "DxoenfgAAAAJ": "Michael Collins",
    "z76PBfYAAAAJ": "Bernt Schiele",
    "Pk-959EAAAAJ": "Kevin Wilson",
    "t4dSV4YAAAAJ": "Devin Guillory",
    "ScoZZPsAAAAJ": "Hyun Oh Song",
    "o6LlkNMAAAAJ": "Colorado J Reed",
    "y1lVpBEAAAAJ": "Forrest Iandola",
    "ED5iKYYAAAAJ": "Katherine J. Kuchenbecker",
    "yA4rb60AAAAJ": "Tinghui Zhou",
    "nXBQn7gAAAAJ": "Stan Sclaroff",
    "sJDqACEAAAAJ": "Daniel Fried",
    "NmHgX-wAAAAJ": "Bingyi Kang",
    "XM97iScAAAAJ": "Irfan Essa",
    "N_rVVG8AAAAJ": "Kaylee Burns",
    "a8Y2OJMAAAAJ": "Piotr Dollár",
    "2X0cwhkAAAAJ": "Kuniaki Saito",
    "n-B0jr4AAAAJ": "Mathieu Salzmann",
    "j8ULfMsAAAAJ": "Candace Sidner",
    "gTWUZlsAAAAJ": "Stefanie Jegelka",
    "XP_Hxm4AAAAJ": "Oscar Beijbom",
    "56EZh6YAAAAJ": "Ryan Farrell",
    "4D1n8scAAAAJ": "Ashish Kapoor",
    "oizZKrsAAAAJ": "Todd Zickler",
    "1TqAq5AAAAAJ": "Lorenzo Riano",
    "FyQAwaEAAAAJ": "Parsa Mahmoudieh",
    "hHkuxSUAAAAJ": "Taesung Park",
    "ZcWO2AEAAAAJ": "Aaron Hertzmann",
    "pfGI-KcAAAAJ": "James Glass",
    "MaSXNhUAAAAJ": "Stephen Miller",
    "_DNzXTcAAAAJ": "Vivian Chu",
    "a4unsk4AAAAJ": "Adam Yala",
    "k-nF0qgAAAAJ": "Kevin S Hughes",
    "aC55XVgAAAAJ": "Rong Tang",
    "euc0GX4AAAAJ": "Karthik Narasimhan",
    "9yRwkr4AAAAJ": "Fernanda C. G. Polubriaginof, MD PhD",
    "a_dbdxAAAAAJ": "Benjamin Recht",
    "iyDxq0EAAAAJ": "Banghua Zhu",
    "nTiSnwUAAAAJ": "Tsachy Weissman",
    "hdTDzlQAAAAJ": "Yanjun Han",
    "OP6ejqgAAAAJ": "Kartik Venkat",
    "DcV-5RAAAAAJ": "Kannan Ramchandran",
    "yDVn5LEAAAAJ": "Hanlin Zhu",
    "df-THM0AAAAJ": "Tianhao Wu",
    "5pKTRxEAAAAJ": "Eric Xing",
    "wSstCv0AAAAJ": "Hongyang Zhang",
    "BgQkdsYAAAAJ": "Paria Rashidinejad",
    "IB_jPZ0AAAAJ": "Cong Ma",
    "ZvX1hXcAAAAJ": "Nived Rajaraman",
    "bZ9oyW8AAAAJ": "Yaodong Yu",
    "3XLQbL8AAAAJ": "Laurent El Ghaoui",
    "0mgEF28AAAAJ": "Yuandong Tian",
    "xRmmtzIAAAAJ": "Thomas Courtade",
    "Op-47sgAAAAJ": "Evan Frick",
    "LKv32bgAAAAJ": "Jacob Steinhardt",
    "HQRnt54AAAAJ": "Yihong Wu",
    "0qfCL-QAAAAJ": "Haim H. Permuter",
    "Fsz9BAUAAAAJ": "Young-Han Kim",
    "fn13u8IAAAAJ": "Robert D Nowak",
    "MzD8rjoAAAAJ": "David Tse",
    "LjsKfKYAAAAJ": "Zhaojin Wen",
    "lMkTx0EAAAAJ": "Jason Weston",
    "ri1sE34AAAAJ": "Sainbayar Sukhbaatar",
    "2k5j4eMAAAAJ": "Weizhe Yuan",
    "umivlPQAAAAJ": "Lin F. Yang (杨林)",
    "siuZCjUAAAAJ": "Ruoyu Zhang",
    "chICXXMAAAAJ": "Baihe Huang",
    "KcPrLhIAAAAJ": "Ikechukwu Uchendu",
    "LIJQ_ZYAAAAJ": "Ted Xiao",
    "-S_9ZRcAAAAJ": "Mengyuan Yan",
    "Y9CoR7QAAAAJ": "Jay Mardia",
    "87nZphcAAAAJ": "Wei-Lin Chiang",
    "Kzj3HC8AAAAJ": "Albert No",
    "FLJ86DwAAAAJ": "Ramy E. Ali",
    "Qhe5ua0AAAAJ": "Salman Avestimehr",
    "MDeIveMAAAAJ": "Basak Guler",
    "AIy7QHIAAAAJ": "Jinhyun So",
    "POlWWAsAAAAJ": "Shuai Wang",
    "_TkfqdgAAAAJ": "Lun Wang",
    "1p3dDesAAAAJ": "Qi Pang",
    "H3Uq3FcAAAAJ": "Jing Xu",
    "_7Q8uIYAAAAJ": "Lianmin Zheng",
    "xMhGYpgAAAAJ": "Ying Sheng",
    "BtwmZfQAAAAJ": "Clark Barrett",
    "3F52RjoAAAAJ": "Geng Zhao",
    "XqLiBQMAAAAJ": "Yi Ma (马毅)",
    "8jVzL_YAAAAJ": "Christina Baek",
    "hiGI9v0AAAAJ": "Zhengyuan Zhou",
    "LeshmV8AAAAJ": "Stephen Bates",
    "gFLW9qcAAAAJ": "Yixin Wang",
    "k7NgVSUAAAAJ": "Zhuoran Yang",
    "E__5Lr0AAAAJ": "Weihao Gao",
    "UE9jz_MAAAAJ": "Tianjun Zhang",
    "qwCO618AAAAJ": "Dmitri S. Pavlichin",
    "-j0q9B4AAAAJ": "Kunhe Yang",
    "67kghxAAAAAJ": "David Wagner",
    "-9geUIIAAAAJ": "Hiteshi Sharma",
    "wy0FA1cAAAAJ": "Felipe Vieira Frujeri",
    "yE4WT_0AAAAJ": "Shi Dong   (董仕）",
    "xVN3UxYAAAAJ": "Wei Zhan",
    "czxMUzcAAAAJ": "Zhen Dong",
    "9I7kD8sAAAAJ": "Brian Yu",
    "p1DZVX8AAAAJ": "Martin Wainwright",
    "MhDyxdYAAAAJ": "Song Mei",
    "hiOfejkAAAAJ": "Rajarshi Mukherjee",
    "NTb14PgAAAAJ": "Jingbo Louise Liu",
    "5lB_d78AAAAJ": "Sanjiban Choudhury",
    "Sbpra_AAAAAJ": "Gokul Swamy",
    "7t4jbPQAAAAJ": "J. Andrew Bagnell",
    "MbF6rTEAAAAJ": "Zhiwei Steven Wu",
    "cnncomYAAAAJ": "Pengtao Xie",
    "MSCQE-YAAAAJ": "Susu Xu",
    "ySwF8ioAAAAJ": "Lele Wang",
    "lyadgWkAAAAJ": "Nadim Ghaddar",
    "dYt8FGcAAAAJ": "Chuan-Zheng Lee",
    "mVkGg80AAAAJ": "Tiancheng Yu",
    "GR_DsT0AAAAJ": "Jason D. Lee",
    "L5jDQS8AAAAJ": "Janice Lan",
    "bRWa8q8AAAAJ": "Julien Piet",
    "LajpoI8AAAAJ": "Connor Chen",
    "1M79iLwAAAAJ": "Tianle Li",
    "vN-is70AAAAJ": "Ion Stoica",
    "nfX25MMAAAAJ": "Anastasios Nikolas Angelopoulos",
    "wKJeOQoAAAAJ": "Sai Praneeth Karimireddy",
    "UFlWdvUAAAAJ": "Norman Mu",
    "FXiSi-4AAAAJ": "Irena Hwang",
    "ESCWolcAAAAJ": "Ziao Wang",
    "Rn_BmTYAAAAJ": "Giulia Fanti",
    "MO7qaUIAAAAJ": "Ashok Vardhan Makkuva",
    "lPycXNcAAAAJ": "Pramod Viswanath",
    "55TAOdgAAAAJ": "sewoong oh",
    "0ei9XEUAAAAJ": "Ranvir Rana",
    "sRpY9TIAAAAJ": "Kevin Yang",
    "mAo_lUwAAAAJ": "Danqing Wang",
    "t8v3JXsAAAAJ": "Xiaomeng Yang",
    "4pWLoJEAAAAJ": "Andrew R. Cohen",
    "8m8taGEAAAAJ": "Masayoshi Tomizuka",
    "x78TL58AAAAJ": "Chen Tang",
    "VbNwxKYAAAAJ": "Jinning Li",
    "Ob0bNAUAAAAJ": "Xinyi Liu",
    "RU0ZAp4AAAAJ": "Kedar Tatwawadi",
    "w4yTWwoAAAAJ": "Mingyu Ding",
    "3yQFuR4AAAAJ": "Philip Jacobson",
    "PGdm9MUAAAAJ": "Zhanhao Hu",
    "rMDVDA8AAAAJ": "Richard Zhuang",
    "kZh8vUMAAAAJ": "Andrew Li",
    "owqhKD8AAAAJ": "Yu Bai",
    "GdOmgYwAAAAJ": "Druv Pai",
    "7HPdnqEAAAAJ": "Tavor Baharav",
    "b4PmtFkAAAAJ": "Yifei Wang 汪祎非",
    "IzUjvBYAAAAJ": "Yujie Liu",
    "OttawxUAAAAJ": "Simon Shaolei Du",
    "JKVR2ksAAAAJ": "Jingbo liu",
    "Bk5q_pAAAAAJ": "Han Zhong",
    "m8m9nD0AAAAJ": "Yunchang Yang",
    "VZHxoh8AAAAJ": "Liwei Wang",
    "1b2kKWoAAAAJ": "Chenguang Zhu",
    "nCFeUqYAAAAJ": "Tianyu Guo",
    "b957ulAAAAAJ": "Andrew Li",
    "czyretsAAAAJ": "Dan Hendrycks",
    "MzKvJhAAAAAJ": "Steven Basart",
    "6dskOSUAAAAJ": "Christopher Olah",
    "6-e-ZBEAAAAJ": "Dario Amodei",
    "Ch9iRwQAAAAJ": "Aditi Raghunathan",
    "CgItEbQAAAAJ": "Gregory Valiant",
    "MN9Kfg8AAAAJ": "Zachary C. Lipton",
    "Nn990CkAAAAJ": "Pang Wei Koh",
    "zX3ba1kAAAAJ": "Moses Charikar",
    "4zybTq4AAAAJ": "Jerry Li",
    "CpMjT0YAAAAJ": "Daniel Kang",
    "RLvsC94AAAAJ": "Tom B Brown",
    "Dtw3YBoAAAAJ": "Andrew Ilyas",
    "07qshUgAAAAJ": "Pravesh K. Kothari",
    "nxNkEiYAAAAJ": "Russ Tedrake",
    "FdNHp8QAAAAJ": "Yi Sun",
    "MK6zHkYAAAAJ": "Gautam Kamath",
    "Vb3FLmkAAAAJ": "Ilias Diakonikolas",
    "s_3ZE8kAAAAJ": "Alistair Stewart",
    "DulpV-cAAAAJ": "Daniel Kane",
    "_koixUEAAAAJ": "Stefan Wager",
    "ThJ-Ju4AAAAJ": "David Steurer",
    "i5srt20AAAAJ": "John Duchi",
    "qRAQ5BsAAAAJ": "Tim (Tianlin) Shi",
    "x1mbRloAAAAJ": "Jonathan Huggins",
    "iVLAQysAAAAJ": "Jonathan Ho",
    "xOWBOKQAAAAJ": "Sachin Patil",
    "HBztuGIAAAAJ": "Rein Houthooft",
    "XCZpOcAAAAAJ": "Wojciech Zaremba",
    "a5nY-pYAAAAJ": "Alexandre Bayen",
    "FFWXLHUAAAAJ": "Philipp Moritz",
    "VjsNXysAAAAJ": "Jur van den Berg",
    "4mVPFQ8AAAAJ": "Dylan Hadfield-Menell",
    "bLUllHEAAAAJ": "Adam Coates",
    "lsbreWwAAAAJ": "Zoe McCarthy",
    "5Iqe53IAAAAJ": "Daphne Koller",
    "9GMg6q8AAAAJ": "Tianhao Zhang",
    "I1EvjZsAAAAJ": "Matei Zaharia",
    "1FrpQaQAAAAJ": "Timothy Hunter",
    "Yxh9WWoAAAAJ": "Sanjay Krishnan",
    "ygFAcZwAAAAJ": "Ben Taskar",
    "rNcmwggAAAAJ": "Rohan Chitnis",
    "fMDLYCUAAAAJ": "Morgan Quigley",
    "SaiH1MIAAAAJ": "Karthik Narayan",
    "w-xdg4sAAAAJ": "Aude Hofleitner",
    "YYT8-7kAAAAJ": "Jia Pan",
    "ExXP2_AAAAAJ": "Ibrahim Awwal",
    "Tsh90D8AAAAJ": "Jeff Mahler",
    "VYiRfCwAAAAJ": "Marco Cusumano-Towner",
    "UWZA0v4AAAAJ": "James F. O'Brien",
    "x-n9rIMAAAAJ": "Dmitry Berenson",
    "Wk2gAZUAAAAJ": "Gal Chechik",
    "85XK-uAAAAAJ": "Pål From",
    "xaYqRfAAAAAJ": "Jan Tommy Gravdahl",
    "LMtE3FQAAAAJ": "Varun Ganapathi",
    "h3qMa1kAAAAJ": "Humphrey Hu",
    "p0sQC6sAAAAJ": "Michael Franklin",
    "23LELwEAAAAJ": "Ankush Gupta",
    "rBJV6QUAAAAJ": "Duncan Haldane",
    "8C2_ZVsAAAAJ": "Ryan C. Julian",
    "tk3X1QkAAAAJ": "Josep M Porta",
    "wVGqmWkAAAAJ": "Gal Elidan",
    "3_toKJ4AAAAJ": "Karthik Lakshmanan",
    "n1zDCkQAAAAJ": "Tang Jie",
    "qWak04oAAAAJ": "Geremy Heitz",
    "3ifikJ0AAAAJ": "Su-In Lee",
    "qTCXoLQAAAAJ": "Saurabh Amin",
    "szDNg-0AAAAJ": "Dmitri Dolgov",
    "y2pH4jcAAAAJ": "Xi Chen",
    "uFJi3IUAAAAJ": "Joseph Hellerstein",
    "DpLFv4gAAAAJ": "Carlos Guestrin",
    "DwdjBUUAAAAJ": "Alvin Wan",
    "SaboshYAAAAJ": "Ankur Dave",
    "fftO_HsAAAAJ": "Brijen Thananjeyan",
    "94RFSSsAAAAJ": "Daniel Crankshaw",
    "b8OxVWUAAAAJ": "Vikram Sreekanti",
    "GUAoEcAAAAAJ": "Scott Shenker",
    "QXyvv94AAAAJ": "Michael Mahoney",
    "K3QJPdMAAAAJ": "Bichen Wu",
    "H3LMjtoAAAAJ": "Danny Bickson",
    "IcaU830AAAAJ": "Richard Liaw",
    "X22nUYgAAAAJ": "Reynold Xin",
    "m0WCd-4AAAAJ": "Johann Schleier-Smith",
    "tfN6V84AAAAJ": "Ashwin Balakrishna",
    "NvKHgzkAAAAJ": "Raluca Ada Popa",
    "Wj4ZBFIAAAAJ": "David Patterson",
    "7P-gZioAAAAJ": "Alexey Tumanov",
    "evUv2MAAAAAJ": "Neeraja J. Yadwadkar",
    "vKlrdpEAAAAJ": "Aapo Kyrola",
    "wmZTE5gAAAAJ": "Eric Liang",
    "zP0S_ikAAAAJ": "Robert Nishihara",
    "YsXNU78AAAAJ": "Ali Ghodsi",
    "5LLV29oAAAAJ": "Shivaram Venkataraman",
    "Q8kbUQEAAAAJ": "Chenggang Wu",
    "FH9nKOAAAAAJ": "Roy Fox",
    "xdGKgtcAAAAJ": "Anthony D. Joseph",
    "PkfChMgAAAAJ": "Randy Katz",
    "jo2C_wkAAAAJ": "Patrick Wendell",
    "dB6ftCcAAAAJ": "Xiangrui Meng",
    "Bl8GgEcAAAAJ": "Michael Armbrust",
    "5JE9m1EAAAAJ": "Tathagata Das",
    "S8D-DqEAAAAJ": "Qifan Pu",
    "b0ehAgIAAAAJ": "Amir Gholami",
    "Zldo9CAAAAAJ": "Xinghao Pan",
    "mQf5cE0AAAAJ": "Joshua Rosen",
    "cl7CnNYAAAAJ": "John R. Gilbert",
    "hRB3wSgAAAAJ": "Aydın Buluç",
    "WXbhp_4AAAAJ": "Ali Ghodsi",
    "_pv1sEcAAAAJ": "Ahmed M. Alaa",
    "DZ3S--MAAAAJ": "Mihaela van der Schaar",
    "kiFd6A8AAAAJ": "Jinsung Yoon",
    "mnU3HpcAAAAJ": "Ioana Bica",
    "NDyEvlQAAAAJ": "Atul J. Butte",
    "Q-v0BgUAAAAJ": "Anthony Philippakis",
    "LfcroyAAAAAJ": "David Sontag",
    "3yT6IX4AAAAJ": "Adrian L Harris",
    "rIjeeRsAAAAJ": "Tom Hartvigsen",
    "L-diWvQAAAAJ": "Deepti Gurdasani",
    "-zaDQ10AAAAJ": "Mark van der Laan",
    "0bwP0i4AAAAJ": "Lars van der Laan",
    "eWRBqsYAAAAJ": "Alicia Curth",
    "CzOD0S4AAAAJ": "Travis Ian Zack",
    "gzpWXPcAAAAJ": "Marie-Laure Charpignon",
    "on2DUKoAAAAJ": "David Ouyang",
    "pzw1-J4AAAAJ": "Inioluwa Deborah Raji",
    "23ZXZvEAAAAJ": "James Zou",
    "VecEj6kAAAAJ": "Gopala K. Anumanchipalli",
    "O43_7KUAAAAJ": "Jivat Neet Kaur",
    "6QWsktwAAAAJ": "Pradeep Natarajan",
    "gd04NQ8AAAAJ": "Zhi Yu",
    "zxB06pcAAAAJ": "Maya Petersen, MD, PhD",
    "QZCU3NkAAAAJ": "Emre Kıcıman",
    "AIZoRQIAAAAJ": "Melanie F. Molina, MD, MAS",
    "xT19Jc0AAAAJ": "Bin YU",
    "YNoe5GAAAAAJ": "Chris Holmes",
    "tX3YzCcAAAAJ": "Jinoos Yazdany",
    "aa9LMvoAAAAJ": "Vivek Rudrapatna",
    "xkH30GgAAAAJ": "Zhiqing Sun",
    "Wi25oKoAAAAJ": "Xiaoyu (Rayne) Zheng",
    "B847xq8AAAAJ": "Christian Borgs",
    "YAHWbtkAAAAJ": "Jennifer Chayes",
    "_PZKLYUAAAAJ": "Amin Saberi",
    "0lZoXCUAAAAJ": "Mohammad Mahdian",
    "fNOReswAAAAJ": "Riccardo Zecchina",
    "gRxBNZoAAAAJ": "Adam Tauman Kalai",
    "_1hCq3UAAAAJ": "Nicole Immorlica",
    "SqFoZNUAAAAJ": "Noam Berger",
    "UnEHCNkAAAAJ": "Michael Brautbar",
    "opbZfw0AAAAJ": "Vahab Mirrokni",
    "8O8MQEUAAAAJ": "Henry Cohn",
    "zS3z8UgAAAAJ": "Remco van der Hofstad",
    "r44N6h8AAAAJ": "Brendan Lucier",
    "4Z6vo5QAAAAJ": "John Hopcroft",
    "QWzsNMDsvlIC": "Gordon Slade",
    "PS-TM94AAAAJ": "Mohsen Bayati",
    "DYUloYkAAAAJ": "Carlo Baldassi",
    "m_HQ-WQAAAAJ": "Alfredo Braunstein",
    "65FCPpwAAAAJ": "Moshe Tennenholtz",
    "lH1PdF8AAAAJ": "Stefano Soatto",
    "y-8unsgAAAAJ": "Marek Biskup",
    "H1vNRiUAAAAJ": "Yufei Zhao",
    "jM23vRsKxuIC": "Raissa D'Souza",
    "zkvW8FQAAAAJ": "Robert Kleinberg",
    "F_ASWCUAAAAJ": "Hamid Nazerzadeh",
    "ajIYB6wAAAAJ": "Christopher Meek",
    "osxb7aMAAAAJ": "Ilan Lobel",
    "-iPZaBcAAAAJ": "Levent Sagun",
    "c_z5hWEAAAAJ": "Pratik Chaudhari",
    "WLN3QrAAAAAJ": "Yann LeCun",
    "l-mlF7YAAAAJ": "Anna Choromanska",
    "vboGT0EAAAAJ": "Wolfhard Janke",
    "7HCKL10AAAAJ": "Abraham Flaxman",
    "LQR0kNcAAAAJ": "Stephan Mertens",
    "q4zv0KYAAAAJ": "Omid Etesami",
    "hISpTpQAAAAJ": "Sebastien Roch",
    "ftI1lBQAAAAJ": "John Z. Imbrie",
    "fkGi-JMAAAAJ": "Adam Smith",
    "-CeUxegAAAAJ": "David B. Wilson",
    "1eBgIWsAAAAJ": "\"Yashodhan Kanoria\" OR \"Yash Kanoria\"",
    "r3q68rcAAAAJ": "Andrea Montanari",
    "eQujqDgAAAAJ": "Amin Sayedi",
    "_vjPh4UAAAAJ": "R Ravi",
    "WX0pI3wAAAAJ": "Erhard Seiler",
    "EWJYRncAAAAJ": "Andrea Pagnani",
    "QxbpIMUAAAAJ": "Ozan Candogan",
    "GBQ6w8IAAAAJ": "Dimitris Achlioptas",
    "EjtpMaoAAAAJ": "Krishna Gade",
    "Wewcpo4AAAAJ": "Brian Karrer",
    "LWlN_BUAAAAJ": "Maria-Florina Balcan",
    "ZQ1Bbb8AAAAJ": "László Miklós Lovász",
    "_tNCgxMAAAAJ": "Anil Aswani",
    "LUe32ToAAAAJ": "Andrea Bajcsy",
    "KgZxzjsAAAAJ": "Shankar Sastry",
    "tsXh_hwAAAAJ": "Smitha Milli",
    "odFQXSYAAAAJ": "Rohin Shah",
    "SlZavnIAAAAJ": "Sanjit A. Seshia",
    "62e5CygAAAAJ": "Andreea Bobu",
    "eurA6WgAAAAJ": "Sandy H Huang",
    "X-Sd3-8AAAAJ": "Kush Bhatia",
    "Hyhp_zUAAAAJ": "Jodi Forlizzi",
    "4bl7qAgAAAAJ": "Nathan Ratliff",
    "sPlonWcAAAAJ": "Maya Cakmak",
    "adnTgaAAAAAJ": "Moritz Hardt",
    "_qr34PIAAAAJ": "Min Kyung Lee",
    "2ylcZSsAAAAJ": "Jessica B. Hamrick",
    "hhm6ZzUAAAAJ": "Chang Liu",
    "NOoKltoAAAAJ": "Matt Zucker",
    "SOt7sr4AAAAJ": "Elizabeth Cha",
    "jikMhF4AAAAJ": "Mehmet R. Dogar",
    "wORhZLMAAAAJ": "Chandrayee Basu",
    "slQp6UYAAAAJ": "Aaron Bestick",
    "kXB8FBoAAAAJ": "Byron Boots",
    "0jSdqoEAAAAJ": "Brian Scassellati",
    "dq3yXjkAAAAJ": "Kevin Jamieson",
    "JwiByPoAAAAJ": "Zita Marinho",
    "HPoaHyQAAAAJ": "Shervin Javdani",
    "wLf0Vw0AAAAJ": "Roberto HOROWITZ",
    "oAlCitYAAAAJ": "Negar Mehr",
    "jIs-Y2gAAAAJ": "Andrea Thomaz",
    "km6CP8cAAAAJ": "Aaron Courville",
    "MOgfm8oAAAAJ": "David Warde-Farley",
    "c646VbAAAAAJ": "Mehdi Mirza",
    "nHh9PSsAAAAJ": "Bing Xu",
    "6F3ZIeEAAAAJ": "Jean Pouget-Abadie",
    "cGxq0cMAAAAJ": "Nicolas Papernot",
    "nCh4qyMAAAAJ": "Alexey Kurakin",
    "AMGqrI0AAAAJ": "Patrick McDaniel",
    "Vs-MdPcAAAAJ": "Samy Bengio",
    "I66ZBYwAAAAJ": "Colin Raffel",
    "GgQ9GEkAAAAJ": "Rob Fergus",
    "L4bNmsMAAAAJ": "Joan Bruna",
    "vWTI60AAAAAJ": "Martin Abadi",
    "XD_01h8AAAAJ": "Kunal Talwar",
    "dOad5HoAAAAJ": "Alec Radford",
    "w68-7AYAAAAJ": "Tim Salimans",
    "hg3A9TgAAAAJ": "Ilya Mironov",
    "iKPWydkAAAAJ": "H. Brendan McMahan",
    "wFEJvJUAAAAJ": "Li Zhang",
    "ijH0-a8AAAAJ": "Florian Tramèr",
    "MwLqCs4AAAAJ": "Dan Boneh",
    "KOBmy0sAAAAJ": "James Bergstra",
    "kjMNMLkAAAAJ": "Navdeep Jaitly",
    "B0KVWJEAAAAJ": "Alireza Makhzani",
    "RjQ7YnMAAAAJ": "Brendan Frey",
    "2r2NuDAAAAAJ": "Andrew Dai",
    "5tVuggUAAAAJ": "(Peter) Xi Chen",
    "BaI7l8QAAAAJ": "Somesh Jha",
    "g1I269gAAAAJ": "Z. Berkay Celik",
    "TvdMDhwAAAAJ": "Catherine Olsson",
    "_S_1cEEAAAAJ": "Frédéric Bastien",
    "bn4xHHIAAAAJ": "Pascal Lamblin",
    "zIv6YN0AAAAJ": "Yaroslav Bulatov",
    "cX2HlhQAAAAJ": "Úlfar Erlingsson",
    "KUG_tG0AAAAJ": "Fartash Faghri",
    "6QpFL68AAAAJ": "Arnaud Bergeron",
    "7nlvOMQAAAAJ": "Tianqi Chen",
    "h0Al1fcAAAAJ": "Andrew Saxe",
    "mG4imMEAAAAJ": "Andrew Ng",
    "M5zMoh4AAAAJ": "Vinay Shet",
    "-ZfwQOkAAAAJ": "William Fedus",
    "Yxv1EwcAAAAJ": "Guillaume Desjardins",
    "s2lG0X0AAAAJ": "Takeru Miyato",
    "mZfgLA4AAAAJ": "Vincent Dumoulin",
    "qOC97ysAAAAJ": "Reuben Feinman",
    "sUK_w2QAAAAJ": "Thomas Leung",
    "Y6L6ZYsAAAAJ": "Yang Song",
    "vfT6-XIAAAAJ": "Quoc V. Le",
    "zqLpO2QAAAAJ": "Olivier Delalleau",
    "NMS69lQAAAAJ": "Jeff Dean",
    "miDt1j8AAAAJ": "Grégoire Mesnil",
    "_WnkXlkAAAAJ": "Xavier Glorot",
    "XSforroAAAAJ": "Yann N. Dauphin",
    "TMawhM4AAAAJ": "Salah Rifai",
    "WBCKQMsAAAAJ": "Pascal Vincent",
    "TB5OwW8AAAAJ": "Olga Russakovsky",
    "YvdzeM8AAAAJ": "Stephen Gould",
    "MpJ00PUAAAAJ": "Alexander Sorokin",
    "yFEHsv4AAAAJ": "Leila Takayama",
    "vKAKE1gAAAAJ": "Caroline Rebecca Pantofaru",
    "Slq0rJcAAAAJ": "Marius Muja",
    "7mnKGGEAAAAJ": "Stephan Zheng",
    "V3JjNJ0AAAAJ": "Karen Hambardzumyan",
    "GdXOFKoAAAAJ": "Berivan Isik",
    "ljxAoR8AAAAJ": "Sunghwan Kim",
    "1azFZ6cAAAAJ": "Hosung Park",
    "ZL-p_cIAAAAJ": "Jong-Seon No",
    "8gEhRVgAAAAJ": "idoia ochoa",
    "CNOqUZoAAAAJ": "Ernest K. Ryu",
    "0IkkBzQAAAAJ": "Amir Ingber",
    "Mu7NXDwAAAAJ": "Jeong Wook Lee",
    "i-g1zC0AAAAJ": "Alexandros Manolakos",
    "II8VI8IAAAAJ": "Joo Young Choi",
    "ARo4eW0AAAAJ": "Minseok Choi",
    "F5PJHPcAAAAJ": "Joongheon Kim",
    "mCuJP1UAAAAJ": "Hyun Kim",
    "vyNLRqgAAAAJ": "Hyuk-Jae Lee",
    "G9DVxcQAAAAJ": "Jongmin Lee",
    "-mh8RQ8AAAAJ": "Mikel Hernaez",
    "JmdnBzcAAAAJ": "Yongqin Xian",
    "bqTPA8kAAAAJ": "Massimiliano Mancini",
    "q9zQhj8AAAAJ": "A. Sophia Koepke",
    "mzZa_yQAAAAJ": "Stephan Alaniz",
    "93ZjIs0AAAAJ": "Karsten Roth",
    "IvqCXP4AAAAJ": "Cordelia Schmid",
    "jEANvfgAAAAJ": "Scott Reed",
    "r8Zh-jwAAAAJ": "Florent Perronnin",
    "1aKTzmIAAAAJ": "Anjan Dutta",
    "u66VocEAAAAJ": "Yanbei Chen",
    "74Cj5GYAAAAJ": "Eric Schulz",
    "OiVCfscAAAAJ": "Shyamgopal Karthik",
    "mW2Jtu0AAAAJ": "Wenjia Xu（许文嘉）",
    "jJz3mXcAAAAJ": "Leonard Salewski",
    "eP6FHFAAAAAJ": "Jae Myung Kim",
    "yCyR-TsAAAAJ": "Zaid Harchaoui",
    "lnCKs0AAAAAJ": "Samarth Sinha",
    "kmXOOdsAAAAJ": "Seong Joon Oh",
    "Zgk0Z6kAAAAJ": "Uddeshya Upadhyay",
    "xfskSZEAAAAJ": "Xinchen Yan",
    "eSPY7nMAAAAJ": "Otniel-Bogdan Mercea",
    "tvgSaXsAAAAJ": "Edgar Schönfeld",
    "wcOO6hgAAAAJ": "Jiuniu WANG",
    "mHbdIAwAAAAJ": "Barbara Caputo",
    "Lvm9Q8QAAAAJ": "Marcel Binz",
    "iCf3SwgAAAAJ": "Christoph H. Lampert",
    "PR2DwYYAAAAJ": "Muhammad Ferjad Naeem",
    "Mkaq4VYAAAAJ": "Sarkhan Badirli",
    "UvNbBnEAAAAJ": "Murat Dundar",
    "-xA1_OAAAAAJ": "Aykut Erdem",
    "eALwl74AAAAJ": "Erkut Erdem",
    "J-vrZ58AAAAJ": "George Mohler",
    "gf-aMd0AAAAJ": "Tobias Lorenz",
    "1H2H7XAAAAAJ": "Junsuk Choe",
    "W1a8vwIAAAAJ": "Isabel Rio-Torto",
    "ILgZT7MAAAAJ": "Anna Khoreva",
    "8200InoAAAAJ": "Max Welling",
    "brsVjNcAAAAJ": "Thomas Hummel",
    "zIS5ibQAAAAJ": "Christine Picard",
    "I8A1STcAAAAJ": "Levent Karacan",
    "Px3ZQ08AAAAJ": "Samuel Tenka",
    "WJNkMakAAAAJ": "Quynh Nguyen",
    "0ZAb3tsAAAAJ": "Matthias Hein",
    "tmZ8MaAAAAAJ": "Gaurav Sharma",
    "TfInmkIAAAAJ": "Marco Federici",
    "yIg7b2gAAAAJ": "Oana-Maria Camburu",
    "4_uj0xcAAAAJ": "Sanghyuk Chun",
    "KB5XZGIAAAAJ": "Hyunjung Shim",
    "vUM0nAgAAAAJ": "Seungho Lee",
    "SVNNgu4AAAAJ": "Rodrigo Benenson",
    "beVJGycAAAAJ": "Julian Coda-Forno",
    "-fEOFbMAAAAJ": "Fabio Cermelli",
    "SrVnrPcAAAAJ": "Andreas Geiger",
    "aCQjyp0AAAAJ": "João F. Henriques",
    "V8fBl-0AAAAJ": "Andreea-Maria Oncescu",
    "BTBd5V4AAAAJ": "Andreas Holzinger",
    "TFsE4BIAAAAJ": "Federico Tombari",
    "bZVkVvoAAAAJ": "Enkelejda Kasneci",
    "Sx75CVsAAAAJ": "Olivier J Hénaff",
    "0z0fNxUAAAAJ": "Matthias Bethge",
    "IUqydU0AAAAJ": "Diego Marcos",
    "arjucpEAAAAJ": "Thomas Lukasiewicz",
    "u3QYKhkAAAAJ": "Virginie Do",
    "YizAq4gAAAAJ": "Jane X. Wang",
    "I_YIc0YAAAAJ": "Nate Kushman",
    "fWbf74cAAAAJ": "Patrick Forré",
    "hdrXRx8AAAAJ": "Subhabrata Choudhury",
    "t9ahuxsAAAAJ": "Katrin Renz",
    "wbqHAq0AAAAJ": "Luca Eyring",
    "RWV9I_IAAAAJ": "Youngwook Kim",
    "2R22h84AAAAJ": "Hendrik PA Lensch",
    "2CGNfAEAAAAJ": "Yao Rong",
    "IEcsMPAAAAAJ": "Dr. Biplab Banerjee",
    "ZbA-z1cAAAAJ": "Xiatian Zhu",
    "8UinjA0AAAAJ": "Lukas Riesch",
    "-4PyWB0AAAAJ": "Kristin Witte",
    "B42Mr-sAAAAJ": "Akshay K. Jagadish",
    "z7WhDRIAAAAJ": "Anders Christensen",
    "7VAwhzUAAAAJ": "Ole Winther",
    "FPRvtUEAAAAJ": "Victor Garcia Satorras",
    "IqJ3zskAAAAJ": "Mateusz Malinowski",
    "jUOcawkAAAAJ": "Vishaal Udandarao",
    "0kK7sSAAAAAJ": "Ameya Prabhu",
    "8vAIQXoAAAAJ": "Sebastian Dziadzio",
    "xk6HHiAAAAAJ": "Leander Girrbach",
    "QURZIzUAAAAJ": "Andreas Bulling",
    "wv5oKToAAAAJ": "Nour Karessli",
    "YC-3YaYAAAAJ": "Lukas Thede",
    "vX5i2CcAAAAJ": "Kashyap Chitta",
    "f9iP-80AAAAJ": "Christian Bauckhage",
    "pchPMh0AAAAJ": "Anurag Das",
    "xf1T870AAAAJ": "Elisa Ricci",
    "3nlXVhAAAAAJ": "Maxime Kayser",
    "jHR4dXcAAAAJ": "Cornelius Emde",
    "T0yIjk4AAAAJ": "Bruno Korbar",
    "ss8KR5gAAAAJ": "Lorenzo Torresani",
    "0eFZtREAAAAJ": "Matthijs Douze",
    "6KWxpxkAAAAJ": "Abhra Chaudhuri",
    "4oXBp9UAAAAJ": "Ying Shan",
    "J2Z-ChoAAAAJ": "Rodolfo Corona",
    "j98IWfoAAAAJ": "Jungwoo Lee",
    "WsbgVR4AAAAJ": "laurens Weitkamp",
    "sqWpn2AAAAAJ": "Fabian J Theis",
    "xnQZonMAAAAJ": "Théo Uscidda",
    "9r_f1w4AAAAJ": "Emily M. Bender",
    "0HuMHFwAAAAJ": "Samuel Gershman",
    "v6YG0YEAAAAJ": "Ilke Cugu",
    "s9UDcdYAAAAJ": "Martin Schiegg",
    "1kZgyI8AAAAJ": "Xiahan Shi",
    "7vCEi-gAAAAJ": "Sergios Gatidis",
    "AqYyoCMAAAAJ": "Mark Ibrahim",
    "pHblCTAAAAAJ": "Andrei Neculai",
    "564o-vIAAAAJ": "Elise van der Pol",
    "mMifMdoAAAAJ": "Ulrike von Luxburg",
    "6PnL3BgAAAAJ": "Sebastian Bordt",
    "M_NWm1wAAAAJ": "Bharat Lal Bhatnagar",
    "OpXMNnMAAAAJ": "Gerard Pons-Moll",
    "U4tFPMQAAAAJ": "Julian Chibane",
    "nWboYt0AAAAJ": "Ushasi Chaudhuri",
    "vWDTlWoAAAAJ": "Ruchika Chavhan",
    "weicM8wAAAAJ": "Kevin Smith",
    "Xtgj8q0AAAAJ": "Michael Kirchhof",
    "2GCPK34AAAAJ": "Sadaf Gulshad",
    "aa5Ou7gAAAAJ": "Arnold Smeulders",
    "w047VfEAAAAJ": "Jan Hendrik Metzen",
    "0A3yyk4AAAAJ": "Mevlana Gemici",
    "_kKvHOAAAAAJ": "Vikrant Rangnekar",
    "jzx6_ZIAAAAJ": "Torsten Sattler",
    "w6hmCEYAAAAJ": "Yuchen Ma",
    "yhz7sFoAAAAJ": "Yana Hasson",
    "9RyeFYwAAAAJ": "Dr. Marzyeh Ghassemi",
    "p3iJiLIAAAAJ": "Devis Tuia",
    "aEd4RLgAAAAJ": "Volker Fischer",
    "JNER_T4AAAAJ": "Lennart Alexander Van der Goten",
    "AVDkgFIAAAAJ": "Maarten de Rijke",
    "ZyaLOy4AAAAJ": "Henry Prakken",
    "rwBWbFAAAAAJ": "Mark Neerincx",
    "l6c85tMAAAAJ": "Holger Hoos",
    "nShf6cgAAAAJ": "Eunji Kim",
    "VxpypngAAAAJ": "Kihyuk Sohn",
    "OaAO-aIAAAAJ": "Yang He (贺洋)",
    "SgbYgdsAAAAJ": "Saurabh Sharma",
    "sUz6qxwAAAAJ": "Thomas Hummel",
    "FcFAKFEAAAAJ": "ANURAG DAS",
    "iXOzeWUAAAAJ": "Diane Bouchacourt",
    "2efgcS0AAAAJ": "Jiajun Wu",
    "3hdOFF0AAAAJ": "Ilker Yildirim",
    "0zZnyMEAAAAJ": "William T. Freeman",
    "rrPyvsgAAAAJ": "Tejas Kulkarni",
    "xBv5ZfkAAAAJ": "Inderjit S. Dhillon",
    "qYhRbJoAAAAJ": "Prateek Jain",
    "eyCw9goAAAAJ": "Suvrit Sra",
    "FHLTntIAAAAJ": "Xide Xia",
    "pJ28HA0AAAAJ": "Bart Selman",
    "JoClQPUAAAAJ": "Ali Siahkamari",
    "0kV69XQAAAAJ": "Sugato Basu",
    "eP2Z3qQAAAAJ": "Matyas A Sustik",
    "5IzwG1AAAAAJ": "Jiawen Chen",
    "RfSQKrIAAAAJ": "Tianfan Xue",
    "S4z3uzMAAAAJ": "Venkatesh Saligrama",
    "eLFhiSYAAAAJ": "Kun He",
    "oX-nvpwAAAAJ": "Fatih Cakir",
    "gX7rSCcAAAAJ": "Jonathan P. How",
    "UfAyRKEAAAAJ": "Trevor Campbell",
    "sI0wlX8AAAAJ": "Rajath Kumar",
    "5zZjmvEAAAAJ": "Sang Peter Chin",
    "1UirFygAAAAJ": "Qichao Que",
    "yQNhFGUAAAAJ": "Peter Bartlett",
    "dPX0wQcAAAAJ": "Tamara Broderick",
    "rtWKzFwAAAAJ": "John C. Platt",
    "7QHvAEYAAAAJ": "Miao Liu",
    "edQgLXcAAAAJ": "Matthew E. Taylor",
    "reUYd_0AAAAJ": "Ben Usman",
    "2mjUsP8AAAAJ": "Srinivasan Parthasarathy",
    "biuxbRsAAAAJ": "Tim Kraska",
    "F_MI0pcAAAAJ": "Alon Halevy",
    "NjeM1LsAAAAJ": "Renee Miller",
    "a1ngrCIAAAAJ": "Samuel Madden",
    "DV8z8DYAAAAJ": "Mitesh Khapra",
    "yxWtZLAAAAAJ": "Sarath Chandar",
    "4PqxB3gAAAAJ": "V Srinivasa Chakravarthy",
    "P6l5tBcAAAAJ": "Sahil Sharma",
    "QDuPGHwAAAAJ": "K Madhava Krishna",
    "R-Cgh08AAAAJ": "Vikas C. Raykar",
    "CMIgrCgAAAAJ": "Andrew Barto",
    "YOVZiJkAAAAJ": "Milind Tambe",
    "GhrKC1gAAAAJ": "Aravind Srinivas",
    "3Zb5Y2YAAAAJ": "Amrita Saha",
    "M6IjHhoAAAAJ": "Pragathi Priyadharsini Balasubramani",
    "9Sf0vd4AAAAJ": "Ahmed Moustafa",
    "R71GD9MAAAAJ": "Karthik V Aadithya",
    "FX5CsuYAAAAJ": "Nick Jennings",
    "6_MJikoAAAAJ": "Priyesh Vijayan",
    "LNXEjT8AAAAJ": "Harshavardhan Kamarthi",
    "hmoy8ssAAAAJ": "Preksha Nema",
    "yaOyQOQAAAAJ": "Shivashankar Subramanian",
    "2c_x00gAAAAJ": "Balaji Vasan Srinivasan",
    "qkn2yIIAAAAJ": "Karthik Raman",
    "EtTJi3oAAAAJ": "Saket Gurukar",
    "llF8XbMAAAAJ": "Sriraam Natarajan",
    "YgykRA0AAAAJ": "Tomasz Michalak",
    "Oy8M_4QAAAAJ": "Anasua Mitra",
    "-novlhIAAAAJ": "Janarthanan Rajendran",
    "p-PdgdYAAAAJ": "Deepak Mittal",
    "h4DSY8MAAAAJ": "Vignesh Prasad",
    "iAkcJ2oAAAAJ": "Gitakrishnan Ramadurai",
    "eZmKjZEAAAAJ": "Piotr L. Szczepański",
    "5n5leq4AAAAJ": "Bharat Kaul",
    "m5hqkt0AAAAJ": "Meha kaushik",
    "jH79pJkAAAAJ": "Vikram Pudi",
    "OP7F8jEAAAAJ": "Anand Raghunathan",
    "x9ly9Q0AAAAJ": "Anirban Santara",
    "C_4IMR4AAAAJ": "Akash Kumar Mohankumar",
    "I5-0kFQAAAAJ": "Stanislas Lauly",
    "6p-OvCcAAAAJ": "Sudarsun Santhiappan",
    "kamjbL0AAAAJ": "Manan Tomar",
    "SvmrjK4AAAAJ": "Prasanna Parthasarathi",
    "UmwJklEAAAAJ": "Mohammed J. Zaki",
    "mh6kznYAAAAJ": "Peeyush Kumar",
    "8RtQzSQAAAAJ": "SHWETA BHARDWAJ",
    "PEzAWAwAAAAJ": "Sangameshwar Patil",
    "dQ0dT2sAAAAJ": "Bryan Wilder",
    "j54VcVEAAAAJ": "Doina Precup",
    "6m4wv6gAAAAJ": "Richard S. Sutton",
    "8RgDBoEAAAAJ": "Satinder Singh",
    "1pMBYn8AAAAJ": "Ramasuri Narayanam",
    "DbeHYRcAAAAJ": "Sankaran Vaidyanathan",
    "0J10RyoAAAAJ": "Anirban Laha",
    "MDfW21AAAAAJ": "pranjal awasthi",
    "K4w5qYUAAAAJ": "Sayan Ranu",
    "p2R-FRoAAAAJ": "Dheevatsa Mudigere",
    "2g0uKnAAAAAJ": "Sasikanth Avancha",
    "LGF6qesAAAAJ": "Ashish Tendulkar",
    "4SDTMIQAAAAJ": "Ritwik Sinha",
    "Ss2KBccAAAAJ": "Aswin Raghavan",
    "9gV4DRsAAAAJ": "Abhishek Naik",
    "b6zhmt0AAAAJ": "Beethika Tripathi",
    "WPESKq0AAAAJ": "KP Naveen",
    "VFixSK8AAAAJ": "Subhojyoti Mukherjee",
    "pe6tmKAAAAAJ": "Shravan Matthur Narayanamurthy",
    "aEOTSMEAAAAJ": "Dipanjan Chakraborty",
    "cZBq_9MAAAAJ": "Kaushik Mitra",
    "2iusLHoAAAAJ": "Pradyot Korupolu VN",
    "rWZq2nQAAAAJ": "Varun Gangal",
    "_D_j2aoAAAAJ": "Dinakar Jayarajan",
    "3Q6vpxYAAAAJ": "Avijit Saha",
    "89u7qcIAAAAJ": "Himanshu Sinha",
    "pfG0_pEAAAAJ": "Kamakoti Veezhinathan",
    "QPCr30IAAAAJ": "Jeshuren Chelladurai",
    "cH2eTqAAAAAJ": "Amari S*",
    "jMSF3ukAAAAJ": "Magdoom Kulam",
    "u-T21zUAAAAJ": "Delip Rao",
    "Vtzdv-MAAAAJ": "Addwiteey Chrungoo",
    "g7E_CLwAAAAJ": "Debarun Kar",
    "d3MKMggAAAAJ": "karthik azhagesan",
    "AQ8w2uEAAAAJ": "Hema A Murthy",
    "y_4QsYAAAAAJ": "Amy McGovern",
    "9FSuHUQAAAAJ": "Jeremy Wyatt",
    "TW1vSVUAAAAJ": "Jose I. Nunez-Varela",
    "mIFso2kAAAAJ": "Arun Tejasvi Chaganty",
    "sLVkoTgAAAAJ": "Asokan Thondiyath",
    "332L1coAAAAJ": "Ameet Deshpande",
    "arZclaMAAAAJ": "SaiNageswar Satchidanand",
    "l3yJjKIAAAAJ": "Soumya Eachempati",
    "-p2OOuQAAAAJ": "Abhishek Narwekar",
    "LrsjJfwAAAAJ": "Vaishnavh Nagarajan",
    "6MpBAH4AAAAJ": "Dibu Philip",
    "vB_P3HUAAAAJ": "Suhas Jayaram Subramanya",
    "9CW-7GAAAAAJ": "Suril V. Shah",
    "aMUoVMMAAAAJ": "Rama Kumar Pasumarthi",
    "e7oZHCsAAAAJ": "Sai Kiran Narayanaswami",
    "u11FXaoAAAAJ": "Ayan Acharya",
    "GyFb98kAAAAJ": "Rakesh R Menon",
    "5xYDlvgAAAAJ": "Deepak Pai",
    "nqDmEHUAAAAJ": "Sukhendu Das",
    "l2RQ_S8AAAAJ": "Swagath Venkataramani",
    "Qt2d3BoAAAAJ": "Jyotika Bahuguna",
    "_TgBTNwAAAAJ": "Prathamesh Deshpande",
    "6vQmgzcAAAAJ": "Lakshmi Ramachandran",
    "Nn_Ee0IAAAAJ": "Bhanu Chander V",
    "Sr7jln4AAAAJ": "Sathiya Keerthi Selvaraj",
    "yK4caV0AAAAJ": "Nilanjan Banerjee",
    "HLfQbBkAAAAJ": "Alan Tickle",
    "IEHo6YcAAAAJ": "Ed Gehringer",
    "Qk8Wh5UAAAAJ": "Nandan Sudarsanam",
    "Xnk4W5cAAAAJ": "Joydeep Ghosh",
    "0KhH2ioAAAAJ": "Ramkrishna Pasumarthy",
    "UsDuS10AAAAJ": "Phani Teja Singamaneni",
    "IhhuIZcAAAAJ": "Ashutosh Kumar Jha",
    "cbIxOLYAAAAJ": "GIRRAJ PAHARIYA",
    "pKEjWnsAAAAJ": "Subendhu Rongali",
    "EIw2QBsAAAAJ": "Sanchari Sen",
    "VdBfGdoAAAAJ": "Sofya Raskhodnikova",
    "U-RE8IgAAAAJ": "Kobbi Nissim",
    "1KRXBIwAAAAJ": "Leonid Reyzin",
    "3yPEc4YAAAAJ": "Yevgeniy Dodis",
    "WfS41RAAAAAJ": "Jonathan Ullman",
    "1rV69hMAAAAJ": "Abhradeep Guha Thakurta",
    "YYJ3aycAAAAJ": "Frank McSherry",
    "XnHdkZUAAAAJ": "Shiva Kasiviswanathan",
    "UvFrX04AAAAJ": "Rafail Ostrovsky",
    "H4rKFc8AAAAJ": "Jonathan Katz",
    "C8qMVQUAAAAJ": "Raef Bassily",
    "kwnwhrgAAAAJ": "Thomas Steinke",
    "373HnhYAAAAJ": "Daniel Gottesman",
    "BLPO9lMAAAAJ": "Claude Crépeau",
    "nRM32-QAAAAJ": "Homin K. Lee",
    "gBkMDloAAAAJ": "Gavin Brown",
    "9wibWOoAAAAJ": "Audra McMillan",
    "8gw3UCMAAAAJ": "Albert Cheu",
    "-PWcE1YAAAAJ": "Ran Canetti",
    "oDwLyYUAAAAJ": "Mark Bun",
    "dqVjyRQAAAAJ": "Salil Vadhan",
    "7wXWIdUAAAAJ": "Benjamin Fuller",
    "Znp3UkEAAAAJ": "Shuchi Chawla",
    "Ew7QLzsAAAAJ": "Uri Stemmer",
    "PiZymREAAAAJ": "Chris Peikert",
    "qIPV_KsAAAAJ": "Jinhui Xu",
    "yORoyhsAAAAJ": "Omer Paneth",
    "Es6jE1kAAAAJ": "Venkatesan Guruswami",
    "AbRFE3IAAAAJ": "Grigory Yaroslavtsev",
    "TOZ-J_wAAAAJ": "Vishesh Karwa",
    "-zlRjYcAAAAJ": "Raghav Bhaskar",
    "OrUyRAcAAAAJ": "Keith Rush",
    "ZnT-QpMAAAAJ": "Nathan Srebro",
    "zc920lAAAAAJ": "Yuval Ishai",
    "XY2YaEkAAAAJ": "Satchit Sivakumar",
    "gqB23VMAAAAJ": "Amit Sahai",
    "QdTErIEAAAAJ": "Daniel Kifer",
    "5b8D1MgAAAAJ": "Marco Gaboardi",
    "5hGRe_QAAAAJ": "Di Wang",
    "lG7aUrkAAAAJ": "Hoeteck Wee",
    "tAM57M8AAAAJ": "Alain Tapp",
    "eghKB-0AAAAJ": "Howard Barnum",
    "8CsZAHUAAAAJ": "Jayshree Sarathy",
    "H3ExIrEAAAAJ": "Amir Shpilka",
    "m-L5Hj0AAAAJ": "Christian Schaffner",
    "t11U6_sAAAAJ": "Marco Tomamichel",
    "BnQdO2UAAAAJ": "Blake Woodworth",
    "vtuhhp8AAAAJ": "Srivatsan Laxman",
    "SIFRrBIAAAAJ": "Adam O'Neill",
    "stSUaHAAAAAJ": "Moni Naor",
    "NE4K0XUAAAAJ": "Marika Swanberg",
    "Wy0bQrwAAAAJ": "Andris Ambainis",
    "jr7gGB4AAAAJ": "Ryan Rogers",
    "kLUQrrYAAAAJ": "Aaron Roth",
    "j5N3bKYAAAAJ": "Om Thakkar",
    "pZhZndYAAAAJ": "Ronitt Rubinfeld",
    "Te94nKAAAAAJ": "abhi shelat",
    "gjLr_FgAAAAJ": "Clément L. Canonne",
    "18exh0MAAAAJ": "Tal Rabin",
    "vHTMzPQAAAAJ": "Jalaj Upadhyay",
    "plbHxNUAAAAJ": "Aleksandra Slavkovic",
    "g7Op2tgAAAAJ": "Aloni Cohen",
    "cnPetCkAAAAJ": "Gil Segev",
    "PoDj4lsAAAAJ": "Jesper Buus Nielsen",
    "-UhqXIEAAAAJ": "Ivan Damgård",
    "ZUEtS-EAAAAJ": "Giovanni Di Crescenzo",
    "okLwXk0AAAAJ": "Ilias Zadik",
    "22dxhNQAAAAJ": "Michael Ben-Or",
    "CnBvgwcAAAAJ": "avinatan hassidim",
    "g3t0ihoAAAAJ": "Jialei Wang",
    "8d8jP60AAAAJ": "Eike Kiltz",
    "g2xwfAMAAAAJ": "payman mohassel",
    "BYLsgysAAAAJ": "Vipul Goyal",
    "GqZBmfgAAAAJ": "Vitaly Feldman",
    "QYNU5jMAAAAJ": "Bhavana Kanukurthi",
    "JpB-xkUAAAAJ": "Adam Groce",
    "5w0Y9JUAAAAJ": "Jens Groth",
    "ZIlzcYcAAAAJ": "Craig Gentry",
    "gvo0nMsAAAAJ": "Kevin Butler",
    "aM1rfhEAAAAJ": "Shabsi Walfish",
    "aKBwXEEAAAAJ": "Matthias Fitzi",
    "RBX7SrkAAAAJ": "Shai Halevi",
    "Q0crxvwAAAAJ": "Maryam Aliakbarpour",
    "Y_XwzKQAAAAJ": "Sophia Yakoubov",
    "E_a3VB4AAAAJ": "Samuel B. Hopkins",
    "s1UQI6kAAAAJ": "Lydia Zakynthinou",
    "A6C3geAAAAAJ": "Fang Song",
    "xiiiSa8AAAAJ": "Sergey Denisov",
    "PQtLkV0AAAAJ": "Daniel Alabi",
    "YPq45Q0AAAAJ": "Sarah Scheffler",
    "1Uk-ZIAAAAAJ": "Govind Ramnarayan",
    "ViBqWZYAAAAJ": "Nishanth Dikkala",
    "P1-HgxMAAAAJ": "Ira Globus-Harris",
    "5sz_jBoAAAAJ": "Gary King",
    "5qo8bOkAAAAJ": "Iden Kalemaj",
    "RZueBXQAAAAJ": "Georgie Evans",
    "KcM-4NsAAAAJ": "William Enck",
    "0b9YnbYAAAAJ": "Mark D. Flood",
    "3dxS1VYAAAAJ": "Stephen E Fienberg 1942-2016",
    "rAP3wVwAAAAJ": "Jing Lei",
    "F2gY_WkAAAAJ": "Anne-Sophie Charest",
    "g3DjOkMAAAAJ": "Joerg Drechsler",
    "y1u15RcAAAAJ": "Quanquan C. Liu",
    "woqUivYAAAAJ": "Anna Lysyanskaya",
    "01ks8yYAAAAJ": "Eric Kolaczyk",
    "ZzJO3UkAAAAJ": "Prashant Nalini Vasudevan",
    "yTd5KnYAAAAJ": "Shurong Lin",
    "pEyaa44AAAAJ": "Connor Wagaman",
    "k6-nvDAAAAAJ": "Milad Nasr",
    "xa-6ZlkAAAAJ": "Borja Balle",
    "Jlv4MR4AAAAJ": "Avrim Blum",
    "t0ZfFH8AAAAJ": "Jamie Morgenstern",
    "yriZqCMAAAAJ": "Ankit Sharma",
    "hb1bGgUAAAAJ": "Mark Lewko",
    "IkEXPUEAAAAJ": "Charalampos E. Tsourakakis",
    "4yuKD_AAAAAJ": "Luca Trevisan",
    "P_q1TRgAAAAJ": "Ronen Shaltiel",
    "4WEQ8h0AAAAJ": "Sergey Yekhanin",
    "fb2-dasAAAAJ": "Parikshit Gopalan",
    "iOLC30YAAAAJ": "Wen Sun",
    "8S5AOggAAAAJ": "Kianté Brantley",
    "FuGllAwAAAAJ": "Christoph Dann",
    "9nnDvooAAAAJ": "Alekh Agarwal",
    "o42MH0MAAAAJ": "Wenhao Zhan",
    "4ANbX-YAAAAJ": "Zhaolin Gao",
    "y0B6gawAAAAJ": "Owen Oertell",
    "0QDCG8IAAAAJ": "Yuda Song",
    "vGBcNVAAAAAJ": "Aarti Singh",
    "AgPS44sAAAAJ": "Juntao Ren",
    "5tk1PV8AAAAJ": "Thorsten Joachims",
    "AtMBDPUAAAAJ": "Yiding Chen",
    "5ApCTCoAAAAJ": "Zuxin Liu",
    "QUmyfogAAAAJ": "Konwoo Kim",
    "z7tPc9IAAAAJ": "Ding Zhao",
    "yjPHHb8AAAAJ": "Nicolas Espinosa-Dice",
    "eBtFiuAAAAAJ": "Runzhe Wu",
    "_qY_t5kAAAAJ": "Jonathan D. Chang",
    "4WLoIRsAAAAJ": "Chris Lu",
    "6z4lQzMAAAAJ": "Jakob Foerster",
    "FxdgVLkAAAAJ": "Silvia Sapora",
    "R6jE0VEAAAAJ": "Fei Fang",
    "H0MLFHEAAAAJ": "Jingwu Tang",
    "lyG0vMQAAAAJ": "Yilin Wu",
    "uY4D8-wAAAAJ": "Ran Tian (田然)",
    "gM7zfrkAAAAJ": "Pamela Cosman",
    "8LcYFjEAAAAJ": "Geoff Gordon",
    "vx68rkMAAAAJ": "Stephanie Milani",
    "-7FMxqsAAAAJ": "Bradley Guo",
    "ViLZaDsAAAAJ": "Yiyi Zhang",
    "2ZRnqiEAAAAJ": "Vibhakar Mohta",
    "tu7wKckAAAAJ": "Arnav Kumar Jain",
    "gryqnyAAAAAJ": "Atiksh Bhardwaj",
    "_4dnp0IAAAAJ": "Kevin Leyton-Brown",
    "T04c3fwAAAAJ": "Dragomir Anguelov",
    "yFMX138AAAAJ": "Wei Liu",
    "jjEht8wAAAAJ": "Alexander C Berg",
    "FpI8dFwAAAAJ": "Pieter-Jan Kindermans",
    "_MEuWIMAAAAJ": "Dilip Krishnan",
    "j3CEIuEAAAAJ": "Nathan Silberman",
    "aGXkhcwAAAAJ": "Been Kim",
    "WL_xXbQAAAAJ": "George Trigeorgis",
    "pnOLBcoAAAAJ": "Maximilian Alber",
    "0e49RfgAAAAJ": "Kristof T. Schütt",
    "iZ5cY0AAAAAJ": "David Dohan",
    "LFiqVpwAAAAJ": "John Langford",
    "Kc8zXcgAAAAJ": "Sven Dähne",
    "xdlBKc8AAAAJ": "Pierre-Antoine Manzagol",
    "Rqy5KDEAAAAJ": "Lihong Li (李力鸿)",
    "wYMTld8AAAAJ": "Miroslav Dudik",
    "Afa_1z4AAAAJ": "Nicolas Boulanger-Lewandowski",
    "MdbxYu8AAAAJ": "Youssouf Chherawala",
    "s0njcGgAAAAJ": "Balazs KEGL",
    "bLb3VdIAAAAJ": "Douglas Eck",
    "vYRgxJ8AAAAJ": "Olivier Chapelle",
    "jNCbl2IAAAAJ": "Eugene Ie",
    "SYvhSBcAAAAJ": "Martin Stumpe",
    "MyPTNBgAAAAJ": "Qian Yu",
    "M-1wKzIAAAAJ": "Jerald Lawless",
    "1mJtQD0AAAAJ": "Andrea Rotnitzky",
    "IYDJuOAAAAAJ": "Cheng-Yang Fu",
    "eQ1uJ6UAAAAJ": "Joseph Turian",
    "k3YaoIEAAAAJ": "Stanley Zdonik",
    "fKV65XQAAAAJ": "Jiannan Wang",
    "B8tFrksAAAAJ": "Michael J. Carey",
    "X53rkecAAAAJ": "Eugene Wu",
    "VghIYWEAAAAJ": "Yanlei Diao",
    "80pKMyMAAAAJ": "David Maier",
    "zdKmnYwAAAAJ": "Jennifer Widom",
    "6iBz3QgAAAAJ": "David DeWitt",
    "Hs3AnAkAAAAJ": "Evan R. Sparks",
    "7w24ptsAAAAJ": "Stephanie Wang",
    "MvYTnPoAAAAJ": "Melih Elibol",
    "yZGlLeMAAAAJ": "Zongheng Yang",
    "kbN88gsAAAAJ": "Leon Bottou",
    "SiCHxTkAAAAJ": "David Lopez-Paz",
    "5PBPqeQAAAAJ": "Laurent Lessard",
    "keIlGm0AAAAJ": "Andrew Packard",
    "36ofBJgAAAAJ": "Soumith Chintala",
    "4BEvaw8AAAAJ": "Iain Murray",
    "ROJq4g4AAAAJ": "Mehrdad Niknami",
    "8zyiGRoAAAAJ": "Zhuohan Li",
    "E3yOuvEAAAAJ": "Danyang Zhuo",
    "KSZmI5EAAAAJ": "Siyuan Zhuang",
    "xEm-9oMAAAAJ": "Ujval Misra",
    "Ksz7c7YAAAAJ": "Thomas William Anthony",
    "odOmEY0AAAAJ": "Tom Minka",
    "oavgGaMAAAAJ": "Daniel Tarlow",
    "E5GfpA4AAAAJ": "Romil Bhardwaj",
    "1ScWJOoAAAAJ": "Chris Pal",
    "FM2DTXwAAAAJ": "Jasper Snoek",
    "JM9-OOsAAAAJ": "Pierre-Marc Jodoin",
    "LAoMyyoAAAAJ": "Mohammad Havaei",
    "cr53lHIAAAAJ": "Sachin Ravi",
    "iBeDoRAAAAAJ": "Richard Zemel",
    "LX2QWBYAAAAJ": "Atousa Torabi",
    "euUV4iUAAAAJ": "Nicolas Ballas",
    "GhPDR9AAAAAJ": "Jerome Louradour",
    "3Qjt0BUAAAAJ": "Benigno Uría",
    "M792u2sAAAAJ": "Mario Marchand",
    "JicYPdAAAAAJ": "Geoffrey Hinton",
    "1cdNGL4AAAAJ": "Loris Bazzani",
    "nzEluBwAAAAJ": "Nando de Freitas",
    "7-9jOvEAAAAJ": "Michael I Mandel",
    "XrKLUO0AAAAJ": "Misha Denil",
    "yV3_PTkAAAAJ": "Vittorio Murino",
    "71a2-WMAAAAJ": "Alexandre Lacoste",
    "rLdfJ1gAAAAJ": "Volodymyr Mnih",
    "ghbWy-0AAAAJ": "George E. Dahl",
    "m9I8jgcAAAAJ": "Maksims Volkovs",
    "dJQf4SYAAAAJ": "Martin Monperrus",
    "fqDBtzYAAAAJ": "Kai-Wei Chang",
    "hRggMmIAAAAJ": "Santosh S. Vempala",
    "jDLa-CUAAAAJ": "Ehud Kalai",
    "3rF9gtAAAAAJ": "Tolga Bolukbasi",
    "Fvh5mcwAAAAJ": "Omer Tamuz",
    "XZrEn1sAAAAJ": "Varun Kanade",
    "q2YhTvAAAAAJ": "Maria De-Arteaga",
    "li4mEfcAAAAJ": "Aditya Krishna Menon",
    "9eyvm28AAAAJ": "Butler Lampson",
    "all0DHsAAAAJ": "Ohad Shamir",
    "OEJUgwkAAAAJ": "Yishay Mansour",
    "fZinJ_AAAAAJ": "Sumit Gulwani",
    "j7MW4iYAAAAJ": "Ce Liu",
    "chD5XxkAAAAJ": "Serge Belongie",
    "fq0DzqoAAAAJ": "Mark DM Leiserson",
    "UD87zMYAAAAJ": "Adam Klivans",
    "umFQktIAAAAJ": "Ankur Moitra",
    "OcPVegoAAAAJ": "Hanna Wallach",
    "uoDW9hkAAAAJ": "Alexandra Chouldechova",
    "ZPqZhnAAAAAJ": "Sahin Cem Geyik",
    "huBJSMwAAAAJ": "Alexey Romanov",
    "NAFriCkAAAAJ": "Krishnaram Kenthapadi",
    "TaR3dq4AAAAJ": "Rosa I. Arriaga",
    "kgsF7uEAAAAJ": "Gati Aher",
    "PqQAVcAAAAAJ": "Katrina Ligett",
    "x7cbdTcAAAAJ": "Rocco Anthony Servedio",
    "u512YusAAAAJ": "Kenneth C. Arnold",
    "e-c3R8QAAAAJ": "Robert C. Miller",
    "LnhCGNMAAAAJ": "Elad Hazan",
    "erv7TP0AAAAJ": "Lester Mackey",
    "wlAYZBwAAAAJ": "Allison Del Giorno",
    "nwHfwCIAAAAJ": "Yin Tat Lee",
    "F5Ik84MAAAAJ": "Jaime Teevan",
    "x8dED5cAAAAJ": "Susan Dumais",
    "JFT_m9kAAAAJ": "Vikas Garg",
    "ELglt8UAAAAJ": "Nathaniel Swinger",
    "GsWe1fgAAAAJ": "Dov Samet",
    "oMLCZ1sAAAAJ": "Ehud Lehrer",
    "9akH-n8AAAAJ": "Heung-Yeung Shum",
    "-6cOYcYAAAAJ": "Steve Seitz",
    "C6pnolkAAAAJ": "Nika Haghtalab",
    "rXYLXJMAAAAJ": "Christos H PAPADIMITRIOU",
    "D-RwB3YAAAAJ": "Madhu Sudan",
    "FqNPXeoAAAAJ": "Claire Monteleoni",
    "gZgQLkgAAAAJ": "Satyen Kale",
    "Ew_nVXEAAAAJ": "azarakhsh malekian",
    "RfHXG5EAAAAJ": "Peter Organisciak",
    "9LcazaMAAAAJ": "Nancy Baym",
    "rlMZibgAAAAJ": "Rahul Santhanam",
    "VX7d5EQAAAAJ": "Jon Kleinberg",
    "sV61CtsAAAAJ": "Ashia C. Wilson",
    "_Q1uzVYAAAAJ": "Anna Rumshisky",
    "z7l0wOcAAAAJ": "andrew postlewaite",
    "wB01auEAAAAJ": "Christos Tzamos",
    "MnnERiQAAAAJ": "Krzysztof Gajos",
    "6iUjvyMAAAAJ": "Ellen Vitercik",
    "2AT4JE4AAAAJ": "Carl Burch",
    "06rffEkAAAAJ": "Shubham Tulsiani",
    "e8aRmAsAAAAJ": "Michael Mitzenmacher",
    "jNQlAkoAAAAJ": "Shiri Azenkot",
    "57UxFrwAAAAJ": "Miaomiao Wen",
    "5wppdUoAAAAJ": "Brendan Juba",
    "HriWXcEAAAAJ": "Sanjeev Khanna",
    "i7lw4LwAAAAJ": "Shyam Upadhyay",
    "2opu1SsAAAAJ": "Stanley F. Chen",
    "ct3WjtoAAAAJ": "Roni Rosenfeld",
    "xhU85M4AAAAJ": "Roi Livni",
    "PCUwf-8AAAAJ": "Brian Bullins",
    "EeYGZCwAAAAJ": "Cameron Musco",
    "fEhNO7YAAAAJ": "Steve Hanneke",
    "8hvFa2AAAAAJ": "Limor Gultchin",
    "s8xc2K4AAAAJ": "Samira Samadi",
    "BIGOtyIAAAAJ": "Konstantina Christakopoulou",
    "1zu2Oh0AAAAJ": "Sivan Sabato",
    "M93Auk4AAAAJ": "Eli Ben-Sasson",
    "G5M9nYwAAAAJ": "Chuan Wen",
    "_GgST9AAAAAJ": "Weirui Ye",
    "HhotyAoAAAAJ": "Yingdong Hu",
    "IhZxOR4AAAAJ": "Fanqi Lin",
    "dVtzVVAAAAAJ": "Ji Lin",
    "uy8T6BYAAAAJ": "David L. Dill",
    "0ret4cUAAAAJ": "Subarna Sinha",
    "N1yNDnQAAAAJ": "Rui Zhao",
    "Nr_yTQgAAAAJ": "Jierui Lin",
    "FiP-TVUAAAAJ": "Jiacheng You",
    "IbcqwaoAAAAJ": "Thanard Kurutach",
    "_egJxfMAAAAJ": "Zhaoheng Yin",
    "0OWBle8AAAAJ": "Xianfan Gu",
    "DmahiOYAAAAJ": "Hang Zhao",
    "LO3pKmwAAAAJ": "Zhengrong Xue",
    "UyZL660AAAAJ": "Li Yi",
    "AhgjQ2QAAAAJ": "Alberto Sangiovanni Vincentelli",
    "-xQ-C1sAAAAJ": "Xiangyu Yue",
    "FTqutJEAAAAJ": "Zangwei Zheng",
    "dusV5HMAAAAJ": "Yi Wu",
    "FWztzhcAAAAJ": "Alex Burka",
    "hrqU1KkAAAAJ": "Siyao Hu",
    "ECHSnpYAAAAJ": "Daniel Seita",
    "tlhfhLoAAAAJ": "Xinlei Pan",
    "NGqfK2wAAAAJ": "Jiaye Teng",
    "lLMX9hcAAAAJ": "Qifeng Chen",
    "ehrpcBwAAAAJ": "Chengbo Yuan",
    "BsMsRuIAAAAJ": "Tong Zhang",
    "LJiQRJIAAAAJ": "Sicheng Zhao",
    "hankD2kAAAAJ": "Xingyu Lin",
    "iHh7IJQAAAAJ": "Qi DOU",
    "Hx3iRaMAAAAJ": "Kai CHEN",
    "o67NTxYAAAAJ": "Jianing Qian",
    "mPpYLhcAAAAJ": "Kaizhe Hu",
    "JCrug-YAAAAJ": "Ruoxi Jia",
    "zUHUsuAAAAAJ": "Haoxu Huang",
    "vc_x1E0AAAAJ": "Hanchen Cui",
    "6dP660cAAAAJ": "Jiaming Song",
    "qSNAaCsAAAAJ": "Marcel Simon",
    "bhpi3vgAAAAJ": "Joachim Denzler",
    "KL4w4bAAAAAJ": "Wanrong He",
    "zSiDAt4AAAAJ": "Ying-Qing Xu",
    "Zr7RJT4AAAAJ": "Joy Hsu",
    "-xaOIZIAAAAJ": "Jiayuan Mao",
    "QpmcFjoAAAAJ": "Jialei Huang",
    "xIJHTUwAAAAJ": "Volker Tresp",
    "Gxz1fqwAAAAJ": "Wei Xu",
    "I0HLZAwAAAAJ": "Ruiqian Nai",
    "7o4wtKEAAAAJ": "Yang Yuan",
    "8W-MW9sAAAAJ": "Dinghuai Zhang 张鼎怀",
    "NbVfqJYAAAAJ": "Zhecheng Yuan",
    "tjNPA04AAAAJ": "Wendy Shang",
    "GfUvUacAAAAJ": "Kun LEI",
    "di5RZ1MAAAAJ": "Jianfei Chen",
    "axsP38wAAAAJ": "Jun Zhu",
    "gwUGHwsAAAAJ": "Ray C. Zheng",
    "ghuIBIYAAAAJ": "Shengjie Wang",
    "7vyVxxQAAAAJ": "Xuanlin Li",
    "BCKhEoAAAAAJ": "Sheng Shen",
    "aLquhd4AAAAJ": "Brandon Trabucco",
    "xDtTbmQAAAAJ": "Jinkun Cao",
    "0t_4lhMAAAAJ": "Fangtao Li",
    "qk61RmIAAAAJ": "Xiance Si",
    "zYI0rysAAAAJ": "Shuchang Zhou",
    "N_Z0SDMAAAAJ": "Chongqing Kang",
    "7LcGErsAAAAJ": "Haiwang Zhong",
    "rEL4-fgAAAAJ": "Boyuan Chen",
    "0ROQMVcAAAAJ": "Yuyang Liu",
    "QAew4J0AAAAJ": "Weijun Dong",
    "LjxqXycAAAAJ": "Chongjie zhang",
    "LWVqxRUAAAAJ": "Yixuan Mei",
    "NMigkG4AAAAJ": "Ziyan Xiong",
    "PK57vrQAAAAJ": "Shiyu Huang",
    "ANtAA98AAAAJ": "Mengchen Wang",
    "leVIam8AAAAJ": "Haoyang Weng",
    "1c1TsZ8AAAAJ": "Geng Chen",
    "2ABKu2YAAAAJ": "Fangchen Liu",
    "CQEyVPMAAAAJ": "Oleh Rybkin",
    "krfIJPUAAAAJ": "Haotian Xu",
    "zu8U47oAAAAJ": "Zixin Wen",
    "XLJrjN8AAAAJ": "Ji Li",
    "slFtxbMAAAAJ": "Yihang Hu",
    "BE7NiFcAAAAJ": "Shaoting Zhu",
    "8vXcIKoAAAAJ": "Suraj Joshi",
    "d4W1UT0AAAAJ": "Xinyun Chen",
    "voqw10cAAAAJ": "Shanghang Zhang",
    "FF3Sp4QAAAAJ": "Shaohuai Liu",
    "OB6vAtkAAAAJ": "Adam W. Harley",
    "SMAmWOQAAAAJ": "Hsiao-Yu (Fish) Tung",
    "Kbi2t9sAAAAJ": "Zhou Xian",
    "jk7GqOEAAAAJ": "Nikolaos Gkanatsios",
    "9rYWAhsAAAAJ": "Gabriel Sarch",
    "lgHhJQ8AAAAJ": "Zhaoyuan Fang",
    "Sm14jYIAAAAJ": "Jianbo Shi",
    "IUZ-7_cAAAAJ": "João Carreira",
    "k0nZO90AAAAJ": "Pablo Arbelaez",
    "bmZbi_UNs-oC": "Rahul Sukthankar",
    "y5fsjDAAAAAJ": "Sudheendra Vijayanarasimhan",
    "gzQY0s8AAAAJ": "Susanna Ricco",
    "RJ_c4xkAAAAJ": "Maximilian Sieb",
    "hgaAO6QAAAAJ": "Ishita Mediratta",
    "2yAMJ1YAAAAJ": "Ethan He",
    "3YZTd_UAAAAJ": "Shoou-I Yu",
    "7AZp7ycAAAAJ": "Weiyu Zhang",
    "UjpM6IAAAAAJ": "Shrinidhi Kowshika Lakshmikanth",
    "0GMYDB8AAAAJ": "Syed Ashar Javed",
    "AERPOfAAAAAJ": "Marta Salas",
    "UxEw4icAAAAJ": "Fangyu Li",
    "Jkss014AAAAJ": "Han Hu",
    "_tbXjP4AAAAJ": "Oliver Kroemer",
    "TpglobcAAAAJ": "bharath hariharan",
    "TIpmrtoAAAAJ": "Abhishek Kar",
    "9YmWGQEAAAAJ": "Ziyan Wang",
    "4hbasIcAAAAJ": "Katharina Muelling",
    "68hTs9wAAAAJ": "Alexander A Alemi",
    "-pu6i_4AAAAJ": "Jonathan Huang",
    "ss-IvjMAAAAJ": "Jason Saragih",
    "sFQD3k4AAAAJ": "Shih-En Wei",
    "HB6mzf0AAAAJ": "Elena Bernardis",
    "s4Q8hbUAAAAJ": "Ersin Yumer",
    "H8FOdHwAAAAJ": "Arpit Agarwal",
    "MExi4eQAAAAJ": "Ricson Cheng",
    "GIZzv_cAAAAJ": "William Seto",
    "GcuxcLYAAAAJ": "Asuman Ozdaglar",
    "l9Or8EMAAAAJ": "Daron Acemoglu",
    "1JvIQ8EAAAAJ": "Munther Dahleh",
    "sao65cAAAAAJ": "Omar Besbes",
    "RiLCRDwAAAAJ": "Renato Paes Leme",
    "e_Y58QEAAAAJ": "Evan Sadler",
    "09_uzi8AAAAJ": "Francisco Castro",
    "btWJVrgAAAAJ": "Maxime C. Cohen",
    "ffqbs_0AAAAJ": "Sébastien Martin",
    "l-Ilg5MAAAAJ": "René Caldentey",
    "yLenCKUAAAAJ": "Diego Feijer",
    "zK4uegoAAAAJ": "Jiawei Zhang",
    "X1N99wsAAAAJ": "Gustavo Vulcano",
    "gewVBA4AAAAJ": "Wenqiang Xiao",
    "hr1PnUkAAAAJ": "Yuri Resende Fonseca",
    "JIJGu30AAAAJ": "Lav R. Varshney",
    "5qh5cc0AAAAJ": "Adrian Vladu",
    "A4xI6moAAAAJ": "Haotian Song",
    "k9uWzAIAAAAJ": "Negin Golrezaei",
    "ONv0HgMAAAAJ": "Daniel Freund",
    "7KI2Fa8AAAAJ": "Garrett van Ryzin",
    "6Atez3UAAAAJ": "Arthur Delarue",
    "meTZPLgAAAAJ": "Jiaqi Lu",
    "UvponD8AAAAJ": "Jiayu Kamessi Zhao",
    "UpnZAg0AAAAJ": "Fanyin Zheng",
    "d5Djcl4AAAAJ": "Humberto Luiz Ataíde Moreira",
    "LSr5-w4AAAAJ": "Omar Mouchtaki",
    "zj6FavAAAAAJ": "Wolfram Burgard",
    "3oe0I0QAAAAJ": "Karl Pertsch",
    "q7nFtUcAAAAJ": "Andy Zeng",
    "1P8Zu04AAAAJ": "Hao Su",
    "-w5DuHgAAAAJ": "Brian Ichter",
    "0VAe-TQAAAAJ": "Thomas Brox",
    "dHec-LkAAAAJ": "Edward Johns",
    "bWoGh8UAAAAJ": "Yonatan Bisk",
    "wbZc9nUAAAAJ": "Cesare Tinelli",
    "-0T1EtoAAAAJ": "Andrew Reynolds",
    "3nYG5BMAAAAJ": "Guy Katz",
    "568MtVQAAAAJ": "Aaron Stump",
    "DsD8SDYAAAAJ": "Morgan Deters",
    "1RElnvEAAAAJ": "Haoze Wu",
    "WMHRQ-8AAAAJ": "Yoni Zohar",
    "14LdhrcAAAAJ": "Haniel Barbosa",
    "cAy9G6oAAAAJ": "Mykel J. Kochenderfer",
    "-vsw3Z4AAAAJ": "Mathias Preiner",
    "NlnpI7QAAAAJ": "Kyle David Julian",
    "dtxmW18AAAAJ": "Aina Niemetz",
    "R4EFw_AAAAAJ": "Andres Nötzli",
    "Qo72ORkAAAAJ": "Makai Mann",
    "TCg0M_8AAAAJ": "Tim King",
    "lWqzpFkAAAAJ": "Dejan Jovanović",
    "MocRuzIAAAAJ": "Liana Hadarean",
    "fRwndxUAAAAJ": "Alex Ozdemir",
    "SCdhzWoAAAAJ": "Subhasish Mitra",
    "CwazDKgAAAAJ": "Leonardo de Moura",
    "m9vu99gAAAAJ": "Gereon Kremer",
    "uobCsQgAAAAJ": "Hanna Lachnitt",
    "TZ7xuYAAAAAJ": "Aleksandar Zeljić",
    "5i5vhFQAAAAJ": "Martin Brain",
    "gs5xeKUAAAAJ": "Eshan Singh",
    "oajw_bMAAAAJ": "Jeremy Levitt",
    "91R66jcAAAAJ": "Abdalrhman Mohamed",
    "bTVBQpcAAAAJ": "Tianyi Liang",
    "pwIuivQAAAAJ": "Corina Pasareanu",
    "rYIFql4AAAAJ": "Ahmed Irfan",
    "QMFlwLQAAAAJ": "Yeting Ge",
    "Lpc8gO4AAAAJ": "Albert Oliveras",
    "RzEnQmgAAAAJ": "Patrick Hanrahan",
    "owApkWAAAAAJ": "Christopher Lazarus",
    "1QKK-zgAAAAJ": "Mudathir Mohamed",
    "AU5d1KUAAAAJ": "Florian Lonsing",
    "2sjWX1sAAAAJ": "Mohammad Rahmani Fadiheh",
    "IR-Vw9kAAAAJ": "Dominik Stoffel",
    "KFXJQ90AAAAJ": "Caleb Donovick",
    "StIHrlMAAAAJ": "Nestan Tsiskaridze",
    "9KRcr3QAAAAJ": "Ross Daly",
    "kmoklesAAAAJ": "Viktor Kunčak",
    "q4qDvAoAAAAJ": "Nicholas Carlini",
    "nUDR4_gAAAAJ": "Baoluo Meng",
    "FmnJtIYAAAAJ": "Divya Gopinath",
    "QSQuvHYAAAAJ": "Kshitij Bansal",
    "AdBqkbIAAAAJ": "Tom Melham",
    "cWMhYJcAAAAJ": "Burak Ekici",
    "qmnmdYsAAAAJ": "Roberto Sebastiani",
    "_zvL7YIAAAAJ": "Alain Mebsout",
    "IzLlyzsAAAAJ": "Thomas Wies",
    "hW-VFhwAAAAJ": "Don Syme",
    "MACCA0cAAAAJ": "Carl Seger",
    "nHlOHXMAAAAJ": "Bruno Dutertre",
    "LO06dIUAAAAJ": "Wei Wang",
    "N4kcAKIAAAAJ": "Sava Krstic",
    "m3aJauEAAAAJ": "Robert Nieuwenhuis",
    "frSU5j0AAAAJ": "John O'Leary",
    "HcyivC0AAAAJ": "Cristian Mattarei",
    "DHddutUAAAAJ": "Daniel Kroening",
    "O-29z5AAAAAJ": "David Brumley",
    "AScYAMYAAAAJ": "Maverick Woo",
    "W_L_cZsAAAAJ": "Silvio Ranise",
    "E20Gzu0AAAAJ": "David Harel",
    "CYfxRVIAAAAJ": "Marsha Chechik",
    "WHTB3_MAAAAJ": "Arie Gurfinkel",
    "8f7XTQIAAAAJ": "Dennis Dams",
    "RtwBsDYAAAAJ": "Kedar Namjoshi",
    "qJBXk9cAAAAJ": "Shunyu Yao",
    "4gVbilMMp-AC": "Izhak Shafran",
    "71G11ksAAAAJ": "John Yang",
    "6jv2-OYAAAAJ": "Regina Barzilay",
    "Y_NYX7MAAAAJ": "Vishvak Murahari",
    "Ue4wghAAAAAJ": "Carlos E. Jimenez",
    "zTfIpA4AAAAJ": "Noah Shinn",
    "B4NztA8AAAAJ": "Tanmay Rajpurohit",
    "VyGrp0QAAAAJ": "Dian Yu",
    "sNMowOIAAAAJ": "Ardavan Saeedi",
    "LeHa8psAAAAJ": "Ofir Press",
    "g-hQdY8AAAAJ": "Tsung-Yen Yang",
    "v474hP4AAAAJ": "NAN DU",
    "gnox0EsAAAAJ": "Runzhe Yang",
    "n8tK15oAAAAJ": "Federico Cassano",
    "wsNa_W4AAAAJ": "Howard Chen",
    "BOMboVoAAAAJ": "Peter J. Ramadge",
    "feURfe4AAAAJ": "Justinian Rosca",
    "N_jSE08AAAAJ": "Alexander Wettig",
    "BB4R2_gAAAAJ": "Austin W. Hanjie",
    "xZal_nUAAAAJ": "Theodore Sumers",
    "byA9yI0AAAAJ": "Kilian Lieret",
    "vvUmC_EAAAAJ": "Akshara Prabhakar",
    "sVR8ktkAAAAJ": "Danqi Chen",
    "Ao4gtsYAAAAJ": "Tommi Jaakkola",
    "KFTttp0AAAAJ": "Pranjal Aggarwal",
    "7EPsnxEAAAAJ": "Robert D. Hawkins",
    "lutJce0AAAAJ": "Matthew Hausknecht",
    "lT3YoNkAAAAJ": "Victor Zhong",
    "lRLvr5EAAAAJ": "Xingyuan Sun",
    "30Izy_cAAAAJ": "Rohan Rao",
    "XUI4PMEAAAAJ": "Sida I. Wang",
    "tWBPUHwAAAAJ": "Zhiwei Deng",
    "TyyftvAAAAAJ": "Michael Hu",
    "FIBljEYAAAAJ": "Zeyu Wang",
    "TPnedXMAAAAJ": "Jens Tuyls",
    "z9em5msAAAAJ": "Anirudh Sivaraman",
    "5cSFXKQAAAAJ": "Pradeep Dogga",
    "4C9naMgAAAAJ": "Ravi Netravali",
    "9rhEuW8AAAAJ": "Damianos Karakos",
    "PvHFAfIAAAAJ": "Kayhan Batmanghelich",
    "eJt6cSIAAAAJ": "Ishita Dasgupta",
    "Hft2m4wAAAAJ": "Sreejan Kumar",
    "h-pwCMUAAAAJ": "Raja Marjieh",
    "8BX3BokAAAAJ": "Armando Solar-Lezama",
    "LJnNKXMAAAAJ": "Yewen Pu",
    "TWXQyuEAAAAJ": "Nicholas Locascio",
    "twlFI3sAAAAJ": "Binghui Peng",
    "hWPIzdkAAAAJ": "Liwei Song",
    "0aJ--58AAAAJ": "Raeid Saqur",
    "UjpbO6IAAAAJ": "Luke Zettlemoyer",
    "krTnRRUAAAAJ": "Jacqueline He",
    "yK7yTiwAAAAJ": "Mark Ho",
    "NCkkQAMAAAAJ": "Jonathan D. Cohen",
    "ibu3FwsAAAAJ": "Anirudha Majumdar",
    "mgMzkYMAAAAJ": "Allen Z. Ren",
    "GRMMc_MAAAAJ": "Yilun Du",
    "gWocpdkAAAAJ": "Shiv Saini",
    "lc6CVqEAAAAJ": "Yi Zhang",
    "sXtjq8IAAAAJ": "Cyril Zhang",
    "JIUz890AAAAJ": "Xinyi Chen",
    "5elBSHQAAAAJ": "Mark Braverman",
    "CIZwXAcAAAAJ": "Partha Talukdar",
    "BFlpS-8AAAAJ": "Yinlam Chow",
    "23SZHUwAAAAJ": "Yu Wu (武宇)",
    "-Txt8vsAAAAJ": "Vikash K. Mansinghka",
    "PTeSCbIAAAAJ": "Chuang Gan",
    "vC8DssQAAAAJ": "Mo Yu",
    "Ay-iC-8AAAAJ": "Charl van Heerden",
    "Xz-fi1cAAAAJ": "Marelie H Davel",
    "KarsBWAAAAAJ": "Anirudh Ajith",
    "2Jw3gv4AAAAJ": "Felix Yu",
    "ZYc-LuMAAAAJ": "Andrew S. Lan",
    "-fPI9LgAAAAJ": "Julie Shah",
    "A2KHeEgAAAAJ": "Ramya Ramakrishnan",
    "fJsSvzkAAAAJ": "Rachit Dubey",
    "BxlScrEAAAAJ": "Nathaniel D. Daw",
    "FWJZYMYAAAAJ": "Aida Nematzadeh",
    "kzglGGEAAAAJ": "Albert X. Jiang",
    "KYHL9aIAAAAJ": "Ashwin Kalyan",
    "kwqPtgcAAAAJ": "Robert J. Full",
    "OafZcSMAAAAJ": "Kellar Autumn",
    "YU4Ce_MAAAAJ": "Metin Sitti",
    "jjbNzhYAAAAJ": "Andrew Gillies",
    "FTYtHb4AAAAJ": "Robert J Wood",
    "SQzKCuUAAAAJ": "Thomas Kenny",
    "1gqyKqcAAAAJ": "Ali Javey",
    "1LyndUsAAAAJ": "Carmel Majidi",
    "Iw9vL9cAAAAJ": "Erik Steltz",
    "oEfBf3sAAAAJ": "Aaron Hoover",
    "kO_RfY4AAAAJ": "Paul Birkmeyer",
    "47L65OMAAAAJ": "Richard Groff",
    "IVMpLjIAAAAJ": "David Zarrouk",
    "06OJ1FQAAAAJ": "Justin Yim",
    "SqHX4UgAAAAJ": "Mark Plecnik",
    "nJJ44zoAAAAJ": "Andrew Pullin",
    "J5gGsg0AAAAJ": "Kevin Peterson",
    "jqzSwdsAAAAJ": "Chen Li",
    "5En4XZEAAAAJ": "Hyunhyub Ko",
    "VEfQf5wAAAAJ": "Nicholas Kohut",
    "0Knul6gAAAAJ": "Stan Baek",
    "9gO29eUAAAAJ": "Domenico CAMPOLO",
    "Qogwc7QAAAAJ": "Roya MABOUDIAN",
    "eeSqBRoAAAAJ": "Matthew D. Berkemeier",
    "r7wE4M4AAAAJ": "Daniel I. Goldman",
    "kc3snaQAAAAJ": "Michael H Dickinson",
    "8iQk0DIAAAAJ": "Michael Kearns",
    "k4Q3TYwAAAAJ": "Seth Neel",
    "9NkngDMAAAAJ": "Haiyi Zhu",
    "ziP-50wAAAAJ": "Kenneth Holstein",
    "f2x233wAAAAJ": "Aleksandrs Slivkins",
    "ZQ4iPZUAAAAJ": "Giuseppe Vietri",
    "TnvQIrYAAAAJ": "Keegan Harris",
    "G1WMpcUAAAAJ": "Vasilis Syrgkanis",
    "qRnP-p0AAAAJ": "Mingyi Hong",
    "2SvHNeQAAAAJ": "Brett Beaulieu-Jones",
    "ZvFaPxUAAAAJ": "Aaditya Ramdas",
    "mBHPMZUAAAAJ": "Dung Daniel Ngo",
    "LxpnsSMAAAAJ": "Justin Whitehouse",
    "h60zIiUAAAAJ": "Shahin Jabbari",
    "1bwPKXpo97YC": "Juba Ziani",
    "2mYxmokAAAAJ": "Rachel Cummings",
    "RY7cuPAAAAAJ": "Arindam Banerjee",
    "HsfKE0sAAAAJ": "Justin Hsu",
    "XPrjbvoAAAAJ": "Luke Guerdan",
    "UrsQh_0AAAAJ": "Christopher Jung",
    "8U7d-_MAAAAJ": "Amanda Coston",
    "ETJoidYAAAAJ": "Casey S. Greene",
    "6ztViH8AAAAJ": "Zhiyi Huang",
    "KLSUWBAAAAAJ": "Miruna Oprescu",
    "WaGlwJ4AAAAJ": "Manish Raghavan",
    "YRPveMcAAAAJ": "Jennifer Wortman Vaughan",
    "K0kaNvkAAAAJ": "Akshay Krishnamurthy",
    "0lcJYs8AAAAJ": "Tim Roughgarden",
    "CaHuRsgAAAAJ": "Aaron Schein",
    "JnWSU4oAAAAJ": "Rakesh Vohra",
    "LXwCIisAAAAJ": "Mingyuan Zhou",
    "6lyS2T4AAAAJ": "Paul Goldberg",
    "RCi98EAAAAAJ": "Siddhartha Srinivasa",
    "aO-849gAAAAJ": "Erol Sahin",
    "DqXsbPAAAAAJ": "Dieter Fox",
    "B1Dy3WMAAAAJ": "Emre Ugur",
    "Ah6du3EAAAAJ": "Michael Murray",
    "NJ3TiCIAAAAJ": "Justin K Huang",
    "ARmXjpcAAAAJ": "Elin A. Björling",
    "02nHF0gAAAAJ": "Rajesh PN Rao",
    "avud6aAAAAAJ": "Michael Jae-Yoon Chung",
    "1dPriv4AAAAJ": "Crystal Chao",
    "TbN31LMAAAAJ": "patrícia alves-oliveira",
    "0a58TKgAAAAJ": "W Bradley Knox",
    "uVgMw8YAAAAJ": "Maria Eugenia Cabrera",
    "I1mOQpAAAAAJ": "Chris Paxton",
    "6QQX88UAAAAJ": "Wei Yang",
    "68V-nNAAAAAJ": "Amal Nanavati",
    "JYaJjE8AAAAJ": "Nick Walker",
    "VGr54BoAAAAJ": "Bilge Mutlu",
    "T0qnS1oAAAAJ": "Saleema Amershi",
    "tflc42wAAAAJ": "Todd Kulesza",
    "48Y9F-YAAAAJ": "Yu-Wei Chao",
    "5QaaYmQAAAAJ": "Sarah Elliott",
    "5sL0xZ4AAAAJ": "Baris Akgun",
    "X1zsXTgAAAAJ": "Tapomayukh Bhattacharjee",
    "8Qu_gAMAAAAJ": "Sara Kiesler",
    "hfmi3QwAAAAJ": "Ethan K. Gordon",
    "sF1vZ0oAAAAJ": "Maxwell Forbes",
    "LidK--MAAAAJ": "Sonya Alexandrova",
    "tgm2Y7oAAAAJ": "Balakumar Sundaralingam",
    "q5GIWC0AAAAJ": "Franziska Roesner",
    "oHv6BrYAAAAJ": "Allison Sauppé",
    "r0EFvOoAAAAJ": "Nick DePalma, Ph.D.",
    "qWEImhMAAAAJ": "Yasaman S. Sefidgar",
    "eG10MqcAAAAJ": "M Asada",
    "HqTUx7YAAAAJ": "Yukie Nagai",
    "r2v8Jc0AAAAJ": "Jimmy BARAGLIA",
    "ZocLOAMAAAAJ": "Guy Hoffman",
    "kV5zQBkAAAAJ": "Gokturk Ucoluk",
    "jz2Tvk4AAAAJ": "Zachary Tatlock",
    "6-ojl1EAAAAJ": "Adithya Murali",
    "gdD2E9QAAAAJ": "Raffay Hamid",
    "dxwPYhQAAAAJ": "Nan Rosemary Ke",
    "BFzFy1YAAAAJ": "Alex Lamb",
    "lmjR_qMAAAAJ": "Michael Mozer",
    "O-oICE8AAAAJ": "Stefan Bauer",
    "RUP4S68AAAAJ": "Sanjeev Arora",
    "f31mvPsAAAAJ": "Charles Blundell",
    "htPVdRMAAAAJ": "Timothy P. Lillicrap",
    "79k7bGEAAAAJ": "Nicolas Heess",
    "rF2VvOgAAAAJ": "Surya Ganguli",
    "-8DNE4UAAAAJ": "David Silver",
    "U_8MaDMAAAAJ": "James S Michaelson",
    "xR6fOrAAAAAJ": "Alphonse Taghian",
    "rY8u8xkAAAAJ": "Donald Berry",
    "CYkqs5UAAAAJ": "Julliette Buckley",
    "N-gKE0oAAAAJ": "Jennifer K Plichta",
    "I8kmeZYAAAAJ": "Kanhua Yin",
    "AGaoCGAAAAAJ": "Emanuele Mazzola",
    "MzAzFm8AAAAJ": "Elissa Ozanne",
    "2DjuFy8AAAAJ": "Marie E. Wood",
    "LUn8dAEAAAAJ": "James A. Colbert, MD",
    "30VwF8YAAAAJ": "Francisco Acevedo",
    "7YZ3sCEAAAAJ": "Wendy Rubinstein, MD, PhD",
    "wVzFBcEAAAAJ": "Zhengyi Deng",
    "9ODmYwoAAAAJ": "Peter G Mikhael",
    "TcXHyvMAAAAJ": "Anne Marie McCarthy",
    "job97voAAAAJ": "Susan Domchek",
    "Ee4Peu4AAAAJ": "Yujia Bao",
    "qy87mcIAAAAJ": "Gigin Lin",
    "q3K8X-IAAAAJ": "Fredrik Strand",
    "smo705AAAAAJ": "Zoe Guan",
    "7yqJjsgAAAAJ": "Georges Grinstein",
    "dLx3Um4AAAAJ": "Victor Diego Armengol",
    "NzLGjWoAAAAJ": "Daniel Gudbjartsson",
    "MnoNkkcAAAAJ": "Phoebe Freer",
    "_oZJDPEAAAAJ": "Amanda Blackford",
    "fT7XeUEAAAAJ": "Mark E. Robson",
    "o_4HDRwAAAAJ": "Andrzej Niemierko",
    "PtSVy9AAAAAJ": "Mohamed Alm El-Din",
    "bRuEhB8AAAAJ": "Robert E Mansel",
    "np43vMAAAAAJ": "Edward P. Ambinder MD FACP FASCO",
    "k_9sF90AAAAJ": "Jeremy L. Warner MD, MS, FAMIA, FASCO",
    "a-ifJKsAAAAJ": "Horacio Asbun",
    "TwABcRgAAAAJ": "Rafael Mitkov Rafailov",
    "6S9C8XoAAAAJ": "Allan Zhou",
    "EM9YhH0AAAAJ": "Lirui Wang",
    "YfPA4YsAAAAJ": "Pete Florence",
    "DkYYtGIAAAAJ": "Anne-Kathrin Schmuck",
    "COuXyKwAAAAJ": "Rupak Majumdar",
    "CG04xrsAAAAJ": "Kaushik Mallik",
    "HuckLq8AAAAJ": "Waseem Gharbieh",
    "vA6ZQ_AAAAAJ": "Daniel M. Roy",
    "zUu0JKYAAAAJ": "James Whittington",
    "5K1QB_8AAAAJ": "Gintare Karolina Dziugaite",
    "GyVPmtYAAAAJ": "Will Dorrell",
    "vRI2blsAAAAJ": "Chong Wang",
    "GQ6xw-oAAAAJ": "Jiankai Sun",
    "qJsC_XsAAAAJ": "Junyuan Xie",
    "1ypDmDwAAAAJ": "Xiaobing Liu",
    "A_grkugAAAAJ": "Sheng Gong",
    "6Wg-hF4AAAAJ": "Hongyi Zhang",
    "RrYw5jkAAAAJ": "Sreeram Kannan",
    "2uHyOSIAAAAJ": "Tianze Zheng",
    "8r2Fiv4AAAAJ": "Xin Yang",
    "mFiX664AAAAJ": "Wen Yan",
    "q1fmhDkAAAAJ": "Zhichen Pu",
    "ih3MdzUAAAAJ": "Kai Jia",
    "rtpoh5wAAAAJ": "Oscar Li",
    "bldHpWIAAAAJ": "Virginia Smith",
    "scJH01QAAAAJ": "Xiaojie Wu",
    "AG51Bv4AAAAJ": "Yuanshun (Kevin) Yao",
    "Daa3WpMAAAAJ": "Aonan Zhang",
    "7joKYcAAAAAJ": "Ruofan Ding",
    "du74HM4AAAAJ": "Zhirui Wang",
    "I9Db408AAAAJ": "Hongyi Wang",
    "1jPQEVMAAAAJ": "Yuheng Bu",
    "abUmi6QAAAAJ": "Shaofeng Zou",
    "gruYQKgAAAAJ": "Venugopal V. Veeravalli",
    "WqF5JigAAAAJ": "Qiming Sun",
    "azE-Yq0AAAAJ": "Weiluo Ren",
    "f7jdz5IAAAAJ": "Zhiao Yu",
    "pndDsyoAAAAJ": "Yu-Han Liu",
    "1xqhHuEAAAAJ": "Xiang Gao",
    "jGymlOMAAAAJ": "Xiang Li",
    "bAXsp5wAAAAJ": "Mengyi Chen",
    "ZCMRvtIAAAAJ": "Zhi Wang",
    "uK5wa_EAAAAJ": "Hyeji Kim",
    "OEZ816YAAAAJ": "Xiaojie Jin, 靳潇杰",
    "nPratvEAAAAJ": "Chaosheng Dong",
    "HWFvq_wAAAAJ": "Yang Jianchao",
    "SmO3044AAAAJ": "Zitian Tang",
    "hLxJ02wAAAAJ": "Shengjie Wang",
    "J8TSTXMAAAAJ": "Simiao Zuo",
    "PnVYoI4AAAAJ": "Alexander William Bukharin",
    "EJXN6tYAAAAJ": "Tuo Zhao",
    "itZCog0AAAAJ": "ERCAN KAHYA",
    "QKFb5pkAAAAJ": "Saeed Vazifehkhah",
    "WrJerFMAAAAJ": "Zijian LI (李子健)",
    "FMDCrXMAAAAJ": "Yijia Wang",
    "dw5f9yIAAAAJ": "Tianyi Liu",
    "7uXCsMgAAAAJ": "Xiang Wu",
    "BXJ3LwEAAAAJ": "Jarvis Haupt",
    "S-pd0NwAAAAJ": "Mario AT Figueiredo",
    "N-BBA20AAAAJ": "Richard Baraniuk",
    "Koez6qoAAAAJ": "Rui Castro",
    "bGRVPl8AAAAJ": "Rebecca Willett",
    "qxWORNoAAAAJ": "Mark Coates",
    "avQkeJEAAAAJ": "Waheed U. Bajwa",
    "cMPKe9UAAAAJ": "Michael Rabbat",
    "VFQRIOwAAAAJ": "Stephen Wright",
    "SEMSJmcAAAAJ": "Clayton Scott",
    "X6fRNfUAAAAJ": "Laura Balzano",
    "hqTu-QcAAAAJ": "Xiaojin Zhu",
    "jiTj6toAAAAJ": "Brian Eriksson",
    "uOLwGG4AAAAJ": "Matt Crouse",
    "4uypulQAAAAJ": "Paul Barford",
    "JBU4ivcAAAAJ": "Matthew L. Malloy",
    "GhqD_rwAAAAJ": "Nikhil Rao",
    "7u_uyOsAAAAJ": "Timothy T. Rogers",
    "Q2U7G6oAAAAJ": "Daniel Pimentel",
    "DSiNzkIAAAAJ": "Alfred Hero",
    "iSL1cKsAAAAJ": "Gautam Dasarathy",
    "hGMSFu4AAAAJ": "Lalit Jain",
    "gLO_20kAAAAJ": "Blake J Mason",
    "-Yge2L0AAAAJ": "Andrew Bolstad",
    "M-y2aLUAAAAJ": "Abhishek Shetty",
    "YatAkqAAAAAJ": "Chara Podimata",
    "m791iN8AAAAJ": "Saba Ahmadi",
    "vzr_L0EAAAAJ": "Hanrui Zhang",
    "mV9LQUoAAAAJ": "Mingda Qiao",
    "eFxnUw4AAAAJ": "Izzy Grosof",
    "d7fUTNIAAAAJ": "Ziv Scully",
    "Ooc7UNUAAAAJ": "Mor Harchol-Balter",
    "xVFrEDwAAAAJ": "Nivasini Ananthakrishnan",
    "6OfjaHQAAAAJ": "Eric Zhao",
    "5QYHMpsAAAAJ": "Paul Gölz",
    "OVRxQj8AAAAJ": "Han Shao",
    "V1qU5dwAAAAJ": "Shuo Xie",
    "Evgx6UkAAAAJ": "Alexandr Andoni",
    "nst5fHgAAAAJ": "Dina Katabi",
    "SWMKy70AAAAJ": "Ludwig Schmidt",
    "gV4dPToAAAAJ": "Tal Wagner",
    "kMmxbbIAAAAJ": "David Woodruff",
    "UE6z_m8AAAAJ": "Eric Price",
    "11JgipcAAAAJ": "Aristides Gionis",
    "MvyO9jAAAAAJ": "S Muthukrishnan",
    "s5-hnX8AAAAJ": "Haitham Hassanieh",
    "UNHdIKoAAAAJ": "Arturs Backurs",
    "CMZAKkEAAAAJ": "Ilya Razenshteyn",
    "zHCTHbYAAAAJ": "Sudipto Guha",
    "NirVdpMAAAAJ": "Sepideh Mahabadi",
    "eJAV17IAAAAJ": "Chinmay Hegde",
    "uXZaVaAAAAAJ": "Ali Vakilian",
    "fE4XXdIAAAAJ": "Mihai Badoiu",
    "YR_MYrAAAAAJ": "Anastasios Sidiropoulos",
    "2s9_ZWgAAAAJ": "Sariel Har-Peled",
    "f0Wc8tkAAAAJ": "Nick Koudas",
    "Z03FLwkAAAAJ": "Suresh Venkatasubramanian",
    "LfF2zfQAAAAJ": "Soumen Chakrabarti",
    "gpLVKmEAAAAJ": "Graham Cormode",
    "ykqoK38AAAAJ": "Yannis Kotidis",
    "GelzUJgAAAAJ": "Taher Haveliwala",
    "M3yUD0cAAAAJ": "Robert Krauthgamer",
    "p2ttvlEAAAAJ": "Richard Cole",
    "AjX6hisAAAAJ": "Yihe Dong",
    "hlWhzU8AAAAJ": "Volkan Cevher",
    "68eoKg4AAAAJ": "Krzysztof Onak",
    "4rihlSYAAAAJ": "Omid Abari",
    "wEUnFc0AAAAJ": "Michael Kapralov",
    "MDCu0WEAAAAJ": "Huy L Nguyễn",
    "B_rKfusAAAAJ": "Ashish Goel",
    "ikn-xhYAAAAJ": "Julia Chuzhoy",
    "lLqnszIAAAAJ": "Thijs Laarhoven",
    "wUJ2bXgAAAAJ": "Jeffrey Ullman",
    "O-TV6OgAAAAJ": "Edith Cohen",
    "MFVj4n4AAAAJ": "Mohammed Abdelghany",
    "QH90248AAAAJ": "Alon Efrat",
    "i5PazXwAAAAJ": "Howard Karloff",
    "g3McheUAAAAJ": "Christian Sohler",
    "IpBjTKQAAAAJ": "Andrew McGregor",
    "OxKLBqwAAAAJ": "Fadel Adib",
    "7j3itaMAAAAJ": "Chandra Chekuri",
    "6Ff2c8wAAAAJ": "Erik Demaine",
    "UNxLPX8AAAAJ": "Kasturi Varadarajan",
    "f89ndwoAAAAJ": "Sofiane Abbar",
    "rMtUkMcAAAAJ": "Sihem Amer-Yahia",
    "uqTfLEgAAAAJ": "Ely Porat (אלי פורת)",
    "FtMADIMAAAAJ": "Prabhakar Raghavan",
    "58Yv3zUAAAAJ": "Baruch Schieber",
    "ZlE1X8IAAAAJ": "Ania Gambin",
    "8Ut6gTcAAAAJ": "Arnon Amir",
    "-3VoT8cAAAAJ": "Mihai Patrascu",
    "dfddm3cAAAAJ": "Mark Iwen",
    "zDax7zYAAAAJ": "Hsu Chen-Yu",
    "9HiV_AEAAAAJ": "Narayanan Sundaram",
    "-ad5RSQAAAAJ": "Pradeep Dubey",
    "srP2ANoAAAAJ": "Hung Q. Ngo",
    "_e5H8IoAAAAJ": "Atri Rudra",
    "1WXpabIAAAAJ": "Reut Levi",
    "TvyZkdwAAAAJ": "John Guttag",
    "_JWhZSAAAAAJ": "Bogdan S Chlebus",
    "VeB3UbcAAAAJ": "Aditya Parameswaran",
    "ATOfqHEAAAAJ": "Hanan Samet",
    "b8pLQq0AAAAJ": "Lixin Shi",
    "GBJLTN8AAAAJ": "Badih Ghazi",
    "TZWVRR8AAAAJ": "Shayan Oveis Gharan",
    "l2Wb8uQAAAAJ": "Alireza Rezaei",
    "SQ1eGN4AAAAJ": "MohammadTaghi Hajiaghayi",
    "lsYXBx8AAAAJ": "Manolis Kellis",
    "50xZTa0AAAAJ": "Rina Panigrahy",
    "0BI-noIAAAAJ": "Yonatan Aumann",
    "otHomQ8AAAAJ": "Amihood Amir",
    "Z8U0BwcAAAAJ": "Ryan O'Donnell",
    "O5m7WK8AAAAJ": "Michel Deza",
    "zQkIKOcAAAAJ": "Ligang Lu",
    "TbQXQ7EAAAAJ": "Leszek A Gąsieniec",
    "QKgg5j4AAAAJ": "Artur Czumaj",
    "2uHUSa8AAAAJ": "Martin Farach-Colton",
    "r4_ZQ2AAAAAJ": "Moshe Lewenstein",
    "WqJvRZoAAAAJ": "Stanislaw Szarek",
    "61lw9YIAAAAJ": "Paris Siminelakis",
    "0koVxB4AAAAJ": "Elyot Grant",
    "pDkhB5EAAAAJ": "Mahdi Cheraghchi",
    "eECXWqUAAAAJ": "Arnab Bhattacharyya",
    "H9x5YXkAAAAJ": "Ning Xie",
    "cjx8PKUAAAAJ": "Anastasios Zouzias",
    "Pe39BdUAAAAJ": "Piotr Krysta",
    "tkDsIggAAAAJ": "Jon Feldman",
    "2vQRGrYAAAAJ": "David Karger",
    "JFap1psAAAAJ": "Amik St-Cyr",
    "YgSxvV4AAAAJ": "Stefan Funke",
    "hgZrGpkAAAAJ": "Elias Tsigaridas",
    "eCXP24kAAAAJ": "Yair Bartal",
    "ri4rEPMAAAAJ": "Ron Shamir",
    "lPaISmIAAAAJ": "Anikait Singh",
    "aH8AJu4AAAAJ": "Rishabh Agarwal",
    "IrixA8MAAAAJ": "Kevin Swersky",
    "E0iCaa4AAAAJ": "Song Han",
    "4gdSoOYAAAAJ": "Hongxu (Danny) Yin",
    "KTYQRzYAAAAJ": "Jiangtao Wen",
    "J9PoyoIAAAAJ": "Pavlo Molchanov",
    "Pb2O3oYAAAAJ": "Sujit Dey",
    "y0LVrtgAAAAJ": "Ligeng Zhu",
    "WxL13BAAAAAJ": "Haotian Tang",
    "P9FclNEAAAAJ": "Jan Kautz",
    "C_AP8XAAAAAJ": "Peng Xu",
    "_LSLmbYAAAAJ": "Xuan Dong",
    "x-AvvrYAAAAJ": "Han Cai",
    "42MVVPgAAAAJ": "Enze Xie",
    "vrYHLMgAAAAJ": "Yunhao Fang",
    "wotfaAgAAAAJ": "Kanishka Rao",
    "SzHPa90AAAAJ": "Paul Wohlhart",
    "mWdYMZ8AAAAJ": "Junyu Chen",
    "vEYUIioAAAAJ": "Dacheng Li",
    "p4zxPP8AAAAJ": "Junsong Chen",
    "aMZAyzwAAAAJ": "Liu Yao",
    "mwzYYPgAAAAJ": "Zhijian Liu",
    "Q1csT-8AAAAJ": "Zhuoyang Zhang",
    "6gKEYRgAAAAJ": "Wei Ping",
    "p71ikL4AAAAJ": "Shang Yang",
    "V64dmUAAAAAJ": "Yujun Lin",
    "eXqOR10AAAAJ": "Yecheng Wu",
    "iyEuK8kAAAAJ": "Sean Kirmani",
    "bDq7MZMAAAAJ": "Chuyuan Fu",
    "NLOh3SUAAAAJ": "Austin C Stone",
    "UJcm1MoAAAAJ": "Jacob Varley",
    "6p0ygKUAAAAJ": "Yukang Chen",
    "Kq0feJIAAAAJ": "Xiuyu Li",
    "WCqe8yUAAAAJ": "Xueshi Hou",
    "62ElavIAAAAJ": "Mohammad Shoeybi",
    "rE7-N30AAAAJ": "Kuang-Huei Lee",
    "DSmxHuMAAAAJ": "Xiaoqian Jiang",
    "GnDGqKQAAAAJ": "Shuang Wang",
    "V4Y4ETQAAAAJ": "Feng Chen",
    "nZsD8XwAAAAJ": "Yan Wang",
    "vcw0TJIAAAAJ": "Michael S. Ryoo",
    "HEY3UzgAAAAJ": "De-An Huang",
    "21W5L1YAAAAJ": "Montserrat Gonzalez Arenas",
    "Izhkp4YAAAAJ": "Eric Jang",
    "Wel9l1wAAAAJ": "Andrew Tao",
    "nkmDOPgAAAAJ": "Anelia Angelova",
    "sUb_eyUAAAAJ": "Sumedh Sontakke",
    "JMHsqIkAAAAJ": "Fuzhao Xue",
    "RhOpyXcAAAAJ": "Marco Pavone",
    "mIlaYj0AAAAJ": "Zhuo Xu",
    "1bF2s2kAAAAJ": "Wenhao Yu",
    "YH1v2uYAAAAJ": "Jiayuan Gu",
    "Z3dxz9IAAAAJ": "Mohi Khansari",
    "Oz9MLlEAAAAJ": "Wenchuan Wei",
    "hYVMrzsAAAAJ": "Wenlong Huang",
    "tWoesqcAAAAJ": "Vikas Sindhwani",
    "lJbBWhMAAAAJ": "Cole Gulino",
    "aPqcyU4AAAAJ": "Benjamin Sapp",
    "uQRY6KoAAAAJ": "Eli Bronstein",
    "RK72t68AAAAJ": "Aleksandra Faust",
    "os-DVLkAAAAJ": "Wenjie Luo",
    "xBv-PMEAAAAJ": "Xiangyu Chen",
    "xPWCLvEAAAAJ": "Nico Montali",
    "FR8zF_4AAAAJ": "Rebecca Roelofs",
    "5Qp_0TUAAAAJ": "Jean Harb",
    "BC8TixYAAAAJ": "Brandyn White",
    "wUUxGfAAAAAJ": "Yiren Lu",
    "2u8jlxgAAAAJ": "Zoey Yang",
    "2IvwHucAAAAJ": "Lucila Ohno-Machado",
    "jzddqQQAAAAJ": "Jihoon Kim",
    "DnQMAnwAAAAJ": "Cinnamon Bloss",
    "TmuUs30AAAAJ": "Kristin E. Lauter",
    "izgpKaYAAAAJ": "Hai Yang",
    "YkSJ7-8AAAAJ": "Amalio Telenti",
    "O8wbTncAAAAJ": "S. Cenk Sahinalp",
    "abyZPXsAAAAJ": "Dov Fox",
    "XI5i5AUAAAAJ": "Ziyu Wen",
    "ji6BSBoAAAAJ": "Zhao Chen",
    "X9AjIugAAAAJ": "Soren Pirk",
    "klZ2MMcAAAAJ": "Haocheng Xi",
    "1VI_oYUAAAAJ": "Zhiding Yu",
    "hTxCe4oAAAAJ": "Qinghao Hu",
    "8Phz8n4AAAAJ": "Hongzhou Lin",
    "vIewY1EAAAAJ": "Vincent Casser",
    "jWz4LrAAAAAJ": "Ariel Gordon",
    "rsBBj3IAAAAJ": "Ankita Pasad",
    "2fo_v44AAAAJ": "Jan Dlabal",
    "EPfOJwQAAAAJ": "Debidatta Dwibedi",
    "GuU6oA4AAAAJ": "Pannag R Sanketi",
    "fz7LJPIAAAAJ": "Suvir Mirchandani",
    "fMN7wNwAAAAJ": "Gabriel Dulac-Arnold",
    "RNdGVHoAAAAJ": "Wei Han",
    "Cmf2HdcAAAAJ": "Nikhil J Joshi",
    "LIG-4BcAAAAJ": "Jeffrey Zhao",
    "_AoZDGEAAAAJ": "Tianli Ding",
    "DSKzTCAAAAAJ": "Sharath Maddineni",
    "y-f-MZgAAAAJ": "Ming-Yu Liu",
    "wUZuAisAAAAJ": "Kunyao Chen",
    "c9QnkJMAAAAJ": "Jeffrey Bingham",
    "RM2vMNcAAAAJ": "Tingnan Zhang",
    "VIPjBSgAAAAJ": "Jon Weisz",
    "uWfcPkkAAAAJ": "Xiaohan Zhang",
    "IetijcoAAAAJ": "Mario Prats",
    "oB0g2IkAAAAJ": "Jang Hyun (Vincent) Cho",
    "BTEsUk8AAAAJ": "Yucong Chen",
    "bYMpSOMAAAAJ": "Michelle Dow",
    "OuSPv-AAAAAJ": "Dan Xu",
    "1XbRknQAAAAJ": "Hanrong Ye",
    "PDu5GC8AAAAJ": "Shunyao Li",
    "J-dq_8EAAAAJ": "Chuchu Fan",
    "BYrARP4AAAAJ": "Kan Chen",
    "XrwHHxAAAAAJ": "Qiang Ning",
    "YT5NJ24AAAAJ": "Zhoutian Feng",
    "l2FS2_IAAAAJ": "Anurag Arnab",
    "ExGkzjQAAAAJ": "Kumara Kahatapitiya",
    "95hBTe8AAAAJ": "Shaoxuan Wang",
    "qdnDZkYAAAAJ": "Thomas Lew",
    "ZGpE5cYAAAAJ": "Sumeet Singh",
    "c4YtO-MAAAAJ": "Tamás Sarlós",
    "J8OgouwAAAAJ": "Krzysztof Choromanski",
    "tBbUAfsAAAAJ": "Kumar Avinava Dubey",
    "iJbdUkQAAAAJ": "Frederick Liu",
    "fhaNx_oAAAAJ": "Deepali Jain",
    "0JH6YbEAAAAJ": "Boyi Li",
    "e1zesfMAAAAJ": "Iretiayo Akinola",
    "8LqrW5AAAAAJ": "Jisheng Li",
    "ncJWfs0AAAAJ": "Adrian Li-Bell",
    "ZRl2aAwAAAAJ": "Weixin Li",
    "fjuWXroAAAAJ": "Qinghao Hu",
    "eJISgYQAAAAJ": "Bohan Li",
    "1FiIlQsAAAAJ": "Sushant Veer",
    "q-WSy3AAAAAJ": "Max Ehrlich",
    "VVIAoY0AAAAJ": "Jonah Philion",
    "AOdxmJYAAAAJ": "Yuxiao Chen",
    "ey9AQcEAAAAJ": "Boris Ivanovic",
    "dthSEsoAAAAJ": "Xinshuo Weng",
    "CBLnYLEAAAAJ": "Wei Meng",
    "eZQNcvcAAAAJ": "Huiwen Chang",
    "r5WezOYAAAAJ": "Huizi Mao",
    "f_sApl4AAAAJ": "Muyang Li",
    "J_XhIsgAAAAJ": "Ravi Kumar",
    "b3HMX-sAAAAJ": "Sergei Vassilvitskii",
    "78Z4ctAAAAAJ": "Alessandro Epasto",
    "3fvu4fcAAAAJ": "Aris Anagnostopoulos",
    "VZCAjz4AAAAJ": "Ebadollah S. Mahmoodian",
    "BgOXDogAAAAJ": "Yinyu Ye",
    "Zq4ioqu5yb8C": "Ranveer Chandra",
    "16posrQAAAAJ": "Lili Qiu",
    "huxkCSoAAAAJ": "Patrick R Jordan",
    "VDyjbagAAAAJ": "Evangelos Markakis",
    "8eB7Q1kAAAAJ": "Vijay Vazirani",
    "ohL-Y50AAAAJ": "Ronald Fagin",
    "-sMCAGcAAAAJ": "D. Sivakumar",
    "O_7MVDIAAAAJ": "Eli Upfal",
    "nSSZmScAAAAJ": "Preston Mcafee",
    "q4QmSekAAAAJ": "Mohammad Salavatipour",
    "3zhgn8MAAAAJ": "Santiago Balseiro",
    "fNvryVUAAAAJ": "David Kempe",
    "4_i_4TkAAAAJ": "David M Pennock",
    "9ZGqm5QAAAAJ": "Anna R. Karlin",
    "-JOkpfQAAAAJ": "Andrew Tomkins",
    "Wn8xr_gAAAAJ": "Qiqi Yan",
    "YPineKcAAAAJ": "Jaroslav Nešetřil",
    "9oNkK7YAAAAJ": "Louay Bazzi",
    "ynJ-R00AAAAJ": "Uri Nadav",
    "3Lmd6AMAAAAJ": "Nikhil Bansal",
    "MGXRuXYAAAAJ": "Flavio Chierichetti",
    "cuSWd3cAAAAJ": "Rados Radoicic",
    "XgifkSsAAAAJ": "Daniel Reeves",
    "Jc97EyAAAAAJ": "Jon Schneider",
    "_xyC5igAAAAJ": "Song Zuo",
    "L82mYv8AAAAJ": "Daniel Spielman",
    "NDhlLv0AAAAJ": "Martin Pál",
    "fcqBMQgAAAAJ": "Hu Fu",
    "R1YK5BsAAAAJ": "Inbal Talgam-Cohen",
    "v-hyE4MAAAAJ": "Bahman Bahmani",
    "RvbzlYUAAAAJ": "Tracy Kimbrel",
    "b6N0NroAAAAJ": "Sadra Yazdanbod",
    "FecYwZ0AAAAJ": "Jacob Fox",
    "FGGfkmMAAAAJ": "Esteban Arcaute",
    "SAEI0jwAAAAJ": "Saeed Seddighin",
    "fkGRlH0AAAAJ": "Mahsa Derakhshan",
    "5EMVIoEAAAAJ": "Philip B. Stark",
    "6qE0tdAAAAAJ": "Ronald L. Rivest",
    "IT7lx4sAAAAJ": "Jakub Lacki",
    "tFq6hXAAAAAJ": "Gary William Flake",
    "qCdLtIoAAAAJ": "Bo Pang",
    "1UWlwuEAAAAJ": "Yang Cai",
    "Y_Ieu7EAAAAJ": "Bo Waggoner",
    "S39CcbQAAAAJ": "Aranyak Mehta",
    "GpXyLGwAAAAJ": "Hoda Heidari",
    "zKORw8wAAAAJ": "Umar Syed",
    "70Rmp1oAAAAJ": "Mohammad Ghodsi",
    "ax3nTU8AAAAJ": "Rouzbeh Touserkani",
    "XRujzBsAAAAJ": "Babak Farzad",
    "wWaA2QwAAAAJ": "Okke Schrijvers",
    "GkMfzy4AAAAJ": "Li Erran Li",
    "mTqef3oAAAAJ": "Karen Aardal",
    "YP90oGMAAAAJ": "sharareh alipour",
    "xuNJ-d8AAAAJ": "Mohammad Ali Abam",
    "Vv8UdowAAAAJ": "Sharad Goel",
    "dfScyQgAAAAJ": "Alex Fabrikant",
    "_cMw1IUAAAAJ": "Arpita Ghosh",
    "uWNrcTUAAAAJ": "Soheil Behnezhad",
    "FzSHcngAAAAJ": "Hazhir Rahmandad",
    "nujTx04AAAAJ": "John Wright",
    "0OsAngEAAAAJ": "Allen Y. Yang",
    "uT8fgagAAAAJ": "Rene Vidal",
    "sQ6l4sMAAAAJ": "Jana Kosecka",
    "TanjFwoAAAAJ": "Zhouchen Lin",
    "hacOX_AAAAAJ": "Shankar Rao",
    "vEcgp3AAAAAJ": "Zihan Zhou",
    "fe-1v0MAAAAJ": "Shenghua Gao",
    "nRQi4O8AAAAJ": "Emmanuel Candes",
    "hYlbtl8AAAAJ": "Shengbang Tong",
    "rGF6-WkAAAAJ": "Thomas S. Huang",
    "Mf9VHRcAAAAJ": "Kui Jia (贾奎)",
    "CSzbLwUAAAAJ": "Kun Huang",
    "WDJ7tY0AAAAJ": "Tsung Han Chan (詹宗翰)",
    "GSHmKZkAAAAJ": "Hossein Mobahi",
    "m3DDS00AAAAJ": "Wei Hong",
    "iyVHKkcAAAAJ": "Haozhi Qi",
    "DNuiPHwAAAAJ": "Shuicheng Yan, Fellow of AAAI, ACM, SAEng, IEEE, IAPR",
    "Mfrpm_IAAAAJ": "Chong You",
    "xF7oivwAAAAJ": "Zhengdong Zhang",
    "PaFLL10AAAAJ": "Guangcan Liu",
    "ghZkSV8AAAAJ": "Omid Shakernia",
    "6V6u2g0AAAAJ": "Yigang Peng (彭义刚)",
    "bW1gAI8AAAAJ": "Liansheng Zhuang",
    "-g58LsoAAAAJ": "Weisheng Dong",
    "11aRt9oAAAAJ": "Guangming Shi",
    "BWnXD4IAAAAJ": "Zinan Zeng",
    "9RAHYd0AAAAJ": "Ziyang Wu",
    "PqlE63kAAAAJ": "Yichao Zhou",
    "bW6qGV0AAAAJ": "Xiaodong Li",
    "DBXWBqcAAAAJ": "Kwan Ho Ryan Chan",
    "CtRMD1UAAAAJ": "Xili Dai",
    "UeltiQ4AAAAJ": "Xiang Bai",
    "9oz-dvgAAAAJ": "Zhuowen Tu",
    "gMBvzGoAAAAJ": "Xin Li",
    "Ikt1e-0AAAAJ": "Harm  Derksen",
    "Ux677B4AAAAJ": "Desen Zhou",
    "ISRNX3gAAAAJ": "Guillermo Sapiro",
    "Iv6ll44AAAAJ": "Chaobing Song",
    "UpZbV44AAAAJ": "Michael Elad",
    "V6FaD-UAAAAJ": "Ju Sun",
    "-84M1m0AAAAJ": "Yong Yu (俞勇)",
    "Y2GtJkAAAAAJ": "Saining Xie",
    "v6HphBcAAAAJ": "Tianzhe Chu",
    "ZqGaKSgAAAAJ": "Zitong Yang",
    "IpmnLFcAAAAJ": "Cong Yao",
    "L3wy9QMAAAAJ": "Tianjiao Ding",
    "JfblW3MAAAAJ": "Qing Qu",
    "RL7jPuQAAAAJ": "Xiaojie Guo (郭晓杰)",
    "Bx9WGD6lBFEC": "Julien Mairal",
    "qtLQJRYAAAAJ": "Ben Haeffele",
    "fXPO6U0AAAAJ": "Roberto Tron",
    "vqYq3egAAAAJ": "Michael Psenka",
    "5WT38A0AAAAJ": "Sam Buchanan",
    "PDgp6OkAAAAJ": "Xiaochun Cao",
    "eomC7sIAAAAJ": "Yasuyuki Matsushita",
    "7620QAMAAAAJ": "Nenghai Yu",
    "o6W_m00AAAAJ": "Xiaojun Yuan",
    "m-om5O8AAAAJ": "Chen Zhu",
    "720Ix7QAAAAJ": "HAO BAI",
    "rJMOlVsAAAAJ": "Ivor W. Tsang, IEEE Fellow",
    "9sCGe-gAAAAJ": "Tianzhu Zhang",
    "K1LjZxcAAAAJ": "Boxin Shi",
    "DQOT0OMAAAAJ": "Hailin Jin",
    "1TV1xrMAAAAJ": "Yoav Sharon",
    "qNCTLV0AAAAJ": "Xinggang Wang",
    "IOagLnEAAAAJ": "David Zhang, Dapeng",
    "tAK5l1IAAAAJ": "Lei Zhang",
    "r2nw6DIAAAAJ": "Meng Yang",
    "R3sUe_EAAAAJ": "Yifan Wang",
    "9Pl5k60AAAAJ": "Alessandro Chiuso",
    "7SgUlggAAAAJ": "Gang Hua",
    "KltleWgAAAAJ": "Matthew Turk",
    "p9-ohHsAAAAJ": "Ming-Hsuan Yang",
    "VD5OsIwAAAAJ": "Ziran Xing",
    "_moJlrIAAAAJ": "Sean (Xiang) Ren",
    "7Hdu5k4AAAAJ": "Dong Xu,  Professor & IEEE Fellow",
    "dY7OSl0AAAAJ": "Narendra Ahuja",
    "5gi3Pm0AAAAJ": "Kewei Tu",
    "j-P28bQAAAAJ": "Shuaiyi Huang",
    "xW-IxnwAAAAJ": "Hao Tang",
    "sCuACdkAAAAJ": "Qiang Wu",
    "qrNPFTQAAAAJ": "Jian Zhang, PhD",
    "pP7EjUsAAAAJ": "Worapan Kusakunniran",
    "Li-BrU4AAAAJ": "Erik Learned-Miller",
    "J5ZQ-BUAAAAJ": "Li-Yi Wei",
    "oN7gaqMAAAAJ": "Qi Sun",
    "7agkJogAAAAJ": "Liang Yang",
    "w_XDRRsAAAAJ": "Paolo Favaro",
    "-CKm5DEAAAAJ": "David Hyunchul Shim",
    "zZO9qG4AAAAJ": "Bruno Sinopoli",
    "GlB6wkgAAAAJ": "Frank Hoffmann",
    "1wzEtxcAAAAJ": "Errui Ding",
    "6G-l4o0AAAAJ": "Xian-Sheng Hua (华先胜)(IEEE Fellow)",
    "cvgKxDQAAAAJ": "Linjun Yang",
    "-F1rk68AAAAJ": "Lei Wu",
    "-bp44DoAAAAJ": "Xiang Sean Zhou",
    "Fn6xg8EAAAAJ": "Bogdan Georgescu",
    "-XZ2HrAAAAAJ": "Dorin Comaniciu",
    "ZeJjFQMAAAAJ": "C. Lawrence Zitnick",
    "bYvl2kwAAAAJ": "Gene Cheung",
    "e38fTZQAAAAJ": "Yizhou Yu",
    "c-uQx_0AAAAJ": "Victor Shia",
    "Kia-4B0AAAAJ": "George Pappas",
    "samruv0AAAAJ": "Daniel Liberzon",
    "9j-6i_oAAAAJ": "Anders Heyden",
    "r6YTppEAAAAJ": "Arvind Ganesh Balasubramanian",
    "yzU6g24AAAAJ": "Xiao-Tong Yuan",
    "Z_CRrRwAAAAJ": "Jian Zhang",
    "3_u1jHQAAAAJ": "Richard Szeliski",
    "vC2vywcAAAAJ": "Jean Ponce",
    "b0k2tTgAAAAJ": "Gerard Medioni",
    "nBwaXUsAAAAJ": "Linda Shapiro",
    "9UfZJskAAAAJ": "Yuting Zhang",
    "5H0arvkAAAAJ": "David Forsyth",
    "YHxZLlwAAAAJ": "Katsushi Ikeuchi",
    "U_NEZHQAAAAJ": "Radu B. Rusu",
    "rJvU7ngAAAAJ": "David Gossow",
    "ivApfKcAAAAJ": "Gregory Hager",
    "NWqnXNEAAAAJ": "Gang Pan (潘纲)",
    "TLQUwIMAAAAJ": "H. Jin Kim (김현진, Hyoun Jin Kim)",
    "SM9v2HMAAAAJ": "Xiaocheng Hu",
    "C-5j7CQAAAAJ": "Christoph Schnörr",
    "NCtKHnQAAAAJ": "Josef Sivic",
    "R9L_AfQAAAAJ": "Jingyi Yu",
    "VQ70NaMAAAAJ": "Veit Hagenmeyer",
    "p-h_BvcAAAAJ": "Vikas Chandra",
    "2r7JwHIAAAAJ": "Mahsa Kamali",
    "UvirJPEAAAAJ": "Eyal Ofek",
    "cSN8ZyQAAAAJ": "Syphers, M.J.",
    "pKf5LtQAAAAJ": "Paul Liang",
    "xPqd-FMAAAAJ": "Tadas Baltrušaitis",
    "rbGxNYwAAAAJ": "Stefan Scherer",
    "oS6gRc4AAAAJ": "Soujanya Poria",
    "r2OOH4cAAAAJ": "Giota Asensio (Stratou)",
    "CX8zqPoAAAAJ": "Chaitanya Ahuja",
    "91NxdC4AAAAJ": "Peter Robinson",
    "Bkq-JK8AAAAJ": "Gale M. Lucas",
    "ilSYpW0AAAAJ": "Erik Cambria",
    "LkoaA0gAAAAJ": "Stacy Marsella",
    "cTZ7Bg8AAAAJ": "Albert Skip Rizzo",
    "evVAmhQAAAAJ": "David Traum",
    "8HdRoroAAAAJ": "Kenji Sagae",
    "FC9Bt6cAAAAJ": "Jill Boberg",
    "E6vCXjkAAAAJ": "Volkan Cirik",
    "UetM7FgAAAAJ": "Rada Mihalcea",
    "spv5CecAAAAJ": "Fabrizio Morbini",
    "SuTJ0iMAAAAJ": "Torsten Wörtwein",
    "3o1o4ukAAAAJ": "Eugene Laksana",
    "QNvkEeoAAAAJ": "Mathieu Chollet",
    "cB7hK3sAAAAJ": "John Pestian",
    "TxKNCSoAAAAJ": "Björn Schuller",
    "Fa1BONsAAAAJ": "Kallirroi Georgila",
    "xZ8OqxMAAAAJ": "Angela Nazarian",
    "zRkcvqgAAAAJ": "Lixing Huang",
    "CSxgi6AAAAAJ": "Moitreya Chatterjee (he/him)",
    "6iOJ8foAAAAJ": "Behnaz Nojavanasghari",
    "h1r4NG0AAAAJ": "Iwan de Kok",
    "jqWZsC0AAAAJ": "Justin T. Baker",
    "dNHNpxoAAAAJ": "Yale Song",
    "irNcfEEAAAAJ": "Derya Ozkan",
    "CFp3IakAAAAJ": "Rowan Zellers",
    "ygpxbK8AAAAJ": "Maja Pantic",
    "wkC9xHMAAAAJ": "Justine Cassell",
    "mYyG4p0AAAAJ": "Marwa Mahmoud",
    "pbb9CG4AAAAJ": "Charlie Hughes",
    "kWEH634AAAAJ": "Chris Lee",
    "oM6Pj3MAAAAJ": "Liangke Gui",
    "B88-xMEAAAAJ": "Alice Oh",
    "QKOH5iYAAAAJ": "Stefanos Zafeiriou",
    "07NrZFIAAAAJ": "Javier Movellan",
    "PGyMqU0AAAAJ": "Jacob Whitehill",
    "de30Rq0AAAAJ": "Peter Carnevale",
    "8f9jTNcAAAAJ": "Anton Leuski",
    "tzYolooAAAAJ": "Anton Nijholt",
    "3plYmtsAAAAJ": "Ari Shapiro",
    "yatiIigAAAAJ": "Veronica Perez-Rosas",
    "5dBp2f4AAAAJ": "Murtaza Dalal",
    "AvvaaJcAAAAJ": "Eugen Solowjow",
    "8TArOy0AAAAJ": "Steven Lin",
    "SJoRNbYAAAAJ": "Jianlan Luo",
    "n9K1v-cAAAAJ": "Marcin Andrychowicz",
    "ROILf3EAAAAJ": "Phillip Isola",
    "yn-nyJwAAAAJ": "Dian Chen",
    "52T2LYoAAAAJ": "Henry Zhu",
    "Zlpuln8AAAAJ": "Giulia Vezzani",
    "H3ZnCqYAAAAJ": "Siddharth Srivastava",
    "zMw7PF8AAAAJ": "Clemens Eppner",
    "QWKWvbEAAAAJ": "Nicholas D. Altieri",
    "RRmQyu8AAAAJ": "Vassilis Athitsos",
    "TkVHKDgAAAAJ": "Jianming Zhang",
    "zjlFcrEAAAAJ": "Sarah Adel Bargal",
    "wQv9q3cAAAAJ": "Marco La Cascia",
    "aXnBRhkAAAAJ": "Romer Rosales",
    "dFNbaFsAAAAJ": "Vitaly Ablavsky",
    "UsqNPH4AAAAJ": "Donghyun Kim",
    "tu39-p8AAAAJ": "Margrit Betke",
    "P2mG6rcAAAAJ": "Leonid Sigal",
    "aCYoiC8AAAAJ": "Quan Yuan",
    "0VFi-vAAAAAJ": "George Kollios",
    "SUd2LJUAAAAJ": "Shugao Ma",
    "bhLQ6oQAAAAJ": "Ashwin Thangali",
    "R0bnqaAAAAAJ": "Zhe L. Lin",
    "1MceCxsAAAAJ": "Taipeng Tian",
    "gwLessAAAAAJ": "Nazli Ikizler-Cinbis",
    "CkVvikAAAAAJ": "Rui Li",
    "pViZYwIAAAAJ": "Xiaohui Shen",
    "_1basdkAAAAJ": "Uğur Murat Erdem",
    "YOb3xH4AAAAJ": "Liliana Lo Presti",
    "p1tu16UAAAAJ": "Qinxun Bai",
    "ntGll74AAAAJ": "Brian Price",
    "RTbYeUcAAAAJ": "Radomir Mech",
    "_Ic8wQ4AAAAJ": "Andrea Zunino",
    "bf2ZrFcAAAAJ": "Alberto Del Bimbo",
    "JIhJXWUAAAAJ": "Mehrnoosh (Mers) Sameki",
    "Za7uka8AAAAJ": "Ramazan Gokberk Cinbis",
    "LSvg03gAAAAJ": "Hee-Deok Yang",
    "8qOWtywAAAAJ": "Panagiotis Papapetrou",
    "PHJokEQAAAAJ": "Dimitrios Gunopulos",
    "oI6AIkMAAAAJ": "Sergio Escalera",
    "LAuxzv0AAAAJ": "Agata Rozga",
    "nFzWaPMAAAAJ": "John Magee",
    "FzwrcoYAAAAJ": "Hugo Jair Escalante",
    "6TGwETYAAAAJ": "Sven Dickinson",
    "UuE08jUAAAAJ": "Walter Nunziati",
    "UyKhhwwAAAAJ": "Filip Malmberg",
    "htt9T1AAAAAJ": "Octavia I. Camps",
    "gb8sbdcAAAAJ": "Gregory D. Abowd",
    "8kA3eDwAAAAJ": "James M. Rehg",
    "G0LfNJcAAAAJ": "Opal Ousley, PhD",
    "xAFGASEAAAAJ": "Mario Romero",
    "6C8rf-0AAAAJ": "Hermann Ney",
    "KoJrMIAAAAAJ": "Jacob Feldman",
    "EoACFEUAAAAJ": "Hao Jiang",
    "5yNbjSoAAAAJ": "Seong-Whan Lee",
    "R2lPbLQAAAAJ": "Jonathan Brandt",
    "75q-6ZQAAAAJ": "Dan Alistarh",
    "YnJVsp4AAAAJ": "Sitan Chen",
    "z4JhSBwAAAAJ": "Milan Vojnovic",
    "TxdeO-UAAAAJ": "Ryota Tomioka",
    "busWvZkAAAAJ": "Kevin Tian",
    "GNYqvgQAAAAJ": "Allen Liu",
    "4FM97JgAAAAJ": "Jordan Cotler",
    "2y5YF-gAAAAJ": "Hsin-Yuan Huang (Robert)",
    "SupjsEUAAAAJ": "Aleksander Mądry",
    "aHtfItQAAAAJ": "Yuanzhi Li",
    "wMx_Eu4AAAAJ": "Demjan Grubic",
    "Kr8JjF0AAAAJ": "Hadi Salman",
    "Xz4RAJkAAAAJ": "Greg Yang",
    "V2Y1L4sAAAAJ": "Sebastien Bubeck",
    "XeEA6r8AAAAJ": "Arun Jambulapati",
    "RRzVwKkAAAAJ": "Ji Liu",
    "Hy4JQ2MAAAAJ": "Kaan Kara",
    "GkXqbmMAAAAJ": "Ce Zhang",
    "n00Ol9UAAAAJ": "Hantian Zhang",
    "MoJFIiQAAAAJ": "Zeyuan Allen-Zhu",
    "aUeGl58AAAAJ": "Brandon Tran",
    "58As-bYAAAAJ": "Justin Kopinsky",
    "u_fAQO4AAAAJ": "Sinho Chewi",
    "70vJVxcAAAAJ": "Jayadev Acharya",
    "H-PvgRsAAAAJ": "Anru Zhang",
    "LTa3GzEAAAAJ": "Huan Zhang",
    "F3_yOXUAAAAJ": "Andrew Critch",
    "JGS2xjkAAAAJ": "Collin Burns",
    "6I7jyygAAAAJ": "Ryan Babbush",
    "r2E5Ak8AAAAJ": "Hartmut Neven",
    "mE1vlGEAAAAJ": "Richard Kueng",
    "yVy2ZIwAAAAJ": "Jarrod R. McClean",
    "KhCiiawAAAAJ": "Masoud Mohseni",
    "K2BMBtcAAAAJ": "John Preskill",
    "SWqd2rgAAAAJ": "Aaron Sidford",
    "HXXSrNMAAAAJ": "Christopher Musco",
    "bg8RrSkAAAAJ": "Dan Iter",
    "FkufKDgAAAAJ": "Reid Pryzant",
    "wFkXSlYAAAAJ": "Adil Salim",
    "SIxd6jgAAAAJ": "Dan Suciu",
    "plYoF-MAAAAJ": "Paul Beame",
    "vzfO5TwAAAAJ": "Sudeepa Roy",
    "zdn08t8AAAAJ": "Tselil Schramm",
    "2ZYz2SwAAAAJ": "Tony Duan",
    "2eADy_8AAAAJ": "Edward Hu",
    "sqCGBtYAAAAJ": "Vikrant Singhal",
    "iq-7vhMAAAAJ": "Giorgi Nadiradze",
    "c0JG32IAAAAJ": "Brice Huang",
    "o7yFQXUAAAAJ": "Sivaraman Balakrishnan",
    "2aMqJTgAAAAJ": "Guy Bresler",
    "guJ_kBQAAAAJ": "Fred Zhang",
    "yDZct7UAAAAJ": "Zhao Song",
    "CTT44Y0AAAAJ": "Shyam Narayanan",
    "Gkc2UeUAAAAJ": "Elena Grigorescu",
    "MaSuaDkAAAAJ": "Trevor Brown",
    "lXCP2cMAAAAJ": "Mark Sellke",
    "i1NrG8UAAAAJ": "Ayush Jain",
    "F0yiLRIAAAAJ": "Ivan Evtimov",
    "s_YDrrgAAAAJ": "Tadayoshi Kohno",
    "7Xko5sYAAAAJ": "Ece Kamar",
    "Gwb4YkUAAAAJ": "Swati Padmanabhan",
    "AxUAEQ4AAAAJ": "Chawin Sitawarin",
    "tzqeiKYAAAAJ": "Nabeel Hingun",
    "vyX6kpwAAAAJ": "Yonina Eldar",
    "Ka0xUQ4AAAAJ": "Guanghao Ye",
    "Yh0IoBgAAAAJ": "Erik Waingarten",
    "glV_LWsAAAAJ": "Aleksandar Nikolov",
    "kNDEuygAAAAJ": "Chen Lu",
    "gYj6GRoAAAAJ": "Jaume de Dios",
    "xuDZ9-sAAAAJ": "Raghu Meka",
    "OGweeKgAAAAJ": "Kirankumar Shiragur",
    "yOt01wgAAAAJ": "Wai Ming Tai",
    "aFDuhV8AAAAJ": "Jeff Phillips",
    "z0Y4snAAAAAJ": "Jasper CH Lee",
    "tYE9bLoAAAAJ": "Hannah Lawrence",
    "w1srHyIAAAAJ": "Huishuai Zhang",
    "19evEwcAAAAJ": "Shourya Pandey",
    "lNVTz20AAAAJ": "Syamantak Kumar",
    "u1Qs7YIAAAAJ": "Ankit Pensia",
    "0b_e2eAAAAAJ": "Rati Gelashvili",
    "MHLyZY4AAAAJ": "Mohsen Ghaffari",
    "bK3wI10AAAAJ": "Eric Frankel",
    "LVPkbeYAAAAJ": "Lillian J. Ratliff",
    "hr81fHoAAAAJ": "Ainesh Bakshi",
    "gckWFYUAAAAJ": "William Kretschmer",
    "dqN-sYkAAAAJ": "John Bostanci",
    "ytm_89IAAAAJ": "Ewin Tang",
    "yngEYigAAAAJ": "Hantian Zhang",
    "Br__ds4AAAAJ": "David Conlon",
    "u0561GMAAAAJ": "Jonathan Tidor",
    "W5bcaXQAAAAJ": "Mehtaab Sawhney",
    "SLNZE7kAAAAJ": "Ashwin Sah",
    "01II9NsAAAAJ": "Eyal Lubetzky",
    "CU1rungAAAAJ": "Zilin Jiang",
    "DSdABLMAAAAJ": "Bhaswar B. Bhattacharya",
    "MavyE28AAAAJ": "Huy Tuan Pham",
    "yqfXEPIAAAAJ": "Benjamin Sudakov",
    "vOYl40wAAAAJ": "Noga Alon",
    "m3wdswkAAAAJ": "David Galvin",
    "LrHm5cgAAAAJ": "Yang P. Liu",
    "owKwr1IAAAAJ": "Matthew Kwan",
    "oCw8EScAAAAJ": "Vishesh Jain",
    "tAdZoKIAAAAJ": "asaf ferber",
    "cNSbfGQAAAAJ": "Adel Javanmard",
    "vFWw1NoAAAAJ": "Ruediger Urbanke",
    "ubaxhUIAAAAJ": "David Donoho",
    "D83Vz00AAAAJ": "Marc Mezard",
    "E8Jst30AAAAJ": "Theodor Misiakiewicz",
    "jUt50EcAAAAJ": "Arian Maleki",
    "k8nSlL4AAAAJ": "Federico Ricci-Tersenghi",
    "24Ke6Q8AAAAJ": "Yash Deshpande",
    "PCtRSvUAAAAJ": "Raghunandan Keshavan",
    "4j-x4ckAAAAJ": "Guilhem Semerjian",
    "OVdu5IEAAAAJ": "Behrooz Ghorbani",
    "kkP2ICsAAAAJ": "amir dembo",
    "lPG5fAIAAAAJ": "Phan-Minh Nguyen",
    "rpbMOTsAAAAJ": "Abdelaziz Amraoui",
    "mZM5KHIAAAAJ": "Emmanuel Abbe",
    "tb2aY4kAAAAJ": "Michael Celentano",
    "TyPF9V4AAAAJ": "Balaji Prabhakar",
    "GPIB5kUAAAAJ": "Stratis Ioannidis",
    "XfSFItwAAAAJ": "Yi Lu",
    "jAAj2XoAAAAJ": "Yuchen Wu",
    "rCH4toMAAAAJ": "Emile Richard",
    "lOGcZowAAAAJ": "Nadia Fawaz",
    "BHdSb5AAAAAJ": "Marco Mondelli",
    "XbjOzyQAAAAJ": "Feng Ruan",
    "oQ5FSggAAAAJ": "Saharon Rosset",
    "tQVe-fAAAAAJ": "Trevor Hastie",
    "cQ1P1qoAAAAJ": "Ryan Tibshirani",
    "Lqc4cdAAAAAJ": "Murat A. Erdogdu",
    "EIAYEl4AAAAJ": "Jun Yan",
    "R4dvN4oAAAAJ": "Youngtak Sohn",
    "pgcjVaYAAAAJ": "Morteza Ibrahimi",
    "xdsgpC0AAAAJ": "Andrea Pelissetto",
    "Ut6nPD8AAAAJ": "Sergio Caracciolo",
    "5t2myD8AAAAJ": "Elchanan Mossel",
    "CeioNO4AAAAJ": "Satish Babu Korada",
    "cCUHSdkAAAAJ": "Hamid Javadi",
    "e6op8BQAAAAJ": "Kangjie Zhou",
    "y0U2EaUAAAAJ": "Allan Sly",
    "cLGOIdMAAAAJ": "Marc Lelarge",
    "tgtareEAAAAJ": "Abdul Kabbani",
    "ZLCLbSQAAAAJ": "Raphaël Berthier",
    "3jDeUlMAAAAJ": "Florent Krzakala",
    "gkCjy_UAAAAJ": "Lenka Zdeborová",
    "CZ3EC4AAAAAJ": "Basil Saeed",
    "fds2VpgAAAAJ": "Alexander Rakhlin",
    "8sGC5D4AAAAJ": "Gerard BEN AROUS",
    "R9L0aqAAAAAJ": "Mihai Nica",
    "in8fQ10AAAAJ": "Yiqiao Zhong",
    "VajMetgAAAAJ": "Nima Aghaeepour",
    "O4pBP40AAAAJ": "Ivana Maric",
    "UqiD090AAAAJ": "Chen Cheng",
    "2c3HfFAAAAAJ": "ofer zeitouni",
    "SJE16yoAAAAJ": "Daniel Reichman",
    "mXtH1UYAAAAJ": "Amy Zhang",
    "VO4oS8UAAAAJ": "Rasmus Pagh",
    "jabdPAwAAAAJ": "Martin Dietzfelbinger",
    "uWan5l0AAAAJ": "Subhabrata Sen",
    "bgI5L7oAAAAJ": "Leo Miolane",
    "J6LkBeUAAAAJ": "Remi Monasson",
    "Kpqp274AAAAJ": "Simona Cocco",
    "B6EgtpUAAAAJ": "Ramji Venkataramanan",
    "TeuEgRkAAAAJ": "Giorgio Parisi",
    "6bJxJIcAAAAJ": "Abraham Tsur",
    "w1-xBhoAAAAJ": "Virginia D Winn",
    "KZL-4GEAAAAJ": "José Bento",
    "fsbXdAYAAAAJ": "Yuting Wei",
    "SvLPY-QAAAAJ": "Tommaso Rizzo",
    "BItCgjYAAAAJ": "Nina Taft",
    "quhI7uQAAAAJ": "Silvio Franz",
    "FEvVS54AAAAJ": "Shirin Jalali",
    "E5NCCUEAAAAJ": "Roberto Imbuzeiro Oliveira",
    "udIzg9QAAAAJ": "Ricardo Restrepo Lopez",
    "FmZaK1wAAAAJ": "Prasad Tetali",
    "8fiH7UkAAAAJ": "Emre Telatar",
    "j0nK_CsAAAAJ": "Matan Gavish",
    "3svZOGAAAAAJ": "Baosen Zhang",
    "dKDdHFsAAAAJ": "MARKUS MÜLLER",
    "CctaxzYAAAAJ": "Leticia F. Cugliandolo",
    "RmhQmkwAAAAJ": "Alexander S. Wein",
    "3qPiYJoAAAAJ": "Devavrat Shah",
    "TvVmLjUAAAAJ": "Laurent Massoulié",
    "6ReT2voAAAAJ": "Nikhil Srivastava",
    "6T1XtW8AAAAJ": "Yuekai Sun",
    "YXrj9aIAAAAJ": "Pulkit Tandon",
    "lQbIarsAAAAJ": "Eren Sasoglu",
    "vV4K9eYAAAAJ": "Udi Weinsberg",
    "UhC0_gwAAAAJ": "Antonio Auffinger",
    "jre2iwMAAAAJ": "Eric W. Tramel",
    "n4eReqMAAAAJ": "Mohammad Hossein Bateni",
    "HlLm4LIAAAAJ": "Jakab Tardos",
    "YYRnhTkAAAAJ": "André Linhares",
    "-KdNGwgAAAAJ": "Ashkan Norouzi-Fard",
    "fizPmUgAAAAJ": "Brice Gaudilliere",
    "TN-sNaMAAAAJ": "Kabir Aladin Verchand",
    "uOyNG_AAAAAJ": "Tom Richardson",
    "NxGK-wQAAAAJ": "Abdelaziz Amraoui",
    "thZJZaYAAAAJ": "Amy X. Zhang",
    "uDVHMCwAAAAJ": "Santhosh Kumar",
    "K3ht_ZUAAAAJ": "Daniel Bolya",
    "1E7m_VsAAAAJ": "Viraj Prabhu",
    "rIK7AMkAAAAJ": "Prithvijit Chattopadhyay",
    "UdpacsMAAAAJ": "Jun-Yan Zhu",
    "66lkylsAAAAJ": "XingChao Peng",
    "rDfyQnIAAAAJ": "Li Fei-Fei",
    "UxuqG1EAAAAJ": "Christoph Feichtenhofer",
    "_bs7PqgAAAAJ": "Dhruv Batra",
    "ktwwLjsAAAAJ": "Mehryar Mohri",
    "19t-gxUAAAAJ": "Ningshan Zhang",
    "6GDfcqEAAAAJ": "Laurens van der Maaten",
    "mS5k4CYAAAAJ": "Justin Johnson",
    "vjZrDKQAAAAJ": "James Hays",
    "zJyuMYgAAAAJ": "Pratik Ramesh",
    "0I2qH0oAAAAJ": "Yogesh Balaji",
    "GN_9dYIAAAAJ": "George Stoica",
    "KmSuVtgAAAAJ": "Tom Goldstein",
    "MVUbYCkAAAAJ": "Zelun Luo",
    "ijpYJQwAAAAJ": "Devi Parikh",
    "Tw2m5kUAAAAJ": "Serena Yeung-Levy",
    "HXowq5YAAAAJ": "Michael Maire",
    "Sl_2kHcAAAAJ": "Igor Vasiljevic",
    "E6ayakEAAAAJ": "Muhammad Haris",
    "Tgbsbs8AAAAJ": "Norimichi Ukita",
    "kCYbVq0AAAAJ": "Karen Livescu",
    "8hIYYuEAAAAJ": "Gustav Larsson",
    "SuWIEE8AAAAJ": "Payman Yadollahpour",
    "MqWYTj0AAAAJ": "Nicholas Kolkin",
    "ow3r9ogAAAAJ": "Vitor Campagnolo Guizilini",
    "RAiewnEAAAAJ": "Matthew R. Walter",
    "2xjjS3oAAAAJ": "Rares Ambrus",
    "AVT2-U4AAAAJ": "Diane Brentari",
    "veCt9kMAAAAJ": "Ruotian Luo",
    "2StUgf4AAAAJ": "Adrien Gaidon",
    "4sontAIAAAAJ": "Haochen Wang",
    "G2-nFaIAAAAJ": "Paul Viola",
    "xqyoorYAAAAJ": "Bowen Shi",
    "2MOwmwYAAAAJ": "Xiaodan Du",
    "E9rg2eEAAAAJ": "Mohammadreza Mostajabi",
    "w9jtLkIAAAAJ": "Jiahao Li",
    "7HDE1ZwAAAAJ": "Raymond A. Yeh",
    "6NjbexEAAAAJ": "Michael J. Black",
    "WghUqGkAAAAJ": "Jiading Fang",
    "5dGWexcAAAAJ": "Taehwan Kim",
    "wS2Fyv8AAAAJ": "Carlos E Vargas-Irwin",
    "l7Qx0zAAAAAJ": "Subhransu Maji",
    "WlJ69p0AAAAJ": "Abner Guzmán Rivera",
    "0v5utcwAAAAJ": "Ayan Chakrabarti",
    "Br80hVMAAAAJ": "Scott Cohen",
    "F3dhs4kAAAAJ": "Herman Kamper",
    "6xWhoLoAAAAJ": "Aurora Martinez del Rio",
    "wlxnii4AAAAJ": "Sharon Alpert",
    "d6vuvHIAAAAJ": "Ronen Basri",
    "oVsC3XcAAAAJ": "meirav galun",
    "w0OodaEAAAAJ": "Daniel Glasner",
    "Eclg4mwAAAAJ": "Roberto Cipolla",
    "D7bpRJ8AAAAJ": "Oгњeн Аранђeлoвић / Ognjen Arandjelović",
    "j7uL6VEAAAAJ": "Kalyan Sunkavalli",
    "OV1Y3FUAAAAJ": "Hao Tan",
    "-q4nE1kAAAAJ": "Sai Bi",
    "NLxrmYQAAAAJ": "Fujun Luan",
    "I_7PXKEAAAAJ": "Yinghao Xu",
    "_RRIYvEAAAAJ": "Zexiang Xu",
    "AerHOzUAAAAJ": "Yicong Hong",
    "eVv0MrsAAAAJ": "Kai Zhang",
    "shLVWDYAAAAJ": "Andrea F. Daniele",
    "fm0h6EkAAAAJ": "Falcon Zhongtian Dai",
    "W2DsnAkAAAAJ": "Chris Dyer",
    "kDHs7DYAAAAJ": "Kevin Gimpel",
    "0hHqYoAAAAAJ": "Huaizu Jiang",
    "VseAjdcAAAAJ": "Yuval Bahat",
    "dF8_yxsAAAAJ": "Sunnie SY Kim",
    "VWX-GMAAAAAJ": "Hanspeter Pfister",
    "vswo4rQAAAAJ": "Jessica Hodgins",
    "6NfC90UAAAAJ": "Liu Ren",
    "PlQaW9YAAAAJ": "Zhile Ren",
    "O9djN1AAAAAJ": "Weiran Wang",
    "EpT5sLAAAAAJ": "Sam Roweis (Memorial)",
    "nbpafUkAAAAJ": "David McAllester",
    "17UDvBAAAAAJ": "Jonathan Michaux",
    "EbyGwncAAAAJ": "Shubhendu Trivedi",
    "AYdoj2AAAAAJ": "Anna Ritz",
    "GhvZjJUAAAAJ": "Ben Raphael",
    "XUsauXIAAAAJ": "Anand Bhattad",
    "X6EqGFoAAAAJ": "Shane Settle",
    "sUGrQicAAAAJ": "Jason Riggle",
    "FuYln-oAAAAJ": "Sudeep Pillai",
    "PwQHMlwAAAAJ": "Pedro Savarese",
    "3Bk5C9EAAAAJ": "Rana Hanocka",
    "tsR6sHUAAAAJ": "Panagiotis Artemiadis",
    "9r7_pN8AAAAJ": "Samory Kpotufe",
    "vJkEuTEAAAAJ": "Marcelo Sandoval-Castañeda",
    "N5QAWfMAAAAJ": "Yanhong Li",
    "JlX2UTEAAAAJ": "Sylvain Paris",
    "rs0a3IQAAAAJ": "Daniel Sýkora",
    "rqoFm6sAAAAJ": "Michal Kučera",
    "5hJNWakAAAAJ": "Michal Irani",
    "D9eVSd8AAAAJ": "Ran El-Yaniv",
    "5c30hccAAAAJ": "Sudarshan Babu",
    "zYzAXcYAAAAJ": "Avery Zhou",
    "Arn3vCUAAAAJ": "Richard Liu",
    "X0RVX3AAAAAJ": "Shester Gueuwou",
    "YHjx7qoAAAAJ": "Sung-Phil Kim",
    "nQvPeCAAAAAJ": "Davis Gilton",
    "u455rGAAAAAJ": "Omar Montasser",
    "0XbUhDUAAAAJ": "Xiangshan Tan",
    "g_zaiVIAAAAJ": "Hongyuan Mei",
    "HqYIsk4AAAAJ": "Sameer A. Ansari MD, PhD",
    "EtYv_AIAAAAJ": "Takuma Yoneda",
    "5z1iJjoAAAAJ": "Tianchong Jiang",
    "K2XA5XEAAAAJ": "Muhammad Zubair Irshad",
    "L4axvLoAAAAJ": "Pavel Kisilev, PhD",
    "AH6MwzwAAAAJ": "Ella Barkan",
    "GIle-VwAAAAJ": "David H. Laidlaw",
    "8fFjYbwAAAAJ": "Çağatay Demiralp",
    "rKyTmpkAAAAJ": "Stephen SMALE",
    "P6MosQgAAAAJ": "Jake Bouvrie",
    "quJBh1EAAAAJ": "Lorenzo Rosasco",
    "ne44BF4AAAAJ": "Joshua Ahn",
    "LIiCDa0AAAAJ": "Alexander H. Liu",
    "zdAyna8AAAAJ": "Dian Chen",
    "VN0X-PcAAAAJ": "Hao Tang",
    "XG7qH_YAAAAJ": "Ken Shanyi Z.",
    "ZLpO3XQAAAAJ": "David Duvenaud",
    "k-0MEIMAAAAJ": "Matthew J. Johnson",
    "g3mGoAwAAAAJ": "David MacKay",
    "cSGXgEAAAAAJ": "Peter Orbanz",
    "4k9lBsoAAAAJ": "Abigail G. Doyle",
    "W8zwlYQAAAAJ": "Jamie Kiros",
    "Jke3O8QAAAAJ": "Elaine Angelino",
    "3q-hbWsAAAAJ": "Sigrid Adriaenssens",
    "WrLjBYgAAAAJ": "Diana Cai",
    "OO-2710AAAAJ": "Emily B. Fox",
    "XeyiyUYAAAAJ": "Margo Seltzer",
    "2XL6xRgAAAAJ": "Alice Gao",
    "QESJSgMAAAAJ": "Hilary K Finucane",
    "VEGtG7YAAAAJ": "Barbara Engelhardt",
    "hwQtFB0AAAAJ": "Finale Doshi-Velez",
    "x_7xA0UAAAAJ": "Yiling Chen",
    "KwEOawwAAAAJ": "David Dunson",
    "oirMEUEAAAAJ": "Inmar Givoni",
    "IR0yJB8AAAAJ": "Gu-Yeon Wei",
    "CkfQy2gAAAAJ": "Asma Ghandeharioun",
    "iGgf9KwAAAAJ": "Gert Aarts",
    "XMKgrt4AAAAJ": "Dénes Sexty",
    "y_wpkH8AAAAJ": "Jürg Fröhlich",
    "AnLxYd8AAAAJ": "David Brydges",
    "RE_wHW0AAAAJ": "Lorenzo Bongiovanni",
    "OM0D_3wAAAAJ": "Barry Simon",
    "nnHveQwAAAAJ": "Benjamin Jäger",
    "AfSC-s4AAAAJ": "Felipe Attanasio",
    "O9BRr1UAAAAJ": "Janos Balog",
    "wewitucAAAAJ": "Manfred Salmhofer",
    "V8NPfyQAAAAJ": "Roberto De Pietri",
    "wD_hj9QAAAAJ": "Alessandra Feo",
    "fsjokJUAAAAJ": "Christof Gattringer",
    "rjmrrlgAAAAJ": "Jan M. Pawlowski",
    "hBRnEHIAAAAJ": "Simon Ruijsenaars",
    "yE9VDTkAAAAJ": "Karl-Henning Rehren",
    "pYBdBjkAAAAJ": "Klaus Fredenhagen",
    "OxnSwKkAAAAJ": "Lorenzo Luis Salcedo Moreno",
    "icXJxqwAAAAJ": "David Campbell",
    "Pq4Yp_kAAAAJ": "Xipeng Qiu（邱锡鹏）",
    "RGsMgZA4H78C": "Huang Xuanjing (黄萱菁)",
    "oIz_CYEAAAAJ": "Pengfei Liu",
    "mnifqeUAAAAJ": "Ming Zhong",
    "ZEnShlcAAAAJ": "Yiran Chen",
    "XEgaCScAAAAJ": "Hao Zhou (周浩)",
    "Vt1j3kEAAAAJ": "Jiaze Chen",
    "ET6V1LEAAAAJ": "Zhenqiao Song",
    "GOUpm_oAAAAJ": "Kexun Zhang",
    "hUh7qCcAAAAJ": "Wenda Xu",
    "8HZzDSwAAAAJ": "Jingjing Xu",
    "fY69CxIAAAAJ": "Chenxin An",
    "4MB4orsAAAAJ": "Fei YE",
    "BYXqAlwAAAAJ": "Lei Li",
    "OBagQ_4AAAAJ": "Lawrence Jackel",
    "Wck7gd0AAAAJ": "patrick g haffner",
    "NHIpV98AAAAJ": "Bernhard Boser",
    "6KgM0OkAAAAJ": "Richard E. Howard",
    "NbXF7T8AAAAJ": "Marc'Aurelio Ranzato",
    "ETU-ePAAAAAJ": "Sumit Chopra",
    "u3u16tgAAAAJ": "Clement Farabet",
    "SSTIBK0AAAAJ": "Michael Mathieu",
    "Q0YEc-QAAAAJ": "Raia Hadsell",
    "sGFyDIUAAAAJ": "koray kavukcuoglu",
    "u3-FxUgAAAAJ": "Arthur Szlam",
    "akrkYU0AAAAJ": "Patrice Simard",
    "2PIkUqgAAAAJ": "Isabelle Guyon",
    "U_IVY50AAAAJ": "Corinna Cortes",
    "1T2Xh68AAAAJ": "Camille Couprie",
    "TGpo3KAAAAAJ": "Eduard Sackinger",
    "W2pvAfEAAAAJ": "Jane Bromley",
    "8ipao8MAAAAJ": "Junbo Zhao",
    "jmERpL4AAAAJ": "Sara A. Solla",
    "j-2_cT0AAAAJ": "Laurent Najman",
    "S1x_xqcAAAAJ": "Randall Balestriero",
    "bX__wkYAAAAJ": "Mikael Henaff",
    "GfcBlpUAAAAJ": "Y-Lan Boureau",
    "vtegaJgAAAAJ": "vapnik",
    "yIkgW-cAAAAJ": "Hans Peter Graf",
    "SvRU8F8AAAAJ": "Adrien Bardes",
    "krWNpKoAAAAJ": "Jure Zbontar",
    "uRlPu-4AAAAJ": "David Eigen",
    "n4QjVfoAAAAJ": "Xiang Zhang",
    "VhxDLwcAAAAJ": "Li Jing",
    "SqsLFwMAAAAJ": "Ravid Shwartz-Ziv",
    "WvufSLAAAAAJ": "Ishan Misra",
    "uKXVH54AAAAJ": "Piotr Mirowski",
    "WeyLqFUAAAAJ": "Yubei Chen",
    "-cL9xWMAAAAJ": "Sixin Zhang",
    "EC4o-1oAAAAJ": "Ross Goroshin",
    "jplQac8AAAAJ": "Klaus-Robert Müller",
    "MVGcpRsAAAAJ": "Christoph (Chris) Bregler",
    "CBzRa74AAAAJ": "Eric Cosatto",
    "SeGmqkIAAAAJ": "Eugenio Culurciello",
    "QUJ0kPMAAAAJ": "Beat Flepp",
    "EOnaBbUAAAAJ": "Kevin Jarrett",
    "UU3N6-UAAAAJ": "Michael Bronstein",
    "elmWdycAAAAJ": "Arjun Jain",
    "spAJDzYAAAAJ": "Ayse Naz Erkan",
    "S6moyNoAAAAJ": "Françoise Fogelman-Soulié",
    "Q9jd0mgAAAAJ": "ruben I. kuzniecky",
    "6PJWcFEAAAAJ": "Francis Bach",
    "-aNI9zwAAAAJ": "Tapani Raiko",
    "1uT7-84AAAAJ": "Harri Valpola",
    "Ysjk8kkAAAAJ": "Holger Schwenk",
    "YCPycGAAAAAJ": "Pablo Sprechmann",
    "6yMIP8AAAAAJ": "M. Reha Civanlar",
    "WRTLuxcAAAAJ": "Jörn Ostermann",
    "1p9NOFEAAAAJ": "Pierre Vandergheynst",
    "llt18PUAAAAJ": "Christopher S. Poultney",
    "45KfCpgAAAAJ": "Alexis Conneau",
    "a2KklUoAAAAJ": "Matthew Zeiler",
    "oZGA-rAAAAAJ": "Jakob Verbeek",
    "8qisprwAAAAJ": "Pauline Luc",
    "vDimc-4AAAAJ": "Tom Schaul",
    "VJ8Qd6sAAAAJ": "Serkan Piantino",
    "rFaxB20AAAAJ": "Patrick Gallinari",
    "8Ir1WvIAAAAJ": "Selcuk Talay",
    "nZEtlZoAAAAJ": "Margarita Osadchy",
    "jWWx33IAAAAJ": "Antoine Bordes",
    "dh03btIAAAAJ": "Jason Tyler Rolfe",
    "PMHXcoAAAAAJ": "Juan Pablo Bello",
    "InxhqXgAAAAJ": "Tommi Vatanen",
    "cLPaHcIAAAAJ": "Natalia Neverova",
    "FMJePIUAAAAJ": "Tom Sercu",
    "LIjnUGgAAAAJ": "Alexander M. Rush",
    "n_ts4eYAAAAJ": "Yoon Kim",
    "TGRPKRIAAAAJ": "Ken Perlin",
    "70I8ZIMAAAAJ": "Behzad Shahraray",
    "PUeKU8kAAAAJ": "Graham Taylor",
    "Oyx-_UIAAAAJ": "Jose M. Alvarez",
    "yqsvxQgAAAAJ": "Theo Gevers",
    "3LYW1zMAAAAJ": "Antonio Manuel López Peña",
    "kzS_Xd4AAAAJ": "Eric J. Humphrey",
    "LmKtwk8AAAAJ": "Nicolas Le Roux",
    "vIGcvLsAAAAJ": "Nicolas Vasilache",
    "LgF3Ds0AAAAJ": "Fabio Piano",
    "1rDKD9kAAAAJ": "Andrew Caplin",
    "zl0AOEgAAAAJ": "John Leahy",
    "j29kMCwAAAAJ": "Pietro Perona",
    "AxFrw0sAAAAJ": "Barak A. Pearlmutter",
    "UVuQeJIAAAAJ": "Gloria Coruzzi",
    "8vjzfWwAAAAJ": "Gab Krouk 光希",
    "iJENOG8AAAAJ": "Brian Kingsbury",
    "YfompPIAAAAJ": "Christian Puhrsch",
    "EKPoKcQAAAAJ": "serrano-gotarredona",
    "yjeEP_EAAAAJ": "Bernabe Linares-Barranco",
    "OaE_xMgAAAAJ": "Phi-Hung PHAM",
    "FBHC_JYAAAAJ": "Xiang Zhang",
    "xlkTND4AAAAJ": "Jeff Johnson",
    "lyMGnwIAAAAJ": "Seth Lloyd",
    "6rl-XhwAAAAJ": "Mykhaylo Andriluka",
    "0yDoR0AAAAAJ": "Stefan Roth",
    "SI6sQPYAAAAJ": "Christian Wojek",
    "lECZKZsAAAAJ": "Leonid Pishchulin",
    "jphx5uUAAAAJ": "Mohamed Omran",
    "fNfrGMIAAAAJ": "Qianru Sun 孙倩茹",
    "ZcULDB0AAAAJ": "Bastian Leibe",
    "mlSE-YwAAAAJ": "Peter Gehler",
    "qsB2vcgAAAAJ": "Jan Hosang",
    "pOSMWfQAAAAJ": "Shanshan Zhang (张姗姗)",
    "cCda-zQAAAAJ": "Michael Stark",
    "3Bfgs9cAAAAJ": "Bjoern Andres",
    "OKtm7t4AAAAJ": "James Crowley",
    "BEFl4j0AAAAJ": "Ales Leonardis",
    "BUDh_4wAAAAJ": "Siyu Tang",
    "TwMib_QAAAAJ": "Luc Van Gool",
    "TxEy3cwAAAAJ": "David Stutz",
    "u4unGhAAAAAJ": "Eldar Insafutdinov",
    "WiTNe3kAAAAJ": "Ulf Blanke",
    "vNZhd_8AAAAJ": "Markus Enzweiler",
    "FZuNgqIAAAAJ": "Konrad Schindler",
    "A8h9enQAAAAJ": "Sebastian Ramos",
    "Z_-JBYgAAAAJ": "Timo Rehfeld (Scharwächter)",
    "RM0ik8wAAAAJ": "Marius Cordts",
    "iPI39lEAAAAJ": "Kristof Van Laerhoven",
    "EuFF9kUAAAAJ": "Tinne Tuytelaars",
    "TNMSbOkAAAAJ": "Yue Fan",
    "Y1XuTkUAAAAJ": "Florian Michahelles",
    "SKb4VyUAAAAJ": "Apratim Bhattacharyya",
    "FTWcemsAAAAJ": "Liqian Ma",
    "xiiE5rYAAAAJ": "Sandra Ebert",
    "LNc2cxUAAAAJ": "Sikandar Amin",
    "jjHAnBUAAAAJ": "Stefan Walk",
    "eLZ_clAAAAAJ": "Anna Kukleva",
    "DC9wzBgAAAAJ": "Shaoshuai Shi",
    "Kn3znAMAAAAJ": "Moritz Boehle",
    "qM5jR7YAAAAJ": "Albrecht Schmidt",
    "1CLaPMEAAAAJ": "Juergen Gall",
    "5cIodxsAAAAJ": "Li Jiang",
    "2z3fl5EAAAAJ": "Bojan Pepik",
    "sbsFpScAAAAJ": "Tribhuvanesh Orekondy",
    "nubwxloAAAAJ": "Rakshith Shetty",
    "wmpvU_YAAAAJ": "Hans Gellersen",
    "2gSuGBEAAAAJ": "Fabio Galasso",
    "axpNZUAAAAAJ": "Max Lapin",
    "s1IAWfgAAAAJ": "Krystian Mikolajczyk",
    "njOmQFsAAAAJ": "David J Fleet",
    "9-WU64IAAAAJ": "Michael Beigl",
    "ki6yi04AAAAJ": "Adrian Schwaninger",
    "gnR4zf8AAAAJ": "Tomas Pajdla",
    "OeuYmWUAAAAJ": "Martin Spengler",
    "lDfq31wAAAAJ": "Lars Erik Holmquist",
    "56UhAooAAAAJ": "Michael Goesele",
    "nI2oJqkAAAAJ": "Diane Larlus",
    "dcv4kpIAAAAJ": "Lajanugen Logeswaran",
    "EuBrsZQAAAAJ": "Michaela Regneri",
    "MYvSvGsAAAAJ": "Eddy Ilg",
    "KMqMQAcAAAAJ": "Margret Keuper",
    "K-g2p4cAAAAJ": "Alexander Sorkine-Hornung",
    "9uWuZkUAAAAJ": "Niket Tandon",
    "ELOVd8sAAAAJ": "Slobodan Ilic",
    "kzoVUPYAAAAJ": "Nassir Navab",
    "1FIyc9kAAAAJ": "Paul Lukowicz",
    "Dn_qYK8AAAAJ": "Tony Jebara",
    "qr8Vo9IAAAAJ": "Thad Starner",
    "R_dIcVwAAAAJ": "Petteri Alahuhta",
    "LGx06n8AAAAJ": "Anton Milan",
    "VJlCMGYAAAAJ": "Nuria Oliver, PhD",
    "D4Z3yrwAAAAJ": "Ahmed Elhayek",
    "B4J3SkcAAAAJ": "Evgeny Levinkov",
    "JO59nyUAAAAJ": "Graham Finlayson",
    "SnQjip0AAAAJ": "Eugen Berlin",
    "rk587vcAAAAJ": "György Szarvas (Gyuri)",
    "BZfj2c8AAAAJ": "Jordi Vitrià",
    "TmbrLRMAAAAJ": "Oskar von Stryk",
    "h5KkpakAAAAJ": "Stefan Kohlbrecher",
    "7TWQgcgAAAAJ": "Johannes Meyer",
    "rIdxtXsAAAAJ": "Friedemann Mattern",
    "xE_pSDAAAAAJ": "Zeeshan Zia",
    "FKUc3vsAAAAJ": "Ivan Titov",
    "TP-_rb0AAAAJ": "Naveen Shankar Nagaraja",
    "y6wdLA8AAAAJ": "Gerd Kortuem",
    "t3A39e8AAAAJ": "Iryna Gurevych",
    "4QvYJ00AAAAJ": "Vittorio Ferrari",
    "wQU1dJAAAAAJ": "Dariu M. Gavrila",
    "a0za4V8AAAAJ": "James Little",
    "gFwEytkAAAAJ": "David Meger",
    "QiQAv48AAAAJ": "Roland Perko",
    "uHwTzpYAAAAJ": "Alexander Waibel",
    "gLdI4FcAAAAJ": "Geert-Jan Kruijff",
    "qpD0AVMAAAAJ": "Xiaowei Sherry Yan",
    "GXJqtYUAAAAJ": "Armando Fox",
    "Z9Pfp6UAAAAJ": "Munmun De Choudhury",
    "NnEMWJsAAAAJ": "Mike Y. Chen - 陳彥仰",
    "8IjN_vgAAAAJ": "Alexandra Olteanu",
    "jaITaUcAAAAJ": "Benjamin Livshits",
    "CXgQufgAAAAJ": "Amit Sharma",
    "BbzYzsgAAAAJ": "Eric Brewer",
    "Yd-SGH8AAAAJ": "George Candea",
    "koPRb8UAAAAJ": "Scott Counts",
    "ZnVZ9xYAAAAJ": "James Cutler",
    "212SLn0AAAAJ": "Fernando Diaz",
    "8gWTOBAAAAAJ": "Robert Osazuwa Ness",
    "D4NJsXEIh1cJ": "Carlos Castillo",
    "-YmsnYMAAAAJ": "David A. Maltz",
    "BkGE4AsAAAAJ": "danah boyd",
    "WDSU0ucAAAAJ": "Andrés Monroy-Hernández",
    "sNeVyqoAAAAJ": "Lakshminarayanan Subramanian",
    "qhu-DxwAAAAJ": "Helen J. Wang",
    "ZiFn598AAAAJ": "Robert West",
    "AIncPrIAAAAJ": "Paul N. Bennett",
    "7jNkTbYAAAAJ": "Mark Dredze",
    "1n5ZdOAAAAAJ": "Glen Coppersmith",
    "tipePDkAAAAJ": "Koustuv Saha",
    "GiCqMFkAAAAJ": "Ming-Wei Chang",
    "qj3IRU8AAAAJ": "Bhaskaran Raman",
    "cYReSuEAAAAJ": "Ben Y. Zhao",
    "U69fiZMAAAAJ": "Ryen W. White",
    "t8YAefAAAAAJ": "Onur Varol",
    "hNsmH54AAAAJ": "John Torous",
    "aXGTpLgAAAAJ": "David Rothschild",
    "eYg0_cEAAAAJ": "Jake Hofman",
    "i2OF1rkAAAAJ": "Chad Verbowski",
    "5qSIhVkAAAAJ": "Shan Lu",
    "6ENuGyoAAAAJ": "Madanlal Musuvathi",
    "KGMaP18AAAAJ": "Chenhao Tan",
    "QgOASJwAAAAJ": "Arnaud Chiolero",
    "kdbzgK4AAAAJ": "Kristina Gligorić",
    "QWTkjB8AAAAJ": "Besmira Nushi",
    "9aA5QTUAAAAJ": "Kori Inkpen",
    "S63gb38AAAAJ": "Andi Peng",
    "_4_X3OgAAAAJ": "Stephen Guo",
    "ieDx3WwAAAAJ": "Lucas Joppa",
    "Hq28JM0AAAAJ": "Tanya Berger-Wolf",
    "Hq5VU2EAAAAJ": "Jason Holmberg",
    "Ba_Ci9UAAAAJ": "Z. Morley Mao (茅斫青)",
    "_ryE-48AAAAJ": "Xiaoxin Yin",
    "HXCMYLsAAAAJ": "andrey rzhetsky",
    "PLcCBl4AAAAJ": "Sanket Sharma",
    "ycTTxNUAAAAJ": "Moises Goldszmidt",
    "bHM8zJkAAAAJ": "Steve Zhang",
    "OsGAl50AAAAJ": "Joshua W. Elliott",
    "dilO2p4AAAAJ": "Jeffrey Shaman",
    "PH5VIGIAAAAJ": "Mary Baker",
    "IOrQrZcAAAAJ": "Edward Swierk",
    "LCNVGpcAAAAJ": "George Danezis",
    "9LJgRFAAAAAJ": "Richard Mortier",
    "ggAIHowAAAAJ": "Huizhong Duan",
    "Ysd-WJgAAAAJ": "Sreenivas Gollapudi",
    "bu1SCOuD_CMC": "Bimal Viswanath",
    "7Z0Z6VsAAAAJ": "Stefan Saroiu",
    "45Jrl1YAAAAJ": "Dongheui Lee",
    "md3U-GEAAAAJ": "Brian Yang",
    "YBttbLMAAAAJ": "Charles Sun",
    "ZzURcb4AAAAJ": "Albert Yu",
    "rK5YVA8AAAAJ": "Alejandro Agostini",
    "ITJGDKQAAAAJ": "Shile Li",
    "pha24HQAAAAJ": "Abhishek Gupta",
    "POXzrBYAAAAJ": "Bill sun",
    "GExyiRkAAAAJ": "Stephen Boyd",
    "XYy_Nm4AAAAJ": "Alan S. Willsky",
    "GkpvilQAAAAJ": "jose principe",
    "ffdt7gMAAAAJ": "Alexander Ihler",
    "nq7tuDkAAAAJ": "Mujdat Cetin",
    "DwXLsT8AAAAJ": "William M. Wells III (Sandy)",
    "49_cCT8AAAAJ": "Julian Straub",
    "fxzlm6IAAAAJ": "Oren Freifeld",
    "mtB5szIAAAAJ": "Randolph L. (Randy) Moses",
    "v_t_fq8AAAAJ": "Jason Chang",
    "zZ0-4SUAAAAJ": "Eric Grimson",
    "aQeTAr4AAAAJ": "Guy Rosman",
    "xOFOVGMAAAAJ": "Kilian M. Pohl",
    "n01L0mEAAAAJ": "Ron Kikinis",
    "psiQDeAAAAAJ": "Jason L. Williams",
    "GdQtWNQAAAAJ": "Junmo Kim",
    "GMzzRRUAAAAJ": "Dahua Lin",
    "JlrEuLkAAAAJ": "Tonio Buonassisi",
    "bUGiGKcAAAAJ": "Martha E. Shenton",
    "910z20QAAAAJ": "Daniela Rus",
    "CZiW6c8AAAAJ": "Anthony Yezzi",
    "WPe7vWwAAAAJ": "John Leonard",
    "hMZMhLoAAAAJ": "Kush R. Varshney",
    "AN6lmmcAAAAJ": "ZEKUN REN",
    "M1fMGOMAAAAJ": "Søren Hauberg",
    "xF2mhDoAAAAJ": "Donglai Wei",
    "71ZEsnEAAAAJ": "Jason L. Pacheco",
    "abx4xHAAAAAJ": "Randi Cabezas",
    "wd6xr6sAAAAJ": "Sue Zheng",
    "XEx1fZkAAAAJ": "Qiang Liu",
    "0pLOTKcAAAAJ": "Armi Tiihonen",
    "EOyZV8YAAAAJ": "James J Levitt",
    "MOitEvkAAAAJ": "Cynthia Wible",
    "xaUJEWAAAAAJ": "Kedar Hippalgaonkar",
    "BOL2qeUAAAAJ": "Felipe Oviedo",
    "BSrwwfYAAAAJ": "Jeremy Kepner",
    "0HNGHckAAAAJ": "Emre Ertin",
    "0T7HVEIAAAAJ": "Andy Tsai",
    "67QZN0gAAAAJ": "Dan Feldman",
    "7ERaCzgAAAAJ": "Lilla Zollei",
    "8jydpnYAAAAJ": "VALLAT laurent",
    "dJoAVvAAAAAJ": "Vincent YF Tan",
    "yehGhR8AAAAJ": "Lee C Potter",
    "3Ee8qHEAAAAJ": "Hsiao-Chun Wu",
    "pzQgnrkAAAAJ": "Oral Buyukozturk",
    "LqBEONAAAAAJ": "Justin G. Chen",
    "zTBFoCoAAAAJ": "John Gribben",
    "XSUvsTMAAAAJ": "Clare Tempany",
    "UQGZX48AAAAJ": "Kinh Tieu",
    "O-DazBUAAAAJ": "Sujay Sanghavi",
    "JeXmlI0AAAAJ": "Jeremy De Bonet",
    "bysr1zQAAAAJ": "Dmitry Malioutov",
    "ePiPQ2cAAAAJ": "Erik B. Sudderth",
    "bGXte_4AAAAJ": "Munchurl Kim",
    "e5fFIDkAAAAJ": "Shijing Sun",
    "EysbmrUAAAAJ": "David S. Hayden",
    "yLQF4mkAAAAJ": "Charless Fowlkes",
    "RKjEFukAAAAJ": "Amir Zamir",
    "Bl9FSL0AAAAJ": "Greg Mori",
    "jktWnL8AAAAJ": "Jon Barron",
    "X08l_4IAAAAJ": "Dinesh Manocha",
    "S2vB4tAAAAAJ": "Sachin Chitta",
    "eZqFrSsAAAAJ": "Chonhyon Park",
    "ZgLOSX8AAAAJ": "Christian Lauterbach",
    "e65kJ08AAAAJ": "Alan Jeffares",
    "Bq1dFNQAAAAJ": "Jeroen Berrevoets",
    "kSvJTg4AAAAJ": "Changhee Lee",
    "71rMURwAAAAJ": "Tobias Hatt",
    "Y_Nmd2sAAAAJ": "Jonathan Crabbé",
    "yfy_BGIAAAAJ": "Alex J. Chan",
    "ynIWXnUAAAAJ": "Javier González",
    "LW8ze_UAAAAJ": "Richard Zhang",
    "0ytii2EAAAAJ": "martial hebert",
    "0B8uuBkAAAAJ": "Oliver Wang",
    "bqL73OkAAAAJ": "Abhinav Gupta",
    "8cxDHS4AAAAJ": "Antonio Torralba",
    "8Sfj7q8AAAAJ": "Derek Hoiem",
    "3RuMCpcAAAAJ": "Bryan Russell",
    "9hX-JksAAAAJ": "Andrew Owens",
    "ypBMJMgAAAAJ": "Aleksander Holynski",
    "hW9fwNYAAAAJ": "Jean-François Lalonde",
    "0MiPsosAAAAJ": "Mathieu Aubry",
    "UZ5wscMAAAAJ": "Andrew Zisserman",
    "RCTeTV0AAAAJ": "Tomasz Malisiewicz",
    "SBTxvCoAAAAJ": "Carl Doersch",
    "MhYrLJAAAAAJ": "Srinivasa Narasimhan",
    "a7drwRMAAAAJ": "Yu Sun",
    "71L4yYMAAAAJ": "Yossi Gandelsman",
    "bQNISbAAAAAJ": "Shiry Ginosar",
    "q0MzO6cAAAAJ": "Ravi Ramamoorthi",
    "ajXAb54AAAAJ": "Ting-Chun Wang",
    "14HASnUAAAAJ": "Tongzhou Wang",
    "jN2Y51YAAAAJ": "Jingwan Lu",
    "-DYvinwAAAAJ": "Santosh Kumar Divvala",
    "0TpaABgAAAAJ": "Sheng-Yu Wang",
    "4GTpCxcAAAAJ": "Yong Jae Lee",
    "FLcpd34AAAAJ": "David Fouhey",
    "L7fTK1MAAAAJ": "Saurabh Singh",
    "yxh9tfEAAAAJ": "George Cazenavette",
    "2k18_1IAAAAJ": "Minyoung Huh",
    "1KFFbEIAAAAJ": "Xiaofeng Ren",
    "nKSXus4AAAAJ": "Xi Shen",
    "uqWkLzMAAAAJ": "Stella X. Yu",
    "JcZUd5IAAAAJ": "Daniel Maturana",
    "mIF9BowAAAAJ": "Abhinav Shrivastava",
    "-9ifK0cAAAAJ": "Ivan Laptev",
    "odEM5hMAAAAJ": "Vincent Delaitre",
    "_j4M4KEAAAAJ": "Dave Epstein",
    "tZprM8IAAAAJ": "Andrew Liu",
    "uQg2t8EAAAAJ": "Hongwen Kang",
    "b_RBE3EAAAAJ": "Bill Peebles",
    "L__n1LUAAAAJ": "Amir Bar",
    "pmVPj94AAAAJ": "Lerrel Pinto",
    "l0Bj7U8AAAAJ": "Matthew Tancik",
    "exClNSsAAAAJ": "Caroline Chan",
    "dUWUGcEAAAAJ": "Tete Xiao",
    "3Rlc8EAAAAAJ": "Amos Storkey",
    "Amky96kAAAAJ": "Yuri Burda",
    "0o470HsAAAAJ": "Harrison Edwards",
    "-mEAM68AAAAJ": "Angela S. Lin",
    "3TMipekAAAAJ": "Krishna Kumar Singh",
    "f_fKey0AAAAJ": "Wei-Lun Sun",
    "KdX5MN4AAAAJ": "adrien bousseau",
    "j4pcHV4AAAAJ": "Sifei Liu",
    "75x4pdcAAAAJ": "Aditya Khosla",
    "i5FMLA4AAAAJ": "Ben Poole",
    "se9kni0AAAAJ": "Marius Leordeanu",
    "OWDai70AAAAJ": "Ayaan Haque",
    "pamL_rIAAAAJ": "Qixing Huang",
    "YZ8Y-sUAAAAJ": "Amil Dravid",
    "ZfV1DqMAAAAJ": "Tom Monnier",
    "YPzKczYAAAAJ": "Maneesh Agrawala",
    "5JlEyTAAAAAJ": "Leonidas Guibas",
    "6rjdDasAAAAJ": "Johanna Delanoy",
    "R6jgG94AAAAJ": "Michaël Gharbi",
    "PUSWc4EAAAAJ": "Matthew Fisher",
    "hepwvtAAAAAJ": "Scott Satkin",
    "YHmzvmMAAAAJ": "Antonio Criminisi",
    "GYksTEEAAAAJ": "John Winn",
    "N_YNMIMAAAAJ": "Carsten Rother",
    "LGo5J4IAAAAJ": "George Drettakis",
    "QGdSgfoAAAAJ": "Utkarsh Ojha",
    "nrsWSt4AAAAJ": "Yijun Li",
    "bOitqMUAAAAJ": "Alexander C. Li",
    "1bYESBYAAAAJ": "Sumith Kulal",
    "Q5KT-hEAAAAJ": "Volkan Isler",
    "qYcG-q0AAAAJ": "yanxi liu 劉燕西",
    "Yd4KvooAAAAJ": "Yaser Sheikh",
    "7aabHgsAAAAJ": "Tomas Simon",
    "ndRmNK8AAAAJ": "Assaf Shocher",
    "zw1TzeEAAAAJ": "Ethan Weber",
    "8TwcVQcAAAAJ": "Evangelos Kalogerakis",
    "8wGH7wsAAAAJ": "Nicklas Hansen",
    "kPxa2w0AAAAJ": "Philip Torr",
    "WsM7ybkAAAAJ": "Puneet K. Dokania",
    "fcThykUAAAAJ": "Arnab Ghosh",
    "Eta6Y-kAAAAJ": "Weicheng Kuo",
    "0TGDhHsAAAAJ": "Nima Kalantari",
    "e7abmgkAAAAJ": "Timo Aila",
    "-_EKVQ0AAAAJ": "Miika Aittala",
    "Vpr6s3sAAAAJ": "Jaakko Lehtinen",
    "t2GAVZkAAAAJ": "Janne Hellsten",
    "3vKjkoQAAAAJ": "Alex Aiken",
    "AFD2rD4AAAAJ": "Vongani H. Maluleke",
    "yJfoD0kAAAAJ": "François Darmon",
    "e5lxgjIAAAAJ": "Julien Philip",
    "UKpinl8AAAAJ": "Ilija Radosavovic",
    "ZeG4wDgAAAAJ": "Kayvon Fatahalian",
    "8bQRH5YAAAAJ": "David Crandall",
    "8j3t5HsAAAAJ": "Stefan Lee",
    "hRV0tY4AAAAJ": "Minh Hoai Nguyen",
    "YB8_6gkAAAAJ": "Fernando De la Torre",
    "NINFXC0AAAAJ": "Connelly Barnes",
    "eqgEprEAAAAJ": "Neerja Thakkar",
    "pImSVwoAAAAJ": "Justin Solomon",
    "Dq0Fom8AAAAJ": "Dmitriy Smirnov",
    "KWD-mmoAAAAJ": "Medhini Narasimhan",
    "i2oLdaYAAAAJ": "Zhangxing Bian",
    "Db4BCX8AAAAJ": "Noah Snavely",
    "JY-WzksAAAAJ": "Aseem Agarwala",
    "Bt4uDWMAAAAJ": "Jue Wang",
    "31eXgMYAAAAJ": "Zihang Lai",
    "5B5rQPkAAAAJ": "Kenneth Vanhoey",
    "Qw72w48AAAAJ": "Fumio Okura",
    "Hp5uEnUAAAAJ": "Ellis Brown",
    "ttBdcmsAAAAJ": "Michael Rubinstein",
    "ifCcZ5IAAAAJ": "Inbar Mosseri",
    "bI7KhScAAAAJ": "Erik Reinhard",
    "kRJkDakAAAAJ": "Armand Joulin",
    "nfXdXswAAAAJ": "Xueting Li",
    "7ja8HqUAAAAJ": "Diego Gutierrez",
    "f7upZyAAAAAJ": "Jose Ribelles",
    "VZIAzPcAAAAJ": "Paul E. Rybski",
    "8jAftjUAAAAJ": "Guillaume Obozinski",
    "vCHNxFcAAAAJ": "John Miller",
    "mapNJjcAAAAJ": "Qiang Zhang",
    "wnK9jX8AAAAJ": "Rachel Brown",
    "GwKF9rMAAAAJ": "Jimei Yang",
    "6yL0xw8AAAAJ": "Yaodong Yang",
    "wIE1tY4AAAAJ": "Jun Wang",
    "YF0Hy1sAAAAJ": "Linghui Meng",
    "vN2ALVYAAAAJ": "Michał Grudzień",
    "n0Tc-dkAAAAJ": "Marina Sirota",
    "5Yjb93IAAAAJ": "Rong Chen",
    "xn4tmfQAAAAJ": "Isaac Kohane",
    "206DEM0AAAAJ": "Joel Dudley",
    "bqx3MAoAAAAJ": "Alexander A Morgan",
    "kFduPiIAAAAJ": "Purvesh Khatri",
    "3TQ5YmMAAAAJ": "Sanchita Bhattacharya",
    "4cxOltkAAAAJ": "Minnie Sarwal",
    "-hr7rD8AAAAJ": "Dvir Aran",
    "MoYaxfYAAAAJ": "Zicheng Hu",
    "cAwC5EQAAAAJ": "Keiichi Kodama",
    "Ecjx73cAAAAJ": "Chirag J Patel",
    "K7MBJlwAAAAJ": "Bin Chen",
    "GljRwkUAAAAJ": "Mark M. Davis",
    "GbBRH4EAAAAJ": "Jeff Wiser",
    "ErkEIHkAAAAJ": "Brenda Miao",
    "RAx8zckAAAAJ": "C. Ronald Kahn",
    "OYc22IoAAAAJ": "Shai S. Shen-Orr",
    "2D06YJAAAAAJ": "Madhumita Sushil",
    "BIHeNNUAAAAJ": "Benjamin Glicksberg",
    "YZYne64AAAAJ": "Michael Snyder",
    "TlFEW10AAAAJ": "Tara Sigdel",
    "Zb0am48AAAAJ": "Euan A. Ashley",
    "EOzumJIAAAAJ": "Carlos D. Bustamante",
    "K3ad1CgAAAAJ": "Hyojung Paik",
    "R41MlbcAAAAJ": "Maarten Naesens",
    "NlA6rBMAAAAJ": "Adam R. Abate",
    "34FcX8gAAAAJ": "Mallar Bhattacharya",
    "sua5tGwAAAAJ": "Sandra Andorf",
    "dj4EiqsAAAAJ": "Julien Sage",
    "wJRAoOsAAAAJ": "Mary Elizabeth Patti",
    "WYE8rtcAAAAJ": "David Ruau",
    "staYplUAAAAJ": "David Furman",
    "YT1DQB8AAAAJ": "Pawel K. Mazur",
    "D2boLjwAAAAJ": "Paul Wolters",
    "9R-3nvsAAAAJ": "Leqian Liu",
    "s6XjtCMAAAAJ": "Russ B Altman",
    "w4Pqoc0AAAAJ": "Rohit Vashisht",
    "q-KRzawAAAAJ": "Gad Getz",
    "ZpG_cJwAAAAJ": "Robert Tibshirani",
    "1OSj0wkAAAAJ": "David Miklos",
    "-rCpBEsAAAAJ": "Persis Wadia",
    "2o8ORCAAAAAJ": "Dexter Hadley",
    "Lr2lbdQAAAAJ": "Lawrence Mandarino",
    "JiiMY_wAAAAJ": "John PA Ioannidis",
    "fuAzo2IAAAAJ": "Konrad Karczewski",
    "FjqLOGsAAAAJ": "Douglas Arneson",
    "E2-uIQYAAAAJ": "Eric Topol",
    "ffwGwU8AAAAJ": "Silke Roedder",
    "9N0LSLsAAAAJ": "Vaka Dedeepya",
    "4B-OkFkAAAAJ": "Jacob J. Hughey",
    "uXoaU1wAAAAJ": "Ralph DeFronzo",
    "1-OBVMMAAAAJ": "Peter J Park",
    "4vJ6wLMAAAAJ": "Erik Corona",
    "EpA-_qgAAAAJ": "Yu-Hua Tseng",
    "eqkBt6EAAAAJ": "Michael Januszyk",
    "kOWrypIAAAAJ": "Nophar Geifman",
    "odYttFAAAAAJ": "E. Alejandro Sweet-Cordero",
    "cC3ZcD8AAAAJ": "Gary E Swan",
    "F63BY8kAAAAJ": "Kelly Zalocusky",
    "RFcbxjoAAAAJ": "Kevin B. Johnson, MD, MS, FAAP, FACMI,FAIMBE",
    "5odGE0wAAAAJ": "Ravi D Shankar",
    "xYL6KC0AAAAJ": "Yannick Pouliot",
    "zY_J9IQAAAAJ": "Geoffrey C. Gurtner",
    "n63DmP8AAAAJ": "Nigam Shah",
    "s18-KHUAAAAJ": "Eric Schadt",
    "rM7Dm0wAAAAJ": "Austin Hsu",
    "Wmr3UIMAAAAJ": "Brian A. Kidd",
    "dS3e-CgAAAAJ": "Michael J Quon",
    "RJ77s-cAAAAJ": "Simeon I. Taylor",
    "AIk5YHsAAAAJ": "Alvin Kho",
    "rpavyzsAAAAJ": "Xuefeng Bruce Ling, Ph.D.",
    "AOGTQn0AAAAJ": "Qiaojun Wen",
    "lWpXUrMAAAAJ": "Reetesh Pai",
    "u9DNHAoAAAAJ": "Nadine Jahchan",
    "6U_O28IAAAAJ": "allison goldfine",
    "ATnKn1UAAAAJ": "Sangeeta Kashyap",
    "lLqTCtUAAAAJ": "PABLO TAMAYO",
    "nrSsSrkAAAAJ": "Dmytro S Lituiev",
    "lJAkLo8AAAAJ": "Zhiyong Lu",
    "SNQERVoAAAAJ": "Michael James Clark",
    "u1TctA0AAAAJ": "Rui Chen",
    "zff-8GkAAAAJ": "Martin Angst",
    "cA4CXXoAAAAJ": "Hua Fan-Minogue",
    "TljlLdIAAAAJ": "wei wei",
    "MdORQMcAAAAJ": "Anne Brunet",
    "IxeW3gwAAAAJ": "Dervis Salih",
    "iBOqTdYAAAAJ": "nicolas reynoird",
    "3yCig6AAAAAJ": "Teri E. Klein",
    "b2EEZfAAAAAJ": "Michael Fischbein",
    "JhIiSHQAAAAJ": "Yves A. Lussier, B. Engineer., MD, Fellow ACMI",
    "oWGEj78AAAAJ": "S Joshua Swamidass",
    "v84zUXYAAAAJ": "C Garrison Fathman",
    "lZPXUgoAAAAJ": "Ron Chen",
    "4eloUCwAAAAJ": "Silve Vicent Cambra",
    "_tDXYaYAAAAJ": "Raymond K. Auerbach",
    "OR5Lx4MAAAAJ": "Kitchener D. Wilson, MD, PhD",
    "VgI1d98AAAAJ": "Matthew J. Kan, MD, PhD",
    "I8UXifUAAAAJ": "Jessica D Tenenbaum",
    "YvjuUugAAAAJ": "Mark Gerstein",
    "ejoWKqsAAAAJ": "Nicholas P Tatonetti",
    "0JA37SgAAAAJ": "Natasha Flores",
    "POWKkqEAAAAJ": "Serafim Batzoglou",
    "CjymsJAAAAAJ": "martin sikora",
    "i3pEsbgAAAAJ": "Donna Slonim",
    "ygM8WtMAAAAJ": "Todd Golub",
    "xo7GHUoAAAAJ": "Jenna Bollyky, MD",
    "NxBuRgcAAAAJ": "Andrea Califano",
    "KnAit3cAAAAJ": "Trey Ideker",
    "eMzW3TwAAAAJ": "Stephen H Friend",
    "bcojPRoAAAAJ": "Camille Guillerey",
    "U0ZjG84AAAAJ": "Nicholas Denko",
    "btk7o4MAAAAJ": "Ioanna Tzoulaki",
    "gdgJQ-wAAAAJ": "Paul Elliott",
    "rSMPsx4AAAAJ": "Li Li",
    "0_1rZqgAAAAJ": "Marc A. Schaub",
    "FmMT4CcAAAAJ": "Mark Musen",
    "G5zYeD8AAAAJ": "Sudhir Kumar",
    "L0BNwUIAAAAJ": "David Rowitch",
    "4QnYN1sAAAAJ": "Alvis Brazma",
    "pg4JhX0AAAAJ": "Clement Jonquet",
    "PjCDBjIAAAAJ": "Olga Troyanskaya",
    "6QrCoOoAAAAJ": "John Quackenbush",
    "58cKLg4AAAAJ": "Lawrence Hunter",
    "shmr0CQAAAAJ": "Marc A. Coram",
    "zuByMYoAAAAJ": "Cecily J. Wolfe",
    "agywNwUAAAAJ": "Silpa Suthram",
    "1a-_ns8AAAAJ": "Scott L. Pomeroy",
    "9r6119kAAAAJ": "Adam Grossman",
    "yUkK-mgAAAAJ": "Scott Sutherland",
    "_6XYKXMpK34C": "Olivier Gevaert",
    "e4_ZXcwAAAAJ": "Greg Gibson",
    "xpe7bloAAAAJ": "Winston Patrick Kuo, DDS, SM, DMSc",
    "fqkakg8AAAAJ": "Alan H. Beggs, PhD",
    "asu1aZMAAAAJ": "Peter Tarczy-Hornoch",
    "RjJyha8AAAAJ": "Daniel Nigrin",
    "vk37k80AAAAJ": "Morris F White",
    "9GHrCy4AAAAJ": "Zhumur Ghosh",
    "fyf_Vt4AAAAJ": "Kelly Ormond",
    "-gEuUZIAAAAJ": "Joseph C. Wu",
    "2wH43aAAAAAJ": "Jay Bhattacharya",
    "KxUFJmoAAAAJ": "Despina Sanoudou",
    "0O9BbqoAAAAJ": "Geoffrey Manley",
    "vFPjMzYAAAAJ": "Antonei Benjamin Csoka",
    "K_PU9tQAAAAJ": "Lukas Habegger",
    "ZZsEXLAAAAAJ": "Hongkai Dai",
    "-VjsrR4AAAAJ": "Robin Deits",
    "tKSxEgQAAAAJ": "Scott Kuindersma",
    "DCSFMuAAAAAJ": "Michael Posa",
    "VEPTSCUAAAAJ": "Ian R. Manchester",
    "0pxg5ssAAAAJ": "Lucas Manuelli",
    "8yg53VQAAAAJ": "Alec Shkolnik",
    "0k4k1WUAAAAJ": "Twan Koolen",
    "5DfprgMAAAAJ": "Andy Ruina",
    "ddu5MKwAAAAJ": "Martijn Wisse",
    "xX_de_YAAAAJ": "Andrés Valenzuela",
    "jfOVNcUAAAAJ": "Tobia Marcucci",
    "WlA92lcAAAAJ": "Yunzhu Li",
    "qX2I6KIAAAAJ": "Pat Marion",
    "BD8llAEAAAAJ": "H Sebastian Seung",
    "auB_CDsAAAAJ": "Katie Byl",
    "BqV8LaoAAAAJ": "Maurice Fallon",
    "B6iZVE0AAAAJ": "HJ Terry Suh",
    "BNNNS-wAAAAJ": "Tao Pang",
    "IcasIiwAAAAJ": "Leslie Kaelbling",
    "Z4Y5S2oAAAAJ": "Robert Platt",
    "Hi7ZdhQAAAAJ": "Kaiqing Zhang",
    "BQ_S4vMAAAAJ": "Frank Permenter",
    "gQOKAggAAAAJ": "Tomas Lozano-Perez",
    "LCzQ6GMAAAAJ": "Wei Gao",
    "eF5vfBAAAAAJ": "Steve Collins",
    "gn3rZ7sAAAAJ": "Fumiya Iida",
    "BGxhOlEAAAAJ": "Andrew J. Barry",
    "BFfjA-8AAAAJ": "Gregory Izatt",
    "LC_8eS4AAAAJ": "Joseph L. Moore",
    "eYY2nMYAAAAJ": "Alexandre Amice",
    "AEKT17QAAAAJ": "Thomas Kollar",
    "aM3i_9oAAAAJ": "Nicholas Roy",
    "EMrV8BIAAAAJ": "Matthew O'Kelly",
    "ZCa4VDcAAAAJ": "Aman Sinha",
    "GvHOmQoAAAAJ": "Benoit Landry",
    "NfeARS4AAAAJ": "Jerry Pratt",
    "M5HFiMIAAAAJ": "Peter Werner",
    "GZt32DEAAAAJ": "Vincent Tjeng",
    "xblGvQgAAAAJ": "Kai Yuanqing Xiao",
    "QGU5FrIAAAAJ": "Alex Alspach",
    "xXQtID8AAAAJ": "Jack Umenberger",
    "iAHjMzQAAAAJ": "Ram Vasudevan",
    "I6sTssIAAAAJ": "Seth Teller",
    "dyXX1EgAAAAJ": "Hongseok Namkoong",
    "q0kUpsoAAAAJ": "Claudia Pérez D'Arpino",
    "C_r8d0AAAAAJ": "Elena L. Glassman",
    "3AJYxmsAAAAJ": "Sisir Karumanchi",
    "3VyGrdwAAAAJ": "Karl Iagnemma",
    "pTcB5WUAAAAJ": "Dehann Fourie",
    "V3rP49wAAAAJ": "Toby Schneider",
    "cgBDhqwAAAAJ": "Andrew Marchese",
    "xlVG6IUAAAAJ": "Ming-fai Fong",
    "Vu-Zb7EAAAAJ": "Sertac Karaman",
    "9I4xFcIAAAAJ": "Jun Zhang, 張駿",
    "zSSrBp4AAAAJ": "Pierre-Brice Wieber",
    "a5RZKIkAAAAJ": "Peter KT Yu",
    "AC93g9kAAAAJ": "Alberto Rodriguez",
    "fE3FSqIAAAAJ": "Nima Fazeli",
    "gYXvxhQAAAAJ": "Davide Falanga",
    "SC9wV2kAAAAJ": "Davide Scaramuzza",
    "DfrisKkAAAAJ": "Philipp Foehn",
    "xaFg_NUAAAAJ": "Albert Wu",
    "qIg8KFYAAAAJ": "Mark Cutkosky",
    "MrI1EV4AAAAJ": "John McDonald",
    "ImjOWWEAAAAJ": "Thomas Whelan",
    "ZPmHxbsAAAAJ": "Geronimo Mirano",
    "ea6cjVUAAAAJ": "John Laird",
    "R5q_E8wAAAAJ": "Samuel Prentice",
    "GU-vJ5AAAAAJ": "Marco Gabiccini",
    "Bmuft6wAAAAJ": "Antonio Bicchi",
    "FqKcLDQAAAAJ": "Cynthia Sung",
    "8JeQMMUAAAAJ": "Andrew Spielberg",
    "WJlBOwQAAAAJ": "Dominik Honegger",
    "aeJGZxIAAAAJ": "Helen Oleynikova",
    "YYH0BjEAAAAJ": "Marc Pollefeys",
    "ZO8UTIUAAAAJ": "Alexandre Megretski",
    "UXh1I6UAAAAJ": "Zico Kolter",
    "LNHbZR0AAAAJ": "Alexis Lussier desbiens",
    "YI1EqBoAAAAJ": "Wilko Schwarting",
    "kwe0VEwAAAAJ": "Felix Naser",
    "H9xADK0AAAAJ": "Liam Paull",
    "-kIVAcAAAAAJ": "Jan Peters",
    "oy7TshoAAAAJ": "Andrew Biewener",
    "fU63KdQAAAAJ": "Huai-Ti Lin",
    "Bj50SwkAAAAJ": "Charles Wampler",
    "VZi7NssAAAAJ": "Thrishantha Nanayakkara",
    "FiXHXwgAAAAJ": "Philipp Reist",
    "CmoKVuUAAAAJ": "Amir Ali Ahmadi",
    "qyMRxowAAAAJ": "Saverio E. Spagnolie",
    "MIwNbDcAAAAJ": "Zhanpeng He",
    "jTnQTBoAAAAJ": "Joseph J. Lim",
    "eDQsOFMAAAAJ": "Deirdre Quillen",
    "iWmtv7gAAAAJ": "Eric Heiden",
    "IjVj4hsAAAAJ": "KR Zentner",
    "6MUY5mgAAAAJ": "Ujjwal Puri",
    "Eed2gcMAAAAJ": "Yulun Zhang",
    "7kaXqgMAAAAJ": "Denis Yarats",
    "US56Kw8AAAAJ": "Tobias Weyand",
    "LoT0z6oAAAAJ": "Scott Emmons",
    "cagVT0AAAAAJ": "Denis Zorin",
    "yk6C1SgAAAAJ": "Vitaly Kurin",
    "462OoekAAAAJ": "Roberta Raileanu",
    "xGORWi0AAAAJ": "Emma Pierson",
    "9EnJFEEAAAAJ": "Shiori Sagawa",
    "Q_kKkIUAAAAJ": "Jure Leskovec",
    "dGPqP-wAAAAJ": "Zhenghao Chen",
    "T2vp1pgAAAAJ": "Anshul Kundaje",
    "5ygiTwsAAAAJ": "Tatsunori Hashimoto",
    "jU4IZs4AAAAJ": "Sewon Min",
    "gkHA4nEAAAAJ": "Kyle M. Loh",
    "KsYfSCIAAAAJ": "Antonio Chella",
    "uHFzzkkAAAAJ": "Irene Macaluso",
    "-yZse64AAAAJ": "Daniel Goehring",
    "UzjHQLcAAAAJ": "Philippe Hansen-Estruch",
    "bezWXYcAAAAJ": "Chongyi Zheng",
    "P-G3sjYAAAAJ": "Erdem Bıyık",
    "L5v2PHAAAAAJ": "Siddharth Karamcheti",
    "ZwnVwKMAAAAJ": "Minae Kwon",
    "oF46lMIAAAAJ": "Hengyuan Hu",
    "kmeUhO8AAAAJ": "Nima Anari",
    "Km5y5nIAAAAJ": "Peyton Greenside",
    "r2Gjhg4AAAAJ": "Samuel Stanton",
    "R5QNdhcAAAAJ": "Nate Gruver",
    "qGWon5kAAAAJ": "Phillip M. Maffettone",
    "05uQHIgAAAAJ": "Polina Kirichenko",
    "ysMAhlwAAAAJ": "Marc Finzi",
    "jCNJhFcAAAAJ": "Beidi Chen",
    "8JKsHJcAAAAJ": "Jang-Hyun Kim",
    "oBU9w4UAAAAJ": "Seungyong Moon",
    "ImpbxLsAAAAJ": "Silvio Savarese",
    "wSE0nWUAAAAJ": "Yeonwoo Jeong",
    "MxxZkEcAAAAJ": "Kevin Murphy",
    "cdP5JicAAAAJ": "Vivek Rathod",
    "9cZUlEYAAAAJ": "Yu Xiang",
    "BI8xFr4AAAAJ": "Ozan Sener",
    "J6iSjTcAAAAJ": "Ashutosh Saxena",
    "8PR-AaoAAAAJ": "Jaekyeom Kim",
    "G_vOcFUAAAAJ": "Stefan Zickler",
    "k1hJzF0AAAAJ": "Pedro Felzenszwalb",
    "fMEMNKMAAAAJ": "Christopher Geyer",
    "luv0xMIAAAAJ": "Alireza Fathi",
    "Svk4ntYAAAAJ": "Peng Wang",
    "KNr3vb4AAAAJ": "Jared Kaplan",
    "McBoXK0AAAAJ": "Benjamin Mann",
    "NYOJzM4AAAAJ": "Amanda Askell",
    "gHp0pu4AAAAJ": "Sam McCandlish",
    "x4JAvwMAAAAJ": "Jeffrey Wu",
    "beiWcokAAAAJ": "Jan Leike",
    "Ml_vQ8MAAAAJ": "Justin Gilmer",
    "8h3AFugAAAAJ": "Tom Henighan",
    "kxUld9MAAAAJ": "Yoshitaka Ushiku",
    "k8rlJ8AAAAAJ": "Tatsuya Harada",
    "emo91rIAAAAJ": "Yusuke Mukuta",
    "1PBvwCgAAAAJ": "Katsunori Ohnishi",
    "RHV5YCkAAAAJ": "Hiroharu Kato",
    "bEuH9QIAAAAJ": "Andrew Shin",
    "XOJE8OEAAAAJ": "Roberto Martín-Martín",
    "yay_v9EAAAAJ": "Chengshu Li",
    "K29Sv1EAAAAJ": "Jacky Liang",
    "mOMChFIAAAAJ": "William Bokui Shen",
    "xvOlfw8AAAAJ": "Noriaki Hirose",
    "PIq7jcUAAAAJ": "Alexander (Sasha) Sax",
    "zjr6n-QAAAAJ": "Martin Jinye Zhang",
    "VCpSh3gAAAAJ": "Kevin Chen",
    "sljtWIUAAAAJ": "Linxi \"Jim\" Fan",
    "Ixg9n-EAAAAJ": "Lantao Yu",
    "ogXTOZ4AAAAJ": "Stefano Ermon",
    "Rkr2uT8AAAAJ": "Saurabh Kumar",
    "6gd_QS0AAAAJ": "Jonas Schneider",
    "0oIAvO8AAAAJ": "Josh Tobin",
    "B76dD7YAAAAJ": "Peter Welinder",
    "MHQv5YUAAAAJ": "Matthias Plappert",
    "R5AmmGwAAAAJ": "Maciek Chociej",
    "dCa-pW8AAAAJ": "Lilian Weng",
    "Bmbkv6sAAAAJ": "Minh-Thang Luong",
    "EmmO7LcAAAAJ": "Matthew Blaschko",
    "OUv7J6QAAAAJ": "Arthur Gretton",
    "oBu8kMMAAAAJ": "Tomas Mikolov",
    "N3J70KkAAAAJ": "Slawomir Grzonkowski",
    "4wcx4HMAAAAJ": "Todd Gureckis",
    "vspmOX8AAAAJ": "Brenden M. Lake",
    "DwTbLh4AAAAJ": "Vinod Grover",
    "fhxshS0AAAAJ": "Alexandre Gramfort",
    "BfmcfEAAAAAJ": "M. Pawan Kumar",
    "ld-vt9QAAAAJ": "OpenAI",
    "ouSpgSkAAAAJ": "Zhongyu Li",
    "o9aFV8cAAAAJ": "Koushil Sreenath",
    "lO17d-EAAAAJ": "Yunrong Guo",
    "BVde3Y0AAAAJ": "Davis Rempe",
    "I3mSZFEAAAAJ": "Grace Zhang",
    "5P2jxPQAAAAJ": "KangKang Yin",
    "E_82W3EAAAAJ": "Erwin Coumans",
    "lHPTxGsAAAAJ": "Zhengyi \"Zen\" Luo",
    "EEp82sIAAAAJ": "Ye Yuan",
    "7eLKa3IAAAAJ": "Chen Tessler",
    "Z8vhOxYAAAAJ": "Xuxin Cheng",
    "Ihs8dwsAAAAJ": "Or Litany",
    "G-x_szsAAAAJ": "Xiaoyu Huang",
    "53OxjmYAAAAJ": "Alejandro Escontrela",
    "nj49RCAAAAAJ": "J. Chase Kew",
    "rFd-DiAAAAAJ": "Karsten Kreis",
    "yv3sH74AAAAJ": "Kris Kitani",
    "J8E8GQYAAAAJ": "Sam Toyer",
    "jEf5Q-4AAAAJ": "Lizhi Yang",
    "wtK4Yh4AAAAJ": "Hao Liu",
    "9g4PcV8AAAAJ": "Jordan Juravsky",
    "qDsqFkMAAAAJ": "Zhaoming Xie",
    "HvJj-pEAAAAJ": "Tingwu Wang",
    "lmsiq6oAAAAJ": "Zixuan Chen",
    "BO_b2O8AAAAJ": "Yanjie Ze",
    "e6zXN64AAAAJ": "Yufeng Chi",
    "IfEzwZIAAAAJ": "Hung Yu Ling",
    "LaPb8-YAAAAJ": "Tianyu Li 黎天宇",
    "fwVWk9UAAAAJ": "Daniele Reda",
    "P9ROgN8AAAAJ": "Guy Tevet",
    "P73-vsoAAAAJ": "Setareh Cohan",
    "OEivUAQAAAAJ": "Scott Delp",
    "vOur3Q4AAAAJ": "Jennifer Hicks",
    "NB4pgZYAAAAJ": "Christopher Granger Atkeson",
    "7rvNQJoAAAAJ": "Lukas Kidzinski",
    "V48OV8YAAAAJ": "Carmichael Ong",
    "Ca2lQs8AAAAJ": "Seungmoon Song",
    "8qHnRnsAAAAJ": "Kevin Zakka",
    "CjOTm_4AAAAJ": "Yuval Tassa",
    "z2F7CSEAAAAJ": "Taylor Howell",
    "q77J4fgAAAAJ": "Eric Anthony Mitchell",
    "qOFs67oAAAAJ": "Atil Iscen",
    "zlBSbUAAAAAJ": "Yiming Ni",
    "4vpQvuwAAAAJ": "Justus Thies",
    "-oy5DaIAAAAJ": "Xialin He",
    "qWfJbHMAAAAJ": "Mohamed Hassan",
    "JSj4f4sAAAAJ": "Yi Shi",
    "q1HlbIUAAAAJ": "Shie Mannor",
    "kc4-e8oAAAAJ": "Yoni Kasten",
    "rmAcDNkAAAAJ": "Viktor Makoviychuk",
    "pEFsZdYAAAAJ": "Farzad Abdolhosseini",
    "PnyV8dgAAAAJ": "Hongbo Zhang",
    "NQ-n2M0AAAAJ": "Bhuvan Basireddy",
    "WzmDQTMAAAAJ": "Yun-hui Liu",
    "kmGkycYAAAAJ": "ZHITAO SONG",
    "77zwH0MAAAAJ": "Gilbert Feng",
    "CDPa3AgAAAAJ": "Youngwoon Lee",
    "tR2Qw0YAAAAJ": "Wilson Yan",
    "VINmGpYAAAAJ": "Danijar Hafner",
    "KFnmktMAAAAJ": "Ademi Adeniji",
    "Ih7iLuUAAAAJ": "Ajay Jain",
    "LyHzJOMAAAAJ": "Yandong Ji",
    "joR1Z4UAAAAJ": "Guanya Shi",
    "ixp-vqMAAAAJ": "Shagun Sodhani",
    "oD1W8a4AAAAJ": "Jonathan Binas",
    "bKMhN4UAAAAJ": "Yunhao Li",
    "snHVatUAAAAJ": "Nimrod Gileadi",
    "8j-IC6sAAAAJ": "Philipp Wu",
    "QGpxkvkAAAAJ": "Qiayuan Liao",
    "t23kOGIAAAAJ": "Ofir Nabati",
    "2IEoTWwAAAAJ": "Ying Yuan",
    "QEqPllIAAAAJ": "Borivoje Nikolic",
    "qSQjR4EAAAAJ": "Ruofeng Wang",
    "YoSGjoUAAAAJ": "Yakun Sophia Shao",
    "YkWi5xoAAAAJ": "Ye Zhao",
    "L8ozqB8AAAAJ": "Stephen McCrory",
    "s5_69i0AAAAJ": "Quan Nguyen",
    "PvDd3k4AAAAJ": "Xianyi Cheng",
    "yd4xmlcAAAAJ": "Abderrahmane Kheddar",
    "IC9VJpsAAAAJ": "Zhaoyuan Gu",
    "km_K9awAAAAJ": "Gordon Cheng",
    "mWGyYMsAAAAJ": "Yuke Zhu",
    "41GA5O4AAAAJ": "Abdulaziz Shamsah",
    "GI5Dse8AAAAJ": "Junheng Li",
    "STnhSioAAAAJ": "Sigal Raab",
    "EPO5_f4AAAAJ": "Amit Haim Bermano",
    "QSKXFiYAAAAJ": "Umar Iqbal",
    "WUKF2ZwAAAAJ": "Mathis Petrovich",
    "ceSzF9YAAAAJ": "Gul Varol",
    "KNWTvgEAAAAJ": "Bo Dai",
    "GStTsxAAAAAJ": "Jingbo Wang",
    "_U-HwfkAAAAJ": "Yen-Jen Wang",
    "GmtZ_jYAAAAJ": "Seungeun Rho",
    "4sgEDv8AAAAJ": "Jeevan Devaranjan",
    "Zp8MeiUAAAAJ": "Haotian Zhang",
    "eRcqOkcAAAAJ": "Pengcheng Xi",
    "Ouu9Zv0AAAAJ": "Chang Shu",
    "KC6FJ14AAAAJ": "Michael Taylor",
    "TkiMCGoAAAAJ": "Zi-ang Cao",
    "Feoyh4AAAAAJ": "Yuxuan Mu",
    "wbJ0vGkAAAAJ": "Ziyu Zhang",
    "gdO9Gb0AAAAJ": "Jiashun Wang",
    "j1zLfKwAAAAJ": "Mazeyu Ji",
    "ABKq-ecAAAAJ": "Xuanbin Peng",
    "AzlUrvUAAAAJ": "Dantong Niu",
    "SvinO8kAAAAJ": "Ze Ma",
    "3tIEZhAAAAAJ": "Sumeet S. Singh",
    "ocMf7fQAAAAJ": "Hongwei Yi",
    "trMUyZIAAAAJ": "Guoquan (Paul) Huang",
    "viGDVSkAAAAJ": "Robert J Griffin",
    "gdUv1PIAAAAJ": "Tao Chen",
    "uv7g5kMAAAAJ": "Anurag Ajay",
    "GZkyN4cAAAAJ": "Zhang-Wei Hong",
    "RNDrSGYAAAAJ": "Anthony Simeonov",
    "Jzt5uNAAAAAJ": "Gabriel B. Margolis",
    "7N-ethYAAAAJ": "Brian Cheung",
    "3Tj5lWEAAAAJ": "Jie Xu",
    "ATj2IF4AAAAJ": "Rahul C. Deo MD, PhD",
    "WgG-GJkAAAAJ": "Jeffrey Zhang",
    "nSZG-vcAAAAJ": "Jack L. GALLANT",
    "oY7AJUgAAAAJ": "Dustin Stansbury",
    "gVFnjOcAAAAJ": "Tom Erez",
    "nQ7Ij30AAAAJ": "Peter Battaglia",
    "zQwXlaYAAAAJ": "Somdeb Majumdar",
    "IWcGY98AAAAJ": "Bhiksha Raj",
    "l4hK4eEAAAAJ": "Gahgene Gweon",
    "BMydCgcAAAAJ": "Carolyn Penstein Rose",
    "HSuy6TQAAAAJ": "Mark Lescroart",
    "6lD1AscAAAAJ": "amitabha mukerjee",
    "xjnef1AAAAAJ": "Nir Friedman",
    "X7bG7YYAAAAJ": "Ami Wiesel",
    "jW80JWEAAAAJ": "Elad Eban",
    "AIsTDk4AAAAJ": "Ian McGraw",
    "sc5iZ3EAAAAJ": "Ariel Jaimovich",
    "Zqqw2FQAAAAJ": "Tommy Kaplan",
    "aJOeGRoAAAAJ": "Dana Pe'er",
    "e7V7-gEAAAAJ": "Mark Horowitz",
    "oExGuP8AAAAJ": "Farshid Moussavi",
    "KMBgMs0AAAAJ": "Ofer Meshi",
    "A7AuNE8AAAAJ": "Iftach Nachman",
    "cXkm3rsAAAAJ": "Craig Boutilier",
    "6_UmGu0AAAAJ": "Israel Nelken",
    "Gc65LRwAAAAJ": "Martin Mladenov",
    "WNqbKzwAAAAJ": "Tyler Lu",
    "xXJIsh4AAAAJ": "Roi Reichart",
    "QNnjg7YAAAAJ": "Rif A. Saurous",
    "LZIPfCkAAAAJ": "Meng Jiang",
    "xByATywAAAAJ": "Xuedong D. Huang",
    "z7GCqT4AAAAJ": "Heng Ji",
    "DN8QtscAAAAJ": "Mohit Bansal",
    "Kv9AbjMAAAAJ": "Jiawei Han",
    "MlZq4XwAAAAJ": "Yiming Yang",
    "icbo4M0AAAAJ": "Julian McAuley",
    "Q1mcglAAAAAJ": "Haixun Wang",
    "ScqM05wAAAAJ": "Yingjie Miao",
    "-kdBDxYAAAAJ": "Lei M. Zhang",
    "ipTsozQAAAAJ": "Esteban Real",
    "_8Egwg8AAAAJ": "Daiyi Peng",
    "-3zYIjQAAAAJ": "Jascha Sohl-Dickstein",
    "HEozmkMAAAAJ": "Ankesh Anand",
    "IzqMoZMAAAAJ": "Bernd Bohnet",
    "1EPxhywAAAAJ": "Peter J. Liu",
    "d3YhiooAAAAJ": "Jaehoon Lee",
    "qS_ugJAAAAAJ": "izzeddin gür",
    "q1AewNAAAAAJ": "Katie Everett",
    "BU79wO4AAAAJ": "Rishi Veerapaneni",
    "RsZBRBQAAAAJ": "Eric Chu",
    "6TOQpT4AAAAJ": "Azade Nova",
    "bXOt49QAAAAJ": "Stephanie CY Chan",
    "i27Wt-cAAAAJ": "Zaheer Abbas",
    "fzRnjFgAAAAJ": "Mitchell Wortsman",
    "6vghMS0AAAAJ": "Abhishek Kumar",
    "1O3RPmsAAAAJ": "Simon Kornblith",
    "fvwzUnIAAAAJ": "Lechao Xiao",
    "cn_FoswAAAAJ": "Jeffrey Pennington",
    "LWvgl-8AAAAJ": "Roman Novak",
    "eAwnN44AAAAJ": "John DeNero",
    "t5Xsx0IAAAAJ": "Daniel Freeman",
    "sFtxaMkAAAAJ": "Yixin Liu",
    "GnpHmO8AAAAJ": "Xingyou (Richard) Song",
    "NvMCACEAAAAJ": "Eugene Brevdo",
    "FpaKuysAAAAJ": "Juan Jose Garau-Luis",
    "AwpU32MAAAAJ": "Aaron Parisi",
    "cAYgoH4AAAAJ": "Jenny Wang",
    "Q93u3c0AAAAJ": "Ben Adlam",
    "34bu2-8AAAAJ": "Frederick Shic",
    "XXiZaA4AAAAJ": "Henny Admoni",
    "mZl2K3AAAAAJ": "Aditi Ramachandran",
    "Rp5teiwAAAAJ": "Nicole Salomons",
    "7JficF8AAAAJ": "Elizabeth S. Kim",
    "ScxqPn4AAAAJ": "Justin Hart",
    "rU_-c5oAAAAJ": "Bradley Hayes",
    "XKSNP_EAAAAJ": "Kevin Gold",
    "iZwOlgsAAAAJ": "Elena Corina Grigore",
    "nV-XGVIAAAAJ": "Alessandro Roncone",
    "o5YQMkMAAAAJ": "Maja J Matarić",
    "k3Oh9D0AAAAJ": "Daniel Ullman",
    "tyKNvM8AAAAJ": "Iolanda Leite",
    "2W82D4QAAAAJ": "Laura Boccanfuso",
    "hyEds7sAAAAJ": "Christopher Crick",
    "0kTel90AAAAJ": "Chien-Ming Huang",
    "FBeJOPgAAAAJ": "Paul Fitzpatrick",
    "QLC6sn4AAAAJ": "Alexandru Litoiu",
    "4QuRUy8AAAAJ": "Marek Doniec",
    "cHZ2U6UAAAAJ": "Wilma Alice Bainbridge",
    "uZvvcgUAAAAJ": "Samuel Spaulding",
    "9JaVNVAAAAAJ": "Katherine M Tsui",
    "J1awhoMAAAAJ": "Elaine Schaertl Short",
    "m1VxcKcAAAAJ": "David Feil-Seifer",
    "wXIOwRoAAAAJ": "Alan E. Kazdin",
    "dp5LnVAAAAAJ": "Odest Chadwicke Jenkins",
    "lPDGYhwAAAAJ": "Adriana Tapus",
    "uh7PNBoAAAAJ": "Charles C. Kemp | Charlie Kemp",
    "CQ39OowAAAAJ": "Aaron Steinfeld",
    "Alsv0h8AAAAJ": "Cindy L. Bethel",
    "niCbywQAAAAJ": "Myron Flickner",
    "rNTIQXYAAAAJ": "Steven W Zucker",
    "jbbtciwAAAAJ": "Katelyn Swift-Spong",
    "EMqQUjoAAAAJ": "Donna Spruijt-Metz",
    "pcfQnOkAAAAJ": "Jin Joo Lee, PhD",
    "0PUtrrgAAAAJ": "Philipp Michel",
    "ySEpPmYAAAAJ": "Daniel Grollman",
    "mT7ppvwAAAAJ": "Andre Martins",
    "y2bVjBIAAAAJ": "Pedro Henrique Martins",
    "Q5J3UXwAAAAJ": "Afonso Mendes",
    "7PGzs4sAAAAJ": "Sebastião Miranda",
    "Q4oVM7IAAAAJ": "Shay Cohen",
    "_nHDasEAAAAJ": "David Nogueira",
    "FAv6Nd8AAAAJ": "Ahmed Hefny",
    "prEcE9IAAAAJ": "Shashi Narayan",
    "SGjYdrEAAAAJ": "Angelos Filos",
    "6Z-RC-QAAAAJ": "Gregory Farquhar",
    "XjWnyM4AAAAJ": "Andreas Vlachos",
    "-Cy0nZ8AAAAJ": "Andrew Secker",
    "PYJlmicAAAAJ": "Ricardo Ferreira",
    "JzXA6NEAAAAJ": "Paulo J. Peixeiro Freitas",
    "0CSbRv8AAAAJ": "Susana Cardoso de Freitas",
    "feM7-mEAAAAJ": "Kate Baumli",
    "W80oBMkAAAAJ": "Hado van Hasselt",
    "odVYodIAAAAJ": "Matteo Hessel",
    "-lONjNgAAAAJ": "Gilwoo Lee",
    "D_JpQnAAAAAJ": "Matthew T. Mason",
    "GN5Mc3UAAAAJ": "Aaron M. Johnson",
    "RahgPAEAAAAJ": "Eszter Vértes",
    "sfvCNiEAAAAJ": "Abram (Abe) Friesen",
    "H-xtdV4AAAAJ": "Andre Barreto",
    "LK_CV24AAAAJ": "Diana Borsa",
    "Jq8ZS5kAAAAJ": "Simon Osindero",
    "TjdFs3EAAAAJ": "Noah A. Smith",
    "-wflT2wAAAAJ": "Carlton Downey",
    "TIKl_foAAAAJ": "Bo Dai",
    "obpl7GQAAAAJ": "Hanjun Dai",
    "cF6i_goAAAAJ": "Saman Amarasinghe",
    "cVZZ7PAAAAAJ": "Riyadh Baghdadi",
    "BGh9WU4AAAAJ": "Julian Shun",
    "bdNbTVIAAAAJ": "Yunming Zhang",
    "mSvrb54AAAAJ": "Shoaib Kamil",
    "Mu_8iOEAAAAJ": "Ekin Dogus Cubuk",
    "YdHW1ycAAAAJ": "Henryk Michalewski",
    "k4l-zNYAAAAJ": "Winnie Xu",
    "eGIw04UAAAAJ": "Lisa Lee",
    "wA5TK_0AAAAJ": "Jason Wei",
    "cbuy0ocAAAAJ": "Hongyu Ren",
    "LHvso9QAAAAJ": "Kamyar Ghasemipour",
    "0dR_wD0AAAAJ": "Jacob Charles Walker",
    "RGNVBKMAAAAJ": "Jake Bruce",
    "2O_ESc4AAAAJ": "Jack Parker-Holder",
    "oFIvUSQAAAAJ": "Tom Le Paine",
    "Lncr-VoAAAAJ": "Mohammad Norouzi",
    "wqRhBXMAAAAJ": "Michael Zhang",
    "fAWKizAAAAAJ": "Yutian Chen",
    "jMUkLqwAAAAJ": "Alexander Novikov",
    "oz4Ca9AAAAAJ": "Cosmin Paduraru",
    "uRImMPoAAAAJ": "Amil Merchant",
    "32rbUtYAAAAJ": "David Venuto",
    "Z5ZeWGMAAAAJ": "Wei Wei",
    "XaFhuG8AAAAJ": "Haoming Jiang",
    "VgNDYeYAAAAJ": "Tongzheng Ren",
    "B320e3kAAAAJ": "Siddharth Verma",
    "hnf_dHwAAAAJ": "Katayoon(Kati) Goshvadi",
    "h1NXfKYAAAAJ": "Yuejie Chi",
    "g2uX6_gAAAAJ": "Jincheng Mei",
    "QIRWZf8AAAAJ": "Shicong Cen",
    "dVZuASAAAAAJ": "Tong Yang",
    "nV-tcHAAAAAJ": "Martin Klissarov",
    "dHDJlo0AAAAJ": "Mohammad Sami Nur Islam",
    "mV7RNZAAAAAJ": "Ankit Anand",
    "Lz5YGiQAAAAJ": "Sreyas Venkataraman",
    "onzZ8qUAAAAJ": "Achint Soni",
    "7JNUMRAAAAAJ": "Muratahan Aykol",
    "364jgpgAAAAJ": "Simon Batzner",
    "IzwvqPIAAAAJ": "Alexander L Gaunt",
    "YJd3v4QAAAAJ": "Brendan McMorrow",
    "rvW4j38AAAAJ": "Danilo Jimenez Rezende",
    "z3IRvDwAAAAJ": "Heiga Zen",
    "M0OhM1UAAAAJ": "Hiroki Furuta",
    "Dy8iau4AAAAJ": "Yutaka Matsuo",
    "SxP7_woAAAAJ": "Ali H. Alawadhi",
    "37M48B0AAAAJ": "Kristin Aslaug Persson (nee Einarsdotter)",
    "Sczy43gAAAAJ": "Omar M. Yaghi",
    "6AyF1U8AAAAJ": "Aaron Kaplan",
    "AkgfxXUAAAAJ": "Mona Abdelgaid",
    "eHn2VXEAAAAJ": "Yen-hsu Lin",
    "tzvqRX4AAAAJ": "Yuan Xue",
    "MTd1890AAAAJ": "Theo Jaffrelot Inizan",
    "hYtGXD0AAAAJ": "Charles Sutton",
    "t5lVb6sAAAAJ": "Pengcheng Yin",
    "6KkohssAAAAJ": "Xingchen Wan",
    "7Fxbm0AAAAAJ": "Phitchaya Mangpo Phothilimthana",
    "baDPMxkAAAAJ": "Rushi Qiang",
    "T-f6XlEAAAAJ": "Yuchen Zhuang",
    "jHgmQEIAAAAJ": "Rongzhi Zhang",
    "2WSooDIAAAAJ": "Yinghao Li",
    "CeEO6SIAAAAJ": "Chao Zhang",
    "02kSQ3IAAAAJ": "Zhiling Zheng",
    "KsocBp8AAAAJ": "Ayzaan Wahid",
    "jTdkr10AAAAJ": "Jun Gao",
    "03n03GEAAAAJ": "Huan Ling",
    "iu-Gqo4AAAAJ": "Amlan Kar",
    "9aFd9dEAAAAJ": "David Acuna",
    "KzhR_TsAAAAJ": "Wenzheng Chen",
    "_CuXgYIAAAAJ": "Yukun Zhu",
    "WS2-qlAAAAAJ": "Kaustav Kundu",
    "GbaikvkAAAAJ": "Xavier Puig",
    "FJ-huxgAAAAJ": "Alan Yuille",
    "2wrS35MAAAAJ": "Renjie Liao",
    "rJotb-YAAAAJ": "Makarand Tapaswi",
    "CCV58dgAAAAJ": "Roozbeh Mottaghi",
    "9D4aG8AAAAAJ": "Bolei Zhou",
    "awvsNQYAAAAJ": "Hang Chu",
    "QFpswmcAAAAJ": "Shenlong Wang",
    "GArEeWQAAAAJ": "Xiaozhi Chen",
    "ymzxRhAAAAAJ": "Jimmy Ba",
    "194wSMsAAAAJ": "Xianjie Chen",
    "XPAkzTEAAAAJ": "Jiaya Jia",
    "Lw0H0EwAAAAJ": "Ziyu Zhang",
    "3B2c31wAAAAJ": "Alexander Schwing",
    "tXJDPJAAAAAJ": "Chen Kong",
    "V3kGMXUAAAAJ": "Jian Yao",
    "XWhajuQAAAAJ": "Lluis Castrejon",
    "iAEBIB4AAAAJ": "Francesc Moreno-Noguer",
    "2bDu3ecAAAAJ": "Edgar Simo-Serra",
    "SFCOJxMAAAAJ": "Rainer Stiefelhagen",
    "eycXl_QAAAAJ": "Song Wang",
    "CgSBtPYAAAAJ": "Jeffrey Mark Siskind",
    "taqlL_cAAAAJ": "Jarrell Waggoner",
    "559LF80AAAAJ": "Chen Change Loy",
    "ACjYGPUAAAAJ": "Liang-Chieh Chen",
    "DSKXnkkAAAAJ": "Bin Yang",
    "t1rjgHgAAAAJ": "Andrei Barbu",
    "u5G_A14AAAAJ": "Zachary Burchill",
    "SVIdh6AAAAAJ": "Wei-Chiu Ma",
    "qvRsU00AAAAJ": "Chenxi Liu",
    "x2wyjkAAAAAJ": "Marcus A Brubaker",
    "qSo45J0AAAAJ": "Wenyuan Zeng",
    "18fTep8AAAAJ": "Abhishek Sharma",
    "V7D7hxMAAAAJ": "N. Siddharth",
    "gXFy11EAAAAJ": "Wesley May",
    "4_JVf14AAAAJ": "Afsaneh Fazly",
    "Wbwt1JgAAAAJ": "Luka Fürst",
    "LHTI1W8AAAAJ": "Cristian Sminchisescu",
    "ElNDOmUAAAAJ": "Zhiwei Zhang",
    "97RDUygAAAAJ": "Yu Cao",
    "ZsM2sW8AAAAJ": "Valentin Fidler",
    "6ujRH5UAAAAJ": "Xinyan (Shane) Yan",
    "dG9MV7oAAAAJ": "Evangelos Theodorou",
    "WNHLjp0AAAAJ": "Adith Swaminathan",
    "rlmROVsAAAAJ": "Tengyang Xie",
    "zCaMimYAAAAJ": "Kamil Saigol",
    "IdkhB44AAAAJ": "Yunpeng Pan",
    "nUlanA8AAAAJ": "Nan Jiang",
    "-0ASVXUAAAAJ": "Keuntaek Lee",
    "SgGIYH0AAAAJ": "Nolan Wagener",
    "yYpm9LoAAAAJ": "Mustafa Mukadam",
    "HG08FCMAAAAJ": "Anqi Li",
    "6Q6TCkkAAAAJ": "Amirreza Shaban",
    "r90OelAAAAAJ": "Allen Nie",
    "_bKTUqAAAAAJ": "Stan Birchfield",
    "pl-qLQwAAAAJ": "Paul Mineiro",
    "bd4gMFAAAAAJ": "Tzu-Hao Huang",
    "khZgnWYAAAAJ": "Huan-Kun Hsu",
    "XHZlMYUAAAAJ": "Mihai Jalobeanu",
    "rIoPIFsAAAAJ": "Dipendra Misra",
    "-ki9u4sAAAAJ": "Mohak Bhardwaj",
    "tmKKPjkAAAAJ": "Michael Santacroce",
    "sNGk-9MAAAAJ": "Ahmed H. Awadallah",
    "Y2YBgCsAAAAJ": "Corby Rosset",
    "ItxA4esAAAAJ": "Arindam Mitra",
    "Th4PuGkAAAAJ": "Jacob Sacks",
    "cHia5p0AAAAJ": "Richard Hartley",
    "dTue6HQAAAAJ": "Amir Rahimi",
    "CXPpSu0AAAAJ": "Ricky Loynd",
    "9TbXgQ0AAAAJ": "Jingling Li",
    "M7y1dj8AAAAJ": "Andrea Zanette",
    "J8_FdjkAAAAJ": "Jonathan N. Lee",
    "GDabimYAAAAJ": "Marc Deisenroth",
    "-CzfgbwAAAAJ": "Hugh Salimbeni",
    "0dQzZH8AAAAJ": "Muhammad Asif Rana",
    "HF-1DDwAAAAJ": "Sheng-Yen Lo",
    "13yyuCcAAAAJ": "Furong Huang",
    "86za4C0AAAAJ": "Ruijie Zheng",
    "PbEw81gAAAAJ": "Hal Daumé III",
    "gu2noOcAAAAJ": "Sean R. Sinclair",
    "6CTPn44AAAAJ": "Jennifer Neville",
    "3-9qq6sAAAAJ": "Luke Marshall",
    "INd48rQAAAAJ": "Ishai Menache",
    "E_UlAVQAAAAJ": "Vibhav Vineet",
    "Bm3pH5AAAAAJ": "Garrett Thomas",
    "TCYAoF8AAAAJ": "Karl Van Wyk",
    "mPabwyYAAAAJ": "Huihan  Liu",
    "1MZF70cAAAAJ": "Remi Tachet des Combes",
    "403nNzMAAAAJ": "Jennifer Molnar",
    "-6s0HQ4AAAAJ": "Lucas Tiziani",
    "H2QWyooAAAAJ": "Frank L. Hammond III",
    "tRCR72EAAAAJ": "Jiun-Yih (Jarvis) Kuan",
    "qlwIFJsAAAAJ": "Sanae Amani",
    "hYMvCbwAAAAJ": "Magnus Egerstedt",
    "-JPZ21IAAAAJ": "seth hutchinson",
    "7PljKpoAAAAJ": "Munzir Zafar",
    "a2jB6z0AAAAJ": "Bruce Wingo",
    "oE6XwXsAAAAJ": "Muhammad Ali Murtaza",
    "BN0O9wgAAAAJ": "Aditya Modi",
    "5zHUcUEAAAAJ": "Sinong Geng",
    "TiDGyF4AAAAJ": "Ming-Bao Huang",
    "9k20Ie4AAAAJ": "Hoai-An Nguyen",
    "1aj4dZcAAAAJ": "Ying Fan",
    "aqSKwDQAAAAJ": "Tyler Westenbroek",
    "3pu8FE0AAAAJ": "Kevin Huang",
    "AMVmM84AAAAJ": "Patrick Yin",
    "tm5kow8AAAAJ": "Chetan Bansal",
    "hwg8plgAAAAJ": "Anjaly Parayil",
    "16srx18AAAAJ": "Shivam Shandilya",
    "BFnzsoMAAAAJ": "Vishak Gopal",
    "kog9iL0AAAAJ": "Sami Khairy",
    "KfTWTtAAAAAJ": "Gabriel Mittag",
    "DiBVENwAAAAJ": "Aditya Soni",
    "wbZtij8AAAAJ": "Supriyo Ghosh",
    "6aZUUEAAAAAJ": "Mayukh Das",
    "0RAmmIAAAAAJ": "Kyunghyun Cho",
    "7hwJ2ckAAAAJ": "Caglar Gulcehre",
    "Nq0dVMcAAAAJ": "Dzmitry Bahdanau",
    "O7MZStwAAAAJ": "Sherjil Ozair",
    "Sm15FXIAAAAJ": "Adriana Romero-Soriano",
    "68c5HfwAAAAJ": "R Devon Hjelm",
    "kcTK_FAAAAAJ": "Petar Veličković",
    "s3l225EAAAAJ": "Paolo Frasconi",
    "2HE7cTEAAAAJ": "Junyoung Chung",
    "CEt6_mMAAAAJ": "Joelle Pineau",
    "EvUM6UUAAAAJ": "Adam Trischler",
    "Q8K3FjQAAAAJ": "Matthieu Courbariaux",
    "dEtv5r4AAAAJ": "Guillem Cucurull",
    "XE9SDzgAAAAJ": "Bart van Merriënboer",
    "yVtSOt8AAAAJ": "Emmanuel Bengio",
    "DJon7w4AAAAJ": "Alessandro Sordoni",
    "oU0jQIAAAAAJ": "Devansh Arpit",
    "QdnjDj8AAAAJ": "Nicolas Chapados",
    "1XAhYswAAAAJ": "Renato De Mori",
    "iFhSTbAAAAAJ": "Arantxa Casanova",
    "F99FuaAAAAAJ": "Samira Ebrahimi Kahou",
    "-6Pj3IYAAAAJ": "Mirco Ravanelli",
    "PsKlNzUAAAAJ": "Dmitriy Serdyuk",
    "FyZbyIUAAAAJ": "Asja Fischer",
    "LNZ4efwAAAAJ": "Zhouhan Lin（林洲汉）",
    "Q6UMpRYAAAAJ": "Philemon Brakel",
    "nfHyDeUAAAAJ": "Sungjin Ahn",
    "0g31OfAAAAAJ": "Iulian Vlad Serban",
    "iH9DuY0AAAAJ": "Nasim Rahaman",
    "7b5tlJkAAAAJ": "Gerry Che",
    "5TZ7f5wAAAAJ": "Jeff Clune",
    "slS0dvUAAAAJ": "Joseph Paul Cohen",
    "aLl3rYoAAAAJ": "Kenji Kawaguchi",
    "gxL1qj8AAAAJ": "Jason Yosinski",
    "32w7x1cAAAAJ": "Ronan Collobert",
    "wbJxGQ8AAAAJ": "Stanisław Jastrzębski",
    "XpscC-EAAAAJ": "Tegan Maharaj",
    "wo_M4uQAAAAJ": "Vikas Verma",
    "udwtIesAAAAJ": "Andrea Lodi",
    "5Uz70IoAAAAJ": "David Scott Krueger",
    "j40pfugAAAAJ": "Guillaume Alain",
    "ZX9LE3QAAAAJ": "Yves Grandvalet",
    "AEBWEm8AAAAJ": "Daniel Soudry",
    "dyYryZYAAAAJ": "Itay Hubara PhD",
    "qx_e_9wAAAAJ": "Kris Sankaran",
    "h-sqIigAAAAJ": "Sai Rajeswar",
    "Yc94070AAAAJ": "Jan Chorowski",
    "9BGzHdUAAAAJ": "Vincent Michalski",
    "oejm5IUAAAAJ": "Simon Lacoste-Julien",
    "K757SxgAAAAJ": "Ioannis (Yannis) Mitliagkas",
    "7i101rcAAAAJ": "Sandeep Subramanian",
    "Sh5PsUUAAAAJ": "Kundan Kumar",
    "mKLoSgMAAAAJ": "C Nadeau",
    "nP8cwkIAAAAJ": "Sasha Luccioni",
    "tvUH3WMAAAAJ": "Sepp Hochreiter",
    "h7OHSkoAAAAJ": "Laurent Dinh",
    "AQIwobkAAAAJ": "Christian Jauvin",
    "0XtGoMUAAAAJ": "Kyle Kastner",
    "7V7yNeoAAAAJ": "Taesup Kim",
    "HT85tXsAAAAJ": "Mohammad Pezeshki",
    "Cul0g2YAAAAJ": "Laurent Charlin",
    "1ir6WUEAAAAJ": "Jian Tang (唐建）",
    "8x8FUr8AAAAJ": "Sébastien Jean",
    "yVIXGqYAAAAJ": "Olivier Breuleux",
    "GWyeAskAAAAJ": "Benjamin Scellier",
    "ZK7OfxkAAAAJ": "Aristide Baratin",
    "h3Nsz6YAAAAJ": "Bowen Zhou",
    "iRgYMuEAAAAJ": "Ryan Lowe",
    "Nj74Gv4AAAAJ": "Rémi Bardenet",
    "hJjeVsQAAAAJ": "Rithesh Kumar",
    "F_Go4V4AAAAJ": "Hod Lipson",
    "PgqC5SYAAAAJ": "Ying Zhang",
    "p7mehDEAAAAJ": "Li Yao",
    "XK_ktwQAAAAJ": "Michał Drożdżal",
    "pDIuuVwAAAAJ": "Guido F. Montufar",
    "yVubPz4AAAAJ": "Jean Pierre David",
    "gLnCTgIAAAAJ": "Juergen Schmidhuber",
    "KynAS2gAAAAJ": "Chinnadhurai Sankar",
    "dLaR9lgAAAAJ": "Orhan Firat",
    "7qufP-8AAAAJ": "Thomas Mesnard",
    "Dg5qUb0AAAAJ": "Tristan Sylvain",
    "bp6Ah4EAAAAJ": "Zachary Kenton",
    "VQYdApgAAAAJ": "Ruixiang Zhang",
    "u2tgePAAAAAJ": "João Felipe Santos",
    "XT3E7RoAAAAJ": "Athul Paul Jacob",
    "JmJfOkMAAAAJ": "Nicholas Léonard",
    "bOQGfFIAAAAJ": "Yuhuai(Tony) Wu",
    "X7kZFnoAAAAJ": "Jörg Bornschein",
    "NBUWnTYAAAAJ": "Eric Thibodeau-Laufer",
    "XRhKEGMAAAAJ": "Valentin Thomas",
    "kaAnZw0AAAAJ": "Francesco Visin",
    "W7uYg0UAAAAJ": "Jian-Yun Nie",
    "LWrdpCsAAAAJ": "Harm de Vries",
    "wBMRRk0AAAAJ": "Marco Gori",
    "uPkyCmIAAAAJ": "Lev Ratinov",
    "Y8-xGncAAAAJ": "Lise Getoor",
    "u5SbAJAAAAAJ": "Christopher Kermorvant",
    "lsFo_DcAAAAJ": "Philippe Hamel",
    "mw9kXD8AAAAJ": "Jacques Robert",
    "lb1fNb0AAAAJ": "Francois Rivest",
    "lLTdYUYAAAAJ": "Stephan Gouws",
    "LCAcHmAAAAAJ": "Jean-Luc Gauvain",
    "IwBHa3gAAAAJ": "Ichiro Takeuchi",
    "p_iffpcAAAAJ": "patrice marcotte",
    "naUbiQ8AAAAJ": "Héctor P. Martínez",
    "LC0j4ekAAAAJ": "Piero Cosi",
    "0xIrC1cAAAAJ": "Heng Luo",
    "sDwpLgwAAAAJ": "Steven Pigeon",
    "W5WbqgoAAAAJ": "Xiaodong He",
    "0fRlG8oAAAAJ": "Guy Lapalme",
    "GQWTo4MAAAAJ": "Li Deng",
    "NAdlsUgAAAAJ": "Saizheng Zhang",
    "uJrcFwYAAAAJ": "John F. Kalaska",
    "4HLUnhIAAAAJ": "Felix Hill",
    "AXOiHucAAAAJ": "Carlo Gatta",
    "vfTpaOAAAAAJ": "Thomas Breuel",
    "4nw0skIAAAAJ": "Erick Lavoie",
    "zeX8KGAAAAAJ": "Marcin Moczulski",
    "Iw-G2qIAAAAJ": "Dong-Hyun Lee",
    "RryVaLgAAAAJ": "Kratarth Goel",
    "SCFarTEAAAAJ": "Francis Dutil",
    "K2WfIlsAAAAJ": "Nathan Kallus",
    "s_qd9x0AAAAJ": "Tommaso Biancalani",
    "r-mWYj0AAAAJ": "Yulai Zhao",
    "XtSSJm0AAAAJ": "Xiaojie Mao (毛小介)",
    "MxeFvewAAAAJ": "Gabriele Scalia",
    "dDGy3N0AAAAJ": "Chengchun Shi",
    "tR-p-r8AAAAJ": "Xuezhou Zhang",
    "bBQx_5MAAAAJ": "Xiner Li",
    "ZIw-AGsAAAAJ": "Whitney Newey",
    "33yNvIgAAAAJ": "Mengdi Wang",
    "Kq0dhLAAAAAJ": "Chenyu Wang",
    "BZGj6sAAAAAJ": "Shuiwang Ji, Professor and Truchard Family Chair",
    "vEiu33sAAAAJ": "Gokcen Eraslan",
    "CLgOCOAAAAAJ": "Avantika Lal",
    "6VW1kJgAAAAJ": "Victor Chernozhukov",
    "anc4v98AAAAJ": "Surag Nair",
    "UnrY-40AAAAJ": "Aapo Hyvärinen",
    "Lu7sHfoAAAAJ": "Amy Wang",
    "Yu_0vEEAAAAJ": "Hanchen Wang",
    "EPQZFzwAAAAJ": "Narita Yusuke",
    "tbu1jqUAAAAJ": "Zihao Li",
    "21_amyAAAAAJ": "Edward F Chang",
    "j9ICsOEAAAAJ": "Peter Wu",
    "Es-YRKMAAAAJ": "Alan W Black",
    "fmUkNVcAAAAJ": "Josh Chartier",
    "yW593xUAAAAJ": "David A. Moses",
    "E1CsZLcAAAAJ": "Jiachen Lian",
    "tu9gL58AAAAJ": "Sean Metzger",
    "-T2Gq-EAAAAJ": "Jessie R. Liu",
    "fa193PsAAAAJ": "Kaylo T Littlejohn",
    "v80j6o0AAAAJ": "Akshat Gupta",
    "-qS6zoJHb0IC": "Cheol Jun Cho",
    "Et-LI74AAAAJ": "Pengfei Sun",
    "ZlqnYZoAAAAJ": "Luis Caldas de Oliveira",
    "UGpC1zgAAAAJ": "Tingle Li",
    "2L_8ynAAAAAJ": "Robin Netzorg",
    "Nh832fgAAAAJ": "Tie-Yan Liu",
    "orVoz4IAAAAJ": "Di He",
    "rPhGUw0AAAAJ": "Shuxin Zheng",
    "mNfCP3gAAAAJ": "Yanyan Lan",
    "tAUdLM0AAAAJ": "Chen Xing (星辰)",
    "6qWcDTAAAAAJ": "Matteo Pirotta",
    "6JZ3R6wAAAAJ": "Alessandro Lazaric",
    "cKtU3eAAAAAJ": "Evrard Garcelon",
    "Bw-WdyUAAAAJ": "Kai Zheng",
    "sioumZAAAAAJ": "Xiaoyu Chen",
    "TiF1WEsAAAAJ": "Alexander K. Lew",
    "1aou7GkAAAAJ": "Feras Saad",
    "hxlxVEUAAAAJ": "martin rinard",
    "-_eJqYQAAAAJ": "Ulrich Schaechtle",
    "RikRyq4AAAAJ": "Nishad Gothoskar",
    "mtejbKYAAAAJ": "Michael Carbin",
    "1pnp1ZAAAAAJ": "Benjamin Sherman",
    "6re6uwMAAAAJ": "David M Maslove",
    "G2zXCNkAAAAJ": "Aleksei Petrenko",
    "d2gqmrUAAAAJ": "Alexey Radul",
    "zCdh4NEAAAAJ": "David Wingate",
    "Y7Rm3DYAAAAJ": "Benjamin Bichsel",
    "aZ1Rh50AAAAJ": "Martin Vechev",
    "HcL76tsAAAAJ": "Timon Gehr",
    "GweT9VUAAAAJ": "Jackson Hamburger",
    "ls_kE0UAAAAJ": "David Hafner",
    "9v86038AAAAJ": "Erik Wijmans",
    "6dr5fLEAAAAJ": "Eugene Vinitsky",
    "vOLXDDAAAAAJ": "Dennis Lee",
    "whdanWAAAAAJ": "Adam Stooke",
    "0gJQCIgAAAAJ": "Kiran Koshy Thekumparampil",
    "m8NUgw0AAAAJ": "Peter Kairouz",
    "AaauqDAAAAAJ": "Ashish Khetan",
    "0Wb80ScAAAAJ": "Yihan Jiang",
    "loxOHhoAAAAJ": "Weihao Kong",
    "7yobGX4AAAAJ": "Xiyang Liu",
    "mim8FQkAAAAJ": "Praneeth Netrapalli",
    "67nE-wQ_g_cC": "Zinan Lin",
    "0M99MEYAAAAJ": "Raghav Somani",
    "UlpHyKAAAAAJ": "Himanshu Asnani",
    "KWG3UUMAAAAJ": "Jungseul Ok",
    "3p-KQUwAAAAJ": "Sahand Negahban",
    "46MDvXcAAAAJ": "Jiaming Xu",
    "m3eDp7kAAAAJ": "Jinwoo Shin",
    "bg92wVEAAAAJ": "Yung Yi",
    "l96zhjwAAAAJ": "Amirhossein Taghvaei",
    "d77eUbgAAAAJ": "Quan Geng",
    "B1guGw8AAAAJ": "Changho Suh",
    "FasIlp0AAAAJ": "Reza Parhizkar",
    "YQcU3NYAAAAJ": "martin vetterli",
    "fVuWflQAAAAJ": "Adam Marcus",
    "DgCDBbkAAAAJ": "Bruce Hajek",
    "0DD8EREAAAAJ": "Vivek Bagaria",
    "mQnBkmoAAAAJ": "Weina Wang",
    "oC8YKjUAAAAJ": "Harshay Shah",
    "YzsCLBoAAAAJ": "Rajat Sen",
    "3r-fWJwAAAAJ": "Peter Bühlmann",
    "FaJALc0AAAAJ": "S. Grace Chang",
    "Q4DTPw4AAAAJ": "Pradeep Ravikumar",
    "t4w1jE4AAAAJ": "peter bickel",
    "fZDywBkAAAAJ": "Guilherme Rocha",
    "yHSi7XkAAAAJ": "Karl Rohe",
    "SO9llAMAAAAJ": "Rebecka Jörnsten",
    "9hkEkG0AAAAJ": "Thomas Naselaris",
    "sdw9roIAAAAJ": "Nicolai Meinshausen",
    "JcaWZAQAAAAJ": "Andrew R Barron",
    "x-G741IAAAAJ": "Peng Gong",
    "GcR_rlkAAAAJ": "Vincent Q. Vu",
    "Ic4pPAYAAAAJ": "Per Mykland",
    "tPlneaIAAAAJ": "Gerald Schuller",
    "J_xhWIQAAAAJ": "Brian Gawalt",
    "K4bCJYcAAAAJ": "Antonio Ortega",
    "T8grPNsAAAAJ": "Bani Mallick",
    "eZ51GLAAAAAJ": "Yoav Benjamini",
    "uDuLNHkAAAAJ": "Hamid Izadinia",
    "jeOFRDsAAAAJ": "Ali Farhadi",
    "dD-3S4QAAAAJ": "Leonard Hasenclever",
    "EEkwehIAAAAJ": "Marshall Tappen",
    "YE9w2BsAAAAJ": "Jan Humplik",
    "jWxX49cAAAAJ": "Ben Moran",
    "YCO3WQsAAAAJ": "Markus Wulfmeier",
    "J7p1Fx4AAAAJ": "Steven Bohez",
    "K4OcFXUAAAAJ": "Josh Merel",
    "080Y_lUAAAAJ": "Mohammad Mehdi Ebadzadeh",
    "HGXVByQAAAAJ": "Roland Hafner",
    "SBKP1acAAAAJ": "Michael Neunert",
    "4QqjaDgAAAAJ": "Baoyuan Liu",
    "q-06TwoAAAAJ": "Dhruva Tirumala",
    "LnAus20AAAAJ": "Joshua R. Smith",
    "QmYUuCYAAAAJ": "Colin X Summers",
    "dTV6Zj4AAAAJ": "Christoforos Mavrogiannis",
    "R889GIQAAAAJ": "Johan Michalove",
    "3uClq6kAAAAJ": "Matt Schmittle",
    "vHs01IMAAAAJ": "Rosario Scalise",
    "e9MgnYYAAAAJ": "Patrick Lancaster",
    "t3l8q6gAAAAJ": "Francesco Nori",
    "jYYYIvsAAAAJ": "Arthur Brussee",
    "wurqZikAAAAJ": "Arunkumar Byravan",
    "l2E0LR4AAAAJ": "Noah Y. Siegel",
    "-GduGkcAAAAJ": "Emilio Parisotto",
    "9dAjSlYAAAAJ": "Saran Tunyasuvunakool",
    "Hahkg24AAAAJ": "Martina Zambelli",
    "0ncQNL8AAAAJ": "Yusuf Aytar",
    "EYk7M80AAAAJ": "Mohammad rahmati",
    "vhP-tlcAAAAJ": "Yejin Choi",
    "zFsdqo8AAAAJ": "Reza Safabakhsh",
    "p6iM9gIAAAAJ": "Claudio Fantacci",
    "DNQTSwsAAAAJ": "Thomas Lampe",
    "dlzWP0UAAAAJ": "Tim Hertweck",
    "cCYTVWQAAAAJ": "Abbas Abdolmaleki",
    "1gVfqpcAAAAJ": "Martin Riedmiller",
    "_CYEGnoAAAAJ": "Parisa Haghani",
    "OeULb38AAAAJ": "Steve Tanimoto",
    "BXNelwwAAAAJ": "Ali Movaghar",
    "8oW4qk4AAAAJ": "Amitabh Sinha",
    "g87CIwgAAAAJ": "Anupam Gupta",
    "diIore8AAAAJ": "Madhav  Marathe",
    "UyD0bLYAAAAJ": "Viswanath Nagarajan",
    "gVUD47sAAAAJ": "Philip Klein",
    "XG2aNyYAAAAJ": "SS Ravi",
    "2UiIURcAAAAJ": "Sibel Salman",
    "WEQF9DgAAAAJ": "Ravi Sundaram",
    "ZP6gGZYAAAAJ": "Kedar Dhamdhere",
    "6ArMETUAAAAJ": "Russell Schwartz",
    "eQ9_vDAAAAAJ": "Mohit Singh",
    "Z6nLCukAAAAJ": "Guy Blelloch",
    "wNRE148AAAAJ": "Naveen Garg",
    "RNHJqvcAAAAJ": "Daniel J. Rosenkrantz",
    "Ak7gyjQAAAAJ": "Jochen Koenemann",
    "axf9B1gAAAAJ": "Vineet Goyal",
    "3WJN5csAAAAJ": "Giuseppe Lancia",
    "j6eVlwsAAAAJ": "Sven Krumke",
    "Qqtyp-EAAAAJ": "Marco Molinaro",
    "RfQ6JRcAAAAJ": "Hsueh-I Lu",
    "w7t5xQsAAAAJ": "Ravishankar Krishnaswamy",
    "bpDPt1QAAAAJ": "Eran Halperin",
    "Ae6siZoAAAAJ": "Refael Hassin",
    "a2PXepkAAAAJ": "Bjarni V. Halldorsson",
    "tf1c4_kAAAAJ": "Su Jia",
    "qk0hejcAAAAJ": "Leen Stougie",
    "rYFeExcAAAAJ": "Inge Li Gørtz",
    "BwjRbkcAAAAJ": "Stylianos Despotakis",
    "olerUhcAAAAJ": "Magnús M. Halldórsson",
    "SKXmmxIAAAAJ": "John Kececioglu",
    "5-pEIw0AAAAJ": "Vojin G. Oklobdzija",
    "gWGQIh4AAAAJ": "Pinar Keskinocak",
    "rkpVQI4AAAAJ": "Kun-Mao Chao",
    "N0tU5N4AAAAJ": "Takuro Fukunaga",
    "x1cDFYsAAAAJ": "Isa Hafalir",
    "_92oJ8IAAAAJ": "Uday Rajan",
    "m6NDX0IAAAAJ": "Benjamin Moseley",
    "62Uqu6wAAAAJ": "Satish B Rao",
    "J9-meToAAAAJ": "Cor Hurkens",
    "abn9WWMAAAAJ": "Sridhar Tayur",
    "umm-i20AAAAJ": "Gary L. Miller",
    "Gwrwxa0AAAAJ": "Bruce Maggs",
    "3evp9QMAAAAJ": "Guy Even",
    "pOd2M64AAAAJ": "David P. Williamson",
    "9mIBxkMAAAAJ": "Wolfgang Gatterbauer",
    "umOOMzsAAAAJ": "Lap Chi Lau",
    "p5LCHHEAAAAJ": "Stefano Leonardi",
    "cTpyTaIAAAAJ": "Fabrizio Grandoni",
    "sgH6VuwAAAAJ": "Yuri Rabinovich",
    "RJEQriwAAAAJ": "Harald Räcke",
    "T1RxzcUAAAAJ": "Thomas Lavastida",
    "n2S1wyQAAAAJ": "Chenyang Xu",
    "a0wbKRAAAAAJ": "Bang Ye Wu",
    "Bri9R_4AAAAJ": "Milind Dawande",
    "dlytHK4AAAAJ": "jayant kalagnanam",
    "QZrx9MEAAAAJ": "Rajmohan Rajaraman",
    "nf_EnbAAAAAJ": "Michel Goemans",
    "begDaeQAAAAJ": "C.Pandu Rangan",
    "E1jZijwAAAAJ": "Guido Schäfer",
    "rwfHSYgAAAAJ": "Afshin Nikzad",
    "gG7M_pIAAAAJ": "John Hooker",
    "k8Px6S8AAAAJ": "Daniel Golovin",
    "bKMKO_AAAAAJ": "Jonathan Minden",
    "6REa4FcAAAAJ": "Amir Ben-Dor",
    "zhxqybUAAAAJ": "Tibor Jordán",
    "ewGrWyQAAAAJ": "Rico Zenklusen",
    "kW06fgwAAAAJ": "Fatemeh Navidi",
    "rRvt-YAAAAAJ": "Sivakumar Rathinam",
    "h8apFZsAAAAJ": "Michael (Mik) Zlatin",
    "whB5QDoAAAAJ": "kannan srinivasan",
    "7-2bbBgAAAAJ": "Jingyan Wang",
    "BF39lMQAAAAJ": "Nihar B. Shah",
    "EqKRQ4YAAAAJ": "Alan Frieze",
    "sPzla6IAAAAJ": "Aravind Srinivasan",
    "XXNAaWQAAAAJ": "Arash Haddadan",
    "T645IqsAAAAJ": "Hassene Aissi",
    "Z9uBjIEAAAAJ": "Hakan Yildiz",
    "SY8DwiUAAAAJ": "Martijn van Ee",
    "Fmq16C4AAAAJ": "Thomas Bosman",
    "xITAf6EAAAAJ": "Alberto Marchetti-Spaccamela",
    "qOgSRPQAAAAJ": "Vittorio Bilò",
    "cGvYY4YAAAAJ": "Zeev Nutov",
    "yc2mM9IAAAAJ": "Ray Reagans",
    "Q1W6RzMAAAAJ": "Kenny Chour",
    "3nXmUP0AAAAJ": "Vibhanshu Abhishek",
    "YUHMFMMAAAAJ": "Daniele Catanzaro",
    "Wd4ChQ8AAAAJ": "Seeun William Umboh",
    "6pR07RQAAAAJ": "Val Polishchuk",
    "6FWSv1EAAAAJ": "Satoru Iwata",
    "BWDUVOIAAAAJ": "Nishant Oli",
    "jmeHpKUAAAAJ": "Peter Dankelmann",
    "4DuiN7AAAAAJ": "Uriel Feige",
    "-ihQeTYAAAAJ": "Lin An",
    "i5U_SqgAAAAJ": "Martin Skutella",
    "61hrt1cAAAAJ": "Eduardo Sany Laber",
    "724lKQgAAAAJ": "Neil Olver",
    "_cIeQgYAAAAJ": "Kanstantsin Pashkovich",
    "1YEoqJsAAAAJ": "Jens Vygen",
    "BHZT068AAAAJ": "Sahil Singla",
    "JR_KR7MAAAAJ": "D Ellis Hershkowitz",
    "9cHjPDkAAAAJ": "niv buchbinder",
    "xGbDr7YAAAAJ": "Joseph Seffi Naor",
    "AdAd4QIAAAAJ": "Jason Hartline",
    "yDXNzfIAAAAJ": "A. Ridha Mahjoub",
    "jAAj8DAAAAAJ": "Kaarthik Sundar",
    "s7-TjaIAAAAJ": "Jungyun Bae (Jung Yun Bae)",
    "8_lfEOsAAAAJ": "Nikhil Chandak",
    "SAemU0sAAAAJ": "Romeo Rizzi",
    "odfHRTcAAAAJ": "Laura Sanità",
    "lWrAwrwAAAAJ": "Guru Guruganesh",
    "2sPxj90AAAAJ": "Nathaniel Dean",
    "MzT5-4kAAAAJ": "Nam Ho-Nguyen",
    "rXpctjYAAAAJ": "Leslie Ann Goldberg",
    "6KQy8zgAAAAJ": "Jose Rolim",
    "gaqzMHAAAAAJ": "Klaus Jansen",
    "kzYoaFYAAAAJ": "Alessandro Panconesi",
    "2Q1BK6gAAAAJ": "László A. Végh",
    "n41vSUAAAAAJ": "Anita Williams Woolley",
    "tMBYEWAAAAAJ": "Rohit Khandekar",
    "jAKBew4AAAAJ": "Michael Jünger",
    "o8048ZwAAAAJ": "Gerdus Benade",
    "VUi7eM8AAAAJ": "Sanjeev Satheesh",
    "FHOFCuEAAAAJ": "Tao Wang",
    "Qq70O4UAAAAJ": "Gregory Diamos",
    "UZ6kI2AAAAAJ": "Bryan Catanzaro",
    "3-mdTUAAAAAJ": "Awni Hannun",
    "pTvhQDQAAAAJ": "Shubho Sengupta",
    "sow8PQYAAAAJ": "David Wu",
    "n0pk_jEAAAAJ": "Jiquan Ngiam",
    "te2go-MAAAAJ": "Sourabh Vora",
    "WlWma8EAAAAJ": "Alex H. Lang",
    "373LKEYAAAAJ": "Holger Caesar",
    "rwtM4roAAAAJ": "Varun Kumar Reddy Bankiti",
    "N0x7TRcAAAAJ": "David Kriegman",
    "nSI1yM0AAAAJ": "Bassam Helou",
    "q3AmlWMAAAAJ": "Venice Erin Liong",
    "yhpAb1YAAAAJ": "David Kline",
    "lQumblsAAAAJ": "Benjamin P. Neal",
    "TMPlDbsAAAAJ": "B. Greg Mitchell",
    "1jgwWYAAAAAJ": "Eric M. Wolff",
    "dztQNeQAAAAJ": "Lubing Zhou",
    "4WVI4SYAAAAJ": "Yu Pan",
    "a3G23eUAAAAJ": "Tali Treibitz",
    "L-TjbwcAAAAJ": "Manuel Gonzalez-Rivero",
    "Ige4r2YAAAAJ": "Ove Hoegh-Guldberg",
    "Q9va0qQAAAAJ": "Jiong YANG",
    "oclUWQEAAAAJ": "Tichakorn Wongpiromsarn",
    "5hH5bt8AAAAJ": "Peter J. Edmunds",
    "qmjjxBoAAAAJ": "Anjani Ganase",
    "_bIWSJAAAAAJ": "Shih-Yuan Liu",
    "j03zZgcAAAAJ": "Dan Morris",
    "Mux9-okAAAAJ": "T. Scott Saponas",
    "aSJthdEAAAAJ": "Neel Joshi",
    "BKfjTj4AAAAJ": "Chris Roelfsema",
    "JlqDXrUAAAAJ": "Eric Orenstein",
    "UjCHdlEAAAAJ": "Thomas Andrew Oliver",
    "BWc6kMsAAAAJ": "Tung Phan-Minh",
    "Jek-NhkAAAAJ": "Nachiket Deo",
    "OzfKmBEAAAAJ": "Pim Bongaerts",
    "9H75c04AAAAJ": "Matthew J Dunlap",
    "-GRqX-QAAAAJ": "Fan TY",
    "hSaJzr8AAAAJ": "Vincent Moriarty",
    "73D0CgcAAAAJ": "Juraj Kabzan",
    "YGxUJXkAAAAJ": "Luke Fletcher",
    "LwtwtDgAAAAJ": "Sammy Omari",
    "GECP5OIAAAAJ": "Scott Drew Pendleton",
    "VtbaGhIAAAAJ": "Juana Valeria Hurtado",
    "LcARjz0AAAAJ": "Abhinav Valada",
    "9emgsOwAAAAJ": "Rohit Mohan",
    "72yPqG4AAAAJ": "Calin Belta",
    "XoXgt4oAAAAJ": "Anne Collin",
    "jgeWbOMAAAAJ": "Radboud J. Duintjer Tebbens",
    "aq4kedwAAAAJ": "Brian Chu",
    "WjF1dugAAAAJ": "Vashisht Madhavan",
    "jxF7YgYAAAAJ": "Dr. Catalina Reyes-Nivia",
    "gfUj1FUAAAAJ": "Courtney S. Couch, PhD",
    "8NoMRR0AAAAJ": "Heidi M. Sosik",
    "uK53FGQAAAAJ": "Andrea Censi",
    "8JGG3KcAAAAJ": "Emilio Frazzoli",
    "7ZXfuAMAAAAJ": "Francesco Seccamonte",
    "bFNzhmwAAAAJ": "Dmitry Yershov",
    "PaEn9KEAAAAJ": "Omar Al Assad",
    "Jt1tl0YAAAAJ": "Oscar Pizarro",
    "HfXk1nEAAAAJ": "Ariell Friedman",
    "mQTedo0AAAAJ": "Ben Upcroft",
    "btHLQeQAAAAJ": "Stuart Phinn",
    "ejD_Z3IAAAAJ": "Gal Eyal",
    "cpv4vqAAAAAJ": "Yossi Loya",
    "H6ArRNYAAAAJ": "Steve Branson",
    "N5MghGIAAAAJ": "Qimin Chen",
    "Ke__1Z8AAAAJ": "Jessica Bouwmeester",
    "WIKDWBQAAAAJ": "Nancy Knowlton",
    "kKYbS08AAAAJ": "Qi (Claire) Chen",
    "E-oOiwwAAAAJ": "Veronica Radice",
    "Fykyo9gAAAAJ": "Nuno Vasconcelos",
    "_Gl7YvAAAAAJ": "Mohammad Saberian",
    "UNXPtTMAAAAJ": "Noushin Mehdipour",
    "64y6FZcAAAAJ": "Cristhian Lizarazo",
    "pSpRfQ4AAAAJ": "Aditya Dusi",
    "Cw7LTkkAAAAJ": "Zhiliang Chen",
    "iQx57VIAAAAJ": "Yiluan Guo",
    "yZ5WqE4AAAAJ": "Anthony Hoogs",
    "ny7iUz4AAAAJ": "Kresimir Williams",
    "pFlJsUEAAAAJ": "Farron Wallace",
    "SywbV14AAAAJ": "Donghyeon Won",
    "7nuMOqoAAAAJ": "Russell Brainard",
    "ISomHK0AAAAJ": "Siddharth Khullar",
    "CJwLwzQAAAAJ": "Yang Gao",
    "gB87zD4AAAAJ": "Nitish Dashora",
    "AGPooMYAAAAJ": "Arjun Bhorkar",
    "OKjAP7AAAAAJ": "Nathan N. Liu",
    "kGOgaowAAAAJ": "Qi Lei",
    "jEzWxQIAAAAJ": "Jonathan Taylor",
    "YvHcBcEAAAAJ": "Alex Damian",
    "EkREu_QAAAAJ": "Suriya Gunasekar",
    "ZQs5JAIAAAAJ": "Eshaan Nichani",
    "CvwLRSMAAAAJ": "Tianle Cai",
    "1yB0eLMAAAAJ": "Haochuan Li",
    "nIWUhXAAAAAJ": "Gaurav Mahajan",
    "MVxcjEoAAAAJ": "Rong Ge",
    "ZybgAqkAAAAJ": "Wei Hu",
    "bc_N2-oAAAAJ": "Maziar Sanjabi",
    "FY_UnPAAAAAJ": "Yun Yang",
    "RtNVud4AAAAJ": "Yuxin Chen",
    "QHZBakwAAAAJ": "Dennis Sun",
    "9OO7nhUAAAAJ": "Colin Wei",
    "narJyMAAAAAJ": "Mahdi Soltanolkotabi",
    "Q21P3fsAAAAJ": "Xiyu Zhai",
    "sUriZlUAAAAJ": "Barnabas Poczos",
    "4BHeGQMAAAAJ": "Ruiqi Gao",
    "n8ZpnWMAAAAJ": "Ruosong Wang",
    "oPDVmsgAAAAJ": "Michael Saunders",
    "BaCR90MAAAAJ": "Jiaqi Yang",
    "ANPFix4AAAAJ": "Maher Nouiehed",
    "hYi6i9sAAAAJ": "Dimitris Papailiopoulos",
    "qjJg6akAAAAJ": "Xi Chen",
    "GINhGvwAAAAJ": "Chi Jin",
    "zl70inwAAAAJ": "Audrey Huang",
    "NQRw0bQAAAAJ": "Tri Dao",
    "TbUEDGIAAAAJ": "Reza Bosagh Zadeh",
    "cyCp3pIAAAAJ": "Rahul Mazumder",
    "wrozdTYAAAAJ": "Mor Shpigel Nacson",
    "sCEl8r-n5VEC": "Kangwook Lee",
    "HSx0BgQAAAAJ": "Zhaoran Wang",
    "5vVjpBsAAAAJ": "Zhiyuan Li",
    "jH9i188AAAAJ": "Ayush Sekhari",
    "RveRRXAAAAAJ": "Yichen Zhang",
    "c73wW0kAAAAJ": "Xin T. Tong",
    "TNdMwp0AAAAJ": "Tianjian Huang",
    "Ar4h7jkAAAAJ": "Georgios Piliouras",
    "5NiFWuwAAAAJ": "Ioannis Panageas",
    "Wy89g4IAAAAJ": "Cho-Jui Hsieh",
    "un0eGzEAAAAJ": "Zhang Zihan",
    "vaSdahkAAAAJ": "Caiming Xiong",
    "qU9WvTgAAAAJ": "Minshuo Chen",
    "7NpTttkAAAAJ": "Huan Wang",
    "_THez4oAAAAJ": "Angeliki Giannou",
    "BCxFU0EAAAAJ": "Tianbao Yang",
    "sPtFRB8AAAAJ": "Qihang Lin",
    "CRWJFnwAAAAJ": "Dmitriy Drusvyatskiy",
    "uGdPyZQAAAAJ": "Damek Davis",
    "lNkw3QYAAAAJ": "Zhengyang Geng",
    "il-F8YYAAAAJ": "Tianyu Gao",
    "9HCmTcwAAAAJ": "Sadhika Malladi",
    "EfxwV6oAAAAJ": "Kaixuan Huang",
    "f6JF7BkAAAAJ": "Shachar Lovett",
    "e6JywScAAAAJ": "Mauro Maggioni",
    "F24vXggAAAAJ": "Nikunj Saunshi",
    "GlArL6AAAAAJ": "Jiacheng  Zhuo",
    "lGgLAiIAAAAJ": "Yingbin Liang",
    "i4_3daEAAAAJ": "Joel A. Tropp",
    "xQqZt2AAAAAJ": "Jikai Jin",
    "843JJtgAAAAJ": "Kaifeng Lyu",
    "LurWtuYAAAAJ": "Tong Zhang",
    "FX6bV4UAAAAJ": "Qi Cai",
    "1YBLp6MAAAAJ": "Kurtland Chua",
    "nzS2jrMAAAAJ": "Itay Safran",
    "m45LD1kAAAAJ": "Tianhao Wang",
    "qEXxyDQAAAAJ": "Shashank Rajput",
    "Cs75s1MAAAAJ": "Jy-yong Sohn",
    "bM44mNEAAAAJ": "Chuanxiong Guo",
    "hKjmnDUAAAAJ": "Markus Kliegl",
    "ewQrF9cAAAAJ": "David Rincón Rivera",
    "z-KILD8AAAAJ": "Jingfeng Wu",
    "biJiXWoAAAAJ": "Nayoung Lee",
    "BP0WzIQAAAAJ": "Kartik Sreenivasan",
    "SWQxcO8AAAAJ": "Haochen Zhang",
    "L8r9ox4AAAAJ": "Shiyu Liang",
    "tDWt_MQAAAAJ": "R. Srikant",
    "PsfzbCMAAAAJ": "Ruoyu Sun",
    "jHEvHNYAAAAJ": "Zexuan Zhong",
    "bKwkUO4AAAAJ": "Zhenyu He",
    "HzlOQRkAAAAJ": "Yihang Chen",
    "i0OY_LAAAAAJ": "Jingtong Su",
    "0b7ZqlcAAAAJ": "Pan Zhou",
    "E0A3lSIAAAAJ": "Kaiyi Ji",
    "eARXJywAAAAJ": "Anna Little",
    "O8d33mkAAAAJ": "Yoon Mo Jung",
    "WoB6M2cAAAAJ": "Chenwei Wu",
    "P_-O-wcAAAAJ": "Ziang Song",
    "Uhf4nBkAAAAJ": "Weijie Su",
    "fXy1pfcAAAAJ": "Yang Pengkun",
    "FaOcyfMAAAAJ": "Richard Socher",
    "6wGt7fYAAAAJ": "Runzhe Wang",
    "9LcxwsMAAAAJ": "Mladen Kolar",
    "HzxnwocAAAAJ": "Mehrdad Mahdavi",
    "whi3UisAAAAJ": "Anthony Man-Cho So",
    "gmSwszcAAAAJ": "Zhihui Zhu",
    "WkRojboAAAAJ": "Xiao Li",
    "JSFmVQEAAAAJ": "Alexandros G Dimakis",
    "iTv2cOgAAAAJ": "Constantinos Daskalakis",
    "5m5ds6UAAAAJ": "David Gleich",
    "JBV4oGQAAAAJ": "Bartek Rajwa",
    "BzOqNoQAAAAJ": "Austin R Benson",
    "W0H5bc0AAAAJ": "He Li",
    "HjWpRCIAAAAJ": "Edgar Minasyan",
    "LVk3xE4AAAAJ": "Gal Vardi",
    "GMvmr8QAAAAJ": "Zihao Wang",
    "ZBF2zKMAAAAJ": "Zihan Wang",
    "DTthB48AAAAJ": "Vladimir Braverman",
    "nX9D5AoAAAAJ": "Karthik Sridharan",
    "v7EjGHkAAAAJ": "Christopher De Sa",
    "SxUNhucAAAAJ": "Qian Yu (于乾)",
    "LRsjX7kAAAAJ": "Songtao Lu",
    "dHjYcrgAAAAJ": "Xiang Wang",
    "JS-_0nUAAAAJ": "Gen Li",
    "PCDSl2sAAAAJ": "Lemeng  Wu",
    "N2M9RPoAAAAJ": "Cong Fang",
    "ChwmtBkAAAAJ": "Yihong Gu",
    "qd06pUgAAAAJ": "Weizhong Zhang",
    "a-yq6EAAAAAJ": "Sina Baharlouei",
    "nnLiId8AAAAJ": "Ran Gilad-Bachrach",
    "B2U8EUwAAAAJ": "Rich Caruana",
    "e1ucbCYAAAAJ": "Behnam Neyshabur",
    "Spe0xdkAAAAJ": "Raman Arora",
    "roFM8XsAAAAJ": "Hadi Daneshmand",
    "HpQGq54AAAAJ": "Yining Wang",
    "Om4Lag0AAAAJ": "Yuchen Zhang",
    "47EBD1QAAAAJ": "Xuanqing Liu",
    "V5gL_H0AAAAJ": "Mao Ye",
    "p5uvh2oAAAAJ": "Zheng Yu",
    "QMV3HxMAAAAJ": "Etash K Guha",
    "L6TpGPMAAAAJ": "Igor Labutov",
    "_kqpoHIAAAAJ": "Siddhartha Banerjee",
    "SnTMyGUAAAAJ": "Jensen Gao",
    "tGAimhAAAAAJ": "Nicholas F Hardy",
    "H2qBVBIAAAAJ": "Nikhilesh Natraj",
    "vjgsd5kAAAAJ": "Karunesh Ganguly",
    "-hGZC54AAAAJ": "Sameer Singh",
    "d0npq2oAAAAJ": "Shi Feng",
    "SfKdzrUAAAAJ": "Matt Gardner",
    "bjdB4K8AAAAJ": "Katherine Lee",
    "BT4XTP4AAAAJ": "Jordan Boyd-Graber",
    "jGdqlOwAAAAJ": "Nikhil Kandpal",
    "2IXVwTMAAAAJ": "Tony Z. Zhao",
    "I0fbJ6cAAAAJ": "Boaz Barak",
    "jJRiZR8AAAAJ": "Dan Klein",
    "eqQQkM4AAAAJ": "Peizhao Zhang",
    "gKUEEY4AAAAJ": "Ramtin Pedarsani",
    "q9g_OlwAAAAJ": "Daniel Lazar",
    "9_QWXrsAAAAJ": "Vasumathi Raman",
    "UXNLsZUAAAAJ": "Katherine Driggs-Campbell",
    "LicjjokAAAAJ": "Susan Cheng",
    "CulluAgAAAAJ": "Neal Yuan",
    "VnvkluIAAAAJ": "Bryan He",
    "NGI_y8IAAAAJ": "Joseph Ebinger",
    "xHC1VkoAAAAJ": "Jonathan H Chen",
    "_kOUMXoAAAAJ": "Christine M. Albert",
    "ep52oxEAAAAJ": "Paul Heidenreich",
    "WQkBYwQAAAAJ": "Curtis P. Langlotz",
    "Z8I-ydAAAAAJ": "Manxi Wu",
    "8GDPQboAAAAJ": "Chinmay Maheshwari",
    "baF3HKUAAAAJ": "PENG WANG",
    "vcGuNDYAAAAJ": "Songze Li",
    "DRA4zoUAAAAJ": "Chien-Sheng Yang",
    "J7vQ-QEAAAAJ": "Yue Niu",
    "NAntFXIAAAAJ": "Murali Annavaram",
    "d7IuSpAAAAAJ": "Tingting Tang",
    "DbrKNSQAAAAJ": "Mahdi Soleymani",
    "mZMaDgEAAAAJ": "Hessam Mahdavifar",
    "VrswntoAAAAJ": "Karim G. Seddik",
    "PVxHYr4AAAAJ": "M Nafie",
    "GXhpY9wAAAAJ": "Ejder Baştuğ",
    "68y3nvYAAAAJ": "Saeid Sahraei",
    "rUmKr3AAAAAJ": "Amr El-Keyi",
    "VhnTrugAAAAJ": "Saurav Prakash",
    "9SakklgAAAAJ": "Federico Penna",
    "Gqp2GqkAAAAJ": "Bilgehan Erman",
    "EYo_WkEAAAAJ": "Sonia Chernova",
    "Y8ep3h8AAAAJ": "Kaushik Subramanian",
    "UTmj6K4AAAAJ": "Tesca Fitzgerald",
    "VjNg25EAAAAJ": "Ashok K. Goel, Ashok Goel",
    "QehMdGIAAAAJ": "Kalesha Bullard",
    "QWK6YXUAAAAJ": "Cory Kidd",
    "bwORIKIAAAAJ": "Jonathan Scholz",
    "ohTFQMMAAAAJ": "Chih-Hung Aaron King",
    "FvP33fEAAAAJ": "Tiffany L. Chen",
    "rynvwScAAAAJ": "Aaron Bobick",
    "TjWwqmwAAAAJ": "Aaron D. Ames",
    "YP9KtBQAAAAJ": "Momotaz Begum",
    "ExJ1IooAAAAJ": "Jaeeun Shim",
    "aWiMKLsAAAAJ": "Amanpreet Singh",
    "bSU7LYoAAAAJ": "Xinlei Chen",
    "fb6FOfsAAAAJ": "Shoubhik Debnath",
    "VeTSl0wAAAAJ": "Tengyu Ma",
    "E8DVVYQAAAAJ": "Yuan-Ting Hu",
    "4LWx24UAAAAJ": "Chaitanya K. Ryali",
    "rqmw-qQAAAAJ": "Haitham Khedr",
    "74zyaaYAAAAJ": "Valentin Gabeur",
    "Tpt57v0AAAAJ": "Roman Rädle",
    "xOrRvKAAAAAJ": "Nikhila Ravi",
    "8Xt3TnAAAAAJ": "Junting Pan (潘俊廷）",
    "QiJPlOIAAAAJ": "Chao-Yuan Wu",
    "DhtAFkwAAAAJ": "Kaiming He",
    "h8u3ll8AAAAJ": "Nicolas Carion",
    "n-SnMhoAAAAJ": "Chloé Rolland",
    "c8IpF9gAAAAJ": "Laura Gustafson",
    "Q0piorUAAAAJ": "Douwe Kiela",
    "bh08FeIAAAAJ": "Vedanuj Goswami",
    "jyaTX64AAAAJ": "Wojciech Galuba",
    "O1DeDyEAAAAJ": "Guillaume Couairon",
    "Q8iay0gAAAAJ": "Jiashi Feng",
    "mN6_BKAAAAAJ": "Taylor Berg-Kirkpatrick",
    "kh8Qe6YAAAAJ": "Oleksii Sidorov",
    "-VgS8AIAAAAJ": "Yanghao Li",
    "76B8lrgAAAAJ": "Haoqi Fan",
    "8gfs8XIAAAAJ": "Angel Chang",
    "hon4EsIAAAAJ": "Dave Zhenyu Chen",
    "GADXPDcAAAAJ": "Damian Mrowca",
    "duIUwpwAAAAJ": "Ruiping Wang",
    "Vkzd7MIAAAAJ": "Shiguang Shan",
    "TW7U1W0AAAAJ": "Ameet Talwalkar",
    "7GK8LQMAAAAJ": "Daniel Haas",
    "n-q-55wAAAAJ": "Ethan Holly",
    "5ErX8dMAAAAJ": "Rico Jonschkowski",
    "OXtG-isAAAAJ": "Stephen James",
    "JQcDmB8AAAAJ": "Stephen Tu",
    "2QfPE54AAAAJ": "Alberto Camacho",
    "pihC5CkAAAAJ": "Luis Alvarez-Icaza",
    "p8ArrV4AAAAJ": "Perry Y. Li",
    "Z-UlU3MAAAAJ": "Jongeun Choi",
    "lE68S9wAAAAJ": "Jingang Yi",
    "6WiWvr0AAAAJ": "Xiao-Yun Lu",
    "Q10gid0AAAAJ": "Laura Muñoz",
    "tGNxOpEAAAAJ": "Sungsu Park",
    "ABSaf6IAAAAJ": "Roger T Howe",
    "XPiir70AAAAJ": "William Messner",
    "H7vcwSAAAAAJ": "Vivek Kwatra",
    "_8SObXwAAAAJ": "Matthias Grundmann",
    "jIKjjSYAAAAJ": "Lu Jiang",
    "y-khfzIAAAAJ": "Vinay Bettadapura",
    "kM95eWgAAAAJ": "Thomas Ploetz",
    "l7nsfT4AAAAJ": "Elizabeth D. Mynatt",
    "iDP84cQAAAAJ": "José Lezama",
    "Pa8qzYQAAAAJ": "David Minnen",
    "B0K-DwEAAAAJ": "Edison Thomaz",
    "_r4LsycAAAAJ": "Steven Hickson",
    "MVanlR8AAAAJ": "Kihwan Kim",
    "Q_4d9N0AAAAJ": "Greg Turk",
    "aOsuqRkAAAAJ": "Daniel Castro Chin",
    "7ip1Ih8AAAAJ": "Nicholas Diakopoulos",
    "UA3tyKwAAAAJ": "Blair MacIntyre",
    "SrHIXjEAAAAJ": "Apoorva Beedu",
    "8vMAKiwAAAAJ": "Aneeq Zia",
    "ThV9ezEAAAAJ": "Harish Haresamudram",
    "rhZm_NAAAAAJ": "Yuan Hao",
    "K-dWyGEAAAAJ": "Vincent Cartillier",
    "IaDc0OcAAAAJ": "Lijun Yu",
    "Cr3WSpIAAAAJ": "Wendy A. Rogers",
    "d53muYsAAAAJ": "Pei Yin",
    "v-A_7UsAAAAJ": "Ari S. Morcos",
    "elEQEEEAAAAJ": "Yachna Sharma",
    "cxEoVL4AAAAJ": "Han Zhang",
    "XjltJv8AAAAJ": "Darnell Moore",
    "4DUcuysAAAAJ": "Peggy Chi",
    "CZiTv0gAAAAJ": "Gabriel J. Brostow",
    "Mg-vyosAAAAJ": "Huda Alamri",
    "NKtRqvYAAAAJ": "Nipun Kwatra",
    "8E442bkAAAAJ": "David Salesin",
    "50baXGgAAAAJ": "Weilong Yang",
    "hyWg3nEAAAAJ": "R. Mitchell Parry",
    "Py54GcEAAAAJ": "Alex Hauptmann",
    "rZ0mlMYAAAAJ": "Yong Cheng",
    "fu_wsGUAAAAJ": "Unaiza Ahsan",
    "4D2vsdYAAAAJ": "Manolis Savva",
    "AxzVaI8AAAAJ": "Agrim Gupta",
    "UD7d2NEAAAAJ": "K. Niranjan Kumar",
    "Lt945BwAAAAJ": "Jue Wang",
    "a_M5FlgAAAAJ": "Chiori Hori",
    "XVUCn40AAAAJ": "Anoop Cherian",
    "rA48PN4AAAAJ": "Tim K. Marks",
    "lEQ3oDAAAAAJ": "Grant Schindler",
    "Xy8kb5gAAAAJ": "Sumit Basu",
    "qCrypnoAAAAJ": "Xiuye Gu",
    "Vz-lz3cAAAAJ": "Jonathan Bidwell, PhD",
    "PI30hN8AAAAJ": "Aman Parnami",
    "rmCtisEAAAAJ": "Monson Hayes",
    "MA8rI0MAAAAJ": "Henrik Iskov Christensen",
    "e-GEqxoAAAAJ": "Shray Bansal",
    "kXkHRK4AAAAJ": "Glenn Entis",
    "ixBXGEYAAAAJ": "Drew Steedly",
    "ZKDLDQoAAAAJ": "Oleksandr Maksymets",
    "kQisE-gAAAAJ": "Georgia Gkioxari",
    "jfy2IG0AAAAJ": "Rawesak Tanawongsuwan",
    "E3NRabsAAAAJ": "Dongryeol Lee",
    "2rzyuRQAAAAJ": "Sing Bing Kang",
    "b8cNEHwAAAAJ": "Kurt Luther",
    "-wpZQY0AAAAJ": "Rapha Gontijo Lopes",
    "Qk_ziKsAAAAJ": "Nils Hammerla",
    "YULFeN0AAAAJ": "Patrick Olivier",
    "-q90a0EAAAAJ": "Ariel Shamir",
    "0ZXfitAAAAAJ": "Iain Matthews",
    "hzOgd9MAAAAJ": "Hung-Yu Tseng",
    "ZxXBaswAAAAJ": "Frank Dellaert",
    "7oxkHYYAAAAJ": "Franziska Meier",
    "IGnKP2AAAAAJ": "Jonathan C. Kim",
    "EKAynJgAAAAJ": "Zhefan Ye",
    "jo5w-KMAAAAJ": "Hrishikesh Rao",
    "_y-8nrcAAAAJ": "Yin Li",
    "xARSfT4AAAAJ": "Chanho Kim",
    "XAveESgAAAAJ": "Eugene Medynskiy",
    "zc6Iy0IAAAAJ": "Avneesh Sud",
    "sdSjnhwAAAAJ": "Sangmin Oh",
    "rqUJfaUAAAAJ": "Mike Stilman",
    "mHwonDEAAAAJ": "Jun Xu",
    "n4pWU_0AAAAJ": "Guy Lebanon",
    "snDpfA0AAAAJ": "Fuxin Li",
    "h3XP9JkAAAAJ": "David Cai (publication under name David Tsai)",
    "aj84iHAAAAAJ": "Nicolas Padoy",
    "SvuSifMAAAAJ": "Matthew Flagg",
    "vsAumE0AAAAJ": "Atsushi Nakazawa",
    "556SqtcAAAAJ": "Sergio Goldenberg",
    "wOYUPpwAAAAJ": "Ramesh Jain",
    "OGdXlpcAAAAJ": "Chris Wojtan",
    "U7svaOMAAAAJ": "Peter J. Mucha",
    "TT-8JRsAAAAJ": "Lionel Reveret",
    "VzkoqhIAAAAJ": "Daniel Ashbrook",
    "J1tqbNAAAAAJ": "Umakishore Ramachandran",
    "mINzfREAAAAJ": "Michael Beetz",
    "5waf3bkAAAAJ": "Mei Han",
    "wR5YWC0AAAAJ": "Andrzej Szymczak",
    "gGh0i8AAAAAJ": "Anne McLaughlin",
    "dRc-rTAAAAAJ": "Yan Huang (黄艳）",
    "t6exkOAAAAAJ": "Abhishek Das",
    "_RVvnS4AAAAJ": "Yingyu Liang",
    "UwLsYw8AAAAJ": "Denny Zhou",
    "EBNa5IEAAAAJ": "Sang Michael Xie",
    "tP5IBFkAAAAJ": "Ananya Kumar",
    "NWPDSEsAAAAJ": "Andrej Risteski",
    "4a6iPeUAAAAJ": "Yining Chen",
    "4Zw1PJ8AAAAJ": "Kaidi Cao",
    "r1Fn_YsAAAAJ": "Yuping Luo",
    "FQHeASwAAAAJ": "Ekin Akyürek",
    "BUc2uq0AAAAJ": "Hong Liu",
    "NFWFaGAAAAAJ": "Nikos Arechiga",
    "XalUZEoAAAAJ": "Kefan Dong",
    "dXzqCT4AAAAJ": "Robbie Jones",
    "CM4o-cgAAAAJ": "Yifeng Lu",
    "IMkVH_8AAAAJ": "Hanxiao Liu",
    "Y4sk3aMAAAAJ": "Jerry Wei",
    "ZjuMpLoAAAAJ": "Da Huang",
    "ocPXoIkAAAAJ": "Jing Huang",
    "Sx-673sAAAAJ": "Hongyang R. Zhang",
    "tqxTaiAAAAAJ": "Aditya Bhaskara",
    "VBclY_cAAAAJ": "Yi Tay",
    "sEMrGicAAAAJ": "Naman Agarwal",
    "oTmQCFUAAAAJ": "Kaiyue Wen",
    "cZneVpUAAAAJ": "Kendrick Shen",
    "wVazIm8AAAAJ": "Dustin Tran",
    "6GpZV0YAAAAJ": "David Hall",
    "25Ha82sAAAAJ": "Ankit Garg",
    "6rQZU7MAAAAJ": "Honglin Yuan",
    "bMoauM4AAAAJ": "Shengjia Zhao",
    "ErDOPbEAAAAJ": "Margalit R Glasgow",
    "3OQplr0AAAAJ": "Albert Webson",
    "Td0j6cUAAAAJ": "Wenxuan Zhou",
    "QMkbFp8AAAAJ": "Shibani Santurkar",
    "-hW6cvgAAAAJ": "Adams Wei Yu",
    "7zp9arUAAAAJ": "Barry (Xuanyi) Dong",
    "0RvAVR4AAAAJ": "Hieu Pham",
    "ScLUQ-YAAAAJ": "Xuezhi Wang",
    "zithBbUAAAAJ": "Preetum Nakkiran",
    "Tlc4yaMAAAAJ": "Zichuan Lin",
    "KiQW8wMAAAAJ": "Jonathan Shi",
    "miPgny8AAAAJ": "Brandon M. Stewart",
    "gIH9P-8AAAAJ": "Mikhail Khodak",
    "hR9rFHgAAAAJ": "Holden Lee",
    "M1aIpoIAAAAJ": "Junwei Lu",
    "2sFj-kcAAAAJ": "Michael P. Kim",
    "hGO6cWYAAAAJ": "Roshni Sahoo",
    "kQ0HeQIAAAAJ": "Le Hou",
    "_N44XxAAAAAJ": "Andrew Kyle Lampinen",
    "vNcBx1sAAAAJ": "Xiangning Chen",
    "GaYmpIgAAAAJ": "Xuechen Li",
    "2Dab2vkAAAAJ": "Neil Band",
    "hyle4iEAAAAJ": "Fereshte Khani",
    "g9d_K0sAAAAJ": "Longbo Huang",
    "9XrWuI8AAAAJ": "Ling Pan",
    "Ek8r82kAAAAJ": "Yajun Wang",
    "BWF8wn4AAAAJ": "Bo Tang",
    "kUe1sZEAAAAJ": "Dan Garber",
    "ct2hw4UAAAAJ": "Haipeng Luo",
    "6RWbQjMAAAAJ": "Kaustubh Supekar",
    "QzqctJgAAAAJ": "Vinod Menon",
    "SFbKPCEAAAAJ": "Srikanth Ryali",
    "29B3BAgAAAAJ": "Chicheng Zhang",
    "05sMX8MAAAAJ": "Benjamin Van Roy",
    "bvDRaVcAAAAJ": "Haike Xu",
    "KMcwQtcAAAAJ": "Michael Auli",
    "f0j0K8QAAAAJ": "Elan Rosenfeld",
    "quJME0oAAAAJ": "Peng Qi",
    "j4Fshz0AAAAJ": "Yuan Zhou",
    "Atc5w-4AAAAJ": "Frederic Koehler",
    "SfwUC14AAAAJ": "Huacheng Yu",
    "WKpSlhQAAAAJ": "Xiaoming Sun",
    "ZZWygh8AAAAJ": "Nicholas Charles Landolfi",
    "70lgwYwAAAAJ": "Sashank J. Reddi",
    "fpUICd0AAAAJ": "Ching-Yao Chuang",
    "w8XocYQAAAAJ": "Khashayar Gatmiry",
    "VPyxd6kAAAAJ": "Lingxiao Wang",
    "LiH53A8AAAAJ": "Mary Wootters",
    "AfLwLQ0AAAAJ": "Nadav Cohen",
    "ss7CIgcAAAAJ": "Lunjia Hu",
    "-nzJN7oAAAAJ": "Mark Neyrinck",
    "Glo43TUAAAAJ": "Joe Silk",
    "Nmty1bkAAAAJ": "Miguel Angel Aragon Calvo",
    "rUiWchkAAAAJ": "AS Szalay",
    "2lvIrNAAAAAJ": "Zhehui Chen",
    "qvK1_5wAAAAJ": "Zaoxing Liu",
    "QJu--ysAAAAJ": "Matey Neykov",
    "uglffdcAAAAJ": "Ethan X. Fang",
    "VoyeryMAAAAJ": "Tamás Budavári",
    "wHAYz5wAAAAJ": "Nikita Ivkin",
    "4QIV0FUAAAAJ": "Pavan Aduri",
    "iojF4S0AAAAJ": "Philip Kaaret",
    "rTJTJJ4AAAAJ": "Randal Burns",
    "Ks3QdEUAAAAJ": "Raghunath Tewari",
    "luSyn1AAAAAJ": "Diptarka Chakraborty",
    "rM0Orl0AAAAJ": "Jarosław Błasiok",
    "jVrqxkYAAAAJ": "Matthias Alexander Lee",
    "xdxuN98AAAAJ": "Marc Kamionkowski",
    "Go5BcawAAAAJ": "Stephen Chestnut",
    "SIayDoQAAAAJ": "Yarin Gal",
    "aqgFQqMAAAAJ": "Carl Edward Rasmussen",
    "8erqrHcAAAAJ": "Blake Wulfe",
    "PKcjcT4AAAAJ": "Mark van der Wilk",
    "WIvjYUIAAAAJ": "Robert Fitch",
    "S47ydIgAAAAJ": "Thierry Peynot",
    "qjnBu0sAAAAJ": "Amar Shah",
    "Ek4hM10AAAAJ": "Adrian Weller",
    "hE2mTp4AAAAJ": "Alex Kendall",
    "xmUDkvQAAAAJ": "Jean Mercat",
    "E9ITYW0AAAAJ": "Panagiotis Tigas",
    "s4mZnz8AAAAJ": "Ugo Rosolia",
    "Cz-Q_IsAAAAJ": "Francesco Borrelli",
    "hX0YYUoAAAAJ": "Felix Li",
    "dnjq-FgAAAAJ": "Salah Sukkarieh",
    "ybjd-fgAAAAJ": "Haruki Nishimura",
    "gCbeGRIAAAAJ": "Charles Packer",
    "u8K7nOwAAAAJ": "Kuan-Hui Lee",
    "AYPlwA0AAAAJ": "Matthew A. Wright",
    "UQBRs7EAAAAJ": "Suneel Belkhale",
    "4MkmgXEAAAAJ": "Alen Alempijevic",
    "MbBntPgAAAAJ": "Tim GJ Rudner",
    "Cvn7Y5YAAAAJ": "Junyu Nan",
    "b15vJuEAAAAJ": "Pavel Tokmakov",
    "U9WUBC4AAAAJ": "Fernando Castañeda",
    "YJxFe1UAAAAJ": "Thomas Krendl Gilbert",
    "feURmn4AAAAJ": "Aaron J. Snoswell",
    "DSfv69oAAAAJ": "Michael Aaron Dennis",
    "wyjZbeMAAAAJ": "Cathy Wu",
    "w4UK_9kAAAAJ": "Gunshi Gupta",
    "Nuw1Y4oAAAAJ": "Igor Gilitschenski",
    "BzyVxVUAAAAJ": "Jiezhi \"Stephen\" Yang",
    "8rU1AaQAAAAJ": "Harshil Bhatia",
    "lWmGADwAAAAJ": "I. Pitas",
    "P5AJTXcAAAAJ": "Rui (Ranger) FAN",
    "ykWqS0YAAAAJ": "Nemanja Djuric",
    "JAmTk5gAAAAJ": "Masha Itkina",
    "z8GwuTgAAAAJ": "Ashkan Mirzaei",
    "zghjmDgAAAAJ": "Moshe Babaioff",
    "h6jljQQAAAAJ": "Eva Tardos",
    "AH5j40kAAAAJ": "Nate Foster",
    "di_T0vwAAAAJ": "Robert Soulé",
    "HhValEMAAAAJ": "Ashwinkumar Badanidiyuru",
    "CBUpEcQAAAAJ": "S. Matthew Weinberg",
    "xdTtK9IAAAAJ": "Nicholas JA Harvey",
    "x34kIOIAAAAJ": "Bruno Abrahao",
    "jn-B_MoAAAAJ": "Shaddin Dughmi",
    "DaDmjMMAAAAJ": "Emin Gün Sirer",
    "teS9lHAAAAAJ": "Shahar Dobzinski",
    "uNsqlqYAAAAJ": "Chris Umans",
    "EPQuuHMAAAAJ": "Larry Blume",
    "ZKeyKNgAAAAJ": "David Easley",
    "dUPre_sAAAAJ": "Filip Radlinski",
    "rD8a4hQAAAAJ": "David Shmoys",
    "gadgSR4AAAAJ": "E. Glen Weyl",
    "8sKIuAcAAAAJ": "Rad Niazadeh",
    "FxyRWlcAAAAJ": "Steven H. Strogatz",
    "OvAOTFkAAAAJ": "Parisa Jalili Marandi",
    "BexX9vYAAAAJ": "Fernando Pedone",
    "r8NO774AAAAJ": "Ron Lavi",
    "7-TwsxsAAAAJ": "Aaron Archer",
    "VhrBelcAAAAJ": "Josef Broder",
    "tEk4qo8AAAAJ": "Yisong Yue",
    "Li0F9VAAAAAJ": "Sucheta Soundarajan",
    "rDQK5tkAAAAJ": "Yogeshwer (Yogi) Sharma",
    "pIwcxfoAAAAJ": "Alexandru Niculescu-Mizil",
    "MhQPCk8AAAAJ": "nikhil r. devanur",
    "WJGqLh8AAAAJ": "Olga V. HOLTZ",
    "JUn8PgwAAAAJ": "David C. Parkes",
    "1sC6u3UAAAAJ": "Shrutarshi Basu",
    "PSh16LsAAAAJ": "Wisdom C. Agboh",
    "23uzLe0AAAAJ": "Matteo Leonetti",
    "6UYFl7cAAAAJ": "Rafael Papallas",
    "bruYeAQAAAAJ": "Robert K. Katzschmann",
    "4O4oaD0AAAAJ": "Wissam BEJJANI",
    "tal4mMkAAAAJ": "Anthony (Tony) G Cohn",
    "dgBh0UMAAAAJ": "Ross A. Knepper",
    "ppZN58sAAAAJ": "Luis Figueredo",
    "WOsQx6EAAAAJ": "Changhyun Choi",
    "-rs_IzoAAAAJ": "Michael Koval",
    "IoGj8UEAAAAJ": "Matei Ciocarlie",
    "S1jUhokAAAAJ": "Kaijen Hsiao",
    "-VtT7q4AAAAJ": "Samit Chakrabarty",
    "BaaPAVYAAAAJ": "He WANG (王鹤)",
    "OfUOpAQAAAAJ": "Daniel Ruprecht",
    "55G7VxoAAAAJ": "Gustav Markkula",
    "ugFNit4AAAAJ": "Ming Lin",
    "aVg7BRwAAAAJ": "Stephen J. Guy",
    "F9kSTM0AAAAJ": "Jamie Snape",
    "-XEZA0UAAAAJ": "Ron Alterovitz",
    "CCP2s2cAAAAJ": "Daman Bareiss",
    "kFyna0YAAAAJ": "Jason Sewall",
    "tiNiOI4AAAAJ": "David Wilkie",
    "NmJcIeEAAAAJ": "Sean Curtis",
    "2-e0jiEAAAAJ": "Dan Halperin",
    "1NyT9gQAAAAJ": "James Kuffner",
    "vh0_vJ4AAAAJ": "Léonard Jaillet",
    "nSgKwcMAAAAJ": "Rajat Shah",
    "MkztWIoAAAAJ": "Dave Ferguson",
    "CIXmtCQAAAAJ": "hengchin Yeh",
    "2fWmq-4AAAAJ": "Daniel Duckworth",
    "fIoDWp8AAAAJ": "Jack Snoeyink",
    "KilQqKYAAAAJ": "Rynson WH Lau",
    "ZlSVieAAAAAJ": "Danica Kragic",
    "KqtBi6MAAAAJ": "Marc Niethammer",
    "iJuDBhEAAAAJ": "Christopher Xie",
    "YdLELsMAAAAJ": "Tsjerk Wassenaar",
    "nzz6PQMAAAAJ": "Jan-Michael Frahm",
    "XDXw3jQAAAAJ": "Florian T. Pokorny",
    "Ga4j7UIAAAAJ": "Kam K. Leang",
    "UzTo6o4AAAAJ": "Luis G. Torres",
    "SfJ_pOYAAAAJ": "Rami Puzis",
    "t4rXchwAAAAJ": "Ariel Felner",
    "X6t18NkAAAAJ": "Roni Stern",
    "zPPcv9sAAAAJ": "Alberto Speranzon",
    "Nd6tX_kAAAAJ": "Brendan Englot",
    "-A_CtWMAAAAJ": "Shaunak D. Bopardikar",
    "0n-reRcAAAAJ": "Kyle Crandall",
    "Zjshth4AAAAJ": "Jatin Chhugani",
    "w3B9Qs8AAAAJ": "Abhinav Golas",
    "gq138e4AAAAJ": "Liang HE",
    "h-GyeogAAAAJ": "Jake J. Abbott",
    "VR8nzcUAAAAJ": "Dustin J. Webb",
    "MDIyLnwAAAAJ": "Roland Siegwart",
    "DwKuTLwAAAAJ": "Ryuichi Takanobu",
    "mWS1pY4AAAAJ": "Minlie Huang",
    "OtgZrhUAAAAJ": "Cyrus Rashtchian",
    "FDpwmgQAAAAJ": "Karthik Ganesan",
    "-CqyjXEAAAAJ": "Yingchen Xu",
    "Jwnl3v0AAAAJ": "Qinqing Zheng",
    "uErE2UUAAAAJ": "Ruiqi Zhang",
    "6ndk_nAAAAAJ": "Benjamin Plaut",
    "xwbHbUQAAAAJ": "Shibo Hao",
    "N7_xhHoAAAAJ": "Zhiting Hu",
    "teiNc0sAAAAJ": "Tianyi (Alex) Qiu",
    "a8yv0nEAAAAJ": "Xiaoyuan Zhu",
    "QwKHApEAAAAJ": "Willie Neiswanger",
    "rJjcA_YAAAAJ": "Sijun Tan",
    "P1jPSzMAAAAJ": "Minlie Huang",
    "SmGQ48gAAAAJ": "Stefan Leutenegger",
    "36qnUD4AAAAJ": "Ali Agha",
    "SRM4v2cAAAAJ": "Annie Xie",
    "r9TQ2n4AAAAJ": "Xuesu Xiao",
    "S9LHLKEAAAAJ": "David Hsu",
    "bsyOi1YAAAAJ": "Apurva Badithela",
    "Bl4SRU0AAAAJ": "Tao Qin",
    "lPh8l7QAAAAJ": "Ze Yang",
    "OUXS8doAAAAJ": "Zhiwu Lu",
    "hJgT4tYAAAAJ": "Bohang Zhang",
    "XboZC1AAAAAJ": "Zhenguo Li",
    "fbVyT0QAAAAJ": "Tiange Luo",
    "CHMpZBIAAAAJ": "Dong Wang",
    "c3PYmxUAAAAJ": "Stephen Lin",
    "tbxCHJgAAAAJ": "Ji-Rong Wen",
    "MeS5d4gAAAAJ": "Tao Xiang",
    "17_nX_kAAAAJ": "Zhou Lu",
    "y0lN_XsAAAAJ": "Wei Chen (陈薇)",
    "GkYIrlIAAAAJ": "Masashi Sugiyama",
    "SQqkcdgAAAAJ": "Kai Fan",
    "rSVIHasAAAAJ": "Zhi-Hua Zhou",
    "Bo-wyrkAAAAJ": "Mohammad Ghavamzadeh",
    "u-OHPhAAAAAJ": "Sabine Hauert",
    "F3YBJxUAAAAJ": "Josh Blum",
    "PksdgoUAAAAJ": "Xiaolin Hu",
    "L_m67ywAAAAJ": "Yaniv Romano",
    "-lKb3XwAAAAJ": "LIHUA LEI",
    "qFtP1MQAAAAJ": "Matteo Sesia",
    "P2VyO-YAAAAJ": "Chiara Sabatti",
    "ixGMcjsAAAAJ": "Shai Feldman",
    "Z-2pv_wAAAAJ": "Clara Fannjiang",
    "ogtsTE4AAAAJ": "Tijana Zrnic",
    "YdS6szoAAAAJ": "Jonathan Marchini",
    "jhPhgf4AAAAJ": "Jennifer Listgarten",
    "LYRkQhMAAAAJ": "Adam Fisch",
    "oo8QRmIAAAAJ": "Tal Schuster",
    "k5HsbdcAAAAJ": "Rina Foygel Barber",
    "XYpPTpQAAAAJ": "Amit Pal Singh Kohli",
    "xC13Kb4AAAAJ": "Eugene Katsevich",
    "Njlo7WAAAAAJ": "Lucas Janson",
    "1KaPl5wAAAAJ": "Jake A. Soloff",
    "U9EvD0wAAAAJ": "Tiffany Ding",
    "w3KgvQIAAAAJ": "Swami Sankaranarayanan",
    "qq4zSmQAAAAJ": "Karl Krauth",
    "PjQhSkgAAAAJ": "Serena Wang",
    "CPye2b4AAAAJ": "PM Aronow",
    "dXztgDYAAAAJ": "Edward H. Kennedy",
    "ktqbPscAAAAJ": "Valérie Ventura",
    "XcD1ffwAAAAJ": "Larry Wasserman",
    "xIpN5lQAAAAJ": "Pierre Boyeau",
    "gSLAdnEAAAAJ": "Nir Yosef",
    "j7Z1Zm8AAAAJ": "Wenshuo Guo",
    "UqtDdZUAAAAJ": "Celestine Mendler-Dünner",
    "dN7AziAAAAAJ": "Hui Xu",
    "iRBUTOAAAAAJ": "Mohamed Elhoseiny, Ph.D.",
    "QJZQgN8AAAAJ": "Yannis Kalantidis",
    "FO8vjQMAAAAJ": "Arslan Chaudhry",
    "l-VuKFsAAAAJ": "Yu Jiang",
    "dbWhFN4AAAAJ": "Meet Shah",
    "JFEHAwIAAAAJ": "Zhicheng Yan",
    "bel5BBcAAAAJ": "Laura Sevilla-Lara",
    "YLh7yrwAAAAJ": "Rahaf Aljundi",
    "-JiwekUAAAAJ": "Yunpeng Chen",
    "Rza8c10AAAAJ": "Thalaiyasingam Ajanthan",
    "H95HfgIAAAAJ": "Shreyank N Gowda",
    "DzI-iPQAAAAJ": "Daylen Yang",
    "UgK1my4AAAAJ": "Albert Gordo",
    "-lbtnAgAAAAJ": "Frank Keller",
    "qoFYHTMAAAAJ": "Jose MF Moura",
    "iQxXG8kAAAAJ": "Satwik Kottur",
    "OMVTRscAAAAJ": "Shih-Fu Chang",
    "KtOqcRUAAAAJ": "Xudong Lin",
    "zP9K32EAAAAJ": "Jiasen Lu",
    "nSpXpqMAAAAJ": "Suzanne Petryk",
    "AbzGfgoAAAAJ": "Vasili Ramanishka",
    "f4DpFfQAAAAJ": "Wei Qiu",
    "TV9sa6QAAAAJ": "Manohar Paluri",
    "ZdfkFuAAAAAJ": "Spencer Whitehead",
    "v1CRzeAAAAAJ": "Rama Vedantam",
    "8CVIK-UAAAAJ": "Annemarie Friedrich",
    "6bQxCusAAAAJ": "Kenneth Marino",
    "M-3cIR0AAAAJ": "Luowei Zhou",
    "g9bV-_sAAAAJ": "Jason Corso",
    "ikq9m9QAAAAJ": "Nikita Kitaev",
    "DxQiCiIAAAAJ": "Ahmed Elgammal",
    "UKIdPdYAAAAJ": "Ji Zhang",
    "h1-3lSoAAAAJ": "Mike Z. SHOU",
    "L4yEk2UAAAAJ": "Abir Das",
    "A4_gQGgAAAAJ": "David Fernández Llorca",
    "fcqkLtcAAAAJ": "Christoph Gustav Keller",
    "hD2WqqcAAAAJ": "Jae Sung (James) Park",
    "0iFtFKEAAAAJ": "Karan Desai",
    "8FWkjw8AAAAJ": "Gedas Bertasius",
    "vxQc2L4AAAAJ": "Fabio Petroni",
    "fChTW6MAAAAJ": "Spandana Gella",
    "SnQnQicAAAAJ": "Mike Lewis",
    "3f2wPekAAAAJ": "Jin-Hwa Kim",
    "sYTUOu8AAAAJ": "Byoung-Tak Zhang",
    "MYRUJkUAAAAJ": "Akash Gokul",
    "B48DDQoAAAAJ": "Will Gan",
    "k2DcM6IAAAAJ": "Vedaad Shakib",
    "HrrtgKkAAAAJ": "Chih-Yao Ma",
    "2a5XgNAAAAAJ": "Zsolt Kira",
    "7k5QSdoAAAAJ": "Ghassan AlRegib",
    "C9rsD2UAAAAJ": "Anil Batra",
    "vNAD0mAAAAAJ": "Gerhard Weikum",
    "5o88MDIAAAAJ": "Jacopo Urbani",
    "MBzLo30AAAAJ": "Kiyoon Kim",
    "wqVWJNIAAAAJ": "Tobias Braun",
    "SpAotDcAAAAJ": "Matthieu Cord",
    "2zReQdQAAAAJ": "Corentin Dancette",
    "cwGB7lwAAAAJ": "Rishabh Maheshwary",
    "UMKkDVwAAAAJ": "Boris Meinardus",
    "oOhnPUgAAAAJ": "Aditya Grover",
    "MV7LPnEAAAAJ": "Arian Hosseini",
    "L1b6JqsAAAAJ": "Nishad Singhi",
    "gAKTYtoAAAAJ": "Hritik Bansal",
    "Ual305IAAAAJ": "Davide Moltisanti",
    "nsuJs6QAAAAJ": "Adnen Abdessaied",
    "dvz7WRQAAAAJ": "Jonas Henry Grebe",
    "Yv6wq2kAAAAJ": "Mohammad Emtiyaz Khan",
    "WIpCH90AAAAJ": "Nathalie Daun",
    "FbkauMAAAAAJ": "Tobias Jan Wieczorek",
    "6C-udIUAAAAJ": "Sancho McCann",
    "HuQF6AsAAAAJ": "Haifeng Xu",
    "T4WYN6YAAAAJ": "Ahmed Elgammal",
    "kTKmpT0AAAAJ": "Yair Carmon",
    "U0_ab4cAAAAJ": "Ankit Singh Rawat",
    "cPmMoXoAAAAJ": "Andrea Goldsmith",
    "m2-OwQEAAAAJ": "Wei Xiong",
    "_flfbOQAAAAJ": "Sirui Zheng",
    "g9WLzWoAAAAJ": "Hanze Dong",
    "c8yK5XsAAAAJ": "Chenlu Ye",
    "3jS17zQAAAAJ": "Miao Lu",
    "8NamuusAAAAJ": "Shenao Zhang",
    "0VVg_R4AAAAJ": "Zhihan Liu",
    "O24CcQQAAAAJ": "Jose Blanchet",
    "QHSUy3MAAAAJ": "Rui Yang",
    "-Z7fY00AAAAJ": "Shuang Qiu",
    "twvDiW8AAAAJ": "Chengshuai Shi",
    "70LBhKcAAAAJ": "Cong Shen",
    "wmDqYvUAAAAJ": "Guhao Feng",
    "-eVum0sAAAAJ": "Jiayi Huang",
    "9RJdEXMAAAAJ": "Xinle Cheng",
    "qBy4wKcAAAAJ": "Zikang Shan",
    "nXyv100AAAAJ": "Jiyuan Tan",
    "U6BRIM4AAAAJ": "Binghui Li",
    "5GavKiQAAAAJ": "Jiachen Hu",
    "zvC19mQAAAAJ": "Csaba Szepesvari",
    "ny0ZgiQAAAAJ": "Tongyang Li",
    "2hjbResAAAAJ": "Runze Li, Eberly Family Chair in Statistics",
    "LILR85MAAAAJ": "Xun Deng",
    "Py4URJUAAAAJ": "Juho Lee",
    "y-nUzMwAAAAJ": "Yee Whye Teh",
    "_3O0RcUAAAAJ": "Seungjin Choi",
    "A20BZnQAAAAJ": "Huaxiu Yao",
    "KXNUYWgAAAAJ": "Jungtaek Kim",
    "i7eVfzwAAAAJ": "Adam R. Kosiorek",
    "f4G8d00AAAAJ": "Caroline Choi",
    "iMlmLO4AAAAJ": "Fahim Tajwar",
    "RP4Qx3QAAAAJ": "Sung Ju Hwang",
    "UWO1mloAAAAJ": "Eunho Yang",
    "UpZ41EwAAAAJ": "Wonjae Kim",
    "dsmssvcAAAAJ": "Johnathan Xie",
    "WKsaDwQAAAAJ": "Jongmin Yoon",
    "HO-fMd8AAAAJ": "Giung Nam",
    "v6U3T4wAAAAJ": "Helena Vasconcelos",
    "zkhHirIAAAAJ": "Michael S. Bernstein",
    "jdpFVlgAAAAJ": "Ari Pakman",
    "dvoF5_cAAAAJ": "Yueqi Wang",
    "yjjrGdgAAAAJ": "Wonpyo Park",
    "zrZu6GkAAAAJ": "Seanie Lee",
    "xFlasdQAAAAJ": "Jungwon Choi",
    "YY_D3XkAAAAJ": "Balhae Kim",
    "E894cQoAAAAJ": "Michelle S. Lam",
    "Xi-B5WIAAAAJ": "Yuejiang Liu",
    "nUTqrPkAAAAJ": "Maximilian Du",
    "3G2EbP4AAAAJ": "Jubayer Ibn Hamid",
    "-gscDIEAAAAJ": "Suha Kwak",
    "_0IIzxgAAAAJ": "Archit Sharma",
    "YKRiYRAAAAAJ": "Ziv Goldfeld",
    "h6-lPBsAAAAJ": "Oron Sabag",
    "ErVxNWkAAAAJ": "Paul Cuff",
    "0P1xwo0AAAAJ": "Ian H. Jermyn",
    "13Tv6dkAAAAJ": "Ayfer Ozgur",
    "XI79Mw0AAAAJ": "Jun Chen",
    "pWvrysEAAAAJ": "Alex Luedtke",
    "j0_aKI0AAAAJ": "Marco Carone",
    "ZjX0crAAAAAJ": "Peter B. Gilbert",
    "N_8WC5oAAAAJ": "Aurelien Bibaut",
    "HOzdZp0AAAAJ": "Khashayar Khosravi",
    "ZbUfUMoAAAAJ": "Hamsa Bastani",
    "dYwbc9sAAAAJ": "guido imbens",
    "UdaJi94AAAAJ": "Susan Athey",
    "GYdw0McAAAAJ": "Mayank Sharma",
    "0y38RJ8AAAAJ": "Nima Hamidi",
    "WLOrHh8AAAAJ": "Joel Goh",
    "V4OPEAgAAAAJ": "Eric Horvitz",
    "m0rXqhkAAAAJ": "Michael Gillam, MD, FACEP",
    "3y7spRQAAAAJ": "Nick Doudchenko",
    "qMDr8HUAAAAJ": "David Gamarnik",
    "CUDUMSkAAAAJ": "Karen Mack",
    "fhLHgd8AAAAJ": "Ramesh Johari",
    "4M6ky2UAAAAJ": "Chandra Nair",
    "WuEJs1AAAAAJ": "Daniel Tawfik",
    "L-ek-X4AAAAJ": "Jochen Profit",
    "D1EmzeoAAAAJ": "Tait Shanafelt",
    "lg_0u-0AAAAJ": "Ruoxuan Xiong",
    "KlrXkXkAAAAJ": "Lee H. Dicker",
    "_ZH86NYAAAAJ": "Stefanos Zenios",
    "Me9JcfgAAAAJ": "Abolfazl Ramezanpour",
    "2P8IbqoAAAAJ": "Ramki Gummadi",
    "k5eocA8AAAAJ": "J. Bryan Sexton",
    "kDjILRMAAAAJ": "Ali Reza Sharafat",
    "03JRmRcAAAAJ": "Jacqueline Vallon",
    "UvxP_J4AAAAJ": "Mohamad Kazem Shirani Faradonbeh",
    "aeKmkoUAAAAJ": "Wanning Chen",
    "W4Y0jUIAAAAJ": "Yury Makarychev",
    "mjDKAAoAAAAJ": "Mark Buyyounouski",
    "0OtX_6gAAAAJ": "John T. Leppert",
    "ScmX2AcAAAAJ": "Mark S. Squillante",
    "WhEIQD0AAAAJ": "Kapil Gupta",
    "QQUxxaIAAAAJ": "Margret Vilborg Bjarnadottir",
    "VGga3R4AAAAJ": "J. Michael Harrison",
    "nd0G8qEAAAAJ": "David Moore",
    "NT8lLwEAAAAJ": "Mark Smith",
    "AT1_prkAAAAJ": "Mark J Smith",
    "92M8xv4AAAAJ": "Kimin Lee",
    "6wwWRdEAAAAJ": "Kibok Lee",
    "ONuIPv0AAAAJ": "Yijie Guo",
    "LNUeOu4AAAAJ": "Junhyuk Oh",
    "uGDQoU0AAAAJ": "Ruben Villegas",
    "3Q8LdcYAAAAJ": "Sungryull Sohn",
    "hvr3ALkAAAAJ": "Seunghoon Hong",
    "UX-H08cAAAAJ": "Jongwook Choi",
    "0cZ_KWMAAAAJ": "Rajat Raina",
    "YxBqNw8AAAAJ": "Richard L. Lewis",
    "yPOT9K0AAAAJ": "Alexis Battle",
    "eG2NHUYAAAAJ": "Juhan Nam",
    "DIBOO50AAAAJ": "Xiaoxiao Guo",
    "xgQd1qgAAAAJ": "Roger Grosse",
    "kddKBCsAAAAJ": "Rajesh Ranganath",
    "JFEjS1QAAAAJ": "James Davidson",
    "YvYBeysAAAAJ": "Yunseok Jang",
    "iGLKl7cAAAAJ": "Jing Yu Koh",
    "vIqWvgwAAAAJ": "Dragomir Radev",
    "RjScbooAAAAJ": "Gary B. Huang",
    "IVm1gDgAAAAJ": "Ian Lenz",
    "ciH2ROgAAAAJ": "Erick Delage",
    "9aaeCToAAAAJ": "Bohyung Han",
    "H1XVLwsAAAAJ": "Benjamin Kuipers",
    "2pH8BZwAAAAJ": "Emily Mower Provost",
    "90Yb_90AAAAJ": "Yelin Kim",
    "P5eWdgsAAAAJ": "Lucy Shapiro",
    "0p-CEygAAAAJ": "Alex Teichman",
    "1Rf6sGcAAAAJ": "Min Sun",
    "tbbfR50AAAAJ": "Patrick T McGrath",
    "vduyqcMAAAAJ": "Harley H. McAdams",
    "lD5J91cAAAAJ": "Malcolm Slaney",
    "vY7MdLYAAAAJ": "Kang G. Shin",
    "ep2QZ70AAAAJ": "Marwan Mattar",
    "ywv6tDUAAAAJ": "Ryan Hoque",
    "EHSuFcwAAAAJ": "Suraj Nair",
    "1Tfui8UAAAAJ": "Michael Danielczuk",
    "6QPoYc4AAAAJ": "Jeong Oen Lee",
    "lJ_oh2EAAAAJ": "Piotr Bojanowski",
    "7UV4ET4AAAAJ": "Edouard Grave",
    "wN9rBkcAAAAJ": "Gabriel Synnaeve",
    "22TE5qkAAAAJ": "Stephen Roller",
    "OXFjRnEAAAAJ": "Lubomir Bourdev",
    "-2wyKzEAAAAJ": "Lina Mezghani",
    "qcyG7rwAAAAJ": "Karteek Alahari",
    "Ad6O4-0AAAAJ": "Adam Lerer",
    "sPTruxEAAAAJ": "Manohar Paluri",
    "U8qAL-0AAAAJ": "Benyamin Ghojogh",
    "9_Hpd5kAAAAJ": "Fakhreddine (Fakhri)  Karray",
    "eL_y80EAAAAJ": "Mark Crowley",
    "6Evj9YwAAAAJ": "Mohamed S. Kamel",
    "OBUwP_oAAAAJ": "Xiaotie Deng",
    "Yn-Lm_QAAAAJ": "Jin-Yi Cai",
    "_pPy-pAAAAAJ": "Mihalis Yannakakis",
    "pXzn2akAAAAJ": "Li-Yang Tan",
    "KFQERBwAAAAJ": "Pinyan Lu",
    "iV2sKq8AAAAJ": "Dimitris Paparas",
    "EfhUHOQAAAAJ": "Sandip Sinha",
    "jq8VoFkAAAAJ": "Xiaorui Sun",
    "aS2nvbsAAAAJ": "Jinyu Xie",
    "T2U5sGIAAAAJ": "Anup Rao",
    "FcQ1xcwAAAAJ": "Chin Ho Lee",
    "lPM8k54AAAAJ": "Anindya De",
    "NQeu1oAAAAAJ": "Ye Du",
    "mm-fpzQAAAAJ": "Timothy Sun",
    "aaGW2qwAAAAJ": "Igor Carboni Oliveira",
    "caPvMq0AAAAJ": "Martin Dyer",
    "G1KQAusAAAAJ": "David Richerby",
    "lVoOIv4AAAAJ": "Yu Cheng",
    "bsqhvmAAAAAJ": "Qiang Du",
    "P7ndQrkAAAAJ": "Xuan Sharon Di",
    "abUcBIkAAAAJ": "Paul Valiant",
    "wsLqB5UAAAAJ": "John Wilmes",
    "RfyLl28AAAAJ": "David Durfee",
    "KbVFiKYAAAAJ": "Laszlo Babai",
    "1NXsdH8AAAAJ": "Zhengyang Liu",
    "XUhsCZwAAAAJ": "Tao Jiang",
    "993eudcAAAAJ": "Heng Guo",
    "f1FwzIsAAAAJ": "Scott Sheffield",
    "yfORTKUAAAAJ": "Yuval Peres",
    "uaiskTYAAAAJ": "Lionel Levine",
    "XDrMB6AAAAAJ": "Etienne Bernard",
    "PDwwvrEAAAAJ": "Greta Panova",
    "9qVRm-AAAAAJ": "Almut Burchard",
    "AlpgbIoAAAAJ": "Jang Soo Kim",
    "6wCEmNYAAAAJ": "Dana Randall",
    "7CH_3FwAAAAJ": "Cynthia Phillips",
    "q5O284UAAAAJ": "Xin Sun",
    "QdlhnBMAAAAJ": "William E Hart",
    "wwkJvoMAAAAJ": "Uri Zwick",
    "GMZYUyQAAAAJ": "Jian Ding",
    "cabvCW8AAAAJ": "Jung-Su Ha",
    "0tWX-EMAAAAJ": "Ozgur S. Oguz",
    "HO3nVAoAAAAJ": "Daniel Haeufle",
    "MNuTR9YAAAAJ": "Valentin N. Hartmann",
    "bQKreEMAAAAJ": "Andreas Orthey",
    "SyACgDAAAAAJ": "Peter Englert",
    "iUEcoesAAAAJ": "Isabell Wochner",
    "or-t5ZcAAAAJ": "Ingmar Schubert",
    "cMHsYdcAAAAJ": "Daniel Hennes",
    "ODdBJAcAAAAJ": "Joaquim Ortiz-Haro",
    "XUQcbFAAAAAJ": "Wolfgang Hönig",
    "eV2tuR8AAAAJ": "Keyulu Xu",
    "hy-qH-cAAAAJ": "Chengtao Li",
    "E02doCkAAAAJ": "Joshua Robinson",
    "L9QufAsAAAAJ": "Jeffrey A. Bilmes",
    "wAFMjfkAAAAJ": "Weihua Hu",
    "OsP7JHAAAAAJ": "Yonglong Tian",
    "DWERCmsAAAAJ": "Ken-ichi Kawarabayashi",
    "FioDApkAAAAJ": "Matthew Staib",
    "U0egIsIAAAAJ": "Zi Wang",
    "eDHv58AAAAAJ": "Andreas Krause",
    "2_gFWe4AAAAJ": "Mozhi Zhang",
    "4v8uJrIAAAAJ": "Haggai Maron",
    "ZXCO3DMAAAAJ": "Behrooz Tahmasebi",
    "XsxZrYYAAAAJ": "David Alvarez-Melis",
    "3pyzQQ8AAAAJ": "Pushmeet Kohli",
    "l_XxJ1kAAAAJ": "Rishabh Iyer",
    "_b_LTjMAAAAJ": "Tomohiro Sonobe",
    "T_bLpqYAAAAJ": "Elsa Olivetti",
    "RbCKRPcAAAAJ": "Lin Yen-Chen",
    "Kce9W-8AAAAJ": "Hao Shen",
    "FSj_J7MAAAAJ": "Edward Kim",
    "xMvt3NEAAAAJ": "Ilija Bogunovic",
    "ZBc_WwYAAAAJ": "Ali Jadbabaie",
    "xxiTm5EAAAAJ": "Sharut Gupta",
    "WhFGh74AAAAJ": "Thien Le",
    "pZ0-BicAAAAJ": "Zach Jensen",
    "KvX7mJUAAAAJ": "Clement Gehring",
    "3f6_I8MAAAAJ": "Christopher Morris",
    "-XGXJbQAAAAJ": "Andreas Loukas",
    "iF01q24AAAAJ": "Tess Smidt",
    "QKslW6EAAAAJ": "Lingxiao Zhao",
    "9fxv1zwAAAAJ": "Adarsh Prasad",
    "H-KEzkUAAAAJ": "Michael Murphy",
    "a4D08aQAAAAJ": "Jonathan Scarlett",
    "BwaMMgoAAAAJ": "Ke Yu",
    "Zw1pfxYAAAAJ": "Li Sun",
    "x942ipYAAAAJ": "Han Zhao",
    "aP5VahUAAAAJ": "Liao Peiyuan",
    "Sou5ih0AAAAJ": "Martin Grohe",
    "yILa1y0AAAAJ": "Andrew McCallum",
    "UCDMtM0AAAAJ": "Emma Strubell",
    "fdGXVd4AAAAJ": "Haw-Shiuan Chang",
    "HOj2qUkAAAAJ": "Sheshera Mysore",
    "FTx_BNsAAAAJ": "Michael Kaufmann",
    "U80atIAAAAAJ": "Charlotte Bunne",
    "8NudxYsAAAAJ": "Jingzhao Zhang",
    "k1eaag4AAAAJ": "Yuanzhen Li",
    "1Cv6Sf4AAAAJ": "Varun Jampani",
    "T2UHRgoAAAAJ": "Sebastian Claici",
    "IgO2ThIAAAAJ": "Johannes Kirschner",
    "x63j7HEAAAAJ": "Baharan Mirzasoleiman",
    "R9MXY8wAAAAJ": "Anton Osokin",
    "Vd6RW7cAAAAJ": "Marwa El Halabi",
    "twuEPEEAAAAJ": "Zelda Mariet",
    "IYPiRoQAAAAJ": "Sebastian Curi",
    "dG7KSW0AAAAJ": "Kfir Yehuda Levy",
    "Wt0ndFIAAAAJ": "Hui Lin",
    "CRLG9UcAAAAJ": "Karalias Nikolaos",
    "NSw87QsAAAAJ": "Gal Shulkind",
    "bSpGhYcAAAAJ": "Gregory Wornell",
    "7-B7aQkAAAAJ": "Sebastian Nowozin",
    "JBGlsDoAAAAJ": "Soledad Villar",
    "yHDXov0AAAAJ": "Bharath Sriperumbudur",
    "SWVeT4AAAAAJ": "Luana Ruiz",
    "omHTV3MAAAAJ": "Ashkan Soleymani",
    "ND0FM6EAAAAJ": "Patrick Jaillet",
    "IroP0EwAAAAJ": "Pan Li",
    "mxYLn8MAAAAJ": "Yinan Huang",
    "OBBqkosAAAAJ": "Muhan Zhang",
    "UJ9-UuIAAAAJ": "Alkis Gotovos",
    "L3zNUG4AAAAJ": "Kristjan Greenewald",
    "6F90JHgAAAAJ": "Youssef Mroueh",
    "7z8NqmUAAAAJ": "Nisha Chandramoorthy",
    "3KoL3eQAAAAJ": "David Healey",
    "zGzDpuUAAAAJ": "Tobias Kind",
    "CNuyivcAAAAJ": "Thomas Butler",
    "roooUB0AAAAJ": "Mingda Li",
    "FPVUA-YAAAAJ": "KS Sesh Kumar",
    "kUcQkpMAAAAJ": "Álvaro Barbero Jiménez",
    "4NdMn_MAAAAJ": "Josip Djolonga",
    "maa1m0oAAAAJ": "Morris Yau",
    "6XorTkcAAAAJ": "Tasuku Soma",
    "fz1mq4AAAAAJ": "Bobak Kiani",
    "Bo7Y1j0AAAAJ": "Melanie Weber",
    "bs5MttgAAAAJ": "Leonid Oliker",
    "xxYMJlUAAAAJ": "Daniel Rokhsar",
    "vkWBb2wAAAAJ": "Rebekka Burkholz",
    "2SmbjHAAAAAJ": "Risto Miikkulainen",
    "h0e2kMQAAAAJ": "James A. Bednar",
    "lHI7-XoAAAAJ": "Marinos Poiitis",
    "ZZP1cXYAAAAJ": "Kartik Ahuja",
    "M9V6y-0AAAAJ": "Hamed Hassani",
    "CbGdL4cAAAAJ": "Zhi Xu",
    "nlJCSWcAAAAJ": "Sebastian Tschiatschek",
    "nHE4ylYAAAAJ": "Lin-wen hu",
    "M0gMbZMAAAAJ": "Ryotaro Okabe",
    "1uucMrsAAAAJ": "JIANKAI YU",
    "2Vt8ZUAAAAAJ": "Tongtong Liu",
    "_fVZiToAAAAJ": "Paxon Frady",
    "aDLGNI0AAAAJ": "Jonathan Li",
    "dGLTaaEAAAAJ": "Tobias Ehrenberger",
    "lS0tvhoAAAAJ": "Karen Sachs",
    "9547Qp4AAAAJ": "Alexander LeNail",
    "jUtYwE0AAAAJ": "Amit Daniely",
    "jk17mo8AAAAJ": "Jamie Smith",
    "8VPkPvUAAAAJ": "Jessica Xu",
    "4GpKQUIAAAAJ": "Polina Golland",
    "RVl8TE0AAAAJ": "Christoph Lippert",
    "mq-Vzk8AAAAJ": "Kevin K. Yang",
    "npqoAWwAAAAJ": "Stephan Günnemann",
    "zRy-zdAAAAAJ": "Adrian V Dalca",
    "ClSXZ4IAAAAJ": "Oliver Stegle",
    "v3JsjMYAAAAJ": "Karsten Borgwardt",
    "jUCiLN4AAAAJ": "Yasemin Altun",
    "coNUBLoAAAAJ": "Joshua F. Robinson",
    "ynvtzZQAAAAJ": "Kevin Huang",
    "vyteiT4AAAAJ": "Yaron Lipman",
    "n8iUBg8AAAAJ": "Balaji Krishnamurthy",
    "8HVTWNkAAAAJ": "Sumit Bhatia",
    "BdwP-3QAAAAJ": "Chris Biemann",
    "x9qzWg8AAAAJ": "Yiding Jiang",
    "bmlgkM4AAAAJ": "Maggie Makar",
    "L7lMQkQAAAAJ": "Karen Simonyan",
    "tWSGUdoAAAAJ": "Liangping Ma",
    "JrnxAZUAAAAJ": "Shouvik Ganguly",
    "PBXTVb4AAAAJ": "Hamid Saber",
    "Cya7Va8AAAAJ": "Jungwon Lee",
    "DgLEyZgAAAAJ": "Richard E Turner",
    "mxiO4IkAAAAJ": "Andriy Mnih",
    "lAp-1WEAAAAJ": "Hong Ge",
    "7bmQ4FgAAAAJ": "Steve Mann",
    "aSAS-aAAAAAJ": "Mert Pilanci",
    "rlAIMRMAAAAJ": "Wuchen Li 李务晨",
    "QfxrxDoAAAAJ": "Zaiwen Wen",
    "AaVPa5kAAAAJ": "Peng Chen",
    "lDjk14QAAAAJ": "Jonathan Lacotte",
    "T1pWaCsAAAAJ": "Tolga Ergen",
    "tgkojSIAAAAJ": "Kangkang Deng 邓康康",
    "A5vhsIYAAAAJ": "Omar Ghattas",
    "9hMb_7IAAAAJ": "Aaron Zimmerman",
    "8TkJbjgAAAAJ": "Zeyu Jia",
    "kzFmAkYAAAAJ": "Pascal Fua",
    "Mq89JAcAAAAJ": "Hongdong Li",
    "Z9gvBegAAAAJ": "Mehrtash Harandi",
    "32RHN4oAAAAJ": "Lars Petersson",
    "dhmdaoQAAAAJ": "Yinlin Hu",
    "OUTSTAYAAAAJ": "Fatemeh Saleh",
    "ptAR7tUAAAAJ": "Miaomiao Liu",
    "EX3OYP4AAAAJ": "Sabine Süsstrunk",
    "1qXJQ7cAAAAJ": "Sadegh Aliakbarian",
    "h0a5q3QAAAAJ": "Vincent Lepetit",
    "3kaiBBYAAAAJ": "Mahsa Baktashmotlagh",
    "0KyeZ2QAAAAJ": "Xuming He",
    "2maWWboAAAAJ": "Helge Rhodin",
    "o8BdwuMAAAAJ": "Zheng Dang",
    "8twuSywAAAAJ": "Pan Ji",
    "Jtmq_m0AAAAJ": "Kaicheng Yu",
    "tKlt2LgAAAAJ": "Isinsu Katircioglu",
    "g_21RKoAAAAJ": "Krishna Kanth Nakka",
    "qYLOPxoAAAAJ": "Sadeep Jayasumana",
    "j5bG8TgAAAAJ": "Krzysztof Lis",
    "p351VxAAAAAJ": "Weizhe Liu",
    "F3YYEmMAAAAJ": "Dr Deblina Bhattacharjee",
    "8uou2n4AAAAJ": "Sina Honari",
    "7PerW6IAAAAJ": "Jörg Spörri",
    "48PsswEAAAAJ": "Chen Liu",
    "3fa02HAAAAAJ": "Bugra Tekin",
    "2YYsi40AAAAJ": "Chen Zhao",
    "gXiGxcMAAAAJ": "Brian C. Lovell",
    "k4SdlbcAAAAJ": "Wei Wang",
    "pk5cKBUAAAAJ": "Aydin Varol",
    "amJQro0AAAAJ": "Lars Andersson",
    "GyvseMkAAAAJ": "Basura Fernando",
    "K2INPyYAAAAJ": "Zeeshan Hayder",
    "ATkNLcQAAAAJ": "Ian D Reid",
    "pr6rIJEAAAAJ": "Kwang Moo Yi",
    "dbggnnAAAAAJ": "Artem Rozantsev",
    "iu8ve8EAAAAJ": "Aisha khan",
    "GNBB3JQAAAAJ": "Mohammad Najafi",
    "BvxYILIAAAAJ": "Sarah Taghavi Namin",
    "BGmxwfAAAAAJ": "Jan Bednarik",
    "yMXs1WcAAAAJ": "Nick Barnes",
    "G9HyayYAAAAJ": "Shaifali Parashar",
    "nZD_5vsAAAAJ": "Erhan Gundogdu",
    "z3TC8X0AAAAJ": "Sena Kiciroglu",
    "wctJ37UAAAAJ": "Van Nguyen Nguyen",
    "Y0FLn-8AAAAJ": "Shuxuan Guo",
    "r1TJBr8AAAAJ": "Martin Jaggi",
    "n4bdAtIAAAAJ": "Claudiu Musat",
    "BENt-uEAAAAJ": "Wei Ke",
    "Ijfl2tkAAAAJ": "Róger Bermúdez-Chacón",
    "OgV3CkYAAAAJ": "Minh Dang",
    "U0JhTbAAAAAJ": "Amrollah Seifoddini",
    "Q-UjnzEAAAAJ": "Wei Zhuo",
    "kCy8JG8AAAAJ": "Tong Zhang",
    "T6h8tLcAAAAJ": "Frédéric Meyer",
    "OKZC1CYAAAAJ": "Eduard Trulls",
    "1Oofk3YAAAAJ": "Matthias Rottmann",
    "WQ0PktMAAAAJ": "Vidit",
    "nHhtvqkAAAAJ": "Timothy M. Hospedales",
    "ykFtI-QAAAAJ": "Tatiana Tommasi",
    "PXm1lPAAAAAJ": "Gabriela Csurka",
    "Pb74Fg4AAAAJ": "Christian Sciuto",
    "cIK1hS8AAAAJ": "Seungryong Kim",
    "9yQ1tQoAAAAJ": "Carl Henrik Ek",
    "VpB8NZ8AAAAJ": "Fatih Porikli",
    "cwKg158AAAAJ": "Rene Ranftl",
    "VxAuxMwAAAAJ": "Hamid Rezatofighi",
    "MILCJzAAAAAJ": "Zhichao Huang",
    "_cHRq1kAAAAJ": "Alban Desmaison",
    "fWVzdOcAAAAJ": "Bahar Aydemir",
    "vy8xXDQAAAAJ": "Weipeng Xu",
    "2Pxx8QIAAAAJ": "Hermann Blum",
    "MRCF9PwAAAAJ": "Robin Chan",
    "7cqQFSoAAAAJ": "Rudy Bunel",
    "2dvDXjkAAAAJ": "Ravi Garg",
    "B3QzwVAAAAAJ": "Engin Tola",
    "Z6gnDIEAAAAJ": "Sudipta N. Sinha",
    "J4SmwaQAAAAJ": "Wenzel Jakob",
    "ANbGE-UAAAAJ": "Sébastien Speierer",
    "nN9bxcIAAAAJ": "Carlos Becker",
    "QE9pa_cAAAAJ": "Tao LIN",
    "HzIp5_YAAAAJ": "Yang Xiao (肖洋）",
    "24OBED0AAAAJ": "Lachlan Horne",
    "TtU74NAAAAAJ": "Yixiao Ge (葛艺潇)",
    "oO53gjEAAAAJ": "Feng Zhu (朱烽)",
    "1c9oQNMAAAAJ": "Rui Zhao",
    "QQnewdYAAAAJ": "Agata Mosinska",
    "oDDqnQ4AAAAJ": "Mateusz Kozinski",
    "E9NVOBUAAAAJ": "Yiran Zhong",
    "6sWGL5wAAAAJ": "Tom Drummond",
    "X0GMj20AAAAJ": "Andrea Fossati",
    "CVVh3DIAAAAJ": "Zhigang Li",
    "HxZDDzUAAAAJ": "Appu Shaji",
    "tQnods8AAAAJ": "Tim Lebailly",
    "2l1fWEoAAAAJ": "Karttikeya Mangalam",
    "fddAbqsAAAAJ": "Yuchao Dai (戴玉超)",
    "ZaJy9J4AAAAJ": "Anastasia Remizova",
    "ocIDAto2lksC": "Anthony Davison",
    "7EBwGhIAAAAJ": "Chris McCarthy",
    "5S1kGcAAAAAJ": "Vladimir G. Kim",
    "eO2xkdMAAAAJ": "Noam Aigerman",
    "QMc-grEAAAAJ": "Siddhartha Chaudhuri",
    "KGRm0QsAAAAJ": "Okan Altingövde",
    "h-3xd3EAAAAJ": "Xuan Wang",
    "WwbRKDUAAAAJ": "Tom Joy",
    "RZ9pOY4AAAAJ": "Amir Habibian",
    "pfEoUpcAAAAJ": "Thomas Probst",
    "1TDqUuwAAAAJ": "Martin Nicolas Everaert",
    "c-ZZKpAAAAAJ": "Jochen Trumpf",
    "IE2DVpIAAAAJ": "Ciprian I. Tomoiagă",
    "yz2P_aUAAAAJ": "Edoardo Remelli",
    "_gH7-4wAAAAJ": "Mengshi Qi（齐梦实）",
    "cLDqm1AAAAAJ": "Ziqi Zhao",
    "H8tlV-oAAAAJ": "Thomas Wollmann",
    "yZS4ce8AAAAJ": "Johannes Otterbach",
    "ViYx9vMAAAAJ": "Auke Ijspeert",
    "8mvohP8AAAAJ": "Vision Robotics ANU / NICTA",
    "SXHb84wAAAAJ": "Ravi Garg",
    "X3ji--4AAAAJ": "Wei Mao",
    "q0ZUBN4AAAAJ": "Frank Yu",
    "AqST318AAAAJ": "Andrey Davydov",
    "7_JY8gkAAAAJ": "Gregory P. Meyer",
    "ncTx_QoAAAAJ": "Huahua Wang",
    "aenlXyEAAAAJ": "Fang-Chieh Chou",
    "hcVpBCIAAAAJ": "Henggang Cui",
    "E275ukwAAAAJ": "Rui Hu",
    "CRnlLm4AAAAJ": "Sidney Sida Zhang",
    "Pqd_-nkAAAAJ": "Carl Wellington",
    "ILDVin4AAAAJ": "Brian Becker",
    "DU-xHpQAAAAJ": "Carlos Vallespi-Gonzalez",
    "YFNi7tsAAAAJ": "Shangxuan Wu",
    "eov2LfUAAAAJ": "Yang Xu",
    "dVpTVwkAAAAJ": "Casey Baker",
    "B3t_szAAAAAJ": "Steven Flavell",
    "KG7Na5oAAAAJ": "Gurrein Madan",
    "d_OCVbEAAAAJ": "Ijeoma Nwabudike",
    "phTqe74AAAAJ": "Ni Ji",
    "nX-_Ou0AAAAJ": "Talya Kramer",
    "j9GCzQUAAAAJ": "Yuqing Du",
    "22LTQSMAAAAJ": "Eliza Kosoy",
    "2tt6ZJ0AAAAJ": "Alison GOPNIK",
    "WXXu26AAAAAJ": "Michael Dennis",
    "kQ-axIUAAAAJ": "Wan-Ping Lee",
    "0QtU-NsAAAAJ": "David Held",
    "c1-jq60AAAAJ": "Brice Rebsamen",
    "FGZ1CJsAAAAJ": "Andrew Stanton",
    "whu7X_kAAAAJ": "Kamelia Aryafar, Ph.D.",
    "4uaSNpYAAAAJ": "Liangjie Hong (洪亮劼)",
    "f5vdXEQAAAAJ": "Alekh Jindal",
    "aApop70AAAAJ": "Sriram Rao",
    "T_IyfqMAAAAJ": "Jose M. Faleiro",
    "9MSpWOUAAAAJ": "Kai Li",
    "dTkWR0MAAAAJ": "Qin Lv",
    "-E3hYj8AAAAJ": "Konstantin Makarychev",
    "tokXOxkAAAAJ": "Aravindan Vijayaraghavan",
    "7b858c0AAAAJ": "Andrei Broder",
    "qVuN4MIAAAAJ": "Anthony Wirth",
    "8T5VDv8AAAAJ": "Wei Dong",
    "6vXTtDQAAAAJ": "samir khuller",
    "FANRIhwAAAAJ": "Manoj Prabhakaran",
    "11tt6p4AAAAJ": "Shi Li",
    "v6PsQKIAAAAJ": "David M. Mount",
    "g3UpmeoAAAAJ": "Afonso S. Bandeira",
    "PEK-v-EAAAAJ": "Marek Karpinski",
    "L766PJkAAAAJ": "Vivek Narasayya",
    "_61pvRYAAAAJ": "Bo Brinkman",
    "CotFJJsAAAAJ": "Qinghua Liu",
    "yj2b7pgAAAAJ": "Yuanhao Wang",
    "B9jUcIgAAAAJ": "Yi Tian",
    "TtAwEMgAAAAJ": "Tiancheng Jin",
    "HjmSOFEAAAAJ": "Max Simchowitz",
    "1mDpUSgAAAAJ": "Yuan Shen",
    "pTTEiHUAAAAJ": "Chengzhi Mao",
    "EqobCqwAAAAJ": "Mingyang Liu",
    "fGv6xi0AAAAJ": "Chi-Ning Chou",
    "3JjcAnoAAAAJ": "Zelai Xu",
    "IkxViPsAAAAJ": "Juspreet Singh Sandhu",
    "QF_rhCIAAAAJ": "Anoop Deoras",
    "oD8eeUYAAAAJ": "Ning Zhang",
    "IiSNwnAAAAAJ": "Chi Wang",
    "b1y1LooAAAAJ": "Licong Lin",
    "kokpiBQAAAAJ": "Fan Chen",
    "TaF4L4EAAAAJ": "Jianqing  Fan",
    "rUcRJEkAAAAJ": "Leo Zhou",
    "mIlQ2lIAAAAJ": "Joao Basso",
    "sJI2aOYAAAAJ": "Yuhang (Will) Cai",
    "H_6RQ7oAAAAJ": "Yingbo Zhou",
    "bqP_zxYAAAAJ": "Jinghan Jia",
    "ReWNzl4AAAAJ": "Jiancheng Liu",
    "GLtCYtgAAAAJ": "Chongyu Fan",
    "C7dO_UgAAAAJ": "Sijia Liu",
    "0Fv4bikAAAAJ": "Nikhil Ghosh",
    "CxeH4uoAAAAJ": "Xuandong Zhao",
    "4kVLYxIAAAAJ": "Emily Getzen",
    "UW2Ji5MAAAAJ": "Wenlong Ji",
    "TUAzs3sAAAAJ": "Linjun Zhang",
    "BA0BaS4AAAAJ": "Jingyu Zhu",
    "jeOPodEAAAAJ": "Kazusato Oko",
    "rP3Ed1oAAAAJ": "Will Cai",
    "e0IRutEAAAAJ": "David Huang",
    "ANBocsYAAAAJ": "Tianneng Shi",
    "iTEcewwAAAAJ": "Yixiao HUANG",
    "kNH8zcgAAAAJ": "Somayeh Sojoudi",
    "M8Hz2NSNe3QC": "Ziheng Cheng",
    "vMOWEMAAAAAJ": "Daman Arora",
    "iTsZVuoAAAAJ": "Christopher Murray",
    "HmbVzpoAAAAJ": "Theo Vos",
    "ld8AkQEAAAAJ": "Harvey Whiteford",
    "M75dilYAAAAJ": "Mohsen Naghavi",
    "CJdblO4AAAAJ": "Fiona Charlson",
    "7Fl-fjIAAAAJ": "Rafael Lozano",
    "ahSpJOAAAAAJ": "Tomas Pfister",
    "-EZBCBAAAAAJ": "Sercan O. Arik",
    "iEFL4-YAAAAJ": "Stephen McAleer",
    "RhFhIIgAAAAJ": "Pierre Baldi",
    "6IkG2m0AAAAJ": "JB Lanier",
    "O7bGqjUAAAAJ": "Michael Laskey",
    "2o3QdBAAAAAJ": "Kolby Nottingham",
    "I9VWDKcAAAAJ": "Litian Liang",
    "Z64LdqQAAAAJ": "Dailin Hu",
    "Vn3L_ioAAAAJ": "Koushik Sen",
    "SMRGdi0AAAAJ": "Caroline Lemieux",
    "LQLq8eEAAAAJ": "Rohan Bavishi",
    "xPnkc80AAAAJ": "Richard Shin",
    "5f47GEsAAAAJ": "Kyungmin Kim",
    "mNwCdqwAAAAJ": "Stephen McKinley",
    "0DpK1EMAAAAJ": "Tuomas Sandholm",
    "Q06Rh6oAAAAJ": "Kevin A. Wang",
    "tVPWAKIAAAAJ": "Alexander Shmakov",
    "GXRermIAAAAJ": "Forest Agostinelli",
    "E_oZZj8AAAAJ": "Marc Lanctot",
    "d1WOhpwAAAAJ": "Ron Berenstein",
    "LOV6_WIAAAAJ": "Hannaneh Hajishirzi",
    "2yaiWZ8AAAAJ": "Prithviraj Ammanabrolu",
    "daslsUkAAAAJ": "Alane Suhr",
    "B2XPxEkAAAAJ": "William Overman",
    "DJ9puk8AAAAJ": "Ajay Tanwani",
    "YCtmdaMAAAAJ": "Yasaman Razeghi",
    "6YRoqzQAAAAJ": "Armin Karamzade",
    "FayXlTYAAAAJ": "Liam Paninski",
    "cZRgwiwAAAAJ": "Andoni Rodriguez",
    "chv2d8IAAAAJ": "Davide Corsi",
    "uwzBnJwAAAAJ": "Cesar Sanchez",
    "xksqo5gAAAAJ": "Dmitrii Krylov",
    "jm6S_kEAAAAJ": "Caleb Chuck",
    "zm4UbBYAAAAJ": "Daeyun Shin",
    "ootP9OgAAAAJ": "Stefano Carpin",
    "t7VnipMAAAAJ": "Sylvain Calinon",
    "G3eFbR0AAAAJ": "Michal Moshkovitz",
    "CSJEObYAAAAJ": "Guy Amir",
    "l53UPjoAAAAJ": "Marco Valtorta",
    "mPC6wp4AAAAJ": "Biplav Srivastava",
    "zVDNPpvMya0C": "Thomas Reeves III",
    "o-5vyEsAAAAJ": "Peter Clark",
    "cEM1a5gAAAAJ": "Bodhisattwa Prasad Majumder",
    "9e0uFr4AAAAJ": "Bhavana Dalvi Mishra",
    "_7fW--oAAAAJ": "Pooya Khajeh",
    "46EMhJMAAAAJ": "Junhan Ouyang",
    "MEowyLcAAAAJ": "Alekhya Pyla",
    "yXvXtrMAAAAJ": "Shahaf S. Shperberg",
    "eSgXTkkAAAAJ": "Neel Kant",
    "92bmh84AAAAJ": "William Paul",
    "MRkBwCQAAAAJ": "Andy Yan",
    "II-AXHYAAAAJ": "Daniel Rothchild",
    "tcCGGDsZJUsC": "Marcelo G Mattar",
    "pDyfiUEAAAAJ": "Anastasia Kiyonaga",
    "oX7L_mMAAAAJ": "Frederick Callaway",
    "uG6vN6QAAAAJ": "Zhewei Yao",
    "ig8JXwIAAAAJ": "William McMahan",
    "OAJ2PSEAAAAJ": "Joseph M. Romano",
    "-YP8MJ0AAAAJ": "Gunter Niemeyer",
    "ip9xnysAAAAJ": "Naomi Fitter",
    "Q5yf4F4AAAAJ": "Heather Culbertson",
    "L9ztLe8AAAAJ": "Jonathan Fiene",
    "R7_-IjUAAAAJ": "Ernest D. Gomez, MD, MTR",
    "lD4Yjn4AAAAJ": "Allison Okamura",
    "PgTO8q4AAAAJ": "Laurel J. Buxbaum",
    "cTIwrjoAAAAJ": "Claudio Pacchierotti",
    "IAD0fQQAAAAJ": "Hasti Seifi",
    "_ZU4B9AAAAAJ": "Hyosang Lee",
    "Oo3fRbcAAAAJ": "Huanbo Sun",
    "cTTbBOsAAAAJ": "Jeremy D. Brown",
    "b-JF-UIAAAAJ": "Georg Martius",
    "fFQTJdEAAAAJ": "Seungmoon Choi",
    "qANkJFwAAAAJ": "Karon MacLean",
    "9Trpw3gAAAAJ": "Steven Jax",
    "RA02NxsAAAAJ": "Farimah Fazlollahi",
    "3N7aVh8AAAAJ": "Yasemin Vardar",
    "Nmz0IzcAAAAJ": "Alexis E. Block",
    "mMjWcPAAAAAJ": "Domenico Prattichizzo",
    "m4fq5VoAAAAJ": "Mayumi Mohan",
    "9GnYJQkAAAAJ": "Gokhan Serhat",
    "LY8SM4IAAAAJ": "Gunhyuk Park",
    "pPcNe2EAAAAJ": "Eric M. Young",
    "ewj-IFsAAAAJ": "Netta Gurari",
    "XYtB2GUAAAAJ": "Rachael Bevill Burns",
    "glg1I70AAAAJ": "Andrew Stanley",
    "MqNK0kQAAAAJ": "William R. Provancher",
    "SDhzsXUAAAAJ": "H Juliette T Unwin",
    "6vBloKgAAAAJ": "David Gueorguiev",
    "Bdlf-Z4AAAAJ": "Michelle J Johnson",
    "GTk-bkoAAAAJ": "kyungseo park",
    "Xdnc5IMAAAAJ": "Jung Kim",
    "YLHQ1QoAAAAJ": "Benjamin A. Richardson",
    "H4XGkH0AAAAJ": "Elisabetta Ambron",
    "Qcn2vwUAAAAJ": "Maria-Paola Forte",
    "PUmV3bwAAAAJ": "Rebecca Khurshid",
    "SHO5PDkAAAAJ": "Kyle Winfree",
    "5diMRzQAAAAJ": "Amy Blank",
    "c7EMylYAAAAJ": "Jonathan Bohren",
    "NiR8zKAAAAAJ": "Hiroyuki Kajimoto",
    "mldMyOsAAAAJ": "Taku Hachisu",
    "wvMb3ccAAAAJ": "Mallory A. Jensen",
    "Nf8TQBQAAAAJ": "Michael Oppermann",
    "AxZIIccAAAAJ": "Roger Gassert",
    "VJuuzLwAAAAJ": "Christian Wallraven",
    "D3ita20AAAAJ": "Preeya Khanna",
    "8SSdKyMAAAAJ": "Hyunkyu Park",
    "kkirJKcAAAAJ": "Julian Nubert",
    "S8kPovUAAAAJ": "Behnam Khojasteh",
    "fiDP8AkAAAAJ": "Guido Caccianiga",
    "Ft3sKZ8AAAAJ": "Jessica Ip",
    "hqGaEUoAAAAJ": "Yitian Shao",
    "93hi3QcAAAAJ": "Massimiliano Di Luca",
    "eCc_7IgAAAAJ": "Tommaso Pardi",
    "JEihq_0AAAAJ": "Alan Wing",
    "KNWPax8AAAAJ": "Michael L Kochman",
    "zEUV5a8AAAAJ": "David Ferguson",
    "iGidFyoAAAAJ": "Kourosh Zareinia",
    "eiIriYIAAAAJ": "Elijah Riddle",
    "W9BOLA8AAAAJ": "Dennis Hiller",
    "P0iOgxMAAAAJ": "Erin Vasudevan",
    "ZRWlokAAAAAJ": "Joanna McGrenere",
    "DSZzGh0AAAAJ": "Saekwang Nam",
    "yfsR0k0AAAAJ": "Kenric M. Murayama",
    "x275ekUAAAAJ": "Nataliya Rokhmanova",
    "e-fdBdIAAAAJ": "Adam Spiers",
    "DO3quJYAAAAJ": "Marco Hutter",
    "uqir0mIAAAAJ": "Neha Thomas",
    "r1L_2qkAAAAJ": "Sammy Christen",
    "Plv4gH4AAAAJ": "Diar Abdlkarim",
    "TB6o7YsAAAAJ": "Eckehard Steinbach",
    "O5J1hyMAAAAJ": "Ravali Gourishetti",
    "I_ZwYZcAAAAJ": "Probal Mitra",
    "Fr9Vhe4AAAAJ": "Eni Halilaj",
    "9kzHZssAAAAJ": "Sebastian Trimpe",
    "h-9pNEkAAAAJ": "Elyse DZ Chase",
    "-hexEEAAAAAJ": "Julien Lambert",
    "lXAUVFcAAAAJ": "Jean-Louis Thonnard",
    "La3_EQwAAAAJ": "Güney Işık Tombak",
    "HosA8_UAAAAJ": "Hojin Lee",
    "LB7sjGwAAAAJ": "Cara M. Nunez",
    "eQpLy20AAAAJ": "Andres M. Bur",
    "eQGpfS8AAAAJ": "Jason Newman",
    "v7UAODsAAAAJ": "Gregory S Weinstein",
    "vf-M8-MAAAAJ": "Ecda Erol",
    "LphRgywAAAAJ": "Chun-Hao Paul Huang",
    "vPVX4TIAAAAJ": "Dimitrios (Dimitris) Tzionas",
    "Hlx9L00AAAAJ": "Peter Kulits",
    "9hk7seYAAAAJ": "Vasileios Choutas",
    "9aDxIYcAAAAJ": "Matthew R. Maltese",
    "mU40GkMAAAAJ": "CHIE TAKAHASHI",
    "QQ7lOvAAAAAJ": "Julia Bullard",
    "fCkoUvEAAAAJ": "Young-Eun Lee",
    "6zm5XD8AAAAJ": "Mark Yim",
    "0mf5NioAAAAJ": "Paulo E. Arratia",
    "LjmBUTAAAAAJ": "Tobias Engler",
    "r50jBCUAAAAJ": "Camillo Jose Taylor",
    "dX4x9z4AAAAJ": "Peter B. Shull",
    "zF5XNJgAAAAJ": "Reed Ferber",
    "PsTik-gAAAAJ": "Owen Pearl, PhD",
    "Y-6riI4AAAAJ": "Gina Adrales",
    "pdPJFIUAAAAJ": "Sergio Machaca",
    "gq_ESzoAAAAJ": "Friedrich Solowjow",
    "Lz6YRtEAAAAJ": "Zahra Taghizadeh",
    "NUtQyXAAAAAJ": "Anja Patricia Regina Lauer",
    "5KBfZzYAAAAJ": "Brian Horwich, MD, MS",
    "4CcAPCgAAAAJ": "Elisa H. Barney Smith",
    "zXESohsAAAAJ": "Daniel A. Hashimoto, MD MS",
    "NxGLVEEAAAAJ": "Carol B. Muller",
    "9cWszHUu9eAC": "VU H NGUYEN",
    "k6TEw8kAAAAJ": "Paul D Martin",
    "bWuZUsoAAAAJ": "Valerio Ortenzi",
    "NbVgjv0AAAAJ": "Shaoxiong (Shawn) Wang",
    "b-o1o7cAAAAJ": "Ruihan Yang",
    "WvtCacIAAAAJ": "Yunfei Li",
    "7oepLUoAAAAJ": "Jingwei Xu",
    "71rdofMAAAAJ": "xinyu xing",
    "KyPheRMAAAAJ": "Wenbo Guo",
    "v8JEPFgAAAAJ": "Joseph P. Near",
    "uf0D-uoAAAAJ": "Ari Juels",
    "YTokrfkAAAAJ": "Fan Zhang",
    "nLnKIikAAAAJ": "Yupeng Zhang",
    "fmwchbsAAAAJ": "Arun Ganesh",
    "VqP_wnMAAAAJ": "Arun Narayanan",
    "xt3XLjcAAAAJ": "Rogerio Feris",
    "KzSKtNUAAAAJ": "Baochen Sun",
    "1xEHKjoAAAAJ": "Vitali Petsiuk",
    "skSqdYsAAAAJ": "Marcus Gualtieri",
    "1Q4R-hIAAAAJ": "Karim Ali",
    "-GnCn1MAAAAJ": "Andreas ten Pas",
    "t2eNzb8AAAAJ": "Andrew Levy",
    "VKbBIIoAAAAJ": "Ulrich Viereck",
    "1c5IZ0QAAAAJ": "Ying Xiong",
    "t1UaPDgAAAAJ": "Timothy J. Hazen",
    "18O0OAwAAAAJ": "Mark Hasegawa-Johnson",
    "8BeTDr0AAAAJ": "Jesse Thomason",
    "6IQ8pQwAAAAJ": "Simon King",
    "U9zz4E0AAAAJ": "Stephen Dawson-Haggerty",
    "JepH3ckAAAAJ": "Daniel Scharstein",
    "hqNhUCYAAAAJ": "Juan Carlos Niebles",
    "KFhCWUcAAAAJ": "Sunil Bandla",
    "QP3QawMAAAAJ": "Daniel J. Brooks",
    "pihccVkAAAAJ": "William Boag",
    "O9hYMUUAAAAJ": "Marie-Francine Moens",
    "74THEUoAAAAJ": "Katerina Pastra",
    "e8Gzgo4AAAAJ": "Philip S. Thomas",
    "0CQMPB0AAAAJ": "Shayan Doroudi",
    "_8DDVkAAAAAJ": "Ken Koedinger",
    "Wnxq0mgAAAAJ": "Seth Flaxman",
    "7BHxn_4AAAAJ": "Gretchen A Stevens",
    "WHelTd0AAAAJ": "William Thies",
    "6S0sCwgAAAAJ": "Anna Rafferty",
    "AlTQrFcAAAAJ": "Mohammad Gheshlaghi Azar",
    "T3jkUBwAAAAJ": "Frank Dabek",
    "YCoLskoAAAAJ": "Frans Kaashoek",
    "cXT3p6cAAAAJ": "Corey Lynch",
    "sCTJI-0AAAAJ": "Ankur Handa",
    "Y7aNyh8AAAAJ": "Gerald E. Loeb",
    "LuA1j4oAAAAJ": "Ludovic Righetti",
    "_X0f2QMAAAAJ": "Xiao Hu",
    "mDtSdp0AAAAJ": "Arun Raghavan",
    "kmgzPeQAAAAJ": "Yong Li",
    "Fks4s-wAAAAJ": "Jian Yuan",
    "AZILAMsAAAAJ": "Kristofer Schlachter",
    "0tLCTHYAAAAJ": "Harris Chan",
    "6GdwHssAAAAJ": "George Papandreou",
    "rQTHsloAAAAJ": "Johnny Lee",
    "7KDSCpQAAAAJ": "Aakanksha Chowdhery",
    "6Hk7QdkAAAAJ": "Maria Attarian",
    "-c8JCbUAAAAJ": "Nori Kanazawa",
    "28sDUWIAAAAJ": "Edilson de Aguiar",
    "sI0DsP8AAAAJ": "Stefan Welker",
    "rO13CwYAAAAJ": "Adrian Wong",
    "LLnrH8IAAAAJ": "Oscar Ramirez",
    "IjJXgWAa708C": "Connor Schenck",
    "rjnJnEkAAAAJ": "Jeannette Bohg",
    "DTNZMGAAAAAJ": "Supasorn Suwajanakorn",
    "NaxShlcAAAAJ": "Bogdan Mazoure",
    "0eQjcEEAAAAJ": "Rahul Garg",
    "y_sLoXoAAAAJ": "Joey Hejna",
    "dFdEHskAAAAJ": "Negin Heravi",
    "cZzmemAAAAAJ": "Yecheng Jason Ma",
    "Lc9GwgwAAAAJ": "Vidhi Jain",
    "Craj5M0AAAAJ": "Peter Kinget",
    "9MjZO8wAAAAJ": "Adrian Wong",
    "oAD8PrkAAAAJ": "Eran Segal",
    "rR96kW0AAAAJ": "Avi Pfeffer",
    "U_EaAcgAAAAJ": "Simon Tong",
    "FsBCAfgAAAAJ": "Joseph Halpern",
    "b-GJ3QIAAAAJ": "Ronald Parr",
    "jzsx52EAAAAJ": "Ben Packer",
    "IzhtPq4AAAAJ": "Vladimir Jojic",
    "ZasL8IoAAAAJ": "Mehran Sahami",
    "qioqafgAAAAJ": "Tal Shay",
    "c4Gcje4AAAAJ": "David Vickrey",
    "XtMdGSkAAAAJ": "Praveen Srinivasan",
    "FZLHMv8AAAAJ": "Dr. Suchi Saria",
    "kEOeI2gAAAAJ": "Nimrod Megiddo",
    "117h3CAAAAAJ": "Stephen B Montgomery",
    "V8GEfeAAAAAJ": "Tianshi Gao",
    "6T1qA5AAAAAJ": "Hugh Durrant-Whyte",
    "hzPq7jUAAAAJ": "Chuong B. Do",
    "Yy4QD_AAAAAJ": "Fahiem Bacchus",
    "wP0IgaAAAAAJ": "Kevin Tang",
    "nBL0J6kAAAAJ": "Sara Mostafavi",
    "BDYIAe4AAAAJ": "James Davis",
    "-qFe-7wAAAAJ": "Yi Liu, PhD.",
    "YY7Rql4AAAAJ": "Jonathan S. Weissman",
    "9xbbxGcAAAAJ": "Christian R. Shelton",
    "OsarV_4AAAAJ": "Scott D. Boyd",
    "uX9yGmAAAAAJ": "Christian Plagemann",
    "opBkPOgAAAAJ": "Brian Milch",
    "3yJr9q4AAAAJ": "Bernhard von Stengel",
    "SdiAQPQAAAAJ": "Andrew H. Beck",
    "0BQzlisAAAAJ": "David Botstein",
    "fpT49d8AAAAJ": "Chris Piech",
    "SfDzdgEAAAAJ": "George Church",
    "n1e6LlcAAAAJ": "Corey Nislow",
    "SD46w90AAAAJ": "Guri Nina Giaever",
    "XunnVQoAAAAJ": "Huayan Wang",
    "_JFStaIAAAAJ": "Nevan Krogan",
    "D-SlUjsAAAAJ": "Aimée M. Dudley",
    "UbWVW6sAAAAJ": "Roman Yelensky",
    "vQwDZR8AAAAJ": "Barbara Stranger",
    "BFWurDEAAAAJ": "Shobha Venkataraman",
    "Bp6tvy0AAAAJ": "Daniel Hsu",
    "HDzOsYAAAAAJ": "Dean Foster",
    "bEcLezcAAAAJ": "Anima Anandkumar",
    "_30hSU8AAAAJ": "Peter Dayan",
    "V-lc8A8AAAAJ": "Matthias Seeger",
    "ttbl4FsAAAAJ": "Ambuj Tewari | अम्बुज तिवारी",
    "I15dUOwAAAAJ": "Eran Malach",
    "qULx8g8AAAAJ": "Aditya Kusupati",
    "Zqz4CQoAAAAJ": "Surbhi Goel",
    "xUUEAG4AAAAJ": "Krishna Pillutla",
    "eWfiq9MAAAAJ": "Nikhil Vyas",
    "ejsX7D0AAAAJ": "Kendall Lowrey",
    "uYVc9koAAAAJ": "Shai Shalev-Shwartz",
    "hYKcn9sAAAAJ": "Eyal Even-Dar",
    "RsicLQsAAAAJ": "Thomas P. Hayes",
    "qA3IkiwAAAAJ": "Varsha Dani",
    "Fc-5yRIAAAAJ": "Matus Telgarsky",
    "PZJIgZUAAAAJ": "Karan Singh",
    "RkuzIZMAAAAJ": "John Thickstun",
    "vlN_kRoAAAAJ": "Maryam Fazel",
    "pdvYP-kAAAAJ": "Mehran Mesbahi",
    "DKx4XFkAAAAJ": "Yi-Kai Liu",
    "yq90c58AAAAJ": "Qingqing Huang",
    "fGZMMKUAAAAJ": "John Blitzer",
    "UoATnWEAAAAJ": "Roy Frostig",
    "rjfj_8AAAAAJ": "Read Montague",
    "BWADJUkAAAAJ": "Nicolò Cesa-Bianchi",
    "Ize17HEAAAAJ": "Vatsal Sharan",
    "3bSbb20AAAAJ": "Jeff Schneider",
    "Xl4E0CsAAAAJ": "Le Song",
    "Uauc4m8AAAAJ": "Majid Janzamin",
    "9B8PoXUAAAAJ": "Deva Ramanan",
    "UK-VpDoAAAAJ": "Siddharth Suri",
    "AGnp8NAAAAAJ": "David Belanger",
    "39JcQcEAAAAJ": "Robert Schapire",
    "vu5Mw_0AAAAJ": "Paramveer Dhillon",
    "KCiDjbkAAAAJ": "Lyle Ungar",
    "8S0L-q8AAAAJ": "Nikos Karampatziakis",
    "qVaQXcoAAAAJ": "Niranjan Srinivas",
    "_QUUb-gAAAAJ": "David A. Hirshberg",
    "H-A5KBYAAAAJ": "Julie Tibshirani",
    "LW1Kw4EAAAAJ": "Erik Sverdrup",
    "WKM_BdYAAAAJ": "Xinkun Nie",
    "xsmFT2UAAAAJ": "Dmitry Arkhangelsky",
    "UZNEAF4AAAAJ": "Xu Kuang (许匡)",
    "KjZluVoAAAAJ": "Shuangning Li",
    "KH3jpkoAAAAJ": "Nikolaos Ignatiadis",
    "oC7EgKQAAAAJ": "Yuchen Hu",
    "lTmDo34AAAAJ": "Vitor Hadad",
    "AlIkUSAAAAAJ": "Julie Josse",
    "hubUU3AAAAAJ": "Suzanne de Treville",
    "duBlF_YAAAAJ": "B Efron",
    "aGvH4yMAAAAJ": "Edgar Dobriban",
    "zVSwZIAAAAAJ": "Will Fithian",
    "DHSivXEAAAAJ": "Evan Munro",
    "G77y978AAAAJ": "Omkar Muralidharan",
    "X2OmK_4AAAAJ": "Lawrence M. Wein",
    "YjS546oAAAAJ": "Arna Ghosh",
    "1CPY1LsAAAAJ": "Blake Richards",
    "Sc7qOfcAAAAJ": "Jesse H. Engel",
    "5kVcNS4AAAAJ": "Rishabh Singh",
    "TPhVfX8AAAAJ": "Naomi Saphra",
    "S2Pk9ooAAAAJ": "Anmol Gulati",
    "0dz0hyQAAAAJ": "Katsu Yamane",
    "OpFFE3cAAAAJ": "Joohyung Kim",
    "H8FJlJoAAAAJ": "Akshara Rai",
    "dJj3vR4AAAAJ": "Aaron Rovinsky",
    "KUc7JJoAAAAJ": "Lucy Xiaoyang Shi",
    "DLzuuVoAAAAJ": "Charles Xu",
    "Zau87Y0AAAAJ": "Jacob Berg",
    "c_jPvP4AAAAJ": "Ria Doshi",
    "OUpIbcQAAAAJ": "Noah D. Goodman",
    "5SF-hRsAAAAJ": "Tomer Ullman",
    "Zbo61UMAAAAJ": "Charles Kemp",
    "SZ3_FMQAAAAJ": "Kevin A Smith",
    "bTdT7hAAAAAJ": "Chris Baker",
    "SACXQKYAAAAJ": "Max Kleiman-Weiner",
    "kpcjFekAAAAJ": "Kelsey Allen",
    "d0TfP8EAAAAJ": "Tobias Gerstenberg",
    "a_OQrYoAAAAJ": "Andrew Perfors",
    "lsiZ9CsAAAAJ": "Julian Jara-Ettinger",
    "pH1PDwYAAAAJ": "nick chater",
    "szUb_isAAAAJ": "Mark Steyvers",
    "dErAioMAAAAJ": "Michael C. Frank",
    "4MrZ9zMAAAAJ": "Edward Vul",
    "MiFqJGcAAAAJ": "Konrad Paul Kording",
    "zykJTC4AAAAJ": "Steven T. Piantadosi",
    "Olalwx8AAAAJ": "Fei Xu (徐绯)",
    "zjl9R-oAAAAJ": "Hyowon Gweon",
    "HUi6F7wAAAAJ": "Patrick Shafto",
    "8OYE6iEAAAAJ": "David Blei",
    "g42kJfIAAAAJ": "Nicholas Dufour",
    "RffbjzgAAAAJ": "David Vawdrey",
    "hgUGouQAAAAJ": "George Hripcsak",
    "zwr9wPEAAAAJ": "Suzanne Bakken",
    "d96wNhsAAAAJ": "Ruth Masterson Creber",
    "RNC-GC0AAAAJ": "Gilad J. Kuperman",
    "Ik6TGDAAAAAJ": "Ahmet Korkut Belli, MD",
    "uL7NxA4AAAAJ": "Jennifer Prey Dawson, PhD",
    "OlpYP3UAAAAJ": "Giovanni Parmigiani",
    "gFAjt2kAAAAJ": "Patrick Ryan",
    "edUsNYIAAAAJ": "Krzysztof Kiryluk, MD",
    "NmlzwEMAAAAJ": "Iuliana Ionita-Laza",
    "iT366TkAAAAJ": "Tal Lorberbaum",
    "ObdsXj8AAAAJ": "Eimear Kenny",
    "ORJ4d3UAAAAJ": "Alexandre Yahi",
    "ekIw7HQAAAAJ": "Rami Vanguri",
    "AJKKzMAAAAAJ": "Mary Regina Boland, MA, MPhil, PhD, FAMIA",
    "fYarJtcAAAAJ": "Nenad Macesic",
    "Ffwbco4AAAAJ": "Sarah Collins Rossetti, RN, PhD",
    "PogsVkYAAAAJ": "Steven Feiner",
    "tjT7-uAAAAAJ": "Rebecca Schnall",
    "aYEVCBwAAAAJ": "Robert Moskovitch",
    "EzQdShoAAAAJ": "Benjamin Lebwohl",
    "BqtGVowAAAAJ": "Mollie Marian Mckillop, PhD, MPH",
    "vyD4QMUAAAAJ": "Kayla M Quinnies",
    "t1u0f5QAAAAJ": "Shubham Chandak",
    "-SuHe48AAAAJ": "Oleksandr Polozov",
    "ifK5o2UAAAAJ": "Tianze Shi",
    "LG_E-4EAAAAJ": "Weizhu Chen",
    "09kJn28AAAAJ": "Thomas Dietterich",
    "g65nv5cAAAAJ": "Nick Gravin",
    "7fQYGjcAAAAJ": "Joel Oren",
    "zXQZPnMAAAAJ": "Noam Nisan",
    "nbZ6QlsAAAAJ": "Brian W. Rogers",
    "agcYx2YAAAAJ": "Michael Molloy",
    "t9iq5TwAAAAJ": "Itai Ashlagi",
    "gnlvP_sAAAAJ": "Balasubramanian Sivan",
    "0pOgVVAAAAAJ": "Prafulla Dhariwal",
    "o_J2CroAAAAJ": "Yang Song",
    "VdlgOXoAAAAJ": "RUIQI GAO",
    "cIlDEugAAAAJ": "Shakir Mohamed",
    "MBM_oOUAAAAJ": "Ilyes Khemakhem",
    "ppYWVlYAAAAJ": "Ricardo Pio Monti",
    "xrSUChoAAAAJ": "Christos Louizos",
    "7k_1QFIAAAAJ": "Ying Nian Wu",
    "nEFU7wIAAAAJ": "Chenlin Meng",
    "ygdQhrIAAAAJ": "Robin Rombach",
    "sRId4vsAAAAJ": "Scott Gray",
    "7ov4UekAAAAJ": "Zhen Xu",
    "8osGCyAAAAAJ": "Erik Nijkamp",
    "fHsIRb0AAAAJ": "RJ Skerry-Ryan",
    "WA86ONsAAAAJ": "Eric Battenberg",
    "wLsZd9wAAAAJ": "Soroosh Mariooryad",
    "_VhMIOIAAAAJ": "Ron J Weiss",
    "sIfE5HIAAAAJ": "Geoffrey Roeder",
    "k_u5ULgAAAAJ": "Luke Metz",
    "dHUiyDkAAAAJ": "Yushun Zhang",
    "zTy9cUwAAAAJ": "Alexey A. Gritsenko",
    "9GJn5FIAAAAJ": "Sirui Xie",
    "kTZ5VE0AAAAJ": "Bowen Peng",
    "7jZjfZ8AAAAJ": "Jeffrey Quesnelle",
    "C7zfAI4AAAAJ": "Rafał Józefowicz",
    "XQJN7dsAAAAJ": "Manoj Kumar",
    "kGODZaIAAAAJ": "Arno Knobbe",
    "rBH-cpMAAAAJ": "Jay Whang",
    "JApued4AAAAJ": "Chitwan Saharia",
    "Nla9qfUAAAAJ": "William Chan",
    "wh_eLqQAAAAJ": "Flavia Sparacino",
    "lc0ARagAAAAJ": "Larry Davis",
    "knzWGD4AAAAJ": "Carson Reynolds",
    "cYkxyg0AAAAJ": "Srinivasa G Rao",
    "uCZ7fPUAAAAJ": "Biliana Kaneva",
    "x3hvdTsAAAAJ": "Daniel Wigdor",
    "j88h_roAAAAJ": "Grace Luo",
    "-x3wvW8AAAAJ": "Jinkyu Kim",
    "4YL23GMAAAAJ": "Xihui Liu",
    "0VwIiIsAAAAJ": "Andy Konwinski",
    "00M1AqQAAAAJ": "John Kubiatowicz",
    "h1XZv94AAAAJ": "Ling Huang",
    "QYsnk-cAAAAJ": "Ari Rabkin",
    "hMG_gR4AAAAJ": "Benjamin IP Rubinstein",
    "jZCCpsIAAAAJ": "Alex Kantchelian",
    "WemX9rAAAAAJ": "Minos Garofalakis",
    "urTiL7QAAAAJ": "David CULLER",
    "u4epKYoAAAAJ": "Sadia Afroz",
    "Az7XqxQAAAAJ": "XuanLong Nguyen",
    "mXJHzYkAAAAJ": "Todd D Hodes",
    "BYSy-9oAAAAJ": "Frank Austin Nothaft",
    "E-rCbqQAAAAJ": "Clifford Neuman",
    "N7kzlPoAAAAJ": "Rekha Bachwani",
    "7CohtIMAAAAJ": "Steve Gribble",
    "cUkE7OgAAAAJ": "Vaishaal Shankar",
    "lMAcwtwAAAAJ": "Devin Petersohn",
    "BOGdPa8AAAAJ": "Yanpei Chen",
    "1VHwJz0AAAAJ": "Dongho Kim",
    "bZNRLNAAAAAJ": "Chen-Nee Chuah",
    "MnsxqAcAAAAJ": "Nikita Borisov",
    "3m1zllIAAAAJ": "Matt Welsh",
    "2aqrWocAAAAJ": "Junda Liu",
    "csgUXLsAAAAJ": "Sharad Agarwal",
    "p0L7kOkAAAAJ": "Yitao Duan",
    "wsYTsIsAAAAJ": "Wilson Hsieh",
    "6Ex1MMYAAAAJ": "Carl Waldspurger",
    "bqKW7NkAAAAJ": "Chrysanthos Dellarocas",
    "1gQvWvUAAAAJ": "Alyssa Morrow",
    "g-WedwYAAAAJ": "George Kesidis",
    "sQ8u6h4AAAAJ": "Carla Brodley",
    "vth4SIcAAAAJ": "Shyhtsun Felix Wu",
    "2oclnIwAAAAJ": "Matt Bishop",
    "HvwPRJ0AAAAJ": "Vern Paxson",
    "iX1CFmYAAAAJ": "Pavel Laskov",
    "e4I7ihkAAAAJ": "Krste Asanovic",
    "sCypmFAAAAAJ": "Fabio Roli",
    "HHn7118AAAAJ": "Matthew Caesar",
    "98iA_ooAAAAJ": "Yan Chen",
    "wgNML_UAAAAJ": "Kevin Lai",
    "DDVtnHEAAAAJ": "Tal Lavian",
    "oQsObk0AAAAJ": "James Landay",
    "_K0GfAoAAAAJ": "Jeff Hammerbacher",
    "3OdbrfMAAAAJ": "Uri Laserson",
    "ox3inugAAAAJ": "Michael Linderman",
    "FsbND-sAAAAJ": "Rachel Greenstadt",
    "zOKOeG4AAAAJ": "Amoolya H. Singh",
    "3jzgrIcAAAAJ": "Klaus Wehrle",
    "0zrqo3B-66wC": "Hakim Weatherspoon",
    "yVLaR1QAAAAJ": "Martin Maas",
    "-1fU6P0AAAAJ": "Philip Reames",
    "S2OjOvYAAAAJ": "David Haussler",
    "ZFGMQsEAAAAJ": "Rahul Biswas",
    "zxzZAi0AAAAJ": "Aylin Caliskan",
    "MplR7_cAAAAJ": "Eero P Simoncelli",
    "j-2RtWUAAAAJ": "Wenlong Mou",
    "MAs0vOwAAAAJ": "Zhengya Zhang",
    "IdSxI0YAAAAJ": "Koulik Khamaru",
    "cht-q2UAAAAJ": "Po-Ling Loh",
    "3bwC_f4AAAAJ": "Jianbo Chen",
    "9ehX_58AAAAJ": "Raaz Dwivedi",
    "239ZfwgAAAAJ": "Javier Portilla",
    "lIKPJ04AAAAJ": "Vasily Strela",
    "D2K-ADYAAAAJ": "P. Brighten Godfrey",
    "oO9-6xEAAAAJ": "Emin Martinian",
    "BfDKicQAAAAJ": "Fanny Yang",
    "cHDBzPcAAAAJ": "Yuansi Chen",
    "Xs7cKMwAAAAJ": "Nhat Ho",
    "Py_StfUAAAAJ": "Andre Wibisono",
    "I5jS8ccAAAAJ": "Abhay Parekh",
    "uplepqQAAAAJ": "Reese Pathak",
    "ewdbG-IAAAAJ": "Elitza Maneva",
    "qX06pRYAAAAJ": "Arash A. Amini",
    "lEls5I8AAAAJ": "Cheng Mao",
    "4zyy7esAAAAJ": "Adityanand Guntuboyina",
    "jgr1-eEAAAAJ": "Anand Sarwate",
    "n6egtH4AAAAJ": "Narayana Santhanam",
    "xd1bW3AAAAAJ": "Eric Xia",
    "ZWV0I7cAAAAJ": "Reinhard Heckel",
    "cHN3PVYAAAAJ": "Chris J Li",
    "T99vQCsAAAAJ": "Yaqi Duan",
    "1I0ff2cAAAAJ": "Ram Rajagopal",
    "7nVGYfgAAAAJ": "Nicolas Flammarion",
    "ze5rCdwAAAAJ": "Yudong Chen",
    "5rz6jiUAAAAJ": "Dovi Poznanski",
    "fHkUYk0AAAAJ": "Joshua S. Bloom",
    "5cg_wrUAAAAJ": "Joseph W. Richards",
    "CjRMyA4AAAAJ": "Mathias Drton",
    "LZacO0sAAAAJ": "Steffen Lauritzen",
    "3prQpXgAAAAJ": "Odelia Schwartz",
    "OkOGR_8AAAAJ": "Yi-An Ma",
    "VVz2wdwAAAAJ": "Vidya Muthukumar",
    "8AXJB5QAAAAJ": "Peng Ding",
    "54bOCmQAAAAJ": "laurent jacob",
    "2KQlie4AAAAJ": "Miles E. Lopes",
    "r1cF30oAAAAJ": "Geoffrey Schiebinger",
    "qqgDCDIAAAAJ": "Johannes Lederer",
    "BBGlIGQAAAAJ": "Vladimir Kolmogorov",
    "c0yPSEYAAAAJ": "Tal Malkin",
    "r49_E2cAAAAJ": "Clifford Stein",
    "lg1fT1kAAAAJ": "Mitchell Stern",
    "Oa3Aze8AAAAJ": "Ahmed El Alaoui",
    "K4t4Rq0AAAAJ": "Fangzhou Su",
    "KwjvGLUAAAAJ": "Tanya G Roosta",
    "_21CagYAAAAJ": "Amin (Aminzadeh) Gohari",
    "yYE8Xo8AAAAJ": "Yuling Yan",
    "KNiO4pwAAAAJ": "Sara van de Geer",
    "Djtri0kAAAAJ": "Horia Mania",
    "fkDxJxcAAAAJ": "Tor Lattimore",
    "g_aM9xcAAAAJ": "Linda Zhao",
    "4806CYgAAAAJ": "Junhui (Jeff) Cai",
    "vK0-CDcAAAAJ": "Lin Xiao",
    "GoarRRwAAAAJ": "Marloes Maathuis",
    "If8AWhgAAAAJ": "Mukesh Singhal",
    "yaSMILkAAAAJ": "Qian Yang",
    "bHFAmtgAAAAJ": "Rodney Martin",
    "G-xTgkgAAAAJ": "Alice M. AGOGINO",
    "t64GpvUAAAAJ": "Aparna Dhinakaran",
    "AF6kWHUAAAAJ": "Kamalika Das, PhD",
    "ydA8Q5AAAAAJ": "Anind K. Dey",
    "ICCMAZ8AAAAJ": "Christian Koehler",
    "2GJDqawAAAAJ": "Stefano Schiavon",
    "jpq33DsAAAAJ": "tom webster",
    "_MjXpXkAAAAJ": "Mingsheng Long",
    "acmtRMAAAAAJ": "Gert Lanckriet",
    "Fl7EBc8AAAAJ": "Robert Jacobs",
    "9DXQi8gAAAAJ": "Yair Weiss",
    "YM8BRlUAAAAJ": "Daniel Wolpert",
    "iPJvBGYAAAAJ": "Nello Cristianini",
    "Bxgu5DQAAAAJ": "Jon McAuliffe",
    "nvR1mBgAAAAJ": "Ben Liblit",
    "rN2ny9kAAAAJ": "Lei Xu",
    "9EFobLUAAAAJ": "Peter Bodik",
    "M5YT8IoAAAAJ": "Zhihua Zhang",
    "MnfzuPYAAAAJ": "Tom Mitchell",
    "r31_fYQAAAAJ": "John Paisley",
    "plt2_DsAAAAJ": "William Stafford Noble",
    "6jN5vScAAAAJ": "Wei Xu",
    "fmsV6nEAAAAJ": "Mayur Naik",
    "m1qAiOUAAAAJ": "Terrence Sejnowski",
    "s1_ay2AAAAAJ": "Matthew J. Beal",
    "qKQD-2cAAAAJ": "Martin Takáč",
    "u7WiGLQAAAAJ": "Adam Paul Arkin",
    "xe7iyikAAAAJ": "Patrick Flaherty",
    "PnUH2KUAAAAJ": "Sriram Sankararaman",
    "q7FfnjgAAAAJ": "Chris HQ Ding （丁宏强）",
    "_SuhcLEAAAAJ": "Tao Li (李涛)",
    "W4SZGV8AAAAJ": "Arnaud Doucet",
    "JEEwSlQAAAAJ": "Alexandre d'Aspremont",
    "gsr-K3ADUvAC": "Christopher M. Bishop",
    "Dav2k7cAAAAJ": "Kenji Fukumizu",
    "VTGXKrYAAAAJ": "David Heckerman",
    "6h7b0fAAAAAJ": "Jennifer Dy",
    "FUqUC2oAAAAJ": "Thomas Schön",
    "r3SJcvoAAAAJ": "Neil D. Lawrence",
    "kcsbLrAAAAAJ": "Christophe Andrieu",
    "o5B39L8AAAAJ": "Donghui Yan",
    "9e7BtYsAAAAJ": "Steven E. Brenner",
    "LTL9MjwAAAAJ": "luca schenato",
    "2E448xEAAAAJ": "Massimo Franceschetti",
    "cH0pbIwAAAAJ": "Jim Pitman",
    "HHd7uewAAAAJ": "Barzan Mozafari",
    "1UU7Rh8AAAAJ": "Donglin Niu",
    "odMFlXUAAAAJ": "Mario Svirsky",
    "1KEMrHkAAAAJ": "Pinar Duygulu Sahin",
    "fKESO6sAAAAJ": "Kobus Barnard",
    "eH_c4R4AAAAJ": "Tijl De Bie",
    "pGh242UAAAAJ": "Peter Richtarik",
    "OsoQ-dcAAAAJ": "Padhraic Smyth",
    "ejWucigAAAAJ": "Claude Prablanc",
    "T3hAyLkAAAAJ": "Thomas Hofmann",
    "OPg56pYAAAAJ": "Deepayan Chakrabarti",
    "wvQmuxgAAAAJ": "Philip N. Sabes",
    "Dzh5C9EAAAAJ": "Mosharaf Chowdhury",
    "DKfEcuEAAAAJ": "Lior Pachter",
    "RhtDZvYAAAAJ": "Jyri J. Kivinen",
    "ipb9-GEAAAAJ": "Slav Petrov",
    "-p2WHtgAAAAJ": "Tamar Flash",
    "4VVgg_UAAAAJ": "Kimmen Sjolander",
    "lXYKgiYAAAAJ": "Ethem Alpaydin",
    "Zmvi6PMAAAAJ": "Amol Deshpande",
    "nPQEV0YAAAAJ": "David Rosenbaum",
    "bb_q7tYAAAAJ": "Quaid Morris",
    "nEsOOx8AAAAJ": "Dit-Yan Yeung",
    "IvgxG60AAAAJ": "Roland Dunbrack",
    "WY8DOSMAAAAJ": "William Lee",
    "bN_1u58AAAAJ": "Michael B. Wakin",
    "61k0rBQAAAAJ": "Tuan Dinh",
    "sgva3HcAAAAJ": "Kathryn B. Laskey",
    "iF1M1sIAAAAJ": "Guoli Wang",
    "A_UWzl8AAAAJ": "Gerard Bailly",
    "7HmZizkAAAAJ": "Derek Radisky",
    "wxauPrwAAAAJ": "Mark Diekhans",
    "pGgB_xAAAAAJ": "Meihong Wang",
    "S7YR2MEAAAAJ": "Aiyou CHEN",
    "V-pBZI8AAAAJ": "Benedict Paten",
    "HAf4pEoAAAAJ": "Shusen Wang",
    "aKkIMogAAAAJ": "Carlotta Domeniconi",
    "N5pB4l4AAAAJ": "Susanna Repo",
    "hfVm90AAAAAJ": "Sameer Agarwal",
    "mwpnDOYAAAAJ": "John Srouji",
    "64G5UgMAAAAJ": "Roded Sharan",
    "gC5ucdsAAAAJ": "Sameer Agarwal",
    "UKqIqRsAAAAJ": "David Baker",
    "d3JgIc8AAAAJ": "Mario Micheli",
    "T1iIhDEAAAAJ": "David Weiss",
    "T8RB_40AAAAJ": "Charles E. Grant",
    "7fONeB0AAAAJ": "Eric Vatikiotis-Bateson",
    "kde_TOYAAAAJ": "Richard Y. Chen",
    "qG1LVpQAAAAJ": "Peter Bailis",
    "AkRWtMUAAAAJ": "Donghui Wang",
    "ugSmcnoAAAAJ": "Michael C. Hughes",
    "ZngqplgAAAAJ": "Sara Mathieson",
    "juUEPSAAAAAJ": "Rhiju Das",
    "NCCdqdcAAAAJ": "Wu-Jun Li",
    "r1quzEkAAAAJ": "Michael Cafarella",
    "EjG2e0QAAAAJ": "Gunther H. Weber",
    "AY6InkoAAAAJ": "Samet Oymak",
    "udZSrkYAAAAJ": "Raghu Ramakrishnan",
    "XaFT1o4AAAAJ": "Han Liu",
    "lc7OkdAAAAAJ": "Mitsuo Kawato",
    "APiItS4AAAAJ": "Rob Schreiber",
    "2qLY2QwAAAAJ": "Siddhartha Chatterjee",
    "Bjpb27sAAAAJ": "Xiaoye Sherry Li",
    "0zQdH0oAAAAJ": "Viral B. Shah",
    "By1xdxEAAAAJ": "James W DEMMEL",
    "uXUA1pgAAAAJ": "David A. Bader",
    "huV-_rsAAAAJ": "Steven P. Reinhardt",
    "OGYs810AAAAJ": "Timothy G Mattson",
    "PjAQATEAAAAJ": "Sivan Toledo",
    "2YKaNDIAAAAJ": "Adam Lugowski",
    "quMILWkAAAAJ": "Bruce Hendrickson",
    "rGS1KaAAAAAJ": "Marshall Bern",
    "lazJixIAAAAJ": "Robert Tarjan",
    "B6OXcFoAAAAJ": "Kevin Deweese",
    "gNMqz_4AAAAJ": "Tim Davis",
    "rldfxOMAAAAJ": "Cleve Moler",
    "WeVsE1AAAAAJ": "Tom Sheffler",
    "h1VSH6UAAAAJ": "Barry W Peyton",
    "gWBoNCsAAAAJ": "Charles E. Leiserson",
    "mXwpea4AAAAJ": "Tatiana Shpeisman",
    "CcqZZqMAAAAJ": "Hans L. Bodlaender",
    "knut91AAAAAJ": "Fred JE Long",
    "MAeMisMAAAAJ": "Erik G. Boman",
    "QVBIKh4AAAAJ": "Alan Edelman",
    "BST6b8AAAAAJ": "Laura Grigori",
    "hwn3OPIAAAAJ": "Matteo Frigo",
    "bYI7VMwAAAAJ": "Kamesh Madduri",
    "QSY7ufMAAAAJ": "David Eppstein",
    "9jK5lfsAAAAJ": "Ariful Azad",
    "wIhJS60AAAAJ": "Ceren Budak",
    "edYZTEEAAAAJ": "Jean-Marc Loingtier",
    "Odh4GSYAAAAJ": "Gregor Kiczales",
    "mSK3340AAAAJ": "Anja Feldmann",
    "xrUwjlQAAAAJ": "Samuel Williams",
    "jPis1roAAAAJ": "Michael T. Heath",
    "pneVd2IAAAAJ": "thomas coleman",
    "-7oupLAAAAAJ": "Lorin Hochstein",
    "B3C4aY8AAAAJ": "V Basili",
    "1r8HluQAAAAJ": "Uzi Vishkin",
    "qCU8duAAAAAJ": "Yun Teng",
    "ShYqyygAAAAJ": "Hristo Djidjev",
    "UO7McmEAAAAJ": "TF Chan",
    "1wnZg6UAAAAJ": "Bjorn Birnir",
    "Z-Wd_x0AAAAJ": "William Pugh",
    "V7aWNcoAAAAJ": "Michel Cosnard",
    "0_aTa8YAAAAJ": "Alethea Barbaro",
    "3G79TTEAAAAJ": "Elizabeth Belding",
    "dgNqguIAAAAJ": "Stefan Karpinski",
    "kdqb_j0AAAAJ": "Doron Chen",
    "gG5PRvgAAAAJ": "Diana Franklin",
    "oXasn9EAAAAJ": "Kevin Almeroth",
    "6IxWYR0AAAAJ": "Linda Petzold",
    "7_7op_IAAAAJ": "Carlos Florensa",
    "qpBtpGsAAAAJ": "Xiaoou Tang",
    "Zb5wT08AAAAJ": "Rong Xiao",
    "UlXfwrkAAAAJ": "Jingyu Cui",
    "AjxoEpIAAAAJ": "Wei Liu, AAAS/IEEE/IAPR Fellow",
    "Y3wdd8oAAAAJ": "Mohit Gupta",
    "HC9-uqsAAAAJ": "Edward Hsiao",
    "VeXMKBoAAAAJ": "Dong Huang",
    "M59O9lkAAAAJ": "Salman Khan",
    "zvaeYnUAAAAJ": "Fahad Shahbaz Khan",
    "Mx8MbWYAAAAJ": "Munawar Hayat",
    "2yTeZ58AAAAJ": "Vinoj Jayasundara",
    "YaEJbvYAAAAJ": "Ranga Rodrigo",
    "iH2BZ8UAAAAJ": "Georgios Pavlakos",
    "CFJHvLcAAAAJ": "Hirunima Jayasekara",
    "K1CAbGwAAAAJ": "Shubham Goel",
    "sOG3L94AAAAJ": "KJ Joseph",
    "7soDcboAAAAJ": "Vineeth N Balasubramanian",
    "pbmjtZsAAAAJ": "Antonio Loquercio",
    "z28rttMAAAAJ": "Aaron Potechin",
    "7c2pTZMAAAAJ": "Peter Manohar",
    "zYhq-BEAAAAJ": "Jun-Ting Hsieh",
    "t5KSayQAAAAJ": "Prasad Raghavendra",
    "J7H4N_4AAAAJ": "Santosh Nagarakatte",
    "T5DyrYUAAAAJ": "Sebastian Burckhardt",
    "Dv1K9boAAAAJ": "Jeff Xu",
    "TfetUkcAAAAJ": "Mitali Bafna",
    "NLW1g68AAAAJ": "Sushrut Karmalkar",
    "6dFFudUAAAAJ": "Ameya Velingker | अमेय वेलिंगकर",
    "35hM-PkAAAAJ": "Pasin Manurangsi",
    "WYTugmIAAAAJ": "Ilan Komargodski",
    "GseGXPsAAAAJ": "He JIA",
    "JB1j474AAAAJ": "Deeparnab Chakrabarty",
    "mrMYnBEAAAAJ": "Rares-Darius Buhai",
    "7q_zIE0AAAAJ": "Ryuhei Mori",
    "NNJzA7MAAAAJ": "Noah Fleming",
    "vmHFZM0AAAAJ": "Ran Raz",
    "0KvXR0AAAAAJ": "Sumegha Garg",
    "GF4pITIAAAAJ": "Sidhanth Mohanty",
    "VZ6S70MAAAAJ": "Aayush Jain",
    "NfvUWXgAAAAJ": "Ruta Mehta",
    "XgA70_oAAAAJ": "Pranay Tankala",
    "l0CjtK4AAAAJ": "Zvika Brakerski",
    "rWg9lSsAAAAJ": "Ariel Schvartzman",
    "_ogM5zAAAAAJ": "Divyarthi Mohan",
    "OL6EahoAAAAJ": "Tommaso d'Orsi",
    "SMn18BwAAAAJ": "Steven Jecmen",
    "i4dDFK8AAAAJ": "Amir Nayyeri",
    "AZMV2qQAAAAJ": "Omar Alrabiah",
    "GixQBggAAAAJ": "Pengda  Liu",
    "FfXcEGMAAAAJ": "Aravind Gollakota",
    "qXzIytoAAAAJ": "Brian Hu Zhang",
    "TlpsH9cAAAAJ": "Swaprava Nath",
    "BkDCPiIAAAAJ": "palash dey",
    "lfJmfM0AAAAJ": "Alon Rosen",
    "00roCOMAAAAJ": "Misha Ivkov",
    "MCZpAkEAAAAJ": "Andrej Bogdanov",
    "PxsyxMsAAAAJ": "David Munhá Correia",
    "5ReVSa8AAAAJ": "Eshan Chattopadhyay",
    "5ZTO0uMAAAAJ": "Madhur Tulsiani",
    "YVrGTe8AAAAJ": "Goutham Rajendran",
    "RQg7790AAAAJ": "Prashanti Anderson",
    "T8AsZ1sAAAAJ": "Lucas Pesenti",
    "50__r6EAAAAJ": "Andrew Lin",
    "JgqpX0oAAAAJ": "Chenggang Wu",
    "U42j5MkAAAAJ": "Surender Baswana",
    "RAt7zSUAAAAJ": "Danny Dolev",
    "Wjs7DOoAAAAJ": "Ori Shental",
    "tpMNnPwAAAAJ": "Benny Pinkas",
    "MNqdSZcAAAAJ": "Elad Yom-Tov",
    "VRR8fGoAAAAJ": "Ittai Abraham",
    "s1PgoeUAAAAJ": "Nitish Srivastava",
    "TMimDRoAAAAJ": "Yao-Hung Hubert Tsai",
    "7qXxyJkAAAAJ": "Zhilin Yang",
    "8ys-38kAAAAJ": "William W. Cohen",
    "1MSpdmQAAAAJ": "Devendra Singh Chaplot",
    "A33FhJMAAAAJ": "Manzil Zaheer",
    "aka4LuAAAAAJ": "Yichuan Charlie Tang",
    "twWX2LIAAAAJ": "Andrew Gordon Wilson",
    "nm3liowAAAAJ": "Sergey Plis",
    "vgzrOK4AAAAJ": "Jacob Goldberger",
    "uBFV6SUAAAAJ": "David Mimno",
    "WjCG3owAAAAJ": "Chris J. Maddison",
    "ICNU7sAAAAAJ": "Yaodong Zhang",
    "ESRugcEAAAAJ": "Scott Lundberg",
    "RhUcYmQAAAAJ": "Keith Ross",
    "rHF25YEAAAAJ": "Mehdi SM Sajjadi",
    "OcownLgAAAAJ": "Klaus Greff",
    "xaOPd1YAAAAJ": "Kamil Ciosek",
    "A7-xkvcAAAAJ": "Yiming Zhang",
    "6U3IGtEAAAAJ": "Minghua Liu",
    "bHsjbLwAAAAJ": "Katja Hofmann",
    "ttJ9AWAAAAAJ": "Robert Loftin",
    "cx_Kg8MAAAAJ": "Che Wang",
    "01je3ewAAAAJ": "Shuang Liu",
    "nxd3mDcAAAAJ": "Sharad Vikram",
    "UmyrEtcAAAAJ": "Sicun Gao",
    "3KF3AIMAAAAJ": "Yuzhe Qin",
    "EF-SzEUAAAAJ": "Kenny Song",
    "uHDiAKQAAAAJ": "Evelyn Xiao-Yue Gong",
    "xD-wj_0AAAAJ": "Jiachen Li",
    "ca_O-WQAAAAJ": "LF Abbott",
    "GjCIDGQAAAAJ": "Peter Y. Wang",
    "q39nzokAAAAJ": "Mukund Sundararajan",
    "4UvZdF8AAAAJ": "John Guibas",
    "Nt9r1_IAAAAJ": "Boris Hanin",
    "hrI8aH8AAAAJ": "Guangyu Robert Yang",
    "uOfp1TEAAAAJ": "Vadim Gorin",
    "Wlq5rZEAAAAJ": "Isil Dillig",
    "urQ9fNgAAAAJ": "Yu Feng",
    "tUrNjFcAAAAJ": "Ian D. Kretz",
    "hEUk48QAAAAJ": "Hanzhi Liu",
    "SzgX3_MAAAAJ": "Anders Miltner",
    "DWWFQkkAAAAJ": "Junrui Liu",
    "JzK8uYAAAAAJ": "Roy R. Lederman",
    "IjXnDdoAAAAJ": "Zhichao Wang",
    "HYrDojkAAAAJ": "Matthew Russo",
    "g66HTn4AAAAJ": "Alexander Varchenko",
    "5NAFTkAAAAAJ": "Tadashi Fukami",
    "5Zf13ZsAAAAJ": "Kaoru Tsuji",
    "Gp90OAUAAAAJ": "Promit Ghosal",
    "mSn1TVMAAAAJ": "Xavier Carreras",
    "edh9Nv4AAAAJ": "Franco M. Luque",
    "Tarh6WoAAAAJ": "Pranava Madhyastha",
    "Oa4qUz8AAAAJ": "Audi Primadhanty",
    "P-md_yYAAAAJ": "Matthias Gallé",
    "zXsQ3CkAAAAJ": "Carme Torras",
    "pW3nxkUAAAAJ": "Raphael Bailly",
    "gZGtgS4AAAAJ": "Sicco Verwer",
    "e0nmxyIAAAAJ": "Adrià Recasens",
    "sE3j8joAAAAJ": "Arnau Ramisa",
    "3_2o8EgAAAAJ": "Germán Ferrero",
    "G2EJz5kAAAAJ": "Christos Kozyrakis",
    "LlfHFqUAAAAJ": "Anurag Khandelwal",
    "eQvG-qoAAAAJ": "João Carreira",
    "mSw8KfIAAAAJ": "Francisco Romero",
    "e4MjcOEAAAAJ": "Eric Jonas",
    "hNQoeOYAAAAJ": "Qian Li",
    "swf47vcAAAAJ": "Κostis Kaffes",
    "whNDkmMAAAAJ": "Ganesh Ananthanarayanan",
    "ribzpr4AAAAJ": "K Gopinath",
    "SbYoEmQAAAAJ": "Chiranjib Bhattacharyya",
    "rmsIyGMAAAAJ": "Marco Tulio Ribeiro",
    "EnCwNycAAAAJ": "Arvind Krishnamurthy",
    "KzESVKwAAAAJ": "Luis Ceze",
    "nd8lQQIAAAAJ": "Christos Faloutsos",
    "AgyW_90AAAAJ": "Dafna Shahaf",
    "ct67_F8AAAAJ": "Jeanne M. VanBriesen",
    "Y28Kt7kAAAAJ": "Mark Paskin",
    "8O3h4_cAAAAJ": "Ajit Paul Singh",
    "-e6KzSUAAAAJ": "Khalid El-Arini",
    "LgAp4-oAAAAJ": "Tyler B. Johnson",
    "sOzdfjYAAAAJ": "Alexandra Meliou",
    "Yipk0X4AAAAJ": "Amarjeet Singh",
    "tzbfgcMAAAAJ": "Fabio Gagliardi Cozman",
    "CZaDvPgAAAAJ": "Branislav Kveton",
    "mY6IzuYAAAAJ": "Eric P Krotkov",
    "W8f0d6oAAAAJ": "Giuseppe Loianno",
    "ztwMmHEAAAAJ": "Jonathan Fink",
    "x5Ig8xMAAAAJ": "Subhrajit Bhattacharya",
    "Bh8bGCYAAAAJ": "M. Ani Hsieh",
    "lfPTD18AAAAJ": "Edward Steager",
    "faO82gYAAAAJ": "Yash Mulgaonkar",
    "hpbQN-AAAAAJ": "Jaydev P. Desai",
    "2kwHHWMAAAAJ": "Miloš Žefran",
    "6Vt1qbwAAAAJ": "Aveek K Das",
    "rh0ubaUAAAAJ": "James Keller",
    "u8Q0_xsAAAAJ": "Shaojie Shen",
    "qWrXkPwAAAAJ": "Mario Fernando Montenegro Campos",
    "I7RhPnIAAAAJ": "Rafael Fierro",
    "EL7zNHcAAAAJ": "Joel M Esposito",
    "mWhnaCkAAAAJ": "John Spletzer",
    "gd8q19oAAAAJ": "Guilherme AS Pereira",
    "bO45VHYAAAAJ": "Ben Grocholsky",
    "-6ws0MoAAAAJ": "Luiz Chaimowicz",
    "4Urexvi1sIcC": "Konstantinos Karydis",
    "hI8nho4AAAAJ": "Daniel Mellinger",
    "xCYHonIAAAAJ": "Jonathan Berant",
    "m1wmXdgAAAAJ": "Alon Brutzkus",
    "qWDmIgIAAAAJ": "Fernando Pereira",
    "LXu_gVkAAAAJ": "Ori Ram",
    "WTlgnYkAAAAJ": "Nir Rosenfeld",
    "cSTLkv8AAAAJ": "Terry Koo",
    "tWI9Pw8AAAAJ": "Edo Cohen-Karlik",
    "hh5nOn4AAAAJ": "Yoav Wald",
    "fsqz49kAAAAJ": "Moshe Raboh",
    "dEbld0EAAAAJ": "Talya Meltzer",
    "WAgx2UsAAAAJ": "Gal Shachaf",
    "PZVd2h8AAAAJ": "Omer Levy",
    "K-6ujU4AAAAJ": "Yonatan Belinkov",
    "zbRUiLgAAAAJ": "Marina Meila",
    "vcJ4hAkAAAAJ": "Yuan Zhang",
    "OBLWtdcAAAAJ": "Shahar Azulay",
    "Dkf39REAAAAJ": "Eran Stark",
    "-9X2XCkAAAAJ": "Menachem Fromer",
    "gypv57sAAAAJ": "Oran Lang",
    "GMVxiYgAAAAJ": "Michal Yarom",
    "VJZj2MsAAAAJ": "Yuval Atzmon",
    "IoVlb40AAAAJ": "Tahira Naseem",
    "g2uay50AAAAJ": "Tao Lei",
    "pEDJ-8cAAAAJ": "Vadim Kantorov",
    "r4-NZhwAAAAJ": "Eilif B. Muller",
    "W3lyJF8AAAAJ": "Henry Markram",
    "JDhMq3kAAAAJ": "Idan Segev",
    "6sI8lowAAAAJ": "Mickey London",
    "sikKD7UAAAAJ": "Srikanth Ramaswamy",
    "vACm0-YAAAAJ": "Eyal Gal",
    "h8W0ppcAAAAJ": "Choon Hui Teo",
    "Tb0ZrYwAAAAJ": "Alex Smola",
    "DNPqaH0AAAAJ": "Amarnag Subramanya",
    "k2FuJZAAAAAJ": "Michael Ringgaard",
    "TXHN2DMAAAAJ": "Nevena Lazic",
    "J4Kj7EIAAAAJ": "Adi Haviv",
    "sJKiJQwAAAAJ": "Yuval Kirstain",
    "viFEu_8AAAAJ": "Eli Brosh",
    "cwXx4EQAAAAJ": "Hang Gao",
    "sQHdOycAAAAJ": "Eilon Vaadia",
    "QY-earAAAAAJ": "Kristian Kersting",
    "JArbMQcAAAAJ": "Felix Creutzig",
    "4QZmEqsAAAAJ": "Avia Efrat",
    "0ECOF7cAAAAJ": "Elad Segal",
    "5Il-agMAAAAJ": "Elad Mezuman",
    "LBi1V04AAAAJ": "Veronica (Nika) Latcinnik",
    "JUpvud8AAAAJ": "omer goldman",
    "NQgRwKAAAAAJ": "Koby Crammer",
    "UXYmnbgAAAAJ": "Ofir Bibi",
    "xGXNsCMAAAAJ": "Eric D. Young",
    "2DzkuhQAAAAJ": "Itay Asher",
    "KA4xjHMAAAAJ": "moshe abeles",
    "R0kl_BUAAAAJ": "Aviv Shamsian",
    "uCoRgGgAAAAJ": "Drorit Neumann",
    "0J0n7sEAAAAJ": "Ofir Pele",
    "WBeDvikAAAAJ": "Michael Werman",
    "AcACRTAAAAAJ": "Roei Sarussi",
    "Q8cTLNMAAAAJ": "Chetan Arora",
    "1GPDFqsAAAAJ": "Achiya Jerbi",
    "X1-ovCkAAAAJ": "Tova Milo",
    "2BnMsFIAAAAJ": "Daniel Deutch",
    "cDeKq4YAAAAJ": "Eric Balkanski",
    "j-MBXNMAAAAJ": "Yaron Singer",
    "_woZ79YAAAAJ": "Aharon Birnbaum",
    "D7WH8ksAAAAJ": "Mor Nitzan",
    "jZwEDZoAAAAJ": "Nataly Brukhim",
    "HDHOS0QAAAAJ": "Fei Sha",
    "0rskDKgAAAAJ": "Yoav Goldberg",
    "wGG1voYAAAAJ": "Tomer Koren",
    "VW1EQEQAAAAJ": "Hillel Taub-Tabib",
    "pYasE5oAAAAJ": "Yehuda Afek",
    "AEr-DWcAAAAJ": "Erez Peterfreund",
    "jac_HrgAAAAJ": "Roy Mor",
    "DZtU6KMAAAAJ": "Orna Steinberg Shemer",
    "_u7raRkAAAAJ": "Vahid Kazemi",
    "n6GdeeIAAAAJ": "Kojin Oshiba",
    "3chExUsAAAAJ": "Deborah Cohen",
    "HGNZ1fkAAAAJ": "Yu-Xiang Wang",
    "OcbAkXwAAAAJ": "Ming Yin",
    "o0qh7IUAAAAJ": "Aadyot Bhatnagar",
    "QHS_pZAAAAAJ": "Edo Liberty",
    "RqwU8xsAAAAJ": "Dylan J. Foster",
    "6vH92bAAAAAJ": "Soham Phade",
    "EOlowBUAAAAJ": "Michael J Curry",
    "sOna0qoAAAAJ": "Qijia Jiang",
    "h3SuftsAAAAJ": "Runyu (Cathy) Zhang 张润玉",
    "qdGelXoAAAAJ": "Na Li",
    "ONNif60AAAAJ": "Ben Krause",
    "m9UbvIkAAAAJ": "Sally Goldman",
    "IoEBLNYAAAAJ": "Yuheng Zhang",
    "-gNBIsYAAAAJ": "Jiacheng Guo",
    "k7aMOCsAAAAJ": "Prafulla Kumar Choubey",
    "eIRG81YAAAAJ": "Nazneen Rajani",
    "BaRpQ_kAAAAJ": "Wenhao Liu",
    "PBvgcC8AAAAJ": "Shiyu Wang",
    "sgBB2sUAAAAJ": "Ran Xu",
    "TaJND9YAAAAJ": "Ning Yu",
    "uqnNle0AAAAJ": "Yihao Feng",
    "1G4GV2EAAAAJ": "Chien-Sheng (Jason) Wu",
    "igOOdBAAAAAJ": "Alexander Trott",
    "9hQJrpAAAAAJ": "Dingwen Kong",
    "mbB3MRIAAAAJ": "Yaniv Taigman",
    "oyWpVa8AAAAJ": "Vlad Morariu",
    "jLraLTcAAAAJ": "Jinghai Rao",
    "nZ8H4nsAAAAJ": "Luca Dall'Asta",
    "li9AfUUAAAAJ": "Fabrizio Altarelli",
    "HU1K_zsAAAAJ": "Martin Weigt",
    "0dmJuNkAAAAJ": "Anna Paola Muntoni",
    "3srp-NYAAAAJ": "Alejandro Lage Castellanos",
    "nmk3WzgAAAAJ": "Alessandro Ingrosso",
    "-dnFl2MAAAAJ": "Fabio Mazza",
    "STRrPekAAAAJ": "Indaco Biazzo",
    "xW33QlMAAAAJ": "Giovanni Catania",
    "PtwDrzEAAAAJ": "Roberto Mulet",
    "WZS_HSgAAAAJ": "Serena Bradde",
    "bWwpLA4AAAAJ": "Farbod Kayhan",
    "4R7_wW8AAAAJ": "Chris Sander",
    "U7HnX4kAAAAJ": "Anil Korkut",
    "nuyBlicAAAAJ": "Martin L Miller",
    "NcaZT3wAAAAJ": "Nicholas Paul Gauthier",
    "10Fx1a4AAAAJ": "Shao-shan Carol Huang",
    "jaGNt2sAAAAJ": "Nurcan Tuncbag",
    "9vumoioAAAAJ": "Nicolas Brunel",
    "b4jR5hkAAAAJ": "Stefano Crotti",
    "3qdaPdoAAAAJ": "francesca tria",
    "sQJvy4MAAAAJ": "Matteo Mariani",
    "Zu68lkkAAAAJ": "Daniele De Martino",
    "QOf1klMAAAAJ": "Ernesto Ortega",
    "045mm50AAAAJ": "Maria Refinetti",
    "Kq272_MAAAAJ": "Stefano SARAO MANNELLI",
    "x9K3GqkAAAAJ": "Antoine Baker",
    "j0_fn9oAAAAJ": "Anthony Gitter",
    "LeiGXOsAAAAJ": "Joël Chavas",
    "IrMKDiIAAAAJ": "Demian Battaglia",
    "MFnbrRUAAAAJ": "Pan Zhang",
    "54urtxYAAAAJ": "Guido Montorsi",
    "hbuu7K8AAAAJ": "Laura Foini",
    "QQtOq2EAAAAJ": "Louise Budzynski",
    "vNUpyxYAAAAJ": "Matthias Heinemann",
    "z9EcgygAAAAJ": "John Realpe Gomez",
    "58GAc80AAAAJ": "Isaac Pérez Castillo",
    "po4ztO4AAAAJ": "Rafael Díaz Hernández Rojas",
    "zc2F3G0AAAAJ": "Mattia Tarabolo",
    "4SlTNbAAAAAJ": "Jacopo Bindi",
    "uDZcR0IAAAAJ": "Thomas Barthel",
    "NqZETvUAAAAJ": "Paolo Giaccone",
    "np0OO24AAAAJ": "Carla Fabiana Chiasserini",
    "CmQzsisAAAAJ": "Emilio Leonardi",
    "0RdaaYsAAAAJ": "Alireza Alemi, PhD",
    "BH86MaMAAAAJ": "Roberto Fontana",
    "eyqQt3gAAAAJ": "Davide Zoccolan",
    "NLBZuoEAAAAJ": "Yoshiyuki Kabashima",
    "YOrLGyAAAAAJ": "Kinshuk Jerath",
    "TJWNYtMAAAAJ": "Morteza Zadimoghaddam",
    "KmlxiiyySHIC": "Jeffrey D Shulman",
    "q3EGms8AAAAJ": "Hamid Mahini",
    "7H3sBioAAAAJ": "Marjan Baghaie",
    "oqDCDOoAAAAJ": "wilfred amaldoss",
    "EyrM4VIAAAAJ": "Bita Hajihashemi",
    "HBtozdUAAAAJ": "Greg Corrado",
    "8RVWMycAAAAJ": "Kilian Weinberger",
    "DGr0fVoAAAAJ": "Zhiqiang Shen",
    "fHfJh9cAAAAJ": "Hanzi Mao",
    "n44GlFcAAAAJ": "Jianguo Li",
    "wCZbouUAAAAJ": "Mingjie Sun",
    "7cuwdr8AAAAJ": "Rohit Girdhar",
    "saWjkLQAAAAJ": "Anna Bair",
    "MKRyHXsAAAAJ": "Yurong Chen",
    "SEbcuNoAAAAJ": "Zhiqiu Xu",
    "F3yrMeUAAAAJ": "Yida Yin",
    "iwBPvPIAAAAJ": "Sanghyun Woo",
    "lA7ylt4AAAAJ": "Zechun Liu",
    "jxpBMwwAAAAJ": "Alaaeldin El-Nouby",
    "QOO8OCcAAAAJ": "Mannat Singh",
    "XO8T-Y4AAAAJ": "Geoff Pleiss",
    "s4rghcgAAAAJ": "Arnav Chavan",
    "AI2f3dkAAAAJ": "Tianhong Li",
    "sao1OhsAAAAJ": "Jiachen Zhu",
    "k5FaRwcAAAAJ": "Yunyang Xiong",
    "6GhZedEAAAAJ": "John W. Lambert",
    "bQTXRrAAAAAJ": "Hungju Wang",
    "mWpu_ooAAAAJ": "Marios Savvides",
    "9P9QcckAAAAJ": "Koustuv Sinha",
    "VAiqiv4AAAAJ": "David Fan",
    "Nsxpe_kAAAAJ": "Deepak Gupta",
    "H02tLFMAAAAJ": "Kirill Vishniakov",
    "-SgpaF8AAAAJ": "Kwang-Ting (Tim) Cheng",
    "lHSilFcAAAAJ": "Joseph Jin",
    "i2II0XIAAAAJ": "Victor Kai Wang",
    "foERjnQAAAAJ": "Zelin Zang",
    "jF4dPZwAAAAJ": "Yang You",
    "c0WCD74AAAAJ": "Yu-Kun Zhou",
    "uToGtIwAAAAJ": "Xiaoqian Shen",
    "SaH2yWMAAAAJ": "Hu Xu",
    "qimMoFIAAAAJ": "Guanhua Wang",
    "QSTd1oUAAAAJ": "Sharon Li",
    "dcVFn08AAAAJ": "Mikolaj Kasprzak",
    "eJ9qDHMAAAAJ": "Kevin Esvelt",
    "cOrfSmIAAAAJ": "Michael Riis Andersen",
    "tYgN0GsAAAAJ": "Aki Vehtari",
    "pOtmLl0AAAAJ": "Alun Lloyd",
    "9rUGrpwAAAAJ": "Jeffrey W Miller",
    "A3ObLdMAAAAJ": "Manushi Welandawe",
    "3ZTrRpAAAAAJ": "Akash Kumar Dhaka",
    "X9fd67gAAAAJ": "Alejandro Catalina",
    "gxnzvbYAAAAJ": "Ethan Alley",
    "UBrbfSwAAAAJ": "Brian L Trippe",
    "fDc1X1YAAAAJ": "Eftychios A. Pnevmatikakis",
    "6AA-AAcAAAAJ": "Måns Magnusson",
    "gc62BUIAAAAJ": "Rahnama Rad, Kamiar",
    "mezKJyoAAAAJ": "Cynthia Rudin",
    "djheYP0AAAAJ": "Tin D. Nguyen",
    "TX6achUAAAAJ": "Masanao Yajima",
    "e8kIbEYAAAAJ": "Aaron Chevalier",
    "Xsn1VsgAAAAJ": "Joshua David Campbell",
    "e5P8uR4AAAAJ": "Ben Wellner",
    "d4yNzXIAAAAJ": "Frank Wood",
    "RZ2KXioAAAAJ": "Ryan Giordano",
    "5V7VFi8AAAAJ": "Rachael Meager",
    "Wx-ul64AAAAJ": "William T. Stephenson",
    "GWkwfBIAAAAJ": "Kaizheng Wang",
    "Qg7x7M8AAAAJ": "Tian Tong",
    "9SITlKwAAAAJ": "Yuepeng Yang",
    "T7Wa3GQAAAAJ": "Jing Zhang",
    "O-3bc_EAAAAJ": "Dominik Janzing",
    "tQuQ1FwAAAAJ": "Gunnar Rätsch",
    "kBQ4VvEAAAAJ": "Jonas Peters",
    "Fg7TcjEAAAAJ": "Sebastian Mika",
    "wQanfTIAAAAJ": "Francesco Locatello",
    "RGoypN4AAAAJ": "Kun Zhang",
    "G4MBruQAAAAJ": "Robert C. Williamson",
    "M7wYOSMAAAAJ": "Michael Hirsch",
    "CHO-UV8AAAAJ": "Olivier Bousquet",
    "15GNzKcAAAAJ": "Moritz Grosse-Wentrup",
    "E2z5uYsAAAAJ": "Krikamol Muandet",
    "Mdr6wjUAAAAJ": "Zhijing Jin",
    "Mxio0T8AAAAJ": "Jeremy Hill",
    "UcuXmuwAAAAJ": "Manuel Gomez Rodriguez",
    "HvVqBmkAAAAJ": "Koji Tsuda",
    "5Hbi5WYAAAAJ": "Dr. Thomas Navin Lal",
    "Td3_kIwAAAAJ": "Joris M. Mooij",
    "TA2fG64AAAAJ": "Stefan Harmeling",
    "6EOl3hAAAAAJ": "Julius von Kügelgen",
    "Nbq6kI0AAAAJ": "Michel Besserve",
    "1iE2ykkAAAAJ": "John Shawe-Taylor",
    "Tpp9ZjoAAAAJ": "Mrinmaya Sachan",
    "ZGmFXNsAAAAJ": "Bernd Pichler",
    "Ycos9pAAAAAJ": "Malte J Rasch",
    "n4k9D7QAAAAJ": "Ilya Tolstikhin",
    "tEGxO60AAAAJ": "Matthias Hofmann",
    "NxrQ794AAAAJ": "Felix Wichmann",
    "pnypNygAAAAJ": "Arash Mehrjou",
    "w0x8vm0AAAAJ": "Niels Birbaumer",
    "mW9BcgsAAAAJ": "Olivier Bachem",
    "RuvHkikAAAAJ": "Ralf Herbrich",
    "5XqE3bQAAAAJ": "Florian Steinke",
    "1Kr0r4kAAAAJ": "Soeren Sonnenburg",
    "34eszXwAAAAJ": "Heinrich H. Bülthoff",
    "hwm5E4kAAAAJ": "Clark Glymour",
    "7EWrVYIAAAAJ": "Manuel Wüthrich",
    "VgzYS6IAAAAJ": "Detlef Weigel",
    "JdZ8DWwAAAAJ": "Luigi Gresele",
    "miAQ1Q4AAAAJ": "Wolf Kienzle",
    "yXdK2wYAAAAJ": "Andre Elisseeff",
    "FKOqtF8AAAAJ": "Jakob Macke",
    "pqpxh7IAAAAJ": "Jean-Philippe Vert",
    "6SDclmEAAAAJ": "Jason Farquhar",
    "hcmW-W0AAAAJ": "David W Hogg",
    "ZMzzV7cAAAAJ": "Christian J. Schuler",
    "oMqNbfsAAAAJ": "Daniel Foreman-Mackey",
    "5vj1VV8AAAAJ": "Zhikun Wang",
    "xA3Jd5gAAAAJ": "David Balduzzi",
    "cy9mlN0AAAAJ": "Gabriele Schweikert",
    "JmiTDLIAAAAJ": "Jakob Zscheischler",
    "8FfrHw0AAAAJ": "Fernando Perez-Cruz",
    "xTi3ouAAAAAJ": "Wolfgang Rosenstiel",
    "UeG5w08AAAAJ": "Philipp Hennig",
    "SfBBevUAAAAJ": "Guillaume Charpiat",
    "AQ_I-NkAAAAJ": "Hannes Nickisch",
    "0wIdMGEAAAAJ": "Kim, Kwang In",
    "6uTDJ9oAAAAJ": "Martin Vingron",
    "i_QJztcAAAAJ": "Femke Nijboer",
    "vyppxW4AAAAJ": "Dun Wang",
    "jYCidWgAAAAJ": "Volker Blanz",
    "tDgCcOEAAAAJ": "Andrew Blake",
    "BpJTboUAAAAJ": "Holger Fröhlich",
    "ofMZr0IAAAAJ": "Cheng Soon Ong",
    "WgAGy7wAAAAJ": "TOMASO POGGIO",
    "ugH_Wg4AAAAJ": "Christian Walder",
    "J3lauQ4AAAAJ": "Marcel Schmittfull",
    "ji0zVjgAAAAJ": "Norman Warthmann",
    "hLTZTG4AAAAJ": "Daniel H. Huson",
    "133WpF8AAAAJ": "Magnus Nordborg",
    "UWyyLgIAAAAJ": "Markus Schmid",
    "BkbnIxkAAAAJ": "Jan Lohmann",
    "k8Rs4JcAAAAJ": "Mike Tipping",
    "5XdNlE8AAAAJ": "Georg Zeller",
    "KsErEBoAAAAJ": "Frank Jäkel",
    "3D-xyjwAAAAJ": "Arnulf BA Graf",
    "xpwMxy8AAAAJ": "Fabian Sinz",
    "e25-lgUAAAAJ": "Christina Leslie",
    "vtxXpVAAAAAJ": "S. Sandeep Pradhan",
    "ynDHUwkAAAAJ": "Rohit Puri",
    "gUO59T8AAAAJ": "KV Rashmi (Rashmi Vinayak)",
    "zqUO0GMAAAAJ": "Igor Kozintsev",
    "RYvdtGcAAAAJ": "Prakash Ishwar",
    "mpxO5ycAAAAJ": "sameer pawar",
    "BCBUDMcAAAAJ": "Zixiang Xiong",
    "lD3PMh0AAAAJ": "Chuohao Yeo",
    "gX8LBfgAAAAJ": "Douglas L. Jones",
    "oBeXCuQAAAAJ": "P Vijay Kumar",
    "EWZ9_SAAAAAJ": "Venkatesan Nallampatti Ekambaram",
    "GP64q_kAAAAJ": "Jan Rabaey",
    "vn4dQRIAAAAJ": "Xiao (Simon) Li",
    "LBaBtwcAAAAJ": "Upamanyu Madhow",
    "aHV3aDMAAAAJ": "M. Kivanc Mihcak",
    "uMbvldoAAAAJ": "Hao Zhang",
    "1FwhEVYAAAAJ": "Cormac Herley",
    "IQ3hcw4AAAAJ": "Michael Gastpar",
    "H4XxdCQAAAAJ": "Julius Kusuma",
    "MB7c7CYAAAAJ": "Brian S Krongold",
    "oAbEdzUAAAAJ": "Animesh Kumar",
    "MCClSvsAAAAJ": "Alyson \"Allie\" K. Fletcher",
    "nM77MX0AAAAJ": "Vivek K Goyal",
    "iBl-QgEAAAAJ": "Gerald Friedland",
    "M7edePUAAAAJ": "Kang-Won Lee",
    "fzSHXS8AAAAJ": "Sundeep Rangan",
    "I5gPRf0AAAAJ": "Krish Eswaran",
    "WzEQ9QwAAAAJ": "Minghua Chen",
    "rPU7fz0AAAAJ": "Jean Walrand",
    "hSUP-4cAAAAJ": "Raja Sengupta",
    "Rz9p0poAAAAJ": "Vinay Vaishampayan",
    "9rYWg2EAAAAJ": "Nan Ma",
    "ja7P1hQAAAAJ": "Matthieu Finiasz",
    "SzZRlcMAAAAJ": "Mario Lučić",
    "m7LvuTkAAAAJ": "Sylvain Gelly",
    "gMndACUAAAAJ": "David Lazer",
    "sjaZfDIAAAAJ": "Esteban Moro",
    "ZkBTPkUAAAAJ": "Manuel Cebrian",
    "btoec6QAAAAJ": "Deb Roy",
    "BIdzgnwAAAAJ": "Yaniv Altshuler",
    "5Ius69wAAAAJ": "Daniel Olguin Olguin",
    "QQHXl9sAAAAJ": "Fabio Pianesi",
    "jUP4oi8AAAAJ": "Erez Shmueli",
    "yKCX2IUAAAAJ": "Iyad Rahwan",
    "LVJtdoEAAAAJ": "Yves-Alexandre de Montjoye",
    "E8RwuIIAAAAJ": "Wei Pan",
    "sR_OzkgAAAAJ": "Nicholas A. Christakis",
    "-pyztDMAAAAJ": "Tanzeem Choudhury",
    "H4CPLUQAAAAJ": "Nadav Aharony",
    "VA5VktEAAAAJ": "Guy Zyskind",
    "E2uuNVoAAAAJ": "Sinan Aral",
    "Ef1hJ8IAAAAJ": "Vivek K. Singh",
    "sp2np4oAAAAJ": "Wen Dong",
    "Fqw9o84AAAAJ": "Noshir Contractor",
    "OPgnjWQAAAAJ": "Burcin Bozkaya",
    "wvkUbiUAAAAJ": "Sune Lehmann",
    "vsj2slIAAAAJ": "Albert-László Barabási",
    "7OW6weoAAAAJ": "Michael Macy",
    "0TJZPj0AAAAJ": "Lada Adamic",
    "nrEeeY4AAAAJ": "Abdullah Almaatouq",
    "VNAFWVoAAAAJ": "Myron Gutmann",
    "ruZDm9QAAAAJ": "Yuval Elovici",
    "0ee8P-cAAAAJ": "Albert Ali Salah",
    "4swDjMAAAAAJ": "Kenji Mase",
    "zMqwIkIAAAAJ": "Marshall Van Alstyne",
    "zGuKpwQAAAAJ": "Arkadiusz Stopczynski",
    "OiVOAHMAAAAJ": "Hong Z Tan",
    "hI5X8UYAAAAJ": "Jacopo Staiano",
    "L4CxNO8AAAAJ": "Peter Gloor",
    "l5Qki4cAAAAJ": "Sai T Moturu",
    "ew0G1PIAAAAJ": "Andrey Bogomolov",
    "xWI4K4sAAAAJ": "Mriganka Sur",
    "pkqB2vEAAAAJ": "Laura Radaelli",
    "LXqHtF4AAAAJ": "Oren Lederman, PhD",
    "P1OaUP8AAAAJ": "Alfred Bruckstein",
    "XOnfkHIAAAAJ": "Alessandro Vinciarelli",
    "gzPWwdIAAAAJ": "Olaf Sporns",
    "HnQ2gqMAAAAJ": "Juyang Weng",
    "kQsnsxIAAAAJ": "Thomas Malone",
    "2UQAbkEAAAAJ": "Christopher Chabris",
    "Uf9gm4oAAAAJ": "Oz Nathan",
    "qF806HcAAAAJ": "Alex Rutherford",
    "ifNxpgkAAAAJ": "Blake Shaw",
    "lqyGZpQAAAAJ": "Erik Brynjolfsson",
    "umA5NjcAAAAJ": "François Bérard",
    "z-JV1e8AAAAJ": "Michael Fire",
    "jJfKig8AAAAJ": "Pål Sundsøy",
    "cmC2pp0AAAAJ": "Hervé Bourlard",
    "vZHanWgAAAAJ": "Gerard George",
    "244WszUAAAAJ": "Jared R Curhan",
    "I58-jXkAAAAJ": "Lynn Wu",
    "c_E3E4kAAAAJ": "Katayoun (Kate) Farrahi",
    "e0VXX60AAAAJ": "Tarjei S. Mikkelsen",
    "ohJ44iMAAAAJ": "Nitin Sawhney",
    "K2KcQKAAAAAJ": "Riley Crane",
    "LU1OKMoAAAAJ": "Daniel Oster",
    "-_hcRfgAAAAJ": "Joseph Paradiso",
    "C8S84g8AAAAJ": "Jan-Olof Eklundh",
    "PRhJB5EAAAAJ": "Kai Fischbach",
    "PBEbCgUAAAAJ": "Detlef Schoder",
    "PKz_a_AAAAAJ": "Fosca Giannotti",
    "5efz6osAAAAJ": "Dino Pedreschi",
    "XZkvOTEAAAAJ": "Kevin W. Bowyer",
    "_3_Y0xQAAAAJ": "Daniel Gatica-Perez",
    "eOkGKuUAAAAJ": "Jacob Strom",
    "a7VNhCIAAAAJ": "Dimitris N. Metaxas",
    "sgLeMy8AAAAJ": "Taemie Kim",
    "_PhjyLoAAAAJ": "Olivier Faugeras",
    "VizsSmEAAAAJ": "Charles R. Dyer",
    "g-_ZXGsAAAAJ": "Anil K. Jain",
    "vy5ngwUAAAAJ": "Alessandro Cappelletti",
    "oH1ScJkAAAAJ": "Massimo Zancanaro",
    "j9jEMToAAAAJ": "Robert Bergevin",
    "3wXH93MAAAAJ": "Irving Biederman",
    "3RnBcXAAAAAJ": "Kyriaki Kalimeri",
    "WOAlvmoAAAAJ": "Katherine Heller",
    "YPq3ax4AAAAJ": "Claudio Pinhanez",
    "tVEF11EAAAAJ": "Dinesh Babu Jayagopi",
    "_CNYi6MAAAAJ": "Gourab Ghoshal",
    "lYqgwwwAAAAJ": "Juan Carlos Barahona, PhD.",
    "tqMGsJwAAAAJ": "kazuo yano",
    "ebrNfPAAAAAJ": "Dirk Helbing",
    "2dTrwzAAAAAJ": "Michael A. Casey",
    "uMNLanIAAAAJ": "Sohan Dsouza",
    "qHG9PB8AAAAJ": "Max A Little",
    "NcT-9asAAAAJ": "Paul Wicks",
    "Ii7P2QQAAAAJ": "Avinash Kak",
    "js-mvgoAAAAJ": "Thorsten Staake",
    "e7VI_HcAAAAJ": "Aaron Clauset",
    "9CEJKM4AAAAJ": "Elgar Fleisch",
    "YjTldCMAAAAJ": "KJ Ray Liu",
    "em7o4kwAAAAJ": "Vikram Krishnamurthy",
    "pk-yb_kAAAAJ": "Josef Kittler",
    "h20U9WcAAAAJ": "Patrick J. Flynn",
    "Ddfev5kAAAAJ": "Shimon Edelman",
    "EFB9ZuwAAAAJ": "Rangachar Kasturi",
    "zNOQUvkAAAAJ": "Elenna R Dugundji",
    "13xdkw4AAAAJ": "WIllem-Jan van den Heuvel",
    "PGcc-RIAAAAJ": "John R Anderson",
    "h4i4fh8AAAAJ": "Ben Shneiderman",
    "LWw60SgAAAAJ": "Victoria Stodden",
    "1H4HuCkAAAAJ": "Daniel PW Ellis",
    "HMnF6i0AAAAJ": "Robert M. Haralick",
    "sGPW9jAAAAAJ": "Susan Brennan",
    "xViwZ0QAAAAJ": "Carlo Tomasi",
    "5mSnPlwAAAAJ": "Giulio Sandini",
    "Z962IGQAAAAJ": "hari sundaram",
    "gpyHJmcAAAAJ": "Steve Maybank",
    "REL2gIEAAAAJ": "Joe Marks",
    "2XCryp4AAAAJ": "Alessandro Acquisti",
    "WsfNeKYAAAAJ": "Harry Halpin",
    "wRYM4qgAAAAJ": "BS Manjunath",
    "tetdudUAAAAJ": "Lalana Kagal",
    "wS0qP_MAAAAJ": "Hiroshi ISHII",
    "nI2URPQAAAAJ": "Simon Johnson",
    "5VJ4YPQAAAAJ": "David C Hogg",
    "eyYubf4AAAAJ": "Jukka-Pekka \"JP\" Onnela",
    "3PqA9YYAAAAJ": "Rahman Oloritun",
    "HoPI8pIAAAAJ": "Harris R. Lieberman",
    "45uuU3gAAAAJ": "Aamena Alshamsi",
    "3UZwE6sAAAAJ": "Piotr Sapiezynski",
    "wgh5X-AAAAAJ": "Mark Bocko",
    "-Tpv_CMAAAAJ": "Jeffrey Hausdorff",
    "BnxU9TEAAAAJ": "Vipin Kumar",
    "qLTEaEIAAAAJ": "Virender Kumar",
    "J6VzIsYAAAAJ": "Sebastian Schnorf",
    "5zUqCuUAAAAJ": "Maryam Zubair Butt",
    "_GzrRGwAAAAJ": "Rosanne Liu",
    "JBnyLicAAAAJ": "Andrea Madotto",
    "pPB_WK0AAAAJ": "Tandy Warnow",
    "7ezIRWQAAAAJ": "Prof. Mike Steel",
    "aNFzP50AAAAJ": "Martin Nowak",
    "Av2Iuu0AAAAJ": "Hristina Hristova",
    "fy2TEm4AAAAJ": "Peter Schmid",
    "qnxPT9UAAAAJ": "Laurette Tuckerman",
    "EAB-RKIAAAAJ": "Neil O'Connell",
    "sFmN6RkAAAAJ": "Sagi Snir",
    "uxSj18QAAAAJ": "Siavash Mirarab",
    "4JsyJK8AAAAJ": "Shankar Bhamidi",
    "D4rBbksAAAAJ": "Lam Si Tung Ho",
    "zgfSvoYAAAAJ": "Cécile Ané",
    "qcrM7F4AAAAJ": "Zhe Xu",
    "_BPdgV0AAAAJ": "Tsung-Yi Lin",
    "bHn29ScAAAAJ": "Alexander Kirillov",
    "dYu68U8AAAAJ": "Vincent Rabaud",
    "T94KevkAAAAJ": "Eric Mintun",
    "krvptckAAAAJ": "Xavier P. Burgos-Artizzu",
    "QBsEFvMAAAAJ": "Hao Fang",
    "TU_s3xAAAAAJ": "Dayu Lin",
    "w4fhxasAAAAJ": "Ron Appel",
    "duSEbnYAAAAJ": "Andrew Tulloch",
    "BU6f7L4AAAAJ": "Pedro O. Pinheiro",
    "5FwRvZAAAAAJ": "Raj Prateek Kosaraju",
    "HzfkQy4AAAAJ": "Boris Babenko",
    "cMDQJIoAAAAJ": "Garrison Cottrell",
    "5na92fcAAAAJ": "Margaret Mitchell",
    "vTWuk1gAAAAJ": "Rupesh Kumar Srivastava",
    "_mMeOTgAAAAJ": "Joon Hee Han",
    "w3fqzIYAAAAJ": "Woonhyun Nam",
    "JETJjHoAAAAJ": "Bowen Cheng",
    "_UJsz3AAAAAJ": "Dennis Park",
    "oa78zHUAAAAJ": "Aaron B. Adcock",
    "EqJw1-4AAAAJ": "Sergey Zagoruyko",
    "8qNEbiUAAAAJ": "Sam Gross",
    "fanhk-gAAAAJ": "Jeffery L Tallon",
    "reEAEWsAAAAJ": "Oren Rippel",
    "cXPscXUAAAAJ": "KATHERINE L NARR",
    "B2YRmGgAAAAJ": "Arthur Toga",
    "zh0Raz8AAAAJ": "Thomas J. Fuchs",
    "b4MEVXsAAAAJ": "Annegret Falkner",
    "Gd9HQn2UsNoC": "Dhruv Mahajan",
    "XTaVGqYAAAAJ": "Quentin Duval",
    "Qwm6ZOYAAAAJ": "Vaibhav Aggarwal",
    "oQyYH9kAAAAJ": "Achal Dave",
    "g558OVoAAAAJ": "Kristin Branson",
    "ufzrGe8AAAAJ": "Nakul Verma",
    "D9XHjNAAAAAJ": "David C. Hall",
    "zFafsk8AAAAJ": "Andrew D. Steele",
    "uH5WA4oAAAAJ": "Yan Zhu",
    "-9yiQMsAAAAJ": "Priya Goyal",
    "YAtwLpwAAAAJ": "Michael F Cohen",
    "E42NyKUAAAAJ": "Johannes Kopf",
    "wnhU3KoAAAAJ": "Yuanyuan Yuan",
    "OeDgxpgAAAAJ": "Wenting Zheng",
    "kIsmHd4AAAAJ": "Zhibo Liu",
    "E31PR1oAAAAJ": "Thomas Schneider",
    "jffu6mUAAAAJ": "Jinhao Zhu",
    "xuSbmssAAAAJ": "Lixu Wang",
    "19qSWk8AAAAJ": "Guy Kortsarz",
    "8AkztB0AAAAJ": "Jon Lee",
    "NLLMDCkAAAAJ": "Heiko Röglin",
    "QP1aKqcAAAAJ": "Jose Correa",
    "4Gw0GgEAAAAJ": "Moslem Kazemi",
    "wAKowxMAAAAJ": "Andreas S. Schulz",
    "PJQPzgcAAAAJ": "Kamesh Munagala",
    "vVvbU7oAAAAJ": "Michael Schapira",
    "hIq09eUAAAAJ": "Bernhard Haeupler",
    "dHU6M_4AAAAJ": "Mallesh M. Pai",
    "2FbkAzYAAAAJ": "Manuela M. Veloso",
    "jM1cT4QAAAAJ": "Tucker Balch",
    "qnwjcfAAAAAJ": "Peter Stone",
    "Iia81jAAAAAJ": "Randeep Bhatia",
    "6bRXWXEAAAAJ": "Ang Li",
    "KoXUMbsAAAAJ": "Ting Chen",
    "l-xu2w0AAAAJ": "Marco Baroni",
    "BMgUIC0AAAAJ": "Angeliki Lazaridou",
    "83HL5FwAAAAJ": "Thomas Kipf",
    "nkTd_BIAAAAJ": "Emiel Hoogeboom",
    "GW9vw8UAAAAJ": "Zilong Huang",
    "QX7xv3UAAAAJ": "Lihe Yang",
    "hR4G6hoAAAAJ": "Xiao Ma",
    "AP_Yd6wAAAAJ": "Kaixin Wang",
    "tE1oVQ4AAAAJ": "Yang Yue（乐洋）",
    "DdCAbWwAAAAJ": "Daquan Zhou",
    "wYDbtFsAAAAJ": "Tianyu Pang",
    "O_4qYW4AAAAJ": "Minghuan Liu",
    "BGONmkIAAAAJ": "Min Lin",
    "47n-0mwAAAAJ": "Xingyi Zhou",
    "BHlY8ewAAAAJ": "Tianwei  Yin",
    "Zi5KiDsAAAAJ": "Yael Pritch",
    "z-oSdPoAAAAJ": "Federico Perazzi",
    "K-k47CMAAAAJ": "Brady Zhou",
    "6_U35tAAAAAJ": "Yue Zhao",
    "_0aMq28AAAAJ": "R. Manmatha",
    "uxk0GmUAAAAJ": "Markus Gross",
    "yvhVTMgAAAAJ": "Manuel Lang",
    "3sbdEW4AAAAJ": "Nayan Singhal",
    "oyh-YNwAAAAJ": "Qi-Zhi Cai",
    "--YtdhAAAAAJ": "Hexiang (Frank) Hu",
    "KyNwquYAAAAJ": "Jeffrey Ouyang-Zhang",
    "Ro6enEEAAAAJ": "Shuhan Tan",
    "VNSzxhUAAAAJ": "Hou-Ning Hu",
    "fszzlckAAAAJ": "Jernej Kos",
    "RUT0Hf8AAAAJ": "Katelyn Gao",
    "yuNhi-8AAAAJ": "Haoshuo Huang",
    "uclqBzgAAAAJ": "Yulong Cao",
    "lVD0CNEAAAAJ": "Danny Jesus Diaz",
    "sbbRtWwAAAAJ": "Vijay Chidambaram",
    "5akTCHoAAAAJ": "Jayashree Mohan",
    "hsxzylEAAAAJ": "Aashaka Shah",
    "ojKsx6AAAAAJ": "Yuanjun Xiong",
    "eWbZJlMAAAAJ": "Florian Schroff",
    "lv9ZeVUAAAAJ": "Boqing Gong",
    "YTyBTmgAAAAJ": "Long Zhao",
    "4wSfAIQAAAAJ": "Ting Liu",
    "1H9CkZgAAAAJ": "Liangzhe Yuan",
    "M7EpKqsAAAAJ": "Jialin  Wu",
    "fWd88tEAAAAJ": "Hartwig Adam",
    "FY-jB3QAAAAJ": "Hui Miao",
    "b4Kj6MIAAAAJ": "Edward Schmerling",
    "zr9B1YgAAAAJ": "Santhosh Kumar Ramakrishnan",
    "rdwkreIAAAAJ": "Yurong You",
    "v-AEFIEAAAAJ": "Yue Wang",
    "zjsSMfIAAAAJ": "Nimit Kalra",
    "xA3RcaUAAAAJ": "Taylor W. Killian",
    "Zdl00bEAAAAJ": "Vignesh Ramanathan",
    "AscakBgAAAAJ": "Chengyue Gong 龚成玥",
    "tWcg0ZsAAAAJ": "Kairan Dou",
    "nuwXTh4AAAAJ": "James Bornholt",
    "BBRkKHUAAAAJ": "Stephen Hanly",
    "hjTzNuQAAAAJ": "Suhas Diggavi",
    "_N7091oAAAAJ": "J Nicholas Laneman",
    "BGggDBwAAAAJ": "Olivier Leveque",
    "UztDgakAAAAJ": "Govinda M. Kamath",
    "oe3NRPQAAAAJ": "Ada Poon",
    "CFIJZwoAAAAJ": "Mohammad Ali Maddah-Ali",
    "D22GptUAAAAJ": "Joseph M. Kahn",
    "GYPCqcYAAAAJ": "Farzan Farnia",
    "4jViXZgAAAAJ": "Jesse Zhang",
    "fMAg4zEAAAAJ": "Ilan Shomorony",
    "bWTPrLEAAAAJ": "John Tsitsiklis",
    "WnFB4iEAAAAJ": "I-Hsiang Wang",
    "ObkOmdMAAAAJ": "Hua Wang",
    "-EMkK7QAAAAJ": "Srinivasan Keshav",
    "MZqwE-wAAAAJ": "Albert YS Lam",
    "lVIk1qIAAAAJ": "Olivier Dousse",
    "7Ek7pqgAAAAJ": "Patrick Thiran",
    "xlOEqOEAAAAJ": "Alejandro Dominguez-Garcia",
    "0fJXXaMAAAAJ": "Dustin Cartwright",
    "ApQt28MAAAAJ": "Reinaldo A. Valenzuela",
    "lptAmrMAAAAJ": "Soheil Feizi",
    "-qV-RYkAAAAJ": "Vasilis Ntranos",
    "79etgAkAAAAJ": "Jamie Evans",
    "0ZA7y4UAAAAJ": "Roy Yates",
    "sJIAF-gAAAAJ": "Christina Fragouli",
    "rJ-biB0AAAAJ": "Seyed Abolfazl Motahari",
    "UZK1i4EAAAAJ": "Sudeep Kamath",
    "MtxwDwoAAAAJ": "Robert Scholtz",
    "nc8HAeIAAAAJ": "Sheng Jing",
    "hvpur7kAAAAJ": "Jilei Hou",
    "6_oL_9IAAAAJ": "Muriel Medard",
    "WrFQzBIAAAAJ": "Vinayak Nagpal",
    "fVo3u5wAAAAJ": "Javad Lavaei",
    "M8o8WaQAAAAJ": "Aydin Sezgin",
    "ceYJJmYAAAAJ": "Edwin KP Chong",
    "UtAdFs8AAAAJ": "Junshan Zhang",
    "MT-S2QMAAAAJ": "Paolo Minero",
    "iWq6Tn4AAAAJ": "Randall Berry",
    "8J1kJhIAAAAJ": "Ka-kit Lam",
    "NW5Y82wAAAAJ": "Asif Khalak",
    "Q-idFOAAAAAJ": "Oliver Kosut",
    "EeYvAfIAAAAJ": "Lang Tong",
    "ofcrge8AAAAJ": "Sergio Verdu",
    "cYoahsBLcjsC": "Abbas El Gamal",
    "C0ddY2kAAAAJ": "David Starobinski",
    "8VNhGv4AAAAJ": "Chih-Chun Wang",
    "4gWt4fgAAAAJ": "Anant SAHAI",
    "CCToMygAAAAJ": "Eduardo Sontag",
    "3N72KDQAAAAJ": "Chao Tian",
    "SsEHa6cAAAAJ": "Bixio Rimoldi",
    "zofVx00AAAAJ": "Piyush Gupta",
    "KIxRFxQAAAAJ": "Eric Wait",
    "JL4E0ZoAAAAJ": "Badrinath Roysam, FIEEE, FAIMBE",
    "_eLWTEUAAAAJ": "Uri Hershberg",
    "OI6ouhAAAAAJ": "Walter C. Mankowski",
    "UCsQ8VgAAAAJ": "Paul Vitanyi",
    "GL3GjBYAAAAJ": "M. Cecilia Caino",
    "qWmCkDMAAAAJ": "Michel Cayouette",
    "xyrOk5EAAAAJ": "Brian S Clark",
    "W56NkyoAAAAJ": "cheng fang",
    "Q2WSQiEAAAAJ": "Timothy A Blenkinsop",
    "2GKLw94AAAAJ": "Jiarui XU",
    "TDxKd6cAAAAJ": "Yinbo Chen",
    "xQM4BlMAAAAJ": "Shalini De Mello",
    "bioUtz4AAAAJ": "Yang Fu",
    "Nav8m8gAAAAJ": "Liang Lin",
    "kNtDoX8AAAAJ": "Ge Yang",
    "nqoOetAAAAAJ": "Binghao Huang",
    "nkEGpKsAAAAJ": "Jianglong Ye",
    "PGFk9ZgAAAAJ": "Shaowei Liu",
    "lL3KYmMAAAAJ": "Yueh-Hua Wu",
    "j8GFD70AAAAJ": "Jiteng Mu",
    "HJHSuxUAAAAJ": "Hanwen Jiang",
    "clTKG0QAAAAJ": "Gunnar Atli Sigurdsson",
    "UFokX9EAAAAJ": "Rishabh Jangir",
    "yqqESloAAAAJ": "Annabella Macaluso",
    "Zoiu7FsAAAAJ": "An-Chieh Cheng",
    "ma7qW2kAAAAJ": "Ge Yan",
    "IgWjDugAAAAJ": "Yufei Ye",
    "PUz8SCQAAAAJ": "Amey Kulkarni",
    "yAWtq6QAAAAJ": "Naiyan Wang",
    "p9-nlRIAAAAJ": "Arash Vahdat",
    "-B5JgjsAAAAJ": "Xiaogang Wang",
    "WKO_1VYAAAAJ": "Jimmy S. Ren",
    "pw_0Z_UAAAAJ": "Wanli Ouyang (欧阳万里)",
    "BN2Ze-QAAAAJ": "Hongsheng Li (李鸿升)",
    "rUOpCEYAAAAJ": "Wangmeng Zuo",
    "XPFPohcAAAAJ": "Karan Dalal",
    "hv1LiiEAAAAJ": "Yuying Ge",
    "HOngPZAAAAAJ": "Chen Bao",
    "moOv1BsAAAAJ": "Minghao Zhang",
    "RTkSatQAAAAJ": "Nikolay A. Atanasov",
    "wwswAvEAAAAJ": "Mohit Jain",
    "w3GjGqoAAAAJ": "Jianhuang Lai",
    "RG9pwnUAAAAJ": "Xinhao Li",
    "EaaOeJwAAAAJ": "Sanmi Koyejo",
    "aJ_Fr4MAAAAJ": "Zhujin Liang",
    "kxqgE9cAAAAJ": "Joanna Materzynska",
    "ZsgWCyMAAAAJ": "Shubhankar Borse",
    "9y3Kd3cAAAAJ": "Hong (Herbert) Cai",
    "-ndXYyoAAAAJ": "Guillem ALENYÀ",
    "iLOoUqIAAAAJ": "Yuntao Chen",
    "HwFGzZMAAAAJ": "Zihan Zhou",
    "qL2ZsgcAAAAJ": "Tianyu Wang",
    "pxFyKAIAAAAJ": "Zhangyang (Atlas) Wang",
    "WBvt5A8AAAAJ": "Humphrey Shi",
    "7rNyP1sAAAAJ": "Vidit Goel",
    "dvplAJkAAAAJ": "Zeyuan Chen",
    "s1X82zMAAAAJ": "Xingqian Xu",
    "tRLUOBIAAAAJ": "Adam Kortylewski",
    "9_AUwFUAAAAJ": "Weichao Qiu",
    "voxznZAAAAAJ": "Xiaodan Liang",
    "9tI89HMAAAAJ": "Yuan Yuan",
    "HPfNU94AAAAJ": "Subarna Tripathi",
    "CrfsfFSiS0kC": "Mohit Shridhar",
    "OZ2MxEYAAAAJ": "Yiyang Ling",
    "IlgMpNoAAAAJ": "Bailin Wang",
    "LjTCVxAAAAAJ": "Hanzhe Hu",
    "mGMy_kwAAAAJ": "Zhenggang Tang",
    "BYoq_bwAAAAJ": "Chao Yu（于超）",
    "Khb7qw8AAAAJ": "Masashi Hamaya",
    "fDHUk18AAAAJ": "Xuanchi Ren",
    "iO6xAdgAAAAJ": "Liliang Zhang",
    "TIST9HIAAAAJ": "Jonathan Zamora",
    "6CWng3MAAAAJ": "Sateesh Kumar",
    "TQw8WLEAAAAJ": "Elad Levi",
    "v19p_0oAAAAJ": "Nitesh B. Gundavarapu",
    "pyBSGjgAAAAJ": "Yizhuo Li",
    "zYONEFQAAAAJ": "Miao Hao",
    "5lFDxsMAAAAJ": "Zonglin Di",
    "LR4CHSkAAAAJ": "Yuanpei Chen",
    "28oeBTgAAAAJ": "Yixin Lin",
    "6G5SEVkAAAAJ": "Vikash Kumar Pandey",
    "t8UduWwAAAAJ": "Rui Huang",
    "lXpi86gAAAAJ": "Helin Xu",
    "aXdjxb4AAAAJ": "Ping Luo (羅平)",
    "7wuq-7AAAAAJ": "Thomas E. Huang",
    "Yv-H6F4AAAAJ": "Haiping Wu",
    "fNl-ZkIAAAAJ": "Benlin Liu",
    "F2e_jZMAAAAJ": "Lichao Huang",
    "uVsZydYAAAAJ": "Tongzhou Mu",
    "NvjazjgAAAAJ": "Yuchen Zhang",
    "Qirk2fYAAAAJ": "Keze Wang (王可泽)",
    "51I5vxkAAAAJ": "John I. Miller",
    "jwkE2lgAAAAJ": "Kaifeng Zhang",
    "RyKtqiQAAAAJ": "Elliot J. Crowley",
    "5i2hUToAAAAJ": "Chenhongyi Yang",
    "t4rgICIAAAAJ": "Deqing Sun",
    "6UHjQQYAAAAJ": "Orazio Gallo",
    "NjZsLZwAAAAJ": "Judith E. Fan",
    "A3Fw5yMAAAAJ": "Xuanchen Lu",
    "uJvw2KUAAAAJ": "Jianhan Ma",
    "Qpfxtc8AAAAJ": "Zhuoqun Chen",
    "VfEVlecAAAAJ": "Yunhai Feng",
    "CQ1cqKkAAAAJ": "Jianfeng Gao",
    "IEvwT5kAAAAJ": "Chloe Hsu",
    "klyIBq8AAAAJ": "Chandramouli Rajagopalan",
    "RScZCLEAAAAJ": "Kiana Ehsani",
    "JnUevM0AAAAJ": "Aniruddha Kembhavi",
    "LUAuzBAAAAAJ": "Raffaele Bugiardini",
    "jiyonF0AAAAJ": "James Jordon",
    "aHa6fz4AAAAJ": "William Zame",
    "dNRKN3wAAAAJ": "Martin Cadeiras",
    "rNpUIKAAAAAJ": "Shuvra S. Bhattacharyya",
    "1MtIU9YAAAAJ": "Cem Tekin",
    "9TKjEuQAAAAJ": "Takashi Hara",
    "XggqoHyV3KQC": "Neal Madras",
    "0iieFBwAAAAJ": "Frank den Hollander",
    "JOD3OtAAAAAJ": "Emmanuel Michta",
    "8kHXJhAAAAAJ": "Nathan Clisby",
    "rXyRgbcAAAAJ": "Yucheng Liu",
    "0p--0vgAAAAJ": "Jesse Goodman",
    "wWWEwk0AAAAJ": "Alan D. Sokal",
    "D6ZDEUgAAAAJ": "Mark Holmes",
    "QS7Z860AAAAJ": "Martin Barlow",
    "Gz1YIaUAAAAJ": "Alexandre Tomberg",
    "Y4TYXDMAAAAJ": "Hugo Duminil-copin",
    "Q7ftcFEAAAAJ": "Akira Sakai",
    "wEFxCvMAAAAJ": "Tom Hutchcroft",
    "PEAQZVEAAAAJ": "Romain Panis",
    "RV-JsYEAAAAJ": "Andrew Rechnitzer",
    "1U-VMCIAAAAJ": "Aleks L Owczarek",
    "Ycmx6l8AAAAJ": "Yao-ban Chan",
    "rLepj0gAAAAJ": "Omer Angel",
    "qFmoeNkAAAAJ": "Debora Marks",
    "ZE5_-DIAAAAJ": "Enzo Marinari",
    "dK2eepUAAAAJ": "Thomas A. Hopf",
    "b_svo9QAAAAJ": "Christoph Feinauer",
    "XV30l4MAAAAJ": "Bryan J. Lunt",
    "z3t35rcAAAAJ": "Faruck Morcos",
    "i0LZR2gAAAAJ": "Jose Onuchic",
    "0cO2nlMAAAAJ": "Paolo Provero",
    "DRTIzTsAAAAJ": "Marco Zamparo",
    "VoWkBjUAAAAJ": "Pier Paolo Pandolfi",
    "a-3LnGUAAAAJ": "Florian Karreth",
    "WAMYIpQAAAAJ": "Riccardo Taulli",
    "UzlqiSMAAAAJ": "Luca Leuzzi",
    "mSj0LUsAAAAJ": "Fabrizio Antenucci",
    "gWg00ScAAAAJ": "Francesco Neri",
    "-2E52C0AAAAJ": "Olivier Martin",
    "GrDAbaEAAAAJ": "Vittorio Loreto",
    "dWKDuxcAAAAJ": "Victor Martin-Mayor",
    "vmLs7E8AAAAJ": "Osvaldo Zagordi",
    "00FDOS8AAAAJ": "Rituraj Purohit",
    "xB42z10AAAAJ": "Pingchuan Ma",
    "Sd8mmE0AAAAJ": "Zongjie Li",
    "WtO-bN8AAAAJ": "Daoyuan Wu",
    "-VQxD1UAAAAJ": "Zhenlan Ji",
    "RivxoIcAAAAJ": "Zhendong Su",
    "lMqmhpwAAAAJ": "Dongwei Xiao",
    "_Pvgwd0AAAAJ": "Yang Liu",
    "4v5x0bUAAAAJ": "Wenxuan Wang",
    "rUZN-zQAAAAJ": "Danfeng Zhang",
    "KNdj9HMAAAAJ": "Xunguang Wang",
    "usJzGjUAAAAJ": "Tsong Yueh Chen",
    "uQnBgK0AAAAJ": "Michael R. Lyu",
    "C7htwEIAAAAJ": "Yinqian Zhang",
    "eO-yR-0AAAAJ": "Huaijin Wang",
    "4DFgv64AAAAJ": "Qingyue Wang",
    "SgNB-ioAAAAJ": "Juanzi Li",
    "dZJy8_8AAAAJ": "Yuxiao Dong",
    "VKI8EhUAAAAJ": "Xiao Liu",
    "Va50YzkAAAAJ": "Ming Ding",
    "3rlMzwYAAAAJ": "Jiezhong Qiu",
    "A8x07E0AAAAJ": "Zhengxiao Du",
    "LCjW058AAAAJ": "Yukuo Cen",
    "9jmmp5sAAAAJ": "Jimeng Sun",
    "cjRV2IsAAAAJ": "Wenzheng Feng",
    "_BiloKgAAAAJ": "Xu Zou",
    "PzoN2hgAAAAJ": "Sen Wu",
    "riuIGwIAAAAJ": "Ying Ding",
    "STftvjoAAAAJ": "Aohan Zeng",
    "Vjo4Tg4AAAAJ": "Tiancheng Lou",
    "yneRh8EAAAAJ": "Duo Zhang",
    "hDLBEhkAAAAJ": "Nitesh V Chawla, Fellow: ACM, IEEE, AAAS, AAAI",
    "ZP4gfYcAAAAJ": "Zi Yang",
    "D3nUPbYAAAAJ": "Lu Liu",
    "SqAsppUAAAAJ": "Qiong Luo",
    "qO3AeDoAAAAJ": "acm fong",
    "D0lL1r0AAAAJ": "Philip S. Yu",
    "54wdDqcAAAAJ": "Qinkai Zheng",
    "FxEDj4wAAAAJ": "Honglei Zhuang",
    "TQgOjK0AAAAJ": "Yizhou Sun",
    "gD640BwAAAAJ": "Bing He",
    "OejqtPoAAAAJ": "Bo Gao",
    "iKlE1A8AAAAJ": "Xin Shuai",
    "AaqB_F4AAAAJ": "Zhanpeng Fang",
    "ej3Nb5wAAAAJ": "Yi Cai",
    "tL9zHywAAAAJ": "Xiaoming Li",
    "eLw6g-UAAAAJ": "Rui Yan (严睿)",
    "lNQmMTMAAAAJ": "Ruoming Jin",
    "C7UqPnoAAAAJ": "Yang Yang",
    "oJESe-cAAAAJ": "Lillian Lee",
    "nTl5mSwAAAAJ": "Hang Li",
    "SdPinGIAAAAJ": "Songcan Chen",
    "-0YOKRoAAAAJ": "David Wild",
    "Ry3K3AMAAAAJ": "Guotong Xie",
    "Adug-7cAAAAJ": "Yintao Yu",
    "Nomi_U0AAAAJ": "Erjia Yan",
    "AjKdHVMAAAAJ": "Cassidy R. Sugimoto",
    "zr22WkQAAAAJ": "Qiaozhu Mei",
    "1FtOcrMAAAAJ": "Limin Yao",
    "JDErdKcAAAAJ": "Ho-fung Leung",
    "0w0Dy34AAAAJ": "Judy Fox",
    "nNVDLb4AAAAJ": "Yunbo Cao",
    "2aqu0VMAAAAJ": "Yang Yang",
    "hon00PIAAAAJ": "Yunhao Liu",
    "D1LEg-YAAAAJ": "Qing Li",
    "s3lQL7YAAAAJ": "Hong Cheng",
    "dgeikT8AAAAJ": "Zhigang Wang",
    "zPVItDgAAAAJ": "Zhen Yang",
    "iDq2Hu8AAAAJ": "Stephen Fox",
    "Y187sPMAAAAJ": "Russell Leek",
    "abd1LXcAAAAJ": "Francesca Buffa",
    "1QlW92QAAAAJ": "Roy Bicknell",
    "FSm4igUAAAAJ": "Francesco Pezzella",
    "UypFDoQAAAAJ": "Ji-Liang Li",
    "BQQjcVAAAAAJ": "Daniele Generali",
    "JAp-yScAAAAJ": "Christos Sotiriou",
    "5q_ZMzYAAAAJ": "Richard Sainsbury",
    "XpFzyRUAAAAJ": "Claire E Lewis",
    "asRzBf4AAAAJ": "Helen Sheldon",
    "oAU5b1wAAAAJ": "Charles Wykoff MD PhD",
    "vrqzitkAAAAJ": "Catharine West",
    "fuVZQsAAAAAJ": "Syed Haider",
    "nHPGOOgAAAAJ": "Simon R Lord",
    "wOkPYS4AAAAJ": "Pawel Swietach",
    "4Bm4gZEAAAAJ": "Peter Vermeulen",
    "EYtt2uQAAAAJ": "Hani Choudhry",
    "evR07usAAAAJ": "David Mole",
    "Wm0VZrQAAAAJ": "Almut Schulze",
    "bAPC01sAAAAJ": "Luke RG Pike, MD, D.Phil.",
    "MobIH6EAAAAJ": "Dean Singleton",
    "9-iC3BsAAAAJ": "Bradly Wouters",
    "0MzVIUsAAAAJ": "Amos Fiat",
    "gWygCaAAAAAJ": "Emmanouil  Pountourakis",
    "U6Tf0VEAAAAJ": "Gregory Stoddard",
    "1oqm0boAAAAJ": "Nima Haghpanah",
    "SO_j4zwAAAAJ": "Anne Condon",
    "YMmzWH7gT-oC": "Evdokia Nikolova",
    "BSa0rkwAAAAJ": "Lintao Zhang",
    "JPr5FAUAAAAJ": "Yigal (Yigal) Bejerano",
    "Arl0IwUAAAAJ": "Brian Dean",
    "euruCPEAAAAJ": "Mu Cai",
    "aAX0au8AAAAJ": "Xiao Li (李虓)",
    "zWfNZnIAAAAJ": "Jihan Yang",
    "1OJiqUQAAAAJ": "Jiayi Pan",
    "Iv5WU4UAAAAJ": "Yifei Zhou",
    "usawh5oAAAAJ": "Yuqian Zhang",
    "S1YPXrgAAAAJ": "Zipeng Leo Lin",
    "WPYCnqIAAAAJ": "Zhili Chen",
    "nEUGF3YAAAAJ": "Zhenyu Liao",
    "GX-PtukAAAAJ": "Carlos Fernandez-Granda",
    "rzhzR-cAAAAJ": "Sheng Liu",
    "GcGVcyoAAAAJ": "Hermish Mehta",
    "OzMYwDIAAAAJ": "Lionel Ni",
    "jUAAhpMAAAAJ": "Chun-Hsiao Yeh",
    "Aok9lxwAAAAJ": "Tobias Kreiman",
    "uyYPun0AAAAJ": "Marc G. Bellemare",
    "n4kXFdsAAAAJ": "Larry Yang",
    "xf_n4xUAAAAJ": "Marlos C. Machado",
    "Jun8c34AAAAJ": "John D. Martin",
    "LS6HY-gAAAAJ": "Colin White",
    "O7p7lRAAAAAJ": "Ruth Urner",
    "8ZpV-lkAAAAJ": "Ariel Procaccia",
    "zMLbnN4AAAAJ": "Bo Xie",
    "McgMhW0AAAAJ": "Yu (Brandon) Xia",
    "hzkTiowAAAAJ": "Florin Constantin",
    "iNcA81MAAAAJ": "Niao He",
    "wpdabDgAAAAJ": "Anant Raj",
    "lJCOQ1cAAAAJ": "Gregory Sorkin",
    "T5GVHawAAAAJ": "Shai Fine",
    "TLfsJRwAAAAJ": "Shang-Tse Chen",
    "j8svx3IAAAAJ": "Aurélien Bellet",
    "r3dW1m0AAAAJ": "Alireza Bagheri Garakani",
    "7qdaJT8AAAAJ": "Daniel McNamara",
    "m0PW6DQAAAAJ": "Yair Zick",
    "Zp2LpwUAAAAJ": "Or Sheffet",
    "F8_JP6sAAAAJ": "TH. Hubert Chan",
    "Z_WrhK8AAAAJ": "Mu Li",
    "ixE1z7UAAAAJ": "Jeff S. Shamma",
    "FY2dQSgAAAAJ": "Bodo Manthey",
    "HvI1xmUAAAAJ": "Alina Beygelzimer",
    "PVty8PUAAAAJ": "Philip Long",
    "fE3Bs1oAAAAJ": "Lei Wang",
    "WYkBdO0AAAAJ": "Ashesh Jain",
    "_twaeHkAAAAJ": "Hema Swetha Koppula",
    "XnhYW0MAAAAJ": "Matthew Moskewicz",
    "NeW9jU8AAAAJ": "Holger Winnemoeller",
    "re00xioAAAAJ": "Matthew Trentacoste",
    "KhnebkgAAAAJ": "Tobias Baumgartner",
    "ai8A090AAAAJ": "Noa Arthurs",
    "664NOb0AAAAJ": "Marti A Hearst",
    "WfzyRAUAAAAJ": "Harold Pimentel",
    "yc4nBNgAAAAJ": "Tim Althoff",
    "54yrQIkAAAAJ": "Nicholas Rotella",
    "LW7uksIAAAAJ": "Felix Grimminger",
    "WCUNvnkAAAAJ": "Majid Khadiv",
    "3Yjo-W8AAAAJ": "S Ali A Moosavian",
    "IMoAPLUAAAAJ": "Sean A Mason",
    "65bIT4oAAAAJ": "Tamim Asfour",
    "lgvyqMQAAAAJ": "Yunfei Bai",
    "_WLInT0AAAAJ": "Daniel Kappler",
    "Wx62iOsAAAAJ": "Javier Romero",
    "PYLHQsYAAAAJ": "Andrea Del Prete",
    "_Whqm1IAAAAJ": "Julian Viereck",
    "yBs28hUAAAAJ": "Sebastien Kleff",
    "A3wg18wAAAAJ": "Daniel S. Brown",
    "HvjirogAAAAJ": "Jaime Fernández Fisac",
    "r30eXmkAAAAJ": "Marius Wiggert",
    "FodLUKcAAAAJ": "Natalia Rost",
    "xxjDmR4AAAAJ": "Mihail Pivtoraiko",
    "jkwHy3AAAAAJ": "Michael Branicky",
    "z7b0sKUAAAAJ": "Sungmoon Joo",
    "8IH6kXQAAAAJ": "Joel Chestnutt",
    "UMG3OGgAAAAJ": "Christopher Rasmussen",
    "emiAAG0AAAAJ": "Andrew L. Maas",
    "5tyrt68AAAAJ": "Christopher Yau",
    "07kG-YsAAAAJ": "Jie Xu",
    "CcruPcoAAAAJ": "Deepak S. Turaga",
    "PuTDB5gAAAAJ": "Zhaozhi Qian",
    "Pczk-PQAAAAJ": "Daniel Jarrett",
    "GJaAw1EAAAAJ": "Hayder Radha",
    "jEHm-fUAAAAJ": "Yiannis Andreopoulos",
    "SjjIQ24AAAAJ": "Yu Zhang",
    "Ya3CmFcAAAAJ": "Yuanzhang Xiao",
    "1RuDJX8AAAAJ": "Nicholas Mastronarde",
    "4qCGgpsAAAAJ": "Fergus Imrie",
    "5g3iJvYAAAAJ": "Jaeok Park",
    "nUZG1SEAAAAJ": "Nabeel Seedat",
    "IFljhlMAAAAJ": "Edina Cenko",
    "cdpb5UcAAAAJ": "Alexis Bellot",
    "iuRC7jgAAAAJ": "Onur Atan",
    "C1FZEtkAAAAJ": "Hyunggon Park",
    "9BHYPnUAAAAJ": "Boris van Breugel",
    "2kfmAzEAAAAJ": "Adrian Munteanu",
    "wBu1J2MAAAAJ": "Peter Schelkens",
    "EMq6KwMAAAAJ": "Alihan Hüyük",
    "LtdHRjsAAAAJ": "Tennison Liu",
    "vJxuKwgAAAAJ": "Trent Kyono",
    "7k2LuTkAAAAJ": "Ari Ercole",
    "7XY3l2wAAAAJ": "Jan Cornelis",
    "Ey5aInIAAAAJ": "Samuel Holt",
    "B3Xd8-kAAAAJ": "Yao Zhang",
    "PH1aZPsAAAAJ": "Jang-Won Lee",
    "afgNSP8AAAAJ": "Beatrice Pesquet-Popescu",
    "7ZNoHJkAAAAJ": "Hao Sun",
    "Bjf-KF8AAAAJ": "Luca Canzian",
    "BPFqibsAAAAJ": "Simpson Zhang",
    "6cNoBY4AAAAJ": "Krzysztof Kacprzyk",
    "UcGN3MoAAAAJ": "Linqi Song",
    "SJi-EFwAAAAJ": "Evgeny S Saveliev",
    "gd23c7MAAAAJ": "Sunghyun Choi, Ph.D., FIEEE",
    "smm3MNcAAAAJ": "R. Michael Buehrer",
    "2NHX1bIAAAAJ": "R. Andres Floto",
    "_uBxMwkAAAAJ": "Eoin McKinney",
    "c5JFDEgAAAAJ": "Anja Klein",
    "uDG9sXQAAAAJ": "Ali H Sayed",
    "QAdcBnQAAAAJ": "Charlotte Deane",
    "QKtoEnkAAAAJ": "Karim Kanoun",
    "fwJ4_WUAAAAJ": "SaiDhiraj Amuru",
    "Z43BgdEAAAAJ": "Anna Scaglione",
    "oLiBK8cAAAAJ": "Nicolás Astorga",
    "F3ba0dEAAAAJ": "Valerio Marra",
    "qwOPQdIAAAAJ": "Hyun-Suk Lee",
    "ieyW4WQAAAAJ": "Dennis Frauen",
    "NECavRYAAAAJ": "Bryan Lim",
    "ULRIRdgAAAAJ": "Sabrina Klos (née Müller)",
    "H1JXhMIAAAAJ": "David Atienza",
    "zeK3OSYAAAAJ": "Emanuele Di Angelantonio",
    "LLkgMYQAAAAJ": "Fiona Gilbert",
    "6cuNVagAAAAJ": "Tom Callender",
    "EMExrOMAAAAJ": "Valentyn Melnychuk",
    "VaLB21wAAAAJ": "yezekael hayel",
    "Z7d93ZYAAAAJ": "Michele Zorzi",
    "iD01qbkAAAAJ": "Yannick Meier",
    "vI5qd9AAAAAJ": "Philip A. Chou",
    "_s5DZOcAAAAJ": "William Hsu",
    "mEgZUP8AAAAJ": "Mohammad Shikh-Bahaei",
    "HAgGqScAAAAJ": "Eleonora Giunchiglia",
    "ww-6D6wAAAAJ": "Amitava Banerjee",
    "onJXki0AAAAJ": "Venkatesh Akella",
    "bWBQzhQAAAAJ": "Professor Vincent J Gnanapragasam",
    "wstakvUAAAAJ": "Lisa Amini",
    "jEdhxGMAAAAJ": "Cyrus Shahabi",
    "n_N-PJkAAAAJ": "Lei He",
    "iyPP6VYAAAAJ": "Thomas Stockhammer",
    "ySLrpsYAAAAJ": "Maria Dimakopoulou",
    "DsHKK-AAAAAJ": "Ruihan Wu",
    "i6tMWAoAAAAJ": "Noveen Sachdeva",
    "0gp5M-kAAAAJ": "Chuan Guo",
    "MOfaB6oAAAAJ": "Ben London",
    "w3PrbKwAAAAJ": "Huazheng Wang",
    "NqsBRwMAAAAJ": "Hae Young Noh",
    "xkIcvmIAAAAJ": "Pei Zhang",
    "Ha8rlUgAAAAJ": "Xinlei Chen",
    "pGib_yMAAAAJ": "Xuechun Li",
    "XEztdZgAAAAJ": "Carlee Joe-Wong",
    "pkp4VXUAAAAJ": "David J Wald",
    "mEEklegAAAAJ": "Xilei Zhao",
    "syUpc-gAAAAJ": "Wei Ma",
    "OGEyrG8AAAAJ": "Tijmen Blankevoort",
    "gh_fDicAAAAJ": "Jingxiao Liu",
    "m5v0PNIAAAAJ": "Xie Hu",
    "Mbg9vJMAAAAJ": "Kishor Jaiswal",
    "175Mu2wAAAAJ": "Luis Ceferino",
    "1zmDOdwAAAAJ": "Christopher D Manning",
    "-tEiRFcAAAAJ": "James Harrison",
    "H1d4BS8AAAAJ": "Hao Zhang",
    "VOf45S0AAAAJ": "Gordon Wetzstein",
    "lBO12XgAAAAJ": "Julien NP Martel",
    "fWCoyDcAAAAJ": "Sixian You",
    "y-RSDYYAAAAJ": "Rohit Varma",
    "O7q6DkEAAAAJ": "Asaf Gendler",
    "NGdMpTYAAAAJ": "Jorg Conradt",
    "nxwNAEgAAAAJ": "Srigokul Upadhyayula",
    "uVrmjIAAAAAJ": "Thayer Alshaabi",
    "Edh7brQAAAAJ": "Mark Humayun",
    "OPlpj2YAAAAJ": "Robert Konrad",
    "3343olgAAAAJ": "Laura Waller",
    "EV3kaHYAAAAJ": "Hossein Ameri",
    "w3DSGTIAAAAJ": "Charles Lu",
    "lDmZxTMAAAAJ": "Jordan Lekeufack Sopze",
    "uTRczaUAAAAJ": "Kyrollos Yanny",
    "X71o1ykAAAAJ": "Kristina Monakhova",
    "gZ-RhocAAAAJ": "Linda Griffith",
    "vEYl-MUAAAAJ": "Cassandra T. Ye",
    "wzifqNkAAAAJ": "Kunzan Liu",
    "aH5QOEcAAAAJ": "Jiashu Han",
    "6oqV3v8AAAAJ": "Naman Jain",
    "X5NSuikAAAAJ": "David McAllister",
    "bV_IUy8AAAAJ": "Federico Gasparoli",
    "JTtnJUIAAAAJ": "Shishir G. Patil",
    "1rPi_78AAAAJ": "Lingjiao Chen",
    "_3bbpWoAAAAJ": "Jared Quincy Davis",
    "NMPUDa0AAAAJ": "Yangsibo Huang",
    "oDE4I64AAAAJ": "Christopher A. Choquette-Choo",
    "COEsqLYAAAAJ": "Daphne Ippolito",
    "l_G2vr0AAAAJ": "Chiyuan Zhang",
    "ljAjAcAAAAAJ": "Ken Ziyu Liu",
    "RatgWlcAAAAJ": "Joseph Tennyson",
    "_8rw_GMAAAAJ": "Matthew Jagielski",
    "0wZN6hEAAAAJ": "Satvik Sharma",
    "N_KDBGcAAAAJ": "Huang(Raven) Huang",
    "TAAQ1LwAAAAJ": "Vincent Blot",
    "eZJI5sAAAAAJ": "Nicolas Brunel",
    "8l9BcBAAAAAJ": "Peter H. Yoon",
    "YO5XSXwAAAAJ": "Jennifer Doudna",
    "ElZ0iNkAAAAJ": "Seyone Chithrananda",
    "qU-JFvMAAAAJ": "Ron Boger",
    "Vy16O5UAAAAJ": "Lisa Dunlap",
    "CylZPggAAAAJ": "Efrat Shimron",
    "76crpgsAAAAJ": "Alfredo De Goyeneche",
    "EWY1qlkAAAAJ": "Michael (Miki) Lustig",
    "Iz3m3v4AAAAJ": "Ke Wang",
    "94yn2j0AAAAJ": "Valerie Chen",
    "YXJ-_k0AAAAJ": "Wayne Chi",
    "MgzHAPQAAAAJ": "Chris Donahue",
    "WIAYNzMAAAAJ": "Aditya Mittal",
    "-2ATsToAAAAJ": "Synho Do, PhD",
    "3yVndk0AAAAJ": "Christopher P. Bridge",
    "R4IDPnoAAAAJ": "Lev, Michael H",
    "KG0pbOYAAAAJ": "Dan Elton",
    "BB833ugAAAAJ": "Mariel Werner",
    "BxmyKVoAAAAJ": "Bo-Jui Chang",
    "b5TVr_UAAAAJ": "Reto Fiolka",
    "JZIeZ3MAAAAJ": "Narges Norouzi",
    "qCmF95EAAAAJ": "Logan King",
    "R_2aiNIAAAAJ": "Mihran Miroyan",
    "ykuVSuEAAAAJ": "Tsung-Han Wu",
    "Wb_lnjAAAAAJ": "Jacob Eisenstein",
    "9MSArZUAAAAJ": "Christian F. Baumgartner",
    "MlDSA9sAAAAJ": "Moritz Fuchs",
    "KsGo-_QAAAAJ": "Magdalini Paschali",
    "5b8b5V8AAAAJ": "Nihal Jain",
    "msQ4KT4AAAAJ": "Alexander Freytag",
    "GazEl1wAAAAJ": "Paul Bodesheim",
    "LNJMblcAAAAJ": "Michael Kemmler",
    "LQSNuf0AAAAJ": "Björn Fröhlich",
    "k2AHIx8AAAAJ": "Björn Barz",
    "ZWPqDxEAAAAJ": "Sven Sickert",
    "Iq0KSBYAAAAJ": "Yanira Guanche",
    "0IXxNKsAAAAJ": "Clemens-Alexander Brust",
    "pAiIxxkAAAAJ": "Simon Reiß",
    "rSuG-f4AAAAJ": "Constantin Seibold",
    "XCkp5uEAAAAJ": "Markus Reichstein",
    "MA6SDuEAAAAJ": "Andreas K. Maier",
    "6iPoAXAAAAAJ": "Marc Aubreville",
    "9pI3MrEAAAAJ": "Christian Jaremenko",
    "TVfLgPAAAAAJ": "Miguel D. Mahecha",
    "GD5bzTgAAAAJ": "Alexander Brenning",
    "sbBPoc0AAAAJ": "Orlando Guntinas-Lichius",
    "iBGPazIAAAAJ": "Ricardo Knauer",
    "iAdho-sAAAAJ": "Anibal Pedraza",
    "hlLuENoAAAAJ": "Chao-Hui HUANG",
    "Bk5BJ80AAAAJ": "Ramakrishnan Mukundan",
    "t4IWpnYAAAAJ": "Talha Qaiser",
    "BSDXhwgAAAAJ": "Nasir M. Rajpoot",
    "04TxLAIAAAAJ": "Tomi Pitkäaho",
    "4-ccLwEAAAAJ": "Gloria Bueno",
    "LfkSQW4AAAAJ": "Taina M. Lehtimäki",
    "IZC7zeUAAAAJ": "Sebastian Sippel",
    "Cxh2C2oAAAAJ": "Hjalmar S. Kühl",
    "199M69AAAAAJ": "Andrea Perino",
    "LigYduEAAAAJ": "Robert B  Fisher",
    "-R2kv9MAAAAJ": "Gunnar Brehm",
    "wjjDKWkAAAAJ": "Johann Wolfgang Wägele",
    "FUiFDqUAAAAJ": "Thomas Bocklitz",
    "xG9s8HEAAAAJ": "Oliver Mothes",
    "SMSWgw0AAAAJ": "Andreas Stallmach",
    "l-BJCdAAAAAJ": "Marius Kloft",
    "lcOacs8AAAAJ": "Massimiliano Pontil",
    "B58vq_cAAAAJ": "Daniel Haase",
    "OYh64JwAAAAJ": "Manuel Amthor",
    "tQgvgxkAAAAJ": "Frank Fuchs-Kittowski",
    "fXl8n9YAAAAJ": "Andreas Abecker",
    "pKnD8WcAAAAJ": "Xiaoyan Jiang",
    "Ae9GkVQAAAAJ": "Raphael Wallsberger",
    "9FZlpDMAAAAJ": "Humberto Sossa",
    "iGgOj5oAAAAJ": "Gonzalo Pajares ( ORCID 0000-0003-0915-6282)",
    "uUuq67cAAAAJ": "Johannes Ruehle",
    "DtV6CrMAAAAJ": "Matthias Budde",
    "wqHic0AAAAAJ": "Mario Koddenbrock",
    "7qTg_1kAAAAJ": "Dario Papale",
    "6mgnauMAAAAJ": "Gustau Camps-Valls",
    "Wsru2ZYAAAAJ": "Stephan Matzka",
    "Y3pGXxwAAAAJ": "Hasnain Raza",
    "Ph-fOwQAAAAJ": "Chris Schmitz",
    "fF1B7mAAAAAJ": "Terrance E. Boult",
    "dlV-qnUAAAAJ": "Walter Scheirer",
    "-LJCZMMAAAAJ": "Angela Yao",
    "JeLy9lMAAAAJ": "Seyed Ali Amirshahi",
    "D5CISpEAAAAJ": "Azeddine Beghdadi",
    "qhEK194AAAAJ": "Kristian Hildebrand",
    "YuOHpwUAAAAJ": "Mohamed Riad YAGOUBI",
    "zX7fPHkAAAAJ": "Nicholas M. Brisson",
    "XDsMg4YAAAAJ": "Professor Deborah Falla",
    "D-AN9vQAAAAJ": "Georg N Duda",
    "am2ohp0AAAAJ": "Alexander Löser",
    "lmQkD9UAAAAJ": "Justus Westerhoff",
    "4sgWuPcAAAAJ": "Alexei Figueroa",
    "bKlSszcAAAAJ": "Kamilla Tenório",
    "Jg7O2scAAAAJ": "Ralf Romeike",
    "8RJ07aQAAAAJ": "Christoph Käding",
    "E1c2bVoAAAAJ": "Lan Lei",
    "3mQFWSYAAAAJ": "Li Wang",
    "0Y3a3M4AAAAJ": "Christian Claudel",
    "JrKoQLgAAAAJ": "Amin Khalek",
    "xdCvBg0AAAAJ": "Han Yufei",
    "8IMaM0QAAAAJ": "Fabien Moutarde",
    "CdEMlrIAAAAJ": "Etienne Côme",
    "njAD34UAAAAJ": "Tianwei Ni",
    "PKRe4QwAAAAJ": "Kenney Ng",
    "5jIJb38AAAAJ": "Bum Chul Kwon",
    "wAxr6b8AAAAJ": "Adam Perer",
    "b2LJDtMAAAAJ": "Janu Verma",
    "3MzhkFIAAAAJ": "Carl Vondrick",
    "bBLqsgkAAAAJ": "Soroush Nasiriany",
    "Vlfz-_IAAAAJ": "Adam Villaflor",
    "iBBpnUEAAAAJ": "Kevin X Li",
    "ao8r3Q4AAAAJ": "Spyros Maniatopoulos",
    "duOys3YAAAAJ": "Hadas Kress-Gazit",
    "sb3lPX8AAAAJ": "David C. Conner",
    "jbYnJLMAAAAJ": "Philipp Schillinger",
    "fSXCOfEAAAAJ": "Jesse Zhang",
    "XYsMnBsAAAAJ": "David Sivakoff",
    "pzkLOIwAAAAJ": "Rick Durrett",
    "3BMRzr8AAAAJ": "Abhishek Gupta",
    "dGs2BcIAAAAJ": "Kostas Daniilidis",
    "_fxnybwAAAAJ": "Janardhan Kulkarni",
    "KQaf5-wAAAAJ": "Huanyu Zhang",
    "FcRGdiwAAAAJ": "Da Yu",
    "mFbLNZQAAAAJ": "Argyris Mouzakis",
    "ke0k9PkAAAAJ": "Yiwei Lu",
    "bYhGFrwAAAAJ": "Sivakanth Gopi",
    "K6ef57QAAAAJ": "Ananda Theertha Suresh",
    "zbXIQMsAAAAJ": "Yaoliang Yu",
    "Jnei_lEAAAAJ": "Mahbod Majid",
    "AUJuK3AAAAAJ": "Alex Bie",
    "BGN4egcAAAAJ": "Huseyin A. Inan",
    "LpWGWAwAAAAJ": "Andre Manoel",
    "2kPveDIAAAAJ": "Lukas Wutschitz",
    "y8s4ok0AAAAJ": "Wanrong Zhang",
    "3I4iQioAAAAJ": "Pranav Subramani",
    "Jy0SwIcAAAAJ": "Matthew Regehr",
    "jJ8BLgsAAAAJ": "Li Xiong",
    "wFLYIm0AAAAJ": "Damien Desfontaines",
    "f8RkRagAAAAJ": "Roxana Geambasu",
    "NcIqQ88AAAAJ": "Andreas Terzis",
    "DsR4PucAAAAJ": "David Evans",
    "lzfVm_8AAAAJ": "Olga Ohrimenko",
    "YqKbGXAAAAAJ": "Jimmy Z Di",
    "cHAnhqcAAAAJ": "Sourav Biswas",
    "NFCefosAAAAJ": "Nicholas Vadivelu",
    "PHvnX-EAAAAJ": "Xingtu Liu",
    "T4DF6CAAAAAJ": "Hassan Ashtiani",
    "bVWm69gAAAAJ": "Ishaq Aden-Ali",
    "kezPqwoAAAAJ": "Shai Ben-David",
    "X-s3kzUAAAAJ": "Jack Douglas",
    "uhFQ9WgAAAAJ": "Shubhankar Mohapatra",
    "rrJTgX0AAAAJ": "Sajin Sasy",
    "kb4ubhcAAAAJ": "Amit Levi",
    "xDNZlnMAAAAJ": "Matthew YR Yang",
    "sSPq-ZEAAAAJ": "Debeshee Das",
    "M3XQkq4AAAAJ": "Ziteng Sun",
    "p8Y0xJEAAAAJ": "Guojun Zhang",
    "oYAf_hgAAAAJ": "Martin Pawelczyk",
    "soDBSE8AAAAJ": "Jie Zhang",
    "NkYQr9QAAAAJ": "Wenxin Ding",
    "Cl73CgcAAAAJ": "Zuoqiu Liu",
    "Nmk26z4AAAAJ": "Ruicheng Xian",
    "7YWMCDkAAAAJ": "Christian Janos Lebeda",
    "is41ryYAAAAJ": "Sushant Agarwal",
    "IFZY5fMAAAAJ": "Tosca Lechner",
    "JhIotuYAAAAJ": "Anne Driemel",
    "QSVAzVIAAAAJ": "Sepehr Assadi",
    "UNzFsf4AAAAJ": "Yihan Wang",
    "SKaPm_QAAAAJ": "Valentio Iverson",
    "YK0NLaUAAAAJ": "Antonio Vergari",
    "F27Q6V4AAAAJ": "Sajid Bashir",
    "0-YNNKUAAAAJ": "Zhiping Luo",
    "YtAIQ34AAAAJ": "Iliana E. Medina-Ramírez",
    "9jfZ5SIAAAAJ": "Srinath Palakurthi",
    "8U7qLuIAAAAJ": "Hong-Cai Zhou",
    "zK33NPkAAAAJ": "Frank Bentley",
    "lXBUU7EAAAAJ": "Linus Gisslén",
    "TXqPY5IAAAAJ": "Pietro Lungaro",
    "GtfVLBAAAAAJ": "Joakim Bergdahl",
    "MZHW6YMAAAAJ": "Scott L Robertson",
    "-QZbHHoAAAAJ": "Laura Levy",
    "ZqLIu1EAAAAJ": "Peter Stephenson",
    "YVfxyeQAAAAJ": "Yngve Sundblad",
    "Yy6WaDkAAAAJ": "jan markendahl",
    "AScNRHUAAAAJ": "Alisa Devlic",
    "PDIstVQAAAAJ": "Kirsten Rassmus-Gröhn",
    "x5iJp8oAAAAJ": "Richard Catrambone",
    "ZxeB6xkAAAAJ": "Pavan Kamaraju",
    "RdvLNP4AAAAJ": "Jörg Müller",
    "z8tUc2IAAAAJ": "Björn Thuresson",
    "NcB2lzcAAAAJ": "Luis Guillermo Martinez Ballesteros",
    "uu7LudIAAAAJ": "Stephen Brewster",
    "mx0jp-YAAAAJ": "L Tiina Sarjakoski",
    "rftklyIAAAAJ": "Margarita Anastassova",
    "ZNE6TqsAAAAJ": "Markus Fiedler",
    "GIejbKQAAAAJ": "Katarzyna Wac",
    "KKLUF8kAAAAJ": "Martin Pielot",
    "b7JHXbgAAAAJ": "Mareike Glöss",
    "nRPjLBQAAAAJ": "Alex Olwal",
    "Jwmp358AAAAJ": "Firdose KA",
    "u4olrOcAAAAJ": "Xiaoliang Dai",
    "qUt2HE8AAAAJ": "Geoffrey H Tison MD, MPH",
    "cEDjw_wAAAAJ": "Robert Avram",
    "mNguJ48AAAAJ": "Derek Wan",
    "_ruE6kgAAAAJ": "Hanxiang Hao",
    "wDltOqQAAAAJ": "Sung Hoon Lim",
    "B48jbeEAAAAJ": "Fatemeh Arbabjolfaei",
    "Jz1O6loAAAAJ": "Amos Lapidoth",
    "5ZYeWgcAAAAJ": "Jongha Jon Ryu",
    "FNwI36EAAAAJ": "Bernd Bandemer",
    "k-o3JBIAAAAJ": "Sae-Young Chung",
    "AEy91GEAAAAJ": "Drew A. Hall",
    "YxkMuYsAAAAJ": "Li Gao",
    "U8dAtsQAAAAJ": "Yu Xiang",
    "56urJP0AAAAJ": "Styrmir Sigurjonsson",
    "6S09ezcAAAAJ": "Ofer Shayevitz",
    "lrzfjUQAAAAJ": "Seok-Ki Ahn",
    "dJRKST0AAAAJ": "Bhaskar Rao",
    "Ci5YRtAAAAAJ": "chiranjib choudhuri",
    "SUAT64AAAAAJ": "Urbashi Mitra",
    "wfnTS8UAAAAJ": "Assaf Ben-Yishai",
    "lOhHz0gAAAAJ": "Yucheng Liu",
    "tJlviVYAAAAJ": "Michele Wigger",
    "Bphl_fIAAAAJ": "Sungroh Yoon",
    "R-7TkKkAAAAJ": "Seung-Jean Kim",
    "eGj3ay4AAAAJ": "Jung-Woo Ha",
    "MSgWKbYAAAAJ": "Minghai Qin",
    "Viv2E9AAAAAJ": "Eitan Yaakobi",
    "OdLQTz4AAAAJ": "Byunghan Lee",
    "LAl0EukAAAAJ": "Gyuwan Kim",
    "YQ0GIUwAAAAJ": "Yuzhe Jin",
    "k8uWc34AAAAJ": "Yung-Kyun Noh",
    "oVLqz3AAAAAJ": "Dan Work",
    "ify5zKQAAAAJ": "Benedetto Piccoli",
    "68HhxmAAAAAJ": "Walid Krichene",
    "bTG82acAAAAJ": "Ian M. Mitchell",
    "V6rOl-gAAAAJ": "Xavier LITRICO",
    "Tiq0XaMAAAAJ": "Jack Reilly",
    "txxQb7cAAAAJ": "Xuegang Ban",
    "Ks1yyXYAAAAJ": "Samitha Samaranayake",
    "k0b8yXkAAAAJ": "Maria Laura Delle Monache",
    "ijIHem4AAAAJ": "goatin paola",
    "VAamLcEAAAAJ": "Shideh Dashti",
    "GkwzzEAAAAAJ": "Dengfeng Sun",
    "74w7FDUAAAAJ": "Nikolaos Bekiaris-Liberis",
    "HSPbKTAAAAAJ": "Marco Gruteser",
    "P2rIVYIAAAAJ": "Baik Hoh",
    "YAGjro8AAAAJ": "Marta C. Gonzalez",
    "dI-eZ3sAAAAJ": "Simon Munier",
    "5_l9dl8AAAAJ": "David Dorchies",
    "OQHNvrEAAAAJ": "Hoam Chung",
    "32gDqAYAAAAJ": "Jean Pierre Aubin",
    "_2k-ppwAAAAJ": "Paul Borokhov",
    "20_pofsAAAAJ": "Anoop Korattikara",
    "90FJPJUAAAAJ": "Zbigniew Wojna",
    "y3xgouMAAAAJ": "Menglong Zhu",
    "vQa7heEAAAAJ": "Chen Sun",
    "7U_OA0oAAAAJ": "Siqi Liu",
    "Zfzp_GIAAAAJ": "Zhenhai Zhu",
    "7IDZrScAAAAJ": "Ning Ye",
    "S6H-0RAAAAAJ": "Lotfi A. Zadeh",
    "JrX99ekAAAAJ": "Jerry M. Mendel",
    "uAsllJMAAAAJ": "Ronald R Yager",
    "ruHs0xMAAAAJ": "Jonathan Lawry",
    "ZZ61SZwAAAAJ": "Hani Hagras",
    "9QR0uE4AAAAJ": "Nick Johnston",
    "svJIv28AAAAJ": "Alexander Gorban",
    "Tw8DY-cAAAAJ": "Austin Myers",
    "qvrqNfwAAAAJ": "Claudio Moraga",
    "jInmtEkAAAAJ": "Jasper RR Uijlings",
    "jn5r6TsAAAAJ": "Pablo Samuel Castro",
    "9om-fCsAAAAJ": "Efi Kokiopoulou",
    "CSHNLDcAAAAJ": "Jesse Berent",
    "Gzo8z-kAAAAJ": "Ryan Dahl",
    "sm1q2bYAAAAJ": "Jonathon Shlens",
    "oUmv8xgAAAAJ": "Oscar Cordón",
    "v3VmgekAAAAJ": "Oscar Ibañez",
    "MFoV3lsAAAAJ": "Gonzalo Bailador",
    "w6RxCIkAAAAJ": "Susana Muñoz Hernández",
    "4hbbNREAAAAJ": "Sergio Damas",
    "zHXnq0IAAAAJ": "David P. Pancho",
    "L_9C4v0AAAAJ": "Jonathan M. Garibaldi",
    "UfCI-NcAAAAJ": "Martine De Cock",
    "kLqUY1gAAAAJ": "Carmen Campomanes-Alvarez",
    "Cj-TQ-AAAAAJ": "BR Campomanes-Alvarez",
    "YNGHCrAAAAAJ": "Veronica Sanz",
    "Lx3Dc9cAAAAJ": "JOSE ANGEL OLIVAS",
    "63TLsRcAAAAJ": "Maxim Batalin",
    "3_WYcR4AAAAJ": "Deborah Estrin",
    "vnsFRJUAAAAJ": "Srikanth Saripalli",
    "7oD5x5oAAAAJ": "Arvind Antonio de Menezes Pereira",
    "0SQP4bwAAAAJ": "Geoffrey Hollinger",
    "ZTkRs84AAAAJ": "Ramesh Govindan",
    "Eja4Kw4AAAAJ": "Jnaneshwar Das",
    "1lHiuAQAAAAJ": "Sameera Poduri",
    "HEulGGsAAAAJ": "Beth A. Stauffer",
    "0dnObMUAAAAJ": "Hordur K Heidarsson",
    "KtSR8_0AAAAJ": "Jonathan Kelly",
    "XizXVNcAAAAJ": "Ryan N. Smith",
    "aOO2tOwAAAAJ": "Karthik Dantu",
    "QXgZyjAAAAAJ": "Harsh Vathsangam",
    "X2Qs7XYAAAAJ": "Mani Srivastava",
    "rPCzqN4AAAAJ": "Richard Vaughan",
    "BSJyuqQAAAAJ": "Artem Molchanov",
    "ncy_2xUAAAAJ": "Denis Wolf",
    "c5HeXxsAAAAJ": "Stergios I. Roumeliotis",
    "MNp5hwoAAAAJ": "Gabe Sibley",
    "ke2MEF0AAAAJ": "Nora Ayanian",
    "3hYIetoAAAAJ": "Stefan Hrabar",
    "CRclm5cAAAAJ": "Ryan Williams",
    "s4I2aDgAAAAJ": "Kasper Stoy",
    "2pp8xosAAAAJ": "Marcos AM Vieira",
    "-BgdY0oAAAAJ": "Harry Zhe Su",
    "FWDKUMUAAAAJ": "Aman Kansal",
    "ccksLFUAAAAJ": "Frédéric Py",
    "jeb2t4AAAAAJ": "Torbjorn S. Dahl",
    "JHJozAYAAAAJ": "Bhaskar Krishnamachari",
    "nQBhQawAAAAJ": "Stephanie Kemna",
    "jqH6384AAAAJ": "Andrea Gasparri",
    "wnePPc4AAAAJ": "Peter Corke",
    "lhpoASkAAAAJ": "Joerg Mueller",
    "kqW_-2gAAAAJ": "Nenad Medvidovic",
    "XxGyUpAAAAAJ": "Lynne E. Parker",
    "ra1iQ8cAAAAJ": "Marin Kobilarov",
    "pcWicN8AAAAJ": "Brian Gerkey",
    "bN_de_QAAAAJ": "John Heidemann",
    "PynKWyQAAAAJ": "Max Pflueger",
    "1ViBXywAAAAJ": "Christian Potthast",
    "-4cUri0AAAAJ": "Goksel Dedeoglu",
    "EjOkyc0AAAAJ": "Yi Chao",
    "gJE5IssAAAAJ": "krishna chintalapudi",
    "a8ZyGisAAAAJ": "Mathieu Desbrun",
    "83OxU_4AAAAJ": "Oliver Brock",
    "8EDHmYkAAAAJ": "Shrikanth (Shri) Narayanan",
    "aQsc6KwAAAAJ": "Erica L Seubert",
    "9RNcFO0AAAAJ": "Sandeep Babel",
    "1sqZDWIAAAAJ": "Andreas Breitenmoser",
    "MDWCSOQAAAAJ": "Luis Mejias",
    "3_tE6JgAAAAJ": "Ashley Tews",
    "fRwcQToAAAAJ": "Megha Gupta",
    "tpoh43QAAAAJ": "Sven Koenig",
    "dQmvEyUAAAAJ": "Stephan Weiss",
    "OpAiiOAAAAAJ": "Srinivas Yerramalli",
    "-EqbTXoAAAAJ": "Mac Schwager",
    "37lzFAoAAAAJ": "Milica Stojanovic",
    "_9G6V38AAAAJ": "Sunav Choudhary",
    "7UCco8IAAAAJ": "Gerard Jounghyun Kim",
    "fiM8AFsAAAAJ": "Sangyoon Lee",
    "XB3_I9cAAAAJ": "Monique Messié",
    "apPMLQ4AAAAJ": "Pascual Campoy",
    "TZ9DF0kAAAAJ": "Thomas C Harmon, Professor",
    "DBLgVFQAAAAJ": "Avinash Parnandi",
    "1e_R-xoAAAAJ": "Jonathan Roberts",
    "hUWfaL0AAAAJ": "Astrid Schnetzer",
    "IxCZDBQAAAAJ": "Sanjiv Singh",
    "_gfwCNwAAAAJ": "Stephen L. Smith",
    "1UEU5PEAAAAJ": "Hanumant Singh",
    "ijtcJ1sAAAAJ": "Parastoo Qarabaqi",
    "RLzWUrwAAAAJ": "Chris Murphy",
    "s9eCQn4AAAAJ": "Brian M Sadler",
    "8M-hWKMAAAAJ": "Nils Peter Borgstrom",
    "gYCRa7wAAAAJ": "Ivona Cetinić",
    "2gpXz3IAAAAJ": "Leana Golubchik",
    "WSN7T_YAAAAJ": "Ronald C. Arkin",
    "dmDQklMAAAAJ": "giovanni ulivi",
    "haCXENgAAAAJ": "George Edwards",
    "0h0oV7oAAAAJ": "Hossein Tajalli",
    "SRCCuo0AAAAJ": "Kasra Khosoussi",
    "t4k2EtkAAAAJ": "Gamini Dissanayake",
    "DMsPWz0AAAAJ": "Shoudong Huang",
    "NOZmGq0AAAAJ": "Bharath Sankaran",
    "9i_MgykAAAAJ": "Hang Qiu",
    "J5kGUDMAAAAJ": "Marie-Eve Garneau",
    "Z-Qe2UUAAAAJ": "Gerardo Toro-Farmer",
    "Vs9YD9kAAAAJ": "Myungsoo Jun",
    "5a9ddsQAAAAJ": "Robert MacLachlan",
    "Kv9W_ZYAAAAJ": "Sangwon Lee",
    "YtWK2I8AAAAJ": "Erik A Johnson",
    "TrMmYPIAAAAJ": "Anthony Cowley",
    "r3A90uAAAAAJ": "Mi Zhang",
    "aLBeFYcAAAAJ": "Nicholas B Wettels",
    "qqbRBXEAAAAJ": "Thane Somers",
    "4wXYfSUAAAAJ": "Scott Niekum",
    "jV66t1kAAAAJ": "Sarah Osentoski",
    "dASv28sAAAAJ": "Daniel Popescu",
    "Lf2KB6cAAAAJ": "Marco Levorato",
    "9PVf18oAAAAJ": "Daphney-Stavroula Zois",
    "10HcE2QAAAAJ": "Yurong Jiang",
    "xWdb5R8AAAAJ": "Marco Zuniga",
    "XOWZzUcAAAAJ": "Jens Kober",
    "VQJR8WoAAAAJ": "Sumit Rangwala",
    "YVfr3wwAAAAJ": "Yuriy Brun",
    "B-4cOBMAAAAJ": "Ivo Krka",
    "qrCVP0YAAAAJ": "Sam Malek",
    "8HCVx48AAAAJ": "Marija Mikic-Rakic",
    "838_NnIAAAAJ": "Mehmet Akar",
    "A8YEQMMAAAAJ": "Erhan Oztop",
    "Kv2Sm7oAAAAJ": "Jesse Butterfield",
    "wOuOYO4AAAAJ": "Robert Ghrist",
    "Q38iIK4AAAAJ": "James Bellingham",
    "2P-Q09UAAAAJ": "Bryan Kian Hsiang Low",
    "WQXD3uAAAAAJ": "M Anthony Lewis",
    "tQPt2LcAAAAJ": "Roshanak Roshandel",
    "R1eV0ekAAAAJ": "Bruno Siciliano",
    "ABr4UU4AAAAJ": "Maite Lopez-Sanchez",
    "7e456ToAAAAJ": "Eric Shieh",
    "DwUrFHUAAAAJ": "Wei Peng",
    "rgLGzAQAAAAJ": "Anand A Joshi",
    "2jOYB6oAAAAJ": "Ajay Deshpande",
    "px1ffwoAAAAJ": "Jesse Goldman",
    "TBoc26oAAAAJ": "Thomas Rühr",
    "qdINILwAAAAJ": "abhishek sharma",
    "jNUBLwMAAAAJ": "William Christopher Evans",
    "A8DhSR4AAAAJ": "Alexander Bahr",
    "uVTR_eoAAAAJ": "Alcherio Martinoli",
    "AFf15XkAAAAJ": "Matthew",
    "L8HAaJYAAAAJ": "Raphael Kudela",
    "QLsu5OQAAAAJ": "Alle An Ying Lie",
    "uHhsRFgAAAAJ": "Ramon Terrado",
    "KCv6gOQAAAAJ": "Kevan Yamahara",
    "mYKbo8YAAAAJ": "James M. Birch",
    "uwadDKYAAAAJ": "Roland Brockers",
    "JtPSC9sAAAAJ": "Shi Qiu",
    "xbHranwAAAAJ": "Hongmo Je",
    "pRclXR8AAAAJ": "Naveen Kumar",
    "nQaxVCsAAAAJ": "Prateek Tandon",
    "f_gNVb8AAAAJ": "Bridget N. Seegers",
    "ALVSZAYAAAAJ": "Jian Sun",
    "AUhj438AAAAJ": "Shaoqing Ren",
    "TDk_NfkAAAAJ": "Joseph Redmon",
    "j5_DDM0AAAAJ": "Lukasz Wesolowski",
    "eSOXB6IAAAAJ": "Jamie Shotton",
    "xY1GdVgAAAAJ": "Sean Bell",
    "Rh16nsIAAAAJ": "Kavita Bala",
    "T_Q-xDkAAAAJ": "Yuxiong Wang",
    "OOcllDwAAAAJ": "Toby Sharp",
    "yuB-cfoAAAAJ": "Xiangyu Zhang",
    "ZO3Ek1gAAAAJ": "Iasonas Kokkinos",
    "bRT7t28AAAAJ": "Andrea Vedaldi",
    "c4mWQPQAAAAJ": "Juho Kannala",
    "SmGZwHYAAAAJ": "Esa Rahtu",
    "4hC_FYoAAAAJ": "Stavros Tsogkas",
    "WH2KmRgAAAAJ": "David W. Jacobs",
    "24OOpyEAAAAJ": "Caroline Klivans",
    "bda1zGQAAAAJ": "Naomi Saphra",
    "-5pzdw4AAAAJ": "Jonathan Z. Long",
    "_TgGqhsAAAAJ": "Elizabeth A. Leicht",
    "QEh45NMAAAAJ": "Pósfai Márton",
    "Z2Kn9ucAAAAJ": "Charles (Charlie) Brummitt",
    "y9jYYRkAAAAJ": "Jan Nagler",
    "5EGhZTgAAAAJ": "Wei Chen",
    "D37XAbIAAAAJ": "James Crutchfield",
    "VWNTaCgAAAAJ": "Anastasiya Salova",
    "rzwHnAcAAAAJ": "Vladimir Filkov",
    "0aIhBb0AAAAJ": "Leonardo Duenas-Osorio",
    "tQ5vbOAAAAAJ": "Prem  Devanbu",
    "FxU9cG0AAAAJ": "Pierre-André Noël",
    "QOLH_TwAAAAJ": "Airlie Chapman",
    "58ShSfwAAAAJ": "Xiaoqun Wu",
    "84FUioAAAAAJ": "Yang-Yu Liu",
    "cOkx0_IAAAAJ": "Guram Mikaberidze",
    "BC1Zc78AAAAJ": "Mario di Bernardo",
    "FHwvVmkAAAAJ": "Eugene Fiume",
    "SUbqiqwAAAAJ": "Philippe Beaudoin",
    "sX31JjwAAAAJ": "Prof. Dr. Stelian Coros",
    "pKuBFaQAAAAJ": "Demetri Terzopoulos",
    "q7FiLBkAAAAJ": "Libin Liu",
    "-NXsLG4AAAAJ": "Nicolas Bonneel",
    "al5P0bAAAAAJ": "Pierre Poulin",
    "qRXK__gAAAAJ": "Weiwei Xu",
    "aHs2JHgAAAAJ": "Shailen Agrawal",
    "_CEwIJwAAAAJ": "Thomas Geijtenbeek",
    "RlSbIJ4AAAAJ": "Frank van der Stappen",
    "h4kYmRYAAAAJ": "Baining Guo",
    "l8WuQJgAAAAJ": "Andrej Karpathy",
    "z0RoFtcAAAAJ": "Marie-Paule CANI",
    "IQSbom0AAAAJ": "Wolfgang Heidrich",
    "s_5xXxQXpU0C": "Ronald A. Rensink",
    "ZisEORUAAAAJ": "Ben Jones",
    "IJ1yaGsAAAAJ": "Jun Wang(王 军)",
    "N-iYby0AAAAJ": "Kun Zhou",
    "IgkGxLsAAAAJ": "Alla Sheffer",
    "w4XsexUAAAAJ": "Loïc Barthe",
    "CROZP6wWEwEC": "Boris Dalstein",
    "Ln5Ksv0AAAAJ": "Anita Layton",
    "Uro_AS0AAAAJ": "Paul Kry",
    "r4gezHUAAAAJ": "Frederic Cordier",
    "c2Att08AAAAJ": "Tamara Munzner",
    "fAxws1sAAAAJ": "Daniel Cohen-Or",
    "JsK4KpMAAAAJ": "Tao Ju",
    "zfTbkBkAAAAJ": "Qian-Yi Zhou",
    "ZiON80cAAAAJ": "Dinesh K. Pai",
    "NJ9c4ygAAAAJ": "Fredo Durand",
    "o29n55IAAAAJ": "Sylvain Lefebvre",
    "EiwH233ldzsC": "Ken Alton",
    "ebNrBjYAAAAJ": "Eric Saund",
    "rQoKPUsAAAAJ": "George Kantor",
    "jZgjlGUAAAAJ": "Lei Zou",
    "UesKv-0AAAAJ": "Yanzeng Li",
    "M8wm74gAAAAJ": "Kari Tammi",
    "o3nJb1EAAAAJ": "José Luis Peralta-Cabezas",
    "A-4JUL4AAAAJ": "John Zimmerman",
    "6YU6_QoAAAAJ": "Scott E. Hudson",
    "YR1EmaAAAAAJ": "Carl DiSalvo (he / him)",
    "JS7sVyQAAAAJ": "Ian Li",
    "LT9zh4sAAAAJ": "William Odom",
    "t-VqN7sAAAAJ": "Reid G. Simmons",
    "1IPn2HgAAAAJ": "Carlo Lucibello",
    "klxwxyUAAAAJ": "Luca Saglietti",
    "TJF5CosAAAAJ": "Enrico M. Malatesta",
    "sT_qeloAAAAJ": "Fabrizio Pittorino",
    "dvDLaPkAAAAJ": "Federica Gerace",
    "zVAYbpYAAAAJ": "Fabio Angelo Maccheroni",
    "6KWZup8AAAAJ": "massimo marinacci",
    "UGZ0jy4AAAAJ": "Clarissa Lauditi",
    "BRWwxYwAAAAJ": "Marino Pagan",
    "qenoZwUAAAAJ": "James J DiCarlo",
    "S8Ov5d8AAAAJ": "Elizaveta Demyanenko",
    "Bs0aA-UAAAAJ": "Federica Cavallo",
    "FLY_0BEAAAAJ": "Carla Bosia",
    "WeEK60YAAAAJ": "Simone Cerreia-Vioglio",
    "DytvG6cAAAAJ": "Rosalba Pacelli",
    "JSkBINwAAAAJ": "Hilbert Johan Kappen",
    "uKuvN64AAAAJ": "Enzo Tartaglione",
    "KvRjw-4AAAAJ": "Matteo Negri",
    "9cBUERoAAAAJ": "Glen Bigan Mbeng",
    "HQDpzBoAAAAJ": "Giuseppe E. Santoro",
    "m4rsQCAAAAAJ": "Deyu Bo",
    "tUq_v90AAAAJ": "Chuan Shi",
    "rIUE-FoAAAAJ": "Qi Yan",
    "eRCF2KsAAAAJ": "Jiaming Cheng",
    "EVWYEMQAAAAJ": "Duong Tung Nguyen",
    "jLPy8-4AAAAJ": "Mohammad Naghshvar",
    "Owy8RMEAAAAJ": "Vijay Bhargava",
    "JS72sbsAAAAJ": "Sihuang Hu",
    "1t-vpJ8AAAAJ": "Paul Siegel",
    "hZhJhmIAAAAJ": "Bicheng Xu",
    "Xn--pmkAAAAJ": "Amirhossein Abaskohi",
    "HNNL22kAAAAJ": "Giuseppe Carenini",
    "10ZeC3MAAAAJ": "AmirHossein DabiriAghdam",
    "EMADq2wAAAAJ": "Guanding Yu",
    "UhmcQ7gAAAAJ": "Szymon Sidor",
    "zMoR8AEAAAAJ": "Wouter Tavernier",
    "VC3Z6dcAAAAJ": "Sahel Sahhaf",
    "fBXk3G4AAAAJ": "Cedric De Boom",
    "hwqQOpUAAAAJ": "Steven M. Block",
    "zSdOp4EAAAAJ": "Christian F Perez",
    "k5RXEZYAAAAJ": "Van Duesterberg",
    "VXtCp7MAAAAJ": "Zhipeng Lu",
    "uhwGITAAAAAJ": "Kongpan Li",
    "7YSki00AAAAJ": "Minjie Zhang",
    "PGodeKsAAAAJ": "Jianhui Bai",
    "DpsEpaoAAAAJ": "Dylan Grosz",
    "ng9o57kAAAAJ": "Vivian Yang",
    "ZpWzifcAAAAJ": "Xinlan Emily Hu",
    "l7Ra9p8AAAAJ": "Richard Fang",
    "sTzb6LAAAAAJ": "Deepak Narayanan",
    "65-B1ZwAAAAJ": "Akul Gupta",
    "XaYJrgoAAAAJ": "Qiusi Zhan",
    "IzXDyR8AAAAJ": "Kunle Olukotun",
    "OtJC70cAAAAJ": "Cody Coleman",
    "Kgs3zQoAAAAJ": "Luigi Nardi",
    "DnnCWN0AAAAJ": "Christopher Ré",
    "SZ7-g60AAAAJ": "Firas Abuzaid",
    "QS5CTxcAAAAJ": "Animesh Koratana",
    "5z2rh_oAAAAJ": "Haoyang Zeng",
    "YaBPvxAAAAAJ": "Evgenya Pergament",
    "cc4Qi_IAAAAJ": "Sachin Katti",
    "K-KlWSsAAAAJ": "Peter Kraft",
    "n5ENv9EAAAAJ": "Shoumik Palkar",
    "OqbV4dwAAAAJ": "Deepti Raghavan",
    "MEk1MWoAAAAJ": "Richard I Sherwood",
    "IWPWNxkAAAAJ": "Logan Engstrom",
    "wm2BrUcAAAAJ": "Jian Zhang",
    "zaF8UJcAAAAJ": "Stephen Casper",
    "7cU2rQsAAAAJ": "Gillian K. Hadfield",
    "O6NknDYAAAAJ": "Andreas Haupt",
    "VSsTq14AAAAJ": "McKane Andrus",
    "3y_M1cUAAAAJ": "Joel Z Leibo",
    "4lmER2EAAAAJ": "Simon Zhuang",
    "MeNbzgIAAAAJ": "Micah Carroll",
    "WxZ_6nsAAAAJ": "Gabriel Kreiman",
    "eEGGCiUAAAAJ": "Raphael Köster",
    "XnUZEcoAAAAJ": "Vael Gates",
    "RGiCLUgAAAAJ": "Pratyusha Sharma",
    "700fyvEAAAAJ": "Belinda Z. Li",
    "38EC20cAAAAJ": "Evan Hernandez",
    "FN2kigYAAAAJ": "Sarah Schwettmann",
    "O-vquhwAAAAJ": "Adam Pauls",
    "1qmAFhsAAAAJ": "Gabriel Grand",
    "RXsYj9IAAAAJ": "Afra Feyza Akyürek",
    "CYI6cKgAAAAJ": "David Bau",
    "ujDhg2sAAAAJ": "Kathleen McKeown",
    "vM8t8zwAAAAJ": "Sara Rosenthal",
    "VBz8gZ4AAAAJ": "Cédric Colas",
    "vHd2qAkAAAAJ": "Daniel Bauer",
    "WmH1GQoAAAAJ": "Karl Moritz Hermann",
    "oQnyyGkAAAAJ": "Kevin Knight",
    "oeg_NN4AAAAJ": "Aleksandr Nisnevich",
    "8lmWWD0AAAAJ": "Derry Tanti Wijaya",
    "r21asW4AAAAJ": "Shiyu Chang",
    "NsuX8R8AAAAJ": "Maxwell Nye",
    "1CgET20AAAAJ": "Evelina (Ev) Fedorenko",
    "gznWHL4AAAAJ": "Shane Gero",
    "_-5PSgQAAAAJ": "Yang Zhang",
    "Rd18rbYAAAAJ": "Olivia Watkins",
    "D1uOAWcAAAAJ": "Linlu Qiu",
    "VOIlmnoAAAAJ": "Larry Gillick",
    "wlosgkoAAAAJ": "Graham Neubig",
    "tjb2UccAAAAJ": "Jason Eisner",
    "j67B9Q4AAAAJ": "Mirella Lapata",
    "eMwEEXUAAAAJ": "Nicolas Pinto",
    "tmK5EPEAAAAJ": "Jonathan May",
    "ubAcojQAAAAJ": "Shikhar Murty",
    "sktDNcEAAAAJ": "Gabriele Farina",
    "ezllEwMAAAAJ": "Edward Grefenstette",
    "zpil5xkAAAAJ": "Jelena Luketina",
    "iSI9-1oAAAAJ": "Nantas Nardelli",
    "mWBY8aIAAAAJ": "Tim Rocktäschel",
    "9zeEI-cAAAAJ": "Shimon Whiteson",
    "hDGGNYIAAAAJ": "Joe O'Connor",
    "_FZpPv0AAAAJ": "David F Gruber",
    "g6MislAAAAAJ": "Sam Thomson",
    "EFVk-mwAAAAJ": "Emmanouil Antonios Platanios",
    "7ICTJmoAAAAJ": "Clinton Wang",
    "iZpSjEYAAAAJ": "Ziqian Zhong",
    "dok0514AAAAJ": "David Chiang",
    "Uod-_B8AAAAJ": "Najoung Kim",
    "53baCywAAAAJ": "Zhaofeng Wu",
    "dHboSOoAAAAJ": "Jayant Krishnamurthy",
    "djLcGEQAAAAJ": "Jesse Mu",
    "ghdbIsoAAAAJ": "Maddy Bowers",
    "6jRu5x4AAAAJ": "Pernille Tønnesen",
    "r7gAWagAAAAJ": "Gašper Beguš",
    "i86O0SAAAAAJ": "Roger Levy",
    "AWNL69MAAAAJ": "Owen Rambow",
    "AZboOI8AAAAJ": "Kapil Thadani",
    "k0vrm6kAAAAJ": "Laura Ruis",
    "tVjxANMAAAAJ": "Kevin Ellis",
    "YQe9pdUAAAAJ": "Harsh Jhamtani",
    "6eHx7EgAAAAJ": "Drew Volpe",
    "orxu07YAAAAJ": "Michael Newman",
    "bBnvK8cAAAAJ": "Stephen Clark",
    "i9-GzNYAAAAJ": "Valts Blukis",
    "G5_VFfkAAAAJ": "Tucker Hermans",
    "1D8C9ZkAAAAJ": "Carina Kauf",
    "eBXEZxgAAAAJ": "Max Tegmark",
    "QeXHxlIAAAAJ": "Ziming Liu",
    "dqVBIjIAAAAJ": "Dan Tchernov",
    "xBX234cAAAAJ": "Daniel M. Vogt",
    "HxMQouAAAAAJ": "Roee Diamant",
    "jb__2PIAAAAJ": "Giovanni Petri",
    "gP9EAWkAAAAJ": "Alan Guo",
    "7WntHrAAAAAJ": "Ian Tenney",
    "w8ZDbO8AAAAJ": "Kelvin Guu",
    "oRPEEWIAAAAJ": "Tal Haklay",
    "pv54dqMAAAAJ": "Martin Wattenberg",
    "UcZbFroAAAAJ": "Kevin Meng",
    "8ihSLrwAAAAJ": "Arnab Sen Sharma",
    "W69x8yYAAAAJ": "Steven Horng",
    "1LuGqFQAAAAJ": "Peter Szolovits",
    "xGGUwFsAAAAJ": "Geeticka Chauhan",
    "h1zSzecAAAAJ": "Ruizhi (Ray) Liao",
    "fJQZVyAAAAAJ": "Or Biran",
    "50O3v1MAAAAJ": "Anton Bakhtin",
    "RLDbLcUAAAAJ": "Noam Brown",
    "k9IJYg8AAAAJ": "Patrick Xia",
    "0v1kYUEAAAAJ": "Yoni Friedman",
    "zV5vhUcAAAAJ": "Nicholas Tomlin",
    "jTMUPNkAAAAJ": "Jessy Lin",
    "xdwK2NsAAAAJ": "Maithra Raghu",
    "pJB4fIEAAAAJ": "Greta Tuckute",
    "SwNmwlcAAAAJ": "Alana Marzoev",
    "jdcLB8kAAAAJ": "Chuck Wooters",
    "qff5rRYAAAAJ": "Yikang Shen",
    "wHlw1L4AAAAJ": "Jason Wolfe",
    "Tqk2bsMAAAAJ": "William P. McCarthy",
    "ev8Ilx0AAAAJ": "Jane Yu",
    "V9JYPP0AAAAJ": "Madian Khabsa",
    "l2pAq_0AAAAJ": "Subhro Roy",
    "DGb-sBwAAAAJ": "Nizar Habash",
    "auA1nNAAAAAJ": "Shuang Li",
    "AOqzUmwAAAAJ": "Anusha Balakrishnan",
    "jRQtBp0AAAAJ": "Alex Gu",
    "okfWOCsAAAAJ": "Anton Belyy",
    "KssJcIAAAAAJ": "Lionel Catherine Wong",
    "p8Ft6RQAAAAJ": "Alexis Ross",
    "4peEKXMAAAAJ": "Maruthi Akella",
    "bIUsRBQAAAAJ": "Shrivu Shankar",
    "TlOMKqMAAAAJ": "Thomas Watteyne",
    "OTk6tAoAAAAJ": "JP Vasseur",
    "3JrkBn4AAAAJ": "Matthew Last",
    "7cLt5PAAAAAJ": "Steven Lanzisera",
    "1RGui4wAAAAJ": "Prof. David C Burnett",
    "wYpNpTEAAAAJ": "Xavier Vilajosana",
    "Yr2yu_sAAAAJ": "Ming C. Wu",
    "rzfe-vsAAAAJ": "Ezekiel Kruglick",
    "2hjvDoAAAAAJ": "Filip Maksimovic",
    "FoGc_e0AAAAJ": "Lih Y. Lin",
    "JbkP8EwAAAAJ": "Ankur Mehta",
    "K4_TvQQAAAAJ": "Jason Vaughn Clark",
    "XFuk24sAAAAJ": "Craig B. Schindler",
    "7cNE8rkAAAAJ": "Osama Khan",
    "27o6cX4AAAAJ": "Anders Brandt",
    "PXMOFVMAAAAJ": "Daniel S. Drew",
    "2wG4enAAAAAJ": "Patrick Chu",
    "N5rG_E0AAAAJ": "Daniel S. Contreras",
    "djRMREYAAAAJ": "Phyllis R. Nelson",
    "EyhHDj4AAAAJ": "Tengfei Chang",
    "SU0c5P0AAAAJ": "Sarah Bergbreiter",
    "O4jW7BsAAAAJ": "Nathan Lambert",
    "I_YsXU4AAAAJ": "Philip Levis",
    "reqGWxMAAAAJ": "Brian Kilberg",
    "EpidFw8AAAAJ": "Branko Kerkez",
    "DJEiH1IAAAAJ": "Michel M. Maharbiz",
    "urhvgT0AAAAJ": "Ali M NIKNEJAD",
    "CXJuZ5YAAAAJ": "Steven D Glaser",
    "xCA8j6oAAAAJ": "Lydia Lee",
    "PtFGOakAAAAJ": "Alyosha Molnar",
    "tVS1jp0AAAAJ": "Tsung-Hsien Lin",
    "tRPd-vQAAAAJ": "Hani C Gomez",
    "04TuVhEAAAAJ": "David Bindel",
    "hyJ_lk8AAAAJ": "Kevin Weekly",
    "i3wkV_kAAAAJ": "Michael W. Judy",
    "uW7jWOcAAAAJ": "Mališa Vučinić ",
    "soiDQbQAAAAJ": "Zhaojun Bai",
    "xADN4DUAAAAJ": "Luke P. Lee",
    "8tpFFEMAAAAJ": "Kevin Korner",
    "8xkg8pIAAAAJ": "Kosuke Iwai",
    "X4k8oLAAAAAJ": "Ben Hightower",
    "OXtNAU4AAAAJ": "D Curtis Deno",
    "l8RaE9YAAAAJ": "Michael H. Hecht",
    "Y0MyYO0AAAAJ": "Shad Roundy",
    "KkVl2qoAAAAJ": "Jan Rentmeister",
    "PNvJsN0AAAAJ": "Felipe MR Campos",
    "pdKcN5gAAAAJ": "Brad Wheeler",
    "iCdq_ZsAAAAJ": "Daniel Teal",
    "RCvR5HAAAAAJ": "Rachel Zoll",
    "LxmQ8eIAAAAJ": "Piotr Grodzinski",
    "5K1mZq0AAAAJ": "Mischa Dohler",
    "gmI1-UIAAAAJ": "Sanjay Govindjee",
    "grsfoH8AAAAJ": "Jason Stauth",
    "AgTN6m4AAAAJ": "Ryan D. Sochol",
    "FTe6HDoAAAAJ": "Liwei Lin",
    "fgDB2BoAAAAJ": "Casey Glick",
    "Wdo9AyQAAAAJ": "Eric Christopher Sweet, PhD",
    "C3-B4nwAAAAJ": "Aaron Wienkers",
    "vKflaosAAAAJ": "Brian Yang",
    "k8bn6q4AAAAJ": "Joseph Yaconelli",
    "nR8UJ3cAAAAJ": "Pere Tuset-Peiró (0000-0001-5803-667X)",
    "qXVG1AEAAAAJ": "Yusuf Bugra EROL",
    "lu2yOLkAAAAJ": "Richard Syms",
    "LbYsy_QAAAAJ": "Ana Claudia Arias",
    "IJgXsgwAAAAJ": "Edward A. LEE",
    "QmP0ggQAAAAJ": "A. Carlos FERNANDEZ-PELLO",
    "evReMyEAAAAJ": "Lance J. Kriegsfeld",
    "GnuEOOgAAAAJ": "Benjamin Smarr",
    "AWKaiasAAAAJ": "Paul Chang",
    "KLFjg9EAAAAJ": "Thomas I. Liao",
    "Bw25vHMAAAAJ": "Jason W. Weigold",
    "rno2y00AAAAJ": "Samantha Santacruz",
    "cnku7dQAAAAJ": "Andrew Fearing",
    "Hl8N_k8AAAAJ": "Mekhail Anwar",
    "kiF6OS4AAAAJ": "Wei Li",
    "ZT1ZkRcAAAAJ": "Dillon Acker-James",
    "SKq6DZcAAAAJ": "Anju Toor",
    "4-AyPLsAAAAJ": "Abhinav M. Gaikwad",
    "0RLF4vUAAAAJ": "Nicola Accettura",
    "5O7jjVgAAAAJ": "Sunil Bhave",
    "UVkOjSAAAAAJ": "Joon-Ho Lee",
    "ejyZTmEAAAAJ": "Borja Martinez",
    "-ILhc-sAAAAJ": "Ignasi Vilajosana",
    "cwff2XYAAAAJ": "John D Long",
    "OfYf-DMAAAAJ": "Nikolaus Correll",
    "yhJQnxwAAAAJ": "Ahad Mujtaba Rauf",
    "YsKTazIAAAAJ": "Andrew Minor",
    "1F1k4AUAAAAJ": "Karl F. Böhringer",
    "myYVVuYAAAAJ": "Wendi B Heinzelman",
    "JpoFnJQAAAAJ": "Ivan Stojmenovic",
    "OQfkwykAAAAJ": "Florian Kehl",
    "R9N6ljUAAAAJ": "Mona E Zaghloul, or Mona Zaghloul, or MEZaghloul, or M.Zaghloul.",
    "Z_A0TDgAAAAJ": "Matthew A Hopcroft",
    "Qb7xQQ0AAAAJ": "Seth R Sanders",
    "RKd3704AAAAJ": "Subramaniam Venkatraman",
    "8hU4uvEAAAAJ": "LY Lin",
    "ahFqdRUAAAAJ": "Igor Paprotny",
    "NxN3gEsAAAAJ": "Pascal Thubert",
    "NILVLIAAAAAJ": "Elena Gaura",
    "RQxKmJMAAAAJ": "Jason F Hou",
    "WuWWdKcAAAAJ": "Błażej Osiński",
    "BEBccCQAAAAJ": "José Miguel Hernández-Lobato",
    "N9QGV6YAAAAJ": "David A. Knowles",
    "3OFgQKcAAAAJ": "Alexander GDG Matthews",
    "3J4zb7gAAAAJ": "Wei Chu（褚崴）",
    "sm1-TZMAAAAJ": "Neil Houlsby",
    "s5-PGF8AAAAJ": "James Robert Lloyd",
    "lelCr80AAAAJ": "Naonori Ueda",
    "koQCVT4AAAAJ": "Ferenc Huszár",
    "l8dX3ssAAAAJ": "James Hensman",
    "a4t8q5MAAAAJ": "Jurgen Van Gael",
    "7QmCrjcAAAAJ": "Konstantina Palla",
    "MUJ51_gAAAAJ": "Richard S Savage",
    "I-ANa0QAAAAJ": "Ricardo Silva",
    "rr8pZoUAAAAJ": "Radford Neal",
    "Lt9LpLMAAAAJ": "Sinead Williamson",
    "NR59_v4AAAAJ": "Shiyi Cao",
    "kIx230gAAAAJ": "Christopher Chou",
    "si-368wAAAAJ": "Coleman Hooper",
    "qR1zQHQAAAAJ": "Song Jian",
    "57gDGpUAAAAJ": "Nicholas Lee",
    "tJpoCUIAAAAJ": "Shuo Yang",
    "vMW39p0AAAAJ": "Haris Vikalo",
    "Se7mocgAAAAJ": "Abolfazl Hashemi",
    "Jyqbex4AAAAJ": "Jixuan Leng",
    "A7gPbV8AAAAJ": "Chengsong Huang",
    "DnxrVXgAAAAJ": "Jiaxin Huang",
    "DzeJ67UAAAAJ": "Cassidy Laidlaw",
    "UJcBAgkAAAAJ": "Qingyi Gu",
    "MtqfTRYAAAAJ": "Lily (Xiaoxuan) Liu",
    "XwutB1AAAAAJ": "Zhikai Li",
    "EguGynAAAAAJ": "Qingyue Zhao",
    "GNiinUoAAAAJ": "Yifan Chen",
    "0qxCVx8AAAAJ": "Zuoqiang Shi",
    "JdRs1sQAAAAJ": "Sethu Vijayakumar",
    "tM4JMcQAAAAJ": "Aude Billard",
    "e378qEIAAAAJ": "Michael Mistry",
    "ejWOgzYAAAAJ": "Jonas Buchli",
    "qg9Gd84AAAAJ": "Dagmar Sternad",
    "7m2X0GoAAAAJ": "Heiko Hoffmann",
    "aHPX6PsAAAAJ": "Freek Stulp",
    "Izp-zW0AAAAJ": "Tomohiro Shibata",
    "zhQaFaMAAAAJ": "Dotan Di Castro",
    "1YjIvioAAAAJ": "Tom Jurgenson",
    "VAgdtpoAAAAJ": "Noga H. Rotman",
    "3A06cR4AAAAJ": "Yonatan Glassner",
    "FiETqWQAAAAJ": "Asaf Valadarsky",
    "7vLwm84AAAAJ": "Huan Xu",
    "MyTEg-8AAAAJ": "Kara Liu",
    "cGemfcYAAAAJ": "Angelina Wang",
    "v84tWxsAAAAJ": "Daniel J. Mankowitz",
    "r3NAa9oAAAAJ": "Ron Meir",
    "DdtAyEIAAAAJ": "Assaf Hallak",
    "PfgeYGwAAAAJ": "Sarit Kraus",
    "OvKEnVwAAAAJ": "Rémi Munos",
    "9dXN6cMAAAAJ": "Tom Zahavy",
    "p1HAb2QAAAAJ": "Nir Levine",
    "Gv4kyjQAAAAJ": "William Wei Wang",
    "Tq1gdBUAAAAJ": "Panos Toulis",
    "BadZJUsAAAAJ": "Giulio Biroli",
    "2GcqQgYAAAAJ": "Stéphane d'Ascoli",
    "YDKPDkgAAAAJ": "Stefano Spigler",
    "YkjjioAAAAAJ": "Matthieu Wyart",
    "Py69D_8AAAAJ": "Mario Geiger",
    "3aYVAZEAAAAJ": "V. Uğur Güney",
    "GyRqJIoAAAAJ": "Matthew Dunn",
    "4S1Ajs8AAAAJ": "Marco Baity-Jesi",
    "8yGMMwcAAAAJ": "Utku Evci",
    "vsLT1BIAAAAJ": "Chiara Cammarota",
    "_iu2AD4AAAAJ": "Jacob Stevenson",
    "pxSj9JkAAAAJ": "Stefano Martiniani",
    "J7fyX_sAAAAJ": "Dhagash Mehta",
    "HFHcNf0AAAAJ": "Thomas Trogdon",
    "MlFf2igAAAAJ": "Daniel L. Chen",
    "o-PadiwAAAAJ": "Liam MacDermed",
    "8tflub4AAAAJ": "Ali Punjani",
    "H4n-cXEAAAAJ": "David L. Roberts",
    "z5SPCmgAAAAJ": "Jingdong Wang (王井东), Fellow of CAE & IEEE & IAPR",
    "726MCb8AAAAJ": "Jiankai Sun",
    "WXd3dDwAAAAJ": "Yulei Niu",
    "6S-WgLkAAAAJ": "David Cox",
    "k9TsUVsAAAAJ": "Lu Yuan",
    "2iBYdwEAAAAJ": "Andrew Jaegle",
    "hlC76YUAAAAJ": "Skanda Koppula",
    "1JQDH_AAAAAJ": "Daniel Zoran",
    "uS6-ZOMAAAAJ": "Sharan Chetlur",
    "hOl-5zcAAAAJ": "Catalin Ionescu",
    "4aqK_74AAAAJ": "Bruno Olshausen",
    "_VmflIEAAAAJ": "Jean-Baptiste Alayrac",
    "v4JMf6kAAAAJ": "Shaoteng Liu",
    "VFO9h14AAAAJ": "Relja Arandjelović / Реља Аранђеловић",
    "NIxD36wAAAAJ": "Andrew Brock",
    "-KzSL30AAAAJ": "Sebastian Borgeaud",
    "Un10q9gAAAAJ": "David Ding",
    "7wclGnQAAAAJ": "Sven Gowal",
    "pHSC4Z0AAAAJ": "Yide Shentu",
    "laq9cq0AAAAJ": "Francesco Croce",
    "19Ouf5MAAAAJ": "Max Argus",
    "X3ZFZ7AAAAAJ": "Ali Taylan Cemgil",
    "HkVy8voAAAAJ": "Jin Gao",
    "FwCqwaoAAAAJ": "Thomas Brunner",
    "swP3h24AAAAJ": "Sylvestre-Alvise Rebuffi",
    "NjYyuQQAAAAJ": "Jue Wang",
    "EaMsuB0AAAAJ": "Haofan Wang",
    "z-b7JmcAAAAJ": "Jincan Deng",
    "OtEdQpcAAAAJ": "An Ju",
    "9NvupxcAAAAJ": "Anthony Fuller",
    "nmxbwm4AAAAJ": "James R Green",
    "P_luG3cAAAAJ": "David Rolnick",
    "TktX0BAAAAAJ": "Marlena Reil",
    "BTZBaosAAAAJ": "Favyen Bastani",
    "c8wc-6YAAAAJ": "Patrick Beukema",
    "to3X9roAAAAJ": "Gabriel Tseng",
    "g5CD7dQAAAAJ": "Hannah Rae Kerner",
    "kgZtMGsAAAAJ": "Mark Hamilton",
    "DHJjPRAAAAAJ": "Frederick Shpilevskiy",
    "WeIvMTUAAAAJ": "Mathias Lécuyer",
    "CALLeYgAAAAJ": "Saiyue Lyu",
    "IyYsKTIAAAAJ": "Daniel G Kyrollos",
    "KJoJ8nMAAAAJ": "Yousef Yassin",
    "kxAk6AoAAAAJ": "Behzad Bozorgtabar",
    "_9n9mi8AAAAJ": "Guillaume Vray",
    "S7DELUgAAAAJ": "Devavrat Tomar",
    "mII-l2cAAAAJ": "Jean-Philippe Thiran",
    "3YnlF3UAAAAJ": "Michal Kazmierski",
    "B9g1lS8AAAAJ": "Daniel H. Solomon",
    "aCLdkF4AAAAJ": "Michael Honigberg",
    "Qxtj86kAAAAJ": "Josef Coresh, MD, PhD",
    "vErFKeAAAAAJ": "Nilanjan Chatterjee, Bloomberg Distinguished Professor",
    "lPU_engAAAAJ": "Md Mesbah Uddin",
    "JVpq7SwAAAAJ": "Seyedeh Maryam Zekavat",
    "q-O4OlYAAAAJ": "Tetsushi Nakao",
    "1LgbXjEAAAAJ": "Peter Libby",
    "FeOUaQYAAAAJ": "Satoshi Koyama",
    "9Wq1xSUAAAAJ": "Frank B. Hu",
    "vRM148kAAAAJ": "Katherine P. Liao, MD, MPH",
    "B2cTx6MAAAAJ": "Haoyu Zhang",
    "JrWUvfEAAAAJ": "Maria A. Zuriaga",
    "7mGMjnIAAAAJ": "Caitlyn Vlasschaert, MD MSc PhD",
    "y_4JsmcAAAAJ": "Tim Coorens",
    "9c-_E-YAAAAJ": "José Javier Fuster",
    "mSO6jtEAAAAJ": "Scott L. Zeger",
    "6hPAjdYAAAAJ": "Alan R Tall",
    "l7HQl-kAAAAJ": "Trevor Fidler",
    "DOg4nhoAAAAJ": "Xihao Li",
    "K2hRQgUAAAAJ": "Zora Zhiruo Wang",
    "gFN4QUYAAAAJ": "Maarten Sap",
    "8rDNIMsAAAAJ": "Scott Wen-tau Yih",
    "CKyX_Y8AAAAJ": "Xuhui Zhou",
    "t6YzEpgAAAAJ": "Shuyan Zhou",
    "-3yFcsMAAAAJ": "Hao Zhu",
    "GskOShAAAAAJ": "Ruiqi Zhong",
    "jkDd-3QAAAAJ": "Freda Shi",
    "1hXyfIkAAAAJ": "Fangzheng (Frank) Xu",
    "Mgm8xyAAAAAJ": "Robert Lo",
    "P21gHIkAAAAJ": "Stephen Kobourov",
    "a3133-8AAAAJ": "Mihai Surdeanu",
    "5_Fn5CIAAAAJ": "Tao Yu",
    "OI0HSa0AAAAJ": "Tianyi Zhang",
    "KxQfzRcAAAAJ": "Armen Aghajanyan",
    "ov9EcNEAAAAJ": "Yiqing Xie",
    "Rdp-tpgAAAAJ": "Dane Bell",
    "tCo0KhkAAAAJ": "Abishek Sridhar",
    "QBn7vq8AAAAJ": "Uri Alon",
    "Q0mfsAMAAAAJ": "Tianyue Ou",
    "nzA4P0oAAAAJ": "Xiang Lisa Li",
    "jtrAdywAAAAJ": "Ari Holtzman",
    "LYVNrhMAAAAJ": "Yiming Wang",
    "njJoC7wAAAAJ": "Yuhang Lai",
    "p1XHoeoAAAAJ": "Chengxi Li",
    "U2MUXuMAAAAJ": "Saujas Vaduguru",
    "HqC4vl8AAAAJ": "Lawrence Keunho Jang",
    "043r6toAAAAJ": "Justin T Chiu",
    "RiDZxz8AAAAJ": "Ruohong Zhang",
    "loh93ZkAAAAJ": "Leena Mathur",
    "EL-QbZ4AAAAJ": "Haofei Yu",
    "wRZrrqwAAAAJ": "Luca Del Pero",
    "eJwbbXEAAAAJ": "Phil Blunsom",
    "WFKit_4AAAAJ": "Chen Henry Wu",
    "iGWgEw8AAAAJ": "Melanie Hingle, Ph.D., MPH, RD",
    "IRTtnAIAAAAJ": "Marjan Ghazvininejad",
    "t70ydxAAAAAJ": "Tamara Polajnar",
    "FtdDAMoAAAAJ": "Andy Liu",
    "Yn59qc4AAAAJ": "Jennifer Hu",
    "16OCMAQAAAAJ": "Roma Patel",
    "wc1Hbl8AAAAJ": "Peter A Jansen",
    "AV6nozIAAAAJ": "Gus Hahn-Powell",
    "uocljD4AAAAJ": "Suhas Kotha",
    "niZiN38AAAAJ": "Jacob Mitchell Springer",
    "gqB4u_wAAAAJ": "Akari Asai",
    "GRMLwjAAAAAJ": "Jade Copet",
    "2QbbLJAAAAAJ": "Olivier Duchenne",
    "Clrvw6kAAAAJ": "Yuxiang Wei",
    "zzbWQE4AAAAJ": "Lingming Zhang",
    "M3BSiiQAAAAJ": "Kevin Duh",
    "Lg6yyBEAAAAJ": "Vishruth Veerendranath",
    "-y6SIhQAAAAJ": "Mona Diab",
    "t41vrrQAAAAJ": "Zhoujun Cheng",
    "f1hBi5wAAAAJ": "Lingpeng Kong",
    "bMTBja0AAAAJ": "Laura Rimell",
    "IBlMTLwAAAAJ": "Dani Yogatama",
    "VBkk_NoAAAAJ": "Adhiguna Kuncoro",
    "pjLCdhIAAAAJ": "Divyanshu Sheth",
    "PoZv5KkAAAAJ": "Xinyan Velocity Yu",
    "rFL468UAAAAJ": "Akhila Yerukola",
    "S9Q7lk4AAAAJ": "Colin Reimer Dawson",
    "8DeZgKkAAAAJ": "Paul R. Cohen",
    "uU2UhGIAAAAJ": "Marco A. Valenzuela-Escárcega",
    "YhWnhQEAAAAJ": "Ali Jannesari",
    "VBouyX8AAAAJ": "Felix Wolf",
    "sLYXumkAAAAJ": "Siddhant Waghjale",
    "sycHskQAAAAJ": "Wenting Zhao",
    "wTTF4yYAAAAJ": "Atharva Naik",
    "BMo9cZ4AAAAJ": "Luwen (Vivian) Huangfu",
    "s3McVn8AAAAJ": "Ryan Liu",
    "OqAc0T0AAAAJ": "Yihan Cao",
    "culGbtkAAAAJ": "Shuyi (Ryan) Chen",
    "s0Fof5IAAAAJ": "Giscard Biamby",
    "mpZg3FnnHpQC": "Pradyot Prakash",
    "CYMAfxsAAAAJ": "Sinong Wang",
    "bI0cfykAAAAJ": "Hejia Zhang",
    "BIO5wVQAAAAJ": "Arya Talebzadeh",
    "mQIqIVwAAAAJ": "Han Fang",
    "steJe6IAAAAJ": "Yuning Mao",
    "picvdvEAAAAJ": "Wenxuan Zhou",
    "D5eyaLwAAAAJ": "Benno Krojer",
    "blTzjfsAAAAJ": "Jiefu Ou",
    "jeNGFfQAAAAJ": "Ufuk Topcu",
    "I6P0SwgAAAAJ": "Jiaxin Ge",
    "yAsgeGIAAAAJ": "Yi-Hao Peng",
    "Xmv0998AAAAJ": "Derek Chen",
    "xVB9askAAAAJ": "Priyan Vaithilingam",
    "IMYgXsYAAAAJ": "Sedrick Keh",
    "MB0OgPEAAAAJ": "Shenghui Chen",
    "ZBBX5u4AAAAJ": "David Gaddy",
    "E9EgKkMAAAAJ": "Valentina Pyatkin",
    "jee2Dy0AAAAJ": "Zhou Yu",
    "xj666rUAAAAJ": "Weiyan Shi",
    "pfqzHqUAAAAJ": "Emily Dinan",
    "r1Zw-VEAAAAJ": "Alex Wilf",
    "AYbfPEAAAAAJ": "Alex Tianyi Xu",
    "hCatCxMAAAAJ": "Yiming Zhang",
    "p7dCP-kAAAAJ": "Vivian Lai",
    "3xUoKkwAAAAJ": "Talita Rani Anthonio",
    "8ew3do4AAAAJ": "Alex Obolenskiy",
    "3-lTFAwAAAAJ": "Alisa Liu",
    "gr_ZVSQAAAAJ": "Elias Stengel-Eskin",
    "PW6eQ6YAAAAJ": "Sandro Pezzelle",
    "8MFFVgEAAAAJ": "Diane Litman",
    "OENNEBIAAAAJ": "Michael Johnston",
    "DP3jcx0AAAAJ": "Felix Gervits",
    "ztpK4iwAAAAJ": "Mert İnan",
    "F4JYGjcAAAAJ": "Ross Mead",
    "w24_ETkAAAAJ": "Malihe Alikhani",
    "VcmM93MAAAAJ": "Katherine Atwell",
    "-mHoWKEAAAAJ": "Jivko Sinapov",
    "Um4ZbbgAAAAJ": "Casey Kennington",
    "8D_Ggb4AAAAJ": "Raj Korpan",
    "QHVdvtUAAAAJ": "Zhao Han",
    "bQzoxtsAAAAJ": "Heather Pon-Barry",
    "C3NuO-AAAAAJ": "Cynthia Matuszek",
    "Pd8-ju0AAAAJ": "Stefanie Tellex",
    "K931JfEAAAAJ": "Matthew Marge",
    "3siz6_0AAAAJ": "Matthew Stone",
    "qg_aiScAAAAJ": "Tom Williams",
    "NmP-rOAAAAAJ": "Natalie Parde",
    "EYWzxPIAAAAJ": "Shiwali Mohan",
    "LDpxmC8AAAAJ": "Angela EB Stewart",
    "fOZk6agAAAAJ": "Marcus Alenius",
    "fVxqrBkAAAAJ": "Abhishek Ninad Kulkarni",
    "eJsW6W8AAAAJ": "Meredith Ringel Morris",
    "nUCWRZAAAAAJ": "Devamanyu Hazarika",
    "gGcRkpYAAAAJ": "Rob Xiangru Tang",
    "SNVrOLwAAAAJ": "Jean-Raphaël  Gaglione",
    "hR249csAAAAJ": "Shafiq Joty",
    "x5QTK9YAAAAJ": "Di Jin",
    "jxQJo9MAAAAJ": "Vishwa Shah",
    "TqDmo1UAAAAJ": "Rishi Shah",
    "fMQZybAAAAAJ": "Uri Alon",
    "DKFiD7cAAAAJ": "S. Karthik Mukkavilli",
    "WBS6zncAAAAJ": "Daniel S Fisher",
    "93zBpkAAAAAJ": "David Thouless",
    "Ajm0ijIAAAAJ": "Jean Carlson",
    "-BO7TXUAAAAJ": "Yi Yang",
    "-gFCCLMAAAAJ": "Tomas Jakab",
    "PtBtfawAAAAJ": "Hakan Bilen",
    "yN7CEicAAAAJ": "Lucas Smaira",
    "ep_nM5sAAAAJ": "Chuhan Zhang",
    "hWzXZUMAAAAJ": "Viorica Patraucean",
    "44ANFF4AAAAJ": "Jonathan Lester",
    "FiTQ7UIAAAAJ": "Karl Koscher",
    "wTCe1mUAAAAJ": "Sunny Consolvo",
    "44jDM6EAAAAJ": "Beverly Harrison",
    "OtREFPYAAAAJ": "Anthony LaMarca",
    "6ma-nCYAAAAJ": "John Woodfill",
    "q9UyGCIAAAAJ": "Danny Wyatt",
    "ysE-XbUAAAAJ": "Harlyn Baker",
    "Ji-VV2cAAAAJ": "Jonathan Bachrach",
    "MkxZCXsAAAAJ": "Luca Cazzanti",
    "crlzbrMAAAAJ": "Yihua Chen",
    "YCbFRsAAAAAJ": "Eric K. Garcia",
    "aAAY3oYAAAAJ": "Gholamhassan Najafi",
    "xsaakpMAAAAJ": "Professor Barat Ghobadian",
    "j7PrPEUAAAAJ": "Roya Kelishadi",
    "oRkkQm4AAAAJ": "Dr Morteza Mansourian",
    "cITeyPkAAAAJ": "Mostafa Qorbani",
    "LuQA_vcAAAAJ": "Rizalman Mamat",
    "STgsgLAAAAAJ": "masoumeh bahman",
    "dGj1KOsAAAAJ": "Atefeh Abedini",
    "sd0Rw0YAAAAJ": "Ali Sheidaei",
    "pL8RApYAAAAJ": "seyedeh sedigheh Hosseini",
    "uO3mk-IAAAAJ": "Ali Soltani",
    "RL61eA0AAAAJ": "Ehya Amalsaleh",
    "44-qrTIAAAAJ": "Mohammad M Mohammadi",
    "1cVvrLYAAAAJ": "maryam mojiri (Ms.c)",
    "5IMEORsAAAAJ": "Alimorad  Rashidi",
    "oTXlEEwAAAAJ": "Mehdi Solhi",
    "QV8hqE4AAAAJ": "Jeffrey Hightower",
    "v8xm0csAAAAJ": "Maya Gupta",
    "_AZwpCAAAAAJ": "sairan nili",
    "iS5ADlgAAAAJ": "Shulin Yang",
    "3aO6KH4AAAAJ": "Abdolhossein Madani",
    "sDjp1K8AAAAJ": "Svetlana Pesina",
    "QzTJEdYAAAAJ": "Amir Dehghani Samani (MD).",
    "evrgC2oAAAAJ": "Ruizhe Zhang",
    "I0EoZyQAAAAJ": "Runzhou Tao",
    "bMDg-3cAAAAJ": "Shunhua Jiang",
    "sdENOQ4AAAAJ": "Xiaoxiao Li",
    "Bk8FeYwAAAAJ": "Hengjie Zhang",
    "XcQ9WqMAAAAJ": "Mengye Ren",
    "ARmv8N4AAAAJ": "Philip Lenz",
    "fqi186AAAAAJ": "Tamir Hazan",
    "OeAQ2c0AAAAJ": "Christoph Stiller",
    "UY7CtEwAAAAJ": "Yujia Li",
    "SlkU8ZQAAAAJ": "Koichiro Yamaguchi",
    "_7QgnUcAAAAJ": "Marc T. Law",
    "D2VLt-8AAAAJ": "Andreas Moshovos",
    "C6GeyOwAAAAJ": "Jorge Albericio",
    "CpFoJ1gAAAAJ": "Natalie Enright Jerger",
    "ayUyj9YAAAAJ": "Jia Xu",
    "Y5x2ZgQAAAAJ": "Eleni Triantafillou",
    "2oq9614AAAAJ": "Aidan Gomez",
    "zCsB5XsAAAAJ": "Tor M. Aamodt",
    "6m1ptOgAAAAJ": "Srikumar Ramalingam",
    "JgTAHxkAAAAJ": "Yuichi Taguchi",
    "GPusciUAAAAJ": "Daniel Thalmann",
    "dlFYlXwAAAAJ": "Petr Dokladal",
    "7BFEwr4AAAAJ": "Isabelle Bloch",
    "JycXWO0AAAAJ": "Brahim Chaib-draa",
    "H2JX-RQAAAAJ": "Jian Peng",
    "9BMXWA8AAAAJ": "Michel Couprie",
    "lveaf5IAAAAJ": "Danny Ruijters",
    "CffJDoEAAAAJ": "Eugene Belilovsky",
    "tvWB_yUAAAAJ": "Yang Song",
    "ZU1fTMYAAAAJ": "Ricardo Chavarriaga",
    "1k8gBxEAAAAJ": "Tae-Hun Kim",
    "tR3AZbwAAAAJ": "Qirong Ho",
    "M9oUY4cAAAAJ": "Wei Dai",
    "EY2lqD0AAAAJ": "Jianxin Li",
    "6HgpyjMAAAAJ": "Abhimanu Kumar",
    "ki5hheQAAAAJ": "Jin Kyu Kim",
    "cxM-P9UAAAAJ": "Jinliang Wei",
    "bniKGtgAAAAJ": "Mikhail Bilenko",
    "tk0e5lYAAAAJ": "Yuntian Deng",
    "HKk8VjoAAAAJ": "Sean (Seunghak) Lee",
    "nhNWrxkAAAAJ": "Zeyu Zheng",
    "4fK8bYIAAAAJ": "Yi Zhou",
    "IKoa5qAAAAAJ": "Wei Wu",
    "Wrfc4V8AAAAJ": "Michael Naehrig",
    "K6RYRTMAAAAJ": "Devendra Singh Sachan",
    "dM1jSoEAAAAJ": "Haoran Shi",
    "lkPKfjgAAAAJ": "Congzheng Song",
    "0DX2YsQAAAAJ": "Nanqing Dong",
    "3xUT1e0AAAAJ": "Zeya Wang, Ph.D.",
    "j9jhYqQAAAAJ": "Diyi Yang",
    "eETZ8vQAAAAJ": "Mike Lam",
    "U5ZZu3IAAAAJ": "Christy Yuan Li",
    "DLazAw4AAAAJ": "Yulong Pei",
    "JY6hDCoAAAAJ": "Dimitris Konomis",
    "Lt4tmL8AAAAJ": "Yuan Yang",
    "qjDVoqQAAAAJ": "Evan Zheran Liu",
    "sAdDcvQAAAAJ": "Sylvia Ratnasamy",
    "SssrcUsAAAAJ": "Aurojit Panda",
    "CZyWk8kAAAAJ": "Lixia Zhang",
    "Qf4bw4UAAAAJ": "Hari Balakrishnan",
    "SqMUez0AAAAJ": "Nick McKeown",
    "9s9o-JcAAAAJ": "David Clark",
    "hmq4rGIAAAAJ": "Larry Peterson",
    "07ds-DAAAAAJ": "Jennifer Rexford",
    "MYqlcPgAAAAJ": "Thomas Anderson",
    "XRyUF6gAAAAJ": "Mark Handley",
    "du-k5BYAAAAJ": "Justin Pettit",
    "KmXVOQkAAAAJ": "Brad Karp",
    "IAeKTGsAAAAJ": "Joan Feigenbaum",
    "hwnskpoAAAAJ": "Byung-Gon Chun",
    "Cgx9W6UAAAAJ": "Jonathan Turner",
    "FVTgmOwAAAAJ": "Michael Walfish",
    "JHwivywAAAAJ": "Pei Cao",
    "Ikz6_Y0AAAAJ": "Barath Raghavan",
    "q33fP9sAAAAJ": "Walter Willinger",
    "Zm0kSvgAAAAJ": "Hongsuda Tangmunarunkit",
    "VuvKPiQAAAAJ": "Rodrigo Fonseca",
    "CZa9GB4AAAAJ": "Haoyuan Li",
    "2-uoevgAAAAJ": "eric friedman",
    "-DBwBK4AAAAJ": "Ben Pfaff",
    "HF2G3LAAAAAJ": "Boon Thau Loo",
    "Q9DsCL4AAAAJ": "Daniel Zappala",
    "nqrkC8IAAAAJ": "Colin Scott",
    "xYfYnG4AAAAJ": "Nick Feamster",
    "cTGO2HoAAAAJ": "Petros Maniatis",
    "d_rxnzAAAAAJ": "Aditya Akella",
    "BFE6IQwAAAAJ": "Michael J. Freedman",
    "qR7R2FMAAAAJ": "Ramakrishna Gummadi",
    "uezRX6QAAAAJ": "Igor Ganichev",
    "96mJbhwAAAAJ": "Radhika Mittal",
    "6_cxCKQAAAAJ": "Mohammad Alizadeh",
    "HHwoC2MAAAAJ": "Sangjin Han",
    "DGcTRyEAAAAJ": "Amin Tootoonchian",
    "_m7uOmUAAAAJ": "Young-Jin Kim",
    "Gzxda70AAAAJ": "Kyriakos Zarifis",
    "DSEH8XsAAAAJ": "Yin Zhang (章寅)",
    "TvV_SVwAAAAJ": "Katerina Argyraki",
    "j4UuW80AAAAJ": "Mooly Sagiv",
    "9RlvgLEAAAAJ": "Steven Bellovin",
    "J1vWqkQAAAAJ": "Kay Ousterhout",
    "HsYH17vSXmQC": "Melvin Walls",
    "hHYRga0AAAAJ": "Neil Patel",
    "pIoPb7sAAAAJ": "Ankit Singla",
    "71IXR1QAAAAJ": "Rachit Agarwal",
    "4ZYEiVEAAAAJ": "Douglas Terry",
    "QfVWndgAAAAJ": "Timothy Roscoe",
    "qnMs-XYAAAAJ": "Jon Crowcroft",
    "Da-s1FQAAAAJ": "KK Ramakrishnan",
    "Sh1yq5QAAAAJ": "Ratul Mahajan",
    "DvbPrWYAAAAJ": "Andreas Wundsam",
    "WOrTFE0AAAAJ": "Sam Whitlock",
    "0irVeiQAAAAJ": "Srinivasan Seshan",
    "tgfOQwEAAAAJ": "Jarno Rajahalme",
    "-OpGJpYAAAAJ": "Mythili Vutukuru",
    "ff0742EAAAAJ": "Hyunseok Chang",
    "4fOVJ7UAAAAJ": "Shuang Yang",
    "UphI-hIAAAAJ": "Hiroaki INOUE",
    "cbTB5-EAAAAJ": "Deepak Ganesan",
    "vG5UNEQAAAAJ": "Michael Pinedo",
    "AQ6AppgAAAAJ": "Y. Richard Yang",
    "5V852JcAAAAJ": "Vyas Sekar",
    "rQ0Zl50AAAAJ": "James R. Wilcox",
    "in6eBIwAAAAJ": "Robert Morris",
    "rHIz0PoAAAAJ": "Jonathan Hui",
    "wUArfPgAAAAJ": "David G. Andersen",
    "uyCsSAEAAAAJ": "Laurent Vanbever",
    "gqkpV2kAAAAJ": "Hans-J. Boehm",
    "aSqr26EAAAAJ": "Jayanthkumar Kannan",
    "7SdcAiEAAAAJ": "Tyson Condie",
    "1_kJPIEAAAAJ": "John C Mitchell",
    "euwkGt0AAAAJ": "S. Thomas McCormick",
    "G-oLZ6wAAAAJ": "Ashish Vulimiri",
    "TxVfH8QAAAAJ": "Christian Schindelhauer",
    "VMXSblwAAAAJ": "Berthold Vöcking",
    "MrWIWNwAAAAJ": "Jinyang Li",
    "Bz3APTsAAAAJ": "Krishna P. Gummadi",
    "hbLmvo0AAAAJ": "Volker Roth",
    "81IhdxgAAAAJ": "Harlan Yu",
    "-N-_kgsAAAAJ": "Brandon Heller",
    "MDRALDkAAAAJ": "David Chu",
    "5pJNSzMAAAAJ": "Somaya Arianfar",
    "-0vALDMAAAAJ": "Edward Knightly",
    "3rq29xkAAAAJ": "Vijay Ramachandran",
    "WbYQGjcAAAAJ": "Hal Varian",
    "Hd3kUc4AAAAJ": "Jeffrey K. MacKie-Mason",
    "VMihW8oAAAAJ": "Eddie Kohler",
    "AaMR6EQAAAAJ": "John Chuang",
    "HeEBacsAAAAJ": "David Wetherall",
    "aQCRuYQAAAAJ": "Amy Greenwald",
    "7kaIUXoAAAAJ": "Anna Bogomolnaia",
    "TKSjVTUAAAAJ": "Peter Alvaro",
    "ZuWlfPEAAAAJ": "Neil Conway",
    "PeCI8KcAAAAJ": "Peter J Haas",
    "vlgs4G4AAAAJ": "Jeffrey Heer",
    "muunN_AAAAAJ": "Yucheng Low",
    "5Ec8ENMAAAAJ": "Sailesh Krishnamurthy",
    "gMOBKfUAAAAJ": "Daisy Zhe Wang",
    "vl8imyIAAAAJ": "William Marczak",
    "Hs9cVRgAAAAJ": "Alan Fekete",
    "C1skWKgAAAAJ": "Remzi Arpaci-Dusseau",
    "1AzRLAUAAAAJ": "David Gay",
    "bgmagbUAAAAJ": "Michael Whittaker",
    "8VkvOEEAAAAJ": "Andrea Arpaci-Dusseau",
    "-3XaxbkAAAAJ": "Kuang Chen",
    "SKVnHakAAAAJ": "HV Jagadish",
    "QQVlcOUAAAAJ": "hamid pirahesh",
    "Iiut4KYAAAAJ": "Tapan Parikh",
    "MIfpzUQAAAAJ": "Yannis Ioannidis",
    "H-VmFU4AAAAJ": "Jeffrey Naughton",
    "RkddXygAAAAJ": "Azza Abouzied",
    "wR_tv-kAAAAJ": "Kimberly Keeton",
    "DXsaMGgAAAAJ": "Heidi Howard",
    "bkcNcHYAAAAJ": "Christopher Olston",
    "BVD_LdgAAAAJ": "Elias Koutsoupias",
    "TBaBNdkAAAAJ": "Haryadi S. Gunawi",
    "-YvgZDEAAAAJ": "A Silberschatz",
    "7_RHB_gAAAAJ": "Adriana Szekeres",
    "NYgWyv0AAAAJ": "Dhruba Borthakur",
    "IhmK-VkAAAAJ": "Andy Chou",
    "Nxmx29UAAAAJ": "Amog Kamsetty",
    "zxeEF2gAAAAJ": "Daniel J. Abadi",
    "93yNuV0AAAAJ": "Katherine Yelick",
    "4bL3ThUAAAAJ": "Kee Siong Ng",
    "DDxFvcIAAAAJ": "Magdalena Balazinska",
    "5lhsTYwAAAAJ": "Matthew Matl",
    "y5uNFK0AAAAJ": "Bill DeRose",
    "ucSLToQAAAAJ": "Brian Hou",
    "kUbCuLgAAAAJ": "Chris Correa",
    "Du7j3mQAAAAJ": "Kai Kohlhoff",
    "rLI9DmoAAAAJ": "MENGLONG GUO",
    "5eoD8UwAAAAJ": "Keisuke Nakagawa",
    "ZSRwsn6tjckC": "Maximo A. Roa-Garzon",
    "KQFUVR8AAAAJ": "Renaud Detry",
    "oH7drVcAAAAJ": "Adam Norton",
    "jFekO3IAAAAJ": "Aaron M. Dollar",
    "awNOAaYAAAAJ": "Joseph Falco",
    "3WEijrIAAAAJ": "Holly Yanco",
    "NcEl9LwAAAAJ": "Elena Messina",
    "PYrd2GMAAAAJ": "Melrose Roderick",
    "Zrv4oQIAAAAJ": "Johan van Leeuwaarden",
    "fdkVqrsAAAAJ": "Nelly Litvak",
    "u0rkSl0AAAAJ": "Clara Stegehuis",
    "kJ9CX6sAAAAJ": "Piet Van Mieghem",
    "zMH25DoAAAAJ": "Wolfgang König",
    "wJ8seI8AAAAJ": "Markus Heydenreich",
    "GLxE-TcAAAAJ": "Robert Fitzner",
    "0ZsqI4kAAAAJ": "Komjáthy Júlia",
    "pCj-4VAAAAAJ": "Pim van der Hoorn",
    "GoR_32IAAAAJ": "Cristian Giardinà",
    "vHi84IsAAAAJ": "Souvik Dhara",
    "4j3sGYwAAAAJ": "Sander Dommers",
    "9IWk2PMAAAAJ": "Sanchayan Sen",
    "4hda5e8AAAAJ": "Alessandro Garavaglia",
    "IuKFwTsAAAAJ": "Gianmarco Bet",
    "-8rxeRIAAAAJ": "Lorenzo Albertazzi",
    "pHTgOOIAAAAJ": "Peter Morters",
    "iusaOxAAAAAJ": "Martijn Gösgens",
    "vPOv3boAAAAJ": "EW Meijer",
    "Dfzm6hsAAAAJ": "Malwina Luczak",
    "nhIirs0AAAAJ": "Ivan Voitalov",
    "NuPqqNAAAAAJ": "Dmitri Krioukov",
    "ovgLRIIAAAAJ": "Asaf Nachmias",
    "0ZgdQZ8AAAAJ": "Richard Post",
    "FOF_PaEAAAAJ": "Kay Bogerd",
    "kf8nxJ8AAAAJ": "Hans (JAP) Heesterbeek",
    "5Xz6xycAAAAJ": "Erik Fledderus",
    "yCyrc0MAAAAJ": "Lorenzo Federico",
    "qbzezVEAAAAJ": "Luc Florack",
    "7MZe4owAAAAJ": "Wouter De Baene",
    "unUhqcwAAAAJ": "Geert-Jan Rutten",
    "VgbZ7z8AAAAJ": "Georgi Radulov",
    "Y-C2u28AAAAJ": "Rounak Ray",
    "cGgZI40AAAAJ": "Bert Zwart",
    "qL9o1Y0AAAAJ": "Oliver Nagy",
    "AgN0kSEAAAAJ": "pfm smulders",
    "V3UXWuMAAAAJ": "Alex van Herk",
    "7unNfcMAAAAJ": "Martijn Schoot Uiterkamp",
    "9YnPccsAAAAJ": "Francesco Caravenna",
    "jxBZFwQAAAAJ": "Alexander F. Mason",
    "-OGSuAkAAAAJ": "Marco De Corato",
    "-K2KHjIAAAAJ": "Jan van Hest",
    "05_s28EAAAAJ": "Samuel Sanchez (https://orcid.org/0000-0001-9713-9997)",
    "QIp7IMUAAAAJ": "Loai KEA Abdelmohsen",
    "ZjyUJyIAAAAJ": "Rajat Subhra Hazra",
    "LWZtl74AAAAJ": "N. Amy Yewdall",
    "NjxgmeIAAAAJ": "Shoupeng Cao",
    "sYncdvUAAAAJ": "Rafael Mestre",
    "Tq0P7eoAAAAJ": "Hao Can",
    "--0WA_UAAAAJ": "Arthur van Roermund",
    "rtfJhO0AAAAJ": "Gerhard Woeginger",
    "VP48uSEAAAAJ": "Sjors Wijnands",
    "Akmpg4gAAAAJ": "Fengnan Gao",
    "SkH-ZyIAAAAJ": "AW van der Vaart",
    "QPlFU6oAAAAJ": "Günter Last",
    "fAO6gAYAAAAJ": "Wioletta Ruszel",
    "_-qBW0UAAAAJ": "Alexey Kuznetsov",
    "HH5gtyoAAAAJ": "Seva Shneer",
    "NaThra4AAAAJ": "Artem Sapozhnikov",
    "REGT0fcAAAAJ": "Tom Bannink",
    "YP3gziUAAAAJ": "Konstantin Avrachenkov",
    "-ooGheoAAAAJ": "Marina Sokol",
    "eqmeFRoAAAAJ": "ER van den Heuvel",
    "4yk44z4AAAAJ": "Peter A. Fokker",
    "96ciTVoAAAAJ": "Jan Diederik van wees",
    "mhpaapIAAAAJ": "Thibault Candela",
    "RHXdl6EAAAAJ": "Jean Paul Ampuero",
    "VFXKWYYAAAAJ": "Frank Redig",
    "iz3e3X8AAAAJ": "Angus Southwell",
    "-DSn7-wAAAAJ": "Pu (Jane) Gao",
    "Pskjj5AAAAAJ": "Rudi Pendavingh",
    "b7w97acAAAAJ": "Tobias Müller",
    "VA4ExhYAAAAJ": "Edwin Perkins",
    "gaiImbAAAAAJ": "Noela Müller",
    "Fv9ag1YAAAAJ": "Jorn van der Pol",
    "zIjCVzAAAAAJ": "Zbigniew Palmowski",
    "W_BvHWoAAAAJ": "Stella Kapodistria",
    "1fNDr6wAAAAJ": "Elie Aidekon",
    "0L8vKCwAAAAJ": "Haodong Zhu",
    "7MoHiJ8AAAAJ": "A Bhattacharya",
    "bOlnJwcAAAAJ": "Dingeman LH van der Haven",
    "HAG5Og4AAAAJ": "Ilja Voets",
    "rFB25cgAAAAJ": "Roderick P. Tas",
    "66s6LkAAAAAJ": "Matthias Löwe",
    "EzMN4zkAAAAJ": "Matteo Sfragara",
    "plQDn_wAAAAJ": "Alessandro Di Bucchianico",
    "0J6vYkEAAAAJ": "Ramjee Prasad",
    "SjP9OAoAAAAJ": "Tim Hulshof",
    "MpuRqeQAAAAJ": "Natalia Sidorova",
    "AnSVkUYAAAAJ": "Qiwen Cui",
    "9sHizzsAAAAJ": "Runlong Zhou",
    "IuMFxFUAAAAJ": "Yiping Wang",
    "NdY_HacAAAAJ": "Bin Shi",
    "OsSiEMEAAAAJ": "Zhihan Xiong",
    "KJLJstYAAAAJ": "Dingli Yu",
    "jQeFWdoAAAAJ": "Jianshu Chen",
    "IURWCt4AAAAJ": "Kangcheng Hou",
    "ym8AZSIAAAAJ": "Andrew Wagenmaker",
    "UnuEcZEAAAAJ": "Rachel Ward",
    "Ry0Bdt8AAAAJ": "Xiaoxia (Shirley) Wu 吴晓霞",
    "XTqgW-EAAAAJ": "Jayanth Koushik",
    "j_SEFF8AAAAJ": "Mo Zhou",
    "3tNXqMIAAAAJ": "Jifan Zhang",
    "9cboKEYAAAAJ": "Yinglun Zhu",
    "yStEfeIAAAAJ": "tian ye",
    "TR6GqIgAAAAJ": "Yancheng Liang",
    "XBg0AAkAAAAJ": "Yinhai Wang",
    "-P9LwcgAAAAJ": "Gao Huang （黄高）",
    "upMvIv4AAAAJ": "Rui Lu (卢睿)",
    "QgETxGoAAAAJ": "Yuyao Liu",
    "2HJu9wgAAAAJ": "Fei Feng",
    "kpQGGFUAAAAJ": "Wotao Yin",
    "bDrXQPUAAAAJ": "Gauthier Gidel",
    "LTKmex0AAAAJ": "Enlu Zhou",
    "GU9HgNAAAAAJ": "Quanquan Gu",
    "NIpOwa8AAAAJ": "Weihang Xu",
    "ZLyJRxoAAAAJ": "Zhenyu \"Allen\" Zhang",
    "eFVB3ksAAAAJ": "Chuning Zhu",
    "4QZgrj0AAAAJ": "Rui Yuan",
    "okKw87MAAAAJ": "Robert Mansel Gower",
    "b8i9J_QAAAAJ": "Minbo Gao",
    "C8bGfr0AAAAJ": "Yunbo Wang",
    "RlaKKWAAAAAJ": "Bo Liu",
    "2uG5ut4AAAAJ": "David Wettergreen",
    "LI7rp1QAAAAJ": "Paloma Sodhi",
    "U71Ps4kAAAAJ": "Srinivasan Vijayarangan",
    "E08IHhoAAAAJ": "Dimitrios Apostolopoulos",
    "jrazNCQAAAAJ": "Michal Valko",
    "KfxoN50AAAAJ": "Jean Tarbouriech",
    "gkG4z3IAAAAJ": "Yan DAI (戴言)",
    "iwN7GtoAAAAJ": "Kunming Wu",
    "puDkuLoAAAAJ": "Gregory Canal",
    "Z1OtYmAAAAAJ": "Nick Hay",
    "L-lz7CUAAAAJ": "Xiao Zhang",
    "5Ysgg7AAAAAJ": "Meixin Zhu",
    "EzCLa-4AAAAJ": "Ziyuan Pu",
    "l4ffN_QAAAAJ": "Peilin Zhong",
    "4VlAkPUAAAAJ": "Xinqi Wang",
    "LBJv1gsAAAAJ": "Wenqing Zheng",
    "fqf2tBsAAAAJ": "Peihao  Wang",
    "YiUWYl0AAAAJ": "Xuan Jiang",
    "0na-wa0AAAAJ": "Jiarui Cai",
    "K7Q4GWQAAAAJ": "Nuoya Xiong",
    "uvrIWrUAAAAJ": "Lijun Ding",
    "1B0l7U8AAAAJ": "Lei Li",
    "HQCpSJMAAAAJ": "Eric Jiang",
    "Tlt5xsYAAAAJ": "Andrew Zhao",
    "VU4chlsAAAAJ": "Haotian Ye",
    "CypbdCkAAAAJ": "Zehao Dou",
    "9fPuoP4AAAAJ": "Zhaoyi Zhou",
    "wZFmjwYAAAAJ": "Shashank Singh",
    "sYza2XwAAAAJ": "Yichong Xu",
    "3L333oYAAAAJ": "Shaobo Han",
    "_lnL4aQAAAAJ": "Zhili Feng",
    "xUOx0loAAAAJ": "Yingbing Huang",
    "2J051LYAAAAJ": "Shusheng Xu",
    "hklOXvkAAAAJ": "Pulkit Grover",
    "Kt1aSnAAAAAJ": "Dave Anderson",
    "k2ZQE1IAAAAJ": "kris Zacny",
    "5mnT2ocAAAAJ": "Nathalie A. Cabrol",
    "8MliTo4AAAAJ": "Bo Liu",
    "vRkNXhwAAAAJ": "Jovana Mitrovic",
    "6nKHDKYAAAAJ": "Razvan Pascanu",
    "4YhNJBEAAAAJ": "Pietro Liò",
    "IS4VSXAAAAAJ": "Brian McWilliams",
    "1h_mxPMAAAAJ": "Lars Buesing",
    "-PIq1igAAAAJ": "Nenad Tomasev",
    "u7GirtIAAAAJ": "Helena Andres Terre",
    "urLZUHwAAAAJ": "Angela Wood",
    "RvtEObEAAAAJ": "Beatrice Bevilacqua",
    "2zHG0dwAAAAJ": "Kyriacos Nikiforou",
    "lWDq-ygAAAAJ": "Matthias Bauer",
    "jaNr8IoAAAAJ": "Christos Kaplanis",
    "57BFBY0AAAAJ": "Matthias Minderer",
    "JDaHecMAAAAJ": "Matko Bošnjak",
    "DD1MSdMAAAAJ": "Goker Erdogan",
    "FVKgcAsAAAAJ": "Malavika Nair",
    "NZUdzyIAAAAJ": "Emma Rocheteau",
    "J8YyZugAAAAJ": "Peter Belhumeur",
    "yqt5PeEAAAAJ": "Ioannis Gkioulekas",
    "66qppJsAAAAJ": "Steven J. Gortler",
    "Q8WGJtQAAAAJ": "Satya Mallick",
    "9aw_QGAAAAAJ": "Anat Levin",
    "c4XKzcIAAAAJ": "Jason Lawrence",
    "wc0FCZUAAAAJ": "Yue M. Lu",
    "EKNrHzQAAAAJ": "Sanjeev Koppal",
    "ZlNq4_4AAAAJ": "Stanley H. Chan",
    "NW_lLBUAAAAJ": "Bei Xiao",
    "aN4IwM4AAAAJ": "Keigo Hirakawa",
    "cbQB0MMAAAAJ": "Shuang Zhao",
    "wbIMbL8AAAAJ": "Wojciech Matusik",
    "XhyKVFMAAAAJ": "Ping Tan",
    "rArDMRMAAAAJ": "Neil Alldrin",
    "pUB0nnwhGVAC": "Tim Weyrich",
    "RaScARwAAAAJ": "Szymon Rusinkiewicz",
    "i0n7VXwAAAAJ": "Petr Jordan, Ph.D.",
    "15g03MoAAAAJ": "Pierre E. Dupont",
    "gxL7aZQAAAAJ": "Hyunsung Park",
    "E_ejWvYAAAAJ": "Lihi Zelnik-Manor",
    "s2Ibok8AAAAJ": "Hans-Peter Seidel",
    "st_GV1QAAAAJ": "Marcus Magnor",
    "eUtEs6YAAAAJ": "Matthias Nießner",
    "ArKKNxwAAAAJ": "Carsten Stoll",
    "cx4AaqoAAAAJ": "Marc Stamminger",
    "qIvZT74AAAAJ": "Srinath Sridhar",
    "AZH_wV0AAAAJ": "Christian Richardt",
    "Ex3pgLAAAAAJ": "James Tompkin",
    "pDvg7X4AAAAJ": "Kiran Varanasi",
    "49ovzE4AAAAJ": "Chenglei Wu",
    "w2Bt-vwAAAAJ": "Naveed Ahmed",
    "hkCVqYkAAAAJ": "Shahram Izadi",
    "_z41TLwAAAAJ": "Antti Oulasvirta",
    "DJRhzzYAAAAJ": "Nils Hasler",
    "ogXIdlYAAAAJ": "Yebin Liu",
    "hdMznfMAAAAJ": "Miguel Granados",
    "CHAajY4AAAAJ": "Qionghai  Dai",
    "uggxDWIAAAAJ": "Meinard Müller",
    "-xjeTa8AAAAJ": "Sebastian Schuon",
    "oj0A7FoAAAAJ": "Art Tevs",
    "ZfUyYtEAAAAJ": "Thomas Neumann",
    "qq3TxtcAAAAJ": "Bodo Rosenhahn",
    "JQ939pQAAAAJ": "Genzhi Ye",
    "PtIe6OkAAAAJ": "Andres Bruhn",
    "_tzVqLEAAAAJ": "Christopher Dyken",
    "4fN_h5QAAAAJ": "Martin Eisemann",
    "XW6MbmAAAAAJ": "Ivo Ihrke",
    "IWwCuGAAAAAJ": "Joachim Weickert",
    "oREmACAAAAAJ": "Holger Theisel",
    "8SZ79v4AAAAJ": "Christian Rössl",
    "kA_rSy4AAAAJ": "Michael Wand",
    "51ZIHGIAAAAJ": "Zhao Dong",
    "kfYJVXEAAAAJ": "Neil Dodgson",
    "O25d8jcAAAAJ": "Savil Srivastava",
    "QCH7hIEAAAAJ": "Henning Zimmer",
    "Pkj8OSoAAAAJ": "Johan Bos",
    "GnTX_20AAAAJ": "Richard Reeve",
    "Sh28erYAAAAJ": "Ewan Klein",
    "I1D9ig8AAAAJ": "Levi Valgaerts",
    "cxYepGkAAAAJ": "Osbert Bastani",
    "K-2OXMIAAAAJ": "William Liang",
    "l19pn2sAAAAJ": "Stephen Tian",
    "p-PC50wAAAAJ": "Alan Bovik",
    "so6uzIwAAAAJ": "Edward S. Hu",
    "t9eduncAAAAJ": "Anush Moorthy",
    "au4CYXQAAAAJ": "Andrew Shen",
    "n4YG-zkAAAAJ": "Ahmad Byagowi",
    "p6DCMrQAAAAJ": "Michael Lambeta",
    "1ctl60EAAAAJ": "Po-Wei Chou",
    "jPD85m0AAAAJ": "Kalpana Seshadrinathan",
    "Y3eqab0AAAAJ": "Oscar Nestares",
    "JbhCpzkAAAAJ": "Daniel Geng",
    "SNqm6doAAAAJ": "Wenzhen Yuan",
    "QDmEj4MAAAAJ": "Guanzhi Wang",
    "AZeK-REAAAAJ": "Pim de Haan",
    "TApLOhkAAAAJ": "Taku Komura",
    "HZPnJ9gAAAAJ": "Lingjie Liu",
    "i02oEgMAAAAJ": "Ruohan Gao",
    "W7fLMpsAAAAJ": "Sam Wang",
    "y3MnZUEAAAAJ": "Weilin Wan",
    "397EbTsAAAAJ": "Nikos Kolotouros",
    "nrcJfPEAAAAJ": "Yu-Chuan Su",
    "5n9CN80AAAAJ": "Mayur Mudigonda",
    "SLRYlKsAAAAJ": "Zhiyang (Frank) Dou",
    "Ml6RzmEAAAAJ": "Kyle Vedder",
    "QIZWnnQAAAAJ": "Eric Eaton",
    "TqjSyUgAAAAJ": "Jeevana Priya Inala",
    "fpx2AWYAAAAJ": "Yunshuang Li",
    "RYLugBwAAAAJ": "Kun Huang",
    "h_q7XhoAAAAJ": "Todor Davchev",
    "Hxic_iwAAAAJ": "Sarah Bechtle",
    "MRYnqOEAAAAJ": "Neha Das",
    "V-HiOnUAAAAJ": "Kaustubh Sridhar",
    "Zcv_mIoAAAAJ": "Souradeep Dutta",
    "YgFOewgAAAAJ": "Douglas J. Durian",
    "x0NU7KEAAAAJ": "Andrea J.  Liu",
    "FehGbqYAAAAJ": "Sam Dillavou",
    "gV_XNa0AAAAJ": "Menachem Stern",
    "DZ-WjTIAAAAJ": "Jingxi Xu",
    "-pgIngUAAAAJ": "Ishan Khatri",
    "b4qKr7gAAAAJ": "Nate Chodosh",
    "X3cGY7wAAAAJ": "Neehar Peri",
    "XsYoY2QAAAAJ": "Arjun Krishna",
    "XAhGkq8AAAAJ": "Junyao Shi",
    "ZDPCh_EAAAAJ": "Nikolai Matni",
    "_0_p13YAAAAJ": "Kausik Sivakumar",
    "F_RBceUAAAAJ": "Luca Weihs",
    "pe1ArKwAAAAJ": "Zichen Zhang",
    "M2diIJYAAAAJ": "Susan R Weiss",
    "dlm2DaAAAAAJ": "Kyle G. Rodino",
    "fMgMCaoAAAAJ": "Frederic Bushman",
    "M3WZP7YAAAAJ": "Hui Chen",
    "JC0I3vgAAAAJ": "Hyun Koo",
    "J5hwfPwAAAAJ": "Dan T. Vogl",
    "KzxURf4AAAAJ": "Alfred Garfall",
    "yPgtxnkAAAAJ": "Sheng Feng",
    "_P954XkAAAAJ": "Una O'Doherty",
    "nXaOKoYAAAAJ": "Jae Seung Lee",
    "hscMk9AAAAAJ": "Ronald G Collman",
    "IeuLakwAAAAJ": "James Weimer",
    "qPlUgrgAAAAJ": "Insup Lee",
    "B0MzhZwAAAAJ": "Elijah S. Lee",
    "5031vK4AAAAJ": "Shuran Song",
    "5vSCuk0AAAAJ": "Yinsen Jia",
    "CRNmfCAAAAAJ": "Bruce D. Lee",
    "JnTrJCQAAAAJ": "Yiming Huang",
    "I6x_9IoAAAAJ": "Long Le",
    "dNOBQ1sAAAAJ": "Jason Xie",
    "uvyYzagAAAAJ": "Yue Yang",
    "D6P3KdMAAAAJ": "James Springer",
    "9c4G6GkAAAAJ": "Leon Kim",
    "u8f4WQ0AAAAJ": "Jake Welde",
    "GPJ2qqgAAAAJ": "Pratik Kunapuli",
    "P0CpOFwAAAAJ": "Sriram Narayanan",
    "Ja-8AFsAAAAJ": "Manmohan Chandraker",
    "7mrPM4kAAAAJ": "Alejandro Ribeiro",
    "VIZvaGsAAAAJ": "Bernadette Bucher",
    "ZvLa1RIAAAAJ": "Rajeev Alur",
    "x6zfRbcAAAAJ": "Steiger Neils Bryke",
    "kSnFGqkAAAAJ": "Tao Ma",
    "hm9dWCsAAAAJ": "Mayur Mudigonda",
    "eZr-ai0AAAAJ": "Seth Cooper",
    "1WSaBBsAAAAJ": "Firas Khatib",
    "tlh8i7gAAAAJ": "Brian Curless",
    "DRt16WsAAAAJ": "Eleanor O'Rourke",
    "H_1utcUAAAAJ": "Eric Butler",
    "78OLNd4AAAAJ": "Adam M. Smith",
    "vZkXCcsAAAAJ": "Andrew Leaver-Fay",
    "orqXipgAAAAJ": "Aaron Bauer",
    "IWDmHggAAAAJ": "Jos Stam",
    "MU5tFcQAAAAJ": "Jia-chi Wu",
    "BaY_Ie8AAAAJ": "Mira Dontcheva",
    "uJHvcMMAAAAJ": "Alexander Jaffe",
    "oQ6AeyEAAAAJ": "Michael D. Ernst",
    "8ablIzIAAAAJ": "Julia Salzman",
    "GAdPpe0AAAAJ": "Ilai Bistritz",
    "zqRN1ZEAAAAJ": "Roozbeh Dehghannasiri",
    "qArWV_wAAAAJ": "Gary Cheng",
    "LiwtZz4AAAAJ": "Alessandro Achille",
    "28p_eLYAAAAJ": "Avinash Ravichandran",
    "K9_XuM8AAAAJ": "Alex Wong",
    "ReEG0FwAAAAJ": "Gianfranco Doretto",
    "KFeN73wAAAAJ": "Rahul Bhotika",
    "IMAwpekAAAAJ": "Aditya Golatkar",
    "gYk4eAgAAAAJ": "Byung-Woo Hong",
    "r2tKnV4AAAAJ": "Yanchao Yang",
    "cXQciMEAAAAJ": "Daniel Cremers",
    "OCdJxC8AAAAJ": "Wei Xia 夏威",
    "Z2Mhh2UAAAAJ": "Luca Zancato",
    "YNi1eSQAAAAJ": "Michalis Raptis",
    "JId76kkAAAAJ": "Brian Fulkerson",
    "3P1gs1sAAAAJ": "Alper Ayvaci",
    "Y-I1X9QAAAAJ": "Hao Yang",
    "l78nduAAAAAJ": "Xiaohan Fei",
    "d3UtiX8AAAAJ": "S osher",
    "uRrSKVIAAAAJ": "Zhaowei Cai",
    "2Q6fIuAAAAAJ": "Jingming Dong",
    "xGI18C0AAAAJ": "Giovanni Paolini",
    "6FV7CNAAAAAJ": "Eagle Jones",
    "dvQXYW0AAAAJ": "Dong Lao",
    "v6o-fksAAAAJ": "Tong He",
    "xfgXYZ0AAAAJ": "Safa Cicek",
    "E2Ur1NwAAAAJ": "Ganesh Sundaramoorthi",
    "gopF7iMAAAAJ": "Nikolaos Karianakis",
    "n9fRgvkAAAAJ": "Vijay Mahadevan",
    "v3w4IYUAAAAJ": "Haibin Ling",
    "VJPRn1oAAAAJ": "Andrea Bertozzi",
    "BNEeEosAAAAJ": "Hao Li",
    "6V1dbO0AAAAJ": "Jason Meltzer",
    "5NUgdPcAAAAJ": "Konstantine Tsotsos",
    "SM-2GN4AAAAJ": "Taehee Lee",
    "dRShpScAAAAJ": "Michael Lam",
    "mukR7ccAAAAJ": "Vasiliy Karasev",
    "iCiUflEAAAAJ": "Yifei Lou",
    "8qsuHEoAAAAJ": "Marzia Polito",
    "BAtMB04AAAAJ": "Alhussein Fawzi",
    "qosS83IAAAAJ": "Seyed-Mohsen Moosavi-Dezfooli",
    "wcr5g6oAAAAJ": "Giorgio Picci",
    "9IpdcgMAAAAJ": "Andrea CG Mennucci",
    "MR3fFXoAAAAJ": "Virginia Estellers",
    "-Ve9sJ0AAAAJ": "Pascal Frossard",
    "7KgIMosAAAAJ": "Orchid Majumder",
    "bEctTN0AAAAJ": "Yantao Shen 沈岩涛",
    "wGNIr6oAAAAJ": "Kamil Wnuk",
    "8bwdGesAAAAJ": "Siqi (Tiffany) Deng",
    "tbAlI9kAAAAJ": "Martin Burger",
    "U3KDpBUAAAAJ": "Shuo Yang",
    "KNcECJQAAAAJ": "Mingze Xu",
    "LPAZlL8AAAAJ": "Adam M. Oberman",
    "sdNtK6QAAAAJ": "RW Brockett",
    "nVsOPtQAAAAJ": "Rasool Fakoor",
    "A6yjdJAAAAAJ": "Bing Xiang",
    "XlqTD2UAAAAJ": "Georgios Georgiadis",
    "Ih29F_QAAAAJ": "Matteo Rovere",
    "h6eAkFwAAAAJ": "Sung Ha Kang",
    "Nv6G5DwAAAAJ": "Shay Deutsch",
    "CG9yOXoAAAAJ": "Cuong V. Nguyen",
    "Sb4o_0IAAAAJ": "Mario E. Munich",
    "VWCMVn4AAAAJ": "Luminita Vese",
    "yVnCUg0AAAAJ": "John Collomosse",
    "-1nmmKgAAAAJ": "Brian Taylor",
    "6yls9oMAAAAJ": "Yen-Hsi Richard Tsai",
    "KZpZTTQAAAAJ": "Ben Athiwaratkun",
    "0FSlSt4AAAAJ": "Jie Ma",
    "KL6_oegAAAAJ": "Jason Krone",
    "F4FxpRoAAAAJ": "Michael Hamilton",
    "E8_P8_wAAAAJ": "sanjoy mitter",
    "fvr-J3sAAAAJ": "Yuanlu Xu",
    "ni3EbYgAAAAJ": "Tony TUNG",
    "IolN_okAAAAJ": "Shunsuke Saito",
    "1ed1sPkAAAAJ": "Oron Anschel",
    "UDRtJsEAAAAJ": "Rachid Deriche",
    "Yk6keUoAAAAJ": "Christophe Lenglet",
    "o500TjwAAAAJ": "Bernd Heisele",
    "eAHAxi0AAAAJ": "Omar Fawzi",
    "tjI54N0AAAAJ": "Albert Zhao",
    "9aQUYVQAAAAJ": "Raja Giryes",
    "1ytghtEAAAAJ": "Qing Liu",
    "akuWIJQAAAAJ": "Xialei Liu 刘夏雷",
    "bkALdvsAAAAJ": "Zicheng Liu",
    "V_VpLksAAAAJ": "Yinpeng Chen",
    "hbNllP0AAAAJ": "Mario Sznaier",
    "FwNaHxQAAAAJ": "Thomas Pock",
    "hV5D8GYAAAAJ": "Tong He",
    "c-cuO9cAAAAJ": "Frank NIELSEN",
    "Zo_TuDUAAAAJ": "Eric Graham",
    "ofoABP8AAAAJ": "Ryuzo Okada",
    "d0KQ9z0AAAAJ": "Guy Van den Broeck",
    "aMkW638AAAAJ": "Daniele Fontanelli",
    "9pSK04MAAAAJ": "Xavier Bresson",
    "oUK2gu8AAAAJ": "Greg Slabaugh",
    "soanB6MAAAAJ": "Gozde Unal, PhD, Professor",
    "MnOal0UAAAAJ": "Mahsan Rofouei",
    "LYt_4uIAAAAJ": "majid sarrafzadeh",
    "EcgjIi4AAAAJ": "Peter Petersen",
    "-kX87sgAAAAJ": "Alberto Pretto",
    "044QzjcAAAAJ": "Choongbum Lee",
    "P8NRbbYAAAAJ": "Vladislav Voroninski",
    "zzG75zEAAAAJ": "Paul Hand",
    "wADiNucAAAAJ": "Tsu-Chin Tsao",
    "10RVXDQAAAAJ": "Zainul Charbiwala",
    "P2oSOR0AAAAJ": "Kyungnam Kim",
    "0W9XZ0cAAAAJ": "Yuri Owechko",
    "yREBSy0AAAAJ": "Soheil Kolouri",
    "dwi5wvYAAAAJ": "Amnon Shashua",
    "55swP8AAAAAJ": "Soheil Ghiasi",
    "0lO_16kAAAAJ": "Chaohui Wang",
    "MIEaoNEAAAAJ": "Peter Sturm",
    "qkIp7AEAAAAJ": "Pingkun Yan",
    "N4sca6EAAAAJ": "Yiqiang Zhan",
    "SazwWasAAAAJ": "Maneesh Dewan",
    "JR7F__MAAAAJ": "Angelo Cenedese",
    "Zd2MrfUAAAAJ": "Emanuele Menegatti",
    "T8LkBTYAAAAJ": "Fabio Cuzzolin",
    "ErvkcKcAAAAJ": "Megan AK Peters",
    "eBooFDEAAAAJ": "Michael Allen",
    "Ggudr9EAAAAJ": "Kevin Tew",
    "qB0jk_EAAAAJ": "Zhao Yi",
    "Y-KJRwoAAAAJ": "Philip W. Rundel",
    "w0Vl_lsAAAAJ": "Allen Tannenbaum",
    "wmx7KVUAAAAJ": "Markus Hadwiger",
    "6OZMoP0AAAAJ": "Simon Korman",
    "Fhs-sfkAAAAJ": "Jameson Merkow",
    "xL45YGMAAAAJ": "Jochen Kruecker",
    "8mA9QpUAAAAJ": "naira hovakimyan",
    "F_KIfrsAAAAJ": "Eric N Johnson",
    "D8dLtRMAAAAJ": "Zhengqing Zhou",
    "U_L2uiwAAAAJ": "Leighton Barnes",
    "uqesapEAAAAJ": "(Joshua) Huadong Meng",
    "X3gGi_0AAAAJ": "Zhimei Ren",
    "qRd8Hh4AAAAJ": "Moe Z. Win",
    "OTFnifoAAAAJ": "Linglong Dai",
    "jhyC8TsAAAAJ": "Zhaocheng Wang",
    "ULgz3noAAAAJ": "Jiayi Zhang",
    "ZNquLr8AAAAJ": "Sihan Li",
    "uy43gzcAAAAJ": "Peter W. Glynn",
    "llcGIZ8AAAAJ": "Pritam Mukherjee",
    "Ylp9SPUAAAAJ": "Gowtham R. Kurri",
    "VLb_0NYAAAAJ": "Or Ordentlich",
    "fnDzqzIAAAAJ": "Guanyang Wang",
    "Du5t4FYAAAAJ": "Yuan Zhang",
    "3mOq4dcAAAAJ": "Somil Bansal",
    "wr9RgmcAAAAJ": "Bidipta Sarkar",
    "GNzbVIsAAAAJ": "Raul Puri",
    "TP0epB8AAAAJ": "Phillip Kuznetsov",
    "PJSVA_QAAAAJ": "Riley Edmunds",
    "XOfA8ckAAAAJ": "Shimon Ullman",
    "u7Kad50AAAAJ": "Evelyne Tzoukermann",
    "dpLLZIAAAAAJ": "Pei Guo",
    "gPKDZtwAAAAJ": "Mark W. Newman",
    "BEHcR-IAAAAJ": "Scott Klemmer",
    "PxYY_nsAAAAJ": "Grant Van Horn",
    "PA9La6oAAAAJ": "Panos Ipeirotis",
    "KJNUEgkAAAAJ": "Abhimanyu Dubey",
    "M1IgIyMAAAAJ": "Nikhil Naik",
    "2aEdHz0AAAAJ": "Otkrist Gupta",
    "8hpOmVgAAAAJ": "Ramesh Raskar",
    "vPoTuLQAAAAJ": "I-Jeng Wang",
    "RoGOW9AAAAAJ": "David Doermann",
    "Mtho-7EAAAAJ": "Yuancheng Luo",
    "8hU3dn8AAAAJ": "João Paulo Papa",
    "1_BWn8IAAAAJ": "Jan Neumann",
    "UV9LxSEAAAAJ": "Geetu Ambwani",
    "_rUcw0EAAAAJ": "Kousha Etessami",
    "l6oz33MAAAAJ": "Greg Ganger",
    "RPWFQlAAAAAJ": "Michael A. Kozuch",
    "tfKeplgAAAAJ": "Charles Reiss",
    "EhCg54EAAAAJ": "Timothy Zhu",
    "F9kqUXkAAAAJ": "Phillip Gibbons",
    "a4HRDBEAAAAJ": "Lianghong Xu",
    "KfGfDvcAAAAJ": "Eyal de Lara",
    "MFZC4EgAAAAJ": "Sangeetha Abdu Jyothi",
    "wb9DYOEAAAAJ": "Carlo Aldo Curino",
    "WYctQAQAAAAJ": "Garth Alan Gibson",
    "7XyGUGkAAAAJ": "Onur Mutlu",
    "78KBaPsAAAAJ": "Wolfgang Stuerzlinger",
    "1LbWyf4AAAAJ": "Rob Allison",
    "8l-mDfQAAAAJ": "Sebastian Urban Stich",
    "rIAYxaMAAAAJ": "Lie He (贺烈)",
    "KKQCt30AAAAJ": "Thijs Vogels",
    "t9PEVrkAAAAJ": "Quentin Rebjock",
    "UA9Hb2EAAAAJ": "Andreas Veit",
    "08CNqrYAAAAJ": "Sanjiv Kumar",
    "zbcN_QIAAAAJ": "Seungyeon Kim",
    "aIRUO8AAAAAJ": "Felix Grimberg",
    "ldJpvE8AAAAJ": "Anastasia Koloskova",
    "FXacC3oAAAAJ": "Matteo Pagliardini",
    "P2CPNr8AAAAJ": "Mary-Anne Hartley",
    "C5IpcRYAAAAJ": "Erum Mushtaq",
    "6IFj7SkAAAAJ": "Jean OGIER DU TERRAIL",
    "CPuApzoAAAAJ": "Shadi Albarqouni",
    "RIBv3lgAAAAJ": "Constantin Philippenko",
    "2z2camUAAAAJ": "Chaoyang He",
    "ajJxXnEAAAAJ": "Giovanni Neglia",
    "n8ysVHUAAAAJ": "Othmane Marfoq",
    "ge-OinUAAAAJ": "Aymeric Dieuleveut",
    "ct4ViZMAAAAJ": "Santiago SILVA",
    "gOkjmJcAAAAJ": "Marco Lorenzi",
    "IRyM3b8AAAAJ": "Marc Tommasi",
    "4HHWesEAAAAJ": "Boris Muzellec",
    "WDB4HqIAAAAJ": "Edwige Cyffers",
    "l7GidmgAAAAJ": "Tanguy Marchand",
    "YGnty0AAAAAJ": "Paul Mangold",
    "6EgqGRwAAAAJ": "Maria Telenczuk",
    "Bj1tRlsAAAAJ": "François Fleuret",
    "Hanjxs8AAAAJ": "Andrei Afonin",
    "DnRJBwUAAAAJ": "Haihao (Sean) Lu",
    "eIdQR5oAAAAJ": "Natalia Ponomareva",
    "d5wGxRsAAAAJ": "Alexander Wei",
    "rxxutcgAAAAJ": "Elisa Celis",
    "npq3yLIAAAAJ": "Dariusz Kowalski",
    "T_mPgZIAAAAJ": "Praneeth Vepakomma",
    "JZqo39cAAAAJ": "Jan F Nygård",
    "S1a25sEAAAAJ": "Xiaoying TANG (Wanrong TANG)",
    "P2NN0PAAAAAJ": "Lin Wang",
    "ZurKqVkAAAAJ": "El Mahdi Chayti",
    "dJg1TUEAAAAJ": "Boi Faltings",
    "Uo0aIHAAAAAJ": "Panayiotis Danassis",
    "S_6zsEwAAAAJ": "Arnout Devos",
    "SY6gzIgAAAAJ": "Duygu Nur Yaldiz",
    "HCH-T5UAAAAJ": "Yavuz Bakman",
    "N1q-egYAAAAJ": "Dravyansh Sharma",
    "pVnRW0YAAAAJ": "Klavdiia Naumova",
    "U7yzfCkAAAAJ": "Dongyang Fan",
    "pwUdiCYAAAAJ": "Kian Ahrabian",
    "7o1I4IkAAAAJ": "Negar Mokhberian",
    "QI-eVvkAAAAJ": "Pegah Jandaghi",
    "I9r2zF0AAAAJ": "tuo zhang",
    "JjASH4UAAAAJ": "Baturalp Buyukates",
    "yvdSr4AAAAAJ": "Jay Pujara",
    "4gE_vYgAAAAJ": "Sungmin Kang",
    "yqIoH34AAAAJ": "Gauri Joshi",
    "7b_ipvgAAAAJ": "Stacy Patterson",
    "mKia7Y4AAAAJ": "Jinghui Chen",
    "fQVZ28cAAAAJ": "Priya Sundaresan",
    "Cybj4ysAAAAJ": "Rory Beard",
    "PRl_gWUAAAAJ": "Pawel Swietojanski",
    "Q5CBlNcAAAAJ": "Ondrej Miksik",
    "U8QXoYkAAAAJ": "Raymond WM Ng",
    "p28z3SQAAAAJ": "Yuan Cao",
    "H4Rq5LwAAAAJ": "Thierry Moreau",
    "jWRhmqoAAAAJ": "Cody (Hao) Yu",
    "NvBZp6MAAAAJ": "Yida Wang",
    "Qzss0GEAAAAJ": "Weinan Zhang",
    "QGcz9-kAAAAJ": "Hilal Asi",
    "FiBMfBsAAAAJ": "Oliver Hinder",
    "bc0aQ7YAAAAJ": "Maxime Cauchois",
    "kUcBGSgAAAAJ": "Tushar Chandra",
    "Olj9jQgAAAAJ": "Suyash Gupta",
    "-mrh5AIAAAAJ": "Gaurav Kapoor",
    "xBRQVAcAAAAJ": "Abhishek Bhowmick",
    "vq4lx5YAAAAJ": "Julien Freudiger",
    "WoSEVJUAAAAJ": "Steve Yadlowsky",
    "v5TPCXFtkUgC": "Alnur Ali",
    "wQSRT18AAAAJ": "Mikael Johansson",
    "jTLiOiMAAAAJ": "Sorathan (Tum) Chaturapruek",
    "Ukl64ggAAAAJ": "Chulhee Yun",
    "YkeS_SoAAAAJ": "Riccardo Volpi",
    "C0kDOzcAAAAJ": "David Harwath",
    "N5HDmqoAAAAJ": "Wei-Ning Hsu",
    "DmIG_WoAAAAJ": "Yu-An Chung",
    "43nqWTUAAAAJ": "Hongyin Luo",
    "EilVnKwAAAAJ": "Yu Zhang",
    "DfXsKZ4AAAAJ": "Preslav Nakov",
    "G43gXjIAAAAJ": "Najim Dehak",
    "t0gYEjAAAAAJ": "Ahmed Ali",
    "SvKKBy4AAAAJ": "Sameer Khurana",
    "-SfNafoAAAAJ": "Suwon Shon",
    "pLwOQV4AAAAJ": "Douglas A Reynolds",
    "0IBt8msAAAAJ": "Chia-ying (Jackie) Lee",
    "K-BdgNwAAAAJ": "Sanjeev Khudanpur",
    "vYUDlsEAAAAJ": "Alessandro Moschitti",
    "7xEd0ZIAAAAJ": "Stephen H. Shum",
    "tPdzoqYAAAAJ": "Eugene Weinstein",
    "ROU76KkAAAAJ": "Nelson Morgan",
    "23rIjfwAAAAJ": "Patrick Cardinal",
    "k4k05hcAAAAJ": "Chin-Hui Lee",
    "Mb40Pw0AAAAJ": "Andrew Correa S.",
    "oK5EzZsAAAAJ": "Igor Malioutov",
    "ZZGpQG4AAAAJ": "Takaaki Hori",
    "yMszfuMAAAAJ": "Brandon Luders",
    "ZTe13LgAAAAJ": "Jeong hwan Jeon",
    "5pKdNQkAAAAJ": "Rabih Zbib",
    "BffFdd0AAAAJ": "Stephan Vogel",
    "ILVcer0AAAAJ": "Mikio Nakano",
    "CKXeqHoAAAAJ": "Philip Guo",
    "-CbjdL8AAAAJ": "Bruce Mehler",
    "tYazD-8AAAAJ": "Mohamad Hasan Bahari",
    "GwGsvm0AAAAJ": "Bo Zhu",
    "0Gqc1vIAAAAJ": "Albert Huang",
    "qbjHRA8AAAAJ": "Ryan M. Rifkin",
    "U9nP_RcAAAAJ": "Nikko Strom",
    "NfyVi8AAAAAJ": "Bryan Reimer",
    "AQcftaEAAAAJ": "Shannon C Roberts",
    "jG0AYyEAAAAJ": "Kiarash Adl",
    "ekic9BkAAAAJ": "William M. Campbell",
    "pRBbU7wAAAAJ": "Lukas Burget",
    "S1F-gScAAAAJ": "Tomoharu Iwata",
    "U5xRA6QAAAAJ": "Shinji Watanabe",
    "BzJ_GboAAAAJ": "Jingjing Liu",
    "yyG8xWcAAAAJ": "Zhang Yu",
    "xPhnaK0AAAAJ": "William P. Li",
    "dXBtN0cAAAAJ": "Iman Saleh",
    "tsdD0N4AAAAJ": "Etienne Grossmann",
    "S-J_ItYAAAAJ": "Mark Billinghurst",
    "KdA9qBkAAAAJ": "Xinjian chen",
    "btkSHDwAAAAJ": "Christos Gkantsidis",
    "pWRtbiMAAAAJ": "Vahideh Manshadi",
    "qzIHHMEAAAAJ": "Shipra Agrawal",
    "BBKfx4oAAAAJ": "Victor Bahl",
    "rmxKTn4AAAAJ": "Qi Qi",
    "QkWtGNkAAAAJ": "Yichuan Ding",
    "Sz01Ye0AAAAJ": "Farnaz Ronaghi",
    "4H4bRkcAAAAJ": "Dan B Goldman",
    "a959F6AAAAAJ": "Adam Finkelstein",
    "haahCZ4AAAAJ": "Dani Lischinski",
    "_dVzmiYAAAAJ": "Michal Lukáč",
    "LDur_VYAAAAJ": "Lena Gorelick",
    "4g-njrYAAAAJ": "Sunil Hadap",
    "_SVdR44AAAAJ": "Jakub Fišer",
    "gp6HUP0AAAAJ": "Zhixin Shu",
    "9_H57VkAAAAJ": "Pradeep Sen",
    "InutcIUAAAAJ": "Soheil Darabi",
    "YZcVsRMAAAAJ": "Ohad Fried",
    "P97vI1EAAAAJ": "Ira Kemelmacher-Shlizerman",
    "tiu7twQAAAAJ": "Ondřej Jamriška",
    "BxbKTYkAAAAJ": "Dimitris Samaras",
    "pp848fYAAAAJ": "Jia-Bin Huang",
    "lwlYARMAAAAJ": "Zhaowen Wang",
    "rQ2WAxoAAAAJ": "Paul Asente",
    "gKJ3MfIAAAAJ": "Yoav HaCohen",
    "jkm1ipUAAAAJ": "Denis Simakov",
    "ADMVEmsAAAAJ": "Leon A. Gatys",
    "tjjniXEAAAAJ": "Chen-Hsuan Lin",
    "vmAe35UAAAAJ": "Simon Lucey",
    "kMFnJxgAAAAJ": "Fei Yang",
    "NFeigSoAAAAJ": "Hao Li",
    "jpIFgToAAAAJ": "Harry Yang",
    "mFC0wp8AAAAJ": "Xin Lu",
    "8GxAlSUAAAAJ": "Ondřej Texler",
    "VgYU_m8AAAAJ": "Alexander S. Ecker",
    "BW2Xix4AAAAJ": "Dmitry Rudoy",
    "9RnyW0cAAAAJ": "Maziar Yaesoubi",
    "ZvIdLmYAAAAJ": "Roey Mechrez",
    "miE8bYkAAAAJ": "Wei-Sheng Lai",
    "0VQ1sjcAAAAJ": "David E. Jacobs",
    "LDb4tb0AAAAJ": "Shi-Min Hu",
    "yGPH-nAAAAAJ": "Seungyong Lee",
    "PeMuphgAAAAJ": "Xiaoyong Shen",
    "yO82m38AAAAJ": "Guang Chen",
    "xEFh0AgAAAAJ": "Nathan Carr",
    "_zLn05oAAAAJ": "Fang-Lue Zhang",
    "6ZDIdEAAAAAJ": "Aditya Sankar",
    "MliblMQAAAAJ": "Tony X. Han",
    "gsv5xicAAAAJ": "Steve Bako",
    "N_maL_AAAAAJ": "Shai Bagon",
    "GBU568oAAAAJ": "Olga Sorkine-Hornung",
    "TmAQaboAAAAJ": "Kevin Dale",
    "hpItE1QAAAAJ": "shai avidan",
    "Voph3LUAAAAJ": "Siying Liu",
    "RIeAomMAAAAJ": "Minh N. Do",
    "q0AgQ2MAAAAJ": "Xiaobai Chen",
    "ft85d8kAAAAJ": "Jonas Wulff",
    "0fqAIGAAAAAJ": "James W. Hennessey",
    "PKSWrbwAAAAJ": "Olga Diamanti",
    "kssA7YwAAAAJ": "Leo Anthony Celi",
    "l7WEDAcAAAAJ": "Maimuna S. Majumder",
    "HMyXWb4AAAAJ": "A. Ian Wong, MD, PhD",
    "63WN_bEAAAAJ": "Judy Wawira Gichoya",
    "Lf3tYKYAAAAJ": "Jackson A Killian",
    "2eWscBQAAAAJ": "Andrew Perrault",
    "2yHJIP0AAAAJ": "Aditya Mate",
    "Ssdg9-sAAAAJ": "M Maria Glymour",
    "hcAHEDYAAAAJ": "Mary E. Lough",
    "QpClwb8AAAAJ": "Han-Ching Ou",
    "eD9_J3wAAAAJ": "Mathew V Kiang",
    "DFAzHK8AAAAJ": "Rene Eber",
    "0uCgFkkAAAAJ": "Ruijia Chen",
    "AMFWWyMAAAAJ": "Mark W. Albers",
    "bamP5BMAAAAJ": "Xiaoli Liu",
    "FMTai3oAAAAJ": "RWMA Madushani",
    "ZiEaIpUAAAAJ": "Lasith Adhikari",
    "Gi6ksZoAAAAJ": "Eduardo Mireles-Cabodevila",
    "EPLEf60AAAAJ": "Edward Christopher Dee, MD",
    "kz2aIc8AAAAJ": "Franck Dernoncourt",
    "9dF2BdMAAAAJ": "Joseph A Paguio",
    "fDmPEMYAAAAJ": "jacqueline cellini",
    "OjWXOSsAAAAJ": "Andrew C. Stokes",
    "BQD1XlcAAAAJ": "Alicia R. Riley",
    "SlLz8KoAAAAJ": "Jack Gallifant",
    "pPaf4pkAAAAJ": "Sudeshna Das",
    "UpCGVSAAAAAJ": "Jhalique Jane Fojas",
    "kJPmYCcAAAAJ": "Anne de Hond",
    "h2L2Xp0AAAAJ": "Jay Chandra",
    "uaQdhE4AAAAJ": "Bang Zheng",
    "PMd9DyQAAAAJ": "João Matos",
    "D2EdRScAAAAJ": "Rafeya Raquib",
    "Sxi1xgkAAAAJ": "Azade Tabaie",
    "_75LDyMAAAAJ": "Ewout W. Steyerberg",
    "Qlq7GEQAAAAJ": "Rishikesan Kamaleswaran",
    "hou2DHoAAAAJ": "Andre Holder",
    "RZOjMYMAAAAJ": "Timothy G. Buchman",
    "_DEJi28AAAAJ": "Han Kim",
    "hKlHPt0AAAAJ": "Bella Vakulenko-Lagun",
    "NEBWPbsAAAAJ": "Liam G. McCoy, MD MSc",
    "J_5y3HMAAAAJ": "Yuan Lai",
    "AkJyLCAAAAAJ": "Rebecca A. Betensky",
    "FXw6xXcAAAAJ": "Bradley Hyman",
    "4dPt9-4AAAAJ": "Yi-han Sheu",
    "s9RsYfcAAAAJ": "Lefkos Middleton",
    "5MdxFjAAAAAJ": "Melek Somai",
    "eU0C31YAAAAJ": "Kyle Evans",
    "4v73L2AAAAAJ": "Artem Sokolov",
    "52f6rLIAAAAJ": "Bowen Su",
    "Fe-VhGoAAAAJ": "Alyssa Mooney",
    "MrOv72wAAAAJ": "Luis Filipe Nakayama",
    "CPQdYCQAAAAJ": "Kenneth D. Mandl",
    "o6m4948AAAAJ": "Anika Puri",
    "s165sfUAAAAJ": "Saahil Sundaresan",
    "AdG54z4AAAAJ": "Ahyoung Cho",
    "o8TlyGMAAAAJ": "Samuel Preston",
    "HxYWiHsAAAAJ": "Irma Elo",
    "zSZt9K0AAAAJ": "Elaine Okanyene Nsoesie",
    "eaZS9_YAAAAJ": "Elizabeth Wrigley-Field",
    "siiL_PUAAAAJ": "Eugenio Paglino",
    "cOQW8gkAAAAJ": "Kirsten Bibbins-Domingo",
    "j3UHaFoAAAAJ": "Ghinwa Y. Hayek",
    "aGpw2rYAAAAJ": "Aaron R. Kaufman",
    "3FsCV_IAAAAJ": "Michelle A DeVost",
    "W_ZjnTUAAAAJ": "Tristan Struja",
    "fadRi1YAAAAJ": "Jaime Cardoso",
    "91WQXlIAAAAJ": "Daniel K. Ebner, MD MPH",
    "4Cqm82UAAAAJ": "Naira Link Woite, MD, MPH",
    "keSzZQIAAAAJ": "Stephanie Cabral",
    "XM2WLE8AAAAJ": "Chrystinne Fernandes",
    "R4DiePwAAAAJ": "William Wasswa",
    "Dmrm4skAAAAJ": "Bradley Ong",
    "C6BeHCMAAAAJ": "Erika Meza",
    "U5LkFfYAAAAJ": "Hélène Eloise Aschmann",
    "PfaeD-8AAAAJ": "Jingxuan Wang",
    "-nsG4ZUAAAAJ": "Mohammad Kashkooli",
    "fAVYK4wAAAAJ": "Amelia Fiske",
    "SotYphoAAAAJ": "Anton Petushkov",
    "wdbul0gAAAAJ": "Chenyu Li",
    "NRlzPgIAAAAJ": "Freddy T. Nguyen, MD, Ph.D.",
    "tRJvzU0AAAAJ": "Igor O. Korolev",
    "A3GVtGAAAAAJ": "Oren J Mechanic",
    "vnGywSsAAAAJ": "Erin Duralde",
    "3A098eMAAAAJ": "Barbara D. Lam",
    "y3ry4kcAAAAJ": "Shrey Jain",
    "3FwavwMAAAAJ": "Rodolphe Thiébaut",
    "usd_zgsAAAAJ": "SIMON CAUCHEMEZ",
    "AcrgWZIAAAAJ": "Melanie Prague",
    "6aNMdbsAAAAJ": "Nathanaël Hozé",
    "cdx_NQIAAAAJ": "Juliette Paireau",
    "heTXnBYAAAAJ": "Catherine Pollack",
    "j-DQLQgAAAAJ": "Shagun Gupta",
    "hTkUgG0AAAAJ": "Jessica Malaty Rivera, MS",
    "57jIWn8AAAAJ": "Christopher V. Cosgriff, MD, MPH",
    "O2nUrQIAAAAJ": "Jessilyn Dunn",
    "eesxmR0AAAAJ": "Christopher E. Cox, MD MPH MHA",
    "SzemdlUAAAAJ": "Krista Haines",
    "w1_KlvoAAAAJ": "Adrien Carrel",
    "Zl9ZzTAAAAAJ": "Longqi Yang",
    "fNUgQjMAAAAJ": "Fereshteh Amini",
    "9lT6OOEAAAAJ": "Yuan Yuan",
    "51it_LkAAAAJ": "Sonia Jaffe",
    "NG5jzCkAAAAJ": "Valencia Joyner Koomson",
    "U8nclXkAAAAJ": "Michael Morley",
    "c4FeOJQAAAAJ": "Jonathan Gruber",
    "YjPIezoAAAAJ": "Michael Kutner",
    "Du51uRIAAAAJ": "Irene Y. Chen",
    "KRQ53ysAAAAJ": "Ayush Jain",
    "x0NsQm0AAAAJ": "Enguerrand Horel",
    "C-NftTgAAAAJ": "B. Aditya Prakash",
    "WKpjMHsAAAAJ": "Sen Pei",
    "5NtH-JcAAAAJ": "Ajitesh Srivastava",
    "lfRiJ8YAAAAJ": "Bijaya Adhikari",
    "6ZYVPEoAAAAJ": "Anushka Bhaskar",
    "ryE3jpMAAAAJ": "Frances Dominique Ho",
    "afp6_lsAAAAJ": "Urvish Jain",
    "lWadInsAAAAJ": "Alexander J Gates",
    "oGqXzKAAAAAJ": "Adam G. Dunn",
    "yd-4aEIAAAAJ": "Hamza Nabulsi",
    "8DvzhZMAAAAJ": "Sulaiman Moukheiber",
    "l_pScqkAAAAJ": "Rachael Parke",
    "dGSrRTYAAAAJ": "Skyler Shapiro",
    "qCAslJ8AAAAJ": "Justin D Salciccioli",
    "KeltSA4AAAAJ": "Louisa H. Smith",
    "8_he8cUAAAAJ": "Anhvinh L Doanvo",
    "uND_5REAAAAJ": "Francesco Tudisco",
    "2f6t6hYAAAAJ": "Satyaki Sikdar",
    "CQVb2IgAAAAJ": "Francesco Rinaldi",
    "NDrCCokAAAAJ": "Santo Fortunato",
    "NhJMwocAAAAJ": "Sagar Kumar",
    "l1taidEAAAAJ": "Sara Venturini",
    "CA3Z5zcAAAAJ": "Erin N Hulland",
    "jI3_2koAAAAJ": "Amulya Yadav",
    "ILkESaUAAAAJ": "Alexander Rodríguez",
    "Gua_MdkAAAAJ": "Elle Lett, MD PhD MA",
    "g0neHX8AAAAJ": "Francesco Carli",
    "66cQtjcAAAAJ": "Gurucharan Lingamallu",
    "IVpn1mkAAAAJ": "Sean Van Diepen",
    "3kKjoMEAAAAJ": "Leonid Garber",
    "pM1yxtsAAAAJ": "Vincent J Major",
    "mM9e90oAAAAJ": "Sema Sgaier",
    "a4bPXeYAAAAJ": "Whitney Wells",
    "JzKCTBgAAAAJ": "Divya Siddarth",
    "TJVj26YAAAAJ": "Peter Smittenaar",
    "t1Xf7NQAAAAJ": "Rajiv Sethi",
    "BD2lkwIAAAAJ": "Michail Papazoglou",
    "kc_fImQAAAAJ": "Grace Charles",
    "JEky9g0AAAAJ": "Saketh Sundar",
    "_1KUuDQAAAAJ": "Kathryn Schaber",
    "MhXqCRAAAAAJ": "Alex Rewegan",
    "GgJdsl4AAAAJ": "RM Klevens",
    "XRsGhZ4AAAAJ": "Jacqueline M. Torres",
    "4C9Bm9YAAAAJ": "Matina Halkia",
    "spWVns8AAAAJ": "Kai Wang",
    "WufbXzIAAAAJ": "Jordan Poles",
    "KP-DwH0AAAAJ": "S. Shyam Sundar",
    "nxXheggAAAAJ": "Aviva Philipp-Muller",
    "KWqO1CgAAAAJ": "Andrew H. Miller",
    "ez_F5gcAAAAJ": "Chao Liu",
    "dkW3lTAAAAAJ": "Jun Yang",
    "wMcK4TQAAAAJ": "Liting Duan",
    "_KpeoVgAAAAJ": "Barry Honig",
    "bD4hIqcAAAAJ": "Qian Cong",
    "pw0LluEAAAAJ": "Yifan Cheng",
    "CsQTBwsAAAAJ": "Larry Swanson",
    "SO1MfpcAAAAJ": "Taylor J Woehl",
    "fDvQyegAAAAJ": "Dr. Shenqiang Ren",
    "s5hQAPwAAAAJ": "Hao Peng",
    "vEqE_rUAAAAJ": "Geoffrey F. Miller",
    "HBjME2gAAAAJ": "Rebecca Sear",
    "dB4mKx4AAAAJ": "Oliver Steinbock",
    "tMNWtzkAAAAJ": "Bruno C Batista",
    "t1cX3kcAAAAJ": "Anh Phuong Tran",
    "PgGOyOUAAAAJ": "Zhaoqi Yan",
    "5RJ6wXAAAAAJ": "Sara Venturini",
    "cCXHHSkAAAAJ": "Hironori Waki",
    "inYyDE4AAAAJ": "Michael K. Tippett",
    "yV03lm0AAAAJ": "Sixto Herrera García",
    "55sPPYMAAAAJ": "Steve A Kay",
    "fup4pNsAAAAJ": "Marianne Reddan",
    "NNr46G8AAAAJ": "Scott Davidoff",
    "DdNAgNwAAAAJ": "Laura Dabbish",
    "zmLNe4AAAAAJ": "Maxim Makachev",
    "dnMoAsUAAAAJ": "Karen P. Tang",
    "O1LZbI4AAAAJ": "Junsung Kim",
    "HKGYvu4AAAAJ": "Robert E. Kraut",
    "YgtBXP0AAAAJ": "Bryan A. Pendleton",
    "YArRsvEAAAAJ": "Mariano Phielipp",
    "MyKLYVMAAAAJ": "Soraia Raupp Musse",
    "iIFHZ1UAAAAJ": "Elke Rundensteiner",
    "Lh7VfoMAAAAJ": "Xiangnan Kong",
    "B1lAghgAAAAJ": "Hamid Palangi",
    "71P8yv4AAAAJ": "Cansu Sen",
    "5xL774wAAAAJ": "Walter Gerych",
    "YtUDgPIAAAAJ": "Marinka Zitnik",
    "OnVgcOkAAAAJ": "Dipankar Ray",
    "6aWRAPkAAAAJ": "Haoran Zhang",
    "ihFmK4cAAAAJ": "Mingtian Tan",
    "VrFFU84AAAAJ": "Saadia Gabriel",
    "ID2aN3QAAAAJ": "Owen Queen",
    "D3BKoHMAAAAJ": "Luke Buquicchio",
    "UtBcznsAAAAJ": "Mike A. Merrill",
    "Ke6ex0wAAAAJ": "Emmanuel Agu",
    "u8SnUUgAAAAJ": "Jidapa Thadajarassiri",
    "br990A8AAAAJ": "Teddy Koker",
    "tQuRm1AAAAAJ": "Vinayak Gupta",
    "zW32dXsAAAAJ": "Shanghua Gao",
    "VUOMP_EAAAAJ": "Kimia Hamidieh",
    "hVUVOTIAAAAJ": "Theodoros Tsiligkaridis",
    "Ftz0NHIAAAAJ": "Shan Chen",
    "aCFYAEsAAAAJ": "Danielle S. Bitterman",
    "LE3ctn0AAAAJ": "Tianlong Chen",
    "WFtyBCwAAAAJ": "Ramesh Doddaiah",
    "39VDRnoAAAAJ": "Prathyush S Parvatharaju",
    "v7G4QvIAAAAJ": "Hugo Aerts",
    "PyuaaWAAAAAJ": "Biao Yin",
    "9MsdbKoAAAAJ": "Faisal Mahmood",
    "elXOB1sAAAAJ": "Frank Rudzicz",
    "8Mlyv3oAAAAJ": "Aparna Balagopalan",
    "Im_m9I8AAAAJ": "Erin Teeple",
    "SHQikPwAAAAJ": "Priyanshu Kumar",
    "PwdervMAAAAJ": "Devansh Jain",
    "M6-o86kAAAAJ": "Kuleen Sasse",
    "qrgWqjYAAAAJ": "Tiffany Y Chen",
    "1UNlyTcAAAAJ": "Andrew H. Song",
    "GhzAXmIAAAAJ": "Ming Y. Lu",
    "ZwmIw4EAAAAJ": "Jana Lipkova",
    "0_bSbIoAAAAJ": "Yuzhe Yang",
    "tAxVl44AAAAJ": "Drew FK Williamson, MD",
    "xmp9PZoAAAAJ": "Emma Dyer",
    "am5XqsQAAAAJ": "Guillaume Jaume",
    "yhGqdMgAAAAJ": "Richard J. Chen",
    "8-nvcSQAAAAJ": "Muhammad Shaban",
    "cEepZOEAAAAJ": "Anna Goldenberg",
    "8YrBnPsAAAAJ": "Sujay Nagaraj",
    "VK4ytuIAAAAJ": "Hang Yin",
    "ELiOV2IAAAAJ": "Kajal Claypool",
    "3ar1DOwAAAAJ": "Yung-Sung Chuang",
    "RSIlobgAAAAJ": "Wei Fang",
    "y8O77DYAAAAJ": "Xixin Wu",
    "dEfp5vQAAAAJ": "Tianhua Zhang",
    "jBvRff0AAAAJ": "Dongyu Zhang",
    "P7LuLZMAAAAJ": "Lauren Oakden-Rayner",
    "95NLzC4AAAAJ": "Lizhou Fan",
    "KpK7n2EAAAAJ": "Brian Anthony MIT",
    "wziaKmQAAAAJ": "Kavin Chandrasekaran",
    "aAe-LN0AAAAJ": "Hamid Mansoor",
    "AkffLRcAAAAJ": "Abdulaziz AlAjaji",
    "xMOPRkQAAAAJ": "Samuel Gehman",
    "n8w3bg8AAAAJ": "Huan He",
    "Ancx9LMAAAAJ": "Bryan R. Christ",
    "wFgLdqUAAAAJ": "Jonathan Kropko",
    "TwifRtcAAAAJ": "Dr. Gregory M. Goldgof MD, PhD",
    "yV_Ws-QAAAAJ": "Alexander Schubert",
    "O50gXqUAAAAJ": "Pedro Moreira",
    "zKaxWRIAAAAJ": "Zachary Gottesman",
    "Efs3XxQAAAAJ": "Jonathan Richard Schwarz",
    "MiI7lj0AAAAJ": "Arinbjörn Kolbeinsson",
    "yFLmPsoAAAAJ": "Tianjin Huang",
    "73IbXtsAAAAJ": "Shiwei Liu",
    "EH4ASmUAAAAJ": "John Boaz Lee",
    "qRp1xZwAAAAJ": "Sihong Xie",
    "gEM0njwAAAAJ": "Dandan Tao",
    "Lyx4TNIAAAAJ": "Ruofan Hu",
    "k1tEBf0AAAAJ": "Hao Feng",
    "KGvc3jwAAAAJ": "Harry Shenghuan Sun",
    "Km0qjY8AAAAJ": "Jackson Pond",
    "dMjagUIAAAAJ": "Nikolaj Munch",
    "0eR4Lt0AAAAJ": "Zach Harned",
    "dy4WeeIAAAAJ": "Lindsay Sanneman",
    "6G8BRLsAAAAJ": "Matthew Lungren",
    "d8pmohMAAAAJ": "Grace Wickerson",
    "jB66t5YAAAAJ": "Elizabeth Bondi-Kelly",
    "IZrh2CkAAAAJ": "Sarah Margaret Goodday, PhD",
    "01Ja8EUAAAAJ": "Sindhu Gowda",
    "LNtKWuIAAAAJ": "Luca Foschini",
    "0iZls38AAAAJ": "Kopal Garg",
    "FkKFiE8AAAAJ": "Maochuan Lu",
    "SIHPQ28AAAAJ": "Eileen Pan",
    "KmHKvzsAAAAJ": "Maanas Kumar Sharma",
    "Mp1C17IAAAAJ": "Shiladitya Dutta",
    "Y04UhM4AAAAJ": "Franny Dean",
    "gfklepYAAAAJ": "Qi Long",
    "D6nN2NcAAAAJ": "Justin F Rousseau",
    "fXxhg5EAAAAJ": "Song  Wang",
    "IwGLficAAAAJ": "Yifan Peng",
    "YC4WABEAAAAJ": "Mengxuan Hu",
    "uztQCmMAAAAJ": "Dongliang Guo",
    "JmzhiYAAAAAJ": "Zihan Guan",
    "DEncVcYAAAAJ": "Sheng Li",
    "peqnQjMAAAAJ": "Derek Powell",
    "gOUeu2IAAAAJ": "Karin Hrovatin",
    "p87Sl34AAAAJ": "Valentina Giunchiglia",
    "uBkIL7YAAAAJ": "Bradley L. Pentelute",
    "WPFAXNAAAAAJ": "George Dasoulas",
    "TLyT0NwAAAAJ": "Ayush Noori",
    "TTnfnugAAAAJ": "Joseph S Brown",
    "vNBuX24AAAAJ": "Yasha Ektefaie",
    "q7Yn0UwAAAAJ": "Robert Calef",
    "vjPJvwYAAAAJ": "Qingsong Wen (文青松)",
    "8xaTRNsAAAAJ": "Haoxin Liu",
    "146OneEAAAAJ": "Zhiyuan Zhao",
    "HTf7H58AAAAJ": "Isha Puri",
    "psuwztYAAAAJ": "Nathan Hoyen Ng",
    "6w3KEiEAAAAJ": "Jorge Mendez-Mendez",
    "Q4j2laYAAAAJ": "Adel Bibi",
    "rVsGTeEAAAAJ": "Bernard Ghanem",
    "GVzdGe8AAAAJ": "Kumail Alhamoud",
    "caAyffEAAAAJ": "Motasem Alfarra",
    "GkkMuvQAAAAJ": "Yasir Ghunaim",
    "COrJW_gAAAAJ": "Yao Su",
    "O0lONMkAAAAJ": "Afsaneh Doryab",
    "yiWlY9IAAAAJ": "Matthew Landers",
    "qfbPQ1YAAAAJ": "Yanyong Zhang",
    "OZDGXgwAAAAJ": "Sana Tonekaboni",
    "6z_XWYcAAAAJ": "Berk Ustun",
    "kXbo1twAAAAJ": "Ruida Zhou",
    "G3OMbFSm858C": "Haitao Mi",
    "LYbs7Q8AAAAJ": "Tao Ge",
    "IrM4gpwAAAAJ": "Xu Ouyang",
    "zMspIjIAAAAJ": "Kaixiong Zhou",
    "tMY31_gAAAAJ": "Dong Yu (俞栋)",
    "AgqvtZkAAAAJ": "Sukwon Yun",
    "Ggy4_UcAAAAJ": "Yanshan Wang, PhD, FAMIA",
    "1cj23VYAAAAJ": "Xinyu Zhao",
    "TqblqYcAAAAJ": "Junfeng Guo",
    "Um_KuoYAAAAJ": "Guangya Wan",
    "-lnWdScAAAAJ": "Stefan Hegselmann",
    "IFINq2QAAAAJ": "Antonio Parziale",
    "a_z5a5wAAAAJ": "Shengpu Tang",
    "E7bRAPkAAAAJ": "Divya Shanmugam",
    "Xy1QFMAAAAAJ": "Mercy Nyamewaa Asiedu, PhD",
    "ADxG8S4AAAAJ": "Serina Y. Chang",
    "Jz_PoUQAAAAJ": "Jacob K Christopher",
    "YdiZoJgAAAAJ": "Brian Bartoldson",
    "SQpJmOgAAAAJ": "Bhavya Kailkhura",
    "EzQhcfwAAAAJ": "Michael Cardei",
    "ASf9Q04AAAAJ": "Ferdinando Fioretto",
    "szP4pC0AAAAJ": "Miriam S. Udler",
    "RBTNWv4AAAAJ": "Xinyue Liu",
    "obgiWfUAAAAJ": "Phudish Prateepamornkul",
    "w_wosd4AAAAJ": "Ava P. Amini",
    "VaaScNkAAAAJ": "Harvineet Singh",
    "n82TkYwAAAAJ": "Xin Dai",
    "YgoU6w0AAAAJ": "Natalie Dullerud",
    "nnK-WMMAAAAJ": "Mercy Asiedu",
    "_Lw8tJ8AAAAJ": "Kyle O'Brien",
    "rEjgIskAAAAJ": "Solon Barocas",
    "0Bi5CMgAAAAJ": "Arvind Narayanan",
    "TD9RhcgAAAAJ": "Omer Reingold",
    "y1bnRg4AAAAJ": "Julius Adebayo",
    "IQ2eTA8AAAAJ": "Lydia T. Liu",
    "n1EE3-8AAAAJ": "Esther Rolf",
    "DZ19008AAAAJ": "Ekaterina Gonina",
    "NcR_PmwAAAAJ": "Luca Belli",
    "F2SAhnQAAAAJ": "Michael C. Muelly",
    "xhKqjpYAAAAJ": "Sarah Dean",
    "TeBmXz4AAAAJ": "Juan Carlos Perdomo",
    "uQZjTq4AAAAJ": "Niki Kilbertus",
    "kq2kOfEAAAAJ": "Afshin Rostamizadeh",
    "sDHHglIAAAAJ": "Rediet Abebe",
    "dDsbkAoAAAAJ": "Guy Rothblum",
    "ZRjM4EgAAAAJ": "Mateo Rojas-Carulla",
    "1zCDX_UAAAAJ": "Giambattista Parascandolo",
    "EJfvPHYAAAAJ": "Frances Ding",
    "asj41ygAAAAJ": "Ira Ktena",
    "wAaJqPYAAAAJ": "Ricardo Dominguez-Olmedo",
    "XW62DrcAAAAJ": "Meena Jagadeesan",
    "9xF7M6wAAAAJ": "Sara Fridovich-Keil",
    "1nLn7pcAAAAJ": "Ritwik Kumar",
    "n5vSK6YAAAAJ": "David Beymer",
    "Ytks8n0AAAAJ": "Tanveer Syeda-Mahmood",
    "aYHq31IAAAAJ": "Florian E. Dorner",
    "AB0CIBAAAAAJ": "Markus Bläser",
    "upz0NPIAAAAJ": "Vivian Y. Nastl",
    "FUSSkq0AAAAJ": "Ali Shirali",
    "FzJ6CXsAAAAJ": "Mila Hardt",
    "YpxRngIAAAAJ": "Joshua Blumenstock",
    "ZTWrzykAAAAJ": "Daniel Björkegren",
    "3-gk0ioAAAAJ": "Oded Regev",
    "yE6LvhMAAAAJ": "Ting Chen",
    "ctk2MhUAAAAJ": "André F. Cruz",
    "GQdnFXQAAAAJ": "Ting Chen",
    "OY1lJEAAAAAJ": "Dr. Tolani A. Britton",
    "GvXDNsYAAAAJ": "Fernanda Viégas",
    "FZOxxvcAAAAJ": "Eric Mazumdar",
    "_hrEN-sAAAAJ": "Guanhua Zhang",
    "rKv_MJ4AAAAJ": "Michael A. Livermore",
    "eFkBvOgAAAAJ": "Jens Frankenreiter",
    "G6txDBYAAAAJ": "Vedant Nanda",
    "cePtsyAAAAAJ": "Gert Smolka",
    "5A0Sg-8AAAAJ": "Claire Y. Cui",
    "NzCaPZsAAAAJ": "Michael D. Howell, MD MPH",
    "ZCN03-cAAAAJ": "Gerardo Flores",
    "s_atrm8AAAAJ": "Rebecca Wexler",
    "fDW6YA0AAAAJ": "Angela Jin",
    "xPSkgtIAAAAJ": "Liam Li",
    "F-ytPfAAAAAJ": "Olawale Salaudeen",
    "nnCmyBoAAAAJ": "Aaron Gonzales",
    "nfLC9S0AAAAJ": "Kristian Lum",
    "nzO_5FMAAAAJ": "Uthaipon Tantipongpipat",
    "PYZ_Xb0AAAAJ": "Kyra Yee",
    "-oESmhEAAAAJ": "Ana-Andreea Stoica",
    "AUuGgYgAAAAJ": "Dorothee Sigg",
    "j7zKTIIAAAAJ": "Jiduan Wu",
    "0AUIC-8AAAAJ": "Mina Remeli",
    "yQ32avUAAAAJ": "Gerardo Flores",
    "aorYJGcAAAAJ": "Alexander Lambert",
    "99RVk_MAAAAJ": "Jing Dong",
    "Nt4rO1EAAAAJ": "Arun Venkatraman",
    "I1IiJCAAAAAJ": "Zhen Liu",
    "uGkQKUIAAAAJ": "Siddarth Srinivasan",
    "NC16W1kAAAAJ": "Brian Goldfain",
    "ACZeu8cAAAAJ": "Grady Williams",
    "gSYxbCYAAAAJ": "Michael C. Yip",
    "Lkrx2SkAAAAJ": "Ahmed H. Qureshi",
    "d8gdZR4AAAAJ": "Brandon Amos",
    "gO-31VYAAAAJ": "Joris Guerin",
    "eiBfCmUAAAAJ": "Olivier GIBARU",
    "nY6P_nwAAAAJ": "Vadim Indelman",
    "xRuVTW4AAAAJ": "Anirudh Vemula",
    "_JjIgGcAAAAJ": "Brian D Ziebart",
    "02FGPmwAAAAJ": "Mathew Monfort",
    "shkKxnQAAAAJ": "Mehrdad Farajtabar",
    "6VJaD6EAAAAJ": "Roberto Capobianco",
    "AtfVA6wAAAAJ": "Ankit Bhatia",
    "O3gezzcAAAAJ": "Artur Dubrawski",
    "IaNhZ9AAAAAJ": "Benjamin Joffe",
    "8sqAOOoAAAAJ": "Reza Azadeh",
    "LAIIfV0AAAAJ": "Jonathan Richard Shewchuk",
    "fArWdfAAAAAJ": "Adam Bargteil",
    "sM41KiAAAAAJ": "Nuttapong Chentanez",
    "4RpscjwAAAAJ": "Bryan Klingner",
    "3oUgDKQAAAAJ": "Tobias Pfaff",
    "3OKn_UYAAAAJ": "Hany Farid",
    "Smr99uEAAAAJ": "Martin Banks",
    "_6SjdyMAAAAJ": "Louis Rosenberg",
    "iHpqfoQAAAAJ": "Huamin Wang",
    "-sGaL8sAAAAJ": "Kris Hauser",
    "uXNnBTUAAAAJ": "Rui Wang",
    "0RiypNsAAAAJ": "Daniel Ritchie",
    "5FrMEXQAAAAJ": "Adam G. Kirk",
    "qoj5YaYAAAAJ": "Cuihua (Cindy) Shen 沈粹华",
    "uHIYS6UAAAAJ": "Eric Kee",
    "TKUlJukAAAAJ": "Abdullah Bulbul",
    "62RXlNoAAAAJ": "Ladislav Kavan",
    "zBdo-BoAAAAJ": "Martin Wicke",
    "hI4XguUAAAAJ": "Bobby Bodenheimer",
    "Mz6M9j0AAAAJ": "Woojong Koh",
    "Xod5HrAAAAAJ": "Robert W. Sumner",
    "6Wo3XX4AAAAJ": "Emily Averill Cooper",
    "piSbEjwAAAAJ": "Tiantian Liu",
    "NyY8ztoAAAAJ": "Victor Zordan",
    "C1H80hoAAAAJ": "Wenjing Pan",
    "y1aC-CMAAAAJ": "Grace A. Bassett",
    "czzhE8wAAAAJ": "Georg Essl",
    "5QC_CV4AAAAJ": "Dalton Omens",
    "AbyxansAAAAJ": "Marc Erich Latoschik",
    "dyD6nsgAAAAJ": "Brandon Huang",
    "vPEmzqYAAAAJ": "Jean Pouliot",
    "bkG57aEAAAAJ": "Doyub Kim",
    "tnimPrsAAAAJ": "Justus Mattern",
    "QGc-TQkAAAAJ": "Jason Cantarella",
    "rgf7oH4AAAAJ": "Dorian Chan",
    "4Vwt9AEAAAAJ": "Gonzalo Munilla Garrido",
    "f7hypjsAAAAJ": "Nikolaos Zioulis",
    "5SUDRqsAAAAJ": "Matt Stanton",
    "Kv2pL8YAAAAJ": "Francois Faure",
    "JscQvlUAAAAJ": "Falk Lieder",
    "ncbyhdMAAAAJ": "Joshua C. Peterson",
    "KS4uI1sAAAAJ": "Christopher G. Lucas",
    "IpkkT5oAAAAJ": "Adam Sanborn",
    "6MfHyuMAAAAJ": "Ilia Sucholutsky",
    "S9xCl8EAAAAJ": "Jordan William Suchow",
    "Jrn-jxQAAAAJ": "Joseph Austerweil",
    "e4peJmoAAAAJ": "Mike Kalish",
    "zLjnC5MAAAAJ": "Joshua T. Abbott",
    "_ZxvlzoAAAAJ": "Sharon Goldwater",
    "4LRxXyIAAAAJ": "Daphna Buchsbaum",
    "fwKsGokAAAAJ": "David D Bourgin",
    "zyR_DF4AAAAJ": "Nori Jacoby",
    "YDLkVDoAAAAJ": "Kevin Canini",
    "FvRFQZ8AAAAJ": "Naomi Feldman",
    "Z_kok3sAAAAJ": "Mark Johnson",
    "MA7j1gkAAAAJ": "Elizabeth Bonawitz",
    "Ajec0lYAAAAJ": "Brian Christian",
    "vfa1cToAAAAJ": "Bas van Opheusden",
    "5_9v0CIAAAAJ": "Simon Kirby",
    "tX0GARYAAAAJ": "Ruairidh McLennan Battleday",
    "_A7rrswAAAAJ": "Stephan Lewandowsky",
    "SkkDQgMAAAAJ": "Michal Rosen-Zvi",
    "0gyS3z0AAAAJ": "Frederic THEUNISSEN",
    "jKcs76MAAAAJ": "Jing Xu",
    "eGgZmPgAAAAJ": "Sebastian Musslick",
    "1Wlj18oAAAAJ": "Sophie Bridgers",
    "JNXWWkIAAAAJ": "Alexander Huth",
    "pa7de7wAAAAJ": "Kenny Smith",
    "_8gD7Y4AAAAJ": "Stephanie Denison",
    "8Qv3HRoAAAAJ": "M Pacer",
    "Ay8t8DEAAAAJ": "Priyam Das",
    "ggLoicQAAAAJ": "Florencia Reali",
    "Amg6a3MAAAAJ": "Amitai Shenhav",
    "9-eaUCMAAAAJ": "Stephan Meylan",
    "Gdow0U4AAAAJ": "Joseph Jay Williams",
    "2dCb2U0AAAAJ": "Anne Hsu",
    "lDzimQIAAAAJ": "Amy Whalen",
    "KjYNz88AAAAJ": "Quentin Huys",
    "LaLilZ8AAAAJ": "Christine Fawcett",
    "UPvWSMYAAAAJ": "Ming Hsu",
    "RlNm1d4AAAAJ": "Matthew Purver",
    "MTmii2YAAAAJ": "Neil Bramley",
    "8TIMnwEAAAAJ": "Wouter Kool",
    "zfCmRZkAAAAJ": "Ronald E Dahl",
    "nHCB2CkAAAAJ": "Takeshi Yamada",
    "gbY_w1IAAAAJ": "Michael Lee",
    "aDKi5l8AAAAJ": "Ghassen Jerfel",
    "c_ssivMAAAAJ": "Dillon Plunkett",
    "tCUvC4oAAAAJ": "Sophia Sanborn",
    "VJODuGkAAAAJ": "Chaitanya Chemudugunta",
    "m2RVgR0AAAAJ": "Peter Sollich",
    "pS-idGwAAAAJ": "Dare Baldwin",
    "WV8GXcsAAAAJ": "Emily Myers",
    "rRcthW0AAAAJ": "Katherine White",
    "gOTxTaoAAAAJ": "Azzurra Ruggeri",
    "TMuSMXoAAAAJ": "Tamar Kushnir",
    "1nBmV3cAAAAJ": "Dawn Chen",
    "7peUPbIAAAAJ": "Saiwing Yeung",
    "07IPOvMAAAAJ": "Alexandre Pouget",
    "nicnuy4AAAAJ": "Richard IVRY",
    "FijpZG8AAAAJ": "Luke Maurits",
    "NBKWzkkAAAAJ": "Elizabeth Seiver",
    "Lkl8nQYAAAAJ": "Jay B. Martin",
    "AMb1WywAAAAJ": "David Lagnado",
    "YRWfuEIAAAAJ": "Alexandra Paxton",
    "s2Y3qnwAAAAJ": "wolf vanpaemel",
    "gY1w14YAAAAJ": "Simon Dennis",
    "DxmHk08AAAAJ": "David Sobel",
    "N9t6-RUAAAAJ": "Michelle LaMar",
    "SB6_-GAAAAAJ": "Marc Ettlinger",
    "QPH_lRIAAAAJ": "Danielle Navarro",
    "1lORpNsAAAAJ": "David Danks",
    "wBMdXsgAAAAJ": "Daniel R. Little",
    "BkTebL0AAAAJ": "Ethan L Schreiber",
    "HHmGYdEAAAAJ": "Sourabh Niyogi",
    "2ftJYXMAAAAJ": "Roy H Campbell",
    "qQMFzBgAAAAJ": "Pooya Khorrami",
    "ktKXDuMAAAAJ": "Prajit Ramachandran",
    "PGZLZFUAAAAJ": "Stephen Tyree",
    "J_1GGJsAAAAJ": "Jason Clemons",
    "PCJJ8LkAAAAJ": "Iuri Frosio",
    "sZrw0v0AAAAJ": "Diamond Bishop",
    "AYpm7KcAAAAJ": "Paris Smaragdis",
    "Rr643xYAAAAJ": "Faraz Faghri",
    "7BM1uyYAAAAJ": "Saurabh Sinha",
    "fT30bHMAAAAJ": "Saeid Akhavan",
    "4Nzf_IcAAAAJ": "Mohammad Hoseyn Sheykholeslam",
    "df3XoJIAAAAJ": "Zahra Zojaji",
    "ETGZXo4AAAAJ": "Shirin Salehi",
    "NTAsObMAAAAJ": "Hedayat Vatankhah",
    "TyfMgeQAAAAJ": "kamal jamshidi",
    "LBEIm8gAAAAJ": "Baifeng Shi",
    "kqVZxpYAAAAJ": "Zhekun Luo",
    "QwL4z2UAAAAJ": "Boyang \"Albert\" Li",
    "Ilx8WNkAAAAJ": "Yancheng Bai",
    "C6kPjgwAAAAJ": "Li, Zhi",
    "AiuGlVQAAAAJ": "Guorong Li",
    "hczHVxEAAAAJ": "Kurt Konolige",
    "DXpZ1lkAAAAJ": "Matthew Kelcey",
    "cGrUZpwAAAAJ": "Stefan Hinterstoisser",
    "izKFQycAAAAJ": "Ali Yahya",
    "JEr3qVwAAAAJ": "Vincent-Pierre Berges",
    "nyicsDgAAAAJ": "Arjun Majumdar",
    "-dCETaQAAAAJ": "Sergio Arnaud",
    "9bt2Z5QAAAAJ": "Tingfan Wu",
    "VsTyEcQAAAAJ": "Karmesh Yadav",
    "6h1O4AMAAAAJ": "Ruslan Partsey",
    "3PJeg1wAAAAJ": "Taosha Fan",
    "27eupmsAAAAJ": "Michael Kaess",
    "pSmh9tkAAAAJ": "Cristian Bodnar",
    "rebEn8oAAAAJ": "Luis Pineda",
    "n6zUuaQAAAAJ": "Ioan Alexandru Sucan",
    "IEPhQd4AAAAJ": "Juan Nunez-Iglesias",
    "Yfo9_boAAAAJ": "Nicolas Hudson",
    "iVavvW8AAAAJ": "Haiyan Huang, Professor",
    "bH1k38AAAAAJ": "Jo-Anne Ting",
    "keDqjK0AAAAJ": "Austin Shih-Ping Wang",
    "JEXV__kAAAAJ": "Benjamin Bolte",
    "bfec5vAAAAAJ": "Torsten Kröger",
    "zQABr7QAAAAJ": "Sehoon Kim",
    "O4_jWCsAAAAJ": "George Biros",
    "mc-_DrEAAAAJ": "Dhairya Malhotra",
    "RId1qZ8AAAAJ": "Christos Davatzikos",
    "j4DDmQ0AAAAJ": "Linjian Ma",
    "LnB5_AcAAAAJ": "Hadi Esmaeilzadeh",
    "jW9ts2cAAAAJ": "Aman Madaan",
    "4Fw2ma4AAAAJ": "Jongse Park",
    "8DKNKhkAAAAJ": "Shrimai Prabhumoye",
    "IqcCDXkAAAAJ": "Nouha Dziri",
    "HmBa_6gAAAAJ": "Divya Mahajan",
    "owcAYmEAAAAJ": "Katherine L. Hermann",
    "Ac6n5pQAAAAJ": "Sean J Welleck",
    "iccBxJIAAAAJ": "Nam Sung Kim",
    "1c7hIUIAAAAJ": "Berkin Akin",
    "WxlqsisAAAAJ": "Hardik Sharma",
    "25HL3QcAAAAJ": "James Laudon",
    "uIQ2vHQAAAAJ": "Prannoy Pilligundla",
    "UZIKgasAAAAJ": "Pejman Lotfi-Kamran",
    "P__ztgcAAAAJ": "Tushar Krishna",
    "yhli360AAAAJ": "Soroush Ghodrati",
    "LiqLdKYAAAAJ": "Milad Hashemi",
    "54KhKdEAAAAJ": "Suvinay Subramanian",
    "avJO4EcAAAAJ": "Kambiz Samadi",
    "mATAz-wAAAAJ": "Ahmed Taha Elthakeb",
    "6d8ODpwAAAAJ": "Sheng-Chun Kao",
    "YuFcRF0AAAAJ": "Prakhar Gupta",
    "YoR3IugAAAAJ": "Sarah Wiegreffe",
    "MYsIXF4AAAAJ": "Todd C. Mowry",
    "ZgqVLuMAAAAJ": "Gennady Pekhimenko",
    "WUCu45YAAAAJ": "Niloofar (Fatemeh) Mireshghallah",
    "ZKEDQXYAAAAJ": "Yanqi Zhou",
    "5JtQbw0AAAAJ": "Doug Burger",
    "52f5kGIAAAAJ": "Shivani Agrawal",
    "S3gQoMgAAAAJ": "Parthasarathy Ranganathan",
    "n1grp7EAAAAJ": "Byung Hoon Ahn",
    "yx0pEmYAAAAJ": "Abbas Rahimi",
    "NSbws80AAAAJ": "Arjang Hassibi",
    "I1w51gUAAAAJ": "Rajesh K. Gupta",
    "CPMS_csAAAAJ": "Kiran Seshadri",
    "6POeyBoAAAAJ": "Mingxing Tan",
    "qXi2lyMAAAAJ": "Kia Bazargan",
    "JI5QYBwAAAAJ": "Anandhavel Nagendrakumar",
    "l6IizNwAAAAJ": "Renee St. Amant",
    "X7a38bAAAAAJ": "Farshad Firouzi",
    "2v1cPRsAAAAJ": "Joon Kyung Kim",
    "zMKzi8kAAAAJ": "Emmanuel Amaro",
    "mfk62y8AAAAJ": "Vahideh Akhlaghi",
    "H8yqlRYAAAAJ": "Mingu Kang",
    "gy4UVGcAAAAJ": "Vijay Janapa Reddi",
    "OXZC0mQAAAAJ": "Christof Angermueller",
    "DCP9rQgAAAAJ": "Michael Brzozowski",
    "XK7HXzMAAAAJ": "Ali Azarpeyvand",
    "dio8IesAAAAJ": "Yingyan (Celine) Lin",
    "cyfI_XQAAAAJ": "Mehdi Kamal",
    "wE5ee_kAAAAJ": "Saeed Safari",
    "17TY2TMAAAAJ": "Bradley T. Kiddie",
    "9R7Gl8YAAAAJ": "Jonathan Ahlbin",
    "f3V6gZMAAAAJ": "Maryam Mehri Dehnavi",
    "JrBgRKUAAAAJ": "Ali Afzali-Kusha",
    "FHiQmOoAAAAJ": "Massoud Pedram",
    "O0W9jEQAAAAJ": "Karthikeyan Sankaralingam",
    "1hLMcNsAAAAJ": "Tony Nowatzki",
    "nBcay4oAAAAJ": "Jonathan Ragan-Kelley",
    "7tr3iQkAAAAJ": "Mikko Lipasti",
    "JgO4NqIAAAAJ": "Hamid Noori",
    "2O3IZlkAAAAJ": "Gabriel Goh",
    "eC3VWhAAAAAJ": "Rewon Child",
    "fzLxuAIAAAAJ": "Pamela Mishkin",
    "QJ9ThJ0AAAAJ": "Girish Sastry",
    "TKvd_Z4AAAAJ": "Kai Chen",
    "8UZIqcoAAAAJ": "Sandhini Agarwal",
    "5fU-QMwAAAAJ": "Mark Chen",
    "astFxkwAAAAJ": "Gretchen Krueger",
    "LlK_saMAAAAJ": "James Martens",
    "MoX2ERkAAAAJ": "Jong Wook Kim",
    "0kVh58wAAAAJ": "Laurent Sifre",
    "bnQMuzgAAAAJ": "Christian Szegedy",
    "cItVg2MAAAAJ": "David Luan",
    "EemUE4gAAAAJ": "Zhifeng Chen",
    "iyD9aw8AAAAJ": "Arthur Guez",
    "AQzIwI4AAAAJ": "Tao Xu",
    "LFyg0tAAAAAJ": "Nal Kalchbrenner",
    "yNNIKJsAAAAJ": "Sander Dieleman",
    "7Ma_PNAAAAAJ": "Aja Huang",
    "V358UyMAAAAJ": "Michael Isard",
    "0KF6ZC8AAAAJ": "Sanjay Ghemawat",
    "yp4Gk3kAAAAJ": "Vijay Vasudevan",
    "9700p4IAAAAJ": "Derek G. Murray",
    "q34R9psAAAAJ": "Paul Barham",
    "Jjp8eYUAAAAJ": "Manjunath Kudlur",
    "W8yZCNsAAAAJ": "Rajat Monga",
    "rT11mdcAAAAJ": "Benoit Steiner",
    "TrdtzgwAAAAJ": "Geoffrey Irving",
    "TAomEzQAAAAJ": "Pranav Shyam",
    "PNH24toAAAAJ": "Thore Graepel",
    "x2PfbDEAAAAJ": "Dominik Grewe",
    "1KvNUWgAAAAJ": "Vedavyas Panneershelvam",
    "AiH3_CkAAAAJ": "Julian Schrittwieser",
    "Br8UEzAAAAAJ": "Filip Wolski",
    "xQAoHP0AAAAJ": "Jonathan Raiman",
    "SgbbTp4AAAAJ": "Christopher Hesse",
    "2FmzuDMAAAAJ": "Michael Petrov",
    "HbChXx0AAAAJ": "Susan Zhang",
    "SAW3KDUAAAAJ": "Mikhail Pavlov",
    "ygTCc6cAAAAJ": "Arvind Neelakantan",
    "lEV5F5kAAAAJ": "Bradly Stadie",
    "UFsTIAEAAAAJ": "Chelsea Sierra Voss",
    "bMfPYdYAAAAJ": "Bowen Baker",
    "kmUgTboAAAAJ": "Christopher Berner",
    "r6mBY50AAAAJ": "Leo Gao",
    "wldNQHoAAAAJ": "Vineet Kosaraju",
    "stCljMYAAAAJ": "Karl Cobbe",
    "S5x4xYUAAAAJ": "Teddy Lee",
    "ZbClz98AAAAJ": "Will Grathwohl",
    "7MxQd6UAAAAJ": "Ricky Tian Qi Chen",
    "hHPeXmYAAAAJ": "Trapit Bansal",
    "-ZpM8jUAAAAJ": "Stanislas Polu",
    "oD_Ea7EAAAAJ": "Karol Kurach",
    "uj1OljkAAAAJ": "Yamini Bansal",
    "xWrOthYAAAAJ": "Luke Vilnis",
    "_N2COeAAAAAJ": "Igor Babuschkin",
    "x7iwG1UAAAAJ": "Jesse Michael Han",
    "iUe4TdgAAAAJ": "Maruan Al-Shedivat",
    "ebBgMSkAAAAJ": "David Sussillo",
    "wjkaNgcAAAAJ": "Jack Clark",
    "aQmpeAEAAAAJ": "Stefan Kombrink",
    "zDy4jSYAAAAJ": "Kunhao Zheng",
    "YGGcq5EAAAAJ": "Tijmen Tieleman",
    "VTe4SGUAAAAJ": "Daniel Huang",
    "RnoIxUwAAAAJ": "Vinod Nair",
    "8xSYX9IAAAAJ": "Dieterich Lawson",
    "dYpPMQEAAAAJ": "Demis Hassabis",
    "ghfkSasAAAAJ": "Anish Athalye",
    "1TTFBEkAAAAJ": "Ivo Danihelka",
    "UJb3uKgAAAAJ": "Craig Citro",
    "aPNDep0AAAAJ": "Oguz Selvitopi",
    "uIpPgJEAAAAJ": "John Owens",
    "B8bCdHsAAAAJ": "Evangelos Georganas",
    "5f3dXLkAAAAJ": "Jose Moreira",
    "WIk2v1QAAAAJ": "Scott McMillan",
    "ag_2UqcAAAAJ": "Steven Hofmeyr",
    "EtGdFOMAAAAJ": "Benjamin Brock",
    "UZLC4TYAAAAJ": "Giulia Guidi",
    "cjr90bEAAAAJ": "Henning Meyerhenke",
    "3bL-H00AAAAJ": "Georgios A. Pavlopoulos",
    "0FuZRPYAAAAJ": "Nikos C Kyrpides",
    "wTppKvQAAAAJ": "Alok Tripathy",
    "C4QFdvAAAAAJ": "Grey Ballard",
    "uwrwLJcAAAAJ": "Oded Schwartz",
    "RuDNWj8AAAAJ": "Md Taufique Hussain",
    "eH-qW3gAAAAJ": "Simon Roux",
    "Dk0fJHIAAAAJ": "Dmitriy Morozov",
    "z_1mfIkAAAAJ": "Christos Α. Ouzounis",
    "0xWltyAAAAAJ": "Peter Sanders",
    "QYesEdIAAAAJ": "Ilya Safro",
    "SZ_vC90AAAAJ": "Christian Schulz",
    "3ZLk60QAAAAJ": "Muaaz Gul Awan",
    "_Fah5fwAAAAJ": "Alex Pothen",
    "nRKhCa8AAAAJ": "Robert Riley",
    "w19KkekAAAAJ": "Saliya Ekanayake, Ph.D.",
    "_z-DXRIAAAAJ": "Penporn Koanantakool",
    "WNSPregAAAAJ": "Scott Beamer",
    "CfLHDYgAAAAJ": "Hasan Metin Aktulga",
    "kFXm6DQAAAAJ": "Chao Yang",
    "YmXg5xMAAAAJ": "Yuxin Chen",
    "EWi-CL4AAAAJ": "Nan Ding",
    "ZcguQt4AAAAJ": "Helen Xu",
    "vP2to0MAAAAJ": "Brian J. Wheatman",
    "N4XAItcAAAAJ": "Adam Session",
    "7XBJiZsAAAAJ": "Yusuke Nagasaka",
    "UcWOl8YAAAAJ": "Satoshi Matsuoka",
    "29qQmWIAAAAJ": "Fotis Baltoumas",
    "tQU8xu0AAAAJ": "Antonio Pedro Camargo",
    "1z6dv-MAAAAJ": "Sang-Yun Oh",
    "qIfpDL0AAAAJ": "Glenn Merlino",
    "dCheWDEAAAAJ": "Edgar Solomonik",
    "0cKXP7cAAAAJ": "Vivek Bharadwaj",
    "VO62HkEAAAAJ": "Prashant Pandey",
    "1sB4m_wAAAAJ": "Emiley Eloe-Fadrosh",
    "dfsJMOYAAAAJ": "Israt Nisa",
    "ilbKQMYAAAAJ": "Johannes Langguth",
    "VIu8KZfWuM0C": "Axel Visel",
    "Hz4oXAYAAAAJ": "Jennifer Pett-Ridge",
    "1ZT-nZEAAAAJ": "Peter Jin",
    "6UIvmp4AAAAJ": "Chaitanya Aluru",
    "9KRGFbYAAAAJ": "Riley Murray",
    "BMFlkT8AAAAJ": "Alex Copeland",
    "Lum6DhoAAAAJ": "Alicia Clum",
    "7HoFN1wAAAAJ": "Aditi Krishnapriyan",
    "C9sg_B8AAAAJ": "Alberto Zeni",
    "TGDrPLOkJIIC": "Hang Liu",
    "u_H-BTQAAAAJ": "Mathias Jacquelin",
    "s1IzhYMAAAAJ": "Arif Khan",
    "P2Joz5sAAAAJ": "Seher Acer Ellis",
    "5vUydbcAAAAJ": "Ananth Kalyanaraman",
    "5X5c8OkAAAAJ": "Sayan Ghosh",
    "qTnlYokAAAAJ": "Muhammad Osama",
    "WAleKq0AAAAJ": "Osman Asif Malik",
    "im_BJdIAAAAJ": "Nicolas (Nick) Swenson",
    "09bl0GIAAAAJ": "Naw Safrin Sattar",
    "_DSRMYIAAAAJ": "Shaikh Arifuzzaman",
    "B88-PigAAAAJ": "Khaled Z Ibrahim",
    "heSjtpgAAAAJ": "Yu-Hang Tang",
    "WsRIDokAAAAJ": "Marco Minutoli",
    "zg9zDcsAAAAJ": "Zoran Budimlic",
    "9vMpR9UAAAAJ": "Max Xiaohang Zhao",
    "GYUuR_sAAAAJ": "Luk Burchard",
    "EpdF_GQAAAAJ": "Srđan Milaković",
    "cQ5w0L0AAAAJ": "Gabriel Raulet",
    "yzcxu7oAAAAJ": "Lorenzo Di Tucci",
    "f8ByXgEAAAAJ": "Francesco Peverelli",
    "57QIaiQAAAAJ": "Jiakun Yan",
    "_Wb6s7cAAAAJ": "Jeremy T. Fineman",
    "BXGfZq4AAAAJ": "Carl Yang",
    "Ou5x9LkAAAAJ": "Andre Seyfarth",
    "8HYQ1tgAAAAJ": "Dieter Büchler",
    "i_X02A0AAAAJ": "Rongguang Wang",
    "wCa6nygAAAAJ": "Rahul Ramesh",
    "kZQQFE4AAAAJ": "Rohit Jena",
    "MIjWr_8AAAAJ": "James Gee",
    "WXOaxKMAAAAJ": "Aston Zhang",
    "Mo8VdkoAAAAJ": "Rubing Yang",
    "IyoEsBQAAAAJ": "Igor Spasojevic",
    "HeVcLzAAAAAJ": "Jonas Mueller",
    "646vnpUAAAAJ": "Guneet Singh Dhillon",
    "MpdsJF0AAAAJ": "Yifei Simon Shao",
    "DIKwHRsAAAAJ": "Jialin Mao",
    "Qyk0paAAAAAJ": "Christopher D. Hsu",
    "Pd4pbaAAAAAJ": "Dexter Ong",
    "PMh2ysEAAAAJ": "Ankit Prabhu",
    "qxMVu4cAAAAJ": "Yansong Gao",
    "H4sNIhwAAAAJ": "Yuwei Wu",
    "7IwA14gAAAAJ": "Yuezhan Tao",
    "YtfPZDAAAAAJ": "Mark Transtrum",
    "a3Uhp58AAAAJ": "Itay Griniasty",
    "W8BMhsgAAAAJ": "James Sethna",
    "bOElZi8AAAAJ": "Paulo Tabuada",
    "jTluf5cAAAAJ": "Siming He",
    "umAny5UAAAAJ": "Yao Liu",
    "dSIEUlEAAAAJ": "Xu Liu",
    "VBNFtRkAAAAJ": "Jiuzhou Lei",
    "eh9yS-QAAAAJ": "Jana Tumova",
    "m5dFh6YAAAAJ": "Luis Ignacio Reyes Castro",
    "PmrXZ8oAAAAJ": "Teoh Han Kheng",
    "odQWZoEAAAAJ": "P. Corey Green",
    "pjPtYgEAAAAJ": "Tian Yu Liu",
    "I0nj-TcAAAAJ": "Nick Erickson",
    "ltj3BwwAAAAJ": "Vijay Balasubramanian",
    "yWJ9BqEAAAAJ": "Huzefa Rangwala",
    "ElqwScwAAAAJ": "George Karypis",
    "fgRMGc4AAAAJ": "Ian Barnett",
    "IVxQvz0AAAAJ": "Zhihong Pan",
    "jd1S28YAAAAJ": "Xin Zhou",
    "5kvESDsAAAAJ": "Fernando Cladera",
    "JiW8z50AAAAJ": "Manfred Morari",
    "5weaWuMAAAAJ": "Achin Jain",
    "7bgABaoAAAAJ": "Gian Antonio Susto",
    "n7Rh7mgAAAAJ": "Heejin Jeong",
    "Cy_VZ3QAAAAJ": "Keshava Katti",
    "RNiP4hsAAAAJ": "Guray Erus",
    "-2qyBJEAAAAJ": "Kavosh Asadi",
    "DWPfdT4AAAAJ": "Joshua T. Vogelstein",
    "xqhwEGIAAAAJ": "Ashwin De Silva",
    "dGKi9Q4AAAAJ": "Eugenio Piasini",
    "hPhvZI0AAAAJ": "Spyridon Bakas",
    "IO8BmHUAAAAJ": "Lyra Zhornyak",
    "uvZ63bMAAAAJ": "Vivek P. Buch, MD",
    "3t2upi8AAAAJ": "Nehal Doiphode",
    "JbBpeE0AAAAJ": "Michael Otte",
    "d1O4KssAAAAJ": "Minghui Zhu",
    "MM4XdKsAAAAJ": "Reza Ehsani",
    "c7hk0RwAAAAJ": "Fanyang Yu",
    "E2kpqtkAAAAJ": "Karl Schmeckpeper",
    "9sqduWYAAAAJ": "Wenbo Zhang",
    "pJ8vEo8AAAAJ": "Valerio Varricchio",
    "dkSYtIIAAAAJ": "Shiyun Xu",
    "13Puu8AAAAAJ": "Ke Yang",
    "dsb5VjkAAAAJ": "Sapana Chaudhary",
    "ApKpgeMAAAAJ": "Ronald W. Di Tullio",
    "zvBNFb0AAAAJ": "Varun Murali",
    "1OwERREAAAAJ": "Matteo Terzi",
    "9cCaIAwAAAAJ": "Laura Jarin-Lipschitz",
    "1NQRXHQAAAAJ": "Nadia Figueroa",
    "P7nTj5EAAAAJ": "Deeksha Sethi",
    "clTVC4UAAAAJ": "Carey E. Priebe",
    "DwTxLXAAAAAJ": "Rita Fioresi",
    "lL5jPysAAAAJ": "Sarthak Pati",
    "RohTif4AAAAJ": "Despina Kontos",
    "FQn7YigAAAAJ": "Ramya Muthukrishnan",
    "X11hfvIAAAAJ": "Jieren Deng",
    "7PC01c0AAAAJ": "Haoran Tang",
    "EP_omZQAAAAJ": "Derek Cheng",
    "DFwje0AAAAAJ": "Haochang Shou",
    "FN3Lb2gAAAAJ": "Vishnu Bashyam",
    "A4-oSJIAAAAJ": "Vasiliki Tassopoulou",
    "CdJ2xRIAAAAJ": "Zhijian Yang",
    "HR0uwyIAAAAJ": "Dinesh D. Thakur",
    "7R_id0YAAAAJ": "Ty Nguyen",
    "q1G89okAAAAJ": "Ian Dennis Miller",
    "fbvYwZcAAAAJ": "Arjun Guru",
    "Sp6mXKsAAAAJ": "Avraham Cohen",
    "o-kMCtAAAAAJ": "Joshua Gold",
    "kroHjvEAAAAJ": "Shuze Liu",
    "ZTRGztgAAAAJ": "Le Kang",
    "qPMJxq0AAAAJ": "Yale Cohen",
    "p2az0gkAAAAJ": "Tianyu Li",
    "QcsE_ZYAAAAJ": "Shafagh Keyvanian",
    "STHWcmIAAAAJ": "Yunfei He",
    "u1CHA2sAAAAJ": "Deep Jariwala",
    "v5F-I34AAAAJ": "Santosh Kurinec",
    "rZtxlqAAAAAJ": "Paul Jacob",
    "a068aTEAAAAJ": "Marco Maggipinto",
    "2uJEkY4AAAAJ": "Sai Spandana Chintapalli",
    "IfqsDyYAAAAJ": "Siliang Zeng",
    "M-X3Q-UAAAAJ": "Zhepeng Cen",
    "u3ogi00AAAAJ": "Michele Donini",
    "x7b5TJMAAAAJ": "Daiwei Chen",
    "_ZAnS78AAAAJ": "Anthony Bisulco",
    "CcLMQagAAAAJ": "Mehrad Mortazavi",
    "NC1KaRwAAAAJ": "Yan Sun",
    "_S7LGEEAAAAJ": "Hamed Akbari, MD, PhD",
    "3s52I10AAAAJ": "MacLean Pancoast Nasrallah",
    "LyQ0SoMAAAAJ": "Steven Brem",
    "bOnw_44AAAAJ": "Anahita Fathi Kazerooni",
    "kfdwrbYAAAAJ": "Donald M. O'Rourke",
    "do7yT8MAAAAJ": "Zev A. Binder",
    "eF34OvgAAAAJ": "Elizabeth Mamourian",
    "W6bign0AAAAJ": "Erik Toorens",
    "ENIyTF8AAAAJ": "John C. Greenwood, MD, MS",
    "rxg0zB4AAAAJ": "Yifan Wu",
    "idC8YcsAAAAJ": "Leonard Kleinrock",
    "O8CIQXcAAAAJ": "Jiahe Yan",
    "t3mQx_kAAAAJ": "Nitant Rai",
    "nfWGSK0AAAAJ": "Siyu Yu",
    "22DYUdgAAAAJ": "Alok N. Shah",
    "1x2nwykAAAAJ": "Rahim Rizi",
    "GtxZI1MAAAAJ": "Hooman Hamedani",
    "vJJFv3YAAAAJ": "Federico Sertic",
    "6hHbBwwAAAAJ": "Tianyu Liu",
    "qYYPst0AAAAJ": "Derek Zhiyuan Cheng",
    "k-DMEhAAAAAJ": "Jun Guo",
    "bjNCUt8AAAAJ": "Huanrui Yang",
    "aUdg4P0AAAAJ": "Yaohui Cai",
    "mimrFAMAAAAJ": "Jinfeng Kang",
    "DUNGEAIAAAAJ": "Peng Huang",
    "5KZ-7BAAAAAJ": "Qijing Jenny Huang",
    "pcLld3wAAAAJ": "Zheng Zhou",
    "hdnpRKsAAAAJ": "John WAWRZYNEK",
    "GLSQo5gAAAAJ": "Runze Han",
    "NZmIA9oAAAAJ": "Leyuan Wang",
    "eOLxyqUAAAAJ": "Long Lian",
    "m3f70oYAAAAJ": "Guangyu Sun",
    "bdwy3iIAAAAJ": "Hayden Kwok-Hay So",
    "6fqNXooAAAAJ": "Rex (Zhitao) Ying",
    "j8JGVvoAAAAJ": "Yu Wang (汪玉)",
    "HWxGEesAAAAJ": "H.-S. Philip Wong",
    "0zX2pcwAAAAJ": "Haitong Li",
    "FXNJRDoAAAAJ": "Alexey Dosovitskiy",
    "DLVP3PcAAAAJ": "Shaojie Bai",
    "_3q6KBIAAAAJ": "Jaesik Park",
    "6hB2vJUAAAAJ": "Stephan R. Richter",
    "NamIygIAAAAJ": "Felipe Codevilla",
    "ZWC33cYAAAAJ": "Elia Kaufmann",
    "X-VK_5EAAAAJ": "Chen Chen",
    "uDFb6OcAAAAJ": "German Ros",
    "ndOMZXMAAAAJ": "Jakob Engel",
    "3Q5zpJwAAAAJ": "Jack M. Wang",
    "OwT_8sQAAAAJ": "Sohil Atul Shah",
    "2BNtbXMAAAAJ": "Martin Bokeloh",
    "GGcjtCsAAAAJ": "Abhijit Kundu",
    "gb2r2ssAAAAJ": "Alfred Aho",
    "YTQnGJsAAAAJ": "Kun He",
    "TM6oPEUAAAAJ": "Steven Fortune",
    "VIFfuYgAAAAJ": "Allan Borodin",
    "W6gQqWcAAAAJ": "Jelani Nelson",
    "kALYnggAAAAJ": "Shay Moran",
    "DLiKRkgAAAAJ": "Vladimir Nikishkin",
    "EnEiF7oAAAAJ": "Richard Ryan Williams",
    "YHSRCCsAAAAJ": "Scott Duke Kominers",
    "K6-JprYAAAAJ": "He Sun",
    "cF2lHxgAAAAJ": "John Iacono",
    "B7ngg6QAAAAJ": "Andrew Spann",
    "7dQo6WcAAAAJ": "Joseph Palmer",
    "g2nxKt0AAAAJ": "Bakir Farhi",
    "TFx_gLQAAAAJ": "Terence Tao",
    "yKGD9ggAAAAJ": "Robert J. Lemke Oliver",
    "i2OSovEAAAAJ": "Cesar E. Silva",
    "ytQV4UcAAAAJ": "Jonathan M. Kane",
    "rb6gXycAAAAJ": "Frank Sifei Luan",
    "wRw-e8EAAAAJ": "Hossein Falaki",
    "daYjNkAAAAAJ": "Paul Vernaza",
    "qR4O45oAAAAJ": "Jianren Wang",
    "-1iyBukAAAAJ": "Gaoyue Zhou",
    "wwW4HRQAAAAJ": "Homanga Bharadhwaj",
    "KNQoLcMAAAAJ": "Alex Kuefler",
    "O3jMNPkAAAAJ": "Michelle Li",
    "On-ONT4AAAAJ": "Jiaqi Guan",
    "p9zVBV4AAAAJ": "Eshed Ohn-Bar",
    "U_R0PWEAAAAJ": "Yan Xu",
    "vbhA9hwAAAAJ": "David D. Fan",
    "6zXsZtEAAAAJ": "Henry A Leopold",
    "Vf0BonwAAAAJ": "Daniel Shin",
    "NACSmGwAAAAJ": "Samyak Parajuli",
    "bBFN_qwAAAAJ": "Arnaud Fickinger",
    "N_vPIhoAAAAJ": "Timothy D Barfoot",
    "stQ_JksAAAAJ": "Hugues THOMAS",
    "Q8yp6zQAAAAJ": "Anqi (Angie) Liu",
    "qzLr75IAAAAJ": "Sunggoo Jung",
    "Dxiw1K8AAAAJ": "Shengbo Eben Li（李升波）",
    "vQ1dKQwAAAAJ": "Wenshuo Wang",
    "HK4x3fkAAAAJ": "Yao (Mark) Mu",
    "x58fnLQAAAAJ": "Keqiang Li",
    "23sOkXYAAAAJ": "Pingping Zhu",
    "7y6i1SQAAAAJ": "Silvia Ferrari",
    "hNy1aBgAAAAJ": "SEUNGHO LEE",
    "UWnwlu4AAAAJ": "H. Eric Tseng",
    "WQnQm0IAAAAJ": "Viktor Rausch",
    "ho3H9IsAAAAJ": "Guofa Li",
    "5mUoFN0AAAAJ": "Jianqiang Wang(王建强)",
    "NqkgsjoAAAAJ": "Donghan Lee",
    "EuCFFwYAAAAJ": "Sarthak Misra",
    "LWmEzL0AAAAJ": "Nathan Michael",
    "JtHZL24AAAAJ": "Jessica Burgner-Kahrs",
    "fxYQWPAAAAAJ": "Robert J. Webster III",
    "Yw2PquQAAAAJ": "Petros Drineas",
    "FoDWxx8AAAAJ": "Fred Roosta",
    "plJC8R0AAAAJ": "Anirban Dasgupta",
    "K-SafJUAAAAJ": "Kimon Fountoulakis",
    "9vAv0c4AAAAJ": "Christos Boutsidis",
    "KVPQoQgAAAAJ": "Haim Avron",
    "xCJ8lboAAAAJ": "Ping Ma",
    "dT7yOrwAAAAJ": "Lorenzo Orecchia",
    "0dIBL4AAAAAJ": "Peristera Paschou",
    "hSyfNekAAAAJ": "Mason Porter",
    "Ao-FJHwAAAAJ": "Aditya Devarakonda",
    "vCuk0SQAAAAJ": "Elad Ziv",
    "SPUjpAwAAAAJ": "Lek-Heng Lim",
    "7C7SiMEAAAAJ": "Istvan Csabai",
    "p_Ua-sIAAAAJ": "Eric Darve",
    "WgSVkNwAAAAJ": "Yingzhou Li",
    "hlEPkxAAAAAJ": "Wei Chen （陈 卫）",
    "PVcaULkAAAAJ": "Guangda Hu",
    "i4ahyPMAAAAJ": "Ben Bowen",
    "5M5nkGAAAAAJ": "Oliver Rübel",
    "MzauO7cAAAAJ": "Jaeyoung Choi",
    "kCxHiwUAAAAJ": "Quanfu Fan",
    "N0Rq-XAAAAAJ": "Tsunehiro Aki",
    "wKjXRn0AAAAJ": "DANIEL B. SZYLD",
    "GFvVRzwAAAAJ": "Mihai Cucuringu",
    "kllQz-YAAAAJ": "László Dobos",
    "OZlvV6kAAAAJ": "Hariharan Narayanan",
    "hlO3qqkAAAAJ": "Asif Javed",
    "JyABkTwAAAAJ": "Patrick O Perry",
    "WhMzaJwAAAAJ": "Efstratios Gallopoulos",
    "1e6XV-YAAAAJ": "Oscar Hernandez",
    "O_PbKNMAAAAJ": "Chenran Li",
    "Yk3s7HUAAAAJ": "Ce Hao",
    "9oDqFwkAAAAJ": "Qingbin Zheng",
    "jcewpCIAAAAJ": "Xi Shen",
    "4ME93EEAAAAJ": "Jang-Kyo Kim",
    "jfu5EP4AAAAJ": "Xiaohan Du",
    "RpqvaTUAAAAJ": "Chenfeng Xu",
    "Uxb6wbkAAAAJ": "Lingfeng Sun",
    "hfqXASoAAAAJ": "Kenta Kawamoto",
    "2F8T0yAAAAAJ": "Jiaheng Hu",
    "uOIgTt8AAAAJ": "Rohan Chandra",
    "OYZrsIQAAAAJ": "Sujitha Martin",
    "Rcjr4UYAAAAJ": "Ángel Cuenca",
    "FUEBroEAAAAJ": "Julian Salt",
    "SNTbGfIAAAAJ": "Tian Li",
    "Jd2A44wAAAAJ": "Yiheng Li",
    "w5T0phcAAAAJ": "Nishan Srishankar",
    "BitIg-YAAAAJ": "Liting Sun",
    "iSFDVj4AAAAJ": "Chiho Choi",
    "QIZZA0oAAAAJ": "Enna Sachdeva",
    "7yn5-VEAAAAJ": "Yaru Niu",
    "4LAT5WYAAAAJ": "Teruhisa Misu",
    "fb-yr1YAAAAJ": "Haonan Chang",
    "vvzAfOwAAAAJ": "Changliu Liu",
    "uggA5n4AAAAJ": "Yeping Hu",
    "EzoDsIMAAAAJ": "Yuxin Chen",
    "A_x6bjQAAAAJ": "Julian M. Salt Ducaju",
    "0rFlyFgAAAAJ": "CONG ZHAO",
    "2IzviGMAAAAJ": "Yi-Kuen Lee",
    "C5D_E04AAAAJ": "Shaoshu Su",
    "Ksm6fEUAAAAJ": "Adam S. Smith",
    "gI5FMw8AAAAJ": "Ariel Kapusta",
    "xkLdn4gAAAAJ": "Kristin Siu",
    "8F1GBF4AAAAJ": "Sohrab Madani",
    "AzcmAtgAAAAJ": "Junfeng Guan",
    "lx-5mjUAAAAJ": "Matthew Chang",
    "qrqim7kAAAAJ": "Arjun Gupta",
    "YzxIuqwAAAAJ": "Dhiraj Gandhi",
    "r5mA7Q8AAAAJ": "Peter Anderson",
    "N0Lv5FUAAAAJ": "Suraj Jog",
    "qXTt3dUAAAAJ": "Aditya Nori",
    "UhDW6jkAAAAJ": "Rahul Sharma",
    "Te3H6mMAAAAJ": "Chunhui Gu",
    "d9s3sbQAAAAJ": "Hao Cheng",
    "EZdKx4IAAAAJ": "Sahil Modi",
    "Oj-2ZNEAAAAJ": "Ashish Kumar",
    "d3rRkqcAAAAJ": "Helen Jiang",
    "wTGk7TIAAAAJ": "Varun Tolani",
    "DUgsNccAAAAJ": "Aditya Prakash",
    "lAiZXhYAAAAJ": "Andres Eduardo Baquero Velasquez",
    "pf2zAXkAAAAJ": "Girish Chowdhary",
    "peIOOn8AAAAJ": "Arun Narenthiran Sivakumar",
    "UbtCA90AAAAJ": "Mateus Valverde Gasparino",
    "h-EphF0AAAAJ": "Waleed Ahmed",
    "kI2nR5gAAAAJ": "Ruisen Tu",
    "M7S3soEAAAAJ": "Mohit Goyal",
    "O8ALPlkAAAAJ": "Michael J. Tarr",
    "IDItm6cAAAAJ": "Paul Schydlo",
    "iILS6kQAAAAJ": "Zhongzheng (Jason) Ren",
    "jXfleiEAAAAJ": "Xiaoyu Zhang",
    "RBwpd88AAAAJ": "Silvery Fu",
    "vh9KxEIAAAAJ": "Ravi Teja Mullapudi",
    "Z8-UfkUAAAAJ": "William Qi",
    "UuwugFEAAAAJ": "Yang Zhou",
    "MgppzFwAAAAJ": "Yiduo Hao",
    "-SWUwoIAAAAJ": "João Ramos",
    "MbsEFrYAAAAJ": "DONGHOON BAEK",
    "T3Tt0S8AAAAJ": "Senthil Purushwalkam",
    "HxJTHvMAAAAJ": "Berk Calli",
    "ozaKHIIAAAAJ": "Abitha Thankaraj",
    "tMrZjn0AAAAJ": "Karanbir Singh Chahal",
    "-9Y7xbAAAAAJ": "Matthew Jin",
    "9HRLi20AAAAJ": "Samuel Grayson",
    "fDtoo50AAAAJ": "Muhammad Huzaifa",
    "5m-oAesAAAAJ": "Sarita Adve",
    "S21bOvsAAAAJ": "Aditi Partap",
    "0qUErHAAAAAJ": "Rishik Sathua",
    "QNRj_g8AAAAJ": "Nie (Elon) Lin",
    "xNxlvjEAAAAJ": "Jiajun Liang",
    "3TggrEkAAAAJ": "Hyung Jin Chang",
    "gI55gF0AAAAJ": "Linlin Yang",
    "WNIxd2UAAAAJ": "Takehiko Ohkawa",
    "ZQFp_3MAAAAJ": "Jeongwan On",
    "VEUW-qIAAAAJ": "Yoichi Sato",
    "Mz1fab8AAAAJ": "Seungryul Baek",
    "ryoyucAAAAAJ": "Karim Abou Zeid",
    "oPV20eMAAAAJ": "Xuanyang Zhang",
    "jZXvcOsAAAAJ": "Zicong Fan",
    "-epU9OsAAAAJ": "Otmar Hilliges",
    "z2SoXI8AAAAJ": "Runpei Dong",
    "dVswVTEAAAAJ": "Youngwoo Sim",
    "LcOIFHEAAAAJ": "Amartya Purushottam",
    "KIgj3WQAAAAJ": "Laura Dodds",
    "ygQznUQAAAAJ": "Hao Zhao",
    "-XWZKZAAAAAJ": "Hanxiao Jiang",
    "9OdMvbAAAAAJ": "Boyuan Chen",
    "MS1P6hcAAAAJ": "Samah Hussein",
    "JSv1FOYAAAAJ": "Bo Peng",
    "kc-qetAAAAAJ": "Sohrab Madani",
    "PF-RPpEfa-0C": "yang zhou",
    "kWAlOAkAAAAJ": "Mukul Khanna",
    "22oxVYkAAAAJ": "Sriram Yenamandra",
    "dkRTvvcAAAAJ": "So Yeon (Tiffany) Min",
    "-o8kQPwAAAAJ": "Theophile Gervet",
    "j6bKU_kAAAAJ": "Anita Chary",
    "oeuqAuQAAAAJ": "Margaret Samuels-Kalow",
    "zkc9pukAAAAJ": "Carlos A Camargo, Jr",
    "skcZ-JwAAAAJ": "Sherri-Ann M. Burnett-Bowie",
    "02hyl6AAAAAJ": "Hamid Shokoohi,MD MPH FACEP",
    "jdSlREMAAAAJ": "Dezhen Song",
    "XmLMNyUAAAAJ": "Mark Faridani",
    "V6LJpwgAAAAJ": "Noah J. Cowan",
    "qoIuyMoAAAAJ": "Gregory Chirikjian",
    "UtmQJt8AAAAJ": "Kyle Reed",
    "HdEjj2MAAAAJ": "Michael Peshkin",
    "K__JmtcAAAAJ": "Eric Paulos",
    "TkayRqQAAAAJ": "Bruce Donald",
    "sLXafasAAAAJ": "Mark Moll",
    "NpccCXwAAAAJ": "Philippe Cudre-Mauroux",
    "_KxkI6UAAAAJ": "Gabor Fichtinger",
    "uDP7UX0AAAAJ": "Dadi Gudmundsson",
    "NGI_giYAAAAJ": "Peter O'Donovan",
    "G8dMSvAAAAAJ": "Stephen DiVerdi",
    "3M9mssIAAAAJ": "Zoya Bylinskii (Gavrilov)",
    "CqqvouwAAAAJ": "Martin de Lasa",
    "avCEoT8AAAAJ": "Erik Härkönen",
    "lCwsfosAAAAJ": "karan singh",
    "g5vDxv8AAAAJ": "Wilmot Li",
    "yBl_j4gAAAAJ": "Cuong Nguyen",
    "Vu1OqIsAAAAJ": "Chen Fang",
    "rRCnB0wAAAAJ": "Zhicheng Liu",
    "uiqXutMAAAAJ": "Feng Liu",
    "8B9EaL8AAAAJ": "Jun Xie",
    "OAtUvx0AAAAJ": "Kimberly Wilber",
    "5v0elikAAAAJ": "Jian Zhao",
    "BghVDhgAAAAJ": "Thomas Funkhouser",
    "PgSzKsgAAAAJ": "Nam Wook Kim",
    "nCZ2PMcAAAAJ": "Derek Nowrouzezahrai",
    "fSgLUqYAAAAJ": "Pierre Bénard",
    "d10sXc8AAAAJ": "Belen Masia",
    "EEre0EcAAAAJ": "Jonathan Taylor",
    "qSGlX6UAAAAJ": "Elena Garces",
    "FHtM5MUAAAAJ": "Difan Liu",
    "TfWlMTYAAAAJ": "Zheng Xu",
    "g3VILNEAAAAJ": "Jānis Lībeks",
    "QY5OAIMAAAAJ": "Spandan Madan",
    "OwA3zyMAAAAJ": "Lexing Ying",
    "IYUPj9MAAAAJ": "Xi Wang",
    "EareJO0AAAAJ": "Robert Pepperell",
    "8kYedXEAAAAJ": "Varun Ramakrishna",
    "9HoiYnYAAAAJ": "Cem Keskin",
    "j-cSRNIAAAAJ": "Tianqiang Liu",
    "-tzn_AsAAAAJ": "Ana Serrano",
    "gXgEgeoAAAAJ": "Patricio Simari",
    "-KN-O0sAAAAJ": "shuhui jiang",
    "RTVRTSsAAAAJ": "Yanshuai Cao",
    "2-P1M2IAAAAJ": "Simon Breslav",
    "Yi5nK1EAAAAJ": "Daniel Vogel",
    "4NUg-zkAAAAJ": "Mohamed Nabail",
    "ma2bi00AAAAJ": "Michael Kass",
    "1ROPmVQAAAAJ": "Cristian Ungureanu",
    "qRXIUuMAAAAJ": "Kannan Achan",
    "kuIqfXkAAAAJ": "Michael Guerzhoy",
    "h-JEcQ8AAAAJ": "Y. Raymond Fu",
    "PghQbXMAAAAJ": "Alex Colburn",
    "-qSroKoAAAAJ": "Balázs Kovács",
    "v0DNZWUAAAAJ": "Hsing-Kuo Pao",
    "zO6kmIAAAAAJ": "Chee Yap",
    "LF-IGAEAAAAJ": "Ronnachai Jaroensri",
    "0xroV7wAAAAJ": "Ying-Chao Tung",
    "IeHKeGYAAAAJ": "Matthew D. Hoffman",
    "QW_JZnsAAAAJ": "Maja Waldron",
    "Y2q1wVEAAAAJ": "Elena Sizikova",
    "TmZ3howAAAAJ": "Jacob O. Wobbrock",
    "ZDL6ITwAAAAJ": "Michael P. Brenner",
    "QwdY5EIAAAAJ": "Varun Gulshan",
    "wKvaIJgAAAAJ": "Eric Feron",
    "XeDv_1IAAAAJ": "Venkataramanan Balakrishnan",
    "3Oiv9FwAAAAJ": "Giuseppe Carlo Calafiore",
    "3QxoymwAAAAJ": "Arkadi Nemirovski",
    "p_ALSeoAAAAJ": "Francois Oustry",
    "yQKlLTQAAAAJ": "Jiayu Zhou",
    "ejchAEYAAAAJ": "Hiroko H. Dodge",
    "GZA3M2AAAAAJ": "Fengyi Tang",
    "egq785sAAAAJ": "Kaixiang Lin",
    "e7rXLKAAAAAJ": "Kevin Hsieh",
    "K6J_DvgAAAAJ": "Yong H. Lee",
    "1VDV6ZEAAAAJ": "Cem Anil",
    "QMfeRz0AAAAJ": "Angela Schoellig",
    "gnBwBZ4AAAAJ": "Xuchan Bao",
    "Qp2pme4AAAAJ": "Sicong(Sheldon) Huang",
    "cI0dYX4AAAAJ": "Sageev Oore",
    "AYaHBAQAAAAJ": "James Lucas",
    "c1FYGAQAAAAJ": "Jörn-Henrik Jacobsen",
    "ewqmB6sAAAAJ": "Mohamed K. Helwa",
    "OZk7X80AAAAJ": "Jingxing Qian",
    "Xr_hCJMAAAAJ": "Zining Zhu",
    "uodw8PQAAAAJ": "Keenan Burnett",
    "_j5XWygAAAAJ": "Sepehr Samavi",
    "RjPS_lUAAAAJ": "Mona Gridseth",
    "YDCsS5EAAAAJ": "Philip Huang",
    "QKNeRFsAAAAJ": "Quinlan Sykora",
    "Nf48jqcAAAAJ": "Jin Peng Zhou",
    "j4VWFL4AAAAJ": "Yunhao Tang",
    "RiDdF2YAAAAJ": "Heinrich Jiang",
    "GAvF3gUAAAAJ": "Silvia Chiappa",
    "5Cm8L90AAAAJ": "Philip J. Ball",
    "oWcFfZcAAAAJ": "Niladri S. Chatterji",
    "-0U84zMAAAAJ": "Mark Rowland",
    "-D0EgMIAAAAJ": "Yasin Abbasi Yadkori",
    "vg_IkckAAAAJ": "Richard Yuanzhe Pang",
    "1_f79vUAAAAJ": "Jiachen Li",
    "MKSTPN8AAAAJ": "Liron Yatziv",
    "2Dymb8oAAAAJ": "Yeqing Li",
    "lKvYBwkAAAAJ": "Ranjith Unnikrishnan",
    "qOtlP1AAAAAJ": "Marco Zennaro",
    "yOcNQVgAAAAJ": "Andrew Rabinovich",
    "17fLjgQAAAAJ": "Andrew Senior",
    "351ivuQAAAAJ": "Burak Gokturk",
    "38fqeIYAAAAJ": "Patrick Nguyen",
    "r9JOIloAAAAJ": "Kuang-chih Lee",
    "aMeteU4AAAAJ": "Tara Sainath",
    "5oa_2lgAAAAJ": "Xiaofan Lin",
    "C6UAIHEAAAAJ": "Navneet Dalal",
    "WwqlChAAAAAJ": "Georg Heigold",
    "HQbrO2kAAAAJ": "Baris Sumengen",
    "tJ_PrzgAAAAJ": "Abdelrahman Mohamed",
    "e8ZEb4wAAAAJ": "Michiel Bacchiani",
    "OqUlGZwAAAAJ": "Erik McDermott",
    "AjkTOkAAAAAJ": "Thomas B. McHugh",
    "kbZqRLkAAAAJ": "Brandon Kinman",
    "NRoF0iwAAAAJ": "Anthony Francis",
    "pEKw_vtA1pcC": "Stefano Mazzocchi",
    "BbfIggwAAAAJ": "Xin Pan",
    "4EOqqUsAAAAJ": "Gábor Bartók",
    "fKBmhcUAAAAJ": "Luciano Sbaiz",
    "QRYX59sAAAAJ": "Ke Wang",
    "IOxo6sIAAAAJ": "Abhijit Ogale",
    "XqAe43gAAAAJ": "Brian P Strope",
    "5GLvj20AAAAJ": "Julie Wilson",
    "h0pQOHgAAAAJ": "Edward Snell",
    "WzkYR-0AAAAJ": "Patrick Charbonneau",
    "NmDY9BMAAAAJ": "David R So",
    "JjID4s0AAAAJ": "Ken Caluwaerts",
    "CdRAIEkAAAAJ": "Françoise Beaufays",
    "57XwZeYAAAAJ": "Janet Newman",
    "eaigsKkAAAAJ": "Vishal Satish",
    "VJFrfM0AAAAJ": "Kate Sanders",
    "HylrshMAAAAJ": "Marcus Dominguez-Kuhne",
    "7CKFg9EAAAAJ": "Jeffrey Ichnowski",
    "AMReihwAAAAJ": "Xin Lei",
    "qjgsTnwAAAAJ": "Aditya Ganapathi",
    "o7zbCEsAAAAJ": "Gabriel Deza",
    "qAWS07wAAAAJ": "Shrey Aeron",
    "2TTqpGQAAAAJ": "Kaushik Shivakumar",
    "2trZ2IYAAAAJ": "Clifford Nass",
    "cjUid0YAAAAJ": "Peter Karkus",
    "oxyHy1MAAAAJ": "Nathan Koenig",
    "c26ONgMAAAAJ": "Romeo Valentin",
    "4U1XK1gAAAAJ": "Sydney Michelle Katz",
    "1rM2RFoAAAAJ": "Mitchel Weintraub",
    "O27t9j4AAAAJ": "Ananth Sankar",
    "VOWP8TUAAAAJ": "Pete Warden",
    "nb8wjsoAAAAJ": "Sherry Moore",
    "zmDJrh0AAAAJ": "Fernando Brandao",
    "6WYsaqMAAAAJ": "aram harrow",
    "n0QrdEMAAAAJ": "Johan Håstad",
    "x7viPbgAAAAJ": "James R. Lee",
    "3TlBVXkAAAAJ": "Alexandra Kolla",
    "Klc6YZcAAAAJ": "Samuel Fiorini",
    "h0_3SjAAAAAJ": "Guy Kindler",
    "IGDs4HwAAAAJ": "Thomas Vidick",
    "qLtTKNwAAAAJ": "Ning Tan",
    "aXWFB2UdJUUC": "Benjamin Doerr",
    "e3hldDEAAAAJ": "Johannes Lengler",
    "Mj1QkjkAAAAJ": "wei lu",
    "rQ68pVwAAAAJ": "Mark Newman",
    "8y9rrq0AAAAJ": "Eytan Bakshy",
    "x8UpLZUAAAAJ": "Johan Ugander",
    "xvnfpkMAAAAJ": "Maximilian Balandat",
    "XXeNb58AAAAJ": "Daniel R. Jiang",
    "TTLOfXIAAAAJ": "Cameron Marlow",
    "beXm1FwAAAAJ": "Samuel Daulton",
    "pCe3nQgAAAAJ": "Alon Shalita",
    "TnJqhXIAAAAJ": "Itai Gat",
    "-8QcdvgAAAAJ": "Matthew Le",
    "oNQRPLYAAAAJ": "Dean Eckles",
    "m1wGy3gAAAAJ": "Moira Burke",
    "2fwi6UIAAAAJ": "Sergey Pupyrev",
    "5Rp2lKIAAAAJ": "Elizaveta (Liza) Levina",
    "KlhDpG0AAAAJ": "Guilherme Ottoni",
    "TJSHa2IAAAAJ": "Laxman Dhulipala",
    "7EoDBR0AAAAJ": "Apoorv Vyas",
    "8t3Ex0QAAAAJ": "Vimal Manohar",
    "SW4wc24AAAAJ": "Leda Sarı",
    "7lP7XcMAAAAJ": "Jay Mahadeokar",
    "SC1L3uAAAAAJ": "Mary Williamson",
    "DL6Gk3AAAAAJ": "Heli Ben-Hamu",
    "5wiSTtUAAAAJ": "Liang Shi",
    "EsoKTawAAAAJ": "Alessandro Presta",
    "761-alkAAAAJ": "neta shaul",
    "EaYZfmoAAAAJ": "Marton Havasi",
    "sOrBUWAAAAAJ": "Mayank Pundir",
    "lmDy04wAAAAJ": "Travis Martin",
    "1ZHcGwIAAAAJ": "Carles Domingo-Enrich",
    "0YstIVMAAAAJ": "Shaun Singh",
    "EIX2jGQAAAAJ": "Giuseppe Ottaviano",
    "Iz9v6dcAAAAJ": "Matthew Muckley",
    "2Dt0VJ4AAAAJ": "Guan-Horng Liu",
    "X8H76XIAAAAJ": "Kamalika Chaudhuri",
    "KDqGTIUAAAAJ": "Maximilian Nickel",
    "CUkAtC4AAAAJ": "Roman Garnett",
    "5LubxuUAAAAJ": "Shali Jiang",
    "0gkajvEAAAAJ": "Jacob Gardner",
    "5bQjLz4AAAAJ": "Daniel Severo",
    "c4yK72IAAAAJ": "Matt Goldman",
    "qzC5Gh0AAAAJ": "Herald Kllapi",
    "SfN31P4AAAAJ": "Michael Stumm",
    "o_1YtVoAAAAJ": "Ashwini Pokle",
    "nIEep3cAAAAJ": "Uriel Singer",
    "yd0R-5MAAAAJ": "Birce Tezel",
    "0YPGwhgAAAAJ": "Nicolas E. Stier-Moses",
    "QrXQQ2kAAAAJ": "Davide Viviano",
    "YlmiyYkAAAAJ": "P. Alex Dow",
    "wnTOU6AAAAAJ": "Farshad Kooti",
    "wY1PiLwAAAAJ": "Paige Maas",
    "VhL7NugAAAAJ": "Daniel Citron",
    "B1RixPAAAAAJ": "Ahmed Medhat",
    "GNwyyrsAAAAJ": "Eugenia Giraudy",
    "JZ0snAcAAAAJ": "Alex Pompe",
    "G0x9hZkAAAAJ": "Kenneth Hung",
    "im5aMngAAAAJ": "Charles Elkan",
    "uDdA-r4AAAAJ": "John Berkowitz",
    "Odek140AAAAJ": "Kamyar Azizzadenesheli",
    "SAnJ1hIAAAAJ": "Saurabh Garg",
    "Sg3jtCgAAAAJ": "Divyansh Kaushik",
    "yteZM6AAAAAJ": "Dave Kale",
    "SLISZFAAAAAJ": "Bhuwan Dhingra",
    "JpSx3EMAAAAJ": "Danish Pruthi",
    "zmbW4iUAAAAJ": "Liu Leqi",
    "JKJ99B0AAAAJ": "Aran Khanna",
    "2jPsTDgAAAAJ": "Pratyush Maini",
    "sYixPw8AAAAJ": "Tommaso Furlanello",
    "DFqp8NkAAAAJ": "Jeffrey P. Bigham",
    "0d59fEcAAAAJ": "Kundan Krishna",
    "mKzKZfUAAAAJ": "Balakrishnan Narayanaswamy",
    "hJS2TXwAAAAJ": "Jean Kossaifi",
    "KTzRHmwAAAAJ": "Byron Wallace",
    "nZxJGeUAAAAJ": "Haohan Wang",
    "ZA0KnX0AAAAJ": "Shantanu Gupta",
    "xhUvqK8AAAAJ": "Laurent Itti",
    "xBJ-7n4AAAAJ": "Jacob Tyo",
    "GPRnVkMAAAAJ": "Sina Fazelpour",
    "BKkK2DoAAAAJ": "Helen Zhou",
    "HJDxXUsAAAAJ": "Yanyao  Shen",
    "UMZrl1cAAAAJ": "Yakov Kronrod",
    "laKl8acAAAAJ": "Faisal Ahmed, PhD",
    "xMne5ZUAAAAJ": "Eduard Hovy",
    "W4oOmZEAAAAJ": "Hyokun Yun",
    "TSj_8nYAAAAJ": "Michael Tschannen",
    "jqHoz9EAAAAJ": "Michael Feffer",
    "RljePdcAAAAJ": "Songwei Ge",
    "T5hu6dsAAAAJ": "Stephan Rabanser",
    "NMIU_S4AAAAJ": "Giulio Zhou",
    "9lh2gH8AAAAJ": "Davis Liang",
    "5rjfy4AAAAAJ": "Truong Nguyen",
    "AMHNjTIAAAAJ": "Simran Kaur",
    "Kz5C0p0AAAAJ": "Jeremy Bernstein",
    "v9-IuzwAAAAJ": "Mansi Gupta",
    "J6_5toMAAAAJ": "Rachel Leah Childers",
    "SW_WaQ0AAAAJ": "Xiujun Li",
    "pYPowr8AAAAJ": "Riccardo Fogliato",
    "d7_f7LsAAAAJ": "Xinyang Feng",
    "LQ5RRNkAAAAJ": "Frank Provenzano",
    "W1kXLwYAAAAJ": "Scott A. Small",
    "LVOGjXYAAAAJ": "Jie Yang",
    "_9GX96fDWAMC": "Hanie Sedghi",
    "r493814AAAAJ": "Jeremy M Cohen",
    "_Y_XvN4AAAAJ": "Tanya Marwah",
    "BbdF4ysAAAAJ": "Sopan Khosla",
    "YMaEuzoAAAAJ": "Aditya Siddhant",
    "fZKJdb0AAAAJ": "Zachary Novack",
    "UliV3XQAAAAJ": "Pranav Mani",
    "uvsSrnoAAAAJ": "Alan Lewis Montgomery",
    "P4G6H7oAAAAJ": "Xingjian Shi",
    "ZOkQ-PoAAAAJ": "Liang Li",
    "YRbB4CgAAAAJ": "Daniel Nagin",
    "Bq9Osr8AAAAJ": "Alice Xiang",
    "GbVC5NYAAAAJ": "Aashiq Muhamed",
    "jQLg-_UAAAAJ": "Yun-Nung (Vivian) Chen",
    "KBHW5wsAAAAJ": "Lee Cohen",
    "SuH4Z2gAAAAJ": "Julian A. Gingold",
    "zyQAdTwAAAAJ": "Nina Desai",
    "BrWvx00AAAAJ": "Jeremy C Weiss",
    "uW8JaBsAAAAJ": "zhiheng huang",
    "SEDPkrsAAAAJ": "Yulia Tsvetkov",
    "GgD-B68AAAAJ": "Zirui Wang",
    "gcS68oUAAAAJ": "Angela H. Jiang",
    "D-CVv_QAAAAJ": "Padmanabhan Pillai",
    "PF-7nJMAAAAJ": "Daniel Lin-Kit Wong",
    "Hd80zWMAAAAJ": "Akshay Balsubramani",
    "C3s1jqIAAAAJ": "Livio Baldini Soares",
    "8LDlwEwAAAAJ": "Cheng Cheng",
    "h5IXxToAAAAJ": "Hanlin Zhang",
    "lUnt8X4AAAAJ": "Yi-Fan Zhang",
    "cXhAfX0AAAAJ": "James Sharpnack",
    "hfZRGpgAAAAJ": "Bhargavi Paranjape",
    "I2LNwZgAAAAJ": "Alankar Jain",
    "ej9SRrAAAAAJ": "Jianfeng Lu 鲁剑锋",
    "lJol4lAAAAAJ": "Brandon Yang",
    "lm55cKIAAAAJ": "Weitang Liu",
    "hNI5rEIAAAAJ": "Fatma Kılınç-Karzan",
    "-xwtUkYAAAAJ": "Nitish Kulkarni",
    "HFwSkGIAAAAJ": "Raghuveer Chanda",
    "P5g-cYwAAAAJ": "Anirudha Rayasam",
    "SEAowdYAAAAJ": "Peiyun Hu",
    "56vtsXMAAAAJ": "Jessica Dai",
    "ypaqepYAAAAJ": "Nil-Jana Akpinar",
    "VECFLiAAAAAJ": "Jianmo Ni",
    "bM4pEGoAAAAJ": "Amy Pavel",
    "gTuG8BsAAAAJ": "Benjamin Schloss",
    "VGfczTIAAAAJ": "Siddhant Arora",
    "X57uzqcAAAAJ": "Norman Sadeh",
    "x-pMK90AAAAJ": "Alex John London",
    "IKUm624AAAAJ": "Yuyang (Bernie) Wang",
    "NrOA9QoAAAAJ": "Hao Wang",
    "u0eUsYsAAAAJ": "Rodney A. Gabriel",
    "O8eqJA4AAAAJ": "George H. Chen",
    "Npd4ZzgAAAAJ": "Saurabh Garg",
    "6NFzfAgAAAAJ": "Nicholas Roberts",
    "_M5OBVkAAAAJ": "Brian E Howard",
    "GGHVmOsAAAAJ": "Omer Ben-Porat",
    "SmuY2sMAAAAJ": "Cheng-i Wang",
    "IuOS8TkAAAAJ": "Tamara Smyth",
    "Nd6DvD4AAAAJ": "Julian Salazar",
    "qhgWjNkAAAAJ": "Rahul Suresh",
    "V5FDxaAAAAAJ": "William Wong",
    "zx4X0fwAAAAJ": "Anurag Katakkar",
    "MhoS1_oAAAAJ": "Fan Yang",
    "k0ZTfQoAAAAJ": "Mansi Gupta",
    "BSORuFoAAAAJ": "Gregory Dudek",
    "kcr8134AAAAJ": "Krishna Murthy Jatavallabhula",
    "KXkVpr4AAAAJ": "Juan Camilo Gamboa Higuera",
    "04dL0akAAAAJ": "Kevin Xie",
    "KjfpioYAAAAJ": "Ioannis Rekleitis",
    "l7X99s0AAAAJ": "Anqi Xu",
    "QAPgF4kAAAAJ": "Travis Manderson",
    "KDTyloUAAAAJ": "Malika Meghjani",
    "DVuM2KsAAAAJ": "Jimmy Li",
    "qvRf9xsAAAAJ": "Florian Golemo",
    "V9EUwCEAAAAJ": "Miles Macklin",
    "bC-gapAAAAAJ": "Breandan Considine",
    "PPCRqZUAAAAJ": "Vikram Voleti",
    "RLOXUngAAAAJ": "Yogesh Girdhar",
    "tgZPkzkAAAAJ": "Philippe Giguère",
    "1EW9Jt4AAAAJ": "Wei-Di Chang",
    "TOzQO_UAAAAJ": "Mohamed Khodeir",
    "MD2-gPcAAAAJ": "Arnold Kalmbach",
    "dy_JBs0AAAAJ": "Peter Henderson",
    "wYDYIYkAAAAJ": "Katrine Turgeon",
    "cgaU4UkAAAAJ": "Junaed Sattar",
    "vDn8bXAAAAAJ": "Johanna Hansen",
    "goCW1d8AAAAJ": "Milena Scaccia",
    "00RihbwAAAAJ": "David Whitney",
    "xak5mK4AAAAJ": "Sung Min Park",
    "dzyzDRIAAAAJ": "Firdaus Janoos",
    "lTXMC44AAAAJ": "Guillaume Leclerc",
    "YMAOvHYAAAAJ": "Larry Rudolph",
    "t_iLVOoAAAAJ": "Kevin Kwok",
    "t8RKSJsAAAAJ": "Kristian Georgiev",
    "BA1kFjMAAAAJ": "Alaa Khaddaj",
    "ePC7IC0AAAAJ": "Ajil  Jalal",
    "6hsn3EYAAAAJ": "Saachi Jain",
    "PnaHFhUAAAAJ": "Sai H. Vemprala",
    "2BTuWpgAAAAJ": "Sarah Huiyi Cen",
    "4VpTwzIAAAAJ": "Owain Evans",
    "nc6hvFgAAAAJ": "Mihaela Curmei",
    "tBAp1-gAAAAJ": "Manolis Zampetakis",
    "haO4sKoAAAAJ": "Aleksandar Makelov",
    "3VZ_E64AAAAJ": "Pengchuan Zhang",
    "IKRu39AAAAAJ": "Yeshwanth Cherapanamjeri",
    "_ambxJIAAAAJ": "Joana Trindade",
    "bBHxY_MAAAAJ": "Raul Castro Fernandez",
    "D_d_d8wAAAAJ": "Roy Rinberg",
    "v1rY3BYAAAAJ": "Jennifer Allen",
    "V3NQnJoAAAAJ": "Hannah Li",
    "lWzkIg4AAAAJ": "Shivam Garg",
    "QkpYowMAAAAJ": "Axel Feldmann",
    "3q8ivkoAAAAJ": "Shivin Dass",
    "26eh1jAAAAAJ": "Dimitris Tsipras",
    "ivUi2T0AAAAJ": "Amr Ahmed",
    "XKCyZk0AAAAJ": "Edoardo M Airoldi",
    "CiSdOV0AAAAJ": "Gunhee Kim",
    "6HVq8KMAAAAJ": "Pedro MQ Aguiar",
    "V4LXxrQAAAAJ": "Brendan T. O'Connor",
    "cSxeVz0AAAAJ": "Ning Chen",
    "feX1fWAAAAAJ": "Li-Jia Li",
    "O-tJRckAAAAJ": "Kriti Puniyani",
    "qQLlBH4AAAAJ": "Robert F. Murphy",
    "mZcPPW4AAAAJ": "Ramesh Maruthi Nallapati",
    "NIIQFrEAAAAJ": "Rong Yan",
    "Wj3t9l0AAAAJ": "Bing Zhao",
    "Dj3gptkAAAAJ": "Christopher Langmead",
    "UUKLPMYAAAAJ": "Yan Liu",
    "N9MkuMwAAAAJ": "Zhen Guo",
    "60ITZUkAAAAJ": "Fan Li (李凡)",
    "bEn7ySYAAAAJ": "Jia-Yu Pan",
    "Xlv5PDYAAAAJ": "Dipanjan Das",
    "GL9M37YAAAAJ": "Changshui Zhang",
    "o37mElYAAAAJ": "Yanghan Wang",
    "RNj18KkAAAAJ": "Fei Sun",
    "2oB4nAIAAAAJ": "Feiping Nie",
    "0ggsACEAAAAJ": "Shiming Xiang",
    "CKqzOqsAAAAJ": "Yunchao Gong",
    "LXSkrXkAAAAJ": "Wei Lin",
    "eteU0U4AAAAJ": "Nan Ding",
    "f9_wq_kAAAAJ": "Andrea Frome",
    "7hf-iAEAAAAJ": "Xufeng Han",
    "vXHA_XYAAAAJ": "David Brooks",
    "3PuVdYEAAAAJ": "Xiaodong Wang",
    "QLjltcIAAAAJ": "Mikhail Smelyanskiy",
    "x9K4md8AAAAJ": "Kim Hazelwood",
    "1YduZuMAAAAJ": "Sarah Bird",
    "zMvBdmQAAAAJ": "James Law",
    "U3Eub-EAAAAJ": "Jia Deng",
    "IyyEKyIAAAAJ": "Chang Huang",
    "NiJYYkkAAAAJ": "Matt Uyttendaele",
    "1mKHwfIAAAAJ": "Marat Dukhan",
    "R-z1R84AAAAJ": "Niraj Jha",
    "ZMLhZJ8AAAAJ": "Long QUAN",
    "s7ky8QUAAAAJ": "Wencong Xiao",
    "_zo4uhoAAAAJ": "Yong Li",
    "sjF5p5wAAAAJ": "Shiru Ren",
    "v8PeLGgAAAAJ": "Arto Klami",
    "j1okDGUAAAAJ": "Seppo Virtanen",
    "6CAfoBgAAAAJ": "Jun Yang",
    "meFUbHIAAAAJ": "Mengdi Wang",
    "64zxhRUAAAAJ": "Jingren Zhou",
    "1bG8fLEAAAAJ": "Wei Zhang",
    "ENJA2f8AAAAJ": "Yingda Chen",
    "tWew360AAAAJ": "Zheng Wang",
    "zxFuDvsAAAAJ": "Tommer Leyvand",
    "nh5a4LQAAAAJ": "Yuan Li",
    "h1Z5hk8AAAAJ": "Bangpeng Yao",
    "foTQUXwAAAAJ": "Zhongdong Wang",
    "V_VEjLUAAAAJ": "Yang Li",
    "XKFJHycAAAAJ": "LIU Wenyin",
    "P28bgJMAAAAJ": "Yabo Xu",
    "QqfCvsgAAAAJ": "Efstratios Gavves",
    "Hz7KBrIAAAAJ": "Des Johnston",
    "VEkbdjcAAAAJ": "Martin Weigel",
    "qbTyWP4AAAAJ": "Johannes Zierenberg",
    "cLCHds0AAAAJ": "Christian Holm",
    "B_IufdEAAAAJ": "Ralph Kenna",
    "IkrviqEAAAAJ": "Suman Majumder",
    "4EKKyosAAAAJ": "Bernd A Berg",
    "HXfCKiQAAAAJ": "Martin Marenz",
    "MYIW1psAAAAJ": "Bertrand Berche",
    "rifOKt4AAAAJ": "Christophe Chatelain",
    "jQnTUZEAAAAJ": "Bartlomiej Waclaw",
    "vpo0U3QAAAAJ": "Leszek Bogacz",
    "_k2LvcEAAAAJ": "Lev Shchur",
    "nwPxp24AAAAJ": "Christoph Junghans",
    "JTfD4akAAAAJ": "Thomas Vogel",
    "-ViviVsAAAAJ": "L.Yu. Barash",
    "aQUQU10AAAAJ": "Joan Adler",
    "5KLRGb0AAAAJ": "Hannes Nagel",
    "gicJpX8AAAAJ": "Jonathan Gross",
    "ej68QYkAAAAJ": "Reinhard Schiemann",
    "WQA9GckAAAAJ": "Marius Grundmann",
    "xazEr4oAAAAJ": "Nikolaos Fytas",
    "0P1J-m8AAAAJ": "Malte Henkel",
    "uBial08AAAAJ": "Annette Beck-Sickinger",
    "Thz9yCEAAAAJ": "Richard Blythe",
    "IuhidDAAAAAJ": "Hans J. Herrmann",
    "4XMv5IoAAAAJ": "Yuko OKAMOTO (岡本祐幸)",
    "l2IhA2IAAAAJ": "Brian Dolan",
    "lvPdFJUAAAAJ": "Sergei Shmulyian",
    "-rlnZrMAAAAJ": "Andreas M. Läuchli",
    "1i6vsBYAAAAJ": "Klaus Kroy",
    "9PvqaoEAAAAJ": "Darka Labavić",
    "f8sVvG0AAAAJ": "Chin-Kun Hu 胡進錕",
    "ju7dyZMAAAAJ": "Wolf Widdra",
    "eln2A94AAAAJ": "Silke Thoms",
    "deCmCVgAAAAJ": "Jörg Kärger",
    "fiRkCU0AAAAJ": "Malcolm Carroll",
    "fKcFF-gAAAAJ": "Simon Mitternacht",
    "MnBxiMsAAAAJ": "Max H. Gerlach",
    "M2GyttIAAAAJ": "Paolo Butera",
    "CM5qHwQAAAAJ": "Jeremi K. Ochab",
    "Bdy3OD0AAAAJ": "Swanand R. Kadhe",
    "fVcFAiIAAAAJ": "Greg Lewis",
    "vLbYPtwAAAAJ": "Ramandeep Randhawa",
    "RUTPdHcAAAAJ": "Markus Mobius",
    "wjRRS3YAAAAJ": "Vytas SunSpiral",
    "_Uzh_ucAAAAJ": "Jonathan Bruce",
    "4PMCkasAAAAJ": "Massimo Vespignani",
    "ae1ve-EAAAAJ": "Venkata N. Padmanabhan",
    "0P35aLUAAAAJ": "Ramachandran Ramjee",
    "TuT3_UwAAAAJ": "Burak Yavuz",
    "9rAYhr8AAAAJ": "Prashanth Mohan",
    "FnD5B1QAAAAJ": "Asankhaya Sharma",
    "xhbf6_oAAAAJ": "Ranjita Bhagwan",
    "HUIAm4UAAAAJ": "Shixiong Zhu",
    "HCHLK5wAAAAJ": "Yuan Zhong",
    "hCbFmUUAAAAJ": "Niloy Ganguly",
    "ywWy5NIAAAAJ": "Atul Singh",
    "utY1nToAAAAJ": "Matteo Marsili",
    "qlKWTsUAAAAJ": "Scott Kirkpatrick",
    "5MeSMfAAAAAJ": "Alain Barrat",
    "fi4HWW8AAAAJ": "Razvan Bunescu",
    "w8JK9v0AAAAJ": "Prem Melville",
    "4kOdChQAAAAJ": "John Zelle",
    "5222Mu8AAAAJ": "Rohit J Kate",
    "jTUvYSAAAAAJ": "Mary Elaine Califf",
    "KxmUmKkAAAAJ": "Edward Marcotte",
    "h9E2XBi3aTAC": "Cynthia A Thompson",
    "MeZLMbkAAAAJ": "Milos Gligoric",
    "tJGm3-YAAAAJ": "Junyi Jessy Li",
    "v7kFHRoAAAAJ": "Katrin Erk",
    "8hxMm5UAAAAJ": "David L. Chen",
    "okf5bmQAAAAJ": "Jude Shavlik",
    "AdSEuYcAAAAJ": "Pengyu Nie",
    "w_GMSlcAAAAJ": "Tuyen N. Huynh (Huỳnh Ngọc Tuyên)",
    "YH7PDvEAAAAJ": "Aishwarya Padmakumar",
    "jkV6H1gAAAAJ": "Iz Beltagy",
    "DEtQ_YAAAAAJ": "Joohyun Kim",
    "zyqZgm8AAAAJ": "Brad Richards",
    "cTPU9HcAAAAJ": "Joseph Reisinger",
    "KjR3yVQAAAAJ": "Karl Pichotta",
    "SUAbOcgAAAAJ": "Maytal Saar-Tsechansky",
    "bxAIuu4AAAAJ": "Sheena Panthaplackel",
    "bOM9qN8AAAAJ": "Mustafa Bilgic",
    "FABZCeAAAAAJ": "Hwee Tou Ng",
    "vlDYiZoAAAAJ": "Prasoon Goyal",
    "H50SekAAAAAJ": "Alexander Strehl",
    "VSc-eTAAAAAJ": "Vanya Cohen",
    "OZKad_UAAAAJ": "Harel Yedidsion",
    "-Km63D4AAAAJ": "Foster Provost",
    "tT9mhNMAAAAJ": "Dan Garrette",
    "D0pzuNoAAAAJ": "Shiqi Zhang",
    "3HSzhHoAAAAJ": "William F Brewer",
    "9ZRcemUAAAAJ": "Nathanael Chambers",
    "TH5szrcAAAAJ": "Yash Kumar Lal",
    "3HAa8ni1oGUC": "Yuqian  Jiang",
    "cbm9vaUAAAAJ": "Maxwell Svetlik",
    "CLZ9dLoAAAAJ": "Sonal Gupta",
    "X3JCGVIAAAAJ": "Niranjan Balasubramanian",
    "rIh5OqoAAAAJ": "Yu Su",
    "ex9BQiIAAAAJ": "Claire Cardie",
    "NFJ9kUEAAAAJ": "Gemma Boleda",
    "V49BsgMAAAAJ": "Parag Singla",
    "s0OErVYAAAAJ": "Krupakar Pasupuleti",
    "rs1M7CAAAAAJ": "Michel Galley",
    "AvH7tJwAAAAJ": "Chris Quirk",
    "bG5-ZzIAAAAJ": "Sarfraz Khurshid",
    "iAG5Mj0AAAAJ": "Zeyuan Hu",
    "k5NbHlEAAAAJ": "Piyush Khandelwal",
    "FuOqWNEAAAAJ": "Vladimir Lifschitz",
    "GwR1fdsAAAAJ": "Fangkai Yang",
    "Vj8SG_oAAAAJ": "JK Aggarwal",
    "_X6fpR8AAAAJ": "Chris Welty",
    "naoTbnIAAAAJ": "Siddharth Patwardhan",
    "NvIcXEYAAAAJ": "Radu Florian",
    "OxrRSKsAAAAJ": "Xiaoqiang Luo",
    "1S7VwIcAAAAJ": "Salim Roukos, Salim Roucos",
    "Dl949GoAAAAJ": "Adriana Kovashka",
    "8PUwH9gAAAAJ": "Yinon Bentor",
    "1-pt7zMAAAAJ": "Ziru Chen",
    "n2ohF50AAAAJ": "Michael White",
    "9rHwD8wAAAAJ": "Ali Payani",
    "ljDY868AAAAJ": "Austin Waters",
    "X6UshLwAAAAJ": "Bryan Silverthorn",
    "KOrhfVMAAAAJ": "Pedro Domingos",
    "DxyeQ5L6RTkJ": "Ulf Hermjakob",
    "aMxXkWkAAAAJ": "David Paulius",
    "OM1hDLcAAAAJ": "Ifrah Idrees",
    "F--ov6gAAAAJ": "Shreyas Sundara Raman",
    "0fA9EQcAAAAJ": "Vítor Santos Costa",
    "qxkui7UAAAAJ": "Jiyang Zhang",
    "ABPKRkAAAAAJ": "tanvi motwani",
    "k4oSgRkAAAAJ": "Emmett Witchel",
    "hdXvVdgAAAAJ": "M Dahlin",
    "69JJbWoAAAAJ": "Shruti Bhosale",
    "M4AKMC4AAAAJ": "Tong Gao",
    "bRGcMbIAAAAJ": "Jierui Li",
    "hIETYPwAAAAJ": "Jim Blythe",
    "0cAcheMAAAAJ": "Horace Liu",
    "jN2DeKcAAAAJ": "Elisa Ferracane",
    "hEhQmT8AAAAJ": "Jordan Guy Voas",
    "xXQq8AIAAAAJ": "Qi Huang",
    "1V8AeXYAAAAJ": "Szymon Tworkowski",
    "3D_o3JUAAAAJ": "Yingying Wu",
    "L6xKfHkAAAAJ": "Douglas Fisher",
    "KXSlX3sAAAAJ": "Shijie Chen",
    "HtNfeKYAAAAJ": "Jayanth Srinivasa",
    "NRQftjIAAAAJ": "Priyanka Mandikal",
    "tUTVVjAAAAAJ": "Tanvi Aggarwal",
    "idOI-IAAAAAJ": "Smriti Singh",
    "jyF9UHAAAAAJ": "Jason Xinyu Liu",
    "KGgOhbAAAAAJ": "Eduardo R. Hruschka",
    "JL5DcncAAAAJ": "Amelia Harrison",
    "vW3djsoAAAAJ": "Ayush Shrivastava",
    "f1lspM0AAAAJ": "Ramprasaath R. Selvaraju",
    "9xLaU5MAAAAJ": "Rishi Shah",
    "j7ZI1WUAAAAJ": "Rolando Fernandez",
    "2TUruWMAAAAJ": "Puyuan  Peng",
    "RiiYXH0AAAAJ": "Anuj Diwan",
    "ns4fY0sAAAAJ": "Sayontan Ghosh",
    "dDr8RIgAAAAJ": "Mahnaz Koupaee",
    "hGM6Go4AAAAJ": "Sugam Devare",
    "UB5EoOEAAAAJ": "Francis Ferraro",
    "dPsQR14AAAAJ": "Nakul Gopalan",
    "CAfsMIsAAAAJ": "Geraud Nangue Tasse",
    "_EJDz50AAAAJ": "Steven James",
    "pWJ0SocAAAAJ": "Benjamin Rosman",
    "R-Cc2h8AAAAJ": "Smriti R Ramakrishnan",
    "Ihyz20wAAAAJ": "Matthew Gombolay",
    "f1feDTMAAAAJ": "Yi-Jen Shih",
    "-d6aNP0AAAAJ": "Wei-Cheng Tseng",
    "7l1HdzYAAAAJ": "N.Krishnamoorthy",
    "ppaEV-8AAAAJ": "Liyan Chen",
    "3dYhzNQAAAAJ": "Yuxiang Zhou",
    "HmCZLyoAAAAJ": "Shane Barratt",
    "MGXJkIAAAAAJ": "Jost Tobias Springenberg",
    "qiFEpzIAAAAJ": "Shikhar Tuli",
    "HM_8xZYAAAAJ": "Suzanne Stevenson",
    "xSavR6cAAAAJ": "R. Thomas McCoy",
    "PRtkZzYAAAAJ": "Paul Smolensky",
    "5mJDXjoAAAAJ": "Tal Linzen",
    "bbfGi6sAAAAJ": "Yang Xu",
    "N1Gjo24AAAAJ": "Michael Y. Li",
    "MfGgaT0AAAAJ": "Thomas Langlois",
    "Ns8jBNsAAAAJ": "Ben Prystawski",
    "XpO6-kEAAAAJ": "Michael Luo",
    "WZfM0qsAAAAJ": "Matthew Brown",
    "8vs5HGYAAAAJ": "David Lowe",
    "VRsNu-EAAAAJ": "Hanhuai Shan",
    "ho_asq8AAAAJ": "Amin Shokrollahi",
    "dGuYytYAAAAJ": "Mohammad Mahmoody",
    "aLdQvEAAAAAJ": "James Cook",
    "h2hT0XcAAAAJ": "Salman Beigi",
    "1Lozhc4AAAAJ": "Saieed Akbari",
    "kW-hl3YAAAAJ": "Saeed Mahloujifar",
    "nscLxl4AAAAJ": "Siyao GUO",
    "R_bC8bkAAAAJ": "Masoud Aipour",
    "JDMpCRAAAAAJ": "Michel Habib",
    "TKmKZSAAAAAJ": "Katherine S Pollard",
    "0LEOL50AAAAJ": "Michael Rosenblum",
    "88cU_4UAAAAJ": "John Cunningham",
    "p_P5DAcAAAAJ": "José R. Zubizarreta",
    "ZZwLZ8UAAAAJ": "Alp Kucukelbir",
    "6mD3I24AAAAJ": "Scott Linderman",
    "VeRSO8EAAAAJ": "Kurt Shuster",
    "tYro5N8AAAAJ": "Usunier Nicolas",
    "8LN5NoQAAAAJ": "Jack Urbanek",
    "3b0l5LEAAAAJ": "Alexander Holden Miller",
    "EgVWuhAAAAAJ": "Pavel P. Kuksa",
    "v8QhiOwAAAAJ": "Chris Watkins",
    "eXKdSu0AAAAJ": "Yanjun Qi",
    "VBXG4CwAAAAJ": "Eleazar Eskin",
    "I1fl4oAAAAAJ": "Asa Ben-Hur",
    "dto2FacAAAAJ": "Mark Stitson",
    "aZALISYAAAAJ": "Lukas Käll",
    "icweOB0AAAAJ": "Michael MacCoss",
    "KjOV76MAAAAJ": "Yangli Hector Yee",
    "ataejQQAAAAJ": "Paul Pavlidis",
    "Al8dyb4AAAAJ": "song-chun zhu",
    "8PiZdy4AAAAJ": "Sara Taylor",
    "cNLW5O4AAAAJ": "Akane Sano",
    "jsy-VxMAAAAJ": "Lynn H. Kaack",
    "ndv95w0AAAAJ": "Szymon Fedor",
    "Ytp9oFQAAAAJ": "Cristina Conati",
    "vKDycp8AAAAJ": "Jason M. Harley",
    "m7Jr-b4AAAAJ": "Daniel McDuff",
    "eg6u4X8AAAAJ": "Karthik Dinakar",
    "OMo39G8AAAAJ": "Judith Amores",
    "2uwoiuIAAAAJ": "Jean-Arcady Meyer",
    "G0JugenpCgwC": "A/Prof Suranga Nanayakkara, PhD NUS",
    "xT8PQ0IAAAAJ": "Jordan Pollack",
    "WXV9HW4AAAAJ": "Roy Shilkrot",
    "5PS-lv8AAAAJ": "Sang-won Leigh",
    "BCGgwlEAAAAJ": "rodney brooks",
    "6-YuY60AAAAJ": "Star Heartsong (fka Hugo Liu), Ph.D.",
    "a58cNycAAAAJ": "Kristin Y. Pettersen",
    "3zP4ag0AAAAJ": "Pål Liljebäck",
    "HEO-wOQAAAAJ": "Øyvind Stavdahl",
    "BAD30S8AAAAJ": "Olav Egeland",
    "_FeYgnUAAAAJ": "Eleni Kelasidi",
    "QpTmnC4AAAAJ": "Raymond Kristiansen",
    "Q-dQhygAAAAJ": "Arnfinn Aas Eielsen",
    "OcjvsmoAAAAJ": "Thomas Røbekk Krogstad",
    "eTOMoMYAAAAJ": "Esten Ingar Grøtli",
    "2B_o_MIAAAAJ": "Walter Caharija",
    "U66RsYsAAAAJ": "Asgeir J. Sørensen",
    "ZYoaQYcAAAAJ": "Signe Moe",
    "qPtFfKAAAAAJ": "Michael Remo Palmén Ragazzon",
    "N3wwcYYAAAAJ": "Mathias Hauan Arbo",
    "gzn3C3oAAAAJ": "Tor Arne Johansen",
    "49PCVw0AAAAJ": "Anna M. Kohl",
    "yvWIqcQAAAAJ": "Christoph Josef Backi",
    "1-6y9qoAAAAJ": "Dr. Trygve Utstumo",
    "SFffUYgAAAAJ": "Marialena Vagia",
    "8n5W2FMAAAAJ": "Nur Uddin",
    "PlOGerYAAAAJ": "adil rasheed",
    "5nn3fN0AAAAJ": "Svein Hovland",
    "nQjxbScAAAAJ": "Roger Birkeland",
    "i17FWMMAAAAJ": "Mariusz Eivind Grøtte",
    "gl3ZczYAAAAJ": "Ehsan Rezapour",
    "pTEtZCYAAAAJ": "Linn Danielsen Evjemo",
    "c7GoaV8AAAAJ": "Erlend Lundby",
    "Ai1cvB8AAAAJ": "Bjørn Andreas Kristiansen",
    "38fYqeYAAAAJ": "Sebastien Gros",
    "PM5ZWS4AAAAJ": "Ivar J. Halvorsen",
    "QLuPP70AAAAJ": "Øyvind Hegrenæs",
    "HTfEll0AAAAJ": "Akhil S Anand",
    "Uq4lu9YAAAAJ": "Mutaz Tuffaha",
    "cPcOoY4AAAAJ": "Katrine Seel",
    "Sn8fzegAAAAJ": "Thor I. Fossen",
    "g2HE3PsAAAAJ": "Marco Bibuli",
    "ozaonZMAAAAJ": "Enrica Zereik",
    "HiyW7J4AAAAJ": "Andrew J. Fleming",
    "QsI17JQAAAAJ": "Therese W Berge",
    "bCuYVE4AAAAJ": "Henrik Schmidt-Didlaukies",
    "ZN0NeWMAAAAJ": "Joseph L Garrett",
    "KED9FsgAAAAJ": "Erlend A. Basso",
    "jFnb_-EAAAAJ": "Fares J. Abu-Dakka",
    "tX56UKEAAAAJ": "Frank Willems",
    "3i8wNscAAAAJ": "John Leth",
    "axvGyXoAAAAJ": "Karen Willcox",
    "9QmGHaYAAAAJ": "Milica Orlandić",
    "VSI-8CwAAAAJ": "Antoine Chaillet",
    "XeDtzHEAAAAJ": "Sivert Bakken",
    "O2gmsKAAAAAJ": "Ingrid Schjølberg",
    "5IFSlsIAAAAJ": "Michael G. Ruppert",
    "UnDvzw0AAAAJ": "David M. Harcombe",
    "V9KyKCwAAAAJ": "Jan Bendtsen",
    "tW21GGYAAAAJ": "Elena Panteley",
    "kosv_k0AAAAJ": "Haakon Robinson",
    "KWH1qbsAAAAJ": "Sigurd Skogestad",
    "5F5LBT8AAAAJ": "Evelyn Honoré-Livermore",
    "arXWx_oAAAAJ": "Henk Nijmeijer",
    "HIcgaZEAAAAJ": "Geir Kvam-Langelandsvik",
    "ASLQHz8AAAAJ": "Tristan Perez",
    "Ab_XjfQAAAAJ": "Yik R. Teo",
    "ImQ7ceQAAAAJ": "Amer Orucevic",
    "GuhpBxMAAAAJ": "Antonio Loria",
    "Z21g5_wAAAAJ": "Ingrid Fjordheim Onstein",
    "cyp0fCAAAAAJ": "Bjørn Kåre Sæbø",
    "ZOF0KysAAAAJ": "Graham clifford goodwin",
    "IH3HEbkAAAAJ": "Tommy Lillehagen",
    "j4XdW_EAAAAJ": "Dirk Reinhardt",
    "VnJUnMoAAAAJ": "Amund Skavhaug",
    "HuZ6F6QAAAAJ": "Aksel Andreas Transeth",
    "hEOInHkAAAAJ": "Arash Bahari Kordabad",
    "l1uvSZIAAAAJ": "Manon Kok",
    "Z_WO2w0AAAAJ": "Herman Biørn Amundsen",
    "OVkZUYoAAAAJ": "Sveinung Johan Ohrem",
    "CmoWrcIAAAAJ": "Luca Rosario Buonocore",
    "lueKv2oAAAAJ": "Gianluca D'Antuono",
    "Zhb-VjwAAAAJ": "Jan Inge Dyrhaug",
    "7aJVFS8AAAAJ": "Christian Løvaas",
    "rXqA5nYAAAAJ": "Simen Å Ellingsen",
    "tGK7hLEAAAAJ": "Vahid Hassani",
    "i5FepLsAAAAJ": "Filippo Sanfilippo",
    "E8aZ_q4AAAAJ": "John Reidar Mathiassen",
    "kdi99YAAAAAJ": "Aleksander Lillienskiold (fka Eilertsen)",
    "8MJh6JcAAAAJ": "Alejandro Rojas",
    "XC3nc68AAAAJ": "Alberto Bemporad",
    "rvIjH9IAAAAJ": "Erling Tveter",
    "60HNWsYAAAAJ": "HARALD MARTENS",
    "8juM0fYAAAAJ": "Frida Viset",
    "0IzM_20AAAAJ": "Bent Oddvar Arnesen Haugaløkken",
    "53OPcJ4AAAAJ": "Tomáš Polóni",
    "19xIGUUAAAAJ": "Edmund Brekke",
    "WmFoofMAAAAJ": "Marilena Greco",
    "Sql50pkAAAAJ": "Andreas Østvik",
    "HSlEhqwAAAAJ": "Markus H. Iversflaten",
    "DyABVI0AAAAJ": "Morten Hovd",
    "cDduRqwAAAAJ": "Stefano Chiaverini",
    "l4lTuMcAAAAJ": "Shambhuraj Sawant",
    "fIEuk78AAAAJ": "Thulasi Mylvaganam",
    "asmcUBEAAAAJ": "Rituraj Kaushik",
    "BTn-nikAAAAJ": "Mathias Marley",
    "OJPj4t0AAAAJ": "Simen Berg",
    "MDDx3Q4AAAAJ": "Weijia Yao",
    "ReXgGMEAAAAJ": "Jørgen Anker Olsen",
    "s5Aqlw4AAAAJ": "Ahmed Mohammed",
    "rupmL3kAAAAJ": "Eirik B. Njaastad",
    "0iktJ5sAAAAJ": "Andrej Cibicik",
    "5br3h-UAAAAJ": "Martin Albertsen Brandt",
    "TaZaMGkAAAAJ": "Kristian Martinsen",
    "y_PW-TcAAAAJ": "Camilla Sterud",
    "5hlRYCIAAAAJ": "Lluís Ros",
    "eXnKggEAAAAJ": "Federico Thomas",
    "LZUyMg8AAAAJ": "Enric Celaya",
    "qU1NHTwAAAAJ": "Ben Krose",
    "NTozWbQAAAAJ": "Juan Andrade-Cetto",
    "izeB4QsAAAAJ": "Oriol Bohigas",
    "Pgor6i8AAAAJ": "Carlos J. Rosales Gallegos",
    "u7oMoQMAAAAJ": "Ricard Bordalba",
    "NAGHvJIAAAAJ": "Montserrat Manubens",
    "HeaQbWsAAAAJ": "Viorela Ila",
    "JJWWPjsAAAAJ": "Nikos Vlassis",
    "twSIZSEAAAAJ": "Matthijs TJ Spaan",
    "JHNm8PMAAAAJ": "Demetrio Raldua",
    "yCaVmHIAAAAJ": "Soheil Sarabandi",
    "bgpBDU4AAAAJ": "Eva Prats",
    "raAzOHoAAAAJ": "Rafael Valencia",
    "ePfXtkoAAAAJ": "Michael E Henderson",
    "uMPWVtIAAAAJ": "Leobardo Manuel Gómez-Oliván",
    "kRdfhVQAAAAJ": "JULIETTE BEDROSSIANTZ",
    "QKw1XxAAAAAJ": "Eric Demeester",
    "KhAJWroAAAAJ": "Pascal Poupart",
    "H_e0wfMAAAAJ": "Raul Suarez",
    "H28xhwQAAAAJ": "Tom Creemers",
    "b4NaZMoAAAAJ": "caterina faggio",
    "Snxa14EAAAAJ": "Natalia Garcia-Reyero",
    "Tlm978oAAAAJ": "Carlos Barata",
    "aajhzaQAAAAJ": "Juan Jesus Perez",
    "HcB81j4AAAAJ": "Martí Morta-Garriga",
    "m1eoR-cAAAAJ": "Vicente Ruiz de Angulo",
    "Hm0UA64AAAAJ": "Juan Cortés",
    "LxsF51oAAAAJ": "Tobias Schoels",
    "ItkapK8AAAAJ": "Jordi Mestres",
    "WsNt9VoAAAAJ": "Cecilia Jimenez-Mallebrera",
    "5u4IlBYAAAAJ": "João Pestana",
    "cplKIP8AAAAJ": "Amadeu Soares",
    "SJctjYgAAAAJ": "Marco Carricato",
    "wC19wG0AAAAJ": "Tommaso Marchi",
    "lrOLKgQAAAAJ": "Adrián Bazaga",
    "JEwMX6wAAAAJ": "Moritz Diehl",
    "2mOtJU4AAAAJ": "Giovanni Mottola",
    "1GgfFDUAAAAJ": "Adnan Sljoka",
    "pn1-9nIAAAAJ": "Walter Whiteley",
    "vdMXuXgAAAAJ": "Bernd Schulze",
    "TucFZBUAAAAJ": "Patrick Grosch",
    "PvoHev4AAAAJ": "Nicolas Rojas",
    "joagTAoAAAAJ": "Cristiana Roberta Multisanti",
    "9UAk6Y0AAAAJ": "Elisabet Golobardes Ribé",
    "gxoPfIYAAAAJ": "Sebastian Scherer",
    "of_W1_MAAAAJ": "Aditya Mandalika",
    "238DAAEAAAAJ": "Sankalp Arora",
    "WFgFAB8AAAAJ": "Rogerio Bonatti",
    "PryclcMAAAAJ": "Wenshan Wang",
    "uIBzJWIAAAAJ": "Debadeepta Dey",
    "wCNY8ZYAAAAJ": "Oren Salzman",
    "m4QAC_EAAAAJ": "Vishal Dugar",
    "9W1jAhEAAAAJ": "Jonathan Gammell",
    "th3BO8MAAAAJ": "Stephen Nuske",
    "DJ6mzSUAAAAJ": "Jeongseok Lee",
    "vPnu7C4AAAAJ": "Shushman Choudhury",
    "W7yeGUoAAAAJ": "Alonzo Kelly",
    "Uva82JYAAAAJ": "Fernando Perez",
    "pCOmQzsAAAAJ": "Matthias Bussonnier",
    "6_i63vgAAAAJ": "Brian E. Granger",
    "xSC3VSAAAAAJ": "Benjamin Ragan-Kelley",
    "Actb5ZYAAAAJ": "Carol Willing",
    "7zk-lgMAAAAJ": "Kyle Kelley",
    "o_ARklQAAAAJ": "Sylvain Corlay",
    "QZW0vl8AAAAJ": "Paul Ivanov",
    "IIci8lAAAAAJ": "Jason Grout",
    "d1oQ8NcAAAAJ": "Alvaro Sanchez Gonzalez",
    "LZxqcX4AAAAJ": "Theophane Weber",
    "95mnc80AAAAJ": "Victor Bapst",
    "jNtH2WUAAAAJ": "Kimberly Lauren Stachenfeld",
    "KKVV2nMAAAAJ": "Kevin R. McKee",
    "_9pmXcsAAAAJ": "Tina O. Zhu",
    "Op4nexcAAAAJ": "Tatiana López-Guevara",
    "aXNBOywAAAAJ": "John V McDonnell",
    "z7inLV8AAAAJ": "Alexander S Rich",
    "lXiXiHAAAAAJ": "Doug Markant",
    "KqVuUA0AAAAJ": "Anna Coenen",
    "GzqY7SAAAAAJ": "David J. Halpern",
    "qa4M89wAAAAJ": "David Chan",
    "QOmjMZ0AAAAJ": "Jasmine Collins",
    "syjQhAMAAAAJ": "Andy Ballard",
    "lpswgyIAAAAJ": "Yazhe Li",
    "-cCry1cAAAAJ": "Fabio Viola",
    "K1GoYW8AAAAJ": "Alexander Neitz",
    "NUv7u80AAAAJ": "Bryanna Kaufmann",
    "Jv1FrfwAAAAJ": "Douglas Blank",
    "jWIWqfcAAAAJ": "John Aslanides",
    "jM6Y0yAAAAAJ": "Larisa Markeeva",
    "DdFjaEEAAAAJ": "Andrew Dudzik",
    "XcRQkcEAAAAJ": "Wilfried Bounsi",
    "uebYofUAAAAJ": "Alex Vitvitskyi",
    "mnVqk28AAAAJ": "Omar Shams",
    "_y14JooAAAAJ": "Thomas Morgan",
    "FF6YBwwAAAAJ": "Susan Hespos",
    "TJEUdh4AAAAJ": "Chaz Firestone",
    "RJeVHPYAAAAJ": "Erin M. Anderson",
    "88xDcnoAAAAJ": "Jan Balaguer",
    "ftEx984AAAAJ": "Madjiheurem Sephora",
    "mM_5lrMAAAAJ": "Alexander L. Brown",
    "bYjKaowAAAAJ": "Bonnie Berger",
    "yZbch0cAAAAJ": "Po-Ru Loh",
    "QkYiDCwAAAAJ": "Piotr Kozakowski",
    "Se68XecAAAAJ": "Piotr Miłoś",
    "TqUN-LwAAAAJ": "Aäron van den Oord",
    "Xc4IOBEAAAAJ": "Brendan Bulik-Sullivan",
    "-OVm5iMAAAAJ": "Nick Patterson",
    "F36qnN0AAAAJ": "Bjarni J. Vilhjalmsson",
    "Es2BBeYAAAAJ": "Carlos Riquelme",
    "cojpd10AAAAJ": "Vinayagam Arunachalam",
    "YG6mTEIAAAAJ": "Ihab F. Ilyas",
    "GFQzUKoAAAAJ": "Kanji Uchino",
    "J5Nwk-UAAAAJ": "Desney Tan",
    "1PEHzesAAAAJ": "Shital Shah",
    "hH3DA2YAAAAJ": "Rosalind Picard",
    "FlY-U3kAAAAJ": "Krysta M. Svore",
    "DSgKHOQAAAAJ": "Nathan Wiebe",
    "LHkrpqEAAAAJ": "Mary Czerwinski",
    "hma0WFAAAAAJ": "James Fogarty",
    "IHPRZuMAAAAJ": "Shuang Ma",
    "ShGrv3kAAAAJ": "Chris Lovett",
    "4F9L0-cAAAAJ": "Ratnesh Madaan",
    "XBjhKdoAAAAJ": "GIREEJA RANADE",
    "xlSoLCYAAAAJ": "Arthur Fender C Bucker",
    "B3ywvIcAAAAJ": "Jayesh K. Gupta",
    "nek5vXMAAAAJ": "Amy K. Karlson",
    "9huOSj4AAAAJ": "Wenhao Luo",
    "1hqOg28AAAAJ": "Mike Roberts",
    "rjqOWi4AAAAJ": "Eric Cristofalo",
    "EsIJmL0AAAAJ": "Tim Taubner",
    "QKhjs2YAAAAJ": "Markus Meister",
    "nVWQwHkAAAAJ": "Yang Liu",
    "eUW2DUEAAAAJ": "Dean Zadok",
    "HqGW4HIAAAAJ": "Amar Phanishayee",
    "qWGk7FUAAAAJ": "John Krumm",
    "Ec8g_QwAAAAJ": "Kayur Patel",
    "-fUDeigAAAAJ": "Ekaterina I Tolstaya",
    "ZoW-xfcAAAAJ": "David Zhao",
    "lQn_FEoAAAAJ": "Prem Kumar Kalra",
    "rFcdDJEAAAAJ": "Maximilian Igl",
    "lEzcLFwAAAAJ": "Luisa Zintgraf",
    "WsRunnEAAAAJ": "Leo Feng",
    "yMGBji4AAAAJ": "Cong Lu",
    "7TVJf1gAAAAJ": "Mattie Fellows",
    "2m-p8FcAAAAJ": "Sasha Salter",
    "9b64ixMAAAAJ": "Walter Goodwin",
    "rQkl8gIAAAAJ": "Marco Bondaschi",
    "EnNwKLgAAAAJ": "Ashwin Hebbar",
    "Jr2CK6QAAAAJ": "Chanakya Ekbote",
    "F6x3R1oAAAAJ": "Suma Bhat",
    "Km1V8WwAAAAJ": "Vivek Borkar",
    "WcXt6YQAAAAJ": "Jasmine Hsu",
    "G7XaqUcAAAAJ": "Saminda Abeyruwan",
    "0NHagNQAAAAJ": "Laura Graesser",
    "FJO1bnsAAAAJ": "David B. D'Ambrosio",
    "kwTTDPMAAAAJ": "Benoit Corda",
    "FBVwO5wAAAAJ": "Mohit Sharma",
    "928yXx4AAAAJ": "Rinon Gal",
    "zLuqh-0AAAAJ": "Ethan Fetaya",
    "aeGDj-IAAAAJ": "Uri Shalit",
    "L3KXa3cAAAAJ": "Eytan Ruppin",
    "N-sME4wAAAAJ": "Aviv Navon",
    "ZYEgD7wAAAAJ": "Eli Meirom",
    "UQIBiUcAAAAJ": "Idan Achituve",
    "_CWxQ1gAAAAJ": "Dvir Samuel",
    "-SlS0mgAAAAJ": "Or Patashnik",
    "uvaPP80AAAAJ": "Yuval Alaluf",
    "NfJiSMMAAAAJ": "Gal Dalal",
    "VSCSNhMAAAAJ": "Yoad Tewel",
    "sJJamz4AAAAJ": "Richard F. Lyon",
    "C4i_vUMAAAAJ": "Rami Ben-Ari",
    "kwZTvH4AAAAJ": "Daphna Weinshall",
    "d-3sFxQAAAAJ": "Noa Liscovitch-Brauer",
    "jHCgT18AAAAJ": "Zheyun Feng",
    "Sc2tw28AAAAJ": "Tom J Duerig",
    "IwSe1-MAAAAJ": "Yossi Matias",
    "IhMQa-MAAAAJ": "Ella Podvalny",
    "qQgUtucAAAAJ": "Misha Tsodyks",
    "opVT1qkAAAAJ": "Gilad Yehudai",
    "2EaTkYEAAAAJ": "Hrishikesh Aradhye",
    "Vz8AQ6oAAAAJ": "Jay Yagnik",
    "zblQKM8AAAAJ": "Tanmay Gupta",
    "C7cw4msAAAAJ": "Sharon Gannot",
    "7Mxp9d4AAAAJ": "Shlomit Beker, PhD",
    "lyh8wacAAAAJ": "Naama Friedmann",
    "wJR3IY4AAAAJ": "Nachman ash",
    "ItOvQJ4AAAAJ": "Erez Levanon",
    "VBMuQbsAAAAJ": "Rony Paz",
    "9XJL-qMAAAAJ": "Gil Zalsman MD MHA BSc",
    "wsGvgA8AAAAJ": "Noam Shazeer",
    "mOG0bwsAAAAJ": "Jakob Uszkoreit",
    "oR9sCGYAAAAJ": "Ashish Vaswani",
    "3SyxFIAAAAAJ": "Illia Polosukhin",
    "dN9QZfEAAAAJ": "Anselm Levskaya",
    "mvojJ2MAAAAJ": "Ben D Goodrich",
    "MmX7K38AAAAJ": "Mohammad Saleh",
    "e1GAF6sAAAAJ": "Étienne Pot",
    "VfYhf2wAAAAJ": "François Chollet",
    "MiHOX3QAAAAJ": "Mostafa Dehghani",
    "4TbxnY0AAAAJ": "Erich Grädel",
    "Lh_ZqdcAAAAJ": "Alexander Ku",
    "VWEg9YQAAAAJ": "Dietmar Berwanger",
    "AxGhhfsAAAAJ": "Enrique Alfonseca",
    "es9clvEAAAAJ": "Roman Rabinovich",
    "8AtDeScAAAAJ": "Bárány Vince",
    "sybphw0AAAAJ": "Łukasz Stafiniak",
    "y80AokkAAAAJ": "Srinivas Devadas",
    "-lQSzAwAAAAJ": "Khalid Ashraf",
    "YZHj-Y4AAAAJ": "William Dally",
    "MV8KGT0AAAAJ": "Sharad Malik",
    "3ACMPEQAAAAJ": "David Chinnery",
    "POm0zXkAAAAJ": "William Plishker",
    "v-ab1_kAAAAJ": "Jike Chong",
    "zT8cqLkAAAAJ": "Dennis Sylvester",
    "YrihYtsAAAAJ": "Rastislav Bodik",
    "1_zc1-IAAAAJ": "Brian (Bo) Li",
    "MBiIblMAAAAJ": "Kaushik Ravindran",
    "vae65B0AAAAJ": "Michael Orshansky",
    "SormeOgAAAAJ": "John Shalf",
    "qlmK27YAAAAJ": "Katie Z Luo",
    "Zrs0wpEAAAAJ": "Diane Havlir",
    "YI1SAjUAAAAJ": "Moses R Kamya",
    "hbriwLcAAAAJ": "Edwin Charlebois",
    "dSU9MtYAAAAJ": "Laura B. Balzer, PhD MPhil",
    "hhu_TQsAAAAJ": "Jane Kabami",
    "EdV_R7oAAAAJ": "Craig R Cohen",
    "O0VelhkAAAAJ": "Elvin Geng",
    "l92sxGEAAAAJ": "Asiphas Owaraganise",
    "azSz1VYAAAAJ": "Carina Marquez",
    "lZ9KLP0AAAAJ": "Harsha Thirumurthy",
    "wmjk13MAAAAJ": "Susana Rojas Pernia",
    "67eC0RcAAAAJ": "James Peng",
    "PP6LKtYAAAAJ": "David Bangsberg",
    "cVHKEaoAAAAJ": "John Schrom",
    "iX-72m8AAAAJ": "Romain Pirracchio",
    "dzP4uYEAAAAJ": "francisco bastos",
    "k6-1woQAAAAJ": "Steven G. Deeks",
    "WNYs930AAAAJ": "Arthur L. Reingold",
    "EjXmTH4AAAAJ": "John Kelsey",
    "WN9t4n0AAAAJ": "Serge Egelman",
    "G7_tE4wAAAAJ": "Adrienne Porter Felt",
    "_7x84lgAAAAJ": "David Molnar",
    "bsDeOEoAAAAJ": "Naveen Sastry",
    "n-Oret4AAAAJ": "Adrian Perrig",
    "bzsYmwYAAAAJ": "Erika Chin",
    "mdPnGScAAAAJ": "Chris Hall",
    "jjXriQwAAAAJ": "Matthew S. Finifter",
    "4VJre9IAAAAJ": "John Stankovic",
    "zRQMWrkAAAAJ": "Primal Wijesekera",
    "tP5rH0wAAAAJ": "Alex Biryukov",
    "gUEkPQEAAAAJ": "Phillip Rogaway",
    "YYcTN2EAAAAJ": "Rob Johnson",
    "EASHOTUAAAAJ": "Grant Ho",
    "YayQtGUAAAAJ": "Lars Ramkilde Knudsen",
    "hOlkT4sAAAAJ": "Cynthia Sturton",
    "-tTv7oYAAAAJ": "Antonio Barresi",
    "QWPwfsgAAAAJ": "Jeffrey S. Foster",
    "xVzAml0AAAAJ": "Konstantin Beznosov",
    "9cFCY5wAAAAJ": "Mathias Payer",
    "lRwkspgAAAAJ": "Devdatta Akhawe",
    "d87RjDgAAAAJ": "Arjun Baokar",
    "0MkHY9cAAAAJ": "Micah Sherr",
    "7D7IaJ4AAAAJ": "Thurston Dang",
    "E3wyDhUAAAAJ": "Mike Stay",
    "1GjHPkcAAAAJ": "Michael McCoyd",
    "KWez2_sAAAAJ": "Aviel D. Rubin",
    "kZch-sMAAAAJ": "Helger Lipmaa",
    "sDiiVkcAAAAJ": "Nathan Good",
    "kek70IwAAAAJ": "Christopher Thompson",
    "ICzsaEsAAAAJ": "Rebecca Sorla Portnoff",
    "v4UZWmcAAAAJ": "Derek Leung",
    "eUHFqm4AAAAJ": "Steven Chen",
    "jyk2KYEAAAAJ": "Michael Theodorides",
    "flCzpwcAAAAJ": "Clay Shields",
    "ZcPi_0wAAAAJ": "Tavish Vaidya",
    "BxkylVAAAAAJ": "Yuankai Zhang",
    "Nr6E_rIAAAAJ": "Wenchao Zhou",
    "MvKQ0B4AAAAJ": "Anne Edmundson",
    "TXTlU3sAAAAJ": "Jason Waddle",
    "o3PQcYgAAAAJ": "Dan Tsafrir",
    "b32YyLIAAAAJ": "Dilma Da Silva",
    "sTwMEA8AAAAJ": "Nicolas T. Courtois",
    "P1XH4nkAAAAJ": "Sakshi Jain",
    "_JhgbioAAAAJ": "Stefan Savage",
    "mmEb3AwAAAAJ": "Aashish Sharma",
    "JvY2c4YAAAAJ": "Paul Pearce",
    "RPPi79MAAAAJ": "Irwin Reyes",
    "HfGUt6AAAAAJ": "Tomer Hertz",
    "yKzSdygAAAAJ": "Asaf Cidon",
    "JvUypEMAAAAJ": "Alec Yasinsac",
    "B7xbi_QAAAAJ": "Deirdre K. Mulligan",
    "GveGRr0AAAAJ": "Brian Holtkamp",
    "Sdz9YPMAAAAJ": "Kerwell Liao",
    "UIM7nGwAAAAJ": "Supriyo Chakraborty",
    "h6yXnyEAAAAJ": "J. Alex Halderman",
    "_rJCgzIAAAAJ": "Matthew Hicks",
    "ca7sXDUAAAAJ": "Samuel T King",
    "h1FDASIAAAAJ": "Won Park",
    "_4i-G3YAAAAJ": "Theodore P. (Ted) Baker",
    "PswI6pYAAAAJ": "Michael Shamos",
    "ehv7qvIAAAAJ": "Breno de Medeiros",
    "_jOpRuIAAAAJ": "Laura Quilter",
    "01YOPpAAAAAJ": "Joshua Tan",
    "RGtMwTgAAAAJ": "Tom Magrino",
    "YTmGBNsAAAAJ": "Eric Kim",
    "FIpwvjsAAAAJ": "Monica Chew",
    "VLft_T4AAAAJ": "Matthew Robshaw",
    "wR84XY1kACcC": "Raphaël C.-W. Phan",
    "471mb4wAAAAJ": "Ariel J. Feldman",
    "_MsNwIsAAAAJ": "Kai Wang",
    "4e2pnKYAAAAJ": "Nicholas Hopper",
    "IyGPTacAAAAJ": "Leonie Simpson",
    "NozmrNYAAAAJ": "Edward Dawson",
    "E0NwK2AAAAAJ": "Hovav Shacham",
    "AFGPpWoAAAAJ": "Joseph Lorenzo Hall",
    "OBiA-IAAAAAJ": "Poorvi L. Vora",
    "O5jENBMAAAAJ": "Jennifer King, PhD",
    "DC7FtVYAAAAJ": "Maritza Johnson",
    "wPNgzO4AAAAJ": "Susmit Jha",
    "MlPFWbgAAAAJ": "Rohit Sinha",
    "XFtrWVsAAAAJ": "Joel Weinberger",
    "BEGRf_EAAAAJ": "Ben Reichardt",
    "891RunEAAAAJ": "Michael Clarkson",
    "-Z4XFnEAAAAJ": "Keaton Mowery",
    "zBQxZrcAAAAJ": "Vincent Rijmen",
    "IQosWycAAAAJ": "Annie I. Antón",
    "1Aa3qxIAAAAJ": "Hao Chen",
    "ku59ZJoAAAAJ": "Khanh Nguyen",
    "NyoUvosAAAAJ": "Fuchun Peng",
    "Rn7APGIAAAAJ": "Russ Greiner",
    "Q7VKnRYAAAAJ": "Yuhong Guo",
    "-WFwzjoAAAAJ": "Mohamed Elgendi",
    "MsuY1TsAAAAJ": "Linli Xu",
    "jrkrn3sAAAAJ": "Xinhua Zhang",
    "35zn-2cAAAAJ": "Daniel Lizotte",
    "PYtPCHoAAAAJ": "Michael Bowling",
    "dKNkD3sAAAAJ": "Finnegan Southey",
    "EBeIYOwAAAAJ": "Xiangji Huang (Jimmy Huang)",
    "t5zdD_IAAAAJ": "Martha White",
    "9IRFiEQAAAAJ": "Li Cheng",
    "i0oFmt0AAAAJ": "James Neufeld",
    "E9ZX2lgAAAAJ": "Terry Caelli",
    "fXRXgPMAAAAJ": "Junfeng Wen",
    "VvdtcWcAAAAJ": "Dekang Lin",
    "tqcSvFIAAAAJ": "SVN Vishwanathan",
    "XSgTV7gAAAAJ": "Guohui Lin",
    "GnR3Y60AAAAJ": "Tiberio Caetano",
    "3_002c0AAAAJ": "Robert Holte",
    "I-rLzGcAAAAJ": "Novi Quadrianto",
    "nrE1OroAAAAJ": "Shane Bergsma",
    "d32BmwcAAAAJ": "Vikas Singh",
    "__CwaPMAAAAJ": "Lopamudra Mukherjee",
    "TNr_OWMAAAAJ": "Colin Cherry",
    "kV4N4zoAAAAJ": "James Evans",
    "ZDG9RD8AAAAJ": "Yujin Potter",
    "O__9HOwAAAAJ": "Junsol Kim",
    "qALDmfcAAAAJ": "Shiyang Lai",
    "3Ir65ZkAAAAJ": "Philippe Rigollet",
    "FL61g6wAAAAJ": "Yuantao Gu",
    "Do8MrDYAAAAJ": "Paxton Turner",
    "oVxK8g0AAAAJ": "Alex Dytso",
    "EzvMOjkAAAAJ": "Feng Liang",
    "MBKRLlgAAAAJ": "Caitlyn Heqi Yin",
    "Dq93mOUAAAAJ": "HV Poor",
    "Y6vuiBUAAAAJ": "Mohammad Hossein Yassaee",
    "VatfufAAAAAJ": "Haresh Karnan",
    "f28F1YUAAAAJ": "Joydeep Biswas",
    "unQVOJkAAAAJ": "Zhiyuan Zhou",
    "AFgYa68AAAAJ": "Randal Bryant",
    "zwA5eokAAAAJ": "Wenchao Li",
    "-TFCgqsAAAAJ": "Ashish Tiwari",
    "0PzT1VoAAAAJ": "Shuvendu Lahiri",
    "EqIVfYcAAAAJ": "Shaz Qadeer",
    "qVzY4XYAAAAJ": "Natarajan Shankar",
    "h0R3z64AAAAJ": "Ofer Strichman",
    "Jok8C54AAAAJ": "Daniel Holcomb",
    "5o111aIAAAAJ": "Orna Kupferman",
    "pbhFW1kAAAAJ": "Marco Di Natale",
    "friM_CIAAAAJ": "Stephen Freund",
    "V828uG8AAAAJ": "Madhusudan Parthasarathy",
    "ToU9KBUAAAAJ": "Jim Mainprice",
    "kqkq_coAAAAJ": "Manuel Lopes",
    "d-jF4zIAAAAJ": "Christian Igel",
    "GrpsKVsAAAAJ": "Nikolay Jetchev",
    "oU2jyxMAAAAJ": "Michael Gienger",
    "IDF-ar0AAAAJ": "Philipp Kratzer",
    "xk1gsM8AAAAJ": "Ngo Anh Vien",
    "VzJAvWEAAAAJ": "Duy Nguyen-Tuong",
    "zStLMKIAAAAJ": "Konrad Rawlik",
    "jk0gVL8AAAAJ": "Johannes Kulick",
    "k9Hczv4AAAAJ": "Andreas Doerr",
    "q_n7d6EAAAAJ": "Shlomo Zilberstein",
    "WHZiLTIAAAAJ": "Akshat Kumar",
    "iGLS8hMAAAAJ": "Robert Lieck",
    "ZyA-aKQAAAAJ": "Thibaut Munzer",
    "rvKJDbIAAAAJ": "Chris Williams",
    "uDLRZQMAAAAJ": "Edwin V. Bonilla",
    "RHYFcckAAAAJ": "Andrea Baisero",
    "p_837e0AAAAJ": "Cristopher Moore",
    "CUqzFcEAAAAJ": "Robert M. Ziff",
    "j2yC2GQAAAAJ": "Stefan Boettcher",
    "VvgVKVYAAAAJ": "Jon Machta",
    "UW3tRn8AAAAJ": "Simon DeDeo",
    "GlIyobYAAAAJ": "Lavanya Sharan",
    "4Ma6NAYAAAAJ": "Tony Movshon",
    "6ggnUzYAAAAJ": "David J Heeger",
    "GTmdNU0AAAAJ": "Ron Dror",
    "Vwas7kAAAAAJ": "Bobak Shahriari",
    "Tom5l8EAAAAJ": "David Budden",
    "n2osZaoAAAAJ": "Matthew W. Hoffman",
    "skyUvycAAAAJ": "SM Ali Eslami",
    "iW_lUIkAAAAJ": "Janos Kramar",
    "afpYZisAAAAJ": "Masrour Zoghi",
    "YUrxwrkAAAAJ": "Frank Hutter",
    "uc4Q6bYAAAAJ": "David Matheson",
    "MMRpEk0AAAAJ": "Firas Hamze",
    "siCYLcUAAAAJ": "Zichao Yang",
    "c_mh0i0AAAAJ": "Nimalan Mahendran",
    "DwHtHE8AAAAJ": "Yannis Assael",
    "lZKlDFcAAAAJ": "Alexander Cumberworth",
    "47sihrsAAAAJ": "Ashraf Aboulnaga",
    "dxBYu1AAAAAJ": "Yishu Miao",
    "mJB-HiIAAAAJ": "Chris Mattmann",
    "i-AStBYAAAAJ": "Sjoerd van Steenkiste",
    "BiCxWC0AAAAJ": "Sidhant Kaushik",
    "aQcYWDMAAAAJ": "William Whitney",
    "MbXKAK8AAAAJ": "Jake C. Snell",
    "tuBQ_uwAAAAJ": "Bhishma Dedhia",
    "KBRHCEEAAAAJ": "Tsung-Hsiang Chang",
    "6IvhxBkAAAAJ": "Michael Skirpan",
    "klWjaQIAAAAJ": "Ryo Suzuki",
    "Nv2jil0AAAAJ": "Andrew Miller",
    "EdROb6UAAAAJ": "Bo Xie, PhD, Professor",
    "D9LfKkAe7d0C": "Casey Fiesler",
    "2COOamwAAAAJ": "Mary Lou Maher",
    "LBfy6oMAAAAJ": "Kazjon Grace",
    "7ftnjtEAAAAJ": "Carol L. Boston",
    "CXB-29IAAAAJ": "Greg Walsh",
    "59O0DBIAAAAJ": "Man Huang",
    "-9acvogAAAAJ": "Haruki Takahashi",
    "_4EISRwAAAAJ": "Katharina Reinecke",
    "9UoNgkYAAAAJ": "Rahmatri Mardiko",
    "0EWw1z8AAAAJ": "Jimmy Lin",
    "mhmvCgsAAAAJ": "Jennifer Mankoff",
    "xSZXqZQAAAAJ": "Anhong Guo",
    "IcW1vJEAAAAJ": "Benjamin B. Bederson",
    "AkEXTbIAAAAJ": "Vishal M. Patel",
    "s9B5sagAAAAJ": "Krist Wongsuphasawat",
    "I2W13z0AAAAJ": "Xiang 'Anthony' Chen",
    "FdNuUb8AAAAJ": "Boris Katz",
    "UOv-ce4AAAAJ": "Yan Chen",
    "jgqZbREAAAAJ": "Mohammed E. Fathy",
    "k8Ovqo8AAAAJ": "Alexander J. Quinn",
    "3SDKldkAAAAJ": "Ian Char",
    "X3FwUngAAAAJ": "Veronica Dahl",
    "xjzc-TwAAAAJ": "Amy Hurst",
    "V8RKLEsAAAAJ": "Sriram Sankaranarayanan",
    "ml-AyBQAAAAJ": "Fredrik D. Johansson",
    "sU6x0E0AAAAJ": "Yoni Halpern",
    "R4Q7jzgAAAAJ": "Monica Agrawal",
    "AK_7EBgAAAAJ": "Yacine Jernite",
    "_xWMxrQAAAAJ": "Hunter Lang",
    "o1IZjggAAAAJ": "Michael Oberst",
    "ilJgXHkAAAAJ": "Rahul G. Krishnan",
    "XCfZyIkAAAAJ": "Hussein Mozannar",
    "lr1JM5MAAAAJ": "Narges Razavian",
    "4Ea9RSkAAAAJ": "Larry Nathanson",
    "jHD1kUsAAAAJ": "Aaron Smith-McLallen",
    "_U02AlsAAAAJ": "Nathan Shapiro",
    "q__pgY9AkUQJ": "Kevyn Collins-Thompson",
    "V0K3gs0AAAAJ": "Shannon Zejiang Shen",
    "f6uvd6kAAAAJ": "Zhengping Che",
    "Q0iwucYAAAAJ": "Sanjay Purushotham",
    "okjycNEAAAAJ": "Alejandro Buendia",
    "29FPauoAAAAJ": "Zeshan M Hussain",
    "RdPknzsAAAAJ": "Sanjat Kanjilal",
    "9Kz5vKYAAAAJ": "Rebecca (Peyser) Boiarsky",
    "omfoflQAAAAJ": "Bhaskara Marthi",
    "_td9cSEAAAAJ": "Xiaoyi Jiang",
    "glNJx5zYUbsC": "Omer Gottesman",
    "DzSgRSoAAAAJ": "Leora Horwitz",
    "r4ldy4AAAAAJ": "Dennis Wei",
    "3JfHObUAAAAJ": "Sebastian de la Chica",
    "eoBHpj4AAAAJ": "Anitha Kannan",
    "YYUK51oAAAAJ": "Xavier(Xavi) Amatriain",
    "FjCbjDYAAAAJ": "Fei Wang, FAMIA, FIAHSI, FACMI",
    "f1wmyEkAAAAJ": "Ming-Chieh Shih",
    "_-KE7lIAAAAJ": "Jamie E Collins",
    "or0oVL0AAAAJ": "Xiang Wang",
    "X3RNgQMAAAAJ": "Andrew C. Miller",
    "SDavuPAAAAAJ": "Sam Wiseman",
    "lCgSjYAAAAAJ": "Juan M. Banda",
    "iUgCzvgAAAAJ": "Bodo Billerbeck",
    "kV9XRxYAAAAJ": "Samuel R. Bowman",
    "j5o1jkEAAAAJ": "Avi Ma'ayan",
    "8bVtuOwAAAAJ": "Kui Tang",
    "x5wW5WIAAAAJ": "Shalmali Joshi",
    "mDLwSZAAAAAJ": "Hung Bui",
    "hFjNgPEAAAAJ": "Josua Krause",
    "anxumroAAAAJ": "Dokook Choe",
    "SUNF5HMAAAAJ": "David Chiu",
    "x_OUOncAAAAJ": "Joshua W Joseph",
    "KtnTuq8AAAAJ": "Ankit Vani",
    "fopP3AsAAAAJ": "Yuanjun Xia",
    "KkkebI8AAAAJ": "Joarder Kamruzzaman",
    "U6AIrqwAAAAJ": "Alireza Abbasi",
    "EZ4qNDUAAAAJ": "Laihang Yu",
    "6THqxEoAAAAJ": "Hamad Naeem",
    "_2ofK_kAAAAJ": "Abhinav Kumar",
    "1nxepREAAAAJ": "James Propp",
    "KntSJpQAAAAJ": "Maryna Viazovska",
    "Ne3wr9oAAAAJ": "Danylo Radchenko",
    "CigslP0AAAAJ": "Joshua A. Grochow",
    "qPP9-msAAAAJ": "Achill Schürmann",
    "b55hlmIAAAAJ": "Amirhossein Tajdini",
    "IYqleYUAAAAJ": "Thomas Hartman",
    "okx33sUAAAAJ": "Nadia Heninger",
    "iLJcSEsAAAAJ": "Richard Kenyon",
    "6ywZAeEAAAAJ": "Thomas Church",
    "5HACNJ0AAAAJ": "David de Laat",
    "cPDxYXMAAAAJ": "Yael Tauman Kalai",
    "KA8dgpMAAAAJ": "Shafi Goldwasser",
    "RnVPcI0AAAAJ": "Will Sawin",
    "9uRDTmUAAAAJ": "Eric Naslund",
    "6mxddyMAAAAJ": "Nina Holden",
    "zC9ANdcAAAAJ": "Felipe Gonçalves",
    "iFYov5EAAAAJ": "Greg (Grigoriy) Blekherman",
    "-V1rJ8wAAAAJ": "Brandon Ballinger",
    "xEidIpMAAAAJ": "Noah Giansiracusa",
    "XBk56N0AAAAJ": "Nir Bitansky",
    "0-I8YNgAAAAJ": "Andrew Salmon",
    "MY1FRYUAAAAJ": "Shirshendu Ganguly",
    "xkn_XZgAAAAJ": "Victor Veitch",
    "t3COq84AAAAJ": "Yang Jiao (焦阳)",
    "D6h2cTYAAAAJ": "Salvatore  Torquato",
    "jxrHPD4AAAAJ": "Kevin Pratt",
    "nqalmtQAAAAJ": "Douglas N Arnold",
    "3IUE2yQAAAAJ": "Nicholas Triantafillou",
    "1pFBWgoAAAAJ": "Nando Leijenhorst",
    "zujScxwAAAAJ": "Ji Yun Son",
    "UDKpJ0IAAAAJ": "Dingding Dong",
    "OHoU9Y4AAAAJ": "David Futer",
    "DqKSB-kAAAAJ": "Isaac Rajagopal",
    "qyPWUBcAAAAJ": "Priya Narasimhan",
    "GwEdlMkAAAAJ": "Jiaqi Tan",
    "wRXPnP8AAAAJ": "Soila Kavulya",
    "q9alvsoAAAAJ": "jianmin chen",
    "i16X9rUAAAAJ": "Eugene Marinelli",
    "sUXvfjUAAAAJ": "Sejoon Lim",
    "-spRnaQAAAAJ": "Javed Aslam",
    "9QO16LcAAAAJ": "Hai Leong Chieu",
    "n41KN9AAAAAJ": "Wei Lu",
    "zZNKHdEAAAAJ": "Denny Britz",
    "r0wOAikAAAAJ": "Ee-Peng Lim",
    "0tPCcKEAAAAJ": "Maximilian Lam",
    "8OVA7ucAAAAJ": "Tanmay Parekh",
    "wHHgs8UAAAAJ": "S. Jaya Nirmala",
    "myi68A4AAAAJ": "Harsimrat Singh",
    "7N4J31IAAAAJ": "Saket Dingliwal",
    "Hu2Ht28AAAAJ": "Arijit Biswas",
    "MEz23joAAAAJ": "Ajay Mandlekar",
    "T_mJiHoAAAAJ": "Fabio Ramos",
    "Ag_6KEgAAAAJ": "Alan Aspuru-Guzik",
    "RhN6jKIAAAAJ": "Ankit Goyal",
    "FwFFVdIAAAAJ": "Kourosh Darvish",
    "eFsEy1YAAAAJ": "Ishika Singh",
    "HYHTg_0AAAAJ": "Dylan Turpin",
    "OYd3hjYAAAAJ": "Marta Skreta",
    "iopH6wIAAAAJ": "Ziyi Wu",
    "mCjP0bAAAAAJ": "Liquan Wang",
    "3Br8x_gAAAAJ": "Konstantinos G. Derpanis",
    "oYlo1ycAAAAJ": "Silviu Pitis",
    "boebIUcAAAAJ": "Elliot Creager",
    "7wfzKHam13MC": "Masoud Moghani",
    "lSJavJUAAAAJ": "Alec Jacobson",
    "SAdQhg4AAAAJ": "Miroslav Bogdanovic",
    "XuQW7ogAAAAJ": "Yoav Artzi",
    "1Yu0vQkAAAAJ": "Ignat Georgiev",
    "eJVXK_EAAAAJ": "Hammad Mazhar",
    "ciragesAAAAJ": "Farbod Farshidian",
    "G5SAV7gAAAAJ": "Amir-massoud Farahmand",
    "JYMjWq8AAAAJ": "Shutong Zhang",
    "iVXG-IkAAAAJ": "Mayank Mittal",
    "1vEw_kgAAAAJ": "Richard Wildes",
    "qKz0qpoAAAAJ": "Albert Wilcox",
    "4FeC1wQAAAAJ": "Silvia Sellán",
    "QZVQEWAAAAAJ": "cewu lu",
    "PHi0YEQAAAAJ": "Weiyu Liu",
    "9aG3giMAAAAJ": "Qiang Zhang",
    "B8sRETUAAAAJ": "Yoshinobu Kawahara",
    "0zKusWIAAAAJ": "Tao Zhong",
    "bD8DWiEAAAAJ": "Steve Easterbrook",
    "1RmD-YsAAAAJ": "Andrea Tagliasacchi",
    "l8wQ39EAAAAJ": "Sara Sabour",
    "-1i9yccAAAAJ": "Mahdi Azizian",
    "kl4jZpAAAAAJ": "Sean D. Huver",
    "U3w720cAAAAJ": "Yu Sun",
    "Bgv4hAUAAAAJ": "Varun Giridhar",
    "RgIBwboAAAAJ": "Michael Poli",
    "Zb0NwBUAAAAJ": "Andrei Ioan Muresanu",
    "_zSP7YMAAAAJ": "Mozhgan Saeidi",
    "wnweG9UAAAAJ": "Haotian Xue",
    "K6-M7A4AAAAJ": "Atharva Mete",
    "2z7iDDUAAAAJ": "Yongxin Chen",
    "NzjKoWIAAAAJ": "Alper Atamturk",
    "fTgRyn4AAAAJ": "Randy Goebel",
    "uxsLx-0AAAAJ": "Jeremy A. Collins",
    "4HTITaMAAAAJ": "Rose Yu",
    "KVUCqGwAAAAJ": "Caelan Garrett",
    "6HwMeesAAAAJ": "Tan Nguyen",
    "ghpLm2cAAAAJ": "Yi-Ling Qiao",
    "b8d5wS-QfscC": "Aleksandr Petiushko",
    "4l2EoB0AAAAJ": "Walker Byrnes",
    "mMANqk8AAAAJ": "Stephen Balakirsky",
    "-A4wqWEAAAAJ": "Andrew I. Cooper",
    "4OBGbW0AAAAJ": "Jason E. Hein",
    "H1v0ztEAAAAJ": "Sami Haddadin",
    "-L0XFlMAAAAJ": "Andres Diaz-Pinto",
    "UFo0PcAAAAAJ": "Vickie Ye",
    "k6fOmQgAAAAJ": "Justin Kerr",
    "LltfiXgAAAAJ": "Alex Yu",
    "Ecy6lXwAAAAJ": "Brent Yi",
    "o_M5CBMAAAAJ": "Christoph Lassner",
    "ODr5lMgAAAAJ": "Chung Min Kim",
    "-d7Ib5UAAAAJ": "Silvia Zuffi",
    "OT1uf7kAAAAJ": "Ameesh Makadia",
    "IkpNZAoAAAAJ": "Richard Tucker",
    "wp1MXzsAAAAJ": "Evonne Ng",
    "1WYrlLkAAAAJ": "Federica Bogo",
    "0Ozzy4IAAAAJ": "Frederik Warburg",
    "j56HgqYAAAAJ": "Jason Y. Zhang",
    "VdmfIeUAAAAJ": "Qianqian Wang",
    "siW2DBoAAAAJ": "Jake Austin",
    "RqOzJR0AAAAJ": "David A. Ross",
    "6H0mhLUAAAAJ": "Ren Ng",
    "QLW0lzcAAAAJ": "Zhengqi Li",
    "WLk8ZikAAAAJ": "Shan Yang",
    "4B-C50EAAAAJ": "Shigeo Morishima",
    "0vZ20kgAAAAJ": "Ryota Natsume",
    "B3FqpjQAAAAJ": "Zeng Huang",
    "UV0IzT4AAAAJ": "Kamyar Salahi",
    "u8p5Y1EAAAAJ": "Alexander Kristoffersen",
    "yh7H1fIAAAAJ": "Abhik Ahuja",
    "g1n-MOEAAAAJ": "Giacomo Meanti",
    "eQ8ZIG4AAAAJ": "Michael Zollhoefer",
    "YMgdDBwAAAAJ": "Hanbyul Joo",
    "8EVs9AEAAAAJ": "Dandan Shan",
    "J7QDRmwAAAAJ": "Lea Müller",
    "Id8SJl8AAAAJ": "Roni Sengupta",
    "jxf3Qv0AAAAJ": "Carlos D. Castillo",
    "-9AvWrwAAAAJ": "Ijaz Akhter",
    "C3KJzwEAAAAJ": "Yinghao Huang (大湾区大学硕博RA招生中，见主页~)",
    "2sKLll8AAAAJ": "Zhe Cao",
    "D04RyEcAAAAJ": "Sam Pepose",
    "l9iNFaMAAAAJ": "Tim Brooks",
    "36NmvrMAAAAJ": "Shangzhe Wu",
    "gz1zcR4AAAAJ": "Shahar Kovalsky",
    "_wds938AAAAJ": "Dena Bazazian",
    "0gEOJSEAAAAJ": "Cornelia Fermuller",
    "7QmEsOwAAAAJ": "Aloimonos",
    "RUWfW-kAAAAJ": "Dejan Pangercic",
    "VGBlCk4AAAAJ": "Dr. Zoltán-Csaba Márton",
    "EpLo4l4AAAAJ": "Marc Mehu",
    "P9-oT8AAAAAJ": "Amélie Royer",
    "CUD7V78AAAAJ": "Jeff Pfaffmann"
  },
  "co_authors": {
    "8R35rCwAAAAJ": [
      "vfPE6hgAAAAJ",
      "vtwH6GkAAAAJ",
      "zBUwaGkAAAAJ",
      "1wLVDP4AAAAJ",
      "yy0UFOwAAAAJ",
      "DRnOvU8AAAAJ",
      "B8wslVsAAAAJ",
      "-gJkPHIAAAAJ",
      "ADkiClQAAAAJ",
      "T9To2C0AAAAJ",
      "l-la0GQAAAAJ",
      "1O83J5MAAAAJ",
      "5VaXUQsAAAAJ",
      "FwxfQosAAAAJ",
      "VT7peyEAAAAJ",
      "bh-uRFMAAAAJ",
      "NSWI3OwAAAAJ",
      "d5y4iKAAAAAJ",
      "BsOkXDsAAAAJ",
      "OFlBL2kAAAAJ",
      "UgHB5oAAAAAJ",
      "neGbgzYAAAAJ",
      "vYougn0AAAAJ",
      "aOklxsQAAAAJ",
      "6uIhh6MAAAAJ",
      "jERkdhIAAAAJ",
      "xUGZX_MAAAAJ",
      "znnl0kwAAAAJ",
      "yxUduqMAAAAJ",
      "7ShMBcwAAAAJ",
      "ITZ1e7MAAAAJ",
      "fA0rYxMAAAAJ",
      "PTS2AOgAAAAJ",
      "-WZcuuwAAAAJ",
      "BIwrJuQAAAAJ",
      "Ivot3fkAAAAJ",
      "DMTuJzAAAAAJ",
      "kg4bCpgAAAAJ",
      "C-ZlBWMAAAAJ",
      "0nPi5YYAAAAJ",
      "zvz6LIYAAAAJ",
      "itSa94cAAAAJ",
      "U_Jw8DUAAAAJ",
      "pqP5_PgAAAAJ",
      "3Y4egcYAAAAJ",
      "Vzr1RukAAAAJ",
      "wfGiqXEAAAAJ",
      "eVYhlDQAAAAJ",
      "Q6F3O0sAAAAJ",
      "2DBmo-wAAAAJ",
      "QxLpghAAAAAJ",
      "DkUUhXEAAAAJ",
      "_EJrRVAAAAAJ",
      "BOAOkNQAAAAJ",
      "sgsLkM0AAAAJ",
      "ZWH5jCwAAAAJ",
      "T7uctwYAAAAJ",
      "NpOg5soAAAAJ",
      "_ws9LLgAAAAJ",
      "8-p9CLsAAAAJ",
      "jrfFYAIAAAAJ",
      "7GSWYLQAAAAJ",
      "qlwwdfEAAAAJ",
      "GyoKzFwAAAAJ",
      "C2_ZXdcAAAAJ",
      "YGQs1AYAAAAJ",
      "UAwKvEsAAAAJ",
      "kukA0LcAAAAJ",
      "uA0kNBUAAAAJ",
      "UpZmJI0AAAAJ",
      "xBH73TYAAAAJ",
      "pouyVyUAAAAJ",
      "fmSHtE8AAAAJ",
      "krrh6OUAAAAJ",
      "BZBkjNYAAAAJ",
      "xegzhJcAAAAJ",
      "wtRVnsYAAAAJ",
      "OI7zFmwAAAAJ",
      "bdHgGgEAAAAJ",
      "e1P1rNkAAAAJ",
      "fpVf9QkAAAAJ",
      "ZaJEZpYAAAAJ",
      "vgfGtykAAAAJ",
      "SiBVfPUAAAAJ",
      "PpzsjioAAAAJ",
      "wCRav7EAAAAJ",
      "0Qr2IGwAAAAJ",
      "B96GkdgAAAAJ",
      "vS8b6GwAAAAJ",
      "78WTKm4AAAAJ",
      "xuLKJboAAAAJ",
      "zUJus70AAAAJ",
      "1HO5UacAAAAJ",
      "8iCb2TwAAAAJ",
      "5NGAbT4AAAAJ",
      "rRJ9wTJMUB8C",
      "2oy3OXYAAAAJ",
      "-5_ksIkAAAAJ",
      "QCBdB7AAAAAJ",
      "wb-DKCIAAAAJ",
      "d97bGd8AAAAJ",
      "dD7EpwQAAAAJ",
      "FWp7728AAAAJ",
      "iYN86KEAAAAJ",
      "i7V1kJgAAAAJ",
      "0uTu7fYAAAAJ",
      "ckZ7q_gAAAAJ",
      "T6PbwPIAAAAJ",
      "SgST3LkAAAAJ",
      "Ci-_QYIAAAAJ",
      "j_xavDQAAAAJ",
      "Uly5spMAAAAJ",
      "x04W_mMAAAAJ",
      "yABlzrsAAAAJ",
      "dnZ8udEAAAAJ",
      "84WzBlYAAAAJ",
      "9xDADY4AAAAJ",
      "JWmiQR0AAAAJ",
      "i38QlUwAAAAJ",
      "CP5x1yEAAAAJ",
      "wIDVzroAAAAJ",
      "DZ-fHPgAAAAJ",
      "t2X4Mg8AAAAJ",
      "kppa2vgAAAAJ",
      "mnAk4HIAAAAJ",
      "bslhbWgAAAAJ",
      "f2NAF7QAAAAJ",
      "KCdL5B0AAAAJ",
      "tcfl2hUAAAAJ",
      "EMDboA4AAAAJ",
      "_QlCijoAAAAJ",
      "ZKRs0oEAAAAJ",
      "5bc-9A4AAAAJ",
      "7c1B_fIAAAAJ",
      "todsDfQAAAAJ",
      "lRUi-A8AAAAJ",
      "lJwPbcUAAAAJ",
      "UAWfBEoAAAAJ",
      "U89FHq4AAAAJ",
      "wMjQdBcAAAAJ",
      "nGUcGrYAAAAJ",
      "zFNvU34AAAAJ",
      "eM916YMAAAAJ",
      "-QopmQoAAAAJ",
      "OSg3D9MAAAAJ",
      "mqpjAt4AAAAJ",
      "bQowYEYAAAAJ",
      "yyIoQu4AAAAJ",
      "8fztli4AAAAJ",
      "xaQuPloAAAAJ",
      "YTO4ex4AAAAJ",
      "B7oP0bIAAAAJ",
      "eIWg8NMAAAAJ",
      "Wd8_fOcAAAAJ",
      "CUlqK5EAAAAJ",
      "HaN8b2YAAAAJ",
      "n7hxT4oAAAAJ",
      "a3K-f2YAAAAJ",
      "dzOd2hgAAAAJ",
      "q-buMEoAAAAJ",
      "Vdu_sqwAAAAJ",
      "BAAZ_ysAAAAJ",
      "no_BfYgAAAAJ",
      "jH_7A6gAAAAJ",
      "BDmtLHsAAAAJ",
      "zp8V7ZMAAAAJ",
      "grQ_GBgAAAAJ",
      "aO8KpGcAAAAJ",
      "wMcPTbEAAAAJ",
      "uemlfQYAAAAJ",
      "Rne0FzEAAAAJ",
      "LAv0HTEAAAAJ",
      "i28fU0MAAAAJ",
      "gQpYbRsAAAAJ",
      "Ctp3igcAAAAJ",
      "wxnzyjwAAAAJ",
      "42m4tGIAAAAJ",
      "axX7PCwAAAAJ",
      "FUOEBDUAAAAJ",
      "bMZFLZ_V4goC",
      "xEWgxBsAAAAJ",
      "lS96SqoAAAAJ",
      "V42yp08AAAAJ"
    ],
    "bh-uRFMAAAAJ": [
      "9xDADY4AAAAJ",
      "UfbuDH8AAAAJ",
      "-ltRSM0AAAAJ",
      "mqpjAt4AAAAJ",
      "W8VIEZgAAAAJ",
      "P4nfoKYAAAAJ",
      "GHpxNQIAAAAJ",
      "mu5Y2rYAAAAJ",
      "3kDtybgAAAAJ",
      "nABXo3sAAAAJ",
      "pvyI8GkAAAAJ",
      "d97bGd8AAAAJ",
      "AEsPCAUAAAAJ",
      "-XCiamcAAAAJ",
      "vtwH6GkAAAAJ",
      "7OTD-LEAAAAJ",
      "gYiCq88AAAAJ",
      "ijmuZ0wAAAAJ",
      "APgaFK0AAAAJ",
      "YLOz1kgAAAAJ",
      "B96GkdgAAAAJ",
      "4V1nNm4AAAAJ",
      "DplAah0AAAAJ",
      "e9gUdKwAAAAJ",
      "Jp6Mz1sAAAAJ",
      "8R35rCwAAAAJ",
      "ID9QePIAAAAJ",
      "wRyjJfMAAAAJ",
      "rTw-pq0AAAAJ",
      "OZ7PjVoAAAAJ",
      "TmWYBeEAAAAJ",
      "12uhMdIAAAAJ",
      "bo0P2qYAAAAJ",
      "dzOd2hgAAAAJ",
      "jQl9RtkAAAAJ",
      "6Q-289IAAAAJ",
      "jyxO2akAAAAJ",
      "izZZAegAAAAJ",
      "t9HPFawAAAAJ",
      "D1okUccAAAAJ",
      "vfPE6hgAAAAJ",
      "XXUsEjsAAAAJ",
      "okcbLqoAAAAJ",
      "_kJ-zUYAAAAJ",
      "zXhuhtwAAAAJ",
      "X0EXfT8AAAAJ",
      "5MTY7-wAAAAJ",
      "mDNhPjAAAAAJ",
      "dnZ8udEAAAAJ",
      "NkzyCvUAAAAJ",
      "eml8HfQAAAAJ",
      "Y8O9N_0AAAAJ",
      "5JserkUAAAAJ",
      "p9RsPG4AAAAJ",
      "UpZmJI0AAAAJ",
      "2ItLnFgAAAAJ",
      "oOwNKsAAAAAJ",
      "Ivot3fkAAAAJ",
      "r81Ss1cAAAAJ",
      "B_FTboQAAAAJ",
      "DxoenfgAAAAJ",
      "z76PBfYAAAAJ",
      "Pk-959EAAAAJ",
      "t4dSV4YAAAAJ",
      "ScoZZPsAAAAJ",
      "o6LlkNMAAAAJ",
      "y1lVpBEAAAAJ",
      "ED5iKYYAAAAJ",
      "yA4rb60AAAAJ",
      "nXBQn7gAAAAJ",
      "LAv0HTEAAAAJ",
      "sJDqACEAAAAJ",
      "NmHgX-wAAAAJ",
      "XM97iScAAAAJ",
      "N_rVVG8AAAAJ",
      "a8Y2OJMAAAAJ",
      "UAwKvEsAAAAJ",
      "2X0cwhkAAAAJ",
      "n-B0jr4AAAAJ",
      "j8ULfMsAAAAJ",
      "gTWUZlsAAAAJ",
      "XP_Hxm4AAAAJ",
      "56EZh6YAAAAJ",
      "4D1n8scAAAAJ",
      "oizZKrsAAAAJ",
      "1TqAq5AAAAAJ",
      "e1P1rNkAAAAJ",
      "FyQAwaEAAAAJ",
      "hHkuxSUAAAAJ",
      "ZcWO2AEAAAAJ",
      "pfGI-KcAAAAJ",
      "MaSXNhUAAAAJ",
      "_DNzXTcAAAAJ"
    ],
    "a4unsk4AAAAJ": [
      "k-nF0qgAAAAJ",
      "aC55XVgAAAAJ",
      "euc0GX4AAAAJ",
      "9yRwkr4AAAAJ"
    ],
    "84WzBlYAAAAJ": [],
    "a_dbdxAAAAAJ": [],
    "aO8KpGcAAAAJ": [
      "iyDxq0EAAAAJ",
      "nTiSnwUAAAAJ",
      "yxUduqMAAAAJ",
      "hdTDzlQAAAAJ",
      "OP6ejqgAAAAJ",
      "DcV-5RAAAAAJ",
      "yDVn5LEAAAAJ",
      "2oy3OXYAAAAJ",
      "df-THM0AAAAJ",
      "5pKTRxEAAAAJ",
      "wSstCv0AAAAJ",
      "BgQkdsYAAAAJ",
      "IB_jPZ0AAAAJ",
      "ZvX1hXcAAAAJ",
      "bZ9oyW8AAAAJ",
      "3XLQbL8AAAAJ",
      "0mgEF28AAAAJ",
      "xRmmtzIAAAAJ",
      "Op-47sgAAAAJ",
      "LKv32bgAAAAJ",
      "HQRnt54AAAAJ",
      "0qfCL-QAAAAJ",
      "Fsz9BAUAAAAJ",
      "fn13u8IAAAAJ",
      "MzD8rjoAAAAJ",
      "LjsKfKYAAAAJ",
      "lMkTx0EAAAAJ",
      "ri1sE34AAAAJ",
      "2k5j4eMAAAAJ",
      "umivlPQAAAAJ",
      "siuZCjUAAAAJ",
      "chICXXMAAAAJ",
      "B96GkdgAAAAJ",
      "KcPrLhIAAAAJ",
      "8R35rCwAAAAJ",
      "LIJQ_ZYAAAAJ",
      "yy0UFOwAAAAJ",
      "-S_9ZRcAAAAJ",
      "OI7zFmwAAAAJ",
      "Y9CoR7QAAAAJ",
      "87nZphcAAAAJ",
      "Kzj3HC8AAAAJ",
      "FLJ86DwAAAAJ",
      "Qhe5ua0AAAAJ",
      "MDeIveMAAAAJ",
      "AIy7QHIAAAAJ",
      "POlWWAsAAAAJ",
      "84WzBlYAAAAJ",
      "_TkfqdgAAAAJ",
      "1p3dDesAAAAJ",
      "H3Uq3FcAAAAJ",
      "_7Q8uIYAAAAJ",
      "xMhGYpgAAAAJ",
      "BtwmZfQAAAAJ",
      "3F52RjoAAAAJ",
      "XqLiBQMAAAAJ",
      "78WTKm4AAAAJ",
      "8jVzL_YAAAAJ",
      "hiGI9v0AAAAJ",
      "LeshmV8AAAAJ",
      "gFLW9qcAAAAJ",
      "k7NgVSUAAAAJ",
      "E__5Lr0AAAAJ",
      "UE9jz_MAAAAJ",
      "qwCO618AAAAJ",
      "-j0q9B4AAAAJ",
      "67kghxAAAAAJ",
      "-9geUIIAAAAJ",
      "wy0FA1cAAAAJ",
      "yE4WT_0AAAAJ",
      "xVN3UxYAAAAJ",
      "czxMUzcAAAAJ",
      "ID9QePIAAAAJ",
      "9I7kD8sAAAAJ",
      "p1DZVX8AAAAJ",
      "MhDyxdYAAAAJ",
      "hiOfejkAAAAJ",
      "NTb14PgAAAAJ",
      "5lB_d78AAAAJ",
      "Sbpra_AAAAAJ",
      "7t4jbPQAAAAJ",
      "MbF6rTEAAAAJ",
      "cnncomYAAAAJ",
      "ITZ1e7MAAAAJ",
      "MSCQE-YAAAAJ",
      "ySwF8ioAAAAJ",
      "lyadgWkAAAAJ",
      "dYt8FGcAAAAJ",
      "mVkGg80AAAAJ",
      "GR_DsT0AAAAJ",
      "L5jDQS8AAAAJ",
      "bRWa8q8AAAAJ",
      "LajpoI8AAAAJ",
      "1M79iLwAAAAJ",
      "vN-is70AAAAJ",
      "nfX25MMAAAAJ",
      "wKJeOQoAAAAJ",
      "UFlWdvUAAAAJ",
      "FXiSi-4AAAAJ",
      "ESCWolcAAAAJ",
      "Rn_BmTYAAAAJ",
      "MO7qaUIAAAAJ",
      "lPycXNcAAAAJ",
      "55TAOdgAAAAJ",
      "0ei9XEUAAAAJ",
      "sRpY9TIAAAAJ",
      "mAo_lUwAAAAJ",
      "t8v3JXsAAAAJ",
      "4pWLoJEAAAAJ",
      "8m8taGEAAAAJ",
      "x78TL58AAAAJ",
      "VbNwxKYAAAAJ",
      "Ob0bNAUAAAAJ",
      "RU0ZAp4AAAAJ",
      "w4yTWwoAAAAJ",
      "3yQFuR4AAAAJ",
      "PGdm9MUAAAAJ",
      "rMDVDA8AAAAJ",
      "kZh8vUMAAAAJ",
      "owqhKD8AAAAJ",
      "GdOmgYwAAAAJ",
      "7HPdnqEAAAAJ",
      "b4PmtFkAAAAJ",
      "itSa94cAAAAJ",
      "IzUjvBYAAAAJ",
      "OttawxUAAAAJ",
      "JKVR2ksAAAAJ",
      "Bk5q_pAAAAAJ",
      "m8m9nD0AAAAJ",
      "VZHxoh8AAAAJ",
      "1b2kKWoAAAAJ",
      "nCFeUqYAAAAJ",
      "b957ulAAAAAJ"
    ],
    "LKv32bgAAAAJ": [
      "czyretsAAAAJ",
      "84WzBlYAAAAJ",
      "MzKvJhAAAAAJ",
      "pouyVyUAAAAJ",
      "6dskOSUAAAAJ",
      "itSa94cAAAAJ",
      "6-e-ZBEAAAAJ",
      "Ch9iRwQAAAAJ",
      "B7oP0bIAAAAJ",
      "CgItEbQAAAAJ",
      "MN9Kfg8AAAAJ",
      "Nn990CkAAAAJ",
      "zX3ba1kAAAAJ",
      "4zybTq4AAAAJ",
      "CpMjT0YAAAAJ",
      "RLvsC94AAAAJ",
      "Dtw3YBoAAAAJ",
      "07qshUgAAAAJ",
      "iyDxq0EAAAAJ",
      "aO8KpGcAAAAJ",
      "nxNkEiYAAAAJ",
      "FdNHp8QAAAAJ",
      "MK6zHkYAAAAJ",
      "Vb3FLmkAAAAJ",
      "s_3ZE8kAAAAJ",
      "DulpV-cAAAAJ",
      "_koixUEAAAAJ",
      "ThJ-Ju4AAAAJ",
      "i5srt20AAAAJ",
      "0uTu7fYAAAAJ",
      "qRAQ5BsAAAAJ",
      "x1mbRloAAAAJ"
    ],
    "vtwH6GkAAAAJ": [
      "8R35rCwAAAAJ",
      "itSa94cAAAAJ",
      "8fztli4AAAAJ",
      "EMDboA4AAAAJ",
      "Vzr1RukAAAAJ",
      "iVLAQysAAAAJ",
      "bh-uRFMAAAAJ",
      "xOWBOKQAAAAJ",
      "kppa2vgAAAAJ",
      "HBztuGIAAAAJ",
      "XCZpOcAAAAAJ",
      "2oy3OXYAAAAJ",
      "x04W_mMAAAAJ",
      "8-p9CLsAAAAJ",
      "a5nY-pYAAAAJ",
      "jERkdhIAAAAJ",
      "FFWXLHUAAAAJ",
      "VjsNXysAAAAJ",
      "4mVPFQ8AAAAJ",
      "bLUllHEAAAAJ",
      "lsbreWwAAAAJ",
      "5Iqe53IAAAAJ",
      "9GMg6q8AAAAJ",
      "I1EvjZsAAAAJ",
      "MaSXNhUAAAAJ",
      "1FrpQaQAAAAJ",
      "zp8V7ZMAAAAJ",
      "Yxh9WWoAAAAJ",
      "ygFAcZwAAAAJ",
      "rNcmwggAAAAJ",
      "fMDLYCUAAAAJ",
      "SaiH1MIAAAAJ",
      "w-xdg4sAAAAJ",
      "YYT8-7kAAAAJ",
      "fmSHtE8AAAAJ",
      "1TqAq5AAAAAJ",
      "ExXP2_AAAAAJ",
      "Tsh90D8AAAAJ",
      "nABXo3sAAAAJ",
      "4V1nNm4AAAAJ",
      "VYiRfCwAAAAJ",
      "UWZA0v4AAAAJ",
      "x-n9rIMAAAAJ",
      "Wk2gAZUAAAAJ",
      "85XK-uAAAAAJ",
      "xaYqRfAAAAAJ",
      "LMtE3FQAAAAJ",
      "h3qMa1kAAAAJ",
      "p0sQC6sAAAAJ",
      "23LELwEAAAAJ",
      "rBJV6QUAAAAJ",
      "8C2_ZVsAAAAJ",
      "gYiCq88AAAAJ",
      "tk3X1QkAAAAJ",
      "wVGqmWkAAAAJ",
      "3_toKJ4AAAAJ",
      "n1zDCkQAAAAJ",
      "qWak04oAAAAJ",
      "3ifikJ0AAAAJ",
      "qTCXoLQAAAAJ",
      "szDNg-0AAAAJ",
      "y2pH4jcAAAAJ"
    ],
    "B96GkdgAAAAJ": [
      "vN-is70AAAAJ",
      "8fztli4AAAAJ",
      "uFJi3IUAAAAJ",
      "bh-uRFMAAAAJ",
      "p0sQC6sAAAAJ",
      "ID9QePIAAAAJ",
      "yxUduqMAAAAJ",
      "I1EvjZsAAAAJ",
      "e9gUdKwAAAAJ",
      "DpLFv4gAAAAJ",
      "DwdjBUUAAAAJ",
      "SaboshYAAAAJ",
      "fftO_HsAAAAJ",
      "94RFSSsAAAAJ",
      "b8OxVWUAAAAJ",
      "GUAoEcAAAAAJ",
      "QXyvv94AAAAJ",
      "K3QJPdMAAAAJ",
      "H3LMjtoAAAAJ",
      "IcaU830AAAAJ",
      "X22nUYgAAAAJ",
      "m0WCd-4AAAAJ",
      "tfN6V84AAAAJ",
      "NvKHgzkAAAAJ",
      "Wj4ZBFIAAAAJ",
      "7P-gZioAAAAJ",
      "-XCiamcAAAAJ",
      "evUv2MAAAAAJ",
      "vKlrdpEAAAAJ",
      "wmZTE5gAAAAJ",
      "zP0S_ikAAAAJ",
      "FFWXLHUAAAAJ",
      "YsXNU78AAAAJ",
      "5LLV29oAAAAJ",
      "Q8kbUQEAAAAJ",
      "FH9nKOAAAAAJ",
      "xdGKgtcAAAAJ",
      "PkfChMgAAAAJ",
      "jo2C_wkAAAAJ",
      "dB6ftCcAAAAJ",
      "Bl8GgEcAAAAJ",
      "5JE9m1EAAAAJ",
      "S8D-DqEAAAAJ",
      "b0ehAgIAAAAJ",
      "Zldo9CAAAAAJ",
      "mQf5cE0AAAAJ",
      "cl7CnNYAAAAJ",
      "hRB3wSgAAAAJ",
      "WXbhp_4AAAAJ"
    ],
    "_pv1sEcAAAAJ": [
      "DZ3S--MAAAAJ",
      "kiFd6A8AAAAJ",
      "mnU3HpcAAAAJ",
      "NDyEvlQAAAAJ",
      "Q-v0BgUAAAAJ",
      "LfcroyAAAAAJ",
      "3yT6IX4AAAAJ",
      "rIjeeRsAAAAJ",
      "L-diWvQAAAAJ",
      "-zaDQ10AAAAJ",
      "0bwP0i4AAAAJ",
      "eWRBqsYAAAAJ",
      "CzOD0S4AAAAJ",
      "gzpWXPcAAAAJ",
      "on2DUKoAAAAJ",
      "pzw1-J4AAAAJ",
      "23ZXZvEAAAAJ",
      "VecEj6kAAAAJ",
      "yxUduqMAAAAJ",
      "O43_7KUAAAAJ",
      "6QWsktwAAAAJ",
      "gd04NQ8AAAAJ",
      "zxB06pcAAAAJ",
      "QZCU3NkAAAAJ",
      "AIZoRQIAAAAJ",
      "cnncomYAAAAJ",
      "xT19Jc0AAAAJ",
      "YNoe5GAAAAAJ",
      "tX3YzCcAAAAJ",
      "aa9LMvoAAAAJ",
      "xkH30GgAAAAJ"
    ],
    "Wi25oKoAAAAJ": [],
    "B847xq8AAAAJ": [
      "YAHWbtkAAAAJ",
      "_PZKLYUAAAAJ",
      "0lZoXCUAAAAJ",
      "fNOReswAAAAJ",
      "gRxBNZoAAAAJ",
      "_1hCq3UAAAAJ",
      "SqFoZNUAAAAJ",
      "UnEHCNkAAAAJ",
      "opbZfw0AAAAJ",
      "8O8MQEUAAAAJ",
      "zS3z8UgAAAAJ",
      "r44N6h8AAAAJ",
      "4Z6vo5QAAAAJ",
      "QWzsNMDsvlIC",
      "PS-TM94AAAAJ",
      "DYUloYkAAAAJ",
      "m_HQ-WQAAAAJ",
      "65FCPpwAAAAJ",
      "lH1PdF8AAAAJ",
      "y-8unsgAAAAJ",
      "H1vNRiUAAAAJ",
      "jM23vRsKxuIC",
      "zkvW8FQAAAAJ",
      "F_ASWCUAAAAJ",
      "ajIYB6wAAAAJ",
      "osxb7aMAAAAJ",
      "-iPZaBcAAAAJ",
      "c_z5hWEAAAAJ",
      "WLN3QrAAAAAJ",
      "l-mlF7YAAAAJ",
      "vboGT0EAAAAJ",
      "7HCKL10AAAAJ",
      "LQR0kNcAAAAJ",
      "q4zv0KYAAAAJ",
      "hISpTpQAAAAJ",
      "ftI1lBQAAAAJ",
      "fkGi-JMAAAAJ",
      "-CeUxegAAAAJ",
      "1eBgIWsAAAAJ",
      "r3q68rcAAAAJ",
      "eQujqDgAAAAJ",
      "_vjPh4UAAAAJ",
      "WX0pI3wAAAAJ",
      "EWJYRncAAAAJ",
      "QxbpIMUAAAAJ",
      "GBQ6w8IAAAAJ",
      "EjtpMaoAAAAJ",
      "Wewcpo4AAAAJ",
      "LWlN_BUAAAAJ",
      "ZQ1Bbb8AAAAJ"
    ],
    "_tNCgxMAAAAJ": [],
    "UgHB5oAAAAAJ": [
      "vtwH6GkAAAAJ",
      "2oy3OXYAAAAJ",
      "8R35rCwAAAAJ",
      "4mVPFQ8AAAAJ",
      "LUe32ToAAAAJ",
      "KgZxzjsAAAAJ",
      "7GSWYLQAAAAJ",
      "tsXh_hwAAAAJ",
      "-5_ksIkAAAAJ",
      "odFQXSYAAAAJ",
      "ZaJEZpYAAAAJ",
      "SlZavnIAAAAJ",
      "62e5CygAAAAJ",
      "eurA6WgAAAAJ",
      "UAwKvEsAAAAJ",
      "X-Sd3-8AAAAJ",
      "8fztli4AAAAJ",
      "Hyhp_zUAAAAJ",
      "4bl7qAgAAAAJ",
      "7t4jbPQAAAAJ",
      "sPlonWcAAAAJ",
      "adnTgaAAAAAJ",
      "_qr34PIAAAAJ",
      "2ylcZSsAAAAJ",
      "hhm6ZzUAAAAJ",
      "NOoKltoAAAAJ",
      "SOt7sr4AAAAJ",
      "8m8taGEAAAAJ",
      "jikMhF4AAAAJ",
      "wORhZLMAAAAJ",
      "Tsh90D8AAAAJ",
      "x-n9rIMAAAAJ",
      "slQp6UYAAAAJ",
      "GyoKzFwAAAAJ",
      "vfPE6hgAAAAJ",
      "kXB8FBoAAAAJ",
      "0jSdqoEAAAAJ",
      "dq3yXjkAAAAJ",
      "Yxh9WWoAAAAJ",
      "JwiByPoAAAAJ",
      "dnZ8udEAAAAJ",
      "HPoaHyQAAAAJ",
      "wLf0Vw0AAAAJ",
      "oAlCitYAAAAJ",
      "jIs-Y2gAAAAJ"
    ],
    "iYN86KEAAAAJ": [
      "kukA0LcAAAAJ",
      "km6CP8cAAAAJ",
      "MOgfm8oAAAAJ",
      "c646VbAAAAAJ",
      "nHh9PSsAAAAJ",
      "6F3ZIeEAAAAJ",
      "cGxq0cMAAAAJ",
      "nCh4qyMAAAAJ",
      "XCZpOcAAAAAJ",
      "AMGqrI0AAAAJ",
      "Vs-MdPcAAAAJ",
      "I66ZBYwAAAAJ",
      "GgQ9GEkAAAAJ",
      "wfGiqXEAAAAJ",
      "L4bNmsMAAAAJ",
      "vWTI60AAAAAJ",
      "x04W_mMAAAAJ",
      "XD_01h8AAAAJ",
      "dOad5HoAAAAJ",
      "w68-7AYAAAAJ",
      "hg3A9TgAAAAJ",
      "iKPWydkAAAAJ",
      "wFEJvJUAAAAJ",
      "ijH0-a8AAAAJ",
      "MwLqCs4AAAAJ",
      "KOBmy0sAAAAJ",
      "kjMNMLkAAAAJ",
      "B0KVWJEAAAAJ",
      "RjQ7YnMAAAAJ",
      "2r2NuDAAAAAJ",
      "5tVuggUAAAAJ",
      "BaI7l8QAAAAJ",
      "g1I269gAAAAJ",
      "TvdMDhwAAAAJ",
      "_S_1cEEAAAAJ",
      "bn4xHHIAAAAJ",
      "l-la0GQAAAAJ",
      "zIv6YN0AAAAJ",
      "8R35rCwAAAAJ",
      "cX2HlhQAAAAJ",
      "KUG_tG0AAAAJ",
      "6QpFL68AAAAJ",
      "7nlvOMQAAAAJ",
      "h0Al1fcAAAAJ",
      "vtwH6GkAAAAJ",
      "mG4imMEAAAAJ",
      "M5zMoh4AAAAJ",
      "-ZfwQOkAAAAJ",
      "Yxv1EwcAAAAJ",
      "s2lG0X0AAAAJ",
      "mZfgLA4AAAAJ",
      "qOC97ysAAAAJ",
      "sUK_w2QAAAAJ",
      "Y6L6ZYsAAAAJ",
      "NkzyCvUAAAAJ",
      "vfT6-XIAAAAJ",
      "fmSHtE8AAAAJ",
      "zqLpO2QAAAAJ",
      "NMS69lQAAAAJ",
      "miDt1j8AAAAJ",
      "_WnkXlkAAAAJ",
      "XSforroAAAAJ",
      "TMawhM4AAAAJ",
      "WBCKQMsAAAAJ",
      "TB5OwW8AAAAJ",
      "YvdzeM8AAAAJ",
      "5Iqe53IAAAAJ",
      "MpJ00PUAAAAJ",
      "yFEHsv4AAAAJ",
      "vKAKE1gAAAAJ",
      "Slq0rJcAAAAJ",
      "7mnKGGEAAAAJ",
      "y2pH4jcAAAAJ",
      "V3JjNJ0AAAAJ"
    ],
    "qTCXoLQAAAAJ": [],
    "Pk-959EAAAAJ": [],
    "S8D-DqEAAAAJ": [],
    "Kzj3HC8AAAAJ": [
      "nTiSnwUAAAAJ",
      "GdXOFKoAAAAJ",
      "OP6ejqgAAAAJ",
      "ljxAoR8AAAAJ",
      "1azFZ6cAAAAJ",
      "ZL-p_cIAAAAJ",
      "8gEhRVgAAAAJ",
      "CNOqUZoAAAAJ",
      "0IkkBzQAAAAJ",
      "Mu7NXDwAAAAJ",
      "i-g1zC0AAAAJ",
      "xRmmtzIAAAAJ",
      "aO8KpGcAAAAJ",
      "II8VI8IAAAAJ",
      "ARo4eW0AAAAJ",
      "F5PJHPcAAAAJ",
      "mCuJP1UAAAAJ",
      "vyNLRqgAAAAJ",
      "G9DVxcQAAAAJ",
      "-mh8RQ8AAAAJ"
    ],
    "1FrpQaQAAAAJ": [],
    "jQl9RtkAAAAJ": [
      "z76PBfYAAAAJ",
      "JmdnBzcAAAAJ",
      "bh-uRFMAAAAJ",
      "bqTPA8kAAAAJ",
      "q9zQhj8AAAAJ",
      "mzZa_yQAAAAJ",
      "93ZjIs0AAAAJ",
      "IvqCXP4AAAAJ",
      "fmSHtE8AAAAJ",
      "jEANvfgAAAAJ",
      "pvyI8GkAAAAJ",
      "r8Zh-jwAAAAJ",
      "1aKTzmIAAAAJ",
      "u66VocEAAAAJ",
      "74Cj5GYAAAAJ",
      "OiVCfscAAAAJ",
      "mW2Jtu0AAAAJ",
      "GHpxNQIAAAAJ",
      "jJz3mXcAAAAJ",
      "3kDtybgAAAAJ",
      "eP6FHFAAAAAJ",
      "yCyR-TsAAAAJ",
      "NkzyCvUAAAAJ",
      "lnCKs0AAAAAJ",
      "kmXOOdsAAAAJ",
      "Zgk0Z6kAAAAJ",
      "xfskSZEAAAAJ",
      "eSPY7nMAAAAJ",
      "tvgSaXsAAAAJ",
      "wRyjJfMAAAAJ",
      "wcOO6hgAAAAJ",
      "mHbdIAwAAAAJ",
      "Lvm9Q8QAAAAJ",
      "iCf3SwgAAAAJ",
      "LAv0HTEAAAAJ",
      "PR2DwYYAAAAJ",
      "Mkaq4VYAAAAJ",
      "UvNbBnEAAAAJ",
      "-xA1_OAAAAAJ",
      "eALwl74AAAAJ",
      "4V1nNm4AAAAJ",
      "_kJ-zUYAAAAJ",
      "J-vrZ58AAAAJ",
      "gf-aMd0AAAAJ",
      "1H2H7XAAAAAJ",
      "W1a8vwIAAAAJ",
      "ILgZT7MAAAAJ",
      "8200InoAAAAJ",
      "brsVjNcAAAAJ",
      "zIS5ibQAAAAJ",
      "I8A1STcAAAAJ",
      "Px3ZQ08AAAAJ",
      "WJNkMakAAAAJ",
      "0ZAb3tsAAAAJ",
      "tmZ8MaAAAAAJ",
      "rTw-pq0AAAAJ",
      "UfbuDH8AAAAJ",
      "TfInmkIAAAAJ",
      "yIg7b2gAAAAJ",
      "4_uj0xcAAAAJ",
      "KB5XZGIAAAAJ",
      "vUM0nAgAAAAJ",
      "SVNNgu4AAAAJ",
      "eM916YMAAAAJ",
      "beVJGycAAAAJ",
      "-fEOFbMAAAAJ",
      "SrVnrPcAAAAJ",
      "aCQjyp0AAAAJ",
      "V8fBl-0AAAAJ",
      "BTBd5V4AAAAJ",
      "TFsE4BIAAAAJ",
      "bZVkVvoAAAAJ",
      "Sx75CVsAAAAJ",
      "0z0fNxUAAAAJ",
      "IUqydU0AAAAJ",
      "arjucpEAAAAJ",
      "u3QYKhkAAAAJ",
      "YizAq4gAAAAJ",
      "I_YIc0YAAAAJ",
      "fWbf74cAAAAJ",
      "hdrXRx8AAAAJ",
      "t9ahuxsAAAAJ",
      "wbqHAq0AAAAJ",
      "RWV9I_IAAAAJ",
      "2R22h84AAAAJ",
      "2CGNfAEAAAAJ",
      "IEcsMPAAAAAJ",
      "ZbA-z1cAAAAJ",
      "8UinjA0AAAAJ",
      "-4PyWB0AAAAJ",
      "B42Mr-sAAAAJ",
      "z7WhDRIAAAAJ",
      "7VAwhzUAAAAJ",
      "FPRvtUEAAAAJ",
      "IqJ3zskAAAAJ",
      "jUOcawkAAAAJ",
      "0kK7sSAAAAAJ",
      "8vAIQXoAAAAJ",
      "xk6HHiAAAAAJ",
      "QURZIzUAAAAJ",
      "wv5oKToAAAAJ",
      "YC-3YaYAAAAJ",
      "vX5i2CcAAAAJ",
      "f9iP-80AAAAJ",
      "pchPMh0AAAAJ",
      "xf1T870AAAAJ",
      "3nlXVhAAAAAJ",
      "jHR4dXcAAAAJ",
      "T0yIjk4AAAAJ",
      "ss8KR5gAAAAJ",
      "0eFZtREAAAAJ",
      "6KWxpxkAAAAJ",
      "4oXBp9UAAAAJ",
      "J2Z-ChoAAAAJ",
      "j98IWfoAAAAJ",
      "WsbgVR4AAAAJ",
      "sqWpn2AAAAAJ",
      "xnQZonMAAAAJ",
      "9r_f1w4AAAAJ",
      "0HuMHFwAAAAJ",
      "v6YG0YEAAAAJ",
      "s9UDcdYAAAAJ",
      "1kZgyI8AAAAJ",
      "7vCEi-gAAAAJ",
      "AqYyoCMAAAAJ",
      "WBCKQMsAAAAJ",
      "pHblCTAAAAAJ",
      "564o-vIAAAAJ",
      "mMifMdoAAAAJ",
      "6PnL3BgAAAAJ",
      "M_NWm1wAAAAJ",
      "OpXMNnMAAAAJ",
      "U4tFPMQAAAAJ",
      "nWboYt0AAAAJ",
      "vWDTlWoAAAAJ",
      "weicM8wAAAAJ",
      "Xtgj8q0AAAAJ",
      "2GCPK34AAAAJ",
      "aa5Ou7gAAAAJ",
      "w047VfEAAAAJ",
      "0A3yyk4AAAAJ",
      "_kKvHOAAAAAJ",
      "jzx6_ZIAAAAJ",
      "w6hmCEYAAAAJ",
      "yhz7sFoAAAAJ",
      "9RyeFYwAAAAJ",
      "zp8V7ZMAAAAJ",
      "U89FHq4AAAAJ",
      "krrh6OUAAAAJ",
      "p3iJiLIAAAAJ",
      "DZ-fHPgAAAAJ",
      "aEd4RLgAAAAJ",
      "JNER_T4AAAAJ",
      "AVDkgFIAAAAJ",
      "ZyaLOy4AAAAJ",
      "rwBWbFAAAAAJ",
      "l6c85tMAAAAJ",
      "nShf6cgAAAAJ",
      "VxpypngAAAAJ",
      "0mgEF28AAAAJ",
      "OaAO-aIAAAAJ",
      "SgbYgdsAAAAJ",
      "sUz6qxwAAAAJ",
      "FcFAKFEAAAAJ",
      "iXOzeWUAAAAJ"
    ],
    "zvz6LIYAAAAJ": [
      "8R35rCwAAAAJ",
      "rRJ9wTJMUB8C",
      "2efgcS0AAAAJ",
      "vfPE6hgAAAAJ",
      "T9To2C0AAAAJ",
      "7ShMBcwAAAAJ",
      "3hdOFF0AAAAJ",
      "0zZnyMEAAAAJ",
      "rrPyvsgAAAAJ",
      "vgfGtykAAAAJ",
      "xBH73TYAAAAJ",
      "euc0GX4AAAAJ"
    ],
    "okcbLqoAAAAJ": [
      "xBv5ZfkAAAAJ",
      "9xDADY4AAAAJ",
      "bh-uRFMAAAAJ",
      "qYhRbJoAAAAJ",
      "Jp6Mz1sAAAAJ",
      "eyCw9goAAAAJ",
      "4V1nNm4AAAAJ",
      "FHLTntIAAAAJ",
      "yxUduqMAAAAJ",
      "pJ28HA0AAAAJ",
      "4Z6vo5QAAAAJ",
      "JoClQPUAAAAJ",
      "p9RsPG4AAAAJ",
      "0kV69XQAAAAJ",
      "mqpjAt4AAAAJ",
      "eP2Z3qQAAAAJ",
      "5IzwG1AAAAAJ",
      "RfSQKrIAAAAJ",
      "S4z3uzMAAAAJ",
      "eLFhiSYAAAAJ",
      "oX-nvpwAAAAJ",
      "nXBQn7gAAAAJ",
      "gX7rSCcAAAAJ",
      "UfAyRKEAAAAJ",
      "sI0wlX8AAAAJ",
      "5zZjmvEAAAAJ",
      "1UirFygAAAAJ",
      "2ItLnFgAAAAJ",
      "UfbuDH8AAAAJ",
      "yQNhFGUAAAAJ",
      "dPX0wQcAAAAJ",
      "rtWKzFwAAAAJ",
      "7QHvAEYAAAAJ",
      "edQgLXcAAAAJ",
      "gTWUZlsAAAAJ",
      "reUYd_0AAAAJ",
      "2mjUsP8AAAAJ"
    ],
    "X22nUYgAAAAJ": [
      "I1EvjZsAAAAJ",
      "p0sQC6sAAAAJ",
      "vN-is70AAAAJ",
      "Bl8GgEcAAAAJ",
      "B96GkdgAAAAJ",
      "dB6ftCcAAAAJ",
      "GUAoEcAAAAAJ",
      "YsXNU78AAAAJ",
      "biuxbRsAAAAJ",
      "F_MI0pcAAAAJ",
      "NjeM1LsAAAAJ",
      "a1ngrCIAAAAJ"
    ],
    "nGUcGrYAAAAJ": [
      "DV8z8DYAAAAJ",
      "2mjUsP8AAAAJ",
      "yxWtZLAAAAAJ",
      "4PqxB3gAAAAJ",
      "P6l5tBcAAAAJ",
      "QDuPGHwAAAAJ",
      "R-Cgh08AAAAJ",
      "CMIgrCgAAAAJ",
      "YOVZiJkAAAAJ",
      "GhrKC1gAAAAJ",
      "3Zb5Y2YAAAAJ",
      "U89FHq4AAAAJ",
      "M6IjHhoAAAAJ",
      "9Sf0vd4AAAAJ",
      "R71GD9MAAAAJ",
      "FX5CsuYAAAAJ",
      "6_MJikoAAAAJ",
      "LNXEjT8AAAAJ",
      "hmoy8ssAAAAJ",
      "yaOyQOQAAAAJ",
      "2c_x00gAAAAJ",
      "qkn2yIIAAAAJ",
      "EtTJi3oAAAAJ",
      "llF8XbMAAAAJ",
      "YgykRA0AAAAJ",
      "Oy8M_4QAAAAJ",
      "-novlhIAAAAJ",
      "p-PdgdYAAAAJ",
      "8R35rCwAAAAJ",
      "_EJrRVAAAAAJ",
      "h4DSY8MAAAAJ",
      "iAkcJ2oAAAAJ",
      "eZmKjZEAAAAJ",
      "5n5leq4AAAAJ",
      "m5hqkt0AAAAJ",
      "jH79pJkAAAAJ",
      "OP7F8jEAAAAJ",
      "x9ly9Q0AAAAJ",
      "C_4IMR4AAAAJ",
      "I5-0kFQAAAAJ",
      "6p-OvCcAAAAJ",
      "kamjbL0AAAAJ",
      "SvmrjK4AAAAJ",
      "UmwJklEAAAAJ",
      "mh6kznYAAAAJ",
      "8RtQzSQAAAAJ",
      "PEzAWAwAAAAJ",
      "dQ0dT2sAAAAJ",
      "j54VcVEAAAAJ",
      "6m4wv6gAAAAJ",
      "8RgDBoEAAAAJ",
      "1pMBYn8AAAAJ",
      "DbeHYRcAAAAJ",
      "0J10RyoAAAAJ",
      "MDfW21AAAAAJ",
      "K4w5qYUAAAAJ",
      "p2R-FRoAAAAJ",
      "2g0uKnAAAAAJ",
      "LGF6qesAAAAJ",
      "4SDTMIQAAAAJ",
      "Ss2KBccAAAAJ",
      "9gV4DRsAAAAJ",
      "b6zhmt0AAAAJ",
      "WPESKq0AAAAJ",
      "VFixSK8AAAAJ",
      "pe6tmKAAAAAJ",
      "aEOTSMEAAAAJ",
      "cZBq_9MAAAAJ",
      "2iusLHoAAAAJ",
      "rWZq2nQAAAAJ",
      "_D_j2aoAAAAJ",
      "3Q6vpxYAAAAJ",
      "89u7qcIAAAAJ",
      "pfG0_pEAAAAJ",
      "QPCr30IAAAAJ",
      "cH2eTqAAAAAJ",
      "jMSF3ukAAAAJ",
      "u-T21zUAAAAJ",
      "Vtzdv-MAAAAJ",
      "g7E_CLwAAAAJ",
      "d3MKMggAAAAJ",
      "AQ8w2uEAAAAJ",
      "y_4QsYAAAAAJ",
      "9FSuHUQAAAAJ",
      "TW1vSVUAAAAJ",
      "mIFso2kAAAAJ",
      "sLVkoTgAAAAJ",
      "332L1coAAAAJ",
      "arZclaMAAAAJ",
      "l3yJjKIAAAAJ",
      "-p2OOuQAAAAJ",
      "LrsjJfwAAAAJ",
      "6MpBAH4AAAAJ",
      "vB_P3HUAAAAJ",
      "9CW-7GAAAAAJ",
      "aMUoVMMAAAAJ",
      "e7oZHCsAAAAJ",
      "u11FXaoAAAAJ",
      "GyFb98kAAAAJ",
      "Ch9iRwQAAAAJ",
      "5xYDlvgAAAAJ",
      "nqDmEHUAAAAJ",
      "l2RQ_S8AAAAJ",
      "Qt2d3BoAAAAJ",
      "_TgBTNwAAAAJ",
      "6vQmgzcAAAAJ",
      "Nn_Ee0IAAAAJ",
      "Sr7jln4AAAAJ",
      "yK4caV0AAAAJ",
      "HLfQbBkAAAAJ",
      "IEHo6YcAAAAJ",
      "Qk8Wh5UAAAAJ",
      "Xnk4W5cAAAAJ",
      "0KhH2ioAAAAJ",
      "UsDuS10AAAAJ",
      "IhhuIZcAAAAJ",
      "cbIxOLYAAAAJ",
      "pKEjWnsAAAAJ",
      "EIw2QBsAAAAJ"
    ],
    "fkGi-JMAAAAJ": [
      "VdBfGdoAAAAJ",
      "U-RE8IgAAAAJ",
      "1KRXBIwAAAAJ",
      "3yPEc4YAAAAJ",
      "WfS41RAAAAAJ",
      "1rV69hMAAAAJ",
      "YYJ3aycAAAAJ",
      "XnHdkZUAAAAJ",
      "UvFrX04AAAAJ",
      "H4rKFc8AAAAJ",
      "C8qMVQUAAAAJ",
      "kwnwhrgAAAAJ",
      "373HnhYAAAAJ",
      "BLPO9lMAAAAJ",
      "nRM32-QAAAAJ",
      "gBkMDloAAAAJ",
      "9wibWOoAAAAJ",
      "8gw3UCMAAAAJ",
      "-PWcE1YAAAAJ",
      "oDwLyYUAAAAJ",
      "dqVjyRQAAAAJ",
      "7wXWIdUAAAAJ",
      "Znp3UkEAAAAJ",
      "Ew7QLzsAAAAJ",
      "PiZymREAAAAJ",
      "iKPWydkAAAAJ",
      "qIPV_KsAAAAJ",
      "yORoyhsAAAAJ",
      "Es6jE1kAAAAJ",
      "AbRFE3IAAAAJ",
      "TOZ-J_wAAAAJ",
      "-zlRjYcAAAAJ",
      "OrUyRAcAAAAJ",
      "YAHWbtkAAAAJ",
      "B847xq8AAAAJ",
      "ZnT-QpMAAAAJ",
      "zc920lAAAAAJ",
      "XY2YaEkAAAAJ",
      "gqB23VMAAAAJ",
      "QdTErIEAAAAJ",
      "5b8D1MgAAAAJ",
      "5hGRe_QAAAAJ",
      "lG7aUrkAAAAJ",
      "tAM57M8AAAAJ",
      "eghKB-0AAAAJ",
      "8CsZAHUAAAAJ",
      "H3ExIrEAAAAJ",
      "m-L5Hj0AAAAJ",
      "t11U6_sAAAAJ",
      "BnQdO2UAAAAJ",
      "vtuhhp8AAAAJ",
      "SIFRrBIAAAAJ",
      "stSUaHAAAAAJ",
      "XD_01h8AAAAJ",
      "NE4K0XUAAAAJ",
      "Wy0bQrwAAAAJ",
      "jr7gGB4AAAAJ",
      "kLUQrrYAAAAJ",
      "j5N3bKYAAAAJ",
      "pZhZndYAAAAJ",
      "Te94nKAAAAAJ",
      "gjLr_FgAAAAJ",
      "18exh0MAAAAJ",
      "vHTMzPQAAAAJ",
      "plbHxNUAAAAJ",
      "g7Op2tgAAAAJ",
      "cnPetCkAAAAJ",
      "qYhRbJoAAAAJ",
      "PoDj4lsAAAAJ",
      "-UhqXIEAAAAJ",
      "ZUEtS-EAAAAJ",
      "okLwXk0AAAAJ",
      "22dxhNQAAAAJ",
      "CnBvgwcAAAAJ",
      "g3t0ihoAAAAJ",
      "8d8jP60AAAAJ",
      "g2xwfAMAAAAJ",
      "BYLsgysAAAAJ",
      "GqZBmfgAAAAJ",
      "QYNU5jMAAAAJ",
      "JpB-xkUAAAAJ",
      "5w0Y9JUAAAAJ",
      "ZIlzcYcAAAAJ",
      "AMGqrI0AAAAJ",
      "gvo0nMsAAAAJ",
      "MK6zHkYAAAAJ",
      "aM1rfhEAAAAJ",
      "aKBwXEEAAAAJ",
      "RBX7SrkAAAAJ",
      "Q0crxvwAAAAJ",
      "Y_XwzKQAAAAJ",
      "E_a3VB4AAAAJ",
      "s1UQI6kAAAAJ",
      "A6C3geAAAAAJ",
      "xiiiSa8AAAAJ",
      "PQtLkV0AAAAJ",
      "YPq45Q0AAAAJ",
      "1Uk-ZIAAAAAJ",
      "ViBqWZYAAAAJ",
      "P1-HgxMAAAAJ",
      "5sz_jBoAAAAJ",
      "5qo8bOkAAAAJ",
      "RZueBXQAAAAJ",
      "KcM-4NsAAAAJ",
      "0b9YnbYAAAAJ",
      "3dxS1VYAAAAJ",
      "rAP3wVwAAAAJ",
      "F2gY_WkAAAAJ",
      "g3DjOkMAAAAJ",
      "y1u15RcAAAAJ",
      "woqUivYAAAAJ",
      "01ks8yYAAAAJ",
      "ZzJO3UkAAAAJ",
      "yTd5KnYAAAAJ",
      "pEyaa44AAAAJ",
      "k6-nvDAAAAAJ",
      "xa-6ZlkAAAAJ",
      "Jlv4MR4AAAAJ",
      "t0ZfFH8AAAAJ",
      "yriZqCMAAAAJ",
      "hb1bGgUAAAAJ",
      "IkEXPUEAAAAJ",
      "4yuKD_AAAAAJ",
      "P_q1TRgAAAAJ",
      "4WEQ8h0AAAAJ",
      "fb2-dasAAAAJ"
    ],
    "jH_7A6gAAAAJ": [],
    "Sbpra_AAAAAJ": [
      "MbF6rTEAAAAJ",
      "7t4jbPQAAAAJ",
      "5lB_d78AAAAJ",
      "iOLC30YAAAAJ",
      "UgHB5oAAAAAJ",
      "8S5AOggAAAAJ",
      "4mVPFQ8AAAAJ",
      "8R35rCwAAAAJ",
      "FuGllAwAAAAJ",
      "9nnDvooAAAAJ",
      "o42MH0MAAAAJ",
      "4ANbX-YAAAAJ",
      "GR_DsT0AAAAJ",
      "y0B6gawAAAAJ",
      "7GSWYLQAAAAJ",
      "0QDCG8IAAAAJ",
      "vGBcNVAAAAAJ",
      "AgPS44sAAAAJ",
      "5tk1PV8AAAAJ",
      "ZvX1hXcAAAAJ",
      "AtMBDPUAAAAJ",
      "5ApCTCoAAAAJ",
      "QUmyfogAAAAJ",
      "z7tPc9IAAAAJ",
      "yjPHHb8AAAAJ",
      "LUe32ToAAAAJ",
      "eBtFiuAAAAAJ",
      "_qY_t5kAAAAJ",
      "4WLoIRsAAAAJ",
      "6z4lQzMAAAAJ",
      "FxdgVLkAAAAJ",
      "R6jE0VEAAAAJ",
      "H0MLFHEAAAAJ",
      "lyG0vMQAAAAJ",
      "uY4D8-wAAAAJ",
      "gM7zfrkAAAAJ",
      "8LcYFjEAAAAJ",
      "vx68rkMAAAAJ",
      "-7FMxqsAAAAJ",
      "ViLZaDsAAAAJ",
      "2ZRnqiEAAAAJ",
      "tu7wKckAAAAJ",
      "gryqnyAAAAAJ"
    ],
    "65FCPpwAAAAJ": [
      "_4dnp0IAAAAJ"
    ],
    "wfGiqXEAAAAJ": [
      "T04c3fwAAAAJ",
      "jEANvfgAAAAJ",
      "yFMX138AAAAJ",
      "0nPi5YYAAAAJ",
      "mu5Y2rYAAAAJ",
      "T7uctwYAAAAJ",
      "jjEht8wAAAAJ",
      "Vs-MdPcAAAAJ",
      "kukA0LcAAAAJ",
      "GgQ9GEkAAAAJ",
      "iYN86KEAAAAJ",
      "XCZpOcAAAAAJ",
      "L4bNmsMAAAAJ",
      "3Y4egcYAAAAJ",
      "x04W_mMAAAAJ",
      "km6CP8cAAAAJ",
      "8R35rCwAAAAJ",
      "NkzyCvUAAAAJ",
      "vfPE6hgAAAAJ",
      "WBCKQMsAAAAJ",
      "FpI8dFwAAAAJ",
      "wtRVnsYAAAAJ",
      "_MEuWIMAAAAJ",
      "j3CEIuEAAAAJ",
      "U89FHq4AAAAJ",
      "aGXkhcwAAAAJ",
      "WL_xXbQAAAAJ",
      "fmSHtE8AAAAJ",
      "pnOLBcoAAAAJ",
      "0e49RfgAAAAJ",
      "iZ5cY0AAAAAJ",
      "KOBmy0sAAAAJ",
      "LFiqVpwAAAAJ",
      "Kc8zXcgAAAAJ",
      "xdlBKc8AAAAJ",
      "Rqy5KDEAAAAJ",
      "wYMTld8AAAAJ",
      "_S_1cEEAAAAJ",
      "Afa_1z4AAAAJ",
      "_WnkXlkAAAAJ",
      "6QpFL68AAAAJ",
      "MdbxYu8AAAAJ",
      "TMawhM4AAAAJ",
      "vfT6-XIAAAAJ",
      "s0njcGgAAAAJ",
      "bLb3VdIAAAAJ",
      "vYRgxJ8AAAAJ",
      "NMS69lQAAAAJ",
      "jNCbl2IAAAAJ",
      "SYvhSBcAAAAJ",
      "M5zMoh4AAAAJ",
      "MyPTNBgAAAAJ",
      "PTS2AOgAAAAJ",
      "M-1wKzIAAAAJ",
      "1mJtQD0AAAAJ",
      "IYDJuOAAAAAJ",
      "Yxv1EwcAAAAJ",
      "eQ1uJ6UAAAAJ",
      "zqLpO2QAAAAJ",
      "bn4xHHIAAAAJ"
    ],
    "p0sQC6sAAAAJ": [
      "vN-is70AAAAJ",
      "uFJi3IUAAAAJ",
      "a1ngrCIAAAAJ",
      "I1EvjZsAAAAJ",
      "biuxbRsAAAAJ",
      "GUAoEcAAAAAJ",
      "X22nUYgAAAAJ",
      "Yxh9WWoAAAAJ",
      "k3YaoIEAAAAJ",
      "5LLV29oAAAAJ",
      "fKV65XQAAAAJ",
      "F_MI0pcAAAAJ",
      "Bl8GgEcAAAAJ",
      "B8tFrksAAAAJ",
      "yxUduqMAAAAJ",
      "8fztli4AAAAJ",
      "X53rkecAAAAJ",
      "VghIYWEAAAAJ",
      "Wj4ZBFIAAAAJ",
      "80pKMyMAAAAJ",
      "YsXNU78AAAAJ",
      "zdKmnYwAAAAJ",
      "6iBz3QgAAAAJ",
      "Hs3AnAkAAAAJ"
    ],
    "QCBdB7AAAAAJ": [],
    "zP0S_ikAAAAJ": [
      "FFWXLHUAAAAJ",
      "vN-is70AAAAJ",
      "yxUduqMAAAAJ",
      "IcaU830AAAAJ",
      "wmZTE5gAAAAJ",
      "B96GkdgAAAAJ",
      "7w24ptsAAAAJ",
      "7P-gZioAAAAJ",
      "MvYTnPoAAAAJ",
      "8fztli4AAAAJ",
      "FH9nKOAAAAAJ",
      "yZGlLeMAAAAJ",
      "kbN88gsAAAAJ",
      "SiCHxTkAAAAJ",
      "a_dbdxAAAAAJ",
      "5PBPqeQAAAAJ",
      "keIlGm0AAAAJ",
      "36ofBJgAAAAJ",
      "DZ-fHPgAAAAJ",
      "grQ_GBgAAAAJ",
      "4BEvaw8AAAAJ",
      "m0WCd-4AAAAJ",
      "ROJq4g4AAAAJ",
      "8zyiGRoAAAAJ",
      "E3yOuvEAAAAJ",
      "KSZmI5EAAAAJ",
      "xEm-9oMAAAAJ",
      "gTWUZlsAAAAJ",
      "w68-7AYAAAAJ",
      "itSa94cAAAAJ",
      "Ksz7c7YAAAAJ",
      "odOmEY0AAAAJ",
      "oavgGaMAAAAJ",
      "E5GfpA4AAAAJ",
      "zIv6YN0AAAAJ"
    ],
    "U89FHq4AAAAJ": [
      "kukA0LcAAAAJ",
      "km6CP8cAAAAJ",
      "WBCKQMsAAAAJ",
      "grQ_GBgAAAAJ",
      "xdlBKc8AAAAJ",
      "1ScWJOoAAAAJ",
      "FM2DTXwAAAAJ",
      "JM9-OOsAAAAJ",
      "LAoMyyoAAAAJ",
      "bn4xHHIAAAAJ",
      "cr53lHIAAAAJ",
      "4BEvaw8AAAAJ",
      "iBeDoRAAAAAJ",
      "wfGiqXEAAAAJ",
      "LX2QWBYAAAAJ",
      "euUV4iUAAAAJ",
      "GhPDR9AAAAAJ",
      "3Qjt0BUAAAAJ",
      "I5-0kFQAAAAJ",
      "M792u2sAAAAJ",
      "JicYPdAAAAAJ",
      "1cdNGL4AAAAJ",
      "ITZ1e7MAAAAJ",
      "KOBmy0sAAAAJ",
      "nzEluBwAAAAJ",
      "7-9jOvEAAAAJ",
      "XrKLUO0AAAAJ",
      "yV3_PTkAAAAJ",
      "71a2-WMAAAAJ",
      "rLdfJ1gAAAAJ",
      "ghbWy-0AAAAJ",
      "m9I8jgcAAAAJ",
      "eQ1uJ6UAAAAJ",
      "dJQf4SYAAAAJ"
    ],
    "gRxBNZoAAAAJ": [
      "fqDBtzYAAAAJ",
      "Jlv4MR4AAAAJ",
      "YAHWbtkAAAAJ",
      "B847xq8AAAAJ",
      "hRggMmIAAAAJ",
      "23ZXZvEAAAAJ",
      "jDLa-CUAAAAJ",
      "S4z3uzMAAAAJ",
      "3rF9gtAAAAAJ",
      "Fvh5mcwAAAAJ",
      "65FCPpwAAAAJ",
      "_1hCq3UAAAAJ",
      "XZrEn1sAAAAJ",
      "7HCKL10AAAAJ",
      "q2YhTvAAAAAJ",
      "li4mEfcAAAAJ",
      "9eyvm28AAAAJ",
      "all0DHsAAAAJ",
      "wb-DKCIAAAAJ",
      "OEJUgwkAAAAJ",
      "fZinJ_AAAAAJ",
      "j7MW4iYAAAAJ",
      "chD5XxkAAAAJ",
      "fq0DzqoAAAAJ",
      "UD87zMYAAAAJ",
      "umFQktIAAAAJ",
      "fb2-dasAAAAJ",
      "OcPVegoAAAAJ",
      "uoDW9hkAAAAJ",
      "ZPqZhnAAAAAJ",
      "huBJSMwAAAAJ",
      "NAFriCkAAAAJ",
      "TaR3dq4AAAAJ",
      "kgsF7uEAAAAJ",
      "PqQAVcAAAAAJ",
      "iKPWydkAAAAJ",
      "x7cbdTcAAAAJ",
      "u512YusAAAAJ",
      "e-c3R8QAAAAJ",
      "LnhCGNMAAAAJ",
      "opbZfw0AAAAJ",
      "CgItEbQAAAAJ",
      "erv7TP0AAAAJ",
      "wlAYZBwAAAAJ",
      "nwHfwCIAAAAJ",
      "F5Ik84MAAAAJ",
      "x8dED5cAAAAJ",
      "LFiqVpwAAAAJ",
      "JFT_m9kAAAAJ",
      "ELglt8UAAAAJ",
      "GsWe1fgAAAAJ",
      "oMLCZ1sAAAAJ",
      "9akH-n8AAAAJ",
      "-6cOYcYAAAAJ",
      "C6pnolkAAAAJ",
      "PQtLkV0AAAAJ",
      "rXYLXJMAAAAJ",
      "D-RwB3YAAAAJ",
      "FqNPXeoAAAAJ",
      "gZgQLkgAAAAJ",
      "Ew_nVXEAAAAJ",
      "RfHXG5EAAAAJ",
      "9LcazaMAAAAJ",
      "rlMZibgAAAAJ",
      "VX7d5EQAAAAJ",
      "sV61CtsAAAAJ",
      "_Q1uzVYAAAAJ",
      "r44N6h8AAAAJ",
      "z7l0wOcAAAAJ",
      "wB01auEAAAAJ",
      "MnnERiQAAAAJ",
      "6iUjvyMAAAAJ",
      "2AT4JE4AAAAJ",
      "Znp3UkEAAAAJ",
      "06rffEkAAAAJ",
      "e8aRmAsAAAAJ",
      "jNQlAkoAAAAJ",
      "57UxFrwAAAAJ",
      "5wppdUoAAAAJ",
      "HriWXcEAAAAJ",
      "i7lw4LwAAAAJ",
      "MbF6rTEAAAAJ",
      "2opu1SsAAAAJ",
      "ct3WjtoAAAAJ",
      "xhU85M4AAAAJ",
      "PCUwf-8AAAAJ",
      "EeYGZCwAAAAJ",
      "LWlN_BUAAAAJ",
      "kLUQrrYAAAAJ",
      "MK6zHkYAAAAJ",
      "fEhNO7YAAAAJ",
      "8hvFa2AAAAAJ",
      "s8xc2K4AAAAJ",
      "BIGOtyIAAAAJ",
      "1zu2Oh0AAAAJ",
      "M93Auk4AAAAJ"
    ],
    "a3K-f2YAAAAJ": [],
    "bo0P2qYAAAAJ": [
      "bh-uRFMAAAAJ",
      "t9HPFawAAAAJ",
      "G5M9nYwAAAAJ",
      "_GgST9AAAAAJ",
      "HhotyAoAAAAJ",
      "vtwH6GkAAAAJ",
      "-XCiamcAAAAJ",
      "DplAah0AAAAJ",
      "pvyI8GkAAAAJ",
      "ED5iKYYAAAAJ",
      "IhZxOR4AAAAJ",
      "ID9QePIAAAAJ",
      "dVtzVVAAAAAJ",
      "XP_Hxm4AAAAJ",
      "QxLpghAAAAAJ",
      "uy8T6BYAAAAJ",
      "0ret4cUAAAAJ",
      "N1yNDnQAAAAJ",
      "Nr_yTQgAAAAJ",
      "FiP-TVUAAAAJ",
      "IbcqwaoAAAAJ",
      "_egJxfMAAAAJ",
      "0OWBle8AAAAJ",
      "DmahiOYAAAAJ",
      "8R35rCwAAAAJ",
      "LO3pKmwAAAAJ",
      "K3QJPdMAAAAJ",
      "UyZL660AAAAJ",
      "AhgjQ2QAAAAJ",
      "-xQ-C1sAAAAJ",
      "FTqutJEAAAAJ",
      "dusV5HMAAAAJ",
      "FWztzhcAAAAJ",
      "hrqU1KkAAAAJ",
      "LAv0HTEAAAAJ",
      "ECHSnpYAAAAJ",
      "tlhfhLoAAAAJ",
      "NGqfK2wAAAAJ",
      "lLMX9hcAAAAJ",
      "ehrpcBwAAAAJ",
      "BsMsRuIAAAAJ",
      "LJiQRJIAAAAJ",
      "hankD2kAAAAJ",
      "iHh7IJQAAAAJ",
      "Hx3iRaMAAAAJ",
      "o67NTxYAAAAJ",
      "mPpYLhcAAAAJ",
      "-ltRSM0AAAAJ",
      "JCrug-YAAAAJ",
      "zUHUsuAAAAAJ",
      "vc_x1E0AAAAJ",
      "6dP660cAAAAJ",
      "qSNAaCsAAAAJ",
      "2ItLnFgAAAAJ",
      "bhpi3vgAAAAJ",
      "KL4w4bAAAAAJ",
      "zSiDAt4AAAAJ",
      "2efgcS0AAAAJ",
      "Zr7RJT4AAAAJ",
      "-xaOIZIAAAAJ",
      "QpmcFjoAAAAJ",
      "xIJHTUwAAAAJ",
      "Gxz1fqwAAAAJ",
      "I0HLZAwAAAAJ",
      "7o4wtKEAAAAJ",
      "kukA0LcAAAAJ",
      "8W-MW9sAAAAJ",
      "NbVfqJYAAAAJ",
      "_EJrRVAAAAAJ",
      "tjNPA04AAAAJ",
      "GfUvUacAAAAJ",
      "di5RZ1MAAAAJ",
      "axsP38wAAAAJ",
      "gwUGHwsAAAAJ",
      "ghuIBIYAAAAJ",
      "7vyVxxQAAAAJ",
      "_kJ-zUYAAAAJ",
      "BCKhEoAAAAAJ",
      "aLquhd4AAAAJ",
      "xDtTbmQAAAAJ",
      "0t_4lhMAAAAJ",
      "qk61RmIAAAAJ",
      "zYI0rysAAAAJ",
      "N_Z0SDMAAAAJ",
      "7LcGErsAAAAJ",
      "rEL4-fgAAAAJ",
      "0ROQMVcAAAAJ",
      "QAew4J0AAAAJ",
      "LjxqXycAAAAJ",
      "LWVqxRUAAAAJ",
      "NMigkG4AAAAJ",
      "PK57vrQAAAAJ",
      "ANtAA98AAAAJ",
      "leVIam8AAAAJ",
      "1c1TsZ8AAAAJ",
      "2ABKu2YAAAAJ",
      "CQEyVPMAAAAJ",
      "krfIJPUAAAAJ",
      "zu8U47oAAAAJ",
      "XLJrjN8AAAAJ",
      "slFtxbMAAAAJ",
      "2oy3OXYAAAAJ",
      "BE7NiFcAAAAJ",
      "8vXcIKoAAAAJ",
      "d4W1UT0AAAAJ",
      "voqw10cAAAAJ",
      "FF3Sp4QAAAAJ",
      "GhrKC1gAAAAJ"
    ],
    "FWp7728AAAAJ": [
      "OB6vAtkAAAAJ",
      "SMAmWOQAAAAJ",
      "Kbi2t9sAAAAJ",
      "jk7GqOEAAAAJ",
      "9rYWAhsAAAAJ",
      "lgHhJQ8AAAAJ",
      "Sm14jYIAAAAJ",
      "8R35rCwAAAAJ",
      "UpZmJI0AAAAJ",
      "IUZ-7_cAAAAJ",
      "k0nZO90AAAAJ",
      "bmZbi_UNs-oC",
      "y5fsjDAAAAAJ",
      "gzQY0s8AAAAJ",
      "RJ_c4xkAAAAJ",
      "hgaAO6QAAAAJ",
      "2yAMJ1YAAAAJ",
      "IvqCXP4AAAAJ",
      "1HO5UacAAAAJ",
      "3YZTd_UAAAAJ",
      "7AZp7ycAAAAJ",
      "UjpM6IAAAAAJ",
      "06rffEkAAAAJ",
      "0GMYDB8AAAAJ",
      "AERPOfAAAAAJ",
      "UxEw4icAAAAJ",
      "Jkss014AAAAJ",
      "_tbXjP4AAAAJ",
      "W8VIEZgAAAAJ",
      "TpglobcAAAAJ",
      "TIpmrtoAAAAJ",
      "9YmWGQEAAAAJ",
      "4hbasIcAAAAJ",
      "68hTs9wAAAAJ",
      "-pu6i_4AAAAJ",
      "ss-IvjMAAAAJ",
      "sFQD3k4AAAAJ",
      "HB6mzf0AAAAJ",
      "s4Q8hbUAAAAJ",
      "H8FOdHwAAAAJ",
      "MExi4eQAAAAJ",
      "GIZzv_cAAAAJ"
    ],
    "5bc-9A4AAAAJ": [],
    "osxb7aMAAAAJ": [
      "GcuxcLYAAAAJ",
      "l9Or8EMAAAAJ",
      "1JvIQ8EAAAAJ",
      "sao65cAAAAAJ",
      "F_ASWCUAAAAJ",
      "RiLCRDwAAAAJ",
      "e_Y58QEAAAAJ",
      "wb-DKCIAAAAJ",
      "09_uzi8AAAAJ",
      "YAHWbtkAAAAJ",
      "B847xq8AAAAJ",
      "btWJVrgAAAAJ",
      "ffqbs_0AAAAJ",
      "QxbpIMUAAAAJ",
      "l-Ilg5MAAAAJ",
      "yLenCKUAAAAJ",
      "zK4uegoAAAAJ",
      "X1N99wsAAAAJ",
      "gewVBA4AAAAJ",
      "hr1PnUkAAAAJ",
      "JIJGu30AAAAJ",
      "5qh5cc0AAAAJ",
      "A4xI6moAAAAJ",
      "k9uWzAIAAAAJ",
      "ONv0HgMAAAAJ",
      "7KI2Fa8AAAAJ",
      "6Atez3UAAAAJ",
      "1eBgIWsAAAAJ",
      "meTZPLgAAAAJ",
      "UvponD8AAAAJ",
      "UpnZAg0AAAAJ",
      "d5Djcl4AAAAJ",
      "LSr5-w4AAAAJ"
    ],
    "nTiSnwUAAAAJ": [],
    "sgsLkM0AAAAJ": [
      "zj6FavAAAAAJ",
      "8R35rCwAAAAJ",
      "3oe0I0QAAAAJ",
      "vfPE6hgAAAAJ",
      "NSWI3OwAAAAJ",
      "LIJQ_ZYAAAAJ",
      "ZaJEZpYAAAAJ",
      "q7nFtUcAAAAJ",
      "zBUwaGkAAAAJ",
      "2efgcS0AAAAJ",
      "1P8Zu04AAAAJ",
      "-w5DuHgAAAAJ",
      "0VAe-TQAAAAJ",
      "vtwH6GkAAAAJ",
      "DRnOvU8AAAAJ",
      "dHec-LkAAAAJ",
      "bWoGh8UAAAAJ"
    ],
    "BtwmZfQAAAAJ": [
      "wbZc9nUAAAAJ",
      "-0T1EtoAAAAJ",
      "3nYG5BMAAAAJ",
      "uy8T6BYAAAAJ",
      "568MtVQAAAAJ",
      "DsD8SDYAAAAJ",
      "1RElnvEAAAAJ",
      "WMHRQ-8AAAAJ",
      "14LdhrcAAAAJ",
      "xMhGYpgAAAAJ",
      "cAy9G6oAAAAJ",
      "-vsw3Z4AAAAJ",
      "NlnpI7QAAAAJ",
      "dtxmW18AAAAJ",
      "R4EFw_AAAAAJ",
      "Qo72ORkAAAAJ",
      "TCg0M_8AAAAJ",
      "lWqzpFkAAAAJ",
      "MocRuzIAAAAJ",
      "fRwndxUAAAAJ",
      "SCdhzWoAAAAJ",
      "CwazDKgAAAAJ",
      "_7Q8uIYAAAAJ",
      "m9vu99gAAAAJ",
      "uobCsQgAAAAJ",
      "TZ7xuYAAAAAJ",
      "5i5vhFQAAAAJ",
      "gs5xeKUAAAAJ",
      "oajw_bMAAAAJ",
      "91R66jcAAAAJ",
      "bTVBQpcAAAAJ",
      "pwIuivQAAAAJ",
      "rYIFql4AAAAJ",
      "QMFlwLQAAAAJ",
      "Lpc8gO4AAAAJ",
      "RzEnQmgAAAAJ",
      "owApkWAAAAAJ",
      "vN-is70AAAAJ",
      "1QKK-zgAAAAJ",
      "AU5d1KUAAAAJ",
      "2sjWX1sAAAAJ",
      "IR-Vw9kAAAAJ",
      "KFXJQ90AAAAJ",
      "SlZavnIAAAAJ",
      "StIHrlMAAAAJ",
      "9KRcr3QAAAAJ",
      "kmoklesAAAAJ",
      "q4qDvAoAAAAJ",
      "nUDR4_gAAAAJ",
      "FmnJtIYAAAAJ",
      "QSQuvHYAAAAJ",
      "AdBqkbIAAAAJ",
      "cWMhYJcAAAAJ",
      "qmnmdYsAAAAJ",
      "_zvL7YIAAAAJ",
      "IzLlyzsAAAAJ",
      "hW-VFhwAAAAJ",
      "MACCA0cAAAAJ",
      "nHlOHXMAAAAJ",
      "LO06dIUAAAAJ",
      "N4kcAKIAAAAJ",
      "m3aJauEAAAAJ",
      "frSU5j0AAAAJ",
      "HcyivC0AAAAJ",
      "DHddutUAAAAJ",
      "O-29z5AAAAAJ",
      "AScYAMYAAAAJ",
      "W_L_cZsAAAAJ",
      "E20Gzu0AAAAJ",
      "CYfxRVIAAAAJ",
      "WHTB3_MAAAAJ",
      "8f7XTQIAAAAJ",
      "RtwBsDYAAAAJ"
    ],
    "euc0GX4AAAAJ": [
      "qJBXk9cAAAAJ",
      "dOad5HoAAAAJ",
      "UAwKvEsAAAAJ",
      "w68-7AYAAAAJ",
      "332L1coAAAAJ",
      "4gVbilMMp-AC",
      "x04W_mMAAAAJ",
      "71G11ksAAAAJ",
      "6jv2-OYAAAAJ",
      "Y_NYX7MAAAAJ",
      "Ue4wghAAAAAJ",
      "zTfIpA4AAAAJ",
      "B4NztA8AAAAJ",
      "VyGrp0QAAAAJ",
      "sNMowOIAAAAJ",
      "LeHa8psAAAAJ",
      "g-hQdY8AAAAJ",
      "v474hP4AAAAJ",
      "gnox0EsAAAAJ",
      "n8tK15oAAAAJ",
      "wsNa_W4AAAAJ",
      "rrPyvsgAAAAJ",
      "BOMboVoAAAAJ",
      "rRJ9wTJMUB8C",
      "feURfe4AAAAJ",
      "N_jSE08AAAAJ",
      "BB4R2_gAAAAJ",
      "TB5OwW8AAAAJ",
      "xZal_nUAAAAJ",
      "byA9yI0AAAAJ",
      "vvUmC_EAAAAJ",
      "sVR8ktkAAAAJ",
      "wb-DKCIAAAAJ",
      "Ao4gtsYAAAAJ",
      "KFTttp0AAAAJ",
      "7EPsnxEAAAAJ",
      "lutJce0AAAAJ",
      "lT3YoNkAAAAJ",
      "lRLvr5EAAAAJ",
      "30Izy_cAAAAJ",
      "XUI4PMEAAAAJ",
      "tWBPUHwAAAAJ",
      "TyyftvAAAAAJ",
      "a4unsk4AAAAJ",
      "FIBljEYAAAAJ",
      "TPnedXMAAAAJ",
      "z9em5msAAAAJ",
      "5cSFXKQAAAAJ",
      "4C9naMgAAAAJ",
      "9rhEuW8AAAAJ",
      "PvHFAfIAAAAJ",
      "eJt6cSIAAAAJ",
      "Hft2m4wAAAAJ",
      "h-pwCMUAAAAJ",
      "8BX3BokAAAAJ",
      "LJnNKXMAAAAJ",
      "I_YIc0YAAAAJ",
      "TWXQyuEAAAAJ",
      "rXYLXJMAAAAJ",
      "twlFI3sAAAAJ",
      "hWPIzdkAAAAJ",
      "zvz6LIYAAAAJ",
      "0aJ--58AAAAJ",
      "UjpbO6IAAAAJ",
      "krTnRRUAAAAJ",
      "yK7yTiwAAAAJ",
      "NCkkQAMAAAAJ",
      "ibu3FwsAAAAJ",
      "mgMzkYMAAAAJ",
      "GRMMc_MAAAAJ",
      "gWocpdkAAAAJ",
      "lc6CVqEAAAAJ",
      "sXtjq8IAAAAJ",
      "JIUz890AAAAJ",
      "5elBSHQAAAAJ",
      "CIZwXAcAAAAJ",
      "BFlpS-8AAAAJ",
      "23SZHUwAAAAJ",
      "x1mbRloAAAAJ",
      "-Txt8vsAAAAJ",
      "PTeSCbIAAAAJ",
      "vC8DssQAAAAJ",
      "Ay-iC-8AAAAJ",
      "Xz-fi1cAAAAJ",
      "KarsBWAAAAAJ",
      "2Jw3gv4AAAAJ",
      "ZYc-LuMAAAAJ",
      "YOVZiJkAAAAJ",
      "R6jE0VEAAAAJ",
      "-fPI9LgAAAAJ",
      "A2KHeEgAAAAJ",
      "fJsSvzkAAAAJ",
      "BxlScrEAAAAJ",
      "FWJZYMYAAAAJ",
      "kzglGGEAAAAJ",
      "OSg3D9MAAAAJ",
      "KYHL9aIAAAAJ"
    ],
    "uA0kNBUAAAAJ": [
      "kwqPtgcAAAAJ",
      "OafZcSMAAAAJ",
      "YU4Ce_MAAAAJ",
      "jjbNzhYAAAAJ",
      "FTYtHb4AAAAJ",
      "rBJV6QUAAAAJ",
      "SQzKCuUAAAAJ",
      "1gqyKqcAAAAJ",
      "1LyndUsAAAAJ",
      "Iw9vL9cAAAAJ",
      "oEfBf3sAAAAJ",
      "kO_RfY4AAAAJ",
      "47L65OMAAAAJ",
      "IVMpLjIAAAAJ",
      "DkUUhXEAAAAJ",
      "06OJ1FQAAAAJ",
      "SqHX4UgAAAAJ",
      "8R35rCwAAAAJ",
      "nJJ44zoAAAAJ",
      "J5gGsg0AAAAJ",
      "jqzSwdsAAAAJ",
      "5En4XZEAAAAJ",
      "VEfQf5wAAAAJ",
      "0Knul6gAAAAJ",
      "mnAk4HIAAAAJ",
      "9gO29eUAAAAJ",
      "Qogwc7QAAAAJ",
      "eeSqBRoAAAAJ",
      "r7wE4M4AAAAJ",
      "kc3snaQAAAAJ"
    ],
    "jERkdhIAAAAJ": [],
    "MbF6rTEAAAAJ": [
      "kLUQrrYAAAAJ",
      "8iQk0DIAAAAJ",
      "k4Q3TYwAAAAJ",
      "9NkngDMAAAAJ",
      "Sbpra_AAAAAJ",
      "ziP-50wAAAAJ",
      "f2x233wAAAAJ",
      "5lB_d78AAAAJ",
      "ZQ4iPZUAAAAJ",
      "7t4jbPQAAAAJ",
      "PqQAVcAAAAAJ",
      "TnvQIrYAAAAJ",
      "G1WMpcUAAAAJ",
      "qRnP-p0AAAAJ",
      "t0ZfFH8AAAAJ",
      "2SvHNeQAAAAJ",
      "WfS41RAAAAAJ",
      "ZvFaPxUAAAAJ",
      "mBHPMZUAAAAJ",
      "OEJUgwkAAAAJ",
      "LxpnsSMAAAAJ",
      "MK6zHkYAAAAJ",
      "wYMTld8AAAAJ",
      "h60zIiUAAAAJ",
      "1bwPKXpo97YC",
      "2mYxmokAAAAJ",
      "jr7gGB4AAAAJ",
      "kwnwhrgAAAAJ",
      "RY7cuPAAAAAJ",
      "HsfKE0sAAAAJ",
      "XPrjbvoAAAAJ",
      "UrsQh_0AAAAJ",
      "oDwLyYUAAAAJ",
      "8U7d-_MAAAAJ",
      "ETJoidYAAAAJ",
      "_1hCq3UAAAAJ",
      "6ztViH8AAAAJ",
      "KLSUWBAAAAAJ",
      "WaGlwJ4AAAAJ",
      "YRPveMcAAAAJ",
      "K0kaNvkAAAAJ",
      "OcPVegoAAAAJ",
      "0lcJYs8AAAAJ",
      "CaHuRsgAAAAJ",
      "U-RE8IgAAAAJ",
      "JnWSU4oAAAAJ",
      "LXwCIisAAAAJ",
      "6lyS2T4AAAAJ"
    ],
    "o6LlkNMAAAAJ": [],
    "sPlonWcAAAAJ": [
      "jIs-Y2gAAAAJ",
      "RCi98EAAAAAJ",
      "jikMhF4AAAAJ",
      "aO-849gAAAAJ",
      "DqXsbPAAAAAJ",
      "B1Dy3WMAAAAJ",
      "Hyhp_zUAAAAJ",
      "Ah6du3EAAAAJ",
      "yFEHsv4AAAAJ",
      "NJ3TiCIAAAAJ",
      "ARmXjpcAAAAJ",
      "02nHF0gAAAAJ",
      "avud6aAAAAAJ",
      "1dPriv4AAAAJ",
      "TbN31LMAAAAJ",
      "0a58TKgAAAAJ",
      "uVgMw8YAAAAJ",
      "I1mOQpAAAAAJ",
      "6QQX88UAAAAJ",
      "68V-nNAAAAAJ",
      "_qr34PIAAAAJ",
      "JYaJjE8AAAAJ",
      "VGr54BoAAAAJ",
      "T0qnS1oAAAAJ",
      "tflc42wAAAAJ",
      "48Y9F-YAAAAJ",
      "5QaaYmQAAAAJ",
      "5sL0xZ4AAAAJ",
      "UgHB5oAAAAAJ",
      "UjpbO6IAAAAJ",
      "X1zsXTgAAAAJ",
      "8Qu_gAMAAAAJ",
      "hfmi3QwAAAAJ",
      "sF1vZ0oAAAAJ",
      "LidK--MAAAAJ",
      "tgm2Y7oAAAAJ",
      "q5GIWC0AAAAJ",
      "oHv6BrYAAAAJ",
      "r0EFvOoAAAAJ",
      "TaR3dq4AAAAJ",
      "qWEImhMAAAAJ",
      "eG10MqcAAAAJ",
      "HqTUx7YAAAAJ",
      "r2v8Jc0AAAAJ",
      "ZocLOAMAAAAJ",
      "kV5zQBkAAAAJ",
      "jz2Tvk4AAAAJ",
      "6-ojl1EAAAAJ",
      "jNQlAkoAAAAJ",
      "gdD2E9QAAAAJ"
    ],
    "krrh6OUAAAAJ": [
      "kukA0LcAAAAJ",
      "dxwPYhQAAAAJ",
      "BFzFy1YAAAAJ",
      "lmjR_qMAAAAJ",
      "DZ-fHPgAAAAJ",
      "O-oICE8AAAAJ",
      "U89FHq4AAAAJ",
      "8R35rCwAAAAJ",
      "RUP4S68AAAAJ",
      "f31mvPsAAAAJ",
      "htPVdRMAAAAJ",
      "eM916YMAAAAJ",
      "79k7bGEAAAAJ",
      "rF2VvOgAAAAJ",
      "-8DNE4UAAAAJ"
    ],
    "odFQXSYAAAAJ": [],
    "UfbuDH8AAAAJ": [],
    "Ch9iRwQAAAAJ": [],
    "k-nF0qgAAAAJ": [
      "U_8MaDMAAAAJ",
      "xR6fOrAAAAAJ",
      "rY8u8xkAAAAJ",
      "CYkqs5UAAAAJ",
      "aC55XVgAAAAJ",
      "a4unsk4AAAAJ",
      "N-gKE0oAAAAJ",
      "I8kmeZYAAAAJ",
      "AGaoCGAAAAAJ",
      "9yRwkr4AAAAJ",
      "MzAzFm8AAAAJ",
      "2DjuFy8AAAAJ",
      "LUn8dAEAAAAJ",
      "30VwF8YAAAAJ",
      "7YZ3sCEAAAAJ",
      "wVzFBcEAAAAJ",
      "9ODmYwoAAAAJ",
      "TcXHyvMAAAAJ",
      "job97voAAAAJ",
      "Ee4Peu4AAAAJ",
      "qy87mcIAAAAJ",
      "q3K8X-IAAAAJ",
      "smo705AAAAAJ",
      "7yqJjsgAAAAJ",
      "dLx3Um4AAAAJ",
      "NzLGjWoAAAAJ",
      "MnoNkkcAAAAJ",
      "_oZJDPEAAAAJ",
      "fT7XeUEAAAAJ",
      "o_4HDRwAAAAJ",
      "PtSVy9AAAAAJ",
      "bRuEhB8AAAAJ",
      "np43vMAAAAAJ",
      "k_9sF90AAAAJ",
      "a-ifJKsAAAAJ"
    ],
    "ZKRs0oEAAAAJ": [
      "vfPE6hgAAAAJ",
      "TwABcRgAAAAJ",
      "pouyVyUAAAAJ",
      "2efgcS0AAAAJ",
      "6S9C8XoAAAAJ",
      "EM9YhH0AAAAJ",
      "YfPA4YsAAAAJ",
      "KCdL5B0AAAAJ"
    ],
    "KCdL5B0AAAAJ": [
      "vfPE6hgAAAAJ",
      "2efgcS0AAAAJ",
      "8R35rCwAAAAJ",
      "DkYYtGIAAAAJ",
      "COuXyKwAAAAJ",
      "CG04xrsAAAAJ",
      "HuckLq8AAAAJ",
      "vA6ZQ_AAAAAJ",
      "DRnOvU8AAAAJ",
      "zUu0JKYAAAAJ",
      "5K1QB_8AAAAJ",
      "GyVPmtYAAAAJ",
      "3oe0I0QAAAAJ",
      "_QlCijoAAAAJ"
    ],
    "oAlCitYAAAAJ": [],
    "E__5Lr0AAAAJ": [
      "vRI2blsAAAAJ",
      "GQ6xw-oAAAAJ",
      "55TAOdgAAAAJ",
      "lPycXNcAAAAJ",
      "qJsC_XsAAAAJ",
      "1ypDmDwAAAAJ",
      "A_grkugAAAAJ",
      "6Wg-hF4AAAAJ",
      "RrYw5jkAAAAJ",
      "2uHyOSIAAAAJ",
      "8r2Fiv4AAAAJ",
      "mFiX664AAAAJ",
      "q1fmhDkAAAAJ",
      "ih3MdzUAAAAJ",
      "rtpoh5wAAAAJ",
      "bldHpWIAAAAJ",
      "scJH01QAAAAJ",
      "AG51Bv4AAAAJ",
      "hdTDzlQAAAAJ",
      "Daa3WpMAAAAJ",
      "7joKYcAAAAAJ",
      "du74HM4AAAAJ",
      "I9Db408AAAAJ",
      "1jPQEVMAAAAJ",
      "abUmi6QAAAAJ",
      "gruYQKgAAAAJ",
      "WqF5JigAAAAJ",
      "azE-Yq0AAAAJ",
      "aO8KpGcAAAAJ",
      "f7jdz5IAAAAJ",
      "pndDsyoAAAAJ",
      "MO7qaUIAAAAJ",
      "1xqhHuEAAAAJ",
      "jGymlOMAAAAJ",
      "bAXsp5wAAAAJ",
      "ZCMRvtIAAAAJ",
      "uK5wa_EAAAAJ",
      "OEZ816YAAAAJ",
      "nPratvEAAAAJ",
      "HWFvq_wAAAAJ",
      "SmO3044AAAAJ",
      "hLxJ02wAAAAJ",
      "J8TSTXMAAAAJ",
      "PnVYoI4AAAAJ",
      "EJXN6tYAAAAJ",
      "itZCog0AAAAJ",
      "QKFb5pkAAAAJ",
      "nTiSnwUAAAAJ",
      "WrJerFMAAAAJ",
      "FMDCrXMAAAAJ",
      "dw5f9yIAAAAJ",
      "7uXCsMgAAAAJ"
    ],
    "MaSXNhUAAAAJ": [
      "vtwH6GkAAAAJ",
      "VjsNXysAAAAJ",
      "8fztli4AAAAJ",
      "bh-uRFMAAAAJ",
      "4V1nNm4AAAAJ",
      "VYiRfCwAAAAJ",
      "UWZA0v4AAAAJ"
    ],
    "4bl7qAgAAAAJ": [],
    "fn13u8IAAAAJ": [
      "BXJ3LwEAAAAJ",
      "S-pd0NwAAAAJ",
      "N-BBA20AAAAJ",
      "Koez6qoAAAAJ",
      "bGRVPl8AAAAJ",
      "qxWORNoAAAAJ",
      "avQkeJEAAAAJ",
      "cMPKe9UAAAAJ",
      "VFQRIOwAAAAJ",
      "dq3yXjkAAAAJ",
      "SEMSJmcAAAAJ",
      "X6fRNfUAAAAJ",
      "hqTu-QcAAAAJ",
      "jiTj6toAAAAJ",
      "uOLwGG4AAAAJ",
      "4uypulQAAAAJ",
      "JBU4ivcAAAAJ",
      "vGBcNVAAAAAJ",
      "a_dbdxAAAAAJ",
      "GhqD_rwAAAAJ",
      "7u_uyOsAAAAJ",
      "01ks8yYAAAAJ",
      "Q2U7G6oAAAAJ",
      "DSiNzkIAAAAJ",
      "xT19Jc0AAAAJ",
      "iSL1cKsAAAAJ",
      "hGMSFu4AAAAJ",
      "gLO_20kAAAAJ",
      "-Yge2L0AAAAJ"
    ],
    "-j0q9B4AAAAJ": [
      "C6pnolkAAAAJ",
      "hdTDzlQAAAAJ",
      "M-y2aLUAAAAJ",
      "YatAkqAAAAAJ",
      "OttawxUAAAAJ",
      "aO8KpGcAAAAJ",
      "2oy3OXYAAAAJ",
      "yDVn5LEAAAAJ",
      "BgQkdsYAAAAJ",
      "m791iN8AAAAJ",
      "vzr_L0EAAAAJ",
      "mV9LQUoAAAAJ",
      "eFxnUw4AAAAJ",
      "d7fUTNIAAAAJ",
      "Ooc7UNUAAAAJ",
      "Jlv4MR4AAAAJ",
      "xVFrEDwAAAAJ",
      "6OfjaHQAAAAJ",
      "5QYHMpsAAAAJ",
      "OVRxQj8AAAAJ",
      "V1qU5dwAAAAJ",
      "umivlPQAAAAJ"
    ],
    "oOwNKsAAAAAJ": [
      "Evgx6UkAAAAJ",
      "nst5fHgAAAAJ",
      "SWMKy70AAAAJ",
      "gV4dPToAAAAJ",
      "kMmxbbIAAAAJ",
      "UE6z_m8AAAAJ",
      "11JgipcAAAAJ",
      "MvyO9jAAAAAJ",
      "s5-hnX8AAAAJ",
      "UNHdIKoAAAAJ",
      "CMZAKkEAAAAJ",
      "bh-uRFMAAAAJ",
      "YLOz1kgAAAAJ",
      "opbZfw0AAAAJ",
      "zHCTHbYAAAAJ",
      "NirVdpMAAAAJ",
      "eJAV17IAAAAJ",
      "uXZaVaAAAAAJ",
      "fE4XXdIAAAAJ",
      "YR_MYrAAAAAJ",
      "pZhZndYAAAAJ",
      "Es6jE1kAAAAJ",
      "_1hCq3UAAAAJ",
      "2s9_ZWgAAAAJ",
      "f0Wc8tkAAAAJ",
      "Z03FLwkAAAAJ",
      "LfF2zfQAAAAJ",
      "gpLVKmEAAAAJ",
      "ykqoK38AAAAJ",
      "GelzUJgAAAAJ",
      "M3yUD0cAAAAJ",
      "p2ttvlEAAAAJ",
      "AjX6hisAAAAJ",
      "hlWhzU8AAAAJ",
      "N-BBA20AAAAJ",
      "68eoKg4AAAAJ",
      "4rihlSYAAAAJ",
      "wEUnFc0AAAAJ",
      "zX3ba1kAAAAJ",
      "a1ngrCIAAAAJ",
      "MDCu0WEAAAAJ",
      "B_rKfusAAAAJ",
      "ikn-xhYAAAAJ",
      "lLqnszIAAAAJ",
      "hRggMmIAAAAJ",
      "wUJ2bXgAAAAJ",
      "O-TV6OgAAAAJ",
      "MFVj4n4AAAAJ",
      "QH90248AAAAJ",
      "i5PazXwAAAAJ",
      "g3McheUAAAAJ",
      "IpBjTKQAAAAJ",
      "OxKLBqwAAAAJ",
      "7j3itaMAAAAJ",
      "6Ff2c8wAAAAJ",
      "T04c3fwAAAAJ",
      "0lZoXCUAAAAJ",
      "UNxLPX8AAAAJ",
      "f89ndwoAAAAJ",
      "rMtUkMcAAAAJ",
      "uqTfLEgAAAAJ",
      "FtMADIMAAAAJ",
      "58Yv3zUAAAAJ",
      "ZlE1X8IAAAAJ",
      "8Ut6gTcAAAAJ",
      "-3VoT8cAAAAJ",
      "dfddm3cAAAAJ",
      "zDax7zYAAAAJ",
      "9HiV_AEAAAAJ",
      "-ad5RSQAAAAJ",
      "srP2ANoAAAAJ",
      "_e5H8IoAAAAJ",
      "1WXpabIAAAAJ",
      "TvyZkdwAAAAJ",
      "_JWhZSAAAAAJ",
      "VeB3UbcAAAAJ",
      "ATOfqHEAAAAJ",
      "b8pLQq0AAAAJ",
      "GBJLTN8AAAAJ",
      "TZWVRR8AAAAJ",
      "l2Wb8uQAAAAJ",
      "SQ1eGN4AAAAJ",
      "lsYXBx8AAAAJ",
      "50xZTa0AAAAJ",
      "0BI-noIAAAAJ",
      "otHomQ8AAAAJ",
      "Z8U0BwcAAAAJ",
      "O5m7WK8AAAAJ",
      "VdBfGdoAAAAJ",
      "zQkIKOcAAAAJ",
      "TbQXQ7EAAAAJ",
      "QKgg5j4AAAAJ",
      "2uHUSa8AAAAJ",
      "r4_ZQ2AAAAAJ",
      "wFEJvJUAAAAJ",
      "WqJvRZoAAAAJ",
      "61lw9YIAAAAJ",
      "0koVxB4AAAAJ",
      "pDkhB5EAAAAJ",
      "eECXWqUAAAAJ",
      "H9x5YXkAAAAJ",
      "cjx8PKUAAAAJ",
      "Pe39BdUAAAAJ",
      "tkDsIggAAAAJ",
      "2vQRGrYAAAAJ",
      "zkvW8FQAAAAJ",
      "JFap1psAAAAJ",
      "YgSxvV4AAAAJ",
      "hgZrGpkAAAAJ",
      "eCXP24kAAAAJ",
      "ri4rEPMAAAAJ"
    ],
    "zBUwaGkAAAAJ": [
      "8R35rCwAAAAJ",
      "-gJkPHIAAAAJ",
      "vfPE6hgAAAAJ",
      "lPaISmIAAAAJ",
      "aH8AJu4AAAAJ",
      "5VaXUQsAAAAJ",
      "1O83J5MAAAAJ",
      "IrixA8MAAAAJ"
    ],
    "OI7zFmwAAAAJ": [
      "E0iCaa4AAAAJ",
      "yy0UFOwAAAAJ",
      "4gdSoOYAAAAJ",
      "LIJQ_ZYAAAAJ",
      "KTYQRzYAAAAJ",
      "J9PoyoIAAAAJ",
      "Pb2O3oYAAAAJ",
      "8R35rCwAAAAJ",
      "y0LVrtgAAAAJ",
      "WxL13BAAAAAJ",
      "vfPE6hgAAAAJ",
      "uemlfQYAAAAJ",
      "pqP5_PgAAAAJ",
      "NSWI3OwAAAAJ",
      "ADkiClQAAAAJ",
      "P9FclNEAAAAJ",
      "C_AP8XAAAAAJ",
      "_LSLmbYAAAAJ",
      "x-AvvrYAAAAJ",
      "42MVVPgAAAAJ",
      "vrYHLMgAAAAJ",
      "2DBmo-wAAAAJ",
      "wotfaAgAAAAJ",
      "SzHPa90AAAAJ",
      "mWdYMZ8AAAAJ",
      "vEYUIioAAAAJ",
      "p4zxPP8AAAAJ",
      "-S_9ZRcAAAAJ",
      "aMZAyzwAAAAJ",
      "mwzYYPgAAAAJ",
      "Q1csT-8AAAAJ",
      "6gKEYRgAAAAJ",
      "jrfFYAIAAAAJ",
      "p71ikL4AAAAJ",
      "V64dmUAAAAAJ",
      "eXqOR10AAAAJ",
      "iyEuK8kAAAAJ",
      "l-la0GQAAAAJ",
      "bDq7MZMAAAAJ",
      "NLOh3SUAAAAJ",
      "d5y4iKAAAAAJ",
      "UJcm1MoAAAAJ",
      "-w5DuHgAAAAJ",
      "6p0ygKUAAAAJ",
      "Kq0feJIAAAAJ",
      "WCqe8yUAAAAJ",
      "YfPA4YsAAAAJ",
      "62ElavIAAAAJ",
      "dVtzVVAAAAAJ",
      "rE7-N30AAAAJ",
      "DSmxHuMAAAAJ",
      "GnDGqKQAAAAJ",
      "V4Y4ETQAAAAJ",
      "nZsD8XwAAAAJ",
      "vcw0TJIAAAAJ",
      "HEY3UzgAAAAJ",
      "21W5L1YAAAAJ",
      "Izhkp4YAAAAJ",
      "Wel9l1wAAAAJ",
      "nkmDOPgAAAAJ",
      "sUb_eyUAAAAJ",
      "JMHsqIkAAAAJ",
      "RhOpyXcAAAAJ",
      "mIlaYj0AAAAJ",
      "1bF2s2kAAAAJ",
      "YH1v2uYAAAAJ",
      "1P8Zu04AAAAJ",
      "DRnOvU8AAAAJ",
      "8C2_ZVsAAAAJ",
      "Z3dxz9IAAAAJ",
      "Oz9MLlEAAAAJ",
      "KcPrLhIAAAAJ",
      "iyDxq0EAAAAJ",
      "aO8KpGcAAAAJ",
      "IB_jPZ0AAAAJ",
      "hYVMrzsAAAAJ",
      "q7nFtUcAAAAJ",
      "Vzr1RukAAAAJ",
      "tWoesqcAAAAJ",
      "lJbBWhMAAAAJ",
      "T9To2C0AAAAJ",
      "xBH73TYAAAAJ",
      "aPqcyU4AAAAJ",
      "-gJkPHIAAAAJ",
      "6uIhh6MAAAAJ",
      "uQRY6KoAAAAJ",
      "RK72t68AAAAJ",
      "os-DVLkAAAAJ",
      "tlhfhLoAAAAJ",
      "xBv-PMEAAAAJ",
      "aH8AJu4AAAAJ",
      "xPWCLvEAAAAJ",
      "T04c3fwAAAAJ",
      "FR8zF_4AAAAJ",
      "5Qp_0TUAAAAJ",
      "BC8TixYAAAAJ",
      "wUUxGfAAAAAJ",
      "2u8jlxgAAAAJ",
      "2IvwHucAAAAJ",
      "jzddqQQAAAAJ",
      "DnQMAnwAAAAJ",
      "TmuUs30AAAAJ",
      "izgpKaYAAAAJ",
      "YkSJ7-8AAAAJ",
      "O8wbTncAAAAJ",
      "abyZPXsAAAAJ",
      "XI5i5AUAAAAJ",
      "ji6BSBoAAAAJ",
      "X9AjIugAAAAJ",
      "klZ2MMcAAAAJ",
      "5VaXUQsAAAAJ",
      "3oe0I0QAAAAJ",
      "C-ZlBWMAAAAJ",
      "zBUwaGkAAAAJ",
      "T6PbwPIAAAAJ",
      "1VI_oYUAAAAJ",
      "2yAMJ1YAAAAJ",
      "hTxCe4oAAAAJ",
      "8Phz8n4AAAAJ",
      "vIewY1EAAAAJ",
      "jWz4LrAAAAAJ",
      "rsBBj3IAAAAJ",
      "2fo_v44AAAAJ",
      "EPfOJwQAAAAJ",
      "GuU6oA4AAAAJ",
      "0nPi5YYAAAAJ",
      "fz7LJPIAAAAJ",
      "4gVbilMMp-AC",
      "fMN7wNwAAAAJ",
      "RNdGVHoAAAAJ",
      "Cmf2HdcAAAAJ",
      "LIG-4BcAAAAJ",
      "_AoZDGEAAAAJ",
      "DSKzTCAAAAAJ",
      "y-f-MZgAAAAJ",
      "wUZuAisAAAAJ",
      "neGbgzYAAAAJ",
      "c9QnkJMAAAAJ",
      "RM2vMNcAAAAJ",
      "VIPjBSgAAAAJ",
      "uWfcPkkAAAAJ",
      "IetijcoAAAAJ",
      "oB0g2IkAAAAJ",
      "BTEsUk8AAAAJ",
      "bYMpSOMAAAAJ",
      "OuSPv-AAAAAJ",
      "1XbRknQAAAAJ",
      "PDu5GC8AAAAJ",
      "J-dq_8EAAAAJ",
      "UyZL660AAAAJ",
      "BYrARP4AAAAJ",
      "XrwHHxAAAAAJ",
      "YT5NJ24AAAAJ",
      "l2FS2_IAAAAJ",
      "ExGkzjQAAAAJ",
      "95hBTe8AAAAJ",
      "qdnDZkYAAAAJ",
      "ZGpE5cYAAAAJ",
      "ID9QePIAAAAJ",
      "c4YtO-MAAAAJ",
      "J8OgouwAAAAJ",
      "tBbUAfsAAAAJ",
      "iJbdUkQAAAAJ",
      "fhaNx_oAAAAJ",
      "bh-uRFMAAAAJ",
      "0JH6YbEAAAAJ",
      "e1zesfMAAAAJ",
      "8LqrW5AAAAAJ",
      "ncJWfs0AAAAJ",
      "ZRl2aAwAAAAJ",
      "fjuWXroAAAAJ",
      "eJISgYQAAAAJ",
      "1FiIlQsAAAAJ",
      "q-WSy3AAAAAJ",
      "VVIAoY0AAAAJ",
      "CUlqK5EAAAAJ",
      "AOdxmJYAAAAJ",
      "ey9AQcEAAAAJ",
      "aOklxsQAAAAJ",
      "dthSEsoAAAAJ",
      "uY4D8-wAAAAJ",
      "CBLnYLEAAAAJ",
      "eZQNcvcAAAAJ",
      "wxnzyjwAAAAJ",
      "T7uctwYAAAAJ",
      "r5WezOYAAAAJ",
      "f_sApl4AAAAJ"
    ],
    "0lZoXCUAAAAJ": [
      "_PZKLYUAAAAJ",
      "_1hCq3UAAAAJ",
      "J_XhIsgAAAAJ",
      "opbZfw0AAAAJ",
      "YAHWbtkAAAAJ",
      "b3HMX-sAAAAJ",
      "78Z4ctAAAAAJ",
      "3fvu4fcAAAAJ",
      "VZCAjz4AAAAJ",
      "zK4uegoAAAAJ",
      "BgOXDogAAAAJ",
      "F_ASWCUAAAAJ",
      "Zq4ioqu5yb8C",
      "16posrQAAAAJ",
      "huxkCSoAAAAJ",
      "VDyjbagAAAAJ",
      "8eB7Q1kAAAAJ",
      "ohL-Y50AAAAJ",
      "-sMCAGcAAAAJ",
      "O_7MVDIAAAAJ",
      "XD_01h8AAAAJ",
      "nSSZmScAAAAJ",
      "q4QmSekAAAAJ",
      "3zhgn8MAAAAJ",
      "SQ1eGN4AAAAJ",
      "q4zv0KYAAAAJ",
      "VX7d5EQAAAAJ",
      "fNvryVUAAAAJ",
      "4_i_4TkAAAAJ",
      "9ZGqm5QAAAAJ",
      "NirVdpMAAAAJ",
      "oOwNKsAAAAAJ",
      "-JOkpfQAAAAJ",
      "Wn8xr_gAAAAJ",
      "YPineKcAAAAJ",
      "9oNkK7YAAAAJ",
      "ynJ-R00AAAAJ",
      "3Lmd6AMAAAAJ",
      "MGXRuXYAAAAJ",
      "cuSWd3cAAAAJ",
      "XgifkSsAAAAJ",
      "k9uWzAIAAAAJ",
      "Jc97EyAAAAAJ",
      "_xyC5igAAAAJ",
      "_e5H8IoAAAAJ",
      "L82mYv8AAAAJ",
      "NDhlLv0AAAAJ",
      "fcqBMQgAAAAJ",
      "R1YK5BsAAAAJ",
      "v-hyE4MAAAAJ",
      "RvbzlYUAAAAJ",
      "58Yv3zUAAAAJ",
      "b6N0NroAAAAJ",
      "FecYwZ0AAAAJ",
      "zkvW8FQAAAAJ",
      "B_rKfusAAAAJ",
      "FGGfkmMAAAAJ",
      "Jlv4MR4AAAAJ",
      "SAEI0jwAAAAJ",
      "fkGRlH0AAAAJ",
      "5EMVIoEAAAAJ",
      "rXYLXJMAAAAJ",
      "6qE0tdAAAAAJ",
      "IT7lx4sAAAAJ",
      "tFq6hXAAAAAJ",
      "qCdLtIoAAAAJ",
      "1UWlwuEAAAAJ",
      "Y_Ieu7EAAAAJ",
      "S39CcbQAAAAJ",
      "GpXyLGwAAAAJ",
      "zKORw8wAAAAJ",
      "70Rmp1oAAAAJ",
      "ax3nTU8AAAAJ",
      "XRujzBsAAAAJ",
      "wWaA2QwAAAAJ",
      "GkMfzy4AAAAJ",
      "mTqef3oAAAAJ",
      "eQujqDgAAAAJ",
      "YP90oGMAAAAJ",
      "xuNJ-d8AAAAJ",
      "Vv8UdowAAAAJ",
      "dfScyQgAAAAJ",
      "_cMw1IUAAAAJ",
      "uWNrcTUAAAAJ",
      "FzSHcngAAAAJ"
    ],
    "XqLiBQMAAAAJ": [
      "KgZxzjsAAAAJ",
      "nujTx04AAAAJ",
      "0OsAngEAAAAJ",
      "uT8fgagAAAAJ",
      "sQ6l4sMAAAAJ",
      "lH1PdF8AAAAJ",
      "TanjFwoAAAAJ",
      "hacOX_AAAAAJ",
      "vEcgp3AAAAAJ",
      "fe-1v0MAAAAJ",
      "nRQi4O8AAAAJ",
      "bZ9oyW8AAAAJ",
      "78WTKm4AAAAJ",
      "hYlbtl8AAAAJ",
      "rGF6-WkAAAAJ",
      "Mf9VHRcAAAAJ",
      "CSzbLwUAAAAJ",
      "WDJ7tY0AAAAJ",
      "GSHmKZkAAAAJ",
      "m3DDS00AAAAJ",
      "iyVHKkcAAAAJ",
      "DNuiPHwAAAAJ",
      "Mfrpm_IAAAAJ",
      "HWFvq_wAAAAJ",
      "xF7oivwAAAAJ",
      "PaFLL10AAAAJ",
      "ghZkSV8AAAAJ",
      "6V6u2g0AAAAJ",
      "bW1gAI8AAAAJ",
      "-g58LsoAAAAJ",
      "11aRt9oAAAAJ",
      "BWnXD4IAAAAJ",
      "9RAHYd0AAAAJ",
      "PqlE63kAAAAJ",
      "bW6qGV0AAAAJ",
      "DBXWBqcAAAAJ",
      "CtRMD1UAAAAJ",
      "UeltiQ4AAAAJ",
      "9oz-dvgAAAAJ",
      "GdOmgYwAAAAJ",
      "WLN3QrAAAAAJ",
      "hiGI9v0AAAAJ",
      "gMBvzGoAAAAJ",
      "Ikt1e-0AAAAJ",
      "Ux677B4AAAAJ",
      "ISRNX3gAAAAJ",
      "8R35rCwAAAAJ",
      "Iv6ll44AAAAJ",
      "UpZbV44AAAAJ",
      "V6FaD-UAAAAJ",
      "-84M1m0AAAAJ",
      "Y2GtJkAAAAAJ",
      "aOklxsQAAAAJ",
      "v6HphBcAAAAJ",
      "ZqGaKSgAAAAJ",
      "IpmnLFcAAAAJ",
      "L3wy9QMAAAAJ",
      "JfblW3MAAAAJ",
      "RL7jPuQAAAAJ",
      "Bx9WGD6lBFEC",
      "LKv32bgAAAAJ",
      "qtLQJRYAAAAJ",
      "9akH-n8AAAAJ",
      "fXPO6U0AAAAJ",
      "vqYq3egAAAAJ",
      "yxUduqMAAAAJ",
      "5WT38A0AAAAJ",
      "PDgp6OkAAAAJ",
      "eomC7sIAAAAJ",
      "7620QAMAAAAJ",
      "o6W_m00AAAAJ",
      "S-pd0NwAAAAJ",
      "m-om5O8AAAAJ",
      "720Ix7QAAAAJ",
      "Y8O9N_0AAAAJ",
      "rJMOlVsAAAAJ",
      "9sCGe-gAAAAJ",
      "K1LjZxcAAAAJ",
      "N-BBA20AAAAJ",
      "DQOT0OMAAAAJ",
      "1TV1xrMAAAAJ",
      "qNCTLV0AAAAJ",
      "IOagLnEAAAAJ",
      "tAK5l1IAAAAJ",
      "r2nw6DIAAAAJ",
      "R3sUe_EAAAAJ",
      "9Pl5k60AAAAJ",
      "7SgUlggAAAAJ",
      "KltleWgAAAAJ",
      "p9-ohHsAAAAJ",
      "VD5OsIwAAAAJ",
      "_moJlrIAAAAJ",
      "7Hdu5k4AAAAJ",
      "dY7OSl0AAAAJ",
      "5gi3Pm0AAAAJ",
      "j-P28bQAAAAJ",
      "xW-IxnwAAAAJ",
      "sCuACdkAAAAJ",
      "qrNPFTQAAAAJ",
      "pP7EjUsAAAAJ",
      "Li-BrU4AAAAJ",
      "J5ZQ-BUAAAAJ",
      "oN7gaqMAAAAJ",
      "-5_ksIkAAAAJ",
      "7agkJogAAAAJ",
      "w_XDRRsAAAAJ",
      "-CKm5DEAAAAJ",
      "zZO9qG4AAAAJ",
      "GlB6wkgAAAAJ",
      "1wzEtxcAAAAJ",
      "6G-l4o0AAAAJ",
      "cvgKxDQAAAAJ",
      "-F1rk68AAAAJ",
      "-bp44DoAAAAJ",
      "Fn6xg8EAAAAJ",
      "-XZ2HrAAAAAJ",
      "ZeJjFQMAAAAJ",
      "bYvl2kwAAAAJ",
      "e38fTZQAAAAJ",
      "c-uQx_0AAAAJ",
      "Kia-4B0AAAAJ",
      "samruv0AAAAJ",
      "9j-6i_oAAAAJ",
      "r6YTppEAAAAJ",
      "yzU6g24AAAAJ",
      "Z_CRrRwAAAAJ",
      "3_u1jHQAAAAJ",
      "vC2vywcAAAAJ",
      "b0k2tTgAAAAJ",
      "nBwaXUsAAAAJ",
      "9UfZJskAAAAJ",
      "5H0arvkAAAAJ",
      "YHxZLlwAAAAJ",
      "U_NEZHQAAAAJ",
      "rJvU7ngAAAAJ",
      "ivApfKcAAAAJ",
      "z76PBfYAAAAJ",
      "NWqnXNEAAAAJ",
      "TLQUwIMAAAAJ",
      "SM9v2HMAAAAJ",
      "C-5j7CQAAAAJ",
      "NCtKHnQAAAAJ",
      "R9L_AfQAAAAJ",
      "VQ70NaMAAAAJ"
    ],
    "pzw1-J4AAAAJ": [],
    "y1lVpBEAAAAJ": [
      "ID9QePIAAAAJ",
      "p-h_BvcAAAAJ",
      "W8VIEZgAAAAJ",
      "aOklxsQAAAAJ",
      "DplAah0AAAAJ",
      "2r7JwHIAAAAJ",
      "UvirJPEAAAAJ",
      "cSN8ZyQAAAAJ"
    ],
    "xRmmtzIAAAAJ": [],
    "APgaFK0AAAAJ": [
      "pKf5LtQAAAAJ",
      "xPqd-FMAAAAJ",
      "rbGxNYwAAAAJ",
      "bh-uRFMAAAAJ",
      "oS6gRc4AAAAJ",
      "r2OOH4cAAAAJ",
      "CX8zqPoAAAAJ",
      "91NxdC4AAAAJ",
      "Bkq-JK8AAAAJ",
      "ilSYpW0AAAAJ",
      "LkoaA0gAAAAJ",
      "cTZ7Bg8AAAAJ",
      "evVAmhQAAAAJ",
      "8HdRoroAAAAJ",
      "FC9Bt6cAAAAJ",
      "E6vCXjkAAAAJ",
      "UetM7FgAAAAJ",
      "spv5CecAAAAJ",
      "SuTJ0iMAAAAJ",
      "3o1o4ukAAAAJ",
      "QNvkEeoAAAAJ",
      "cB7hK3sAAAAJ",
      "TxKNCSoAAAAJ",
      "Fa1BONsAAAAJ",
      "j8ULfMsAAAAJ",
      "xZ8OqxMAAAAJ",
      "zRkcvqgAAAAJ",
      "D1okUccAAAAJ",
      "CSxgi6AAAAAJ",
      "6iOJ8foAAAAJ",
      "h1r4NG0AAAAJ",
      "jqWZsC0AAAAJ",
      "dNHNpxoAAAAJ",
      "irNcfEEAAAAJ",
      "CFp3IakAAAAJ",
      "ygpxbK8AAAAJ",
      "9xDADY4AAAAJ",
      "wkC9xHMAAAAJ",
      "wtRVnsYAAAAJ",
      "mYyG4p0AAAAJ",
      "pbb9CG4AAAAJ",
      "kWEH634AAAAJ",
      "oM6Pj3MAAAAJ",
      "B88-xMEAAAAJ",
      "QKOH5iYAAAAJ",
      "07NrZFIAAAAJ",
      "PGyMqU0AAAAJ",
      "de30Rq0AAAAJ",
      "8f9jTNcAAAAJ",
      "tzYolooAAAAJ",
      "DxoenfgAAAAJ",
      "3plYmtsAAAAJ",
      "yatiIigAAAAJ"
    ],
    "BsOkXDsAAAAJ": [
      "8R35rCwAAAAJ",
      "bdHgGgEAAAAJ",
      "BIwrJuQAAAAJ",
      "5dBp2f4AAAAJ",
      "vtwH6GkAAAAJ",
      "AvvaaJcAAAAJ",
      "UpZmJI0AAAAJ",
      "8TArOy0AAAAJ",
      "SJoRNbYAAAAJ",
      "PTS2AOgAAAAJ",
      "XCZpOcAAAAAJ",
      "n9K1v-cAAAAJ",
      "ROILf3EAAAAJ",
      "yn-nyJwAAAAJ",
      "-WZcuuwAAAAJ",
      "BZBkjNYAAAAJ"
    ],
    "1wLVDP4AAAAJ": [
      "8R35rCwAAAAJ",
      "vtwH6GkAAAAJ",
      "vfPE6hgAAAAJ",
      "52T2LYoAAAAJ",
      "DRnOvU8AAAAJ",
      "yy0UFOwAAAAJ",
      "eVYhlDQAAAAJ",
      "Ivot3fkAAAAJ",
      "zUJus70AAAAJ",
      "1O83J5MAAAAJ",
      "_EJrRVAAAAAJ",
      "VT7peyEAAAAJ",
      "QCBdB7AAAAAJ",
      "Zlpuln8AAAAJ",
      "bh-uRFMAAAAJ",
      "znnl0kwAAAAJ",
      "dnZ8udEAAAAJ",
      "xBH73TYAAAAJ",
      "BsOkXDsAAAAJ",
      "5dBp2f4AAAAJ",
      "l-la0GQAAAAJ",
      "5VaXUQsAAAAJ",
      "Uly5spMAAAAJ",
      "GyoKzFwAAAAJ",
      "8-p9CLsAAAAJ",
      "H3ZnCqYAAAAJ",
      "zMw7PF8AAAAJ",
      "C2_ZXdcAAAAJ",
      "d5y4iKAAAAAJ",
      "vgfGtykAAAAJ",
      "QWKWvbEAAAAJ"
    ],
    "5LLV29oAAAAJ": [],
    "nXBQn7gAAAAJ": [
      "RRmQyu8AAAAJ",
      "P4nfoKYAAAAJ",
      "TkVHKDgAAAAJ",
      "9xDADY4AAAAJ",
      "zjlFcrEAAAAJ",
      "wQv9q3cAAAAJ",
      "aXnBRhkAAAAJ",
      "dFNbaFsAAAAJ",
      "UsqNPH4AAAAJ",
      "tu39-p8AAAAJ",
      "P2mG6rcAAAAJ",
      "eLFhiSYAAAAJ",
      "aCYoiC8AAAAJ",
      "0VFi-vAAAAAJ",
      "SUd2LJUAAAAJ",
      "bhLQ6oQAAAAJ",
      "R0bnqaAAAAAJ",
      "1MceCxsAAAAJ",
      "oX-nvpwAAAAJ",
      "gwLessAAAAAJ",
      "CkVvikAAAAAJ",
      "bh-uRFMAAAAJ",
      "pViZYwIAAAAJ",
      "yV3_PTkAAAAJ",
      "_1basdkAAAAJ",
      "YOb3xH4AAAAJ",
      "XM97iScAAAAJ",
      "p1tu16UAAAAJ",
      "ntGll74AAAAJ",
      "RTbYeUcAAAAJ",
      "_Ic8wQ4AAAAJ",
      "bf2ZrFcAAAAJ",
      "eml8HfQAAAAJ",
      "JIhJXWUAAAAJ",
      "Za7uka8AAAAJ",
      "p9-ohHsAAAAJ",
      "LSvg03gAAAAJ",
      "8qOWtywAAAAJ",
      "PHJokEQAAAAJ",
      "oI6AIkMAAAAJ",
      "LAuxzv0AAAAJ",
      "nFzWaPMAAAAJ",
      "FzwrcoYAAAAJ",
      "6TGwETYAAAAJ",
      "UuE08jUAAAAJ",
      "UyKhhwwAAAAJ",
      "htt9T1AAAAAJ",
      "gb8sbdcAAAAJ",
      "8kA3eDwAAAAJ",
      "G0LfNJcAAAAJ",
      "xAFGASEAAAAJ",
      "6C8rf-0AAAAJ",
      "KoJrMIAAAAAJ",
      "EoACFEUAAAAJ",
      "5yNbjSoAAAAJ",
      "R2lPbLQAAAAJ"
    ],
    "4zybTq4AAAAJ": [
      "75q-6ZQAAAAJ",
      "YnJVsp4AAAAJ",
      "Vb3FLmkAAAAJ",
      "z4JhSBwAAAAJ",
      "TxdeO-UAAAAJ",
      "MK6zHkYAAAAJ",
      "DulpV-cAAAAJ",
      "umFQktIAAAAJ",
      "SWMKy70AAAAJ",
      "s_3ZE8kAAAAJ",
      "busWvZkAAAAJ",
      "E_a3VB4AAAAJ",
      "GNYqvgQAAAAJ",
      "4FM97JgAAAAJ",
      "2y5YF-gAAAAJ",
      "SupjsEUAAAAJ",
      "CMZAKkEAAAAJ",
      "aHtfItQAAAAJ",
      "LKv32bgAAAAJ",
      "wMx_Eu4AAAAJ",
      "Kr8JjF0AAAAJ",
      "Xz4RAJkAAAAJ",
      "V2Y1L4sAAAAJ",
      "XeEA6r8AAAAJ",
      "RRzVwKkAAAAJ",
      "Hy4JQ2MAAAAJ",
      "GkXqbmMAAAAJ",
      "n00Ol9UAAAAJ",
      "MoJFIiQAAAAJ",
      "aUeGl58AAAAJ",
      "nwHfwCIAAAAJ",
      "58As-bYAAAAJ",
      "u_fAQO4AAAAJ",
      "70vJVxcAAAAJ",
      "H-PvgRsAAAAJ",
      "LTa3GzEAAAAJ",
      "MzKvJhAAAAAJ",
      "84WzBlYAAAAJ",
      "F3_yOXUAAAAJ",
      "czyretsAAAAJ",
      "JGS2xjkAAAAJ",
      "6I7jyygAAAAJ",
      "r2E5Ak8AAAAJ",
      "mE1vlGEAAAAJ",
      "yVy2ZIwAAAAJ",
      "KhCiiawAAAAJ",
      "K2BMBtcAAAAJ",
      "SWqd2rgAAAAJ",
      "HXXSrNMAAAAJ",
      "bg8RrSkAAAAJ",
      "FkufKDgAAAAJ",
      "wFkXSlYAAAAJ",
      "SIxd6jgAAAAJ",
      "plYoF-MAAAAJ",
      "vzfO5TwAAAAJ",
      "zdn08t8AAAAJ",
      "2ZYz2SwAAAAJ",
      "2eADy_8AAAAJ",
      "WfS41RAAAAAJ",
      "sqCGBtYAAAAJ",
      "iq-7vhMAAAAJ",
      "c0JG32IAAAAJ",
      "OttawxUAAAAJ",
      "o7yFQXUAAAAJ",
      "vGBcNVAAAAAJ",
      "AjX6hisAAAAJ",
      "2aMqJTgAAAAJ",
      "guJ_kBQAAAAJ",
      "gjLr_FgAAAAJ",
      "Z8U0BwcAAAAJ",
      "eJAV17IAAAAJ",
      "yDZct7UAAAAJ",
      "EeYGZCwAAAAJ",
      "CTT44Y0AAAAJ",
      "Gkc2UeUAAAAJ",
      "68eoKg4AAAAJ",
      "MaSuaDkAAAAJ",
      "lXCP2cMAAAAJ",
      "i1NrG8UAAAAJ",
      "F0yiLRIAAAAJ",
      "s_YDrrgAAAAJ",
      "7Xko5sYAAAAJ",
      "QZCU3NkAAAAJ",
      "Gwb4YkUAAAAJ",
      "AxUAEQ4AAAAJ",
      "67kghxAAAAAJ",
      "tzqeiKYAAAAJ",
      "vyX6kpwAAAAJ",
      "Ka0xUQ4AAAAJ",
      "Yh0IoBgAAAAJ",
      "glV_LWsAAAAJ",
      "kNDEuygAAAAJ",
      "gYj6GRoAAAAJ",
      "xuDZ9-sAAAAJ",
      "OGweeKgAAAAJ",
      "yOt01wgAAAAJ",
      "aFDuhV8AAAAJ",
      "z0Y4snAAAAAJ",
      "tYE9bLoAAAAJ",
      "w1srHyIAAAAJ",
      "19evEwcAAAAJ",
      "lNVTz20AAAAJ",
      "u1Qs7YIAAAAJ",
      "0b_e2eAAAAAJ",
      "MHLyZY4AAAAJ",
      "Nn990CkAAAAJ",
      "bK3wI10AAAAJ",
      "LVPkbeYAAAAJ",
      "55TAOdgAAAAJ",
      "hr81fHoAAAAJ",
      "gckWFYUAAAAJ",
      "dqN-sYkAAAAJ",
      "ytm_89IAAAAJ",
      "yngEYigAAAAJ",
      "1b2kKWoAAAAJ"
    ],
    "H1vNRiUAAAAJ": [
      "FecYwZ0AAAAJ",
      "8O8MQEUAAAAJ",
      "Br__ds4AAAAJ",
      "u0561GMAAAAJ",
      "W5bcaXQAAAAJ",
      "SLNZE7kAAAAJ",
      "YAHWbtkAAAAJ",
      "B847xq8AAAAJ",
      "01II9NsAAAAJ",
      "CU1rungAAAAJ",
      "DSdABLMAAAAJ",
      "MavyE28AAAAJ",
      "yqfXEPIAAAAJ",
      "vOYl40wAAAAJ",
      "m3wdswkAAAAJ",
      "LrHm5cgAAAAJ",
      "owKwr1IAAAAJ",
      "oCw8EScAAAAJ",
      "tAdZoKIAAAAJ"
    ],
    "jo2C_wkAAAAJ": [],
    "r3q68rcAAAAJ": [
      "MhDyxdYAAAAJ",
      "cNSbfGQAAAAJ",
      "vFWw1NoAAAAJ",
      "ubaxhUIAAAAJ",
      "PS-TM94AAAAJ",
      "55TAOdgAAAAJ",
      "D83Vz00AAAAJ",
      "E8Jst30AAAAJ",
      "jUt50EcAAAAJ",
      "k8nSlL4AAAAJ",
      "24Ke6Q8AAAAJ",
      "PCtRSvUAAAAJ",
      "4j-x4ckAAAAJ",
      "1eBgIWsAAAAJ",
      "OVdu5IEAAAAJ",
      "_PZKLYUAAAAJ",
      "kkP2ICsAAAAJ",
      "lPG5fAIAAAAJ",
      "rpbMOTsAAAAJ",
      "mZM5KHIAAAAJ",
      "tb2aY4kAAAAJ",
      "TyPF9V4AAAAJ",
      "GPIB5kUAAAAJ",
      "XfSFItwAAAAJ",
      "jAAj2XoAAAAJ",
      "rCH4toMAAAAJ",
      "lOGcZowAAAAJ",
      "BHdSb5AAAAAJ",
      "XbjOzyQAAAAJ",
      "lXCP2cMAAAAJ",
      "oQ5FSggAAAAJ",
      "tQVe-fAAAAAJ",
      "cQ1P1qoAAAAJ",
      "Lqc4cdAAAAAJ",
      "EIAYEl4AAAAJ",
      "R4dvN4oAAAAJ",
      "pgcjVaYAAAAJ",
      "MzD8rjoAAAAJ",
      "xdsgpC0AAAAJ",
      "Ut6nPD8AAAAJ",
      "5t2myD8AAAAJ",
      "owqhKD8AAAAJ",
      "CeioNO4AAAAJ",
      "cCUHSdkAAAAJ",
      "e6op8BQAAAAJ",
      "y0U2EaUAAAAJ",
      "cLGOIdMAAAAJ",
      "tgtareEAAAAJ",
      "YAHWbtkAAAAJ",
      "B847xq8AAAAJ",
      "ZLCLbSQAAAAJ",
      "3jDeUlMAAAAJ",
      "gkCjy_UAAAAJ",
      "CZ3EC4AAAAAJ",
      "yQNhFGUAAAAJ",
      "fds2VpgAAAAJ",
      "fNOReswAAAAJ",
      "8sGC5D4AAAAJ",
      "R9L0aqAAAAAJ",
      "in8fQ10AAAAJ",
      "VajMetgAAAAJ",
      "O4pBP40AAAAJ",
      "UqiD090AAAAJ",
      "2c3HfFAAAAAJ",
      "SJE16yoAAAAJ",
      "mXtH1UYAAAAJ",
      "e8aRmAsAAAAJ",
      "VO4oS8UAAAAJ",
      "jabdPAwAAAAJ",
      "uWan5l0AAAAJ",
      "bgI5L7oAAAAJ",
      "J6LkBeUAAAAJ",
      "Kpqp274AAAAJ",
      "B6EgtpUAAAAJ",
      "TeuEgRkAAAAJ",
      "6bJxJIcAAAAJ",
      "w1-xBhoAAAAJ",
      "KZL-4GEAAAAJ",
      "fsbXdAYAAAAJ",
      "SvLPY-QAAAAJ",
      "BItCgjYAAAAJ",
      "quhI7uQAAAAJ",
      "nTiSnwUAAAAJ",
      "FEvVS54AAAAJ",
      "E5NCCUEAAAAJ",
      "udIzg9QAAAAJ",
      "FmZaK1wAAAAJ",
      "8fiH7UkAAAAJ",
      "j0nK_CsAAAAJ",
      "3svZOGAAAAAJ",
      "dKDdHFsAAAAJ",
      "CctaxzYAAAAJ",
      "RmhQmkwAAAAJ",
      "3qPiYJoAAAAJ",
      "TvVmLjUAAAAJ",
      "6ReT2voAAAAJ",
      "6T1XtW8AAAAJ",
      "Z8U0BwcAAAAJ",
      "zdn08t8AAAAJ",
      "c0JG32IAAAAJ",
      "MavyE28AAAAJ",
      "YXrj9aIAAAAJ",
      "i1NrG8UAAAAJ",
      "lQbIarsAAAAJ",
      "vV4K9eYAAAAJ",
      "UhC0_gwAAAAJ",
      "jre2iwMAAAAJ",
      "SCdhzWoAAAAJ",
      "n4eReqMAAAAJ",
      "HlLm4LIAAAAJ",
      "YYRnhTkAAAAJ",
      "-KdNGwgAAAAJ",
      "fizPmUgAAAAJ",
      "TN-sNaMAAAAJ",
      "uOyNG_AAAAAJ",
      "NxGK-wQAAAAJ",
      "thZJZaYAAAAJ",
      "ZvFaPxUAAAAJ",
      "uDVHMCwAAAAJ"
    ],
    "mqpjAt4AAAAJ": [
      "bh-uRFMAAAAJ",
      "9xDADY4AAAAJ",
      "nABXo3sAAAAJ",
      "UfbuDH8AAAAJ",
      "K3ht_ZUAAAAJ",
      "1E7m_VsAAAAJ",
      "DplAah0AAAAJ",
      "mu5Y2rYAAAAJ",
      "NkzyCvUAAAAJ",
      "rIK7AMkAAAAJ",
      "UdpacsMAAAAJ",
      "ROILf3EAAAAJ",
      "2ItLnFgAAAAJ",
      "66lkylsAAAAJ",
      "rDfyQnIAAAAJ",
      "OZ7PjVoAAAAJ",
      "hHkuxSUAAAAJ",
      "UxuqG1EAAAAJ",
      "W8VIEZgAAAAJ",
      "aOklxsQAAAAJ",
      "1HO5UacAAAAJ",
      "d97bGd8AAAAJ",
      "gYiCq88AAAAJ",
      "_bs7PqgAAAAJ",
      "ktwwLjsAAAAJ",
      "19t-gxUAAAAJ",
      "ZeJjFQMAAAAJ",
      "6GDfcqEAAAAJ",
      "mS5k4CYAAAAJ",
      "TpglobcAAAAJ",
      "XM97iScAAAAJ",
      "okcbLqoAAAAJ",
      "vjZrDKQAAAAJ",
      "zJyuMYgAAAAJ",
      "-XCiamcAAAAJ",
      "vtwH6GkAAAAJ",
      "rTw-pq0AAAAJ",
      "0I2qH0oAAAAJ",
      "GN_9dYIAAAAJ",
      "8R35rCwAAAAJ",
      "Ivot3fkAAAAJ",
      "vfPE6hgAAAAJ",
      "KmSuVtgAAAAJ",
      "MVUbYCkAAAAJ",
      "t0ZfFH8AAAAJ",
      "AEsPCAUAAAAJ",
      "-ltRSM0AAAAJ",
      "ijpYJQwAAAAJ",
      "Tw2m5kUAAAAJ"
    ],
    "YLOz1kgAAAAJ": [
      "bh-uRFMAAAAJ",
      "HXowq5YAAAAJ",
      "Sl_2kHcAAAAJ",
      "E6ayakEAAAAJ",
      "Tgbsbs8AAAAJ",
      "kCYbVq0AAAAJ",
      "8hIYYuEAAAAJ",
      "SuWIEE8AAAAJ",
      "MqWYTj0AAAAJ",
      "ow3r9ogAAAAJ",
      "RAiewnEAAAAJ",
      "2xjjS3oAAAAJ",
      "AVT2-U4AAAAJ",
      "veCt9kMAAAAJ",
      "2StUgf4AAAAJ",
      "4sontAIAAAAJ",
      "_bs7PqgAAAAJ",
      "G2-nFaIAAAAJ",
      "xqyoorYAAAAJ",
      "2MOwmwYAAAAJ",
      "E9rg2eEAAAAJ",
      "w9jtLkIAAAAJ",
      "izZZAegAAAAJ",
      "Jp6Mz1sAAAAJ",
      "7HDE1ZwAAAAJ",
      "6NjbexEAAAAJ",
      "WghUqGkAAAAJ",
      "5dGWexcAAAAJ",
      "wS2Fyv8AAAAJ",
      "l7Qx0zAAAAAJ",
      "WlJ69p0AAAAJ",
      "0v5utcwAAAAJ",
      "ntGll74AAAAJ",
      "Br80hVMAAAAJ",
      "F3dhs4kAAAAJ",
      "6xWhoLoAAAAJ",
      "wlxnii4AAAAJ",
      "d6vuvHIAAAAJ",
      "oVsC3XcAAAAJ",
      "w0OodaEAAAAJ",
      "Li-BrU4AAAAJ",
      "Eclg4mwAAAAJ",
      "D7bpRJ8AAAAJ",
      "j7uL6VEAAAAJ",
      "OV1Y3FUAAAAJ",
      "-q4nE1kAAAAJ",
      "NLxrmYQAAAAJ",
      "I_7PXKEAAAAJ",
      "_RRIYvEAAAAJ",
      "AerHOzUAAAAJ",
      "eVv0MrsAAAAJ",
      "shLVWDYAAAAJ",
      "fm0h6EkAAAAJ",
      "MzKvJhAAAAAJ",
      "W2DsnAkAAAAJ",
      "kDHs7DYAAAAJ",
      "0hHqYoAAAAAJ",
      "VseAjdcAAAAJ",
      "dF8_yxsAAAAJ",
      "VWX-GMAAAAAJ",
      "vswo4rQAAAAJ",
      "6NfC90UAAAAJ",
      "PlQaW9YAAAAJ",
      "xW-IxnwAAAAJ",
      "O9djN1AAAAAJ",
      "B_FTboQAAAAJ",
      "ZnT-QpMAAAAJ",
      "EpT5sLAAAAAJ",
      "nbpafUkAAAAJ",
      "17UDvBAAAAAJ",
      "EbyGwncAAAAJ",
      "AYdoj2AAAAAJ",
      "GhvZjJUAAAAJ",
      "XUsauXIAAAAJ",
      "X6EqGFoAAAAJ",
      "sUGrQicAAAAJ",
      "jyxO2akAAAAJ",
      "zj6FavAAAAAJ",
      "FuYln-oAAAAJ",
      "PwQHMlwAAAAJ",
      "3Bk5C9EAAAAJ",
      "tsR6sHUAAAAJ",
      "g3t0ihoAAAAJ",
      "9r7_pN8AAAAJ",
      "vJkEuTEAAAAJ",
      "N5QAWfMAAAAJ",
      "JlX2UTEAAAAJ",
      "rs0a3IQAAAAJ",
      "rqoFm6sAAAAJ",
      "5hJNWakAAAAJ",
      "D9eVSd8AAAAJ",
      "5c30hccAAAAJ",
      "zYzAXcYAAAAJ",
      "Arn3vCUAAAAJ",
      "X0RVX3AAAAAJ",
      "YHjx7qoAAAAJ",
      "nQvPeCAAAAAJ",
      "bGRVPl8AAAAJ",
      "Jlv4MR4AAAAJ",
      "u455rGAAAAAJ",
      "wSstCv0AAAAJ",
      "0XbUhDUAAAAJ",
      "g_zaiVIAAAAJ",
      "HqYIsk4AAAAJ",
      "EtYv_AIAAAAJ",
      "5z1iJjoAAAAJ",
      "K2XA5XEAAAAJ",
      "L4axvLoAAAAJ",
      "AH6MwzwAAAAJ",
      "GIle-VwAAAAJ",
      "8fFjYbwAAAAJ",
      "rKyTmpkAAAAJ",
      "P6MosQgAAAAJ",
      "quJBh1EAAAAJ",
      "ne44BF4AAAAJ",
      "LIiCDa0AAAAJ",
      "zdAyna8AAAAJ",
      "VN0X-PcAAAAJ",
      "XG7qH_YAAAAJ"
    ],
    "7t4jbPQAAAAJ": [],
    "grQ_GBgAAAAJ": [
      "ZLpO3XQAAAAJ",
      "U89FHq4AAAAJ",
      "k-0MEIMAAAAJ",
      "4BEvaw8AAAAJ",
      "0uTu7fYAAAAJ",
      "iBeDoRAAAAAJ",
      "g3mGoAwAAAAJ",
      "nzEluBwAAAAJ",
      "cSGXgEAAAAAJ",
      "4k9lBsoAAAAJ",
      "ghbWy-0AAAAJ",
      "W8zwlYQAAAAJ",
      "Jke3O8QAAAAJ",
      "3q-hbWsAAAAJ",
      "WrLjBYgAAAAJ",
      "OO-2710AAAAJ",
      "XeyiyUYAAAAJ",
      "yxUduqMAAAAJ",
      "OcPVegoAAAAJ",
      "rRJ9wTJMUB8C",
      "2XL6xRgAAAAJ",
      "QESJSgMAAAAJ",
      "VEGtG7YAAAAJ",
      "hwQtFB0AAAAJ",
      "x_7xA0UAAAAJ",
      "x04W_mMAAAAJ",
      "ITZ1e7MAAAAJ",
      "dPX0wQcAAAAJ",
      "KwEOawwAAAAJ",
      "oirMEUEAAAAJ",
      "IR0yJB8AAAAJ",
      "CkfQy2gAAAAJ"
    ],
    "WX0pI3wAAAAJ": [
      "iGgf9KwAAAAJ",
      "XMKgrt4AAAAJ",
      "y_wpkH8AAAAJ",
      "AnLxYd8AAAAJ",
      "RE_wHW0AAAAJ",
      "OM0D_3wAAAAJ",
      "nnHveQwAAAAJ",
      "AfSC-s4AAAAJ",
      "O9BRr1UAAAAJ",
      "wewitucAAAAJ",
      "B847xq8AAAAJ",
      "V8NPfyQAAAAJ",
      "wD_hj9QAAAAJ",
      "fsjokJUAAAAJ",
      "rjmrrlgAAAAJ",
      "hBRnEHIAAAAJ",
      "yE9VDTkAAAAJ",
      "pYBdBjkAAAAJ",
      "OxnSwKkAAAAJ",
      "icXJxqwAAAAJ"
    ],
    "mAo_lUwAAAAJ": [
      "Pq4Yp_kAAAAJ",
      "RGsMgZA4H78C",
      "oIz_CYEAAAAJ",
      "mnifqeUAAAAJ",
      "ZEnShlcAAAAJ",
      "XEgaCScAAAAJ",
      "Vt1j3kEAAAAJ",
      "ET6V1LEAAAAJ",
      "0mgEF28AAAAJ",
      "GOUpm_oAAAAJ",
      "hUh7qCcAAAAJ",
      "8HZzDSwAAAAJ",
      "fY69CxIAAAAJ",
      "4MB4orsAAAAJ",
      "BYXqAlwAAAAJ"
    ],
    "WLN3QrAAAAAJ": [
      "kukA0LcAAAAJ",
      "kbN88gsAAAAJ",
      "OBagQ_4AAAAJ",
      "Wck7gd0AAAAJ",
      "NHIpV98AAAAJ",
      "JicYPdAAAAAJ",
      "6KgM0OkAAAAJ",
      "NbXF7T8AAAAJ",
      "0nPi5YYAAAAJ",
      "ETU-ePAAAAAJ",
      "u3u16tgAAAAJ",
      "SSTIBK0AAAAJ",
      "Q0YEc-QAAAAJ",
      "sGFyDIUAAAAJ",
      "L4bNmsMAAAAJ",
      "u3-FxUgAAAAJ",
      "akrkYU0AAAAJ",
      "2PIkUqgAAAAJ",
      "U_IVY50AAAAJ",
      "1T2Xh68AAAAJ",
      "TGpo3KAAAAAJ",
      "GgQ9GEkAAAAJ",
      "vC2vywcAAAAJ",
      "W2pvAfEAAAAJ",
      "8ipao8MAAAAJ",
      "jmERpL4AAAAJ",
      "j-2_cT0AAAAJ",
      "S1x_xqcAAAAJ",
      "bX__wkYAAAAJ",
      "GfcBlpUAAAAJ",
      "vtegaJgAAAAJ",
      "yIkgW-cAAAAJ",
      "SvRU8F8AAAAJ",
      "krWNpKoAAAAJ",
      "uRlPu-4AAAAJ",
      "l-mlF7YAAAAJ",
      "U_Jw8DUAAAAJ",
      "n4QjVfoAAAAJ",
      "VhxDLwcAAAAJ",
      "SqsLFwMAAAAJ",
      "WvufSLAAAAAJ",
      "uKXVH54AAAAJ",
      "WeyLqFUAAAAJ",
      "-cL9xWMAAAAJ",
      "XCZpOcAAAAAJ",
      "EC4o-1oAAAAJ",
      "jplQac8AAAAJ",
      "MVGcpRsAAAAJ",
      "WBCKQMsAAAAJ",
      "CBzRa74AAAAJ",
      "SeGmqkIAAAAJ",
      "QUJ0kPMAAAAJ",
      "36ofBJgAAAAJ",
      "EOnaBbUAAAAJ",
      "-iPZaBcAAAAJ",
      "UU3N6-UAAAAJ",
      "elmWdycAAAAJ",
      "spAJDzYAAAAJ",
      "S6moyNoAAAAJ",
      "8sGC5D4AAAAJ",
      "Q9jd0mgAAAAJ",
      "6PJWcFEAAAAJ",
      "-aNI9zwAAAAJ",
      "1uT7-84AAAAJ",
      "Ysjk8kkAAAAJ",
      "YCPycGAAAAAJ",
      "6yMIP8AAAAAJ",
      "WRTLuxcAAAAJ",
      "1p9NOFEAAAAJ",
      "llt18PUAAAAJ",
      "yyIoQu4AAAAJ",
      "45KfCpgAAAAJ",
      "a2KklUoAAAAJ",
      "oZGA-rAAAAAJ",
      "8qisprwAAAAJ",
      "vDimc-4AAAAJ",
      "VJ8Qd6sAAAAJ",
      "rFaxB20AAAAJ",
      "8Ir1WvIAAAAJ",
      "nZEtlZoAAAAJ",
      "jWWx33IAAAAJ",
      "dh03btIAAAAJ",
      "PMHXcoAAAAAJ",
      "lMkTx0EAAAAJ",
      "InxhqXgAAAAJ",
      "cLPaHcIAAAAJ",
      "FMJePIUAAAAJ",
      "LIjnUGgAAAAJ",
      "n_ts4eYAAAAJ",
      "TGRPKRIAAAAJ",
      "70I8ZIMAAAAJ",
      "PUeKU8kAAAAJ",
      "Oyx-_UIAAAAJ",
      "yqsvxQgAAAAJ",
      "3LYW1zMAAAAJ",
      "kzS_Xd4AAAAJ",
      "lH1PdF8AAAAJ",
      "c_z5hWEAAAAJ",
      "DYUloYkAAAAJ",
      "fNOReswAAAAJ",
      "YAHWbtkAAAAJ",
      "LmKtwk8AAAAJ",
      "vIGcvLsAAAAJ",
      "LgF3Ds0AAAAJ",
      "1rDKD9kAAAAJ",
      "zl0AOEgAAAAJ",
      "j29kMCwAAAAJ",
      "AxFrw0sAAAAJ",
      "UVuQeJIAAAAJ",
      "8vjzfWwAAAAJ",
      "iJENOG8AAAAJ",
      "YfompPIAAAAJ",
      "EKPoKcQAAAAJ",
      "yjeEP_EAAAAJ",
      "OaE_xMgAAAAJ",
      "FBHC_JYAAAAJ",
      "xlkTND4AAAAJ",
      "lyMGnwIAAAAJ"
    ],
    "z76PBfYAAAAJ": [
      "4V1nNm4AAAAJ",
      "SVNNgu4AAAAJ",
      "6rl-XhwAAAAJ",
      "jQl9RtkAAAAJ",
      "0yDoR0AAAAAJ",
      "SI6sQPYAAAAJ",
      "3kDtybgAAAAJ",
      "JmdnBzcAAAAJ",
      "lECZKZsAAAAJ",
      "jphx5uUAAAAJ",
      "fNfrGMIAAAAJ",
      "ZcULDB0AAAAJ",
      "0ZAb3tsAAAAJ",
      "mlSE-YwAAAAJ",
      "ILgZT7MAAAAJ",
      "qsB2vcgAAAAJ",
      "pOSMWfQAAAAJ",
      "cCda-zQAAAAJ",
      "3Bfgs9cAAAAJ",
      "OKtm7t4AAAAJ",
      "BEFl4j0AAAAJ",
      "BUDh_4wAAAAJ",
      "kmXOOdsAAAAJ",
      "GHpxNQIAAAAJ",
      "TwMib_QAAAAJ",
      "TxEy3cwAAAAJ",
      "u4unGhAAAAAJ",
      "WiTNe3kAAAAJ",
      "vNZhd_8AAAAJ",
      "FZuNgqIAAAAJ",
      "fmSHtE8AAAAJ",
      "A8h9enQAAAAJ",
      "Z_-JBYgAAAAJ",
      "RM0ik8wAAAAJ",
      "iPI39lEAAAAJ",
      "EuFF9kUAAAAJ",
      "TNMSbOkAAAAJ",
      "0VAe-TQAAAAJ",
      "Y1XuTkUAAAAJ",
      "SKb4VyUAAAAJ",
      "jEANvfgAAAAJ",
      "P4nfoKYAAAAJ",
      "FTWcemsAAAAJ",
      "xiiE5rYAAAAJ",
      "bh-uRFMAAAAJ",
      "LNc2cxUAAAAJ",
      "a8Y2OJMAAAAJ",
      "pvyI8GkAAAAJ",
      "jjHAnBUAAAAJ",
      "eLZ_clAAAAAJ",
      "DC9wzBgAAAAJ",
      "Kn3znAMAAAAJ",
      "qM5jR7YAAAAJ",
      "1CLaPMEAAAAJ",
      "5cIodxsAAAAJ",
      "eIWg8NMAAAAJ",
      "2z3fl5EAAAAJ",
      "sbsFpScAAAAJ",
      "OpXMNnMAAAAJ",
      "nubwxloAAAAJ",
      "j29kMCwAAAAJ",
      "wmpvU_YAAAAJ",
      "2gSuGBEAAAAJ",
      "axpNZUAAAAAJ",
      "s1IAWfgAAAAJ",
      "njOmQFsAAAAJ",
      "9-WU64IAAAAJ",
      "ki6yi04AAAAJ",
      "elmWdycAAAAJ",
      "gnR4zf8AAAAJ",
      "tvgSaXsAAAAJ",
      "OeuYmWUAAAAJ",
      "lDfq31wAAAAJ",
      "56UhAooAAAAJ",
      "gf-aMd0AAAAJ",
      "nI2oJqkAAAAJ",
      "QURZIzUAAAAJ",
      "dcv4kpIAAAAJ",
      "EuBrsZQAAAAJ",
      "MYvSvGsAAAAJ",
      "KMqMQAcAAAAJ",
      "K-g2p4cAAAAJ",
      "9uWuZkUAAAAJ",
      "ELOVd8sAAAAJ",
      "kzoVUPYAAAAJ",
      "1FIyc9kAAAAJ",
      "iCf3SwgAAAAJ",
      "tmZ8MaAAAAAJ",
      "Dn_qYK8AAAAJ",
      "qr8Vo9IAAAAJ",
      "R_dIcVwAAAAJ",
      "LGx06n8AAAAJ",
      "VJlCMGYAAAAJ",
      "D4Z3yrwAAAAJ",
      "B4J3SkcAAAAJ",
      "JO59nyUAAAAJ",
      "6TGwETYAAAAJ",
      "SnQjip0AAAAJ",
      "rk587vcAAAAJ",
      "BZfj2c8AAAAJ",
      "UfbuDH8AAAAJ",
      "TmbrLRMAAAAJ",
      "h5KkpakAAAAJ",
      "7TWQgcgAAAAJ",
      "rIdxtXsAAAAJ",
      "IqJ3zskAAAAJ",
      "xE_pSDAAAAAJ",
      "9FSuHUQAAAAJ",
      "rTw-pq0AAAAJ",
      "FKUc3vsAAAAJ",
      "TP-_rb0AAAAJ",
      "y6wdLA8AAAAJ",
      "t3A39e8AAAAJ",
      "4QvYJ00AAAAJ",
      "wQU1dJAAAAAJ",
      "a0za4V8AAAAJ",
      "gFwEytkAAAAJ",
      "QiQAv48AAAAJ",
      "uHwTzpYAAAAJ",
      "gLdI4FcAAAAJ",
      "mHbdIAwAAAAJ",
      "qpD0AVMAAAAJ"
    ],
    "QZCU3NkAAAAJ": [
      "GXJqtYUAAAAJ",
      "Z9Pfp6UAAAAJ",
      "NnEMWJsAAAAJ",
      "8IjN_vgAAAAJ",
      "jaITaUcAAAAJ",
      "CXgQufgAAAAJ",
      "BbzYzsgAAAAJ",
      "Wj4ZBFIAAAAJ",
      "Yd-SGH8AAAAJ",
      "koPRb8UAAAAJ",
      "ZnVZ9xYAAAAJ",
      "212SLn0AAAAJ",
      "8gWTOBAAAAAJ",
      "D4NJsXEIh1cJ",
      "-YmsnYMAAAAJ",
      "rtWKzFwAAAAJ",
      "PkfChMgAAAAJ",
      "BkGE4AsAAAAJ",
      "WDSU0ucAAAAJ",
      "sNeVyqoAAAAJ",
      "qhu-DxwAAAAJ",
      "ZiFn598AAAAJ",
      "xdGKgtcAAAAJ",
      "AIncPrIAAAAJ",
      "7jNkTbYAAAAJ",
      "1n5ZdOAAAAAJ",
      "tipePDkAAAAJ",
      "GiCqMFkAAAAJ",
      "7Xko5sYAAAAJ",
      "qj3IRU8AAAAJ",
      "cYReSuEAAAAJ",
      "U69fiZMAAAAJ",
      "t8YAefAAAAAJ",
      "hNsmH54AAAAJ",
      "aXGTpLgAAAAJ",
      "eYg0_cEAAAAJ",
      "i2OF1rkAAAAJ",
      "5qSIhVkAAAAJ",
      "6ENuGyoAAAAJ",
      "KGMaP18AAAAJ",
      "QgOASJwAAAAJ",
      "kdbzgK4AAAAJ",
      "QWTkjB8AAAAJ",
      "9aA5QTUAAAAJ",
      "S63gb38AAAAJ",
      "_4_X3OgAAAAJ",
      "ieDx3WwAAAAJ",
      "Hq28JM0AAAAJ",
      "Hq5VU2EAAAAJ",
      "Ba_Ci9UAAAAJ",
      "_ryE-48AAAAJ",
      "HXCMYLsAAAAJ",
      "PLcCBl4AAAAJ",
      "ycTTxNUAAAAJ",
      "bHM8zJkAAAAJ",
      "OsGAl50AAAAJ",
      "dilO2p4AAAAJ",
      "PH5VIGIAAAAJ",
      "IOrQrZcAAAAJ",
      "LCNVGpcAAAAJ",
      "9LJgRFAAAAAJ",
      "ggAIHowAAAAJ",
      "Ysd-WJgAAAAJ",
      "bu1SCOuD_CMC",
      "7Z0Z6VsAAAAJ"
    ],
    "y-8unsgAAAAJ": [],
    "n7hxT4oAAAAJ": [
      "8R35rCwAAAAJ",
      "45Jrl1YAAAAJ",
      "md3U-GEAAAAJ",
      "YBttbLMAAAAJ",
      "-WZcuuwAAAAJ",
      "Ivot3fkAAAAJ",
      "ZWH5jCwAAAAJ",
      "UAWfBEoAAAAJ",
      "zBUwaGkAAAAJ",
      "ZzURcb4AAAAJ",
      "C2_ZXdcAAAAJ",
      "rK5YVA8AAAAJ",
      "ITJGDKQAAAAJ",
      "pha24HQAAAAJ"
    ],
    "-S_9ZRcAAAAJ": [
      "1P8Zu04AAAAJ",
      "POXzrBYAAAAJ",
      "GExyiRkAAAAJ"
    ],
    "e1P1rNkAAAAJ": [],
    "izZZAegAAAAJ": [
      "XYy_Nm4AAAAJ",
      "GkpvilQAAAAJ",
      "ffdt7gMAAAAJ",
      "bh-uRFMAAAAJ",
      "nq7tuDkAAAAJ",
      "DwXLsT8AAAAJ",
      "49_cCT8AAAAJ",
      "fxzlm6IAAAAJ",
      "mtB5szIAAAAJ",
      "v_t_fq8AAAAJ",
      "zZ0-4SUAAAAJ",
      "aQeTAr4AAAAJ",
      "xOFOVGMAAAAJ",
      "n01L0mEAAAAJ",
      "psiQDeAAAAAJ",
      "GdQtWNQAAAAJ",
      "GMzzRRUAAAAJ",
      "YLOz1kgAAAAJ",
      "G2-nFaIAAAAJ",
      "JlrEuLkAAAAJ",
      "bUGiGKcAAAAJ",
      "GSHmKZkAAAAJ",
      "910z20QAAAAJ",
      "CZiW6c8AAAAJ",
      "gX7rSCcAAAAJ",
      "WPe7vWwAAAAJ",
      "p1DZVX8AAAAJ",
      "hMZMhLoAAAAJ",
      "UfAyRKEAAAAJ",
      "AN6lmmcAAAAJ",
      "M1fMGOMAAAAJ",
      "xF2mhDoAAAAJ",
      "71ZEsnEAAAAJ",
      "abx4xHAAAAAJ",
      "wd6xr6sAAAAJ",
      "Li-BrU4AAAAJ",
      "XEx1fZkAAAAJ",
      "0pLOTKcAAAAJ",
      "EOyZV8YAAAAJ",
      "0zZnyMEAAAAJ",
      "MOitEvkAAAAJ",
      "xaUJEWAAAAAJ",
      "BOL2qeUAAAAJ",
      "BSrwwfYAAAAJ",
      "0HNGHckAAAAJ",
      "Eclg4mwAAAAJ",
      "D7bpRJ8AAAAJ",
      "0T7HVEIAAAAJ",
      "67QZN0gAAAAJ",
      "Pk-959EAAAAJ",
      "7ERaCzgAAAAJ",
      "8jydpnYAAAAJ",
      "PvHFAfIAAAAJ",
      "dJoAVvAAAAAJ",
      "yehGhR8AAAAJ",
      "3Ee8qHEAAAAJ",
      "pzQgnrkAAAAJ",
      "LqBEONAAAAAJ",
      "APgaFK0AAAAJ",
      "zTBFoCoAAAAJ",
      "XSUvsTMAAAAJ",
      "UQGZX48AAAAJ",
      "O-DazBUAAAAJ",
      "OO-2710AAAAJ",
      "JeXmlI0AAAAJ",
      "bysr1zQAAAAJ",
      "ePiPQ2cAAAAJ",
      "bGXte_4AAAAJ",
      "e5fFIDkAAAAJ",
      "EysbmrUAAAAJ"
    ],
    "aOklxsQAAAAJ": [
      "yLQF4mkAAAAJ",
      "bh-uRFMAAAAJ",
      "W8VIEZgAAAAJ",
      "chD5XxkAAAAJ",
      "k0nZO90AAAAJ",
      "j29kMCwAAAAJ",
      "UfbuDH8AAAAJ",
      "1HO5UacAAAAJ",
      "Ci-_QYIAAAAJ",
      "UxuqG1EAAAAJ",
      "Sm14jYIAAAAJ",
      "d97bGd8AAAAJ",
      "RKjEFukAAAAJ",
      "sUK_w2QAAAAJ",
      "Bl9FSL0AAAAJ",
      "TpglobcAAAAJ",
      "jjEht8wAAAAJ",
      "l7Qx0zAAAAAJ",
      "06rffEkAAAAJ",
      "jktWnL8AAAAJ"
    ],
    "xVN3UxYAAAAJ": [],
    "YYT8-7kAAAAJ": [
      "X08l_4IAAAAJ",
      "S2vB4tAAAAAJ",
      "eZqFrSsAAAAJ",
      "vtwH6GkAAAAJ",
      "8fztli4AAAAJ",
      "xOWBOKQAAAAJ",
      "EMDboA4AAAAJ",
      "itSa94cAAAAJ",
      "8-p9CLsAAAAJ",
      "ZgLOSX8AAAAJ"
    ],
    "GBQ6w8IAAAAJ": [],
    "wSstCv0AAAAJ": [],
    "eWRBqsYAAAAJ": [
      "DZ3S--MAAAAJ",
      "mnU3HpcAAAAJ",
      "e65kJ08AAAAJ",
      "Bq1dFNQAAAAJ",
      "kSvJTg4AAAAJ",
      "71rMURwAAAAJ",
      "Y_Nmd2sAAAAJ",
      "yfy_BGIAAAAJ",
      "ynIWXnUAAAAJ"
    ],
    "d97bGd8AAAAJ": [
      "UdpacsMAAAAJ",
      "ROILf3EAAAAJ",
      "LW8ze_UAAAAJ",
      "hHkuxSUAAAAJ",
      "bh-uRFMAAAAJ",
      "yA4rb60AAAAJ",
      "B_FTboQAAAAJ",
      "0ytii2EAAAAJ",
      "0B8uuBkAAAAJ",
      "bqL73OkAAAAJ",
      "AEsPCAUAAAAJ",
      "aOklxsQAAAAJ",
      "NCtKHnQAAAAJ",
      "8cxDHS4AAAAJ",
      "8Sfj7q8AAAAJ",
      "vjZrDKQAAAAJ",
      "0zZnyMEAAAAJ",
      "3RuMCpcAAAAJ",
      "dzOd2hgAAAAJ",
      "9hX-JksAAAAJ",
      "ypBMJMgAAAAJ",
      "hW9fwNYAAAAJ",
      "Y8O9N_0AAAAJ",
      "0MiPsosAAAAJ",
      "UpZmJI0AAAAJ",
      "UZ5wscMAAAAJ",
      "RCTeTV0AAAAJ",
      "06rffEkAAAAJ",
      "Ci-_QYIAAAAJ",
      "SBTxvCoAAAAJ",
      "Bl9FSL0AAAAJ",
      "MhYrLJAAAAAJ",
      "a7drwRMAAAAJ",
      "71L4yYMAAAAJ",
      "bQNISbAAAAAJ",
      "q0MzO6cAAAAJ",
      "ajXAb54AAAAJ",
      "14HASnUAAAAJ",
      "jN2Y51YAAAAJ",
      "-DYvinwAAAAJ",
      "0TpaABgAAAAJ",
      "nABXo3sAAAAJ",
      "4GTpCxcAAAAJ",
      "jjEht8wAAAAJ",
      "UfbuDH8AAAAJ",
      "8R35rCwAAAAJ",
      "FLcpd34AAAAJ",
      "sUK_w2QAAAAJ",
      "_QlCijoAAAAJ",
      "-ltRSM0AAAAJ",
      "L7fTK1MAAAAJ",
      "yxh9tfEAAAAJ",
      "9xDADY4AAAAJ",
      "mqpjAt4AAAAJ",
      "e1P1rNkAAAAJ",
      "2k18_1IAAAAJ",
      "adnTgaAAAAAJ",
      "7OTD-LEAAAAJ",
      "1KFFbEIAAAAJ",
      "nKSXus4AAAAJ",
      "uqWkLzMAAAAJ",
      "JcZUd5IAAAAJ",
      "mIF9BowAAAAJ",
      "-9ifK0cAAAAJ",
      "odEM5hMAAAAJ",
      "_j4M4KEAAAAJ",
      "tZprM8IAAAAJ",
      "uQg2t8EAAAAJ",
      "b_RBE3EAAAAJ",
      "L__n1LUAAAAJ",
      "pmVPj94AAAAJ",
      "l0Bj7U8AAAAJ",
      "exClNSsAAAAJ",
      "dUWUGcEAAAAJ",
      "3Rlc8EAAAAAJ",
      "Amky96kAAAAJ",
      "0o470HsAAAAJ",
      "5VaXUQsAAAAJ",
      "-mEAM68AAAAJ",
      "3TMipekAAAAJ",
      "f_fKey0AAAAJ",
      "vtwH6GkAAAAJ",
      "ZcWO2AEAAAAJ",
      "KdX5MN4AAAAJ",
      "j4pcHV4AAAAJ",
      "75x4pdcAAAAJ",
      "i5FMLA4AAAAJ",
      "se9kni0AAAAJ",
      "UAwKvEsAAAAJ",
      "OWDai70AAAAJ",
      "pamL_rIAAAAJ",
      "YZ8Y-sUAAAAJ",
      "ZfV1DqMAAAAJ",
      "YPzKczYAAAAJ",
      "5JlEyTAAAAAJ",
      "1P8Zu04AAAAJ",
      "P9FclNEAAAAJ",
      "6rjdDasAAAAJ",
      "R6jgG94AAAAJ",
      "PUSWc4EAAAAJ",
      "hepwvtAAAAAJ",
      "yn-nyJwAAAAJ",
      "FyQAwaEAAAAJ",
      "YHmzvmMAAAAJ",
      "GYksTEEAAAAJ",
      "N_YNMIMAAAAJ",
      "LGo5J4IAAAAJ",
      "QGdSgfoAAAAJ",
      "nrsWSt4AAAAJ",
      "bOitqMUAAAAJ",
      "5JserkUAAAAJ",
      "LKv32bgAAAAJ",
      "QxLpghAAAAAJ",
      "1bYESBYAAAAJ",
      "Sm14jYIAAAAJ",
      "Q5KT-hEAAAAJ",
      "8kA3eDwAAAAJ",
      "vswo4rQAAAAJ",
      "6NfC90UAAAAJ",
      "qYcG-q0AAAAJ",
      "Yd4KvooAAAAJ",
      "7aabHgsAAAAJ",
      "ndRmNK8AAAAJ",
      "zw1TzeEAAAAJ",
      "fJsSvzkAAAAJ",
      "8TwcVQcAAAAJ",
      "8wGH7wsAAAAJ",
      "kPxa2w0AAAAJ",
      "WsM7ybkAAAAJ",
      "fcThykUAAAAJ",
      "1HO5UacAAAAJ",
      "Eta6Y-kAAAAJ",
      "0TGDhHsAAAAJ",
      "e7abmgkAAAAJ",
      "-_EKVQ0AAAAJ",
      "Vpr6s3sAAAAJ",
      "y-f-MZgAAAAJ",
      "t2GAVZkAAAAJ",
      "3vKjkoQAAAAJ",
      "2efgcS0AAAAJ",
      "t4dSV4YAAAAJ",
      "AFD2rD4AAAAJ",
      "yJfoD0kAAAAJ",
      "e5lxgjIAAAAJ",
      "OFlBL2kAAAAJ",
      "UKpinl8AAAAJ",
      "ZeG4wDgAAAAJ",
      "8bQRH5YAAAAJ",
      "8j3t5HsAAAAJ",
      "hRV0tY4AAAAJ",
      "YB8_6gkAAAAJ",
      "NINFXC0AAAAJ",
      "FTWcemsAAAAJ",
      "eqgEprEAAAAJ",
      "pImSVwoAAAAJ",
      "Dq0Fom8AAAAJ",
      "KWD-mmoAAAAJ",
      "i2oLdaYAAAAJ",
      "Db4BCX8AAAAJ",
      "JY-WzksAAAAJ",
      "Bt4uDWMAAAAJ",
      "31eXgMYAAAAJ",
      "5B5rQPkAAAAJ",
      "Qw72w48AAAAJ",
      "Hp5uEnUAAAAJ",
      "ttBdcmsAAAAJ",
      "ifCcZ5IAAAAJ",
      "bI7KhScAAAAJ",
      "kRJkDakAAAAJ",
      "R0bnqaAAAAAJ",
      "p9-ohHsAAAAJ",
      "nfXdXswAAAAJ",
      "7ja8HqUAAAAJ",
      "f7upZyAAAAAJ",
      "VZIAzPcAAAAJ",
      "md3U-GEAAAAJ",
      "8jAftjUAAAAJ",
      "vCHNxFcAAAAJ",
      "mapNJjcAAAAJ",
      "wnK9jX8AAAAJ",
      "GwKF9rMAAAAJ"
    ],
    "Vb3FLmkAAAAJ": [],
    "wMjQdBcAAAAJ": [
      "6yL0xw8AAAAJ",
      "wIE1tY4AAAAJ",
      "6z4lQzMAAAAJ",
      "YF0Hy1sAAAAJ",
      "vN2ALVYAAAAJ"
    ],
    "NDyEvlQAAAAJ": [
      "n0Tc-dkAAAAJ",
      "5Yjb93IAAAAJ",
      "xn4tmfQAAAAJ",
      "206DEM0AAAAJ",
      "bqx3MAoAAAAJ",
      "kFduPiIAAAAJ",
      "3TQ5YmMAAAAJ",
      "4cxOltkAAAAJ",
      "-hr7rD8AAAAJ",
      "MoYaxfYAAAAJ",
      "cAwC5EQAAAAJ",
      "Ecjx73cAAAAJ",
      "K7MBJlwAAAAJ",
      "aa9LMvoAAAAJ",
      "GljRwkUAAAAJ",
      "GbBRH4EAAAAJ",
      "ErkEIHkAAAAJ",
      "CzOD0S4AAAAJ",
      "RAx8zckAAAAJ",
      "OYc22IoAAAAJ",
      "2D06YJAAAAAJ",
      "BIHeNNUAAAAJ",
      "YZYne64AAAAJ",
      "TlFEW10AAAAJ",
      "Zb0am48AAAAJ",
      "EOzumJIAAAAJ",
      "K3ad1CgAAAAJ",
      "R41MlbcAAAAJ",
      "NlA6rBMAAAAJ",
      "34FcX8gAAAAJ",
      "sua5tGwAAAAJ",
      "dj4EiqsAAAAJ",
      "wJRAoOsAAAAJ",
      "WYE8rtcAAAAJ",
      "staYplUAAAAJ",
      "YT1DQB8AAAAJ",
      "D2boLjwAAAAJ",
      "9R-3nvsAAAAJ",
      "s6XjtCMAAAAJ",
      "w4Pqoc0AAAAJ",
      "q-KRzawAAAAJ",
      "ZpG_cJwAAAAJ",
      "1OSj0wkAAAAJ",
      "-rCpBEsAAAAJ",
      "2o8ORCAAAAAJ",
      "Lr2lbdQAAAAJ",
      "JiiMY_wAAAAJ",
      "tQVe-fAAAAAJ",
      "fuAzo2IAAAAJ",
      "FjqLOGsAAAAJ",
      "E2-uIQYAAAAJ",
      "ffwGwU8AAAAJ",
      "9N0LSLsAAAAJ",
      "4B-OkFkAAAAJ",
      "uXoaU1wAAAAJ",
      "1-OBVMMAAAAJ",
      "4vJ6wLMAAAAJ",
      "EpA-_qgAAAAJ",
      "eqkBt6EAAAAJ",
      "2IvwHucAAAAJ",
      "kOWrypIAAAAJ",
      "odYttFAAAAAJ",
      "cC3ZcD8AAAAJ",
      "F63BY8kAAAAJ",
      "RFcbxjoAAAAJ",
      "5odGE0wAAAAJ",
      "xYL6KC0AAAAJ",
      "zY_J9IQAAAAJ",
      "n63DmP8AAAAJ",
      "s18-KHUAAAAJ",
      "rM7Dm0wAAAAJ",
      "Wmr3UIMAAAAJ",
      "dS3e-CgAAAAJ",
      "RJ77s-cAAAAJ",
      "AIk5YHsAAAAJ",
      "rpavyzsAAAAJ",
      "AOGTQn0AAAAJ",
      "lWpXUrMAAAAJ",
      "u9DNHAoAAAAJ",
      "6U_O28IAAAAJ",
      "ATnKn1UAAAAJ",
      "lLqTCtUAAAAJ",
      "nrSsSrkAAAAJ",
      "lJAkLo8AAAAJ",
      "SNQERVoAAAAJ",
      "u1TctA0AAAAJ",
      "zff-8GkAAAAJ",
      "cA4CXXoAAAAJ",
      "TljlLdIAAAAJ",
      "MdORQMcAAAAJ",
      "IxeW3gwAAAAJ",
      "iBOqTdYAAAAJ",
      "3yCig6AAAAAJ",
      "b2EEZfAAAAAJ",
      "JhIiSHQAAAAJ",
      "oWGEj78AAAAJ",
      "v84zUXYAAAAJ",
      "lZPXUgoAAAAJ",
      "4eloUCwAAAAJ",
      "_tDXYaYAAAAJ",
      "OR5Lx4MAAAAJ",
      "VgI1d98AAAAJ",
      "I8UXifUAAAAJ",
      "YvjuUugAAAAJ",
      "ejoWKqsAAAAJ",
      "0JA37SgAAAAJ",
      "POWKkqEAAAAJ",
      "CjymsJAAAAAJ",
      "i3pEsbgAAAAJ",
      "ygM8WtMAAAAJ",
      "xo7GHUoAAAAJ",
      "NxBuRgcAAAAJ",
      "KnAit3cAAAAJ",
      "eMzW3TwAAAAJ",
      "bcojPRoAAAAJ",
      "U0ZjG84AAAAJ",
      "btk7o4MAAAAJ",
      "gdgJQ-wAAAAJ",
      "rSMPsx4AAAAJ",
      "0_1rZqgAAAAJ",
      "FmMT4CcAAAAJ",
      "G5zYeD8AAAAJ",
      "L0BNwUIAAAAJ",
      "4QnYN1sAAAAJ",
      "pg4JhX0AAAAJ",
      "PjCDBjIAAAAJ",
      "6QrCoOoAAAAJ",
      "58cKLg4AAAAJ",
      "shmr0CQAAAAJ",
      "zuByMYoAAAAJ",
      "agywNwUAAAAJ",
      "1a-_ns8AAAAJ",
      "9r6119kAAAAJ",
      "yUkK-mgAAAAJ",
      "_6XYKXMpK34C",
      "e4_ZXcwAAAAJ",
      "xpe7bloAAAAJ",
      "fqkakg8AAAAJ",
      "asu1aZMAAAAJ",
      "RjJyha8AAAAJ",
      "vk37k80AAAAJ",
      "9GHrCy4AAAAJ",
      "fyf_Vt4AAAAJ",
      "-gEuUZIAAAAJ",
      "2wH43aAAAAAJ",
      "KxUFJmoAAAAJ",
      "0O9BbqoAAAAJ",
      "vFPjMzYAAAAJ",
      "K_PU9tQAAAAJ"
    ],
    "nxNkEiYAAAAJ": [
      "ZZsEXLAAAAAJ",
      "-VjsrR4AAAAJ",
      "tKSxEgQAAAAJ",
      "ibu3FwsAAAAJ",
      "DCSFMuAAAAAJ",
      "YfPA4YsAAAAJ",
      "VEPTSCUAAAAJ",
      "0pxg5ssAAAAJ",
      "8yg53VQAAAAJ",
      "0k4k1WUAAAAJ",
      "5DfprgMAAAAJ",
      "ddu5MKwAAAAJ",
      "xX_de_YAAAAJ",
      "jfOVNcUAAAAJ",
      "WlA92lcAAAAJ",
      "qX2I6KIAAAAJ",
      "BD8llAEAAAAJ",
      "auB_CDsAAAAJ",
      "BqV8LaoAAAAJ",
      "B6iZVE0AAAAJ",
      "910z20QAAAAJ",
      "BNNNS-wAAAAJ",
      "IcasIiwAAAAJ",
      "Z4Y5S2oAAAAJ",
      "Hi7ZdhQAAAAJ",
      "BQ_S4vMAAAAJ",
      "gQOKAggAAAAJ",
      "LCzQ6GMAAAAJ",
      "eF5vfBAAAAAJ",
      "gn3rZ7sAAAAJ",
      "BGxhOlEAAAAJ",
      "BFfjA-8AAAAJ",
      "LC_8eS4AAAAJ",
      "8cxDHS4AAAAJ",
      "eYY2nMYAAAAJ",
      "i5srt20AAAAJ",
      "AEKT17QAAAAJ",
      "aM3i_9oAAAAJ",
      "EMrV8BIAAAAJ",
      "ZCa4VDcAAAAJ",
      "rRJ9wTJMUB8C",
      "2efgcS0AAAAJ",
      "t2X4Mg8AAAAJ",
      "GvHOmQoAAAAJ",
      "NfeARS4AAAAJ",
      "M5HFiMIAAAAJ",
      "GZt32DEAAAAJ",
      "xblGvQgAAAAJ",
      "QGU5FrIAAAAJ",
      "xXQtID8AAAAJ",
      "iAHjMzQAAAAJ",
      "I6sTssIAAAAJ",
      "UdpacsMAAAAJ",
      "dyXX1EgAAAAJ",
      "q0kUpsoAAAAJ",
      "C_r8d0AAAAAJ",
      "LKv32bgAAAAJ",
      "RAiewnEAAAAJ",
      "RhOpyXcAAAAJ",
      "3AJYxmsAAAAJ",
      "3VyGrdwAAAAJ",
      "-fPI9LgAAAAJ",
      "pTcB5WUAAAAJ",
      "V3rP49wAAAAJ",
      "cgBDhqwAAAAJ",
      "todsDfQAAAAJ",
      "xlVG6IUAAAAJ",
      "Vu-Zb7EAAAAJ",
      "9I4xFcIAAAAJ",
      "zSSrBp4AAAAJ",
      "a5RZKIkAAAAJ",
      "AC93g9kAAAAJ",
      "fE3FSqIAAAAJ",
      "gYXvxhQAAAAJ",
      "SC9wV2kAAAAJ",
      "DfrisKkAAAAJ",
      "xaFg_NUAAAAJ",
      "qIg8KFYAAAAJ",
      "MrI1EV4AAAAJ",
      "ImjOWWEAAAAJ",
      "ZPmHxbsAAAAJ",
      "ea6cjVUAAAAJ",
      "R5q_E8wAAAAJ",
      "GU-vJ5AAAAAJ",
      "Bmuft6wAAAAJ",
      "FqKcLDQAAAAJ",
      "8JeQMMUAAAAJ",
      "WJlBOwQAAAAJ",
      "aeJGZxIAAAAJ",
      "YYH0BjEAAAAJ",
      "c-uQx_0AAAAJ",
      "ZO8UTIUAAAAJ",
      "UXh1I6UAAAAJ",
      "LNHbZR0AAAAJ",
      "YI1EqBoAAAAJ",
      "kwe0VEwAAAAJ",
      "WPe7vWwAAAAJ",
      "H9xADK0AAAAJ",
      "-kIVAcAAAAAJ",
      "oy7TshoAAAAJ",
      "fU63KdQAAAAJ",
      "hwQtFB0AAAAJ",
      "Bj50SwkAAAAJ",
      "VZi7NssAAAAJ",
      "FiXHXwgAAAAJ",
      "CmoKVuUAAAAJ",
      "qyMRxowAAAAJ",
      "wxnzyjwAAAAJ"
    ],
    "8C2_ZVsAAAAJ": [
      "yy0UFOwAAAAJ",
      "MIwNbDcAAAAJ",
      "vfPE6hgAAAAJ",
      "8R35rCwAAAAJ",
      "lRUi-A8AAAAJ",
      "jTnQTBoAAAAJ",
      "5VaXUQsAAAAJ",
      "eDQsOFMAAAAJ",
      "iWmtv7gAAAAJ",
      "DRnOvU8AAAAJ",
      "ADkiClQAAAAJ",
      "LIJQ_ZYAAAAJ",
      "UJcm1MoAAAAJ",
      "2DBmo-wAAAAJ",
      "uA0kNBUAAAAJ",
      "YGQs1AYAAAAJ",
      "OI7zFmwAAAAJ",
      "IjVj4hsAAAAJ",
      "vtwH6GkAAAAJ",
      "rBJV6QUAAAAJ",
      "6MUY5mgAAAAJ",
      "Eed2gcMAAAAJ",
      "h3qMa1kAAAAJ",
      "-w5DuHgAAAAJ"
    ],
    "yABlzrsAAAAJ": [],
    "PTS2AOgAAAAJ": [
      "8R35rCwAAAAJ",
      "GgQ9GEkAAAAJ",
      "7kaXqgMAAAAJ",
      "C-ZlBWMAAAAJ",
      "U_Jw8DUAAAAJ",
      "BOAOkNQAAAAJ",
      "zvz6LIYAAAAJ",
      "BsOkXDsAAAAJ",
      "1CLaPMEAAAAJ",
      "US56Kw8AAAAJ",
      "DRnOvU8AAAAJ",
      "mXtH1UYAAAAJ",
      "ZcULDB0AAAAJ",
      "ri1sE34AAAAJ",
      "EPfOJwQAAAAJ",
      "LoT0z6oAAAAJ",
      "L4bNmsMAAAAJ",
      "cagVT0AAAAAJ",
      "yk6C1SgAAAAJ",
      "462OoekAAAAJ"
    ],
    "nABXo3sAAAAJ": [],
    "Nn990CkAAAAJ": [
      "pouyVyUAAAAJ",
      "xGORWi0AAAAJ",
      "9EnJFEEAAAAJ",
      "Q_kKkIUAAAAJ",
      "dGPqP-wAAAAJ",
      "T2vp1pgAAAAJ",
      "5ygiTwsAAAAJ",
      "SWMKy70AAAAJ",
      "jU4IZs4AAAAJ",
      "mG4imMEAAAAJ",
      "gkHA4nEAAAAJ",
      "LKv32bgAAAAJ",
      "5Iqe53IAAAAJ",
      "vfT6-XIAAAAJ"
    ],
    "HPoaHyQAAAAJ": [],
    "1TqAq5AAAAAJ": [
      "vtwH6GkAAAAJ",
      "bh-uRFMAAAAJ",
      "2oy3OXYAAAAJ",
      "ED5iKYYAAAAJ",
      "_DNzXTcAAAAJ",
      "KsYfSCIAAAAJ",
      "uHFzzkkAAAAJ",
      "gYiCq88AAAAJ",
      "mu5Y2rYAAAAJ",
      "-yZse64AAAAJ"
    ],
    "ygFAcZwAAAAJ": [],
    "5NGAbT4AAAAJ": [
      "8R35rCwAAAAJ",
      "UgHB5oAAAAAJ",
      "BZBkjNYAAAAJ",
      "ZWH5jCwAAAAJ",
      "YTO4ex4AAAAJ",
      "UzjHQLcAAAAJ",
      "bezWXYcAAAAJ",
      "DRnOvU8AAAAJ",
      "ZaJEZpYAAAAJ",
      "P-G3sjYAAAAJ",
      "vfPE6hgAAAAJ",
      "L5v2PHAAAAAJ",
      "ZwnVwKMAAAAJ",
      "oF46lMIAAAAJ",
      "kmeUhO8AAAAJ",
      "Km5y5nIAAAAJ",
      "r2Gjhg4AAAAJ",
      "R5QNdhcAAAAJ",
      "qGWon5kAAAAJ",
      "05uQHIgAAAAJ",
      "ysMAhlwAAAAJ"
    ],
    "mQf5cE0AAAAJ": [],
    "xMhGYpgAAAAJ": [
      "_7Q8uIYAAAAJ",
      "vN-is70AAAAJ",
      "B96GkdgAAAAJ",
      "BtwmZfQAAAAJ",
      "WMHRQ-8AAAAJ",
      "jCNJhFcAAAAJ"
    ],
    "ScoZZPsAAAAJ": [
      "8JKsHJcAAAAJ",
      "gTWUZlsAAAAJ",
      "bh-uRFMAAAAJ",
      "oBU9w4UAAAAJ",
      "ImpbxLsAAAAJ",
      "wSE0nWUAAAAJ",
      "W8VIEZgAAAAJ",
      "MxxZkEcAAAAJ",
      "cdP5JicAAAAJ",
      "9cZUlEYAAAAJ",
      "4V1nNm4AAAAJ",
      "BI8xFr4AAAAJ",
      "J6iSjTcAAAAJ",
      "8R35rCwAAAAJ",
      "8PR-AaoAAAAJ",
      "Bx9WGD6lBFEC",
      "yCyR-TsAAAAJ",
      "G_vOcFUAAAAJ",
      "k1hJzF0AAAAJ",
      "fMEMNKMAAAAJ",
      "luv0xMIAAAAJ",
      "gYiCq88AAAAJ",
      "Svk4ntYAAAAJ",
      "4GTpCxcAAAAJ"
    ],
    "NpOg5soAAAAJ": [],
    "RLvsC94AAAAJ": [
      "KNr3vb4AAAAJ",
      "6-e-ZBEAAAAJ",
      "McBoXK0AAAAJ",
      "NYOJzM4AAAAJ",
      "gHp0pu4AAAAJ",
      "dOad5HoAAAAJ",
      "x4JAvwMAAAAJ",
      "B7oP0bIAAAAJ",
      "TvdMDhwAAAAJ",
      "iYN86KEAAAAJ",
      "beiWcokAAAAJ",
      "Ml_vQ8MAAAAJ",
      "8h3AFugAAAAJ"
    ],
    "2X0cwhkAAAAJ": [
      "9xDADY4AAAAJ",
      "kxUld9MAAAAJ",
      "k8rlJ8AAAAAJ",
      "66lkylsAAAAJ",
      "emo91rIAAAAJ",
      "1PBvwCgAAAAJ",
      "RHV5YCkAAAAJ",
      "bEuH9QIAAAAJ"
    ],
    "pqP5_PgAAAAJ": [
      "-w5DuHgAAAAJ",
      "yy0UFOwAAAAJ",
      "q7nFtUcAAAAJ",
      "ImpbxLsAAAAJ",
      "8R35rCwAAAAJ",
      "YfPA4YsAAAAJ",
      "XOJE8OEAAAAJ",
      "ZaJEZpYAAAAJ",
      "C_AP8XAAAAAJ",
      "LIJQ_ZYAAAAJ",
      "hYVMrzsAAAAJ",
      "yay_v9EAAAAJ",
      "rDfyQnIAAAAJ",
      "K29Sv1EAAAAJ",
      "U_Jw8DUAAAAJ",
      "iyEuK8kAAAAJ",
      "RM2vMNcAAAAJ",
      "NSWI3OwAAAAJ",
      "5JlEyTAAAAAJ",
      "Vzr1RukAAAAJ",
      "ADkiClQAAAAJ",
      "neGbgzYAAAAJ",
      "0nPi5YYAAAAJ",
      "1bF2s2kAAAAJ",
      "5VaXUQsAAAAJ",
      "mOMChFIAAAAJ",
      "mIlaYj0AAAAJ",
      "OI7zFmwAAAAJ",
      "T6PbwPIAAAAJ",
      "xvOlfw8AAAAJ",
      "MzD8rjoAAAAJ",
      "PIq7jcUAAAAJ",
      "bDq7MZMAAAAJ",
      "9cZUlEYAAAAJ",
      "DqXsbPAAAAAJ",
      "23ZXZvEAAAAJ",
      "zjr6n-QAAAAJ",
      "VCpSh3gAAAAJ",
      "sljtWIUAAAAJ",
      "wxnzyjwAAAAJ"
    ],
    "5VaXUQsAAAAJ": [
      "vfPE6hgAAAAJ",
      "8R35rCwAAAAJ",
      "yy0UFOwAAAAJ",
      "vtwH6GkAAAAJ",
      "zBUwaGkAAAAJ",
      "Ixg9n-EAAAAJ",
      "ogXTOZ4AAAAJ",
      "Rkr2uT8AAAAJ",
      "9GMg6q8AAAAJ",
      "i38QlUwAAAAJ",
      "vYougn0AAAAJ",
      "ROILf3EAAAAJ",
      "UdpacsMAAAAJ",
      "d97bGd8AAAAJ",
      "LW8ze_UAAAAJ",
      "T9To2C0AAAAJ"
    ],
    "OFlBL2kAAAAJ": [],
    "XCZpOcAAAAAJ": [
      "x04W_mMAAAAJ",
      "6gd_QS0AAAAJ",
      "GgQ9GEkAAAAJ",
      "iYN86KEAAAAJ",
      "L4bNmsMAAAAJ",
      "n9K1v-cAAAAJ",
      "0oIAvO8AAAAJ",
      "B76dD7YAAAAJ",
      "wfGiqXEAAAAJ",
      "MHQv5YUAAAAJ",
      "NkzyCvUAAAAJ",
      "itSa94cAAAAJ",
      "WLN3QrAAAAAJ",
      "R5AmmGwAAAAJ",
      "NbXF7T8AAAAJ",
      "dCa-pW8AAAAJ",
      "vfT6-XIAAAAJ",
      "Bmbkv6sAAAAJ",
      "EmmO7LcAAAAJ",
      "OUv7J6QAAAAJ",
      "B7oP0bIAAAAJ",
      "kRJkDakAAAAJ",
      "oBu8kMMAAAAJ",
      "36ofBJgAAAAJ",
      "0mgEF28AAAAJ",
      "N3J70KkAAAAJ",
      "4wcx4HMAAAAJ",
      "vspmOX8AAAAJ",
      "DwTbLh4AAAAJ",
      "fhxshS0AAAAJ",
      "BfmcfEAAAAAJ",
      "ld-vt9QAAAAJ"
    ],
    "FwxfQosAAAAJ": [
      "8R35rCwAAAAJ",
      "vtwH6GkAAAAJ",
      "lJwPbcUAAAAJ",
      "-WZcuuwAAAAJ",
      "CUlqK5EAAAAJ",
      "ouSpgSkAAAAJ",
      "o9aFV8cAAAAJ",
      "lO17d-EAAAAJ",
      "Ci-_QYIAAAAJ",
      "BOAOkNQAAAAJ",
      "neGbgzYAAAAJ",
      "BVde3Y0AAAAJ",
      "I3mSZFEAAAAJ",
      "XCZpOcAAAAAJ",
      "n9K1v-cAAAAJ",
      "zBUwaGkAAAAJ",
      "RM2vMNcAAAAJ",
      "5P2jxPQAAAAJ",
      "E_82W3EAAAAJ",
      "6NjbexEAAAAJ",
      "lHPTxGsAAAAJ",
      "EEp82sIAAAAJ",
      "Q6F3O0sAAAAJ",
      "7eLKa3IAAAAJ",
      "Z8vhOxYAAAAJ",
      "Ihs8dwsAAAAJ",
      "G-x_szsAAAAJ",
      "7kaXqgMAAAAJ",
      "_EJrRVAAAAAJ",
      "Wk2gAZUAAAAJ",
      "8fztli4AAAAJ",
      "53OxjmYAAAAJ",
      "nj49RCAAAAAJ",
      "1bF2s2kAAAAJ",
      "rFd-DiAAAAAJ",
      "yv3sH74AAAAJ",
      "aOklxsQAAAAJ",
      "J8E8GQYAAAAJ",
      "jEf5Q-4AAAAJ",
      "wtK4Yh4AAAAJ",
      "9g4PcV8AAAAJ",
      "vgfGtykAAAAJ",
      "qDsqFkMAAAAJ",
      "HvJj-pEAAAAJ",
      "VVIAoY0AAAAJ",
      "lmsiq6oAAAAJ",
      "BO_b2O8AAAAJ",
      "2efgcS0AAAAJ",
      "e6zXN64AAAAJ",
      "IfEzwZIAAAAJ",
      "LaPb8-YAAAAJ",
      "fwVWk9UAAAAJ",
      "P9ROgN8AAAAJ",
      "P73-vsoAAAAJ",
      "OEivUAQAAAAJ",
      "vOur3Q4AAAAJ",
      "NB4pgZYAAAAJ",
      "7rvNQJoAAAAJ",
      "V48OV8YAAAAJ",
      "Ca2lQs8AAAAJ",
      "q7nFtUcAAAAJ",
      "8qHnRnsAAAAJ",
      "YfPA4YsAAAAJ",
      "CjOTm_4AAAAJ",
      "z2F7CSEAAAAJ",
      "vfPE6hgAAAAJ",
      "q77J4fgAAAAJ",
      "TwABcRgAAAAJ",
      "qOFs67oAAAAJ",
      "zlBSbUAAAAAJ",
      "4vpQvuwAAAAJ",
      "-oy5DaIAAAAJ",
      "qWfJbHMAAAAJ",
      "JSj4f4sAAAAJ",
      "q1HlbIUAAAAJ",
      "kc4-e8oAAAAJ",
      "ZeG4wDgAAAAJ",
      "rmAcDNkAAAAJ",
      "pEFsZdYAAAAJ",
      "PnyV8dgAAAAJ",
      "NQ-n2M0AAAAJ",
      "WzmDQTMAAAAJ",
      "kmGkycYAAAAJ",
      "77zwH0MAAAAJ",
      "CDPa3AgAAAAJ",
      "tR2Qw0YAAAAJ",
      "VINmGpYAAAAJ",
      "KFnmktMAAAAJ",
      "Ih7iLuUAAAAJ",
      "LyHzJOMAAAAJ",
      "joR1Z4UAAAAJ",
      "ixp-vqMAAAAJ",
      "oD1W8a4AAAAJ",
      "kukA0LcAAAAJ",
      "krrh6OUAAAAJ",
      "bKMhN4UAAAAJ",
      "snHVatUAAAAJ",
      "8j-IC6sAAAAJ",
      "QGpxkvkAAAAJ",
      "t23kOGIAAAAJ",
      "2IEoTWwAAAAJ",
      "QEqPllIAAAAJ",
      "qSQjR4EAAAAJ",
      "YoSGjoUAAAAJ",
      "YkWi5xoAAAAJ",
      "L8ozqB8AAAAJ",
      "s5_69i0AAAAJ",
      "i28fU0MAAAAJ",
      "PvDd3k4AAAAJ",
      "yd4xmlcAAAAJ",
      "IC9VJpsAAAAJ",
      "km_K9awAAAAJ",
      "mWGyYMsAAAAJ",
      "41GA5O4AAAAJ",
      "GI5Dse8AAAAJ",
      "STnhSioAAAAJ",
      "EPO5_f4AAAAJ",
      "QSKXFiYAAAAJ",
      "WUKF2ZwAAAAJ",
      "ceSzF9YAAAAJ",
      "KNWTvgEAAAAJ",
      "GStTsxAAAAAJ",
      "ZGpE5cYAAAAJ",
      "KgZxzjsAAAAJ",
      "1HO5UacAAAAJ",
      "_U-HwfkAAAAJ",
      "GmtZ_jYAAAAJ",
      "4sgEDv8AAAAJ",
      "Zp8MeiUAAAAJ",
      "eRcqOkcAAAAJ",
      "Ouu9Zv0AAAAJ",
      "KC6FJ14AAAAJ",
      "TkiMCGoAAAAJ",
      "Feoyh4AAAAAJ",
      "vswo4rQAAAAJ",
      "wbJ0vGkAAAAJ",
      "gdO9Gb0AAAAJ",
      "bh-uRFMAAAAJ",
      "j1zLfKwAAAAJ",
      "ABKq-ecAAAAJ",
      "AzlUrvUAAAAJ",
      "SvinO8kAAAAJ",
      "3tIEZhAAAAAJ",
      "ocMf7fQAAAAJ",
      "trMUyZIAAAAJ",
      "viGDVSkAAAAJ"
    ],
    "UpZmJI0AAAAJ": [
      "gdUv1PIAAAAJ",
      "AEsPCAUAAAAJ",
      "uv7g5kMAAAAJ",
      "d97bGd8AAAAJ",
      "GZkyN4cAAAAJ",
      "bh-uRFMAAAAJ",
      "8R35rCwAAAAJ",
      "RNDrSGYAAAAJ",
      "Jzt5uNAAAAAJ",
      "GRMMc_MAAAAJ",
      "rRJ9wTJMUB8C",
      "7N-ethYAAAAJ",
      "2k18_1IAAAAJ",
      "3Tj5lWEAAAAJ",
      "IUZ-7_cAAAAJ",
      "ROILf3EAAAAJ",
      "FWp7728AAAAJ",
      "yn-nyJwAAAAJ",
      "vtwH6GkAAAAJ",
      "BsOkXDsAAAAJ",
      "ATj2IF4AAAAJ",
      "WgG-GJkAAAAJ",
      "W8VIEZgAAAAJ",
      "nSZG-vcAAAAJ",
      "UAwKvEsAAAAJ",
      "FyQAwaEAAAAJ",
      "oY7AJUgAAAAJ",
      "fJsSvzkAAAAJ",
      "gVFnjOcAAAAJ",
      "XrKLUO0AAAAJ",
      "nzEluBwAAAAJ",
      "rrPyvsgAAAAJ",
      "nQ7Ij30AAAAJ",
      "zQwXlaYAAAAJ",
      "IWcGY98AAAAJ",
      "l4hK4eEAAAAJ",
      "BMydCgcAAAAJ",
      "HSuy6TQAAAAJ",
      "6lD1AscAAAAJ"
    ],
    "Ivot3fkAAAAJ": [],
    "wVGqmWkAAAAJ": [
      "xjnef1AAAAAJ",
      "5Iqe53IAAAAJ",
      "5JserkUAAAAJ",
      "qWak04oAAAAJ",
      "X7bG7YYAAAAJ",
      "jW80JWEAAAAJ",
      "AIsTDk4AAAAJ",
      "YvdzeM8AAAAJ",
      "sc5iZ3EAAAAJ",
      "Zqqw2FQAAAAJ",
      "aJOeGRoAAAAJ",
      "vtwH6GkAAAAJ",
      "Wk2gAZUAAAAJ",
      "e7V7-gEAAAAJ",
      "oExGuP8AAAAJ",
      "xaQuPloAAAAJ",
      "KMBgMs0AAAAJ",
      "A7AuNE8AAAAJ",
      "i5srt20AAAAJ",
      "oavgGaMAAAAJ",
      "cXkm3rsAAAAJ",
      "6_UmGu0AAAAJ",
      "xhU85M4AAAAJ",
      "Gc65LRwAAAAJ",
      "WNqbKzwAAAAJ",
      "xXJIsh4AAAAJ",
      "QNnjg7YAAAAJ"
    ],
    "1b2kKWoAAAAJ": [
      "LZIPfCkAAAAJ",
      "xByATywAAAAJ",
      "z7GCqT4AAAAJ",
      "DN8QtscAAAAJ",
      "Kv9AbjMAAAAJ",
      "MlZq4XwAAAAJ",
      "TyPF9V4AAAAJ",
      "Q_kKkIUAAAAJ",
      "icbo4M0AAAAJ",
      "Q1mcglAAAAAJ"
    ],
    "xBH73TYAAAAJ": [
      "RK72t68AAAAJ",
      "8R35rCwAAAAJ",
      "-gJkPHIAAAAJ",
      "aH8AJu4AAAAJ",
      "ScqM05wAAAAJ",
      "-kdBDxYAAAAJ",
      "1wLVDP4AAAAJ",
      "ipTsozQAAAAJ",
      "vfPE6hgAAAAJ",
      "2efgcS0AAAAJ",
      "T9To2C0AAAAJ",
      "_8Egwg8AAAAJ",
      "FR8zF_4AAAAJ",
      "vtwH6GkAAAAJ",
      "-3zYIjQAAAAJ",
      "HEozmkMAAAAJ",
      "IzqMoZMAAAAJ",
      "C2_ZXdcAAAAJ",
      "-WZcuuwAAAAJ",
      "1EPxhywAAAAJ",
      "d3YhiooAAAAJ",
      "qS_ugJAAAAAJ",
      "q1AewNAAAAAJ",
      "rRJ9wTJMUB8C",
      "vgfGtykAAAAJ",
      "zvz6LIYAAAAJ",
      "BU79wO4AAAAJ",
      "vfT6-XIAAAAJ",
      "DRnOvU8AAAAJ",
      "zUJus70AAAAJ",
      "lJbBWhMAAAAJ",
      "BC8TixYAAAAJ",
      "5Qp_0TUAAAAJ",
      "aPqcyU4AAAAJ",
      "OI7zFmwAAAAJ",
      "6uIhh6MAAAAJ",
      "uQRY6KoAAAAJ",
      "os-DVLkAAAAJ",
      "tlhfhLoAAAAJ",
      "xBv-PMEAAAAJ",
      "xPWCLvEAAAAJ",
      "T04c3fwAAAAJ",
      "nZsD8XwAAAAJ",
      "wUUxGfAAAAAJ",
      "RsZBRBQAAAAJ",
      "6TOQpT4AAAAJ",
      "U89FHq4AAAAJ",
      "bXOt49QAAAAJ",
      "i27Wt-cAAAAJ",
      "fzRnjFgAAAAJ",
      "GyoKzFwAAAAJ",
      "6vghMS0AAAAJ",
      "1O3RPmsAAAAJ",
      "fvwzUnIAAAAJ",
      "Ml_vQ8MAAAAJ",
      "cn_FoswAAAAJ",
      "68hTs9wAAAAJ",
      "LWvgl-8AAAAJ",
      "fmSHtE8AAAAJ",
      "eAwnN44AAAAJ",
      "dnZ8udEAAAAJ",
      "t5Xsx0IAAAAJ",
      "sFtxaMkAAAAJ",
      "VINmGpYAAAAJ",
      "xUGZX_MAAAAJ",
      "GnpHmO8AAAAJ",
      "NvMCACEAAAAJ",
      "FpaKuysAAAAJ",
      "AwpU32MAAAAJ",
      "cAYgoH4AAAAJ",
      "Q93u3c0AAAAJ"
    ],
    "0jSdqoEAAAAJ": [
      "34bu2-8AAAAJ",
      "XXiZaA4AAAAJ",
      "mZl2K3AAAAAJ",
      "Rp5teiwAAAAJ",
      "7JficF8AAAAJ",
      "ScxqPn4AAAAJ",
      "rU_-c5oAAAAJ",
      "XKSNP_EAAAAJ",
      "iZwOlgsAAAAJ",
      "nV-XGVIAAAAJ",
      "o5YQMkMAAAAJ",
      "k3Oh9D0AAAAJ",
      "tyKNvM8AAAAJ",
      "2W82D4QAAAAJ",
      "hyEds7sAAAAJ",
      "0kTel90AAAAJ",
      "FBeJOPgAAAAJ",
      "QLC6sn4AAAAJ",
      "4QuRUy8AAAAJ",
      "cHZ2U6UAAAAJ",
      "uZvvcgUAAAAJ",
      "9JaVNVAAAAAJ",
      "J1awhoMAAAAJ",
      "m1VxcKcAAAAJ",
      "wXIOwRoAAAAJ",
      "dp5LnVAAAAAJ",
      "lPDGYhwAAAAJ",
      "uh7PNBoAAAAJ",
      "CQ39OowAAAAJ",
      "Alsv0h8AAAAJ",
      "niCbywQAAAAJ",
      "rNTIQXYAAAAJ",
      "RCi98EAAAAAJ",
      "UgHB5oAAAAAJ",
      "jbbtciwAAAAJ",
      "EMqQUjoAAAAJ",
      "pcfQnOkAAAAJ",
      "0PUtrrgAAAAJ",
      "ySEpPmYAAAAJ"
    ],
    "I1EvjZsAAAAJ": [],
    "JwiByPoAAAAJ": [
      "mT7ppvwAAAAJ",
      "y2bVjBIAAAAJ",
      "Q5J3UXwAAAAJ",
      "8LcYFjEAAAAJ",
      "RCi98EAAAAAJ",
      "7PGzs4sAAAAJ",
      "Q4oVM7IAAAAJ",
      "_nHDasEAAAAJ",
      "iOLC30YAAAAJ",
      "FAv6Nd8AAAAJ",
      "UgHB5oAAAAAJ",
      "kXB8FBoAAAAJ",
      "prEcE9IAAAAJ",
      "SGjYdrEAAAAJ",
      "6Z-RC-QAAAAJ",
      "XjWnyM4AAAAJ",
      "-Cy0nZ8AAAAJ",
      "PYJlmicAAAAJ",
      "JzXA6NEAAAAJ",
      "0CSbRv8AAAAJ",
      "vDimc-4AAAAJ",
      "feM7-mEAAAAJ",
      "-8DNE4UAAAAJ",
      "W80oBMkAAAAJ",
      "odVYodIAAAAJ",
      "-lONjNgAAAAJ",
      "D_JpQnAAAAAJ",
      "GN5Mc3UAAAAJ",
      "RahgPAEAAAAJ",
      "sfvCNiEAAAAJ",
      "H-xtdV4AAAAJ",
      "LK_CV24AAAAJ",
      "Jq8ZS5kAAAAJ",
      "TjdFs3EAAAAJ",
      "-wflT2wAAAAJ"
    ],
    "7c1B_fIAAAAJ": [
      "xaQuPloAAAAJ",
      "C-ZlBWMAAAAJ",
      "TIKl_foAAAAJ",
      "vtwH6GkAAAAJ",
      "GRMMc_MAAAAJ",
      "obpl7GQAAAAJ",
      "8R35rCwAAAAJ",
      "Vzr1RukAAAAJ",
      "rRJ9wTJMUB8C",
      "cF6i_goAAAAJ",
      "cVZZ7PAAAAAJ",
      "T9To2C0AAAAJ",
      "BGh9WU4AAAAJ",
      "bdNbTVIAAAAJ",
      "mSvrb54AAAAJ",
      "Mu_8iOEAAAAJ",
      "aGXkhcwAAAAJ",
      "U_Jw8DUAAAAJ",
      "-gJkPHIAAAAJ",
      "dD7EpwQAAAAJ",
      "-QopmQoAAAAJ",
      "YdHW1ycAAAAJ",
      "t5Xsx0IAAAAJ",
      "rE7-N30AAAAJ",
      "gYiCq88AAAAJ",
      "k4l-zNYAAAAJ",
      "eGIw04UAAAAJ",
      "Izhkp4YAAAAJ",
      "wA5TK_0AAAAJ",
      "cbuy0ocAAAAJ",
      "LHvso9QAAAAJ",
      "Rqy5KDEAAAAJ",
      "PTS2AOgAAAAJ",
      "0dR_wD0AAAAJ",
      "H-xtdV4AAAAJ",
      "RGNVBKMAAAAJ",
      "2O_ESc4AAAAJ",
      "oFIvUSQAAAAJ",
      "Lncr-VoAAAAJ",
      "wqRhBXMAAAAJ",
      "fAWKizAAAAAJ",
      "jMUkLqwAAAAJ",
      "zBUwaGkAAAAJ",
      "oz4Ca9AAAAAJ",
      "pouyVyUAAAAJ",
      "Q_kKkIUAAAAJ",
      "uRImMPoAAAAJ",
      "j54VcVEAAAAJ",
      "32rbUtYAAAAJ",
      "Z5ZeWGMAAAAJ",
      "XaFhuG8AAAAJ",
      "EJXN6tYAAAAJ",
      "B96GkdgAAAAJ",
      "VgNDYeYAAAAJ",
      "UE9jz_MAAAAJ",
      "B320e3kAAAAJ",
      "hnf_dHwAAAAJ",
      "h1NXfKYAAAAJ",
      "g2uX6_gAAAAJ",
      "QIRWZf8AAAAJ",
      "dVZuASAAAAAJ",
      "nV-tcHAAAAAJ",
      "dHDJlo0AAAAJ",
      "mV7RNZAAAAAJ",
      "Lz5YGiQAAAAJ",
      "onzZ8qUAAAAJ",
      "7JNUMRAAAAAJ",
      "364jgpgAAAAJ",
      "IzwvqPIAAAAJ",
      "YJd3v4QAAAAJ",
      "rvW4j38AAAAJ",
      "z3IRvDwAAAAJ",
      "M0OhM1UAAAAJ",
      "RK72t68AAAAJ",
      "Dy8iau4AAAAJ",
      "SxP7_woAAAAJ",
      "37M48B0AAAAJ",
      "Sczy43gAAAAJ",
      "B847xq8AAAAJ",
      "YAHWbtkAAAAJ",
      "6AyF1U8AAAAJ",
      "AkgfxXUAAAAJ",
      "eHn2VXEAAAAJ",
      "q7nFtUcAAAAJ",
      "-w5DuHgAAAAJ",
      "tzvqRX4AAAAJ",
      "MTd1890AAAAJ",
      "hYtGXD0AAAAJ",
      "6TOQpT4AAAAJ",
      "t5lVb6sAAAAJ",
      "6KkohssAAAAJ",
      "7Fxbm0AAAAAJ",
      "baDPMxkAAAAJ",
      "T-f6XlEAAAAJ",
      "jHgmQEIAAAAJ",
      "2WSooDIAAAAJ",
      "CeEO6SIAAAAJ",
      "02kSQ3IAAAAJ",
      "_egJxfMAAAAJ",
      "IcasIiwAAAAJ",
      "0nPi5YYAAAAJ",
      "YfPA4YsAAAAJ",
      "KsocBp8AAAAJ",
      "5VaXUQsAAAAJ",
      "pqP5_PgAAAAJ"
    ],
    "8jVzL_YAAAAJ": [],
    "vYougn0AAAAJ": [],
    "CUlqK5EAAAAJ": [
      "jyxO2akAAAAJ",
      "8cxDHS4AAAAJ",
      "jTdkr10AAAAJ",
      "03n03GEAAAAJ",
      "iu-Gqo4AAAAJ",
      "9aFd9dEAAAAJ",
      "KzhR_TsAAAAJ",
      "_CuXgYIAAAAJ",
      "WS2-qlAAAAAJ",
      "GbaikvkAAAAJ",
      "FJ-huxgAAAAJ",
      "iBeDoRAAAAAJ",
      "W8zwlYQAAAAJ",
      "GMzzRRUAAAAJ",
      "ITZ1e7MAAAAJ",
      "2wrS35MAAAAJ",
      "rJotb-YAAAAJ",
      "CCV58dgAAAAJ",
      "9D4aG8AAAAAJ",
      "DmahiOYAAAAJ",
      "awvsNQYAAAAJ",
      "QFpswmcAAAAJ",
      "6TGwETYAAAAJ",
      "GArEeWQAAAAJ",
      "ymzxRhAAAAAJ",
      "194wSMsAAAAJ",
      "XPAkzTEAAAAJ",
      "Lw0H0EwAAAAJ",
      "3B2c31wAAAAJ",
      "tXJDPJAAAAAJ",
      "njOmQFsAAAAJ",
      "KUG_tG0AAAAJ",
      "V3kGMXUAAAAJ",
      "XWhajuQAAAAJ",
      "KNWTvgEAAAAJ",
      "iAEBIB4AAAAJ",
      "2bDu3ecAAAAJ",
      "IrixA8MAAAAJ",
      "SFCOJxMAAAAJ",
      "ijpYJQwAAAAJ",
      "eycXl_QAAAAJ",
      "CgSBtPYAAAAJ",
      "taqlL_cAAAAJ",
      "559LF80AAAAJ",
      "DN8QtscAAAAJ",
      "ACjYGPUAAAAJ",
      "DSKXnkkAAAAJ",
      "t1rjgHgAAAAJ",
      "u5G_A14AAAAJ",
      "SVIdh6AAAAAJ",
      "qvRsU00AAAAJ",
      "YYH0BjEAAAAJ",
      "x2wyjkAAAAAJ",
      "qSo45J0AAAAJ",
      "18fTep8AAAAJ",
      "bh-uRFMAAAAJ",
      "4V1nNm4AAAAJ",
      "ijmuZ0wAAAAJ",
      "cCda-zQAAAAJ",
      "z76PBfYAAAAJ",
      "V7D7hxMAAAAJ",
      "6rl-XhwAAAAJ",
      "gXFy11EAAAAJ",
      "4_JVf14AAAAJ",
      "Wbwt1JgAAAAJ",
      "LHTI1W8AAAAJ",
      "ElNDOmUAAAAJ",
      "97RDUygAAAAJ",
      "ZsM2sW8AAAAJ"
    ],
    "qWak04oAAAAJ": [],
    "bMZFLZ_V4goC": [
      "kXB8FBoAAAAJ",
      "6ujRH5UAAAAJ",
      "xEWgxBsAAAAJ",
      "dG9MV7oAAAAJ",
      "WNHLjp0AAAAJ",
      "rlmROVsAAAAJ",
      "9nnDvooAAAAJ",
      "zCaMimYAAAAJ",
      "IdkhB44AAAAJ",
      "nUlanA8AAAAJ",
      "4bl7qAgAAAAJ",
      "-0ASVXUAAAAJ",
      "SgGIYH0AAAAJ",
      "yYpm9LoAAAAJ",
      "HG08FCMAAAAJ",
      "6Q6TCkkAAAAJ",
      "DqXsbPAAAAAJ",
      "r90OelAAAAAJ",
      "_bKTUqAAAAAJ",
      "pl-qLQwAAAAJ",
      "bd4gMFAAAAAJ",
      "wy0FA1cAAAAJ",
      "khZgnWYAAAAJ",
      "XHZlMYUAAAAJ",
      "rIoPIFsAAAAJ",
      "-ki9u4sAAAAJ",
      "tmKKPjkAAAAJ",
      "sNGk-9MAAAAJ",
      "Y2YBgCsAAAAJ",
      "ItxA4esAAAAJ",
      "Th4PuGkAAAAJ",
      "cHia5p0AAAAJ",
      "dTue6HQAAAAJ",
      "CXPpSu0AAAAJ",
      "9TbXgQ0AAAAJ",
      "M7y1dj8AAAAJ",
      "J8_FdjkAAAAJ",
      "8fztli4AAAAJ",
      "GDabimYAAAAJ",
      "-CzfgbwAAAAJ",
      "0dQzZH8AAAAJ",
      "HF-1DDwAAAAJ",
      "YTO4ex4AAAAJ",
      "ZWH5jCwAAAAJ",
      "8R35rCwAAAAJ",
      "5NGAbT4AAAAJ",
      "UgHB5oAAAAAJ",
      "UzjHQLcAAAAJ",
      "BZBkjNYAAAAJ",
      "13yyuCcAAAAJ",
      "86za4C0AAAAJ",
      "PbEw81gAAAAJ",
      "gu2noOcAAAAJ",
      "6CTPn44AAAAJ",
      "3-9qq6sAAAAJ",
      "INd48rQAAAAJ",
      "E_UlAVQAAAAJ",
      "Bm3pH5AAAAAJ",
      "TCYAoF8AAAAJ",
      "lutJce0AAAAJ",
      "mWGyYMsAAAAJ",
      "mPabwyYAAAAJ",
      "8LcYFjEAAAAJ",
      "1MZF70cAAAAJ",
      "403nNzMAAAAJ",
      "-6s0HQ4AAAAJ",
      "H2QWyooAAAAJ",
      "tRCR72EAAAAJ",
      "qlwIFJsAAAAJ",
      "umivlPQAAAAJ",
      "hYMvCbwAAAAJ",
      "-JPZ21IAAAAJ",
      "7PljKpoAAAAJ",
      "a2jB6z0AAAAJ",
      "oE6XwXsAAAAJ",
      "BN0O9wgAAAAJ",
      "5zHUcUEAAAAJ",
      "no_BfYgAAAAJ",
      "TiDGyF4AAAAJ",
      "9k20Ie4AAAAJ",
      "1aj4dZcAAAAJ",
      "aqSKwDQAAAAJ",
      "3pu8FE0AAAAJ",
      "AMVmM84AAAAJ",
      "1wLVDP4AAAAJ",
      "tm5kow8AAAAJ",
      "hwg8plgAAAAJ",
      "16srx18AAAAJ",
      "BFnzsoMAAAAJ",
      "kog9iL0AAAAJ",
      "KfTWTtAAAAAJ",
      "DiBVENwAAAAJ",
      "wbZtij8AAAAJ",
      "6aZUUEAAAAAJ"
    ],
    "dD7EpwQAAAAJ": [],
    "kukA0LcAAAAJ": [
      "km6CP8cAAAAJ",
      "iYN86KEAAAAJ",
      "0RAmmIAAAAAJ",
      "WBCKQMsAAAAJ",
      "WLN3QrAAAAAJ",
      "MOgfm8oAAAAJ",
      "7hwJ2ckAAAAJ",
      "U89FHq4AAAAJ",
      "Nq0dVMcAAAAJ",
      "c646VbAAAAAJ",
      "O7MZStwAAAAJ",
      "krrh6OUAAAAJ",
      "kbN88gsAAAAJ",
      "_WnkXlkAAAAJ",
      "KOBmy0sAAAAJ",
      "Sm15FXIAAAAJ",
      "nHh9PSsAAAAJ",
      "6F3ZIeEAAAAJ",
      "1ScWJOoAAAAJ",
      "Wck7gd0AAAAJ",
      "68c5HfwAAAAJ",
      "kcTK_FAAAAAJ",
      "BFzFy1YAAAAJ",
      "zqLpO2QAAAAJ",
      "Ysjk8kkAAAAJ",
      "dxwPYhQAAAAJ",
      "euUV4iUAAAAJ",
      "bn4xHHIAAAAJ",
      "s3l225EAAAAJ",
      "LmKtwk8AAAAJ",
      "2HE7cTEAAAAJ",
      "CEt6_mMAAAAJ",
      "jWWx33IAAAAJ",
      "EvUM6UUAAAAJ",
      "Q8K3FjQAAAAJ",
      "wfGiqXEAAAAJ",
      "dEtv5r4AAAAJ",
      "XE9SDzgAAAAJ",
      "XSforroAAAAJ",
      "yVtSOt8AAAAJ",
      "xdlBKc8AAAAJ",
      "DJon7w4AAAAJ",
      "oU0jQIAAAAAJ",
      "QdnjDj8AAAAJ",
      "1XAhYswAAAAJ",
      "Vs-MdPcAAAAJ",
      "iFhSTbAAAAAJ",
      "F99FuaAAAAAJ",
      "Yxv1EwcAAAAJ",
      "-6Pj3IYAAAAJ",
      "PsKlNzUAAAAJ",
      "FyZbyIUAAAAJ",
      "LNZ4efwAAAAJ",
      "Q6UMpRYAAAAJ",
      "nfHyDeUAAAAJ",
      "TMawhM4AAAAJ",
      "akrkYU0AAAAJ",
      "0g31OfAAAAAJ",
      "GyoKzFwAAAAJ",
      "eQ1uJ6UAAAAJ",
      "iH9DuY0AAAAJ",
      "ymzxRhAAAAAJ",
      "miDt1j8AAAAJ",
      "lmjR_qMAAAAJ",
      "7b5tlJkAAAAJ",
      "5TZ7f5wAAAAJ",
      "slS0dvUAAAAJ",
      "aLl3rYoAAAAJ",
      "gxL1qj8AAAAJ",
      "_S_1cEEAAAAJ",
      "LAoMyyoAAAAJ",
      "yxWtZLAAAAAJ",
      "32w7x1cAAAAJ",
      "wbJxGQ8AAAAJ",
      "XpscC-EAAAAJ",
      "GhPDR9AAAAAJ",
      "wo_M4uQAAAAJ",
      "-ZfwQOkAAAAJ",
      "udwtIesAAAAJ",
      "5Uz70IoAAAAJ",
      "lMkTx0EAAAAJ",
      "iBeDoRAAAAAJ",
      "Afa_1z4AAAAJ",
      "oBu8kMMAAAAJ",
      "j40pfugAAAAJ",
      "ZX9LE3QAAAAJ",
      "AEBWEm8AAAAJ",
      "dyYryZYAAAAJ",
      "D9eVSd8AAAAJ",
      "qx_e_9wAAAAJ",
      "h-sqIigAAAAJ",
      "Yc94070AAAAJ",
      "9BGzHdUAAAAJ",
      "oejm5IUAAAAJ",
      "K757SxgAAAAJ",
      "7i101rcAAAAJ",
      "Sh5PsUUAAAAJ",
      "mKLoSgMAAAAJ",
      "nP8cwkIAAAAJ",
      "tvUH3WMAAAAJ",
      "h7OHSkoAAAAJ",
      "AQIwobkAAAAJ",
      "0XtGoMUAAAAJ",
      "s0njcGgAAAAJ",
      "7V7yNeoAAAAJ",
      "HT85tXsAAAAJ",
      "Cul0g2YAAAAJ",
      "1ir6WUEAAAAJ",
      "8x8FUr8AAAAJ",
      "yVIXGqYAAAAJ",
      "GWyeAskAAAAJ",
      "ZK7OfxkAAAAJ",
      "h3Nsz6YAAAAJ",
      "iRgYMuEAAAAJ",
      "Nj74Gv4AAAAJ",
      "hJjeVsQAAAAJ",
      "8R35rCwAAAAJ",
      "6QpFL68AAAAJ",
      "F_Go4V4AAAAJ",
      "PgqC5SYAAAAJ",
      "p7mehDEAAAAJ",
      "XK_ktwQAAAAJ",
      "oD1W8a4AAAAJ",
      "pDIuuVwAAAAJ",
      "yVubPz4AAAAJ",
      "gLnCTgIAAAAJ",
      "KynAS2gAAAAJ",
      "dLaR9lgAAAAJ",
      "7qufP-8AAAAJ",
      "Dg5qUb0AAAAJ",
      "W8zwlYQAAAAJ",
      "rF2VvOgAAAAJ",
      "bp6Ah4EAAAAJ",
      "VQYdApgAAAAJ",
      "u2tgePAAAAAJ",
      "XT3E7RoAAAAJ",
      "JmJfOkMAAAAJ",
      "bOQGfFIAAAAJ",
      "X7kZFnoAAAAJ",
      "NBUWnTYAAAAJ",
      "XRhKEGMAAAAJ",
      "bLb3VdIAAAAJ",
      "kaAnZw0AAAAJ",
      "mZfgLA4AAAAJ",
      "W7uYg0UAAAAJ",
      "LWrdpCsAAAAJ",
      "7-9jOvEAAAAJ",
      "wBMRRk0AAAAJ",
      "uPkyCmIAAAAJ",
      "Y8-xGncAAAAJ",
      "u5SbAJAAAAAJ",
      "lsFo_DcAAAAJ",
      "vYRgxJ8AAAAJ",
      "mw9kXD8AAAAJ",
      "dJQf4SYAAAAJ",
      "lb1fNb0AAAAJ",
      "lLTdYUYAAAAJ",
      "LCAcHmAAAAAJ",
      "IwBHa3gAAAAJ",
      "p_iffpcAAAAJ",
      "Wk2gAZUAAAAJ",
      "naUbiQ8AAAAJ",
      "LC0j4ekAAAAJ",
      "0xIrC1cAAAAJ",
      "vtegaJgAAAAJ",
      "sDwpLgwAAAAJ",
      "xYL6KC0AAAAJ",
      "W5WbqgoAAAAJ",
      "0fRlG8oAAAAJ",
      "GQWTo4MAAAAJ",
      "NAdlsUgAAAAJ",
      "uJrcFwYAAAAJ",
      "4HLUnhIAAAAJ",
      "AXOiHucAAAAJ",
      "vfTpaOAAAAAJ",
      "4nw0skIAAAAJ",
      "Ivot3fkAAAAJ",
      "zeX8KGAAAAAJ",
      "Iw-G2qIAAAAJ",
      "RryVaLgAAAAJ",
      "SCFarTEAAAAJ"
    ],
    "xuLKJboAAAAJ": [
      "K2WfIlsAAAAJ",
      "iOLC30YAAAAJ",
      "8R35rCwAAAAJ",
      "s_qd9x0AAAAJ",
      "GR_DsT0AAAAJ",
      "r-mWYj0AAAAJ",
      "XtSSJm0AAAAJ",
      "nUlanA8AAAAJ",
      "o42MH0MAAAAJ",
      "MxeFvewAAAAJ",
      "dDGy3N0AAAAJ",
      "tR-p-r8AAAAJ",
      "G1WMpcUAAAAJ",
      "bBQx_5MAAAAJ",
      "ZIw-AGsAAAAJ",
      "33yNvIgAAAAJ",
      "Dy8iau4AAAAJ",
      "Kq0dhLAAAAAJ",
      "BZGj6sAAAAAJ",
      "vEiu33sAAAAJ",
      "9nnDvooAAAAJ",
      "rlmROVsAAAAJ",
      "CLgOCOAAAAAJ",
      "6VW1kJgAAAAJ",
      "eBtFiuAAAAAJ",
      "anc4v98AAAAJ",
      "UnrY-40AAAAJ",
      "Ao4gtsYAAAAJ",
      "Lu7sHfoAAAAJ",
      "Yu_0vEEAAAAJ",
      "EPQZFzwAAAAJ",
      "tbu1jqUAAAAJ",
      "wMjQdBcAAAAJ"
    ],
    "x-n9rIMAAAAJ": [],
    "VecEj6kAAAAJ": [
      "21_amyAAAAAJ",
      "j9ICsOEAAAAJ",
      "Es-YRKMAAAAJ",
      "fmUkNVcAAAAJ",
      "yW593xUAAAAJ",
      "E1CsZLcAAAAJ",
      "tu9gL58AAAAJ",
      "-T2Gq-EAAAAJ",
      "fa193PsAAAAJ",
      "v80j6o0AAAAJ",
      "-qS6zoJHb0IC",
      "Et-LI74AAAAJ",
      "ZlqnYZoAAAAJ",
      "UGpC1zgAAAAJ",
      "2L_8ynAAAAAJ"
    ],
    "B7oP0bIAAAAJ": [],
    "m8m9nD0AAAAJ": [
      "VZHxoh8AAAAJ",
      "Nh832fgAAAAJ",
      "orVoz4IAAAAJ",
      "rPhGUw0AAAAJ",
      "w1srHyIAAAAJ",
      "mNfCP3gAAAAJ",
      "tAUdLM0AAAAJ",
      "OttawxUAAAAJ",
      "df-THM0AAAAJ",
      "Bk5q_pAAAAAJ",
      "6qWcDTAAAAAJ",
      "6JZ3R6wAAAAJ",
      "cKtU3eAAAAAJ",
      "Bw-WdyUAAAAJ",
      "sioumZAAAAAJ"
    ],
    "VYiRfCwAAAAJ": [
      "-Txt8vsAAAAJ",
      "TiF1WEsAAAAJ",
      "vtwH6GkAAAAJ",
      "1aou7GkAAAAJ",
      "MaSXNhUAAAAJ",
      "UWZA0v4AAAAJ",
      "hxlxVEUAAAAJ",
      "-_eJqYQAAAAJ",
      "rRJ9wTJMUB8C",
      "RikRyq4AAAAJ",
      "mtejbKYAAAAJ",
      "1pnp1ZAAAAAJ",
      "6re6uwMAAAAJ",
      "dzOd2hgAAAAJ",
      "kg4bCpgAAAAJ",
      "G2zXCNkAAAAJ",
      "d2gqmrUAAAAJ",
      "zCdh4NEAAAAJ",
      "Y7Rm3DYAAAAJ",
      "aZ1Rh50AAAAJ",
      "HcL76tsAAAAJ",
      "GweT9VUAAAAJ",
      "ls_kE0UAAAAJ",
      "9v86038AAAAJ",
      "6dr5fLEAAAAJ",
      "2oy3OXYAAAAJ"
    ],
    "j_xavDQAAAAJ": [
      "vtwH6GkAAAAJ",
      "EMDboA4AAAAJ",
      "5tVuggUAAAAJ",
      "8R35rCwAAAAJ",
      "HBztuGIAAAAJ",
      "VT7peyEAAAAJ",
      "itSa94cAAAAJ",
      "bh-uRFMAAAAJ",
      "t9HPFawAAAAJ",
      "C-ZlBWMAAAAJ",
      "vOLXDDAAAAAJ",
      "whdanWAAAAAJ"
    ],
    "55TAOdgAAAAJ": [
      "lPycXNcAAAAJ",
      "0gJQCIgAAAAJ",
      "m8NUgw0AAAAJ",
      "r3q68rcAAAAJ",
      "RrYw5jkAAAAJ",
      "Rn_BmTYAAAAJ",
      "PCtRSvUAAAAJ",
      "AaauqDAAAAAJ",
      "qYhRbJoAAAAJ",
      "uK5wa_EAAAAJ",
      "3qPiYJoAAAAJ",
      "0Wb80ScAAAAJ",
      "loxOHhoAAAAJ",
      "7yobGX4AAAAJ",
      "2vQRGrYAAAAJ",
      "MO7qaUIAAAAJ",
      "E__5Lr0AAAAJ",
      "mim8FQkAAAAJ",
      "67nE-wQ_g_cC",
      "0M99MEYAAAAJ",
      "UlpHyKAAAAAJ",
      "KWG3UUMAAAAJ",
      "3p-KQUwAAAAJ",
      "vRI2blsAAAAJ",
      "wb-DKCIAAAAJ",
      "46MDvXcAAAAJ",
      "m3eDp7kAAAAJ",
      "bg92wVEAAAAJ",
      "DcV-5RAAAAAJ",
      "l96zhjwAAAAJ",
      "GR_DsT0AAAAJ",
      "d77eUbgAAAAJ",
      "B1guGw8AAAAJ",
      "FasIlp0AAAAJ",
      "YQcU3NYAAAAJ",
      "e-c3R8QAAAAJ",
      "fVuWflQAAAAJ",
      "a1ngrCIAAAAJ",
      "DgCDBbkAAAAJ",
      "0DD8EREAAAAJ",
      "MzD8rjoAAAAJ",
      "mQnBkmoAAAAJ",
      "vFWw1NoAAAAJ",
      "CeioNO4AAAAJ",
      "aO8KpGcAAAAJ",
      "PS-TM94AAAAJ",
      "_PZKLYUAAAAJ",
      "oC8YKjUAAAAJ",
      "oExGuP8AAAAJ",
      "YzsCLBoAAAAJ"
    ],
    "xT19Jc0AAAAJ": [
      "3r-fWJwAAAAJ",
      "YQcU3NYAAAAJ",
      "FaJALc0AAAAJ",
      "Q4DTPw4AAAAJ",
      "t4w1jE4AAAAJ",
      "fZDywBkAAAAJ",
      "fn13u8IAAAAJ",
      "yHSi7XkAAAAJ",
      "qxWORNoAAAAJ",
      "SO9llAMAAAAJ",
      "9hkEkG0AAAAJ",
      "sdw9roIAAAAJ",
      "3p-KQUwAAAAJ",
      "JcaWZAQAAAAJ",
      "x-G741IAAAAJ",
      "Bx9WGD6lBFEC",
      "GcR_rlkAAAAJ",
      "Ic4pPAYAAAAJ",
      "tPlneaIAAAAJ",
      "Koez6qoAAAAJ",
      "J_xhWIQAAAAJ",
      "K4bCJYcAAAAJ",
      "T8grPNsAAAAJ",
      "eZ51GLAAAAAJ"
    ],
    "vS8b6GwAAAAJ": [
      "8R35rCwAAAAJ",
      "uDuLNHkAAAAJ",
      "jeOFRDsAAAAJ",
      "T6PbwPIAAAAJ",
      "79k7bGEAAAAJ",
      "dD-3S4QAAAAJ",
      "EEkwehIAAAAJ",
      "YE9w2BsAAAAJ",
      "VT7peyEAAAAJ",
      "jWxX49cAAAAJ",
      "Izhkp4YAAAAJ",
      "-DYvinwAAAAJ",
      "YCO3WQsAAAAJ",
      "J7p1Fx4AAAAJ",
      "K4OcFXUAAAAJ",
      "Q0YEc-QAAAAJ",
      "080Y_lUAAAAJ",
      "HGXVByQAAAAJ",
      "SBKP1acAAAAJ",
      "all0DHsAAAAJ",
      "j7MW4iYAAAAJ",
      "4QqjaDgAAAAJ",
      "q-06TwoAAAAJ",
      "Zlpuln8AAAAJ",
      "LnAus20AAAAJ",
      "QmYUuCYAAAAJ",
      "dTV6Zj4AAAAJ",
      "R889GIQAAAAJ",
      "3uClq6kAAAAJ",
      "5lB_d78AAAAJ",
      "vHs01IMAAAAJ",
      "e9MgnYYAAAAJ",
      "ZeJjFQMAAAAJ",
      "t3l8q6gAAAAJ",
      "jYYYIvsAAAAJ",
      "wurqZikAAAAJ",
      "Q6UMpRYAAAAJ",
      "l2E0LR4AAAAJ",
      "-GduGkcAAAAJ",
      "CjOTm_4AAAAJ",
      "9dAjSlYAAAAJ",
      "Hahkg24AAAAJ",
      "0ncQNL8AAAAJ",
      "EYk7M80AAAAJ",
      "vhP-tlcAAAAJ",
      "zFsdqo8AAAAJ",
      "P2mG6rcAAAAJ",
      "p6iM9gIAAAAJ",
      "DNQTSwsAAAAJ",
      "dlzWP0UAAAAJ",
      "cCYTVWQAAAAJ",
      "1gVfqpcAAAAJ",
      "_CYEGnoAAAAJ",
      "OeULb38AAAAJ",
      "yA4rb60AAAAJ",
      "BXNelwwAAAAJ"
    ],
    "_vjPh4UAAAAJ": [
      "8oW4qk4AAAAJ",
      "g87CIwgAAAAJ",
      "diIore8AAAAJ",
      "UyD0bLYAAAAJ",
      "gVUD47sAAAAJ",
      "XG2aNyYAAAAJ",
      "2UiIURcAAAAJ",
      "WEQF9DgAAAAJ",
      "ZP6gGZYAAAAJ",
      "6ArMETUAAAAJ",
      "eQ9_vDAAAAAJ",
      "Z6nLCukAAAAJ",
      "wNRE148AAAAJ",
      "RNHJqvcAAAAJ",
      "Ak7gyjQAAAAJ",
      "axf9B1gAAAAJ",
      "3WJN5csAAAAJ",
      "eQujqDgAAAAJ",
      "j6eVlwsAAAAJ",
      "Qqtyp-EAAAAJ",
      "RfQ6JRcAAAAJ",
      "w7t5xQsAAAAJ",
      "hRggMmIAAAAJ",
      "bpDPt1QAAAAJ",
      "Ae6siZoAAAAJ",
      "a2PXepkAAAAJ",
      "Jlv4MR4AAAAJ",
      "tf1c4_kAAAAJ",
      "NDhlLv0AAAAJ",
      "qk0hejcAAAAJ",
      "rYFeExcAAAAJ",
      "BwjRbkcAAAAJ",
      "olerUhcAAAAJ",
      "MvyO9jAAAAAJ",
      "SKXmmxIAAAAJ",
      "5-pEIw0AAAAJ",
      "gWGQIh4AAAAJ",
      "rkpVQI4AAAAJ",
      "N0tU5N4AAAAJ",
      "x1cDFYsAAAAJ",
      "Znp3UkEAAAAJ",
      "_92oJ8IAAAAJ",
      "m6NDX0IAAAAJ",
      "YAHWbtkAAAAJ",
      "B847xq8AAAAJ",
      "62Uqu6wAAAAJ",
      "J9-meToAAAAJ",
      "abn9WWMAAAAJ",
      "umm-i20AAAAJ",
      "Gwrwxa0AAAAJ",
      "3evp9QMAAAAJ",
      "pOd2M64AAAAJ",
      "Wewcpo4AAAAJ",
      "9mIBxkMAAAAJ",
      "umOOMzsAAAAJ",
      "p5LCHHEAAAAJ",
      "cTpyTaIAAAAJ",
      "YR_MYrAAAAAJ",
      "sgH6VuwAAAAJ",
      "fE4XXdIAAAAJ",
      "RJEQriwAAAAJ",
      "T1RxzcUAAAAJ",
      "n2S1wyQAAAAJ",
      "a0wbKRAAAAAJ",
      "Bri9R_4AAAAJ",
      "dlytHK4AAAAJ",
      "QZrx9MEAAAAJ",
      "nf_EnbAAAAAJ",
      "begDaeQAAAAJ",
      "SQ1eGN4AAAAJ",
      "E1jZijwAAAAJ",
      "AScYAMYAAAAJ",
      "rwfHSYgAAAAJ",
      "gG7M_pIAAAAJ",
      "k8Px6S8AAAAJ",
      "bKMKO_AAAAAJ",
      "6REa4FcAAAAJ",
      "zhxqybUAAAAJ",
      "ewGrWyQAAAAJ",
      "kW06fgwAAAAJ",
      "rRvt-YAAAAAJ",
      "h8apFZsAAAAJ",
      "whB5QDoAAAAJ",
      "7-2bbBgAAAAJ",
      "BF39lMQAAAAJ",
      "VX7d5EQAAAAJ",
      "EqKRQ4YAAAAJ",
      "sPzla6IAAAAJ",
      "XXNAaWQAAAAJ",
      "T645IqsAAAAJ",
      "Z9uBjIEAAAAJ",
      "SY8DwiUAAAAJ",
      "Fmq16C4AAAAJ",
      "xITAf6EAAAAJ",
      "qOgSRPQAAAAJ",
      "cGvYY4YAAAAJ",
      "yc2mM9IAAAAJ",
      "Q1W6RzMAAAAJ",
      "3nXmUP0AAAAJ",
      "YUHMFMMAAAAJ",
      "XD_01h8AAAAJ",
      "Wd4ChQ8AAAAJ",
      "6pR07RQAAAAJ",
      "6FWSv1EAAAAJ",
      "BWDUVOIAAAAJ",
      "jmeHpKUAAAAJ",
      "4DuiN7AAAAAJ",
      "-ihQeTYAAAAJ",
      "i5U_SqgAAAAJ",
      "61hrt1cAAAAJ",
      "724lKQgAAAAJ",
      "_cIeQgYAAAAJ",
      "1YEoqJsAAAAJ",
      "BHZT068AAAAJ",
      "JR_KR7MAAAAJ",
      "9cHjPDkAAAAJ",
      "xGbDr7YAAAAJ",
      "oOwNKsAAAAAJ",
      "AdAd4QIAAAAJ",
      "yDXNzfIAAAAJ",
      "jAAj8DAAAAAJ",
      "s7-TjaIAAAAJ",
      "8_lfEOsAAAAJ",
      "SAemU0sAAAAJ",
      "odfHRTcAAAAJ",
      "lWrAwrwAAAAJ",
      "2sPxj90AAAAJ",
      "MzT5-4kAAAAJ",
      "rXpctjYAAAAJ",
      "6KQy8zgAAAAJ",
      "gaqzMHAAAAAJ",
      "aHtfItQAAAAJ",
      "kzYoaFYAAAAJ",
      "t0ZfFH8AAAAJ",
      "2Q1BK6gAAAAJ",
      "n41vSUAAAAAJ",
      "tMBYEWAAAAAJ",
      "jAKBew4AAAAJ",
      "o8048ZwAAAAJ"
    ],
    "bLUllHEAAAAJ": [
      "VUi7eM8AAAAJ",
      "FHOFCuEAAAAJ",
      "Qq70O4UAAAAJ",
      "UZ6kI2AAAAAJ",
      "3-mdTUAAAAAJ",
      "pTvhQDQAAAAJ",
      "vtwH6GkAAAAJ",
      "sow8PQYAAAAJ",
      "fmSHtE8AAAAJ",
      "vfT6-XIAAAAJ",
      "n0pk_jEAAAAJ",
      "fMDLYCUAAAAJ",
      "LMtE3FQAAAAJ"
    ],
    "XP_Hxm4AAAAJ": [
      "te2go-MAAAAJ",
      "WlWma8EAAAAJ",
      "373LKEYAAAAJ",
      "rwtM4roAAAAJ",
      "N0x7TRcAAAAJ",
      "nSI1yM0AAAAJ",
      "q3AmlWMAAAAJ",
      "yhpAb1YAAAAJ",
      "lQumblsAAAAJ",
      "TMPlDbsAAAAJ",
      "1jgwWYAAAAAJ",
      "dztQNeQAAAAJ",
      "4WVI4SYAAAAJ",
      "a3G23eUAAAAJ",
      "bh-uRFMAAAAJ",
      "L-TjbwcAAAAJ",
      "Ige4r2YAAAAJ",
      "Q9va0qQAAAAJ",
      "oclUWQEAAAAJ",
      "5hH5bt8AAAAJ",
      "qmjjxBoAAAAJ",
      "_bIWSJAAAAAJ",
      "iZwOlgsAAAAJ",
      "j03zZgcAAAAJ",
      "Mux9-okAAAAJ",
      "aSJthdEAAAAJ",
      "BKfjTj4AAAAJ",
      "bo0P2qYAAAAJ",
      "DplAah0AAAAJ",
      "JlqDXrUAAAAJ",
      "mqpjAt4AAAAJ",
      "UjCHdlEAAAAJ",
      "BWc6kMsAAAAJ",
      "Jek-NhkAAAAJ",
      "OzfKmBEAAAAJ",
      "9H75c04AAAAJ",
      "-GRqX-QAAAAJ",
      "hSaJzr8AAAAJ",
      "73D0CgcAAAAJ",
      "YGxUJXkAAAAJ",
      "LwtwtDgAAAAJ",
      "GECP5OIAAAAJ",
      "VtbaGhIAAAAJ",
      "LcARjz0AAAAJ",
      "9emgsOwAAAAJ",
      "72yPqG4AAAAJ",
      "XoXgt4oAAAAJ",
      "jgeWbOMAAAAJ",
      "aq4kedwAAAAJ",
      "WjF1dugAAAAJ",
      "jxF7YgYAAAAJ",
      "gfUj1FUAAAAJ",
      "8NoMRR0AAAAJ",
      "uK53FGQAAAAJ",
      "8JGG3KcAAAAJ",
      "7ZXfuAMAAAAJ",
      "bFNzhmwAAAAJ",
      "PaEn9KEAAAAJ",
      "Jt1tl0YAAAAJ",
      "HfXk1nEAAAAJ",
      "mQTedo0AAAAJ",
      "btHLQeQAAAAJ",
      "ejD_Z3IAAAAJ",
      "cpv4vqAAAAAJ",
      "H6ArRNYAAAAJ",
      "chD5XxkAAAAJ",
      "N5MghGIAAAAJ",
      "Ke__1Z8AAAAJ",
      "WIKDWBQAAAAJ",
      "kKYbS08AAAAJ",
      "E-oOiwwAAAAJ",
      "Fykyo9gAAAAJ",
      "_Gl7YvAAAAAJ",
      "UNXPtTMAAAAJ",
      "64y6FZcAAAAJ",
      "pSpRfQ4AAAAJ",
      "Cw7LTkkAAAAJ",
      "VVIAoY0AAAAJ",
      "CUlqK5EAAAAJ",
      "iQx57VIAAAAJ",
      "yZ5WqE4AAAAJ",
      "ny7iUz4AAAAJ",
      "pFlJsUEAAAAJ",
      "SywbV14AAAAJ",
      "7nuMOqoAAAAJ",
      "ISomHK0AAAAJ",
      "CJwLwzQAAAAJ"
    ],
    "wCRav7EAAAAJ": [
      "d5y4iKAAAAAJ",
      "8R35rCwAAAAJ",
      "xvOlfw8AAAAJ",
      "PpzsjioAAAAJ",
      "5bc-9A4AAAAJ",
      "gB87zD4AAAAJ",
      "AGPooMYAAAAJ",
      "axX7PCwAAAAJ"
    ],
    "dB6ftCcAAAAJ": [
      "OKjAP7AAAAAJ"
    ],
    "GR_DsT0AAAAJ": [
      "OttawxUAAAAJ",
      "6T1XtW8AAAAJ",
      "yxUduqMAAAAJ",
      "wb-DKCIAAAAJ",
      "kGOgaowAAAAJ",
      "o42MH0MAAAAJ",
      "i38QlUwAAAAJ",
      "ZnT-QpMAAAAJ",
      "iOLC30YAAAAJ",
      "jEzWxQIAAAAJ",
      "YvHcBcEAAAAJ",
      "EkREu_QAAAAJ",
      "AEBWEm8AAAAJ",
      "ZQs5JAIAAAAJ",
      "XEx1fZkAAAAJ",
      "CvwLRSMAAAAJ",
      "1yB0eLMAAAAJ",
      "chICXXMAAAAJ",
      "nIWUhXAAAAAJ",
      "VZHxoh8AAAAJ",
      "MVxcjEoAAAAJ",
      "a_dbdxAAAAAJ",
      "ZybgAqkAAAAJ",
      "xuLKJboAAAAJ",
      "tQVe-fAAAAAJ",
      "bc_N2-oAAAAJ",
      "FY_UnPAAAAAJ",
      "RtNVud4AAAAJ",
      "QHZBakwAAAAJ",
      "9nnDvooAAAAJ",
      "RUP4S68AAAAJ",
      "owqhKD8AAAAJ",
      "K2WfIlsAAAAJ",
      "0mgEF28AAAAJ",
      "9OO7nhUAAAAJ",
      "narJyMAAAAAJ",
      "Q21P3fsAAAAJ",
      "PwQHMlwAAAAJ",
      "sUriZlUAAAAJ",
      "vGBcNVAAAAAJ",
      "4BHeGQMAAAAJ",
      "n8ZpnWMAAAAJ",
      "BnQdO2UAAAAJ",
      "cNSbfGQAAAAJ",
      "oPDVmsgAAAAJ",
      "BaCR90MAAAAJ",
      "ANPFix4AAAAJ",
      "hYi6i9sAAAAJ",
      "qjJg6akAAAAJ",
      "k7NgVSUAAAAJ",
      "GINhGvwAAAAJ",
      "zl70inwAAAAJ",
      "NQRw0bQAAAAJ",
      "TbUEDGIAAAAJ",
      "cyCp3pIAAAAJ",
      "wrozdTYAAAAJ",
      "qRnP-p0AAAAJ",
      "sCEl8r-n5VEC",
      "r-mWYj0AAAAJ",
      "HSx0BgQAAAAJ",
      "h1NXfKYAAAAJ",
      "5vVjpBsAAAAJ",
      "jH9i188AAAAJ",
      "ITZ1e7MAAAAJ",
      "RveRRXAAAAAJ",
      "c73wW0kAAAAJ",
      "ymzxRhAAAAAJ",
      "TNdMwp0AAAAJ",
      "Ar4h7jkAAAAJ",
      "5NiFWuwAAAAJ",
      "Wy89g4IAAAAJ",
      "un0eGzEAAAAJ",
      "vaSdahkAAAAJ",
      "qU9WvTgAAAAJ",
      "EJXN6tYAAAAJ",
      "7NpTttkAAAAJ",
      "L4bNmsMAAAAJ",
      "_THez4oAAAAJ",
      "BCxFU0EAAAAJ",
      "sPtFRB8AAAAJ",
      "CRWJFnwAAAAJ",
      "uGdPyZQAAAAJ",
      "lNkw3QYAAAAJ",
      "il-F8YYAAAAJ",
      "9HCmTcwAAAAJ",
      "sVR8ktkAAAAJ",
      "EfxwV6oAAAAJ",
      "f6JF7BkAAAAJ",
      "p1DZVX8AAAAJ",
      "l96zhjwAAAAJ",
      "MO7qaUIAAAAJ",
      "55TAOdgAAAAJ",
      "e6JywScAAAAJ",
      "F24vXggAAAAJ",
      "GlArL6AAAAAJ",
      "lGgLAiIAAAAJ",
      "i4_3daEAAAAJ",
      "xQqZt2AAAAAJ",
      "843JJtgAAAAJ",
      "LurWtuYAAAAJ",
      "FX6bV4UAAAAJ",
      "nUlanA8AAAAJ",
      "1YBLp6MAAAAJ",
      "nzS2jrMAAAAJ",
      "m45LD1kAAAAJ",
      "33yNvIgAAAAJ",
      "yDZct7UAAAAJ",
      "qEXxyDQAAAAJ",
      "Cs75s1MAAAAJ",
      "bM44mNEAAAAJ",
      "hKjmnDUAAAAJ",
      "ewQrF9cAAAAJ",
      "z-KILD8AAAAJ",
      "biJiXWoAAAAJ",
      "BP0WzIQAAAAJ",
      "SWQxcO8AAAAJ",
      "L8r9ox4AAAAJ",
      "tDWt_MQAAAAJ",
      "PsfzbCMAAAAJ",
      "orVoz4IAAAAJ",
      "jHEvHNYAAAAJ",
      "bKwkUO4AAAAJ",
      "HzlOQRkAAAAJ",
      "i0OY_LAAAAAJ",
      "df-THM0AAAAJ",
      "QIRWZf8AAAAJ",
      "0b7ZqlcAAAAJ",
      "E0A3lSIAAAAJ",
      "eARXJywAAAAJ",
      "O8d33mkAAAAJ",
      "WoB6M2cAAAAJ",
      "P_-O-wcAAAAJ",
      "Uhf4nBkAAAAJ",
      "fXy1pfcAAAAJ",
      "FaOcyfMAAAAJ",
      "6wGt7fYAAAAJ",
      "9LcxwsMAAAAJ",
      "HzxnwocAAAAJ",
      "g3t0ihoAAAAJ",
      "whi3UisAAAAJ",
      "gmSwszcAAAAJ",
      "WkRojboAAAAJ",
      "JSFmVQEAAAAJ",
      "iTv2cOgAAAAJ",
      "5m5ds6UAAAAJ",
      "JBV4oGQAAAAJ",
      "BzOqNoQAAAAJ",
      "W0H5bc0AAAAJ",
      "LnhCGNMAAAAJ",
      "JIUz890AAAAJ",
      "HjWpRCIAAAAJ",
      "LVk3xE4AAAAJ",
      "GMvmr8QAAAAJ",
      "ZBF2zKMAAAAJ",
      "DTthB48AAAAJ",
      "nX9D5AoAAAAJ",
      "gZgQLkgAAAAJ",
      "v7EjGHkAAAAJ",
      "SxUNhucAAAAJ",
      "LRsjX7kAAAAJ",
      "yDVn5LEAAAAJ",
      "iyDxq0EAAAAJ",
      "aO8KpGcAAAAJ",
      "dHjYcrgAAAAJ",
      "JS-_0nUAAAAJ",
      "PCDSl2sAAAAJ",
      "N2M9RPoAAAAJ",
      "ChwmtBkAAAAJ",
      "qd06pUgAAAAJ",
      "a-yq6EAAAAAJ",
      "nnLiId8AAAAJ",
      "B2U8EUwAAAAJ",
      "e1ucbCYAAAAJ",
      "Spe0xdkAAAAJ",
      "roFM8XsAAAAJ",
      "HpQGq54AAAAJ",
      "Om4Lag0AAAAJ",
      "47EBD1QAAAAJ",
      "V5gL_H0AAAAJ",
      "j0nK_CsAAAAJ",
      "p5uvh2oAAAAJ",
      "QMV3HxMAAAAJ"
    ],
    "7GSWYLQAAAAJ": [
      "8R35rCwAAAAJ",
      "UgHB5oAAAAAJ",
      "5tk1PV8AAAAJ",
      "L6TpGPMAAAAJ",
      "_kqpoHIAAAAJ",
      "beiWcokAAAAJ",
      "SnTMyGUAAAAJ",
      "-WZcuuwAAAAJ",
      "Sbpra_AAAAAJ",
      "tGAimhAAAAAJ",
      "H2qBVBIAAAAJ",
      "vjgsd5kAAAAJ"
    ],
    "SgST3LkAAAAJ": [
      "-hGZC54AAAAJ",
      "ijH0-a8AAAAJ",
      "d0npq2oAAAAJ",
      "q4qDvAoAAAAJ",
      "84WzBlYAAAAJ",
      "I66ZBYwAAAAJ",
      "SfKdzrUAAAAJ",
      "bjdB4K8AAAAJ",
      "BT4XTP4AAAAJ",
      "jGdqlOwAAAAJ",
      "2IXVwTMAAAAJ",
      "8R35rCwAAAAJ",
      "UjpbO6IAAAAJ",
      "jU4IZs4AAAAJ",
      "czyretsAAAAJ",
      "B96GkdgAAAAJ",
      "I0fbJ6cAAAAJ",
      "dCa-pW8AAAAJ",
      "TjdFs3EAAAAJ",
      "jJRiZR8AAAAJ"
    ],
    "K3QJPdMAAAAJ": [
      "ID9QePIAAAAJ",
      "eqQQkM4AAAAJ",
      "B96GkdgAAAAJ",
      "-xQ-C1sAAAAJ",
      "DwdjBUUAAAAJ",
      "0mgEF28AAAAJ",
      "LJiQRJIAAAAJ",
      "mu5Y2rYAAAAJ",
      "y1lVpBEAAAAJ"
    ],
    "ZaJEZpYAAAAJ": [
      "SlZavnIAAAAJ",
      "P-G3sjYAAAAJ",
      "KgZxzjsAAAAJ",
      "UgHB5oAAAAAJ",
      "gKUEEY4AAAAJ",
      "q9g_OlwAAAAJ",
      "4D1n8scAAAAJ",
      "9_QWXrsAAAAJ",
      "UXNLsZUAAAAJ"
    ],
    "on2DUKoAAAAJ": [
      "LicjjokAAAAJ",
      "23ZXZvEAAAAJ",
      "CulluAgAAAAJ",
      "VnvkluIAAAAJ",
      "NGI_y8IAAAAJ",
      "Zb0am48AAAAJ",
      "xHC1VkoAAAAJ",
      "_kOUMXoAAAAJ",
      "ep52oxEAAAAJ",
      "WQkBYwQAAAAJ"
    ],
    "GdOmgYwAAAAJ": [
      "XqLiBQMAAAAJ",
      "bZ9oyW8AAAAJ",
      "5WT38A0AAAAJ",
      "hYlbtl8AAAAJ",
      "v6HphBcAAAAJ",
      "Z8I-ydAAAAAJ",
      "KgZxzjsAAAAJ",
      "8GDPQboAAAAJ",
      "baF3HKUAAAAJ",
      "JfblW3MAAAAJ"
    ],
    "FLJ86DwAAAAJ": [
      "Qhe5ua0AAAAJ",
      "AIy7QHIAAAAJ",
      "MDeIveMAAAAJ",
      "vcGuNDYAAAAJ",
      "DRA4zoUAAAAJ",
      "J7vQ-QEAAAAJ",
      "NAntFXIAAAAJ",
      "d7IuSpAAAAAJ",
      "aO8KpGcAAAAJ",
      "DbrKNSQAAAAJ",
      "mZMaDgEAAAAJ",
      "VrswntoAAAAJ",
      "PVxHYr4AAAAJ",
      "GXhpY9wAAAAJ",
      "68y3nvYAAAAJ",
      "rUmKr3AAAAAJ",
      "VhnTrugAAAAJ",
      "9SakklgAAAAJ",
      "Gqp2GqkAAAAJ"
    ],
    "jIs-Y2gAAAAJ": [
      "sPlonWcAAAAJ",
      "1dPriv4AAAAJ",
      "EYo_WkEAAAAJ",
      "5sL0xZ4AAAAJ",
      "ZocLOAMAAAAJ",
      "Y8ep3h8AAAAJ",
      "_DNzXTcAAAAJ",
      "UTmj6K4AAAAJ",
      "VjNg25EAAAAJ",
      "QehMdGIAAAAJ",
      "QWK6YXUAAAAJ",
      "i28fU0MAAAAJ",
      "bwORIKIAAAAJ",
      "uh7PNBoAAAAJ",
      "ohTFQMMAAAAJ",
      "FvP33fEAAAAJ",
      "rynvwScAAAAJ",
      "TaR3dq4AAAAJ",
      "0kTel90AAAAJ",
      "TjWwqmwAAAAJ",
      "YP9KtBQAAAAJ",
      "ExJ1IooAAAAJ"
    ],
    "rTw-pq0AAAAJ": [
      "bh-uRFMAAAAJ",
      "3kDtybgAAAAJ",
      "9xDADY4AAAAJ",
      "aWiMKLsAAAAJ",
      "dnZ8udEAAAAJ",
      "GHpxNQIAAAAJ",
      "bSU7LYoAAAAJ",
      "W8VIEZgAAAAJ",
      "Y2GtJkAAAAAJ",
      "fb6FOfsAAAAJ",
      "VeTSl0wAAAAJ",
      "E8DVVYQAAAAJ",
      "4LWx24UAAAAJ",
      "rqmw-qQAAAAJ",
      "74zyaaYAAAAJ",
      "Tpt57v0AAAAJ",
      "a8Y2OJMAAAAJ",
      "UxuqG1EAAAAJ",
      "xOrRvKAAAAAJ",
      "sJDqACEAAAAJ",
      "8Xt3TnAAAAAJ",
      "QiJPlOIAAAAJ",
      "DhtAFkwAAAAJ",
      "7OTD-LEAAAAJ",
      "h8u3ll8AAAAJ",
      "n-SnMhoAAAAJ",
      "c8IpF9gAAAAJ",
      "mqpjAt4AAAAJ",
      "pvyI8GkAAAAJ",
      "jQl9RtkAAAAJ",
      "Q0piorUAAAAJ",
      "bh08FeIAAAAJ",
      "jyaTX64AAAAJ",
      "O1DeDyEAAAAJ",
      "Q8iay0gAAAAJ",
      "t9HPFawAAAAJ",
      "E6vCXjkAAAAJ",
      "APgaFK0AAAAJ",
      "mN6_BKAAAAAJ",
      "z76PBfYAAAAJ",
      "kh8Qe6YAAAAJ",
      "-VgS8AIAAAAJ",
      "76B8lrgAAAAJ",
      "8gfs8XIAAAAJ",
      "AEsPCAUAAAAJ",
      "jjEht8wAAAAJ",
      "hon4EsIAAAAJ",
      "GADXPDcAAAAJ",
      "TmWYBeEAAAAJ",
      "duIUwpwAAAAJ",
      "Vkzd7MIAAAAJ"
    ],
    "dq3yXjkAAAAJ": [
      "fn13u8IAAAAJ",
      "TW7U1W0AAAAJ",
      "a_dbdxAAAAAJ",
      "V2Y1L4sAAAAJ",
      "JBU4ivcAAAAJ",
      "7GK8LQMAAAAJ"
    ],
    "2DBmo-wAAAAJ": [
      "8R35rCwAAAAJ",
      "l-la0GQAAAAJ",
      "UJcm1MoAAAAJ",
      "jrfFYAIAAAAJ",
      "Izhkp4YAAAAJ",
      "yy0UFOwAAAAJ",
      "ADkiClQAAAAJ",
      "DMTuJzAAAAAJ",
      "LIJQ_ZYAAAAJ",
      "eDQsOFMAAAAJ",
      "n-q-55wAAAAJ",
      "vfPE6hgAAAAJ",
      "OI7zFmwAAAAJ",
      "T7uctwYAAAAJ",
      "_ws9LLgAAAAJ",
      "tWoesqcAAAAJ",
      "5ErX8dMAAAAJ",
      "OXtG-isAAAAJ",
      "wtRVnsYAAAAJ",
      "SzHPa90AAAAJ",
      "Q0YEc-QAAAAJ",
      "J8OgouwAAAAJ",
      "fhaNx_oAAAAJ",
      "8C2_ZVsAAAAJ",
      "ZGpE5cYAAAAJ",
      "Z3dxz9IAAAAJ",
      "vcw0TJIAAAAJ",
      "q7nFtUcAAAAJ",
      "JQcDmB8AAAAJ",
      "e1zesfMAAAAJ",
      "2QfPE54AAAAJ"
    ],
    "lsbreWwAAAAJ": [],
    "fpVf9QkAAAAJ": [],
    "LjsKfKYAAAAJ": [],
    "wLf0Vw0AAAAJ": [
      "pihC5CkAAAAJ",
      "p8ArrV4AAAAJ",
      "8m8taGEAAAAJ",
      "Z-UlU3MAAAAJ",
      "lE68S9wAAAAJ",
      "6WiWvr0AAAAJ",
      "Q10gid0AAAAJ",
      "tGNxOpEAAAAJ",
      "oAlCitYAAAAJ",
      "ABSaf6IAAAAJ",
      "XPiir70AAAAJ"
    ],
    "df-THM0AAAAJ": [
      "aO8KpGcAAAAJ",
      "iyDxq0EAAAAJ",
      "Op-47sgAAAAJ",
      "VZHxoh8AAAAJ",
      "ri1sE34AAAAJ",
      "lMkTx0EAAAAJ",
      "DcV-5RAAAAAJ",
      "yDVn5LEAAAAJ",
      "OttawxUAAAAJ",
      "siuZCjUAAAAJ",
      "LjsKfKYAAAAJ",
      "Bk5q_pAAAAAJ"
    ],
    "XM97iScAAAAJ": [
      "H7vcwSAAAAAJ",
      "qr8Vo9IAAAAJ",
      "gb8sbdcAAAAJ",
      "rynvwScAAAAJ",
      "_8SObXwAAAAJ",
      "P4nfoKYAAAAJ",
      "jIKjjSYAAAAJ",
      "_bs7PqgAAAAJ",
      "y-khfzIAAAAJ",
      "kM95eWgAAAAJ",
      "l7nsfT4AAAAJ",
      "NB4pgZYAAAAJ",
      "iDP84cQAAAAJ",
      "Pa8qzYQAAAAJ",
      "9v86038AAAAJ",
      "VxpypngAAAAJ",
      "ijpYJQwAAAAJ",
      "B0K-DwEAAAAJ",
      "_r4LsycAAAAJ",
      "eZQNcvcAAAAJ",
      "MVanlR8AAAAJ",
      "Q_4d9N0AAAAJ",
      "p9-ohHsAAAAJ",
      "aOsuqRkAAAAJ",
      "7ip1Ih8AAAAJ",
      "UA3tyKwAAAAJ",
      "8kA3eDwAAAAJ",
      "SrHIXjEAAAAJ",
      "8j3t5HsAAAAJ",
      "8vMAKiwAAAAJ",
      "gdD2E9QAAAAJ",
      "ThV9ezEAAAAJ",
      "bh-uRFMAAAAJ",
      "rhZm_NAAAAAJ",
      "K-dWyGEAAAAJ",
      "nXBQn7gAAAAJ",
      "IaDc0OcAAAAJ",
      "Cr3WSpIAAAAJ",
      "d53muYsAAAAJ",
      "v-A_7UsAAAAJ",
      "elEQEEEAAAAJ",
      "cxEoVL4AAAAJ",
      "XjltJv8AAAAJ",
      "4DUcuysAAAAJ",
      "CZiTv0gAAAAJ",
      "Mg-vyosAAAAJ",
      "NKtRqvYAAAAJ",
      "QWK6YXUAAAAJ",
      "8E442bkAAAAJ",
      "50baXGgAAAAJ",
      "hyWg3nEAAAAJ",
      "Py54GcEAAAAJ",
      "rZ0mlMYAAAAJ",
      "fu_wsGUAAAAJ",
      "4D2vsdYAAAAJ",
      "AxzVaI8AAAAJ",
      "UD7d2NEAAAAJ",
      "Q6F3O0sAAAAJ",
      "3_u1jHQAAAAJ",
      "vjZrDKQAAAAJ",
      "Lt945BwAAAAJ",
      "a_M5FlgAAAAJ",
      "XVUCn40AAAAJ",
      "rA48PN4AAAAJ",
      "vswo4rQAAAAJ",
      "mqpjAt4AAAAJ",
      "vKAKE1gAAAAJ",
      "lEQ3oDAAAAAJ",
      "bmZbi_UNs-oC",
      "Xy8kb5gAAAAJ",
      "qCrypnoAAAAJ",
      "Vz-lz3cAAAAJ",
      "PI30hN8AAAAJ",
      "rmCtisEAAAAJ",
      "MA8rI0MAAAAJ",
      "kXB8FBoAAAAJ",
      "e-GEqxoAAAAJ",
      "6Q6TCkkAAAAJ",
      "kXkHRK4AAAAJ",
      "niCbywQAAAAJ",
      "ixBXGEYAAAAJ",
      "ZKDLDQoAAAAJ",
      "kQisE-gAAAAJ",
      "jfy2IG0AAAAJ",
      "E3NRabsAAAAJ",
      "YHmzvmMAAAAJ",
      "GYksTEEAAAAJ",
      "LAuxzv0AAAAJ",
      "2rzyuRQAAAAJ",
      "b8cNEHwAAAAJ",
      "-wpZQY0AAAAJ",
      "Qk_ziKsAAAAJ",
      "YULFeN0AAAAJ",
      "-q90a0EAAAAJ",
      "0ZXfitAAAAAJ",
      "hzOgd9MAAAAJ",
      "ZxXBaswAAAAJ",
      "7oxkHYYAAAAJ",
      "xAFGASEAAAAJ",
      "IGnKP2AAAAAJ",
      "YOb3xH4AAAAJ",
      "G0LfNJcAAAAJ",
      "EKAynJgAAAAJ",
      "jo5w-KMAAAAJ",
      "_y-8nrcAAAAJ",
      "TkVHKDgAAAAJ",
      "xARSfT4AAAAJ",
      "XAveESgAAAAJ",
      "zc6Iy0IAAAAJ",
      "sdSjnhwAAAAJ",
      "rqUJfaUAAAAJ",
      "mHwonDEAAAAJ",
      "n4pWU_0AAAAJ",
      "snDpfA0AAAAJ",
      "y5fsjDAAAAAJ",
      "h3XP9JkAAAAJ",
      "kzoVUPYAAAAJ",
      "aj84iHAAAAAJ",
      "SvuSifMAAAAJ",
      "vsAumE0AAAAJ",
      "556SqtcAAAAJ",
      "wOYUPpwAAAAJ",
      "OGdXlpcAAAAJ",
      "U7svaOMAAAAJ",
      "TT-8JRsAAAAJ",
      "VzkoqhIAAAAJ",
      "J1tqbNAAAAAJ",
      "YYH0BjEAAAAJ",
      "U_NEZHQAAAAJ",
      "mINzfREAAAAJ",
      "5waf3bkAAAAJ",
      "wR5YWC0AAAAJ",
      "gGh0i8AAAAAJ",
      "dRc-rTAAAAAJ",
      "t6exkOAAAAAJ"
    ],
    "i38QlUwAAAAJ": [
      "9OO7nhUAAAAJ",
      "RUP4S68AAAAJ",
      "pouyVyUAAAAJ",
      "MVxcjEoAAAAJ",
      "_RVvnS4AAAAJ",
      "GR_DsT0AAAAJ",
      "UwLsYw8AAAAJ",
      "EBNa5IEAAAAJ",
      "tP5IBFkAAAAJ",
      "NWPDSEsAAAAJ",
      "aHtfItQAAAAJ",
      "2StUgf4AAAAJ",
      "SWQxcO8AAAAJ",
      "Ch9iRwQAAAAJ",
      "5vVjpBsAAAAJ",
      "4a6iPeUAAAAJ",
      "4Zw1PJ8AAAAJ",
      "Bm3pH5AAAAAJ",
      "r1Fn_YsAAAAJ",
      "FQHeASwAAAAJ",
      "BUc2uq0AAAAJ",
      "NFWFaGAAAAAJ",
      "XalUZEoAAAAJ",
      "ogXTOZ4AAAAJ",
      "LnhCGNMAAAAJ",
      "dXzqCT4AAAAJ",
      "CM4o-cgAAAAJ",
      "d4W1UT0AAAAJ",
      "IMkVH_8AAAAJ",
      "XSforroAAAAJ",
      "Y4sk3aMAAAAJ",
      "ZjuMpLoAAAAJ",
      "t9HPFawAAAAJ",
      "8R35rCwAAAAJ",
      "ocPXoIkAAAAJ",
      "5VaXUQsAAAAJ",
      "Sx-673sAAAAJ",
      "tqxTaiAAAAAJ",
      "adnTgaAAAAAJ",
      "VBclY_cAAAAJ",
      "sEMrGicAAAAJ",
      "PCUwf-8AAAAJ",
      "3pu8FE0AAAAJ",
      "oTmQCFUAAAAJ",
      "dnZ8udEAAAAJ",
      "6Wg-hF4AAAAJ",
      "vfPE6hgAAAAJ",
      "Ixg9n-EAAAAJ",
      "23ZXZvEAAAAJ",
      "cZneVpUAAAAJ",
      "lc6CVqEAAAAJ",
      "wVazIm8AAAAJ",
      "wA5TK_0AAAAJ",
      "XEx1fZkAAAAJ",
      "6GpZV0YAAAAJ",
      "MDCu0WEAAAAJ",
      "25Ha82sAAAAJ",
      "wb-DKCIAAAAJ",
      "bh-uRFMAAAAJ",
      "0mgEF28AAAAJ",
      "5ygiTwsAAAAJ",
      "vfT6-XIAAAAJ",
      "umFQktIAAAAJ",
      "6rQZU7MAAAAJ",
      "xaQuPloAAAAJ",
      "bMoauM4AAAAJ",
      "a_dbdxAAAAAJ",
      "ErDOPbEAAAAJ",
      "3OQplr0AAAAJ",
      "Td0j6cUAAAAJ",
      "BCxFU0EAAAAJ",
      "sPtFRB8AAAAJ",
      "OttawxUAAAAJ",
      "kMmxbbIAAAAJ",
      "5elBSHQAAAAJ",
      "QMkbFp8AAAAJ",
      "-hW6cvgAAAAJ",
      "v474hP4AAAAJ",
      "7zp9arUAAAAJ",
      "0RvAVR4AAAAJ",
      "CvwLRSMAAAAJ",
      "ScLUQ-YAAAAJ",
      "zithBbUAAAAJ",
      "Tlc4yaMAAAAJ",
      "YvHcBcEAAAAJ",
      "ThJ-Ju4AAAAJ",
      "KiQW8wMAAAAJ",
      "F24vXggAAAAJ",
      "miPgny8AAAAJ",
      "gIH9P-8AAAAJ",
      "hR9rFHgAAAAJ",
      "owqhKD8AAAAJ",
      "M1aIpoIAAAAJ",
      "2sFj-kcAAAAJ",
      "hGO6cWYAAAAJ",
      "kQ0HeQIAAAAJ",
      "_N44XxAAAAAJ",
      "vNcBx1sAAAAJ",
      "GaYmpIgAAAAJ",
      "2Dab2vkAAAAJ",
      "hyle4iEAAAAJ",
      "g9d_K0sAAAAJ",
      "9XrWuI8AAAAJ",
      "zBUwaGkAAAAJ",
      "-gJkPHIAAAAJ",
      "km6CP8cAAAAJ",
      "aH8AJu4AAAAJ",
      "Ek8r82kAAAAJ",
      "BWF8wn4AAAAJ",
      "kUe1sZEAAAAJ",
      "ct2hw4UAAAAJ",
      "6RWbQjMAAAAJ",
      "QzqctJgAAAAJ",
      "SFbKPCEAAAAJ",
      "29B3BAgAAAAJ",
      "BaCR90MAAAAJ",
      "05sMX8MAAAAJ",
      "bvDRaVcAAAAJ",
      "KMcwQtcAAAAJ",
      "lXCP2cMAAAAJ",
      "f0j0K8QAAAAJ",
      "quJME0oAAAAJ",
      "zK4uegoAAAAJ",
      "qjJg6akAAAAJ",
      "j4Fshz0AAAAJ",
      "Atc5w-4AAAAJ",
      "SfwUC14AAAAJ",
      "WKpSlhQAAAAJ",
      "ZZWygh8AAAAJ",
      "WoB6M2cAAAAJ",
      "dHjYcrgAAAAJ",
      "6dP660cAAAAJ",
      "gTWUZlsAAAAJ",
      "70lgwYwAAAAJ",
      "fpUICd0AAAAJ",
      "w8XocYQAAAAJ",
      "VPyxd6kAAAAJ",
      "LiH53A8AAAAJ",
      "e1ucbCYAAAAJ",
      "yDZct7UAAAAJ",
      "L4bNmsMAAAAJ",
      "Spe0xdkAAAAJ",
      "GINhGvwAAAAJ",
      "AfLwLQ0AAAAJ",
      "W5WbqgoAAAAJ",
      "h3Nsz6YAAAAJ",
      "vaSdahkAAAAJ",
      "7NpTttkAAAAJ",
      "ss7CIgcAAAAJ"
    ],
    "umivlPQAAAAJ": [
      "DTthB48AAAAJ",
      "33yNvIgAAAAJ",
      "wb-DKCIAAAAJ",
      "EJXN6tYAAAAJ",
      "-nzJN7oAAAAJ",
      "M3yUD0cAAAAJ",
      "kMmxbbIAAAAJ",
      "Glo43TUAAAAJ",
      "Nmty1bkAAAAJ",
      "rUiWchkAAAAJ",
      "2lvIrNAAAAAJ",
      "qvK1_5wAAAAJ",
      "BXJ3LwEAAAAJ",
      "HSx0BgQAAAAJ",
      "QJu--ysAAAAJ",
      "uglffdcAAAAJ",
      "VoyeryMAAAAJ",
      "wHAYz5wAAAAJ",
      "4QIV0FUAAAAJ",
      "g3McheUAAAAJ",
      "LurWtuYAAAAJ",
      "iojF4S0AAAAJ",
      "rTJTJJ4AAAAJ",
      "Ks3QdEUAAAAJ",
      "luSyn1AAAAAJ",
      "rM0Orl0AAAAJ",
      "Spe0xdkAAAAJ",
      "jVrqxkYAAAAJ",
      "n8ZpnWMAAAAJ",
      "xdxuN98AAAAJ",
      "Go5BcawAAAAJ",
      "k7NgVSUAAAAJ"
    ],
    "3yQFuR4AAAAJ": [],
    "6uIhh6MAAAAJ": [
      "8R35rCwAAAAJ",
      "SIayDoQAAAAJ",
      "xUGZX_MAAAAJ",
      "fA0rYxMAAAAJ",
      "2StUgf4AAAAJ",
      "yv3sH74AAAAJ",
      "aqgFQqMAAAAJ",
      "8erqrHcAAAAJ",
      "PKcjcT4AAAAJ",
      "1YBLp6MAAAAJ",
      "B96GkdgAAAAJ",
      "WIvjYUIAAAAJ",
      "S47ydIgAAAAJ",
      "qjnBu0sAAAAJ",
      "Ek4hM10AAAAJ",
      "Eclg4mwAAAAJ",
      "hE2mTp4AAAAJ",
      "xmUDkvQAAAAJ",
      "tfN6V84AAAAJ",
      "SGjYdrEAAAAJ",
      "E9ITYW0AAAAJ",
      "mXtH1UYAAAAJ",
      "jERkdhIAAAAJ",
      "8fztli4AAAAJ",
      "s4mZnz8AAAAJ",
      "fftO_HsAAAAJ",
      "Cz-Q_IsAAAAJ",
      "hX0YYUoAAAAJ",
      "dnjq-FgAAAAJ",
      "ybjd-fgAAAAJ",
      "gCbeGRIAAAAJ",
      "u8K7nOwAAAAJ",
      "lJbBWhMAAAAJ",
      "T9To2C0AAAAJ",
      "xBH73TYAAAAJ",
      "aPqcyU4AAAAJ",
      "-gJkPHIAAAAJ",
      "uQRY6KoAAAAJ",
      "RK72t68AAAAJ",
      "os-DVLkAAAAJ",
      "tlhfhLoAAAAJ",
      "aH8AJu4AAAAJ",
      "xPWCLvEAAAAJ",
      "T04c3fwAAAAJ",
      "FR8zF_4AAAAJ",
      "BC8TixYAAAAJ",
      "5Qp_0TUAAAAJ",
      "OI7zFmwAAAAJ",
      "nZsD8XwAAAAJ",
      "xBv-PMEAAAAJ",
      "wUUxGfAAAAAJ",
      "2u8jlxgAAAAJ",
      "AYPlwA0AAAAJ",
      "UQBRs7EAAAAJ",
      "4MkmgXEAAAAJ",
      "MbBntPgAAAAJ",
      "dthSEsoAAAAJ",
      "Cvn7Y5YAAAAJ",
      "5TZ7f5wAAAAJ",
      "BIwrJuQAAAAJ",
      "RhOpyXcAAAAJ",
      "ey9AQcEAAAAJ",
      "b15vJuEAAAAJ",
      "U9WUBC4AAAAJ",
      "o9aFV8cAAAAJ",
      "YJxFe1UAAAAJ",
      "feURmn4AAAAJ",
      "DSfv69oAAAAJ",
      "e9gUdKwAAAAJ",
      "wyjZbeMAAAAJ",
      "w4UK_9kAAAAJ",
      "Nuw1Y4oAAAAJ",
      "BzyVxVUAAAAJ",
      "8rU1AaQAAAAJ",
      "lWmGADwAAAAJ",
      "P5AJTXcAAAAJ",
      "-XCiamcAAAAJ",
      "ykWqS0YAAAAJ",
      "BDmtLHsAAAAJ",
      "JAmTk5gAAAAJ",
      "z8GwuTgAAAAJ"
    ],
    "zkvW8FQAAAAJ": [
      "zghjmDgAAAAJ",
      "VX7d5EQAAAAJ",
      "AdAd4QIAAAAJ",
      "SQ1eGN4AAAAJ",
      "_1hCq3UAAAAJ",
      "fcqBMQgAAAAJ",
      "WEQF9DgAAAAJ",
      "7o4wtKEAAAAJ",
      "h6jljQQAAAAJ",
      "AH5j40kAAAAJ",
      "di_T0vwAAAAJ",
      "HhValEMAAAAJ",
      "CBUpEcQAAAAJ",
      "xdTtK9IAAAAJ",
      "5tk1PV8AAAAJ",
      "x34kIOIAAAAJ",
      "Znp3UkEAAAAJ",
      "jn-B_MoAAAAJ",
      "jM23vRsKxuIC",
      "YAHWbtkAAAAJ",
      "DaDmjMMAAAAJ",
      "teS9lHAAAAAJ",
      "O_7MVDIAAAAJ",
      "uNsqlqYAAAAJ",
      "EPQuuHMAAAAJ",
      "ZKeyKNgAAAAJ",
      "dUPre_sAAAAJ",
      "Ar4h7jkAAAAJ",
      "01II9NsAAAAJ",
      "rD8a4hQAAAAJ",
      "rXYLXJMAAAAJ",
      "gadgSR4AAAAJ",
      "8sKIuAcAAAAJ",
      "FxyRWlcAAAAJ",
      "Y_Ieu7EAAAAJ",
      "OvAOTFkAAAAJ",
      "BexX9vYAAAAJ",
      "r8NO774AAAAJ",
      "7-TwsxsAAAAJ",
      "VhrBelcAAAAJ",
      "tEk4qo8AAAAJ",
      "Li0F9VAAAAAJ",
      "8O8MQEUAAAAJ",
      "rDQK5tkAAAAJ",
      "pIwcxfoAAAAJ",
      "MhQPCk8AAAAJ",
      "WJGqLh8AAAAJ",
      "Ew_nVXEAAAAJ",
      "JUn8PgwAAAAJ",
      "1sC6u3UAAAAJ"
    ],
    "jikMhF4AAAAJ": [
      "RCi98EAAAAAJ",
      "sPlonWcAAAAJ",
      "B1Dy3WMAAAAJ",
      "aO-849gAAAAJ",
      "910z20QAAAAJ",
      "PSh16LsAAAAJ",
      "23uzLe0AAAAJ",
      "6UYFl7cAAAAJ",
      "bruYeAQAAAAJ",
      "4O4oaD0AAAAJ",
      "tal4mMkAAAAJ",
      "dgBh0UMAAAAJ",
      "8JeQMMUAAAAJ",
      "ppZN58sAAAAJ",
      "8fztli4AAAAJ",
      "WOsQx6EAAAAJ",
      "-rs_IzoAAAAJ",
      "IoGj8UEAAAAJ",
      "S1jUhokAAAAJ",
      "-VtT7q4AAAAJ",
      "BaaPAVYAAAAJ",
      "OfUOpAQAAAAJ",
      "55G7VxoAAAAJ",
      "aQeTAr4AAAAJ"
    ],
    "VjsNXysAAAAJ": [
      "X08l_4IAAAAJ",
      "ugFNit4AAAAJ",
      "aVg7BRwAAAAJ",
      "xOWBOKQAAAAJ",
      "8fztli4AAAAJ",
      "vtwH6GkAAAAJ",
      "F9kSTM0AAAAJ",
      "-XEZA0UAAAAJ",
      "CCP2s2cAAAAJ",
      "kFyna0YAAAAJ",
      "tiNiOI4AAAAJ",
      "MaSXNhUAAAAJ",
      "NmJcIeEAAAAJ",
      "2-e0jiEAAAAJ",
      "1NyT9gQAAAAJ",
      "lsbreWwAAAAJ",
      "vh0_vJ4AAAAJ",
      "nSgKwcMAAAAJ",
      "MkztWIoAAAAJ",
      "Tsh90D8AAAAJ",
      "iOLC30YAAAAJ",
      "bh-uRFMAAAAJ",
      "4V1nNm4AAAAJ",
      "CIXmtCQAAAAJ",
      "h3qMa1kAAAAJ",
      "2fWmq-4AAAAJ",
      "fIoDWp8AAAAJ",
      "KilQqKYAAAAJ",
      "ZlSVieAAAAAJ",
      "tk3X1QkAAAAJ",
      "mqpjAt4AAAAJ",
      "rqUJfaUAAAAJ",
      "itSa94cAAAAJ",
      "KqtBi6MAAAAJ",
      "IoGj8UEAAAAJ",
      "iJuDBhEAAAAJ",
      "YdLELsMAAAAJ",
      "nzz6PQMAAAAJ",
      "XDXw3jQAAAAJ",
      "Ga4j7UIAAAAJ",
      "UzTo6o4AAAAJ",
      "SfJ_pOYAAAAJ",
      "t4rXchwAAAAJ",
      "X6t18NkAAAAJ",
      "8-p9CLsAAAAJ",
      "EMDboA4AAAAJ",
      "zPPcv9sAAAAJ",
      "Nd6tX_kAAAAJ",
      "-A_CtWMAAAAJ",
      "0n-reRcAAAAJ",
      "zc6Iy0IAAAAJ",
      "Zjshth4AAAAJ",
      "w3B9Qs8AAAAJ",
      "-ad5RSQAAAAJ",
      "gq138e4AAAAJ",
      "h-GyeogAAAAJ",
      "VR8nzcUAAAAJ",
      "YYT8-7kAAAAJ",
      "MDIyLnwAAAAJ"
    ],
    "-XCiamcAAAAJ": [],
    "yDVn5LEAAAAJ": [
      "aO8KpGcAAAAJ",
      "iyDxq0EAAAAJ",
      "2oy3OXYAAAAJ",
      "0mgEF28AAAAJ",
      "df-THM0AAAAJ",
      "Op-47sgAAAAJ",
      "yxUduqMAAAAJ",
      "chICXXMAAAAJ",
      "mAo_lUwAAAAJ",
      "sRpY9TIAAAAJ",
      "t8v3JXsAAAAJ",
      "BgQkdsYAAAAJ",
      "DwKuTLwAAAAJ",
      "mWS1pY4AAAAJ",
      "OtgZrhUAAAAJ",
      "kMmxbbIAAAAJ",
      "-j0q9B4AAAAJ",
      "DcV-5RAAAAAJ",
      "87nZphcAAAAJ",
      "FDpwmgQAAAAJ",
      "GR_DsT0AAAAJ",
      "-CqyjXEAAAAJ",
      "Jwnl3v0AAAAJ",
      "mXtH1UYAAAAJ",
      "MhDyxdYAAAAJ",
      "n8ZpnWMAAAAJ",
      "uErE2UUAAAAJ",
      "6ndk_nAAAAAJ",
      "bRWa8q8AAAAJ",
      "xwbHbUQAAAAJ",
      "N7_xhHoAAAAJ",
      "NvKHgzkAAAAJ",
      "teiNc0sAAAAJ",
      "a8yv0nEAAAAJ",
      "QwKHApEAAAAJ",
      "rJjcA_YAAAAJ",
      "P1jPSzMAAAAJ",
      "nCFeUqYAAAAJ"
    ],
    "d5y4iKAAAAAJ": [
      "8R35rCwAAAAJ",
      "xvOlfw8AAAAJ",
      "pqP5_PgAAAAJ",
      "LIJQ_ZYAAAAJ",
      "xUGZX_MAAAAJ",
      "ZaJEZpYAAAAJ",
      "-w5DuHgAAAAJ",
      "DRnOvU8AAAAJ",
      "PTS2AOgAAAAJ",
      "vfPE6hgAAAAJ",
      "I1mOQpAAAAAJ",
      "1wLVDP4AAAAJ",
      "neGbgzYAAAAJ",
      "T6PbwPIAAAAJ",
      "SmGQ48gAAAAJ",
      "tWoesqcAAAAJ",
      "tfN6V84AAAAJ",
      "BOAOkNQAAAAJ",
      "36qnUD4AAAAJ",
      "K29Sv1EAAAAJ",
      "U_Jw8DUAAAAJ",
      "SRM4v2cAAAAJ",
      "Ivot3fkAAAAJ",
      "r9TQ2n4AAAAJ",
      "S9LHLKEAAAAJ",
      "ibu3FwsAAAAJ",
      "bsyOi1YAAAAJ",
      "mgMzkYMAAAAJ",
      "aOklxsQAAAAJ",
      "lS96SqoAAAAJ",
      "wxnzyjwAAAAJ"
    ],
    "VZHxoh8AAAAJ": [
      "orVoz4IAAAAJ",
      "Nh832fgAAAAJ",
      "CvwLRSMAAAAJ",
      "Bl4SRU0AAAAJ",
      "lPh8l7QAAAAJ",
      "OUXS8doAAAAJ",
      "hJgT4tYAAAAJ",
      "Bk5q_pAAAAAJ",
      "Jkss014AAAAJ",
      "OttawxUAAAAJ",
      "XboZC1AAAAAJ",
      "4Z6vo5QAAAAJ",
      "fbVyT0QAAAAJ",
      "CHMpZBIAAAAJ",
      "c3PYmxUAAAAJ",
      "GR_DsT0AAAAJ",
      "tbxCHJgAAAAJ",
      "1yB0eLMAAAAJ",
      "MeS5d4gAAAAJ",
      "jTdkr10AAAAJ",
      "17_nX_kAAAAJ",
      "y0lN_XsAAAAJ",
      "GINhGvwAAAAJ",
      "8zyiGRoAAAAJ",
      "GkYIrlIAAAAJ",
      "SQqkcdgAAAAJ",
      "HpQGq54AAAAJ",
      "rSVIHasAAAAJ",
      "Bw-WdyUAAAAJ"
    ],
    "C-ZlBWMAAAAJ": [
      "8R35rCwAAAAJ",
      "xaQuPloAAAAJ",
      "-gJkPHIAAAAJ",
      "BFlpS-8AAAAJ",
      "B8wslVsAAAAJ",
      "Lncr-VoAAAAJ",
      "TIKl_foAAAAJ",
      "7c1B_fIAAAAJ",
      "Bo-wyrkAAAAJ",
      "zBUwaGkAAAAJ",
      "PTS2AOgAAAAJ",
      "fmSHtE8AAAAJ",
      "Rqy5KDEAAAAJ",
      "RK72t68AAAAJ",
      "GyoKzFwAAAAJ",
      "jW80JWEAAAAJ",
      "jWz4LrAAAAAJ",
      "JWmiQR0AAAAJ",
      "Vs-MdPcAAAAJ",
      "u-OHPhAAAAAJ",
      "F3YBJxUAAAAJ"
    ],
    "qRAQ5BsAAAAJ": [
      "pouyVyUAAAAJ",
      "axsP38wAAAAJ",
      "PksdgoUAAAAJ"
    ],
    "LeshmV8AAAAJ": [
      "nfX25MMAAAAJ",
      "yxUduqMAAAAJ",
      "L_m67ywAAAAJ",
      "nRQi4O8AAAAJ",
      "-lKb3XwAAAAJ",
      "qFtP1MQAAAAJ",
      "ZpG_cJwAAAAJ",
      "aOklxsQAAAAJ",
      "P2VyO-YAAAAJ",
      "ixGMcjsAAAAJ",
      "tQVe-fAAAAAJ",
      "Z-2pv_wAAAAJ",
      "ogtsTE4AAAAJ",
      "YdS6szoAAAAJ",
      "jhPhgf4AAAAJ",
      "gFLW9qcAAAAJ",
      "LYRkQhMAAAAJ",
      "oo8QRmIAAAAJ",
      "k5HsbdcAAAAJ",
      "XYpPTpQAAAAJ",
      "xC13Kb4AAAAJ",
      "Njlo7WAAAAAJ",
      "1KaPl5wAAAAJ",
      "U9EvD0wAAAAJ",
      "cQ1P1qoAAAAJ",
      "iyDxq0EAAAAJ",
      "bZ9oyW8AAAAJ",
      "w3KgvQIAAAAJ",
      "ROILf3EAAAAJ",
      "qq4zSmQAAAAJ",
      "PjQhSkgAAAAJ",
      "CPye2b4AAAAJ",
      "C6pnolkAAAAJ",
      "dXztgDYAAAAJ",
      "ktqbPscAAAAJ",
      "XcD1ffwAAAAJ",
      "xIpN5lQAAAAJ",
      "gSLAdnEAAAAJ",
      "j7Z1Zm8AAAAJ",
      "UqtDdZUAAAAJ",
      "jEzWxQIAAAAJ",
      "dN7AziAAAAAJ",
      "MhDyxdYAAAAJ"
    ],
    "3kDtybgAAAAJ": [
      "bh-uRFMAAAAJ",
      "z76PBfYAAAAJ",
      "9xDADY4AAAAJ",
      "GHpxNQIAAAAJ",
      "TmWYBeEAAAAJ",
      "pvyI8GkAAAAJ",
      "ijpYJQwAAAAJ",
      "rTw-pq0AAAAJ",
      "iRBUTOAAAAAJ",
      "bSU7LYoAAAAJ",
      "UfbuDH8AAAAJ",
      "_bs7PqgAAAAJ",
      "QJZQgN8AAAAJ",
      "aWiMKLsAAAAJ",
      "p9RsPG4AAAAJ",
      "Q8iay0gAAAAJ",
      "dnZ8udEAAAAJ",
      "_kJ-zUYAAAAJ",
      "LNc2cxUAAAAJ",
      "6rl-XhwAAAAJ",
      "FO8vjQMAAAAJ",
      "NbXF7T8AAAAJ",
      "l-VuKFsAAAAJ",
      "dbWhFN4AAAAJ",
      "JFEHAwIAAAAJ",
      "bel5BBcAAAAJ",
      "EuFF9kUAAAAJ",
      "YLh7yrwAAAAJ",
      "jQl9RtkAAAAJ",
      "gYiCq88AAAAJ",
      "bh08FeIAAAAJ",
      "4V1nNm4AAAAJ",
      "9uWuZkUAAAAJ",
      "EuBrsZQAAAAJ",
      "wRyjJfMAAAAJ",
      "cCda-zQAAAAJ",
      "DNuiPHwAAAAJ",
      "-JiwekUAAAAJ",
      "eml8HfQAAAAJ",
      "kPxa2w0AAAAJ",
      "Rza8c10AAAAJ",
      "WsM7ybkAAAAJ",
      "IqJ3zskAAAAJ",
      "H95HfgIAAAAJ",
      "DzI-iPQAAAAJ",
      "NmHgX-wAAAAJ",
      "UgK1my4AAAAJ",
      "Y2GtJkAAAAAJ",
      "8j3t5HsAAAAJ",
      "-lbtnAgAAAAJ",
      "rk587vcAAAAJ",
      "jyaTX64AAAAJ",
      "Q0piorUAAAAJ",
      "O1DeDyEAAAAJ",
      "nHh9PSsAAAAJ",
      "76B8lrgAAAAJ",
      "qoFYHTMAAAAJ",
      "iQxXG8kAAAAJ",
      "t9HPFawAAAAJ",
      "OMVTRscAAAAJ",
      "KtOqcRUAAAAJ",
      "zP9K32EAAAAJ",
      "nSpXpqMAAAAJ",
      "B96GkdgAAAAJ",
      "AbzGfgoAAAAJ",
      "kh8Qe6YAAAAJ",
      "FKUc3vsAAAAJ",
      "f4DpFfQAAAAJ",
      "LX2QWBYAAAAJ",
      "U89FHq4AAAAJ",
      "km6CP8cAAAAJ",
      "1ScWJOoAAAAJ",
      "Li-BrU4AAAAJ",
      "0hHqYoAAAAAJ",
      "WvufSLAAAAAJ",
      "TV9sa6QAAAAJ",
      "vNZhd_8AAAAJ",
      "wQU1dJAAAAAJ",
      "ZdfkFuAAAAAJ",
      "t3A39e8AAAAJ",
      "nubwxloAAAAJ",
      "xiiE5rYAAAAJ",
      "v1CRzeAAAAAJ",
      "8CVIK-UAAAAJ",
      "7oxkHYYAAAAJ",
      "fA0rYxMAAAAJ",
      "bqL73OkAAAAJ",
      "6bQxCusAAAAJ",
      "M-3cIR0AAAAJ",
      "g9bV-_sAAAAJ",
      "0mgEF28AAAAJ",
      "ikq9m9QAAAAJ",
      "DxQiCiIAAAAJ",
      "UKIdPdYAAAAJ",
      "h1-3lSoAAAAJ",
      "L4yEk2UAAAAJ",
      "A4_gQGgAAAAJ",
      "fcqkLtcAAAAJ",
      "C-5j7CQAAAAJ",
      "hD2WqqcAAAAJ",
      "0iFtFKEAAAAJ",
      "8FWkjw8AAAAJ",
      "ss8KR5gAAAAJ",
      "vxQc2L4AAAAJ",
      "fChTW6MAAAAJ",
      "SnQnQicAAAAJ",
      "3f2wPekAAAAJ",
      "sYTUOu8AAAAJ",
      "kmXOOdsAAAAJ",
      "BUDh_4wAAAAJ",
      "MYRUJkUAAAAJ",
      "B48DDQoAAAAJ",
      "k2DcM6IAAAAJ",
      "HrrtgKkAAAAJ",
      "2a5XgNAAAAAJ",
      "7k5QSdoAAAAJ",
      "C9rsD2UAAAAJ",
      "vNAD0mAAAAAJ",
      "5o88MDIAAAAJ",
      "MBzLo30AAAAJ",
      "mqpjAt4AAAAJ",
      "GADXPDcAAAAJ",
      "wqVWJNIAAAAJ",
      "SpAotDcAAAAJ",
      "2zReQdQAAAAJ",
      "cwGB7lwAAAAJ",
      "rbGxNYwAAAAJ",
      "UMKkDVwAAAAJ",
      "fqDBtzYAAAAJ",
      "oOhnPUgAAAAJ",
      "MV7LPnEAAAAJ",
      "L1b6JqsAAAAJ",
      "gAKTYtoAAAAJ",
      "Ual305IAAAAJ",
      "QURZIzUAAAAJ",
      "nsuJs6QAAAAJ",
      "dvz7WRQAAAAJ",
      "Yv6wq2kAAAAJ",
      "WIpCH90AAAAJ",
      "FbkauMAAAAAJ",
      "6C-udIUAAAAJ",
      "HuQF6AsAAAAJ",
      "sJDqACEAAAAJ",
      "T4WYN6YAAAAJ"
    ],
    "aa9LMvoAAAAJ": [],
    "itSa94cAAAAJ": [],
    "OP6ejqgAAAAJ": [
      "nTiSnwUAAAAJ",
      "aO8KpGcAAAAJ",
      "hdTDzlQAAAAJ",
      "Kzj3HC8AAAAJ",
      "8gEhRVgAAAAJ",
      "i-g1zC0AAAAJ",
      "xRmmtzIAAAAJ",
      "kTKmpT0AAAAJ",
      "_6XYKXMpK34C",
      "U0_ab4cAAAAJ",
      "cPmMoXoAAAAJ"
    ],
    "Bk5q_pAAAAAJ": [
      "VZHxoh8AAAAJ",
      "LurWtuYAAAAJ",
      "m2-OwQEAAAAJ",
      "HSx0BgQAAAAJ",
      "k7NgVSUAAAAJ",
      "_flfbOQAAAAJ",
      "nUlanA8AAAAJ",
      "g9WLzWoAAAAJ",
      "c8yK5XsAAAAJ",
      "3jS17zQAAAAJ",
      "8NamuusAAAAJ",
      "0VVg_R4AAAAJ",
      "yxUduqMAAAAJ",
      "O24CcQQAAAAJ",
      "QHSUy3MAAAAJ",
      "OttawxUAAAAJ",
      "m8m9nD0AAAAJ",
      "df-THM0AAAAJ",
      "-Z7fY00AAAAJ",
      "twvDiW8AAAAJ",
      "70LBhKcAAAAJ",
      "z7GCqT4AAAAJ",
      "wmDqYvUAAAAJ",
      "umivlPQAAAAJ",
      "-eVum0sAAAAJ",
      "sioumZAAAAAJ",
      "orVoz4IAAAAJ",
      "9RJdEXMAAAAJ",
      "qBy4wKcAAAAJ",
      "nXyv100AAAAJ",
      "xQqZt2AAAAAJ",
      "4Z6vo5QAAAAJ",
      "U6BRIM4AAAAJ",
      "5GavKiQAAAAJ",
      "6qWcDTAAAAAJ",
      "6JZ3R6wAAAAJ",
      "cKtU3eAAAAAJ",
      "zvC19mQAAAAJ",
      "LjxqXycAAAAJ",
      "mXtH1UYAAAAJ",
      "GINhGvwAAAAJ",
      "ny0ZgiQAAAAJ",
      "uglffdcAAAAJ",
      "2hjbResAAAAJ",
      "LILR85MAAAAJ",
      "aO8KpGcAAAAJ"
    ],
    "BAAZ_ysAAAAJ": [
      "vfPE6hgAAAAJ",
      "Py4URJUAAAAJ",
      "y-nUzMwAAAAJ",
      "_3O0RcUAAAAJ",
      "A20BZnQAAAAJ",
      "bslhbWgAAAAJ",
      "KXNUYWgAAAAJ",
      "i7eVfzwAAAAJ",
      "q77J4fgAAAAJ",
      "f4G8d00AAAAJ",
      "tP5IBFkAAAAJ",
      "iMlmLO4AAAAJ",
      "pouyVyUAAAAJ",
      "8R35rCwAAAAJ",
      "i7V1kJgAAAAJ",
      "RP4Qx3QAAAAJ",
      "UWO1mloAAAAJ",
      "Nn990CkAAAAJ",
      "UpZ41EwAAAAJ",
      "dsmssvcAAAAJ",
      "WKsaDwQAAAAJ",
      "HO-fMd8AAAAJ",
      "v6U3T4wAAAAJ",
      "zkhHirIAAAAJ",
      "jdpFVlgAAAAJ",
      "dvoF5_cAAAAJ",
      "Ch9iRwQAAAAJ",
      "6S9C8XoAAAAJ",
      "yjjrGdgAAAAJ",
      "zrZu6GkAAAAJ",
      "xFlasdQAAAAJ",
      "YY_D3XkAAAAJ",
      "E894cQoAAAAJ",
      "Xi-B5WIAAAAJ",
      "SRM4v2cAAAAJ",
      "nUTqrPkAAAAJ",
      "3G2EbP4AAAAJ",
      "-gscDIEAAAAJ",
      "ogXTOZ4AAAAJ",
      "_0IIzxgAAAAJ",
      "lPaISmIAAAAJ"
    ],
    "PGdm9MUAAAAJ": [],
    "0qfCL-QAAAAJ": [
      "nTiSnwUAAAAJ",
      "YKRiYRAAAAAJ",
      "h6-lPBsAAAAJ",
      "ErVxNWkAAAAJ",
      "Fsz9BAUAAAAJ",
      "UlpHyKAAAAAJ",
      "0P1xwo0AAAAJ",
      "13Tv6dkAAAAJ",
      "XI79Mw0AAAAJ"
    ],
    "0bwP0i4AAAAJ": [
      "pWvrysEAAAAJ",
      "j0_aKI0AAAAJ",
      "-zaDQ10AAAAJ",
      "ZjX0crAAAAAJ",
      "_pv1sEcAAAAJ",
      "K2WfIlsAAAAJ",
      "N_8WC5oAAAAJ"
    ],
    "PS-TM94AAAAJ": [
      "r3q68rcAAAAJ",
      "HOzdZp0AAAAJ",
      "ZbUfUMoAAAAJ",
      "_PZKLYUAAAAJ",
      "YAHWbtkAAAAJ",
      "B847xq8AAAAJ",
      "dYwbc9sAAAAJ",
      "UdaJi94AAAAJ",
      "GYdw0McAAAAJ",
      "0y38RJ8AAAAJ",
      "3qPiYJoAAAAJ",
      "fNOReswAAAAJ",
      "5m5ds6UAAAAJ",
      "WLOrHh8AAAAJ",
      "Lqc4cdAAAAAJ",
      "V4OPEAgAAAAJ",
      "m0rXqhkAAAAJ",
      "3y7spRQAAAAJ",
      "qMDr8HUAAAAJ",
      "FmZaK1wAAAAJ",
      "cLGOIdMAAAAJ",
      "CUDUMSkAAAAJ",
      "m_HQ-WQAAAAJ",
      "1eBgIWsAAAAJ",
      "fhLHgd8AAAAJ",
      "4M6ky2UAAAAJ",
      "WuEJs1AAAAAJ",
      "L-ek-X4AAAAJ",
      "D1EmzeoAAAAJ",
      "lg_0u-0AAAAJ",
      "KlrXkXkAAAAJ",
      "_ZH86NYAAAAJ",
      "Me9JcfgAAAAJ",
      "TyPF9V4AAAAJ",
      "2P8IbqoAAAAJ",
      "k5eocA8AAAAJ",
      "kDjILRMAAAAJ",
      "03JRmRcAAAAJ",
      "UvxP_J4AAAAJ",
      "aeKmkoUAAAAJ",
      "W4Y0jUIAAAAJ",
      "mjDKAAoAAAAJ",
      "0OtX_6gAAAAJ",
      "ScmX2AcAAAAJ",
      "WhEIQD0AAAAJ",
      "QQUxxaIAAAAJ",
      "55TAOdgAAAAJ",
      "PCtRSvUAAAAJ",
      "VGga3R4AAAAJ",
      "nd0G8qEAAAAJ",
      "NT8lLwEAAAAJ",
      "AT1_prkAAAAJ"
    ],
    "fmSHtE8AAAAJ": [
      "mG4imMEAAAAJ",
      "dcv4kpIAAAAJ",
      "VxpypngAAAAJ",
      "jEANvfgAAAAJ",
      "m3eDp7kAAAAJ",
      "92M8xv4AAAAJ",
      "6wwWRdEAAAAJ",
      "ONuIPv0AAAAJ",
      "LNUeOu4AAAAJ",
      "uGDQoU0AAAAJ",
      "3Q8LdcYAAAAJ",
      "8RgDBoEAAAAJ",
      "hvr3ALkAAAAJ",
      "z76PBfYAAAAJ",
      "jQl9RtkAAAAJ",
      "UX-H08cAAAAJ",
      "Lncr-VoAAAAJ",
      "xfskSZEAAAAJ",
      "0cZ_KWMAAAAJ",
      "9UfZJskAAAAJ",
      "8R35rCwAAAAJ",
      "YxBqNw8AAAAJ",
      "B8wslVsAAAAJ",
      "VINmGpYAAAAJ",
      "yPOT9K0AAAAJ",
      "1O3RPmsAAAAJ",
      "75x4pdcAAAAJ",
      "eG2NHUYAAAAJ",
      "n0pk_jEAAAAJ",
      "DIBOO50AAAAJ",
      "C-ZlBWMAAAAJ",
      "xgQd1qgAAAAJ",
      "kddKBCsAAAAJ",
      "JFEjS1QAAAAJ",
      "cxEoVL4AAAAJ",
      "wfGiqXEAAAAJ",
      "vtwH6GkAAAAJ",
      "bLUllHEAAAAJ",
      "Li-BrU4AAAAJ",
      "ImpbxLsAAAAJ",
      "YvYBeysAAAAJ",
      "iGLKl7cAAAAJ",
      "vfT6-XIAAAAJ",
      "vIqWvgwAAAAJ",
      "RjScbooAAAAJ",
      "J6iSjTcAAAAJ",
      "IVm1gDgAAAAJ",
      "p9-ohHsAAAAJ",
      "T04c3fwAAAAJ",
      "ciH2ROgAAAAJ",
      "lc6CVqEAAAAJ",
      "9aaeCToAAAAJ",
      "iYN86KEAAAAJ",
      "h0Al1fcAAAAJ",
      "H1XVLwsAAAAJ",
      "3ifikJ0AAAAJ",
      "2pH8BZwAAAAJ",
      "90Yb_90AAAAJ",
      "P5eWdgsAAAAJ",
      "0p-CEygAAAAJ",
      "1Rf6sGcAAAAJ",
      "tbbfR50AAAAJ",
      "vduyqcMAAAAJ",
      "DSiNzkIAAAAJ",
      "lD5J91cAAAAJ",
      "vY7MdLYAAAAJ",
      "GQWTo4MAAAAJ",
      "GwKF9rMAAAAJ",
      "ep2QZ70AAAAJ",
      "s4Q8hbUAAAAJ"
    ],
    "j8ULfMsAAAAJ": [],
    "tfN6V84AAAAJ": [
      "8fztli4AAAAJ",
      "fftO_HsAAAAJ",
      "B96GkdgAAAAJ",
      "ywv6tDUAAAAJ",
      "EHSuFcwAAAAJ",
      "8R35rCwAAAAJ",
      "vfPE6hgAAAAJ",
      "1Tfui8UAAAAJ",
      "6QPoYc4AAAAJ"
    ],
    "ri1sE34AAAAJ": [
      "lMkTx0EAAAAJ",
      "GgQ9GEkAAAAJ",
      "u3-FxUgAAAAJ",
      "0mgEF28AAAAJ",
      "lJ_oh2EAAAAJ",
      "kRJkDakAAAAJ",
      "H3Uq3FcAAAAJ",
      "7UV4ET4AAAAJ",
      "2k5j4eMAAAAJ",
      "wN9rBkcAAAAJ",
      "22TE5qkAAAAJ",
      "OXFjRnEAAAAJ",
      "L4bNmsMAAAAJ",
      "-2wyKzEAAAAJ",
      "qcyG7rwAAAAJ",
      "TV9sa6QAAAAJ",
      "0RAmmIAAAAAJ",
      "PTS2AOgAAAAJ",
      "9D4aG8AAAAAJ",
      "Ad6O4-0AAAAJ",
      "36ofBJgAAAAJ",
      "sPTruxEAAAAJ"
    ],
    "MzKvJhAAAAAJ": [],
    "rNcmwggAAAAJ": [],
    "WXbhp_4AAAAJ": [
      "U8qAL-0AAAAJ",
      "9_Hpd5kAAAAJ",
      "eL_y80EAAAAJ",
      "6Evj9YwAAAAJ"
    ],
    "y2pH4jcAAAAJ": [
      "OBUwP_oAAAAJ",
      "x7cbdTcAAAAJ",
      "Yh0IoBgAAAAJ",
      "Yn-Lm_QAAAAJ",
      "_pPy-pAAAAAJ",
      "pXzn2akAAAAJ",
      "KFQERBwAAAAJ",
      "iV2sKq8AAAAJ",
      "twlFI3sAAAAJ",
      "EfhUHOQAAAAJ",
      "jq8VoFkAAAAJ",
      "aS2nvbsAAAAJ",
      "T2U5sGIAAAAJ",
      "I0fbJ6cAAAAJ",
      "FcQ1xcwAAAAJ",
      "lPM8k54AAAAJ",
      "Vb3FLmkAAAAJ",
      "rXYLXJMAAAAJ",
      "NQeu1oAAAAAJ",
      "mm-fpzQAAAAJ",
      "aaGW2qwAAAAJ",
      "rXpctjYAAAAJ",
      "caPvMq0AAAAJ",
      "G1KQAusAAAAJ",
      "0lcJYs8AAAAJ",
      "xMhGYpgAAAAJ",
      "BWF8wn4AAAAJ",
      "lVoOIv4AAAAJ",
      "bsqhvmAAAAAJ",
      "P7ndQrkAAAAJ",
      "abUcBIkAAAAJ",
      "wsLqB5UAAAAJ",
      "RfyLl28AAAAJ",
      "KbVFiKYAAAAJ",
      "1NXsdH8AAAAJ",
      "WKpSlhQAAAAJ",
      "XUhsCZwAAAAJ",
      "993eudcAAAAJ"
    ],
    "-CeUxegAAAAJ": [
      "f1FwzIsAAAAJ",
      "yfORTKUAAAAJ",
      "uaiskTYAAAAJ",
      "XDrMB6AAAAAJ",
      "PDwwvrEAAAAJ",
      "9qVRm-AAAAAJ",
      "AlpgbIoAAAAJ",
      "6wCEmNYAAAAJ",
      "7CH_3FwAAAAJ",
      "7HCKL10AAAAJ",
      "q5O284UAAAAJ",
      "rXpctjYAAAAJ",
      "QdlhnBMAAAAJ",
      "wwkJvoMAAAAJ",
      "GMZYUyQAAAAJ"
    ],
    "wxnzyjwAAAAJ": [
      "t2X4Mg8AAAAJ",
      "YfPA4YsAAAAJ",
      "cabvCW8AAAAJ",
      "0tWX-EMAAAAJ",
      "nxNkEiYAAAAJ",
      "HO3nVAoAAAAJ",
      "WlA92lcAAAAJ",
      "MNuTR9YAAAAJ",
      "bQKreEMAAAAJ",
      "SyACgDAAAAAJ",
      "iUEcoesAAAAJ",
      "or-t5ZcAAAAJ",
      "cMHsYdcAAAAJ",
      "ODdBJAcAAAAJ",
      "XUQcbFAAAAAJ"
    ],
    "gTWUZlsAAAAJ": [
      "eV2tuR8AAAAJ",
      "eyCw9goAAAAJ",
      "hy-qH-cAAAAJ",
      "E02doCkAAAAJ",
      "Q_kKkIUAAAAJ",
      "fpUICd0AAAAJ",
      "L9QufAsAAAAJ",
      "wAFMjfkAAAAJ",
      "ScoZZPsAAAAJ",
      "Ao4gtsYAAAAJ",
      "OsP7JHAAAAAJ",
      "DWERCmsAAAAJ",
      "FioDApkAAAAJ",
      "8cxDHS4AAAAJ",
      "U0egIsIAAAAJ",
      "eDHv58AAAAAJ",
      "2_gFWe4AAAAJ",
      "bh-uRFMAAAAJ",
      "4v8uJrIAAAAJ",
      "ZXCO3DMAAAAJ",
      "ImpbxLsAAAAJ",
      "XsxZrYYAAAAJ",
      "8Phz8n4AAAAJ",
      "OUv7J6QAAAAJ",
      "w8XocYQAAAAJ",
      "3pyzQQ8AAAAJ",
      "l_XxJ1kAAAAJ",
      "_b_LTjMAAAAJ",
      "9cZUlEYAAAAJ",
      "OttawxUAAAAJ",
      "9TbXgQ0AAAAJ",
      "T_bLpqYAAAAJ",
      "yxUduqMAAAAJ",
      "MxxZkEcAAAAJ",
      "cdP5JicAAAAJ",
      "RbCKRPcAAAAJ",
      "Kce9W-8AAAAJ",
      "FSj_J7MAAAAJ",
      "Bx9WGD6lBFEC",
      "xMvt3NEAAAAJ",
      "B96GkdgAAAAJ",
      "ZBc_WwYAAAAJ",
      "xxiTm5EAAAAJ",
      "WhFGh74AAAAJ",
      "mMifMdoAAAAJ",
      "6PJWcFEAAAAJ",
      "JFT_m9kAAAAJ",
      "70lgwYwAAAAJ",
      "pZ0-BicAAAAJ",
      "Zldo9CAAAAAJ",
      "RY7cuPAAAAAJ",
      "yCyR-TsAAAAJ",
      "W8VIEZgAAAAJ",
      "Q8iay0gAAAAJ",
      "KvX7mJUAAAAJ",
      "3f6_I8MAAAAJ",
      "-XGXJbQAAAAJ",
      "9D4aG8AAAAAJ",
      "iF01q24AAAAJ",
      "QKslW6EAAAAJ",
      "_bs7PqgAAAAJ",
      "9fxv1zwAAAAJ",
      "4GTpCxcAAAAJ",
      "H-KEzkUAAAAJ",
      "hlWhzU8AAAAJ",
      "a4D08aQAAAAJ",
      "BwaMMgoAAAAJ",
      "PvHFAfIAAAAJ",
      "Zw1pfxYAAAAJ",
      "ITZ1e7MAAAAJ",
      "x942ipYAAAAJ",
      "aP5VahUAAAAJ",
      "8LcYFjEAAAAJ",
      "Sou5ih0AAAAJ",
      "dPX0wQcAAAAJ",
      "yILa1y0AAAAJ",
      "UCDMtM0AAAAJ",
      "fdGXVd4AAAAJ",
      "HOj2qUkAAAAJ",
      "FTx_BNsAAAAJ",
      "U80atIAAAAAJ",
      "8NudxYsAAAAJ",
      "k1eaag4AAAAJ",
      "1Cv6Sf4AAAAJ",
      "X0EXfT8AAAAJ",
      "pImSVwoAAAAJ",
      "T2UHRgoAAAAJ",
      "IgO2ThIAAAAJ",
      "aLl3rYoAAAAJ",
      "dNHNpxoAAAAJ",
      "E_UlAVQAAAAJ",
      "e9gUdKwAAAAJ",
      "aSJthdEAAAAJ",
      "68c5HfwAAAAJ",
      "x63j7HEAAAAJ",
      "R9MXY8wAAAAJ",
      "Vd6RW7cAAAAJ",
      "5vVjpBsAAAAJ",
      "twuEPEEAAAAJ",
      "IYPiRoQAAAAJ",
      "dG7KSW0AAAAJ",
      "Wt0ndFIAAAAJ",
      "CRLG9UcAAAAJ",
      "NSw87QsAAAAJ",
      "bSpGhYcAAAAJ",
      "BT4XTP4AAAAJ",
      "7-B7aQkAAAAJ",
      "JBGlsDoAAAAJ",
      "DZ-fHPgAAAAJ",
      "yHDXov0AAAAJ",
      "zP0S_ikAAAAJ",
      "SWVeT4AAAAAJ",
      "dQ0dT2sAAAAJ",
      "omHTV3MAAAAJ",
      "ND0FM6EAAAAJ",
      "IroP0EwAAAAJ",
      "mxYLn8MAAAAJ",
      "OBBqkosAAAAJ",
      "V2Y1L4sAAAAJ",
      "UJ9-UuIAAAAJ",
      "L3zNUG4AAAAJ",
      "6F90JHgAAAAJ",
      "7z8NqmUAAAAJ",
      "3KoL3eQAAAAJ",
      "zGzDpuUAAAAJ",
      "CNuyivcAAAAJ",
      "V4OPEAgAAAAJ",
      "4D1n8scAAAAJ",
      "L4bNmsMAAAAJ",
      "roooUB0AAAAJ",
      "DNuiPHwAAAAJ",
      "gQOKAggAAAAJ",
      "IcasIiwAAAAJ",
      "FPVUA-YAAAAJ",
      "kUcQkpMAAAAJ",
      "4NdMn_MAAAAJ",
      "maa1m0oAAAAJ",
      "i38QlUwAAAAJ",
      "6XorTkcAAAAJ",
      "fz1mq4AAAAAJ",
      "Bo7Y1j0AAAAJ",
      "hRB3wSgAAAAJ",
      "cl7CnNYAAAAJ",
      "bs5MttgAAAAJ",
      "xxYMJlUAAAAJ",
      "vkWBb2wAAAAJ",
      "6QrCoOoAAAAJ",
      "2SmbjHAAAAAJ",
      "h0e2kMQAAAAJ",
      "lHI7-XoAAAAJ",
      "SiCHxTkAAAAJ",
      "ZZP1cXYAAAAJ",
      "SWMKy70AAAAJ",
      "M9V6y-0AAAAJ",
      "CbGdL4cAAAAJ",
      "okcbLqoAAAAJ",
      "xBv5ZfkAAAAJ",
      "nlJCSWcAAAAJ",
      "nHE4ylYAAAAJ",
      "M0gMbZMAAAAJ",
      "1uucMrsAAAAJ",
      "2Vt8ZUAAAAAJ",
      "_fVZiToAAAAJ",
      "-ltRSM0AAAAJ",
      "aDLGNI0AAAAJ",
      "dGLTaaEAAAAJ",
      "lS0tvhoAAAAJ",
      "9547Qp4AAAAJ",
      "jUtYwE0AAAAJ",
      "jk17mo8AAAAJ",
      "8VPkPvUAAAAJ",
      "Q0crxvwAAAAJ",
      "4GpKQUIAAAAJ",
      "RVl8TE0AAAAJ",
      "mq-Vzk8AAAAJ",
      "npqoAWwAAAAJ",
      "eJAV17IAAAAJ",
      "62e5CygAAAAJ",
      "zRy-zdAAAAAJ",
      "ClSXZ4IAAAAJ",
      "v3JsjMYAAAAJ",
      "jUCiLN4AAAAJ",
      "coNUBLoAAAAJ",
      "ynvtzZQAAAAJ",
      "fds2VpgAAAAJ",
      "vyteiT4AAAAJ"
    ],
    "O43_7KUAAAAJ": [
      "n8iUBg8AAAAJ",
      "8HVTWNkAAAAJ",
      "QZCU3NkAAAAJ",
      "BdwP-3QAAAAJ",
      "CXgQufgAAAAJ",
      "pKf5LtQAAAAJ",
      "x9qzWg8AAAAJ",
      "yxUduqMAAAAJ",
      "_pv1sEcAAAAJ",
      "bmlgkM4AAAAJ",
      "WNHLjp0AAAAJ"
    ],
    "NkzyCvUAAAAJ": [
      "NMS69lQAAAAJ",
      "x04W_mMAAAAJ",
      "Vs-MdPcAAAAJ",
      "JicYPdAAAAAJ",
      "L7lMQkQAAAAJ"
    ],
    "lyadgWkAAAAJ": [
      "ySwF8ioAAAAJ",
      "Fsz9BAUAAAAJ",
      "iyDxq0EAAAAJ",
      "tWSGUdoAAAAJ",
      "JrnxAZUAAAAJ",
      "aO8KpGcAAAAJ",
      "PBXTVb4AAAAJ",
      "Cya7Va8AAAAJ"
    ],
    "B8wslVsAAAAJ": [
      "8R35rCwAAAAJ",
      "DgLEyZgAAAAJ",
      "0uTu7fYAAAAJ",
      "x04W_mMAAAAJ",
      "mxiO4IkAAAAJ",
      "lAp-1WEAAAAJ",
      "7bmQ4FgAAAAJ"
    ],
    "b4PmtFkAAAAJ": [
      "aSAS-aAAAAAJ",
      "rlAIMRMAAAAJ",
      "QfxrxDoAAAAJ",
      "AaVPa5kAAAAJ",
      "lDjk14QAAAAJ",
      "T1pWaCsAAAAJ",
      "nRQi4O8AAAAJ",
      "tgkojSIAAAAJ",
      "MzD8rjoAAAAJ",
      "A5vhsIYAAAAJ",
      "9hMb_7IAAAAJ",
      "8TkJbjgAAAAJ",
      "hdTDzlQAAAAJ",
      "aO8KpGcAAAAJ"
    ],
    "0ei9XEUAAAAJ": [],
    "n-B0jr4AAAAJ": [
      "kzFmAkYAAAAJ",
      "Mq89JAcAAAAJ",
      "Z9gvBegAAAAJ",
      "Oyx-_UIAAAAJ",
      "32RHN4oAAAAJ",
      "dhmdaoQAAAAJ",
      "cHia5p0AAAAJ",
      "OUTSTAYAAAAJ",
      "ptAR7tUAAAAJ",
      "EX3OYP4AAAAJ",
      "1qXJQ7cAAAAJ",
      "h0a5q3QAAAAJ",
      "3kaiBBYAAAAJ",
      "0KyeZ2QAAAAJ",
      "YvdzeM8AAAAJ",
      "jyxO2akAAAAJ",
      "2maWWboAAAAJ",
      "o8BdwuMAAAAJ",
      "8twuSywAAAAJ",
      "Jtmq_m0AAAAJ",
      "tKlt2LgAAAAJ",
      "g_21RKoAAAAJ",
      "qYLOPxoAAAAJ",
      "j5bG8TgAAAAJ",
      "p351VxAAAAAJ",
      "F3YYEmMAAAAJ",
      "8uou2n4AAAAJ",
      "7PerW6IAAAAJ",
      "bh-uRFMAAAAJ",
      "48PsswEAAAAJ",
      "3fa02HAAAAAJ",
      "2YYsi40AAAAJ",
      "gXiGxcMAAAAJ",
      "k4SdlbcAAAAJ",
      "ELOVd8sAAAAJ",
      "pk5cKBUAAAAJ",
      "amJQro0AAAAJ",
      "GyvseMkAAAAJ",
      "K2INPyYAAAAJ",
      "ATkNLcQAAAAJ",
      "pr6rIJEAAAAJ",
      "dbggnnAAAAAJ",
      "iu8ve8EAAAAJ",
      "GNBB3JQAAAAJ",
      "BvxYILIAAAAJ",
      "BGmxwfAAAAAJ",
      "yMXs1WcAAAAJ",
      "G9HyayYAAAAJ",
      "nZD_5vsAAAAJ",
      "z3TC8X0AAAAJ",
      "wctJ37UAAAAJ",
      "Y0FLn-8AAAAJ",
      "r1TJBr8AAAAJ",
      "n4bdAtIAAAAJ",
      "mu5Y2rYAAAAJ",
      "BENt-uEAAAAJ",
      "Ijfl2tkAAAAJ",
      "OgV3CkYAAAAJ",
      "U0JhTbAAAAAJ",
      "Q-UjnzEAAAAJ",
      "kCy8JG8AAAAJ",
      "T6h8tLcAAAAJ",
      "OKZC1CYAAAAJ",
      "1Oofk3YAAAAJ",
      "WQ0PktMAAAAJ",
      "Rza8c10AAAAJ",
      "nHhtvqkAAAAJ",
      "ykFtI-QAAAAJ",
      "PXm1lPAAAAAJ",
      "iAEBIB4AAAAJ",
      "Pb74Fg4AAAAJ",
      "cIK1hS8AAAAJ",
      "9yQ1tQoAAAAJ",
      "VpB8NZ8AAAAJ",
      "cwKg158AAAAJ",
      "VxAuxMwAAAAJ",
      "MILCJzAAAAAJ",
      "kPxa2w0AAAAJ",
      "_cHRq1kAAAAJ",
      "fWVzdOcAAAAJ",
      "vy8xXDQAAAAJ",
      "2Pxx8QIAAAAJ",
      "MDIyLnwAAAAJ",
      "MRCF9PwAAAAJ",
      "BfmcfEAAAAAJ",
      "7cqQFSoAAAAJ",
      "x2wyjkAAAAAJ",
      "2dvDXjkAAAAJ",
      "B3QzwVAAAAAJ",
      "Z6gnDIEAAAAJ",
      "J4SmwaQAAAAJ",
      "ANbGE-UAAAAJ",
      "nN9bxcIAAAAJ",
      "TxdeO-UAAAAJ",
      "QE9pa_cAAAAJ",
      "HzIp5_YAAAAJ",
      "24OBED0AAAAJ",
      "TtU74NAAAAAJ",
      "oO53gjEAAAAJ",
      "1c9oQNMAAAAJ",
      "QQnewdYAAAAJ",
      "oDDqnQ4AAAAJ",
      "E9NVOBUAAAAJ",
      "6sWGL5wAAAAJ",
      "X0GMj20AAAAJ",
      "CVVh3DIAAAAJ",
      "HxZDDzUAAAAJ",
      "tQnods8AAAAJ",
      "2l1fWEoAAAAJ",
      "fddAbqsAAAAJ",
      "ZaJy9J4AAAAJ",
      "ocIDAto2lksC",
      "7EBwGhIAAAAJ",
      "5S1kGcAAAAAJ",
      "eO2xkdMAAAAJ",
      "QMc-grEAAAAJ",
      "KGRm0QsAAAAJ",
      "h-3xd3EAAAAJ",
      "3pyzQQ8AAAAJ",
      "WwbRKDUAAAAJ",
      "RZ9pOY4AAAAJ",
      "pfEoUpcAAAAJ",
      "TwMib_QAAAAJ",
      "1TDqUuwAAAAJ",
      "c-ZZKpAAAAAJ",
      "IE2DVpIAAAAJ",
      "yz2P_aUAAAAJ",
      "_gH7-4wAAAAJ",
      "cLDqm1AAAAAJ",
      "H8tlV-oAAAAJ",
      "yZS4ce8AAAAJ",
      "ViYx9vMAAAAJ",
      "8mvohP8AAAAJ",
      "SXHb84wAAAAJ",
      "X3ji--4AAAAJ",
      "q0ZUBN4AAAAJ",
      "AqST318AAAAJ"
    ],
    "Qhe5ua0AAAAJ": [],
    "V42yp08AAAAJ": [
      "7_JY8gkAAAAJ",
      "ncTx_QoAAAAJ",
      "aenlXyEAAAAJ",
      "hcVpBCIAAAAJ",
      "ykWqS0YAAAAJ",
      "E275ukwAAAAJ",
      "CRnlLm4AAAAJ",
      "Pqd_-nkAAAAJ",
      "ILDVin4AAAAJ",
      "DU-xHpQAAAAJ",
      "YFNi7tsAAAAJ",
      "eov2LfUAAAAJ",
      "dVpTVwkAAAAJ",
      "B3t_szAAAAAJ",
      "KG7Na5oAAAAJ",
      "d_OCVbEAAAAJ",
      "phTqe74AAAAJ",
      "nX-_Ou0AAAAJ",
      "j9GCzQUAAAAJ",
      "22LTQSMAAAAJ",
      "vtwH6GkAAAAJ",
      "2tt6ZJ0AAAAJ",
      "2oy3OXYAAAAJ",
      "WXXu26AAAAAJ",
      "kQ-axIUAAAAJ",
      "vgfGtykAAAAJ",
      "8R35rCwAAAAJ",
      "mXtH1UYAAAAJ",
      "UAwKvEsAAAAJ",
      "7oxkHYYAAAAJ"
    ],
    "Jp6Mz1sAAAAJ": [],
    "t4dSV4YAAAAJ": [
      "bh-uRFMAAAAJ",
      "eml8HfQAAAAJ",
      "ImpbxLsAAAAJ",
      "0QtU-NsAAAAJ",
      "c1-jq60AAAAJ",
      "FGZ1CJsAAAAJ",
      "whu7X_kAAAAJ",
      "4uaSNpYAAAAJ"
    ],
    "Q8kbUQEAAAAJ": [
      "uFJi3IUAAAAJ",
      "b8OxVWUAAAAJ",
      "m0WCd-4AAAAJ",
      "7P-gZioAAAAJ",
      "yZGlLeMAAAAJ",
      "f5vdXEQAAAAJ",
      "aApop70AAAAJ",
      "T_IyfqMAAAAJ"
    ],
    "zX3ba1kAAAAJ": [
      "9MSpWOUAAAAJ",
      "dTkWR0MAAAAJ",
      "zHCTHbYAAAAJ",
      "-E3hYj8AAAAJ",
      "W4Y0jUIAAAAJ",
      "7j3itaMAAAAJ",
      "Es6jE1kAAAAJ",
      "gqB23VMAAAAJ",
      "tqxTaiAAAAAJ",
      "tokXOxkAAAAJ",
      "50xZTa0AAAAJ",
      "B_rKfusAAAAJ",
      "e8aRmAsAAAAJ",
      "7b858c0AAAAJ",
      "qVuN4MIAAAAJ",
      "i5PazXwAAAAJ",
      "2uHUSa8AAAAJ",
      "8T5VDv8AAAAJ",
      "w7t5xQsAAAAJ",
      "xGbDr7YAAAAJ",
      "MDfW21AAAAAJ",
      "6vXTtDQAAAAJ",
      "CgItEbQAAAAJ",
      "LKv32bgAAAAJ",
      "umFQktIAAAAJ",
      "EqKRQ4YAAAAJ",
      "FANRIhwAAAAJ",
      "h6jljQQAAAAJ",
      "rD8a4hQAAAAJ",
      "oOwNKsAAAAAJ",
      "J_XhIsgAAAAJ",
      "11tt6p4AAAAJ",
      "v6PsQKIAAAAJ",
      "g3UpmeoAAAAJ",
      "PEK-v-EAAAAJ",
      "SQ1eGN4AAAAJ",
      "-JOkpfQAAAAJ",
      "L766PJkAAAAJ",
      "VX7d5EQAAAAJ",
      "n4eReqMAAAAJ",
      "_61pvRYAAAAJ",
      "nf_EnbAAAAAJ",
      "62Uqu6wAAAAJ"
    ],
    "mVkGg80AAAAJ": [
      "GINhGvwAAAAJ",
      "eyCw9goAAAAJ",
      "owqhKD8AAAAJ",
      "CotFJJsAAAAJ",
      "yj2b7pgAAAAJ",
      "B9jUcIgAAAAJ",
      "ct2hw4UAAAAJ",
      "TtAwEMgAAAAJ",
      "K0kaNvkAAAAJ",
      "HjmSOFEAAAAJ",
      "MhDyxdYAAAAJ",
      "1mDpUSgAAAAJ",
      "pTTEiHUAAAAJ",
      "8NudxYsAAAAJ",
      "Hi7ZdhQAAAAJ",
      "EqobCqwAAAAJ",
      "GcuxcLYAAAAJ",
      "P_-O-wcAAAAJ",
      "nTiSnwUAAAAJ",
      "hdTDzlQAAAAJ",
      "aO8KpGcAAAAJ",
      "dYt8FGcAAAAJ",
      "HQRnt54AAAAJ",
      "fGv6xi0AAAAJ",
      "3JjcAnoAAAAJ",
      "IkxViPsAAAAJ",
      "QF_rhCIAAAAJ"
    ],
    "q-buMEoAAAAJ": [],
    "ESCWolcAAAAJ": [
      "ySwF8ioAAAAJ",
      "iyDxq0EAAAAJ",
      "lyadgWkAAAAJ",
      "mQnBkmoAAAAJ",
      "oD8eeUYAAAAJ",
      "aO8KpGcAAAAJ",
      "IiSNwnAAAAAJ"
    ],
    "MhDyxdYAAAAJ": [
      "r3q68rcAAAAJ",
      "owqhKD8AAAAJ",
      "E8Jst30AAAAJ",
      "b1y1LooAAAAJ",
      "OVdu5IEAAAAJ",
      "vaSdahkAAAAJ",
      "7NpTttkAAAAJ",
      "lPG5fAIAAAAJ",
      "kokpiBQAAAAJ",
      "uErE2UUAAAAJ",
      "P_-O-wcAAAAJ",
      "R9L0aqAAAAAJ",
      "8sGC5D4AAAAJ",
      "qU9WvTgAAAAJ",
      "TaF4L4EAAAAJ",
      "33yNvIgAAAAJ",
      "mVkGg80AAAAJ",
      "GINhGvwAAAAJ",
      "tb2aY4kAAAAJ",
      "rUcRJEkAAAAJ",
      "mIlQ2lIAAAAJ",
      "yxUduqMAAAAJ",
      "E5NCCUEAAAAJ",
      "ImpbxLsAAAAJ",
      "ZybgAqkAAAAJ",
      "sJI2aOYAAAAJ",
      "qMDr8HUAAAAJ",
      "jAAj2XoAAAAJ",
      "aO8KpGcAAAAJ",
      "ZqGaKSgAAAAJ",
      "H_6RQ7oAAAAJ",
      "bqP_zxYAAAAJ",
      "ReWNzl4AAAAJ",
      "GLtCYtgAAAAJ",
      "C7dO_UgAAAAJ",
      "0Fv4bikAAAAJ",
      "xT19Jc0AAAAJ",
      "z-KILD8AAAAJ",
      "yQNhFGUAAAAJ",
      "84WzBlYAAAAJ",
      "CxeH4uoAAAAJ",
      "GdOmgYwAAAAJ",
      "4kVLYxIAAAAJ",
      "Uhf4nBkAAAAJ",
      "lMkTx0EAAAAJ",
      "H3Uq3FcAAAAJ",
      "0RAmmIAAAAAJ",
      "UW2Ji5MAAAAJ",
      "2k5j4eMAAAAJ",
      "TUAzs3sAAAAJ",
      "2oy3OXYAAAAJ",
      "yDVn5LEAAAAJ",
      "BA0BaS4AAAAJ",
      "jeOPodEAAAAJ",
      "rP3Ed1oAAAAJ",
      "e0IRutEAAAAJ",
      "ANBocsYAAAAJ",
      "iTEcewwAAAAJ",
      "kNH8zcgAAAAJ",
      "jEzWxQIAAAAJ",
      "dN7AziAAAAAJ",
      "LeshmV8AAAAJ",
      "ZpG_cJwAAAAJ",
      "e6op8BQAAAAJ",
      "M8Hz2NSNe3QC",
      "M7y1dj8AAAAJ",
      "vMOWEMAAAAAJ",
      "nCFeUqYAAAAJ"
    ],
    "7HCKL10AAAAJ": [
      "iTsZVuoAAAAJ",
      "HmbVzpoAAAAJ",
      "ld8AkQEAAAAJ",
      "M75dilYAAAAJ",
      "CJdblO4AAAAJ",
      "7Fl-fjIAAAAJ"
    ],
    "wRyjJfMAAAAJ": [
      "bh-uRFMAAAAJ",
      "ahSpJOAAAAAJ",
      "lnCKs0AAAAAJ",
      "-EZBCBAAAAAJ",
      "3kDtybgAAAAJ",
      "tvgSaXsAAAAJ",
      "jQl9RtkAAAAJ",
      "AEsPCAUAAAAJ",
      "t4dSV4YAAAAJ",
      "iRBUTOAAAAAJ",
      "X0EXfT8AAAAJ",
      "o6LlkNMAAAAJ",
      "-xQ-C1sAAAAJ",
      "ID9QePIAAAAJ",
      "fA0rYxMAAAAJ",
      "7oxkHYYAAAAJ",
      "GHpxNQIAAAAJ"
    ],
    "FH9nKOAAAAAJ": [
      "8fztli4AAAAJ",
      "vN-is70AAAAJ",
      "iEFL4-YAAAAJ",
      "RhFhIIgAAAAJ",
      "6IkG2m0AAAAJ",
      "B96GkdgAAAAJ",
      "O7bGqjUAAAAJ",
      "Yxh9WWoAAAAJ",
      "IcaU830AAAAJ",
      "wmZTE5gAAAAJ",
      "zP0S_ikAAAAJ",
      "FFWXLHUAAAAJ",
      "J8_FdjkAAAAJ",
      "-hGZC54AAAAJ",
      "2o3QdBAAAAAJ",
      "yxUduqMAAAAJ",
      "jdpFVlgAAAAJ",
      "vtwH6GkAAAAJ",
      "I9VWDKcAAAAJ",
      "UgHB5oAAAAAJ",
      "Z64LdqQAAAAJ",
      "Vn3L_ioAAAAJ",
      "SMRGdi0AAAAJ",
      "LQLq8eEAAAAJ",
      "84WzBlYAAAAJ",
      "xPnkc80AAAAJ",
      "5f47GEsAAAAJ",
      "mNwCdqwAAAAJ",
      "0DpK1EMAAAAJ",
      "Q06Rh6oAAAAJ",
      "tVPWAKIAAAAJ",
      "GXRermIAAAAJ",
      "E_oZZj8AAAAJ",
      "d1WOhpwAAAAJ",
      "LOV6_WIAAAAJ",
      "2yaiWZ8AAAAJ",
      "vhP-tlcAAAAJ",
      "daslsUkAAAAJ",
      "LAv0HTEAAAAJ",
      "ECHSnpYAAAAJ",
      "ffdt7gMAAAAJ",
      "5NiFWuwAAAAJ",
      "B2XPxEkAAAAJ",
      "yLQF4mkAAAAJ",
      "DJ9puk8AAAAJ",
      "YCtmdaMAAAAJ",
      "6YRoqzQAAAAJ",
      "FayXlTYAAAAJ",
      "Dn_qYK8AAAAJ",
      "K4OcFXUAAAAJ",
      "Tsh90D8AAAAJ",
      "cZRgwiwAAAAJ",
      "chv2d8IAAAAJ",
      "uwzBnJwAAAAJ",
      "xksqo5gAAAAJ",
      "jm6S_kEAAAAJ",
      "65FCPpwAAAAJ",
      "zm4UbBYAAAAJ",
      "ootP9OgAAAAJ",
      "fftO_HsAAAAJ",
      "t7VnipMAAAAJ",
      "G3eFbR0AAAAJ",
      "3nYG5BMAAAAJ",
      "CSJEObYAAAAJ",
      "l53UPjoAAAAJ",
      "mPC6wp4AAAAJ",
      "zVDNPpvMya0C",
      "o-5vyEsAAAAJ",
      "cEM1a5gAAAAJ",
      "9e0uFr4AAAAJ",
      "_7fW--oAAAAJ",
      "46EMhJMAAAAJ",
      "WXXu26AAAAAJ",
      "MEowyLcAAAAJ",
      "yXvXtrMAAAAJ",
      "eSgXTkkAAAAJ",
      "92bmh84AAAAJ",
      "MRkBwCQAAAAJ",
      "QXyvv94AAAAJ",
      "II-AXHYAAAAJ",
      "tcCGGDsZJUsC",
      "pDyfiUEAAAAJ",
      "oX7L_mMAAAAJ",
      "uG6vN6QAAAAJ"
    ],
    "ED5iKYYAAAAJ": [
      "ig8JXwIAAAAJ",
      "OAJ2PSEAAAAJ",
      "-YP8MJ0AAAAJ",
      "ip9xnysAAAAJ",
      "Q5yf4F4AAAAJ",
      "L9ztLe8AAAAJ",
      "bh-uRFMAAAAJ",
      "R7_-IjUAAAAJ",
      "lD4Yjn4AAAAJ",
      "PgTO8q4AAAAJ",
      "cTIwrjoAAAAJ",
      "IAD0fQQAAAAJ",
      "_ZU4B9AAAAAJ",
      "Oo3fRbcAAAAJ",
      "cTTbBOsAAAAJ",
      "b-JF-UIAAAAJ",
      "fFQTJdEAAAAJ",
      "qANkJFwAAAAJ",
      "9Trpw3gAAAAJ",
      "RA02NxsAAAAJ",
      "3N7aVh8AAAAJ",
      "Nmz0IzcAAAAJ",
      "pvyI8GkAAAAJ",
      "bo0P2qYAAAAJ",
      "mMjWcPAAAAAJ",
      "m4fq5VoAAAAJ",
      "9GnYJQkAAAAJ",
      "hrqU1KkAAAAJ",
      "_DNzXTcAAAAJ",
      "1TqAq5AAAAAJ",
      "LY8SM4IAAAAJ",
      "pPcNe2EAAAAJ",
      "ewj-IFsAAAAJ",
      "XYtB2GUAAAAJ",
      "glg1I70AAAAJ",
      "MqNK0kQAAAAJ",
      "qIg8KFYAAAAJ",
      "FWztzhcAAAAJ",
      "SDhzsXUAAAAJ",
      "6vBloKgAAAAJ",
      "Bdlf-Z4AAAAJ",
      "GTk-bkoAAAAJ",
      "Xdnc5IMAAAAJ",
      "YLHQ1QoAAAAJ",
      "H4XGkH0AAAAJ",
      "Qcn2vwUAAAAJ",
      "PUmV3bwAAAAJ",
      "SHO5PDkAAAAJ",
      "5diMRzQAAAAJ",
      "c7EMylYAAAAJ",
      "NiR8zKAAAAAJ",
      "mldMyOsAAAAJ",
      "wvMb3ccAAAAJ",
      "Nf8TQBQAAAAJ",
      "AxZIIccAAAAJ",
      "VJuuzLwAAAAJ",
      "D3ita20AAAAJ",
      "SOt7sr4AAAAJ",
      "8SSdKyMAAAAJ",
      "kkirJKcAAAAJ",
      "S8kPovUAAAAJ",
      "fiDP8AkAAAAJ",
      "Ft3sKZ8AAAAJ",
      "hqGaEUoAAAAJ",
      "93hi3QcAAAAJ",
      "eCc_7IgAAAAJ",
      "JEihq_0AAAAJ",
      "KNWPax8AAAAJ",
      "zEUV5a8AAAAJ",
      "iGidFyoAAAAJ",
      "eiIriYIAAAAJ",
      "W9BOLA8AAAAJ",
      "P0iOgxMAAAAJ",
      "ZRWlokAAAAAJ",
      "DSZzGh0AAAAJ",
      "yfsR0k0AAAAJ",
      "x275ekUAAAAJ",
      "e-fdBdIAAAAJ",
      "DO3quJYAAAAJ",
      "uqir0mIAAAAJ",
      "r1L_2qkAAAAJ",
      "Plv4gH4AAAAJ",
      "TB6o7YsAAAAJ",
      "O5J1hyMAAAAJ",
      "I_ZwYZcAAAAJ",
      "Fr9Vhe4AAAAJ",
      "9kzHZssAAAAJ",
      "FUOEBDUAAAAJ",
      "h-9pNEkAAAAJ",
      "-hexEEAAAAAJ",
      "lXAUVFcAAAAJ",
      "La3_EQwAAAAJ",
      "HosA8_UAAAAJ",
      "LB7sjGwAAAAJ",
      "eQpLy20AAAAJ",
      "eQGpfS8AAAAJ",
      "v7UAODsAAAAJ",
      "vf-M8-MAAAAJ",
      "6NjbexEAAAAJ",
      "LphRgywAAAAJ",
      "vPVX4TIAAAAJ",
      "Hlx9L00AAAAJ",
      "9hk7seYAAAAJ",
      "9aDxIYcAAAAJ",
      "mU40GkMAAAAJ",
      "QQ7lOvAAAAAJ",
      "fCkoUvEAAAAJ",
      "6zm5XD8AAAAJ",
      "0mf5NioAAAAJ",
      "LjmBUTAAAAAJ",
      "r50jBCUAAAAJ",
      "dX4x9z4AAAAJ",
      "zF5XNJgAAAAJ",
      "PsTik-gAAAAJ",
      "Y-6riI4AAAAJ",
      "pdPJFIUAAAAJ",
      "gq_ESzoAAAAJ",
      "Lz6YRtEAAAAJ",
      "NUtQyXAAAAAJ",
      "5KBfZzYAAAAJ",
      "4CcAPCgAAAAJ",
      "zXESohsAAAAJ",
      "NxGLVEEAAAAJ",
      "9cWszHUu9eAC",
      "k6TEw8kAAAAJ",
      "bWuZUsoAAAAJ"
    ],
    "i28fU0MAAAAJ": [],
    "t9HPFawAAAAJ": [
      "bh-uRFMAAAAJ",
      "Y8O9N_0AAAAJ",
      "bo0P2qYAAAAJ",
      "dusV5HMAAAAJ",
      "-XCiamcAAAAJ",
      "0mgEF28AAAAJ",
      "i38QlUwAAAAJ",
      "r1Fn_YsAAAAJ",
      "NbVgjv0AAAAJ",
      "b-o1o7cAAAAJ",
      "rEL4-fgAAAAJ",
      "3kDtybgAAAAJ",
      "Q8iay0gAAAAJ",
      "rTw-pq0AAAAJ",
      "OttawxUAAAAJ",
      "8R35rCwAAAAJ",
      "WvtCacIAAAAJ",
      "j_xavDQAAAAJ",
      "vtwH6GkAAAAJ",
      "R6jE0VEAAAAJ",
      "vOLXDDAAAAAJ",
      "7oepLUoAAAAJ"
    ],
    "hiOfejkAAAAJ": [],
    "SOt7sr4AAAAJ": [],
    "_TkfqdgAAAAJ": [
      "84WzBlYAAAAJ",
      "71rdofMAAAAJ",
      "KyPheRMAAAAJ",
      "j5N3bKYAAAAJ",
      "v8JEPFgAAAAJ",
      "POlWWAsAAAAJ",
      "1rV69hMAAAAJ",
      "uf0D-uoAAAAJ",
      "YTokrfkAAAAJ",
      "nLnKIikAAAAJ",
      "JCrug-YAAAAJ",
      "aO8KpGcAAAAJ",
      "yxUduqMAAAAJ",
      "iyDxq0EAAAAJ",
      "fmwchbsAAAAJ",
      "kwnwhrgAAAAJ",
      "VqP_wnMAAAAJ"
    ],
    "8m8taGEAAAAJ": [],
    "9xDADY4AAAAJ": [
      "bh-uRFMAAAAJ",
      "mqpjAt4AAAAJ",
      "nABXo3sAAAAJ",
      "nXBQn7gAAAAJ",
      "UfbuDH8AAAAJ",
      "TmWYBeEAAAAJ",
      "2X0cwhkAAAAJ",
      "66lkylsAAAAJ",
      "3kDtybgAAAAJ",
      "xt3XLjcAAAAJ",
      "eml8HfQAAAAJ",
      "KzSKtNUAAAAJ",
      "pvyI8GkAAAAJ",
      "gYiCq88AAAAJ",
      "UsqNPH4AAAAJ",
      "p9RsPG4AAAAJ",
      "reUYd_0AAAAJ",
      "okcbLqoAAAAJ",
      "4V1nNm4AAAAJ",
      "Z4Y5S2oAAAAJ",
      "L4yEk2UAAAAJ",
      "rTw-pq0AAAAJ",
      "1xEHKjoAAAAJ",
      "GHpxNQIAAAAJ",
      "2ItLnFgAAAAJ",
      "Q8iay0gAAAAJ",
      "DplAah0AAAAJ",
      "dnZ8udEAAAAJ",
      "pfGI-KcAAAAJ",
      "AbzGfgoAAAAJ",
      "N_rVVG8AAAAJ",
      "skSqdYsAAAAJ",
      "mu5Y2rYAAAAJ",
      "TkVHKDgAAAAJ",
      "1Q4R-hIAAAAJ",
      "-GnCn1MAAAAJ",
      "kCYbVq0AAAAJ",
      "hHkuxSUAAAAJ",
      "ROILf3EAAAAJ",
      "UdpacsMAAAAJ",
      "d97bGd8AAAAJ",
      "8R35rCwAAAAJ",
      "vfPE6hgAAAAJ",
      "k8rlJ8AAAAAJ",
      "APgaFK0AAAAJ",
      "t2eNzb8AAAAJ",
      "VKbBIIoAAAAJ",
      "P2mG6rcAAAAJ",
      "sJDqACEAAAAJ",
      "ijmuZ0wAAAAJ",
      "1c5IZ0QAAAAJ",
      "t1UaPDgAAAAJ",
      "eLFhiSYAAAAJ",
      "W8VIEZgAAAAJ",
      "vtwH6GkAAAAJ",
      "Ivot3fkAAAAJ",
      "EuFF9kUAAAAJ",
      "jktWnL8AAAAJ",
      "oizZKrsAAAAJ",
      "18O0OAwAAAAJ",
      "AEsPCAUAAAAJ",
      "8BeTDr0AAAAJ",
      "5Iqe53IAAAAJ",
      "uqWkLzMAAAAJ",
      "0v5utcwAAAAJ",
      "6IQ8pQwAAAAJ",
      "U9zz4E0AAAAJ",
      "56EZh6YAAAAJ",
      "JepH3ckAAAAJ",
      "GADXPDcAAAAJ",
      "hqNhUCYAAAAJ",
      "Jp6Mz1sAAAAJ",
      "KFhCWUcAAAAJ",
      "4GTpCxcAAAAJ",
      "-yZse64AAAAJ",
      "rDfyQnIAAAAJ",
      "QP3QawMAAAAJ",
      "pihccVkAAAAJ",
      "O9hYMUUAAAAJ",
      "74THEUoAAAAJ"
    ],
    "HaN8b2YAAAAJ": [
      "e8Gzgo4AAAAJ",
      "6JZ3R6wAAAAJ",
      "FuGllAwAAAAJ",
      "aM3i_9oAAAAJ",
      "0CQMPB0AAAAJ",
      "0Qr2IGwAAAAJ",
      "Rqy5KDEAAAAJ",
      "_8DDVkAAAAAJ",
      "AEKT17QAAAAJ",
      "Wnxq0mgAAAAJ",
      "7BHxn_4AAAAJ",
      "WHelTd0AAAAJ",
      "6S0sCwgAAAAJ",
      "AlTQrFcAAAAJ",
      "vN-is70AAAAJ",
      "T3jkUBwAAAAJ",
      "YCoLskoAAAAJ",
      "2vQRGrYAAAAJ",
      "gQOKAggAAAAJ"
    ],
    "ZWH5jCwAAAAJ": [],
    "ADkiClQAAAAJ": [
      "8R35rCwAAAAJ",
      "yy0UFOwAAAAJ",
      "YGQs1AYAAAAJ",
      "0nPi5YYAAAAJ",
      "NSWI3OwAAAAJ",
      "lRUi-A8AAAAJ",
      "vfPE6hgAAAAJ",
      "cXT3p6cAAAAJ",
      "YfPA4YsAAAAJ",
      "DqXsbPAAAAAJ",
      "sCTJI-0AAAAJ",
      "DMTuJzAAAAAJ",
      "T7uctwYAAAAJ",
      "jrfFYAIAAAAJ",
      "Y7aNyh8AAAAJ",
      "-w5DuHgAAAAJ",
      "rmAcDNkAAAAJ",
      "LuA1j4oAAAAJ",
      "ZaJEZpYAAAAJ",
      "-kIVAcAAAAAJ"
    ],
    "BgQkdsYAAAAJ": [
      "aO8KpGcAAAAJ",
      "2oy3OXYAAAAJ",
      "IB_jPZ0AAAAJ",
      "iyDxq0EAAAAJ",
      "0mgEF28AAAAJ",
      "B96GkdgAAAAJ",
      "UE9jz_MAAAAJ",
      "_X0f2QMAAAAJ",
      "mDtSdp0AAAAJ"
    ],
    "IzUjvBYAAAAJ": [
      "kmgzPeQAAAAJ",
      "Fks4s-wAAAAJ"
    ],
    "U_Jw8DUAAAAJ": [
      "0nPi5YYAAAAJ",
      "EPfOJwQAAAAJ",
      "YfPA4YsAAAAJ",
      "8R35rCwAAAAJ",
      "KsocBp8AAAAJ",
      "MVGcpRsAAAAJ",
      "q7nFtUcAAAAJ",
      "cXT3p6cAAAAJ",
      "WLN3QrAAAAAJ",
      "elmWdycAAAAJ",
      "LIJQ_ZYAAAAJ",
      "UZ5wscMAAAAJ",
      "yy0UFOwAAAAJ",
      "pqP5_PgAAAAJ",
      "0ncQNL8AAAAJ",
      "EC4o-1oAAAAJ",
      "Vzr1RukAAAAJ",
      "ADkiClQAAAAJ",
      "PTS2AOgAAAAJ",
      "AZILAMsAAAAJ",
      "TGRPKRIAAAAJ",
      "-w5DuHgAAAAJ",
      "0tLCTHYAAAAJ",
      "MxxZkEcAAAAJ",
      "6GdwHssAAAAJ",
      "C-ZlBWMAAAAJ",
      "tWoesqcAAAAJ",
      "7c1B_fIAAAAJ",
      "K29Sv1EAAAAJ",
      "rQTHsloAAAAJ",
      "6rl-XhwAAAAJ",
      "T7uctwYAAAAJ",
      "7KDSCpQAAAAJ",
      "NSWI3OwAAAAJ",
      "_AoZDGEAAAAJ",
      "6Hk7QdkAAAAJ",
      "-c8JCbUAAAAJ",
      "T6PbwPIAAAAJ",
      "GRMMc_MAAAAJ",
      "Z3dxz9IAAAAJ",
      "LHvso9QAAAAJ",
      "Wd8_fOcAAAAJ",
      "YCPycGAAAAAJ",
      "28sDUWIAAAAJ",
      "lECZKZsAAAAJ",
      "eIWg8NMAAAAJ",
      "z76PBfYAAAAJ",
      "D4Z3yrwAAAAJ",
      "L4bNmsMAAAAJ",
      "uRlPu-4AAAAJ",
      "sI0DsP8AAAAJ",
      "rO13CwYAAAAJ",
      "LLnrH8IAAAAJ",
      "ZaJEZpYAAAAJ",
      "8qHnRnsAAAAJ",
      "GgQ9GEkAAAAJ",
      "IjJXgWAa708C",
      "rjnJnEkAAAAJ",
      "vfPE6hgAAAAJ",
      "2IXVwTMAAAAJ",
      "Lncr-VoAAAAJ",
      "DTNZMGAAAAAJ",
      "Db4BCX8AAAAJ",
      "PUeKU8kAAAAJ",
      "8fztli4AAAAJ",
      "ECHSnpYAAAAJ",
      "E_82W3EAAAAJ",
      "DqXsbPAAAAAJ",
      "vtwH6GkAAAAJ",
      "xaQuPloAAAAJ",
      "NLOh3SUAAAAJ",
      "NaxShlcAAAAJ",
      "UQBRs7EAAAAJ",
      "0eQjcEEAAAAJ",
      "jrfFYAIAAAAJ",
      "yFEHsv4AAAAJ",
      "d5y4iKAAAAAJ",
      "y_sLoXoAAAAJ",
      "wUUxGfAAAAAJ",
      "dFdEHskAAAAJ",
      "DRnOvU8AAAAJ",
      "GuU6oA4AAAAJ",
      "Nuw1Y4oAAAAJ",
      "zp8V7ZMAAAAJ",
      "cZzmemAAAAAJ",
      "1bF2s2kAAAAJ",
      "C_AP8XAAAAAJ",
      "iyEuK8kAAAAJ",
      "Lc9GwgwAAAAJ",
      "Craj5M0AAAAJ",
      "DZ-fHPgAAAAJ",
      "9MjZO8wAAAAJ",
      "rRJ9wTJMUB8C",
      "IcasIiwAAAAJ"
    ],
    "UnEHCNkAAAAJ": [],
    "KgZxzjsAAAAJ": [],
    "5Iqe53IAAAAJ": [
      "xjnef1AAAAAJ",
      "oAD8PrkAAAAJ",
      "ygFAcZwAAAAJ",
      "rR96kW0AAAAJ",
      "mG4imMEAAAAJ",
      "Y8-xGncAAAAJ",
      "YvdzeM8AAAAJ",
      "U_EaAcgAAAAJ",
      "FsBCAfgAAAAJ",
      "b-GJ3QIAAAAJ",
      "T04c3fwAAAAJ",
      "2oy3OXYAAAAJ",
      "DpLFv4gAAAAJ",
      "jzsx52EAAAAJ",
      "BfmcfEAAAAAJ",
      "wVGqmWkAAAAJ",
      "qWak04oAAAAJ",
      "yPOT9K0AAAAJ",
      "IzhtPq4AAAAJ",
      "ZasL8IoAAAAJ",
      "vtwH6GkAAAAJ",
      "qioqafgAAAAJ",
      "c4Gcje4AAAAJ",
      "Wk2gAZUAAAAJ",
      "XtMdGSkAAAAJ",
      "FZLHMv8AAAAJ",
      "aJOeGRoAAAAJ",
      "kEOeI2gAAAAJ",
      "117h3CAAAAAJ",
      "rDfyQnIAAAAJ",
      "V8GEfeAAAAAJ",
      "LMtE3FQAAAAJ",
      "6T1qA5AAAAAJ",
      "0uTu7fYAAAAJ",
      "hzPq7jUAAAAJ",
      "Yy4QD_AAAAAJ",
      "wP0IgaAAAAAJ",
      "nBL0J6kAAAAJ",
      "BDYIAe4AAAAJ",
      "-qFe-7wAAAAJ",
      "3ifikJ0AAAAJ",
      "YY7Rql4AAAAJ",
      "9xbbxGcAAAAJ",
      "OsarV_4AAAAJ",
      "uX9yGmAAAAAJ",
      "opBkPOgAAAAJ",
      "3yJr9q4AAAAJ",
      "GljRwkUAAAAJ",
      "staYplUAAAAJ",
      "SdiAQPQAAAAJ",
      "0BQzlisAAAAJ",
      "fpT49d8AAAAJ",
      "dGPqP-wAAAAJ",
      "SfDzdgEAAAAJ",
      "n1e6LlcAAAAJ",
      "SD46w90AAAAJ",
      "XunnVQoAAAAJ",
      "_JFStaIAAAAJ",
      "cXkm3rsAAAAJ",
      "ycTTxNUAAAAJ",
      "D-SlUjsAAAAJ",
      "UbWVW6sAAAAJ",
      "vQwDZR8AAAAJ",
      "BFWurDEAAAAJ"
    ],
    "wb-DKCIAAAAJ": [
      "Bp6tvy0AAAAJ",
      "HDzOsYAAAAAJ",
      "mim8FQkAAAAJ",
      "MVxcjEoAAAAJ",
      "bEcLezcAAAAJ",
      "LurWtuYAAAAJ",
      "qYhRbJoAAAAJ",
      "LFiqVpwAAAAJ",
      "GINhGvwAAAAJ",
      "9nnDvooAAAAJ",
      "GR_DsT0AAAAJ",
      "SWqd2rgAAAAJ",
      "_30hSU8AAAAJ",
      "V-lc8A8AAAAJ",
      "ttbl4FsAAAAJ",
      "eDHv58AAAAAJ",
      "K0kaNvkAAAAJ",
      "_EJrRVAAAAAJ",
      "sXtjq8IAAAAJ",
      "jeOFRDsAAAAJ",
      "I15dUOwAAAAJ",
      "OttawxUAAAAJ",
      "qULx8g8AAAAJ",
      "Zqz4CQoAAAAJ",
      "LnhCGNMAAAAJ",
      "OEJUgwkAAAAJ",
      "xUUEAG4AAAAJ",
      "nIWUhXAAAAAJ",
      "iOLC30YAAAAJ",
      "yCyR-TsAAAAJ",
      "nX9D5AoAAAAJ",
      "eWfiq9MAAAAJ",
      "8iQk0DIAAAAJ",
      "yxUduqMAAAAJ",
      "umivlPQAAAAJ",
      "z-KILD8AAAAJ",
      "ejsX7D0AAAAJ",
      "8R35rCwAAAAJ",
      "uYVc9koAAAAJ",
      "hYKcn9sAAAAJ",
      "loxOHhoAAAAJ",
      "RsicLQsAAAAJ",
      "qA3IkiwAAAAJ",
      "vfPE6hgAAAAJ",
      "gRxBNZoAAAAJ",
      "Fc-5yRIAAAAJ",
      "PZJIgZUAAAAJ",
      "CgItEbQAAAAJ",
      "fds2VpgAAAAJ",
      "RkuzIZMAAAAJ",
      "vlN_kRoAAAAJ",
      "pdvYP-kAAAAJ",
      "QCBdB7AAAAAJ",
      "DKx4XFkAAAAJ",
      "osxb7aMAAAAJ",
      "yq90c58AAAAJ",
      "Vzr1RukAAAAJ",
      "BxlScrEAAAAJ",
      "kCYbVq0AAAAJ",
      "F_ASWCUAAAAJ",
      "fGZMMKUAAAAJ",
      "mG4imMEAAAAJ",
      "pouyVyUAAAAJ",
      "yQNhFGUAAAAJ",
      "all0DHsAAAAJ",
      "UoATnWEAAAAJ",
      "rjfj_8AAAAAJ",
      "BWADJUkAAAAJ",
      "PqQAVcAAAAAJ",
      "cNSbfGQAAAAJ",
      "Rqy5KDEAAAAJ",
      "Ize17HEAAAAJ",
      "7t4jbPQAAAAJ",
      "3bSbb20AAAAJ",
      "EeYGZCwAAAAJ",
      "ITZ1e7MAAAAJ",
      "Xl4E0CsAAAAJ",
      "vtwH6GkAAAAJ",
      "V2Y1L4sAAAAJ",
      "MhQPCk8AAAAJ",
      "Uauc4m8AAAAJ",
      "9B8PoXUAAAAJ",
      "UK-VpDoAAAAJ",
      "AGnp8NAAAAAJ",
      "kUe1sZEAAAAJ",
      "y-nUzMwAAAAJ",
      "EpT5sLAAAAAJ",
      "O-DazBUAAAAJ",
      "39JcQcEAAAAJ",
      "vu5Mw_0AAAAJ",
      "KCiDjbkAAAAJ",
      "8S0L-q8AAAAJ",
      "7HCKL10AAAAJ",
      "qVaQXcoAAAAJ"
    ],
    "tcfl2hUAAAAJ": [
      "84WzBlYAAAAJ",
      "wtK4Yh4AAAAJ",
      "8R35rCwAAAAJ",
      "vtwH6GkAAAAJ",
      "vYougn0AAAAJ",
      "SgST3LkAAAAJ",
      "dD7EpwQAAAAJ",
      "d4W1UT0AAAAJ"
    ],
    "_koixUEAAAAJ": [
      "UdaJi94AAAAJ",
      "dYwbc9sAAAAJ",
      "_QUUb-gAAAAJ",
      "H-A5KBYAAAAJ",
      "LW1Kw4EAAAAJ",
      "WKM_BdYAAAAJ",
      "pouyVyUAAAAJ",
      "XUI4PMEAAAAJ",
      "xsmFT2UAAAAJ",
      "UZNEAF4AAAAJ",
      "KjZluVoAAAAJ",
      "KH3jpkoAAAAJ",
      "oC7EgKQAAAAJ",
      "ZpG_cJwAAAAJ",
      "lTmDo34AAAAJ",
      "AlIkUSAAAAAJ",
      "HaN8b2YAAAAJ",
      "hubUU3AAAAAJ",
      "hiGI9v0AAAAJ",
      "duBlF_YAAAAJ",
      "tQVe-fAAAAAJ",
      "aGvH4yMAAAAJ",
      "zVSwZIAAAAAJ",
      "LKv32bgAAAAJ",
      "hGO6cWYAAAAJ",
      "DHSivXEAAAAJ",
      "-lKb3XwAAAAJ",
      "CgItEbQAAAAJ",
      "G77y978AAAAJ",
      "X2OmK_4AAAAJ"
    ],
    "CgItEbQAAAAJ": [],
    "zFNvU34AAAAJ": [],
    "Wd8_fOcAAAAJ": [
      "YjS546oAAAAJ",
      "1CPY1LsAAAAJ",
      "U_Jw8DUAAAAJ",
      "Sc7qOfcAAAAJ",
      "i5FMLA4AAAAJ",
      "oOhnPUgAAAAJ",
      "vN-is70AAAAJ",
      "B96GkdgAAAAJ",
      "5kVcNS4AAAAJ",
      "TPhVfX8AAAAJ",
      "S2Pk9ooAAAAJ"
    ],
    "Q6F3O0sAAAAJ": [
      "neGbgzYAAAAJ",
      "8R35rCwAAAAJ",
      "i28fU0MAAAAJ",
      "VT7peyEAAAAJ",
      "0dz0hyQAAAAJ",
      "1bF2s2kAAAAJ",
      "OpFFE3cAAAAJ",
      "H8FJlJoAAAAJ",
      "Q_4d9N0AAAAJ"
    ],
    "f2NAF7QAAAAJ": [
      "8R35rCwAAAAJ",
      "SJoRNbYAAAAJ",
      "_0IIzxgAAAAJ",
      "vfPE6hgAAAAJ",
      "1wLVDP4AAAAJ",
      "2IXVwTMAAAAJ",
      "3oe0I0QAAAAJ",
      "dJj3vR4AAAAJ",
      "KUc7JJoAAAAJ",
      "GyoKzFwAAAAJ",
      "YGQs1AYAAAAJ",
      "DLzuuVoAAAAJ",
      "Zau87Y0AAAAJ",
      "ckZ7q_gAAAAJ",
      "c_jPvP4AAAAJ"
    ],
    "rRJ9wTJMUB8C": [
      "UAwKvEsAAAAJ",
      "2efgcS0AAAAJ",
      "OUpIbcQAAAAJ",
      "5SF-hRsAAAAJ",
      "8cxDHS4AAAAJ",
      "Zbo61UMAAAAJ",
      "0zZnyMEAAAAJ",
      "-Txt8vsAAAAJ",
      "0HuMHFwAAAAJ",
      "SZ3_FMQAAAAJ",
      "vspmOX8AAAAJ",
      "bTdT7hAAAAAJ",
      "SACXQKYAAAAJ",
      "8BX3BokAAAAJ",
      "kpcjFekAAAAJ",
      "d0TfP8EAAAAJ",
      "ITZ1e7MAAAAJ",
      "a_OQrYoAAAAJ",
      "3hdOFF0AAAAJ",
      "lsiZ9CsAAAAJ",
      "rrPyvsgAAAAJ",
      "pH1PDwYAAAAJ",
      "szUb_isAAAAJ",
      "dErAioMAAAAJ",
      "3pyzQQ8AAAAJ",
      "4MrZ9zMAAAAJ",
      "nQ7Ij30AAAAJ",
      "2ylcZSsAAAAJ",
      "MiFqJGcAAAAJ",
      "LFiqVpwAAAAJ",
      "2tt6ZJ0AAAAJ",
      "zykJTC4AAAAJ",
      "Olalwx8AAAAJ",
      "vA6ZQ_AAAAAJ",
      "zjl9R-oAAAAJ",
      "HUi6F7wAAAAJ",
      "ZLpO3XQAAAAJ",
      "8OYE6iEAAAAJ",
      "xgQd1qgAAAAJ",
      "g42kJfIAAAAJ"
    ],
    "9yRwkr4AAAAJ": [
      "RffbjzgAAAAJ",
      "ejoWKqsAAAAJ",
      "hgUGouQAAAAJ",
      "k-nF0qgAAAAJ",
      "zwr9wPEAAAAJ",
      "d96wNhsAAAAJ",
      "RNC-GC0AAAAJ",
      "Ik6TGDAAAAAJ",
      "AGaoCGAAAAAJ",
      "uL7NxA4AAAAJ",
      "OlpYP3UAAAAJ",
      "gFAjt2kAAAAJ",
      "edUsNYIAAAAJ",
      "NmlzwEMAAAAJ",
      "iT366TkAAAAJ",
      "ObdsXj8AAAAJ",
      "206DEM0AAAAJ",
      "ORJ4d3UAAAAJ",
      "ekIw7HQAAAAJ",
      "a4unsk4AAAAJ",
      "AJKKzMAAAAAJ",
      "fYarJtcAAAAJ",
      "Ffwbco4AAAAJ",
      "PogsVkYAAAAJ",
      "tjT7-uAAAAAJ",
      "aYEVCBwAAAAJ",
      "EzQdShoAAAAJ",
      "BqtGVowAAAAJ",
      "vyD4QMUAAAAJ",
      "rSMPsx4AAAAJ"
    ],
    "RU0ZAp4AAAAJ": [
      "nTiSnwUAAAAJ",
      "t1u0f5QAAAAJ",
      "8gEhRVgAAAAJ",
      "-mh8RQ8AAAAJ",
      "-SuHe48AAAAJ",
      "ogXTOZ4AAAAJ",
      "ifK5o2UAAAAJ",
      "LG_E-4EAAAAJ",
      "FXiSi-4AAAAJ",
      "aO8KpGcAAAAJ"
    ],
    "czyretsAAAAJ": [
      "84WzBlYAAAAJ",
      "LKv32bgAAAAJ",
      "kDHs7DYAAAAJ",
      "09kJn28AAAAJ"
    ],
    "r44N6h8AAAAJ": [
      "zghjmDgAAAAJ",
      "G1WMpcUAAAAJ",
      "RiLCRDwAAAAJ",
      "UnEHCNkAAAAJ",
      "g65nv5cAAAAJ",
      "AdAd4QIAAAAJ",
      "INd48rQAAAAJ",
      "7fQYGjcAAAAJ",
      "h6jljQQAAAAJ",
      "zXQZPnMAAAAJ",
      "xGbDr7YAAAAJ",
      "HriWXcEAAAAJ",
      "nbZ6QlsAAAAJ",
      "agcYx2YAAAAJ",
      "umFQktIAAAAJ",
      "Znp3UkEAAAAJ",
      "GMZYUyQAAAAJ",
      "t9iq5TwAAAAJ",
      "gnlvP_sAAAAJ"
    ],
    "N_rVVG8AAAAJ": [],
    "yyIoQu4AAAAJ": [
      "ymzxRhAAAAAJ",
      "8200InoAAAAJ",
      "w68-7AYAAAAJ",
      "0pOgVVAAAAAJ",
      "i5FMLA4AAAAJ",
      "ogXTOZ4AAAAJ",
      "o_J2CroAAAAJ",
      "-3zYIjQAAAAJ",
      "5tVuggUAAAAJ",
      "VdlgOXoAAAAJ",
      "iVLAQysAAAAJ",
      "6vghMS0AAAAJ",
      "x04W_mMAAAAJ",
      "cIlDEugAAAAJ",
      "rvW4j38AAAAJ",
      "WLN3QrAAAAAJ",
      "UnrY-40AAAAJ",
      "MBM_oOUAAAAJ",
      "ppYWVlYAAAAJ",
      "xrSUChoAAAAJ",
      "7k_1QFIAAAAJ",
      "vtwH6GkAAAAJ",
      "itSa94cAAAAJ",
      "EMDboA4AAAAJ",
      "8R35rCwAAAAJ",
      "wfGiqXEAAAAJ",
      "3Y4egcYAAAAJ",
      "h7OHSkoAAAAJ",
      "vfPE6hgAAAAJ",
      "nEFU7wIAAAAJ",
      "ygdQhrIAAAAJ",
      "dOad5HoAAAAJ",
      "sRId4vsAAAAJ",
      "2r2NuDAAAAAJ",
      "7ov4UekAAAAJ",
      "8osGCyAAAAAJ",
      "fHsIRb0AAAAJ",
      "WA86ONsAAAAJ",
      "wLsZd9wAAAAJ",
      "_VhMIOIAAAAJ",
      "sIfE5HIAAAAJ",
      "k_u5ULgAAAAJ",
      "njOmQFsAAAAJ",
      "dHUiyDkAAAAJ",
      "zTy9cUwAAAAJ",
      "MxxZkEcAAAAJ",
      "9GJn5FIAAAAJ",
      "kTZ5VE0AAAAJ",
      "7jZjfZ8AAAAJ",
      "C7zfAI4AAAAJ",
      "HBztuGIAAAAJ",
      "iYN86KEAAAAJ",
      "XCZpOcAAAAAJ",
      "XQJN7dsAAAAJ",
      "kGODZaIAAAAJ",
      "Lncr-VoAAAAJ",
      "rBH-cpMAAAAJ",
      "JApued4AAAAJ",
      "Nla9qfUAAAAJ"
    ],
    "slQp6UYAAAAJ": [],
    "zXhuhtwAAAAJ": [
      "P4nfoKYAAAAJ",
      "bh-uRFMAAAAJ",
      "wh_eLqQAAAAJ",
      "MpJ00PUAAAAJ",
      "qr8Vo9IAAAAJ",
      "VpB8NZ8AAAAJ",
      "lc0ARagAAAAJ",
      "knzWGD4AAAAJ",
      "_1basdkAAAAJ",
      "cYkxyg0AAAAJ",
      "uCZ7fPUAAAAJ",
      "x3hvdTsAAAAJ",
      "rynvwScAAAAJ",
      "VJlCMGYAAAAJ"
    ],
    "GHpxNQIAAAAJ": [
      "bh-uRFMAAAAJ",
      "3kDtybgAAAAJ",
      "z76PBfYAAAAJ",
      "_kJ-zUYAAAAJ",
      "9xDADY4AAAAJ",
      "pvyI8GkAAAAJ",
      "jQl9RtkAAAAJ",
      "rTw-pq0AAAAJ",
      "N_rVVG8AAAAJ",
      "9uWuZkUAAAAJ",
      "5JserkUAAAAJ",
      "L__n1LUAAAAJ",
      "6Q-289IAAAAJ",
      "sJDqACEAAAAJ",
      "BCKhEoAAAAAJ",
      "j88h_roAAAAJ",
      "LAv0HTEAAAAJ",
      "-x3wvW8AAAAJ",
      "X0EXfT8AAAAJ",
      "4YL23GMAAAAJ",
      "hD2WqqcAAAAJ",
      "1ScWJOoAAAAJ",
      "km6CP8cAAAAJ",
      "B96GkdgAAAAJ",
      "KWD-mmoAAAAJ",
      "LX2QWBYAAAAJ",
      "8CVIK-UAAAAJ",
      "XpscC-EAAAAJ"
    ],
    "BOAOkNQAAAAJ": [],
    "e9gUdKwAAAAJ": [],
    "DkUUhXEAAAAJ": [],
    "xEWgxBsAAAAJ": [],
    "4V1nNm4AAAAJ": [],
    "xdGKgtcAAAAJ": [
      "PkfChMgAAAAJ",
      "vN-is70AAAAJ",
      "GXJqtYUAAAAJ",
      "Wj4ZBFIAAAAJ",
      "0VwIiIsAAAAJ",
      "cYReSuEAAAAJ",
      "Bl8GgEcAAAAJ",
      "00M1AqQAAAAJ",
      "I1EvjZsAAAAJ",
      "h1XZv94AAAAJ",
      "QYsnk-cAAAAJ",
      "hMG_gR4AAAAJ",
      "GUAoEcAAAAAJ",
      "BItCgjYAAAAJ",
      "jZCCpsIAAAAJ",
      "yxUduqMAAAAJ",
      "WemX9rAAAAAJ",
      "YCoLskoAAAAJ",
      "BbzYzsgAAAAJ",
      "qj3IRU8AAAAJ",
      "uFJi3IUAAAAJ",
      "B96GkdgAAAAJ",
      "urTiL7QAAAAJ",
      "YsXNU78AAAAJ",
      "u4epKYoAAAAJ",
      "Az7XqxQAAAAJ",
      "62Uqu6wAAAAJ",
      "mXJHzYkAAAAJ",
      "Ba_Ci9UAAAAJ",
      "qhu-DxwAAAAJ",
      "KgZxzjsAAAAJ",
      "BYSy-9oAAAAJ",
      "E-rCbqQAAAAJ",
      "hYtGXD0AAAAJ",
      "N7kzlPoAAAAJ",
      "7CohtIMAAAAJ",
      "8fztli4AAAAJ",
      "sNeVyqoAAAAJ",
      "cUkE7OgAAAAJ",
      "lMAcwtwAAAAJ",
      "WXbhp_4AAAAJ",
      "QXyvv94AAAAJ",
      "84WzBlYAAAAJ",
      "BOGdPa8AAAAJ",
      "QZCU3NkAAAAJ",
      "1VHwJz0AAAAJ",
      "bZNRLNAAAAAJ",
      "MnsxqAcAAAAJ",
      "3m1zllIAAAAJ",
      "2aqrWocAAAAJ",
      "csgUXLsAAAAJ",
      "p0L7kOkAAAAJ",
      "p0sQC6sAAAAJ",
      "wsYTsIsAAAAJ",
      "6Ex1MMYAAAAJ",
      "bqKW7NkAAAAJ",
      "yQNhFGUAAAAJ",
      "1gQvWvUAAAAJ",
      "g-WedwYAAAAJ",
      "sQ8u6h4AAAAJ",
      "vth4SIcAAAAJ",
      "2oclnIwAAAAJ",
      "HvwPRJ0AAAAJ",
      "iX1CFmYAAAAJ",
      "e4I7ihkAAAAJ",
      "sCypmFAAAAAJ",
      "HHn7118AAAAJ",
      "98iA_ooAAAAJ",
      "wgNML_UAAAAJ",
      "DDVtnHEAAAAJ",
      "oQsObk0AAAAJ",
      "_K0GfAoAAAAJ",
      "3OdbrfMAAAAJ",
      "ox3inugAAAAJ",
      "NnEMWJsAAAAJ",
      "FsbND-sAAAAJ",
      "zOKOeG4AAAAJ",
      "3jzgrIcAAAAJ",
      "0zrqo3B-66wC",
      "yVLaR1QAAAAJ",
      "-1fU6P0AAAAJ",
      "S2OjOvYAAAAJ",
      "ZFGMQsEAAAAJ",
      "zxzZAi0AAAAJ"
    ],
    "gQpYbRsAAAAJ": [],
    "hHkuxSUAAAAJ": [
      "UdpacsMAAAAJ",
      "d97bGd8AAAAJ",
      "LW8ze_UAAAAJ",
      "ROILf3EAAAAJ",
      "B_FTboQAAAAJ",
      "y-f-MZgAAAAJ",
      "ajXAb54AAAAJ",
      "mqpjAt4AAAAJ",
      "bh-uRFMAAAAJ",
      "nABXo3sAAAAJ",
      "9xDADY4AAAAJ",
      "0B8uuBkAAAAJ",
      "8R35rCwAAAAJ"
    ],
    "szDNg-0AAAAJ": [],
    "p1DZVX8AAAAJ": [
      "yxUduqMAAAAJ",
      "i5srt20AAAAJ",
      "xT19Jc0AAAAJ",
      "XYy_Nm4AAAAJ",
      "3p-KQUwAAAAJ",
      "Q4DTPw4AAAAJ",
      "yQNhFGUAAAAJ",
      "DcV-5RAAAAAJ",
      "9nnDvooAAAAJ",
      "MplR7_cAAAAJ",
      "JSFmVQEAAAAJ",
      "Az7XqxQAAAAJ",
      "o7yFQXUAAAAJ",
      "Ao4gtsYAAAAJ",
      "j-2RtWUAAAAJ",
      "MAs0vOwAAAAJ",
      "IdSxI0YAAAAJ",
      "QEqPllIAAAAJ",
      "BF39lMQAAAAJ",
      "cht-q2UAAAAJ",
      "3bwC_f4AAAAJ",
      "9ehX_58AAAAJ",
      "ZvFaPxUAAAAJ",
      "aSAS-aAAAAAJ",
      "tkDsIggAAAAJ",
      "ZpG_cJwAAAAJ",
      "239ZfwgAAAAJ",
      "lIKPJ04AAAAJ",
      "D2K-ADYAAAAJ",
      "nq7tuDkAAAAJ",
      "xRmmtzIAAAAJ",
      "oO9-6xEAAAAJ",
      "tQVe-fAAAAAJ",
      "2vQRGrYAAAAJ",
      "BfDKicQAAAAJ",
      "cHDBzPcAAAAJ",
      "8jAftjUAAAAJ",
      "ePiPQ2cAAAAJ",
      "fsbXdAYAAAAJ",
      "Xs7cKMwAAAAJ",
      "izZZAegAAAAJ",
      "Py_StfUAAAAJ",
      "I5jS8ccAAAAJ",
      "Xl4E0CsAAAAJ",
      "uplepqQAAAAJ",
      "FY_UnPAAAAAJ",
      "ewdbG-IAAAAJ",
      "qX06pRYAAAAJ",
      "lEls5I8AAAAJ",
      "4zyy7esAAAAJ",
      "jgr1-eEAAAAJ",
      "n6egtH4AAAAJ",
      "ffdt7gMAAAAJ",
      "mtB5szIAAAAJ",
      "xd1bW3AAAAAJ",
      "ZWV0I7cAAAAJ",
      "IB_jPZ0AAAAJ",
      "M7y1dj8AAAAJ",
      "X-Sd3-8AAAAJ",
      "cHN3PVYAAAAJ",
      "T99vQCsAAAAJ",
      "1I0ff2cAAAAJ",
      "7nVGYfgAAAAJ",
      "ze5rCdwAAAAJ",
      "5rz6jiUAAAAJ",
      "fHkUYk0AAAAJ",
      "5cg_wrUAAAAJ",
      "CjRMyA4AAAAJ",
      "LZacO0sAAAAJ",
      "k5HsbdcAAAAJ",
      "GR_DsT0AAAAJ",
      "3prQpXgAAAAJ",
      "OkOGR_8AAAAJ",
      "5t2myD8AAAAJ",
      "VVz2wdwAAAAJ",
      "GINhGvwAAAAJ",
      "8AXJB5QAAAAJ",
      "54bOCmQAAAAJ",
      "2KQlie4AAAAJ",
      "r1cF30oAAAAJ",
      "qqgDCDIAAAAJ",
      "BBGlIGQAAAAJ",
      "HaN8b2YAAAAJ",
      "x7cbdTcAAAAJ",
      "c0yPSEYAAAAJ",
      "r49_E2cAAAAJ",
      "lg1fT1kAAAAJ",
      "Oa3Aze8AAAAJ",
      "33yNvIgAAAAJ",
      "pouyVyUAAAAJ",
      "dq3yXjkAAAAJ",
      "XbjOzyQAAAAJ",
      "iTv2cOgAAAAJ",
      "K4t4Rq0AAAAJ",
      "KwjvGLUAAAAJ",
      "KgZxzjsAAAAJ",
      "_21CagYAAAAJ",
      "yYE8Xo8AAAAJ",
      "iyDxq0EAAAAJ",
      "aO8KpGcAAAAJ",
      "KNiO4pwAAAAJ",
      "a_dbdxAAAAAJ",
      "Djtri0kAAAAJ",
      "24Ke6Q8AAAAJ",
      "erv7TP0AAAAJ",
      "fkDxJxcAAAAJ",
      "b1y1LooAAAAJ",
      "g_aM9xcAAAAJ",
      "4806CYgAAAAJ",
      "UgHB5oAAAAAJ",
      "tb2aY4kAAAAJ",
      "vK0-CDcAAAAJ",
      "3r-fWJwAAAAJ",
      "Om4Lag0AAAAJ",
      "GoarRRwAAAAJ"
    ],
    "wORhZLMAAAAJ": [
      "If8AWhgAAAAJ",
      "yaSMILkAAAAJ",
      "UgHB5oAAAAAJ",
      "bHFAmtgAAAAJ",
      "G-xTgkgAAAAJ",
      "t64GpvUAAAAJ",
      "AF6kWHUAAAAJ",
      "ydA8Q5AAAAAJ",
      "ICCMAZ8AAAAJ",
      "2GJDqawAAAAJ",
      "jpq33DsAAAAJ"
    ],
    "yxUduqMAAAAJ": [
      "8OYE6iEAAAAJ",
      "0uTu7fYAAAAJ",
      "yQNhFGUAAAAJ",
      "6PJWcFEAAAAJ",
      "_MjXpXkAAAAJ",
      "vN-is70AAAAJ",
      "acmtRMAAAAAJ",
      "Fl7EBc8AAAAJ",
      "Wj4ZBFIAAAAJ",
      "i5srt20AAAAJ",
      "FFWXLHUAAAAJ",
      "a_dbdxAAAAAJ",
      "5pKTRxEAAAAJ",
      "vtwH6GkAAAAJ",
      "dPX0wQcAAAAJ",
      "Az7XqxQAAAAJ",
      "9DXQi8gAAAAJ",
      "ePiPQ2cAAAAJ",
      "8R35rCwAAAAJ",
      "TW7U1W0AAAAJ",
      "2oy3OXYAAAAJ",
      "YM8BRlUAAAAJ",
      "y-nUzMwAAAAJ",
      "h1XZv94AAAAJ",
      "p0sQC6sAAAAJ",
      "OO-2710AAAAJ",
      "XYy_Nm4AAAAJ",
      "iPJvBGYAAAAJ",
      "Bxgu5DQAAAAJ",
      "pouyVyUAAAAJ",
      "GR_DsT0AAAAJ",
      "KgZxzjsAAAAJ",
      "JicYPdAAAAAJ",
      "itSa94cAAAAJ",
      "3vKjkoQAAAAJ",
      "8jAftjUAAAAJ",
      "zP0S_ikAAAAJ",
      "nvR1mBgAAAAJ",
      "rN2ny9kAAAAJ",
      "erv7TP0AAAAJ",
      "ygFAcZwAAAAJ",
      "sV61CtsAAAAJ",
      "9EFobLUAAAAJ",
      "UAwKvEsAAAAJ",
      "nzEluBwAAAAJ",
      "bldHpWIAAAAJ",
      "M5YT8IoAAAAJ",
      "MnfzuPYAAAAJ",
      "r1TJBr8AAAAJ",
      "r31_fYQAAAAJ",
      "plt2_DsAAAAJ",
      "biuxbRsAAAAJ",
      "Zldo9CAAAAAJ",
      "6jN5vScAAAAJ",
      "xdGKgtcAAAAJ",
      "Djtri0kAAAAJ",
      "8RgDBoEAAAAJ",
      "hYtGXD0AAAAJ",
      "fmsV6nEAAAAJ",
      "m1qAiOUAAAAJ",
      "s1_ay2AAAAAJ",
      "qKQD-2cAAAAJ",
      "oejm5IUAAAAJ",
      "u7WiGLQAAAAJ",
      "xe7iyikAAAAJ",
      "PnUH2KUAAAAJ",
      "QCBdB7AAAAAJ",
      "q7FfnjgAAAAJ",
      "_SuhcLEAAAAJ",
      "W4SZGV8AAAAJ",
      "JEEwSlQAAAAJ",
      "gsr-K3ADUvAC",
      "Dav2k7cAAAAJ",
      "DcV-5RAAAAAJ",
      "zZO9qG4AAAAJ",
      "VEGtG7YAAAAJ",
      "BItCgjYAAAAJ",
      "WemX9rAAAAAJ",
      "MxxZkEcAAAAJ",
      "VTGXKrYAAAAJ",
      "6h7b0fAAAAAJ",
      "8iQk0DIAAAAJ",
      "FUqUC2oAAAAJ",
      "bpDPt1QAAAAJ",
      "r3SJcvoAAAAJ",
      "kcsbLrAAAAAJ",
      "rRJ9wTJMUB8C",
      "SD46w90AAAAJ",
      "o5B39L8AAAAJ",
      "uFJi3IUAAAAJ",
      "9e7BtYsAAAAJ",
      "qjJg6akAAAAJ",
      "LTL9MjwAAAAJ",
      "2E448xEAAAAJ",
      "hYi6i9sAAAAJ",
      "okcbLqoAAAAJ",
      "cH0pbIwAAAAJ",
      "V-lc8A8AAAAJ",
      "a1ngrCIAAAAJ",
      "HHd7uewAAAAJ",
      "1UU7Rh8AAAAJ",
      "odMFlXUAAAAJ",
      "1KEMrHkAAAAJ",
      "5H0arvkAAAAJ",
      "fKESO6sAAAAJ",
      "eH_c4R4AAAAJ",
      "pGh242UAAAAJ",
      "I1EvjZsAAAAJ",
      "OsoQ-dcAAAAJ",
      "n1e6LlcAAAAJ",
      "ejWucigAAAAJ",
      "T3hAyLkAAAAJ",
      "OPg56pYAAAAJ",
      "wvQmuxgAAAAJ",
      "WXbhp_4AAAAJ",
      "PkfChMgAAAAJ",
      "Dzh5C9EAAAAJ",
      "grQ_GBgAAAAJ",
      "DKfEcuEAAAAJ",
      "RhtDZvYAAAAJ",
      "ipb9-GEAAAAJ",
      "Yd-SGH8AAAAJ",
      "-p2WHtgAAAAJ",
      "4VVgg_UAAAAJ",
      "lXYKgiYAAAAJ",
      "Zmvi6PMAAAAJ",
      "nPQEV0YAAAAJ",
      "NnEMWJsAAAAJ",
      "bb_q7tYAAAAJ",
      "ri4rEPMAAAAJ",
      "nEsOOx8AAAAJ",
      "jyxO2akAAAAJ",
      "lmjR_qMAAAAJ",
      "9nnDvooAAAAJ",
      "i4_3daEAAAAJ",
      "IvgxG60AAAAJ",
      "WY8DOSMAAAAJ",
      "N-BBA20AAAAJ",
      "ISRNX3gAAAAJ",
      "hlWhzU8AAAAJ",
      "bN_1u58AAAAJ",
      "61k0rBQAAAAJ",
      "bh-uRFMAAAAJ",
      "sgva3HcAAAAJ",
      "iF1M1sIAAAAJ",
      "vRI2blsAAAAJ",
      "A_UWzl8AAAAJ",
      "7HmZizkAAAAJ",
      "QZCU3NkAAAAJ",
      "GUAoEcAAAAAJ",
      "wxauPrwAAAAJ",
      "pGgB_xAAAAAJ",
      "S7YR2MEAAAAJ",
      "V-pBZI8AAAAJ",
      "HAf4pEoAAAAJ",
      "aKkIMogAAAAJ",
      "N5pB4l4AAAAJ",
      "Om4Lag0AAAAJ",
      "hfVm90AAAAAJ",
      "Hs3AnAkAAAAJ",
      "mwpnDOYAAAAJ",
      "64G5UgMAAAAJ",
      "gC5ucdsAAAAJ",
      "UKqIqRsAAAAJ",
      "d3JgIc8AAAAJ",
      "T1iIhDEAAAAJ",
      "T8RB_40AAAAJ",
      "7fONeB0AAAAJ",
      "Yxh9WWoAAAAJ",
      "UwLsYw8AAAAJ",
      "kde_TOYAAAAJ",
      "TLQUwIMAAAAJ",
      "rtWKzFwAAAAJ",
      "keIlGm0AAAAJ",
      "5PBPqeQAAAAJ",
      "94RFSSsAAAAJ",
      "qG1LVpQAAAAJ",
      "AkRWtMUAAAAJ",
      "S2OjOvYAAAAJ",
      "ugSmcnoAAAAJ",
      "Jke3O8QAAAAJ",
      "ZngqplgAAAAJ",
      "7GK8LQMAAAAJ",
      "juUEPSAAAAAJ",
      "NCCdqdcAAAAJ",
      "r1quzEkAAAAJ",
      "EjG2e0QAAAAJ",
      "AY6InkoAAAAJ",
      "udZSrkYAAAAJ",
      "BbzYzsgAAAAJ",
      "XaFT1o4AAAAJ",
      "lc7OkdAAAAAJ"
    ],
    "cl7CnNYAAAAJ": [
      "hRB3wSgAAAAJ",
      "APiItS4AAAAJ",
      "BSrwwfYAAAAJ",
      "2qLY2QwAAAAJ",
      "Bjpb27sAAAAJ",
      "0zQdH0oAAAAJ",
      "By1xdxEAAAAJ",
      "uXUA1pgAAAAJ",
      "huV-_rsAAAAJ",
      "OGYs810AAAAJ",
      "PjAQATEAAAAJ",
      "2YKaNDIAAAAJ",
      "quMILWkAAAAJ",
      "rGS1KaAAAAAJ",
      "lazJixIAAAAJ",
      "umm-i20AAAAJ",
      "B6OXcFoAAAAJ",
      "bs5MttgAAAAJ",
      "gNMqz_4AAAAJ",
      "rldfxOMAAAAJ",
      "WeVsE1AAAAAJ",
      "h1VSH6UAAAAJ",
      "gWBoNCsAAAAJ",
      "mXwpea4AAAAJ",
      "CcqZZqMAAAAJ",
      "knut91AAAAAJ",
      "MAeMisMAAAAJ",
      "QVBIKh4AAAAJ",
      "BST6b8AAAAAJ",
      "hwn3OPIAAAAJ",
      "bYI7VMwAAAAJ",
      "QSY7ufMAAAAJ",
      "9jK5lfsAAAAJ",
      "wIhJS60AAAAJ",
      "edYZTEEAAAAJ",
      "A5vhsIYAAAAJ",
      "Odh4GSYAAAAJ",
      "mSK3340AAAAJ",
      "xrUwjlQAAAAJ",
      "mSvrb54AAAAJ",
      "jPis1roAAAAJ",
      "pneVd2IAAAAJ",
      "-7oupLAAAAAJ",
      "B3C4aY8AAAAJ",
      "1r8HluQAAAAJ",
      "Z6nLCukAAAAJ",
      "qCU8duAAAAAJ",
      "ShYqyygAAAAJ",
      "UO7McmEAAAAJ",
      "1wnZg6UAAAAJ",
      "Z-Wd_x0AAAAJ",
      "V7aWNcoAAAAJ",
      "0_aTa8YAAAAJ",
      "gTWUZlsAAAAJ",
      "3G79TTEAAAAJ",
      "dgNqguIAAAAJ",
      "kdqb_j0AAAAJ",
      "gG5PRvgAAAAJ",
      "oXasn9EAAAAJ",
      "6IxWYR0AAAAJ"
    ],
    "EMDboA4AAAAJ": [
      "vtwH6GkAAAAJ",
      "5tVuggUAAAAJ",
      "itSa94cAAAAJ",
      "HBztuGIAAAAJ",
      "x04W_mMAAAAJ",
      "j_xavDQAAAAJ",
      "iVLAQysAAAAJ",
      "8fztli4AAAAJ",
      "xOWBOKQAAAAJ",
      "7_7op_IAAAAJ",
      "iYN86KEAAAAJ",
      "cGxq0cMAAAAJ",
      "8-p9CLsAAAAJ",
      "8R35rCwAAAAJ",
      "bh-uRFMAAAAJ",
      "yQNhFGUAAAAJ",
      "YYT8-7kAAAAJ",
      "ExXP2_AAAAAJ",
      "XCZpOcAAAAAJ",
      "n9K1v-cAAAAJ",
      "6gd_QS0AAAAJ",
      "yyIoQu4AAAAJ",
      "0pOgVVAAAAAJ",
      "VjsNXysAAAAJ",
      "lsbreWwAAAAJ"
    ],
    "0mgEF28AAAAJ": [
      "MhYrLJAAAAAJ",
      "ZeJjFQMAAAAJ",
      "qpBtpGsAAAAJ",
      "Zb5wT08AAAAJ",
      "UlXfwrkAAAAJ",
      "AjxoEpIAAAAJ",
      "Y3wdd8oAAAAJ",
      "axsP38wAAAAJ",
      "HC9-uqsAAAAJ",
      "VeXMKBoAAAAJ",
      "YB8_6gkAAAAJ"
    ],
    "Wj4ZBFIAAAAJ": [],
    "m0WCd-4AAAAJ": [],
    "Ctp3igcAAAAJ": [
      "aOklxsQAAAAJ",
      "M59O9lkAAAAJ",
      "zvaeYnUAAAAJ",
      "Mx8MbWYAAAAJ",
      "2yTeZ58AAAAJ",
      "YaEJbvYAAAAJ",
      "Ci-_QYIAAAAJ",
      "iH2BZ8UAAAAJ",
      "CFJHvLcAAAAJ",
      "UxuqG1EAAAAJ",
      "K1CAbGwAAAAJ",
      "sOG3L94AAAAJ",
      "7soDcboAAAAJ",
      "71L4yYMAAAAJ",
      "8R35rCwAAAAJ",
      "vfPE6hgAAAAJ",
      "d97bGd8AAAAJ",
      "pbmjtZsAAAAJ",
      "0JH6YbEAAAAJ",
      "WLN3QrAAAAAJ"
    ],
    "07qshUgAAAAJ": [
      "ThJ-Ju4AAAAJ",
      "I0fbJ6cAAAAJ",
      "E_a3VB4AAAAJ",
      "UD87zMYAAAAJ",
      "z28rttMAAAAJ",
      "7c2pTZMAAAAJ",
      "zYhq-BEAAAAJ",
      "hr81fHoAAAAJ",
      "t5KSayQAAAAJ",
      "GqZBmfgAAAAJ",
      "xuDZ9-sAAAAJ",
      "zdn08t8AAAAJ",
      "6ENuGyoAAAAJ",
      "J7H4N_4AAAAJ",
      "T5DyrYUAAAAJ",
      "qYhRbJoAAAAJ",
      "Es6jE1kAAAAJ",
      "umFQktIAAAAJ",
      "Z8U0BwcAAAAJ",
      "LKv32bgAAAAJ",
      "hRggMmIAAAAJ",
      "Dv1K9boAAAAJ",
      "TfetUkcAAAAJ",
      "NLW1g68AAAAJ",
      "1rV69hMAAAAJ",
      "Vb3FLmkAAAAJ",
      "DulpV-cAAAAJ",
      "6dFFudUAAAAJ",
      "35hM-PkAAAAJ",
      "ZybgAqkAAAAJ",
      "RUP4S68AAAAJ",
      "xhU85M4AAAAJ",
      "WYTugmIAAAAJ",
      "GseGXPsAAAAJ",
      "JB1j474AAAAJ",
      "mrMYnBEAAAAJ",
      "7q_zIE0AAAAJ",
      "NNJzA7MAAAAJ",
      "vmHFZM0AAAAJ",
      "0KvXR0AAAAAJ",
      "GF4pITIAAAAJ",
      "pDkhB5EAAAAJ",
      "nRM32-QAAAAJ",
      "VZ6S70MAAAAJ",
      "NfvUWXgAAAAJ",
      "guJ_kBQAAAAJ",
      "PQtLkV0AAAAJ",
      "XgA70_oAAAAJ",
      "RmhQmkwAAAAJ",
      "l0CjtK4AAAAJ",
      "aaGW2qwAAAAJ",
      "rWg9lSsAAAAJ",
      "_ogM5zAAAAAJ",
      "BHZT068AAAAJ",
      "CBUpEcQAAAAJ",
      "OL6EahoAAAAJ",
      "SMn18BwAAAAJ",
      "BF39lMQAAAAJ",
      "i4dDFK8AAAAJ",
      "AZMV2qQAAAAJ",
      "GixQBggAAAAJ",
      "FfXcEGMAAAAJ",
      "gqB23VMAAAAJ",
      "D-RwB3YAAAAJ",
      "qXzIytoAAAAJ",
      "TlpsH9cAAAAJ",
      "BkDCPiIAAAAJ",
      "lfJmfM0AAAAJ",
      "00roCOMAAAAJ",
      "GBJLTN8AAAAJ",
      "MCZpAkEAAAAJ",
      "PxsyxMsAAAAJ",
      "yqfXEPIAAAAJ",
      "5ReVSa8AAAAJ",
      "tokXOxkAAAAJ",
      "5ZTO0uMAAAAJ",
      "YVrGTe8AAAAJ",
      "RQg7790AAAAJ",
      "rM0Orl0AAAAJ",
      "4yuKD_AAAAAJ",
      "T8AsZ1sAAAAJ",
      "50__r6EAAAAJ",
      "JgqpX0oAAAAJ",
      "U42j5MkAAAAJ"
    ],
    "H3LMjtoAAAAJ": [
      "DpLFv4gAAAAJ",
      "RAt7zSUAAAAJ",
      "vKlrdpEAAAAJ",
      "uFJi3IUAAAAJ",
      "Wjs7DOoAAAAJ",
      "ffdt7gMAAAAJ",
      "GExyiRkAAAAJ",
      "OUv7J6QAAAAJ",
      "Xl4E0CsAAAAJ",
      "tpMNnPwAAAAJ",
      "9DXQi8gAAAAJ",
      "MNqdSZcAAAAJ",
      "VRR8fGoAAAAJ"
    ],
    "ITZ1e7MAAAAJ": [
      "JicYPdAAAAAJ",
      "s1PgoeUAAAAJ",
      "TMimDRoAAAAJ",
      "7qXxyJkAAAAJ",
      "8ys-38kAAAAJ",
      "iBeDoRAAAAAJ",
      "x04W_mMAAAAJ",
      "1MSpdmQAAAAJ",
      "kukA0LcAAAAJ",
      "ymzxRhAAAAAJ",
      "5pKTRxEAAAAJ",
      "W8zwlYQAAAAJ",
      "rRJ9wTJMUB8C",
      "0RAmmIAAAAAJ",
      "8cxDHS4AAAAJ",
      "A33FhJMAAAAJ",
      "-GduGkcAAAAJ",
      "N7_xhHoAAAAJ",
      "km6CP8cAAAAJ",
      "GyoKzFwAAAAJ",
      "sUriZlUAAAAJ",
      "EpT5sLAAAAAJ",
      "aka4LuAAAAAJ",
      "_CuXgYIAAAAJ",
      "mxiO4IkAAAAJ",
      "xgQd1qgAAAAJ",
      "vspmOX8AAAAJ",
      "ZnT-QpMAAAAJ",
      "4BEvaw8AAAAJ",
      "68c5HfwAAAAJ",
      "Amky96kAAAAJ",
      "bOQGfFIAAAAJ",
      "twWX2LIAAAAJ",
      "e1ucbCYAAAAJ",
      "nm3liowAAAAJ",
      "vgzrOK4AAAAJ",
      "0uTu7fYAAAAJ",
      "U89FHq4AAAAJ",
      "IrixA8MAAAAJ",
      "uBFV6SUAAAAJ",
      "njOmQFsAAAAJ",
      "Lncr-VoAAAAJ",
      "WLN3QrAAAAAJ",
      "GR_DsT0AAAAJ",
      "wb-DKCIAAAAJ",
      "a_dbdxAAAAAJ",
      "i4_3daEAAAAJ",
      "WjCG3owAAAAJ",
      "0zZnyMEAAAAJ",
      "LFiqVpwAAAAJ",
      "HDzOsYAAAAAJ",
      "ICNU7sAAAAAJ",
      "oavgGaMAAAAJ",
      "pfGI-KcAAAAJ",
      "W4Y0jUIAAAAJ",
      "grQ_GBgAAAAJ",
      "all0DHsAAAAJ"
    ],
    "3ifikJ0AAAAJ": [
      "ESRugcEAAAAJ"
    ],
    "bZ9oyW8AAAAJ": [],
    "NSWI3OwAAAAJ": [
      "8R35rCwAAAAJ",
      "vfPE6hgAAAAJ",
      "yy0UFOwAAAAJ",
      "ADkiClQAAAAJ",
      "LIJQ_ZYAAAAJ",
      "3oe0I0QAAAAJ",
      "ZaJEZpYAAAAJ",
      "pqP5_PgAAAAJ",
      "ZWH5jCwAAAAJ",
      "KsocBp8AAAAJ",
      "q7nFtUcAAAAJ",
      "5VaXUQsAAAAJ",
      "iyEuK8kAAAAJ",
      "1P8Zu04AAAAJ",
      "-w5DuHgAAAAJ",
      "GuU6oA4AAAAJ",
      "0nPi5YYAAAAJ",
      "OI7zFmwAAAAJ",
      "sgsLkM0AAAAJ",
      "znnl0kwAAAAJ",
      "RhUcYmQAAAAJ",
      "uemlfQYAAAAJ",
      "zBUwaGkAAAAJ",
      "wotfaAgAAAAJ",
      "T7uctwYAAAAJ",
      "t2X4Mg8AAAAJ",
      "U_Jw8DUAAAAJ",
      "hYVMrzsAAAAJ",
      "rHF25YEAAAAJ",
      "YfPA4YsAAAAJ",
      "7KDSCpQAAAAJ",
      "cXT3p6cAAAAJ",
      "OcownLgAAAAJ",
      "Vzr1RukAAAAJ",
      "2fWmq-4AAAAJ",
      "MA8rI0MAAAAJ",
      "xaOPd1YAAAAJ",
      "C_AP8XAAAAAJ",
      "SzHPa90AAAAJ",
      "A7-xkvcAAAAJ",
      "mIlaYj0AAAAJ",
      "1bF2s2kAAAAJ",
      "rE7-N30AAAAJ",
      "lPaISmIAAAAJ",
      "NLOh3SUAAAAJ",
      "jrfFYAIAAAAJ",
      "6U3IGtEAAAAJ",
      "bHsjbLwAAAAJ",
      "ttJ9AWAAAAAJ",
      "cx_Kg8MAAAAJ",
      "01je3ewAAAAJ",
      "nxd3mDcAAAAJ",
      "UmyrEtcAAAAJ",
      "3KF3AIMAAAAJ",
      "EF-SzEUAAAAJ",
      "uHDiAKQAAAAJ",
      "xD-wj_0AAAAJ",
      "wxnzyjwAAAAJ"
    ],
    "FdNHp8QAAAAJ": [
      "CpMjT0YAAAAJ",
      "5ygiTwsAAAAJ",
      "LKv32bgAAAAJ",
      "czyretsAAAAJ",
      "RLvsC94AAAAJ",
      "I1EvjZsAAAAJ",
      "vN-is70AAAAJ",
      "qG1LVpQAAAAJ",
      "ca_O-WQAAAAJ",
      "GjCIDGQAAAAJ",
      "Ao4gtsYAAAAJ",
      "q39nzokAAAAJ",
      "m45LD1kAAAAJ",
      "4UvZdF8AAAAJ",
      "Nt9r1_IAAAAJ",
      "hrI8aH8AAAAJ",
      "q5O284UAAAAJ",
      "uOfp1TEAAAAJ",
      "HQRnt54AAAAJ",
      "Wlq5rZEAAAAJ",
      "urQ9fNgAAAAJ",
      "tUrNjFcAAAAJ",
      "hEUk48QAAAAJ",
      "SzgX3_MAAAAJ",
      "DWWFQkkAAAAJ",
      "JzK8uYAAAAAJ",
      "IjXnDdoAAAAJ",
      "HYrDojkAAAAJ",
      "g66HTn4AAAAJ",
      "5NAFTkAAAAAJ",
      "5Zf13ZsAAAAJ",
      "Gp90OAUAAAAJ"
    ],
    "D1okUccAAAAJ": [
      "bh-uRFMAAAAJ",
      "mSn1TVMAAAAJ",
      "DxoenfgAAAAJ",
      "APgaFK0AAAAJ",
      "xa-6ZlkAAAAJ",
      "8cxDHS4AAAAJ",
      "edh9Nv4AAAAJ",
      "iAEBIB4AAAAJ",
      "Tarh6WoAAAAJ",
      "2bDu3ecAAAAJ",
      "Oa4qUz8AAAAJ",
      "P-md_yYAAAAJ",
      "zXsQ3CkAAAAJ",
      "pW3nxkUAAAAJ",
      "gZGtgS4AAAAJ",
      "e0nmxyIAAAAJ",
      "5JserkUAAAAJ",
      "sE3j8joAAAAJ",
      "3_2o8EgAAAAJ"
    ],
    "_kJ-zUYAAAAJ": [
      "bh-uRFMAAAAJ",
      "GHpxNQIAAAAJ",
      "3kDtybgAAAAJ",
      "pvyI8GkAAAAJ",
      "jQl9RtkAAAAJ",
      "z76PBfYAAAAJ",
      "AbzGfgoAAAAJ",
      "L4yEk2UAAAAJ",
      "9xDADY4AAAAJ"
    ],
    "evUv2MAAAAAJ": [
      "G2EJz5kAAAAJ",
      "B96GkdgAAAAJ",
      "LlfHFqUAAAAJ",
      "m0WCd-4AAAAJ",
      "eQvG-qoAAAAJ",
      "qq4zSmQAAAAJ",
      "b8OxVWUAAAAJ",
      "mSw8KfIAAAAJ",
      "e4MjcOEAAAAJ",
      "hNQoeOYAAAAJ",
      "PkfChMgAAAAJ",
      "Wj4ZBFIAAAAJ",
      "vN-is70AAAAJ",
      "NvKHgzkAAAAJ",
      "swf47vcAAAAJ",
      "TpglobcAAAAJ",
      "S8D-DqEAAAAJ",
      "cUkE7OgAAAAJ",
      "whNDkmMAAAAJ",
      "ribzpr4AAAAJ",
      "SbYoEmQAAAAJ",
      "uFJi3IUAAAAJ"
    ],
    "fftO_HsAAAAJ": [],
    "k7NgVSUAAAAJ": [],
    "b8OxVWUAAAAJ": [],
    "xegzhJcAAAAJ": [],
    "bRWa8q8AAAAJ": [],
    "DpLFv4gAAAAJ": [
      "7nlvOMQAAAAJ",
      "eDHv58AAAAAJ",
      "-hGZC54AAAAJ",
      "rmsIyGMAAAAJ",
      "uFJi3IUAAAAJ",
      "H3LMjtoAAAAJ",
      "vKlrdpEAAAAJ",
      "Q_kKkIUAAAAJ",
      "a1ngrCIAAAAJ",
      "5Iqe53IAAAAJ",
      "EnCwNycAAAAJ",
      "KzESVKwAAAAJ",
      "nd8lQQIAAAAJ",
      "AgyW_90AAAAJ",
      "OO-2710AAAAJ",
      "ygFAcZwAAAAJ",
      "ct67_F8AAAAJ",
      "Y28Kt7kAAAAJ",
      "b-GJ3QIAAAAJ",
      "VX7d5EQAAAAJ",
      "8O3h4_cAAAAJ",
      "V4OPEAgAAAAJ",
      "-e6KzSUAAAAJ",
      "LgAp4-oAAAAJ",
      "9EFobLUAAAAJ",
      "5JlEyTAAAAAJ",
      "OUv7J6QAAAAJ",
      "sOzdfjYAAAAJ",
      "tEk4qo8AAAAJ",
      "iKPWydkAAAAJ",
      "Yipk0X4AAAAJ",
      "Z6nLCukAAAAJ",
      "tzbfgcMAAAAJ",
      "bmZbi_UNs-oC",
      "CZaDvPgAAAAJ",
      "Xl4E0CsAAAAJ",
      "mY6IzuYAAAAJ",
      "BFWurDEAAAAJ"
    ],
    "FUOEBDUAAAAJ": [
      "Kia-4B0AAAAJ",
      "r50jBCUAAAAJ",
      "W8f0d6oAAAAJ",
      "ztwMmHEAAAAJ",
      "x5Ig8xMAAAAJ",
      "Bh8bGCYAAAAJ",
      "lfPTD18AAAAJ",
      "faO82gYAAAAJ",
      "hpbQN-AAAAAJ",
      "72yPqG4AAAAJ",
      "2kwHHWMAAAAJ",
      "6Vt1qbwAAAAJ",
      "rh0ubaUAAAAJ",
      "910z20QAAAAJ",
      "u8Q0_xsAAAAJ",
      "qWrXkPwAAAAJ",
      "I7RhPnIAAAAJ",
      "EL7zNHcAAAAJ",
      "mWhnaCkAAAAJ",
      "gd8q19oAAAAJ",
      "bO45VHYAAAAJ",
      "-6ws0MoAAAAJ",
      "4Urexvi1sIcC",
      "hI8nho4AAAAJ"
    ],
    "9GMg6q8AAAAJ": [
      "vtwH6GkAAAAJ",
      "8R35rCwAAAAJ",
      "5VaXUQsAAAAJ",
      "jERkdhIAAAAJ",
      "8fztli4AAAAJ",
      "lsbreWwAAAAJ",
      "5tVuggUAAAAJ",
      "kppa2vgAAAAJ"
    ],
    "5JserkUAAAAJ": [
      "Wk2gAZUAAAAJ",
      "Ao4gtsYAAAAJ",
      "xCYHonIAAAAJ",
      "bh-uRFMAAAAJ",
      "6Q-289IAAAAJ",
      "m1wmXdgAAAAJ",
      "L__n1LUAAAAJ",
      "LfcroyAAAAAJ",
      "EpT5sLAAAAAJ",
      "KMBgMs0AAAAJ",
      "wVGqmWkAAAAJ",
      "9DXQi8gAAAAJ",
      "uYVc9koAAAAJ",
      "qWDmIgIAAAAJ",
      "DxoenfgAAAAJ",
      "GHpxNQIAAAAJ",
      "mSn1TVMAAAAJ",
      "LXu_gVkAAAAJ",
      "WTlgnYkAAAAJ",
      "cSTLkv8AAAAJ",
      "xhU85M4AAAAJ",
      "tWI9Pw8AAAAJ",
      "hh5nOn4AAAAJ",
      "fsqz49kAAAAJ",
      "dEbld0EAAAAJ",
      "71L4yYMAAAAJ",
      "I15dUOwAAAAJ",
      "X7bG7YYAAAAJ",
      "WAgx2UsAAAAJ",
      "oo8QRmIAAAAJ",
      "eml8HfQAAAAJ",
      "PZVd2h8AAAAJ",
      "jW80JWEAAAAJ",
      "K-6ujU4AAAAJ",
      "zbRUiLgAAAAJ",
      "vcJ4hAkAAAAJ",
      "OBLWtdcAAAAJ",
      "yQNhFGUAAAAJ",
      "xXJIsh4AAAAJ",
      "Dkf39REAAAAJ",
      "-9X2XCkAAAAJ",
      "ROILf3EAAAAJ",
      "ifCcZ5IAAAAJ",
      "5hJNWakAAAAJ",
      "gypv57sAAAAJ",
      "CnBvgwcAAAAJ",
      "GMVxiYgAAAAJ",
      "0zZnyMEAAAAJ",
      "VJZj2MsAAAAJ",
      "IoVlb40AAAAJ",
      "g2uay50AAAAJ",
      "e9gUdKwAAAAJ",
      "pEDJ-8cAAAAJ",
      "o6LlkNMAAAAJ",
      "r4-NZhwAAAAJ",
      "W3lyJF8AAAAJ",
      "JDhMq3kAAAAJ",
      "6sI8lowAAAAJ",
      "sikKD7UAAAAJ",
      "vACm0-YAAAAJ",
      "h8W0ppcAAAAJ",
      "Tb0ZrYwAAAAJ",
      "DNPqaH0AAAAJ",
      "k2FuJZAAAAAJ",
      "LfF2zfQAAAAJ",
      "TXHN2DMAAAAJ",
      "J4Kj7EIAAAAJ",
      "6_UmGu0AAAAJ",
      "0lcJYs8AAAAJ",
      "sJKiJQwAAAAJ",
      "viFEu_8AAAAJ",
      "cwXx4EQAAAAJ",
      "oavgGaMAAAAJ",
      "Gc65LRwAAAAJ",
      "sQHdOycAAAAJ",
      "QY-earAAAAAJ",
      "wrozdTYAAAAJ",
      "BnQdO2UAAAAJ",
      "AEBWEm8AAAAJ",
      "ZnT-QpMAAAAJ",
      "JArbMQcAAAAJ",
      "4QZmEqsAAAAJ",
      "0ECOF7cAAAAJ",
      "5Il-agMAAAAJ",
      "LBi1V04AAAAJ",
      "JUpvud8AAAAJ",
      "NQgRwKAAAAAJ",
      "LIjnUGgAAAAJ",
      "xjnef1AAAAAJ",
      "sc5iZ3EAAAAJ",
      "UXYmnbgAAAAJ",
      "xGXNsCMAAAAJ",
      "Y8O9N_0AAAAJ",
      "2DzkuhQAAAAJ",
      "KA4xjHMAAAAJ",
      "R0kl_BUAAAAJ",
      "uCoRgGgAAAAJ",
      "ygFAcZwAAAAJ",
      "0J0n7sEAAAAJ",
      "WBeDvikAAAAJ",
      "AcACRTAAAAAJ",
      "Q8cTLNMAAAAJ",
      "fGZMMKUAAAAJ",
      "xa-6ZlkAAAAJ",
      "D1okUccAAAAJ",
      "1GPDFqsAAAAJ",
      "X1-ovCkAAAAJ",
      "2BnMsFIAAAAJ",
      "cDeKq4YAAAAJ",
      "j-MBXNMAAAAJ",
      "_woZ79YAAAAJ",
      "D7WH8ksAAAAJ",
      "OEJUgwkAAAAJ",
      "jZwEDZoAAAAJ",
      "7oxkHYYAAAAJ",
      "HDHOS0QAAAAJ",
      "0rskDKgAAAAJ",
      "wGG1voYAAAAJ",
      "VW1EQEQAAAAJ",
      "pYasE5oAAAAJ",
      "AEr-DWcAAAAJ",
      "j0nK_CsAAAAJ",
      "jac_HrgAAAAJ",
      "DZtU6KMAAAAJ",
      "jUtYwE0AAAAJ",
      "_u7raRkAAAAJ",
      "n6GdeeIAAAAJ",
      "3chExUsAAAAJ"
    ],
    "owqhKD8AAAAJ": [
      "MhDyxdYAAAAJ",
      "vaSdahkAAAAJ",
      "7NpTttkAAAAJ",
      "GINhGvwAAAAJ",
      "HGNZ1fkAAAAJ",
      "kokpiBQAAAAJ",
      "nUlanA8AAAAJ",
      "mVkGg80AAAAJ",
      "GR_DsT0AAAAJ",
      "rlmROVsAAAAJ",
      "qU9WvTgAAAAJ",
      "CotFJJsAAAAJ",
      "r3q68rcAAAAJ",
      "OcbAkXwAAAAJ",
      "P_-O-wcAAAAJ",
      "b1y1LooAAAAJ",
      "wb-DKCIAAAAJ",
      "EJXN6tYAAAAJ",
      "o0qh7IUAAAAJ",
      "uErE2UUAAAAJ",
      "33yNvIgAAAAJ",
      "QHS_pZAAAAAJ",
      "yj2b7pgAAAAJ",
      "0b7ZqlcAAAAJ",
      "NWPDSEsAAAAJ",
      "i38QlUwAAAAJ",
      "RqwU8xsAAAAJ",
      "6vH92bAAAAAJ",
      "EOlowBUAAAAJ",
      "ZybgAqkAAAAJ",
      "V6FaD-UAAAAJ",
      "sOna0qoAAAAJ",
      "h3SuftsAAAAJ",
      "qdGelXoAAAAJ",
      "ZqGaKSgAAAAJ",
      "ONNif60AAAAJ",
      "m9UbvIkAAAAJ",
      "wFEJvJUAAAAJ",
      "ZQs5JAIAAAAJ",
      "IoEBLNYAAAAJ",
      "-gNBIsYAAAAJ",
      "k7aMOCsAAAAJ",
      "eIRG81YAAAAJ",
      "BaRpQ_kAAAAJ",
      "i5srt20AAAAJ",
      "aO8KpGcAAAAJ",
      "yxUduqMAAAAJ",
      "GdOmgYwAAAAJ",
      "PBvgcC8AAAAJ",
      "sgBB2sUAAAAJ",
      "TaJND9YAAAAJ",
      "uqnNle0AAAAJ",
      "1G4GV2EAAAAJ",
      "BgOXDogAAAAJ",
      "igOOdBAAAAAJ",
      "9hQJrpAAAAAJ",
      "nCFeUqYAAAAJ"
    ],
    "DplAah0AAAAJ": [
      "bh-uRFMAAAAJ",
      "nABXo3sAAAAJ",
      "mqpjAt4AAAAJ",
      "UfbuDH8AAAAJ",
      "9xDADY4AAAAJ",
      "mu5Y2rYAAAAJ",
      "NkzyCvUAAAAJ",
      "OXFjRnEAAAAJ",
      "56EZh6YAAAAJ",
      "bo0P2qYAAAAJ",
      "W8VIEZgAAAAJ",
      "XP_Hxm4AAAAJ",
      "GgQ9GEkAAAAJ",
      "mbB3MRIAAAAJ",
      "NbXF7T8AAAAJ",
      "n1zDCkQAAAAJ",
      "vcJ4hAkAAAAJ",
      "y1lVpBEAAAAJ",
      "lc0ARagAAAAJ",
      "oyWpVa8AAAAJ",
      "2ItLnFgAAAAJ",
      "gYiCq88AAAAJ",
      "-ltRSM0AAAAJ",
      "jLraLTcAAAAJ",
      "sPTruxEAAAAJ"
    ],
    "YTO4ex4AAAAJ": [],
    "m_HQ-WQAAAAJ": [
      "fNOReswAAAAJ",
      "nZ8H4nsAAAAJ",
      "EWJYRncAAAAJ",
      "li9AfUUAAAAJ",
      "HU1K_zsAAAAJ",
      "0dmJuNkAAAAJ",
      "YAHWbtkAAAAJ",
      "B847xq8AAAAJ",
      "D83Vz00AAAAJ",
      "DYUloYkAAAAJ",
      "Me9JcfgAAAAJ",
      "3srp-NYAAAAJ",
      "nmk3WzgAAAAJ",
      "gkCjy_UAAAAJ",
      "4j-x4ckAAAAJ",
      "-dnFl2MAAAAJ",
      "STRrPekAAAAJ",
      "xW33QlMAAAAJ",
      "PtwDrzEAAAAJ",
      "PS-TM94AAAAJ",
      "WZS_HSgAAAAJ",
      "bWwpLA4AAAAJ",
      "4R7_wW8AAAAJ",
      "U7HnX4kAAAAJ",
      "nuyBlicAAAAJ",
      "NcaZT3wAAAAJ",
      "10Fx1a4AAAAJ",
      "jaGNt2sAAAAJ",
      "9vumoioAAAAJ",
      "b4jR5hkAAAAJ",
      "3qdaPdoAAAAJ",
      "sQJvy4MAAAAJ",
      "k8nSlL4AAAAJ",
      "Zu68lkkAAAAJ",
      "QOf1klMAAAAJ",
      "3jDeUlMAAAAJ",
      "045mm50AAAAJ",
      "Kq272_MAAAAJ",
      "x9K3GqkAAAAJ",
      "j0_fn9oAAAAJ",
      "LeiGXOsAAAAJ",
      "IrMKDiIAAAAJ",
      "MFnbrRUAAAAJ",
      "54urtxYAAAAJ",
      "quhI7uQAAAAJ",
      "7HCKL10AAAAJ",
      "hbuu7K8AAAAJ",
      "QQtOq2EAAAAJ",
      "vNUpyxYAAAAJ",
      "z9EcgygAAAAJ",
      "58GAc80AAAAJ",
      "po4ztO4AAAAJ",
      "zc2F3G0AAAAJ",
      "4SlTNbAAAAAJ",
      "uDZcR0IAAAAJ",
      "NqZETvUAAAAJ",
      "np0OO24AAAAJ",
      "CmQzsisAAAAJ",
      "0RdaaYsAAAAJ",
      "BH86MaMAAAAJ",
      "eyqQt3gAAAAJ",
      "NLBZuoEAAAAJ"
    ],
    "eQujqDgAAAAJ": [
      "_vjPh4UAAAAJ",
      "YOrLGyAAAAAJ",
      "TJWNYtMAAAAJ",
      "6Ff2c8wAAAAJ",
      "SQ1eGN4AAAAJ",
      "x1cDFYsAAAAJ",
      "B847xq8AAAAJ",
      "YAHWbtkAAAAJ",
      "KmlxiiyySHIC",
      "q3EGms8AAAAJ",
      "Wewcpo4AAAAJ",
      "7H3sBioAAAAJ",
      "BwjRbkcAAAAJ",
      "whB5QDoAAAAJ",
      "oqDCDOoAAAAJ",
      "Jlv4MR4AAAAJ",
      "70Rmp1oAAAAJ",
      "EyrM4VIAAAAJ",
      "yc2mM9IAAAAJ",
      "TZWVRR8AAAAJ",
      "nSSZmScAAAAJ",
      "0lZoXCUAAAAJ",
      "J_XhIsgAAAAJ"
    ],
    "1O83J5MAAAAJ": [],
    "OZ7PjVoAAAAJ": [],
    "6dskOSUAAAAJ": [
      "6-e-ZBEAAAAJ",
      "LKv32bgAAAAJ",
      "itSa94cAAAAJ",
      "mZfgLA4AAAAJ",
      "vfT6-XIAAAAJ",
      "2r2NuDAAAAAJ",
      "HBtozdUAAAAJ"
    ],
    "7OTD-LEAAAAJ": [
      "Y2GtJkAAAAAJ",
      "bh-uRFMAAAAJ",
      "8RVWMycAAAAJ",
      "6GDfcqEAAAAJ",
      "DGr0fVoAAAAJ",
      "UxuqG1EAAAAJ",
      "QiJPlOIAAAAJ",
      "fHfJh9cAAAAJ",
      "n44GlFcAAAAJ",
      "wCZbouUAAAAJ",
      "bSU7LYoAAAAJ",
      "a7drwRMAAAAJ",
      "yA4rb60AAAAJ",
      "Y8O9N_0AAAAJ",
      "NmHgX-wAAAAJ",
      "7cuwdr8AAAAJ",
      "UXh1I6UAAAAJ",
      "WLN3QrAAAAAJ",
      "hYlbtl8AAAAJ",
      "saWjkLQAAAAJ",
      "adnTgaAAAAAJ",
      "d97bGd8AAAAJ",
      "MKRyHXsAAAAJ",
      "eml8HfQAAAAJ",
      "SEbcuNoAAAAJ",
      "F3yrMeUAAAAJ",
      "5pKTRxEAAAAJ",
      "rTw-pq0AAAAJ",
      "iwBPvPIAAAAJ",
      "fb6FOfsAAAAJ",
      "lA7ylt4AAAAJ",
      "WvufSLAAAAAJ",
      "jxpBMwwAAAAJ",
      "QOO8OCcAAAAJ",
      "kRJkDakAAAAJ",
      "Q8iay0gAAAAJ",
      "e9gUdKwAAAAJ",
      "-XCiamcAAAAJ",
      "XqLiBQMAAAAJ",
      "78WTKm4AAAAJ",
      "XO8T-Y4AAAAJ",
      "DhtAFkwAAAAJ",
      "s4rghcgAAAAJ",
      "AI2f3dkAAAAJ",
      "-ltRSM0AAAAJ",
      "sao1OhsAAAAJ",
      "k5FaRwcAAAAJ",
      "kg4bCpgAAAAJ",
      "vjZrDKQAAAAJ",
      "BI8xFr4AAAAJ",
      "6GhZedEAAAAJ",
      "7vyVxxQAAAAJ",
      "bQTXRrAAAAAJ",
      "mWpu_ooAAAAJ",
      "9P9QcckAAAAJ",
      "cMPKe9UAAAAJ",
      "VAiqiv4AAAAJ",
      "Nsxpe_kAAAAJ",
      "H02tLFMAAAAJ",
      "-SgpaF8AAAAJ",
      "lHSilFcAAAAJ",
      "i2II0XIAAAAJ",
      "foERjnQAAAAJ",
      "jF4dPZwAAAAJ",
      "c0WCD74AAAAJ",
      "uToGtIwAAAAJ",
      "iRBUTOAAAAAJ",
      "SaH2yWMAAAAJ",
      "qimMoFIAAAAJ",
      "KSZmI5EAAAAJ",
      "vN-is70AAAAJ",
      "B96GkdgAAAAJ",
      "QSTd1oUAAAAJ",
      "4Z6vo5QAAAAJ"
    ],
    "vN-is70AAAAJ": [],
    "x1mbRloAAAAJ": [
      "dPX0wQcAAAAJ",
      "UfAyRKEAAAAJ",
      "dcVFn08AAAAJ",
      "eJ9qDHMAAAAJ",
      "FayXlTYAAAAJ",
      "cOrfSmIAAAAJ",
      "tYgN0GsAAAAJ",
      "pOtmLl0AAAAJ",
      "9rUGrpwAAAAJ",
      "A3ObLdMAAAAJ",
      "3ZTrRpAAAAAJ",
      "X9fd67gAAAAJ",
      "erv7TP0AAAAJ",
      "gxnzvbYAAAAJ",
      "vA6ZQ_AAAAAJ",
      "UBrbfSwAAAAJ",
      "fDc1X1YAAAAJ",
      "23ZXZvEAAAAJ",
      "gX7rSCcAAAAJ",
      "sNMowOIAAAAJ",
      "6AA-AAcAAAAJ",
      "grQ_GBgAAAAJ",
      "gc62BUIAAAAJ",
      "mezKJyoAAAAJ",
      "euc0GX4AAAAJ",
      "-Txt8vsAAAAJ",
      "djheYP0AAAAJ",
      "rRJ9wTJMUB8C",
      "TX6achUAAAAJ",
      "e8kIbEYAAAAJ",
      "Xsn1VsgAAAAJ",
      "jdpFVlgAAAAJ",
      "e5P8uR4AAAAJ",
      "d4yNzXIAAAAJ",
      "yxUduqMAAAAJ",
      "RZ2KXioAAAAJ",
      "5V7VFi8AAAAJ",
      "r1cF30oAAAAJ",
      "Wx-ul64AAAAJ",
      "LKv32bgAAAAJ",
      "k-0MEIMAAAAJ"
    ],
    "IB_jPZ0AAAAJ": [
      "RtNVud4AAAAJ",
      "h1NXfKYAAAAJ",
      "TaF4L4EAAAAJ",
      "GWkwfBIAAAAJ",
      "iyDxq0EAAAAJ",
      "aO8KpGcAAAAJ",
      "Qg7x7M8AAAAJ",
      "yYE8Xo8AAAAJ",
      "BgQkdsYAAAAJ",
      "p1DZVX8AAAAJ",
      "in8fQ10AAAAJ",
      "uplepqQAAAAJ",
      "9SITlKwAAAAJ",
      "n1zDCkQAAAAJ",
      "T7Wa3GQAAAAJ",
      "XaFT1o4AAAAJ"
    ],
    "DZ-fHPgAAAAJ": [
      "Tb0ZrYwAAAAJ",
      "O-3bc_EAAAAJ",
      "OUv7J6QAAAAJ",
      "jplQac8AAAAJ",
      "tQuQ1FwAAAAJ",
      "vYRgxJ8AAAAJ",
      "O-oICE8AAAAJ",
      "lMkTx0EAAAAJ",
      "rtWKzFwAAAAJ",
      "kBQ4VvEAAAAJ",
      "Fg7TcjEAAAAJ",
      "wQanfTIAAAAJ",
      "RGoypN4AAAAJ",
      "G4MBruQAAAAJ",
      "M7wYOSMAAAAJ",
      "CHO-UV8AAAAJ",
      "15GNzKcAAAAJ",
      "E2z5uYsAAAAJ",
      "v3JsjMYAAAAJ",
      "Mdr6wjUAAAAJ",
      "Mxio0T8AAAAJ",
      "UcuXmuwAAAAJ",
      "HvVqBmkAAAAJ",
      "5Hbi5WYAAAAJ",
      "Dav2k7cAAAAJ",
      "vtegaJgAAAAJ",
      "UwLsYw8AAAAJ",
      "Td3_kIwAAAAJ",
      "TA2fG64AAAAJ",
      "6EOl3hAAAAAJ",
      "-kIVAcAAAAAJ",
      "Nbq6kI0AAAAJ",
      "1iE2ykkAAAAJ",
      "Tpp9ZjoAAAAJ",
      "yQNhFGUAAAAJ",
      "kukA0LcAAAAJ",
      "ZGmFXNsAAAAJ",
      "yHDXov0AAAAJ",
      "Ycos9pAAAAAJ",
      "n4k9D7QAAAAJ",
      "tEGxO60AAAAJ",
      "NxrQ794AAAAJ",
      "pnypNygAAAAJ",
      "w0x8vm0AAAAJ",
      "mW9BcgsAAAAJ",
      "RuvHkikAAAAJ",
      "5XqE3bQAAAAJ",
      "T3hAyLkAAAAJ",
      "1Kr0r4kAAAAJ",
      "34eszXwAAAAJ",
      "krrh6OUAAAAJ",
      "mlSE-YwAAAAJ",
      "hwm5E4kAAAAJ",
      "7EWrVYIAAAAJ",
      "VgzYS6IAAAAJ",
      "JdZ8DWwAAAAJ",
      "Xl4E0CsAAAAJ",
      "miAQ1Q4AAAAJ",
      "yXdK2wYAAAAJ",
      "FKOqtF8AAAAJ",
      "pqpxh7IAAAAJ",
      "6SDclmEAAAAJ",
      "hcmW-W0AAAAJ",
      "ZMzzV7cAAAAJ",
      "acmtRMAAAAAJ",
      "oMqNbfsAAAAJ",
      "kbN88gsAAAAJ",
      "5vj1VV8AAAAJ",
      "eyCw9goAAAAJ",
      "xA3Jd5gAAAAJ",
      "cy9mlN0AAAAJ",
      "JmiTDLIAAAAJ",
      "8FfrHw0AAAAJ",
      "aqgFQqMAAAAJ",
      "xTi3ouAAAAAJ",
      "UeG5w08AAAAJ",
      "SfBBevUAAAAJ",
      "AQ_I-NkAAAAJ",
      "kPxa2w0AAAAJ",
      "x8dED5cAAAAJ",
      "0wIdMGEAAAAJ",
      "6uTDJ9oAAAAJ",
      "i_QJztcAAAAJ",
      "vyppxW4AAAAJ",
      "jYCidWgAAAAJ",
      "tDgCcOEAAAAJ",
      "BpJTboUAAAAJ",
      "ofMZr0IAAAAJ",
      "WgAGy7wAAAAJ",
      "ugH_Wg4AAAAJ",
      "akrkYU0AAAAJ",
      "J3lauQ4AAAAJ",
      "ji0zVjgAAAAJ",
      "hLTZTG4AAAAJ",
      "133WpF8AAAAJ",
      "4hbasIcAAAAJ",
      "V-lc8A8AAAAJ",
      "Q_kKkIUAAAAJ",
      "UWyyLgIAAAAJ",
      "BkbnIxkAAAAJ",
      "k8Rs4JcAAAAJ",
      "jUCiLN4AAAAJ",
      "5XdNlE8AAAAJ",
      "KsErEBoAAAAJ",
      "3D-xyjwAAAAJ",
      "xpwMxy8AAAAJ",
      "xaQuPloAAAAJ",
      "plt2_DsAAAAJ",
      "e25-lgUAAAAJ"
    ],
    "9I7kD8sAAAAJ": [],
    "DcV-5RAAAAAJ": [
      "vtxXpVAAAAAJ",
      "ynDHUwkAAAAJ",
      "YQcU3NYAAAAJ",
      "BF39lMQAAAAJ",
      "K4bCJYcAAAAJ",
      "gUO59T8AAAAJ",
      "sCEl8r-n5VEC",
      "zqUO0GMAAAAJ",
      "RYvdtGcAAAAJ",
      "JSFmVQEAAAAJ",
      "mpxO5ycAAAAJ",
      "BCBUDMcAAAAJ",
      "gKUEEY4AAAAJ",
      "lD3PMh0AAAAJ",
      "gX8LBfgAAAAJ",
      "oBeXCuQAAAAJ",
      "EWZ9_SAAAAAJ",
      "B1guGw8AAAAJ",
      "hYi6i9sAAAAJ",
      "GP64q_kAAAAJ",
      "vn4dQRIAAAAJ",
      "LBaBtwcAAAAJ",
      "aHV3aDMAAAAJ",
      "uMbvldoAAAAJ",
      "I5jS8ccAAAAJ",
      "1FwhEVYAAAAJ",
      "Rn_BmTYAAAAJ",
      "IQ3hcw4AAAAJ",
      "H4XxdCQAAAAJ",
      "MB7c7CYAAAAJ",
      "oAbEdzUAAAAJ",
      "MCClSvsAAAAJ",
      "nM77MX0AAAAJ",
      "g9d_K0sAAAAJ",
      "MzD8rjoAAAAJ",
      "D2K-ADYAAAAJ",
      "iBl-QgEAAAAJ",
      "M7edePUAAAAJ",
      "fzSHXS8AAAAJ",
      "I5gPRf0AAAAJ",
      "WzEQ9QwAAAAJ",
      "rPU7fz0AAAAJ",
      "hSUP-4cAAAAJ",
      "Rz9p0poAAAAJ",
      "9rYWg2EAAAAJ",
      "ja7P1hQAAAAJ"
    ],
    "pouyVyUAAAAJ": [],
    "X0EXfT8AAAAJ": [
      "bh-uRFMAAAAJ",
      "GHpxNQIAAAAJ",
      "PUSWc4EAAAAJ",
      "AEsPCAUAAAAJ",
      "ijpYJQwAAAAJ",
      "B_FTboQAAAAJ",
      "iYN86KEAAAAJ",
      "Q8iay0gAAAAJ",
      "SzZRlcMAAAAJ",
      "m7LvuTkAAAAJ",
      "vtwH6GkAAAAJ"
    ],
    "P4nfoKYAAAAJ": [
      "bh-uRFMAAAAJ",
      "VJlCMGYAAAAJ",
      "qr8Vo9IAAAAJ",
      "Dn_qYK8AAAAJ",
      "gMndACUAAAAJ",
      "KltleWgAAAAJ",
      "nXBQn7gAAAAJ",
      "sjaZfDIAAAAJ",
      "zXhuhtwAAAAJ",
      "ZkBTPkUAAAAJ",
      "btoec6QAAAAJ",
      "BIdzgnwAAAAJ",
      "5Ius69wAAAAJ",
      "QQHXl9sAAAAJ",
      "jUP4oi8AAAAJ",
      "yKCX2IUAAAAJ",
      "LVJtdoEAAAAJ",
      "XM97iScAAAAJ",
      "E8RwuIIAAAAJ",
      "sR_OzkgAAAAJ",
      "-pyztDMAAAAJ",
      "H4CPLUQAAAAJ",
      "VA5VktEAAAAJ",
      "E2uuNVoAAAAJ",
      "Ef1hJ8IAAAAJ",
      "sp2np4oAAAAJ",
      "5sz_jBoAAAAJ",
      "Fqw9o84AAAAJ",
      "OPgnjWQAAAAJ",
      "wvkUbiUAAAAJ",
      "vsj2slIAAAAJ",
      "wh_eLqQAAAAJ",
      "6TGwETYAAAAJ",
      "7OW6weoAAAAJ",
      "0TJZPj0AAAAJ",
      "ygpxbK8AAAAJ",
      "rRJ9wTJMUB8C",
      "z76PBfYAAAAJ",
      "nrEeeY4AAAAJ",
      "VNAFWVoAAAAJ",
      "ruZDm9QAAAAJ",
      "0ee8P-cAAAAJ",
      "4swDjMAAAAAJ",
      "zMqwIkIAAAAJ",
      "zGuKpwQAAAAJ",
      "OiVOAHMAAAAJ",
      "hI5X8UYAAAAJ",
      "tzYolooAAAAJ",
      "L4CxNO8AAAAJ",
      "l5Qki4cAAAAJ",
      "ew0G1PIAAAAJ",
      "xWI4K4sAAAAJ",
      "pkqB2vEAAAAJ",
      "LXqHtF4AAAAJ",
      "P1OaUP8AAAAJ",
      "1FIyc9kAAAAJ",
      "wOYUPpwAAAAJ",
      "XOnfkHIAAAAJ",
      "gzPWwdIAAAAJ",
      "HnQ2gqMAAAAJ",
      "kQsnsxIAAAAJ",
      "2UQAbkEAAAAJ",
      "Uf9gm4oAAAAJ",
      "qF806HcAAAAJ",
      "todsDfQAAAAJ",
      "ifNxpgkAAAAJ",
      "lqyGZpQAAAAJ",
      "umA5NjcAAAAJ",
      "z-JV1e8AAAAJ",
      "jJfKig8AAAAJ",
      "cmC2pp0AAAAJ",
      "vZHanWgAAAAJ",
      "244WszUAAAAJ",
      "I58-jXkAAAAJ",
      "c_E3E4kAAAAJ",
      "e0VXX60AAAAJ",
      "rynvwScAAAAJ",
      "ohJ44iMAAAAJ",
      "K2KcQKAAAAAJ",
      "LU1OKMoAAAAJ",
      "-_hcRfgAAAAJ",
      "Eclg4mwAAAAJ",
      "C8S84g8AAAAJ",
      "PRhJB5EAAAAJ",
      "PBEbCgUAAAAJ",
      "PKz_a_AAAAAJ",
      "5efz6osAAAAJ",
      "XZkvOTEAAAAJ",
      "2IvwHucAAAAJ",
      "_3_Y0xQAAAAJ",
      "eOkGKuUAAAAJ",
      "a7VNhCIAAAAJ",
      "sgLeMy8AAAAJ",
      "_PhjyLoAAAAJ",
      "YHxZLlwAAAAJ",
      "8kA3eDwAAAAJ",
      "VizsSmEAAAAJ",
      "lc0ARagAAAAJ",
      "MplR7_cAAAAJ",
      "dY7OSl0AAAAJ",
      "g-_ZXGsAAAAJ",
      "vy5ngwUAAAAJ",
      "oH1ScJkAAAAJ",
      "j9jEMToAAAAJ",
      "3wXH93MAAAAJ",
      "OKtm7t4AAAAJ",
      "3RnBcXAAAAAJ",
      "WOAlvmoAAAAJ",
      "5H0arvkAAAAJ",
      "YPq3ax4AAAAJ",
      "tVEF11EAAAAJ",
      "_CNYi6MAAAAJ",
      "lYqgwwwAAAAJ",
      "tqMGsJwAAAAJ",
      "WgAGy7wAAAAJ",
      "ebrNfPAAAAAJ",
      "2dTrwzAAAAAJ",
      "uMNLanIAAAAJ",
      "qHG9PB8AAAAJ",
      "NcT-9asAAAAJ",
      "wkC9xHMAAAAJ",
      "Ii7P2QQAAAAJ",
      "js-mvgoAAAAJ",
      "e7VI_HcAAAAJ",
      "9CEJKM4AAAAJ",
      "PogsVkYAAAAJ",
      "YjTldCMAAAAJ",
      "LAv0HTEAAAAJ",
      "em7o4kwAAAAJ",
      "tDgCcOEAAAAJ",
      "pk-yb_kAAAAJ",
      "h20U9WcAAAAJ",
      "Ddfev5kAAAAJ",
      "EFB9ZuwAAAAJ",
      "zNOQUvkAAAAJ",
      "V4OPEAgAAAAJ",
      "L9QufAsAAAAJ",
      "13xdkw4AAAAJ",
      "PGcc-RIAAAAJ",
      "h4i4fh8AAAAJ",
      "LWw60SgAAAAJ",
      "1H4HuCkAAAAJ",
      "HMnF6i0AAAAJ",
      "sGPW9jAAAAAJ",
      "xViwZ0QAAAAJ",
      "bf2ZrFcAAAAJ",
      "5mSnPlwAAAAJ",
      "Z962IGQAAAAJ",
      "gpyHJmcAAAAJ",
      "REL2gIEAAAAJ",
      "wQU1dJAAAAAJ",
      "2XCryp4AAAAJ",
      "WsfNeKYAAAAJ",
      "wRYM4qgAAAAJ",
      "tetdudUAAAAJ",
      "Q_kKkIUAAAAJ",
      "wS0qP_MAAAAJ",
      "nI2URPQAAAAJ",
      "5VJ4YPQAAAAJ",
      "DqXsbPAAAAAJ",
      "eyYubf4AAAAJ",
      "3PqA9YYAAAAJ",
      "nBwaXUsAAAAJ",
      "HoPI8pIAAAAJ",
      "45uuU3gAAAAJ",
      "3UZwE6sAAAAJ",
      "wgh5X-AAAAAJ",
      "-Tpv_CMAAAAJ",
      "BnxU9TEAAAAJ",
      "qLTEaEIAAAAJ",
      "J6VzIsYAAAAJ",
      "5zUqCuUAAAAJ"
    ],
    "L5jDQS8AAAAJ": [
      "gxL1qj8AAAAJ",
      "_GzrRGwAAAAJ",
      "JBnyLicAAAAJ"
    ],
    "HQRnt54AAAAJ": [],
    "hISpTpQAAAAJ": [
      "5t2myD8AAAAJ",
      "iTv2cOgAAAAJ",
      "pPB_WK0AAAAJ",
      "7ezIRWQAAAAJ",
      "p_iffpcAAAAJ",
      "y0U2EaUAAAAJ",
      "aNFzP50AAAAJ",
      "iSL1cKsAAAAJ",
      "fn13u8IAAAAJ",
      "Av2Iuu0AAAAJ",
      "fy2TEm4AAAAJ",
      "qnxPT9UAAAAJ",
      "EAB-RKIAAAAJ",
      "sFmN6RkAAAAJ",
      "uxSj18QAAAAJ",
      "4JsyJK8AAAAJ",
      "1I0ff2cAAAAJ",
      "Evgx6UkAAAAJ",
      "CnBvgwcAAAAJ",
      "opbZfw0AAAAJ",
      "D4rBbksAAAAJ",
      "zgfSvoYAAAAJ",
      "yfORTKUAAAAJ"
    ],
    "lS96SqoAAAAJ": [
      "8R35rCwAAAAJ",
      "1wLVDP4AAAAJ",
      "_EJrRVAAAAAJ",
      "QCBdB7AAAAAJ",
      "bqL73OkAAAAJ",
      "52T2LYoAAAAJ",
      "vtwH6GkAAAAJ",
      "eVYhlDQAAAAJ",
      "vfPE6hgAAAAJ",
      "VT7peyEAAAAJ",
      "yy0UFOwAAAAJ",
      "B8wslVsAAAAJ",
      "qcrM7F4AAAAJ",
      "_0IIzxgAAAAJ",
      "0oIAvO8AAAAJ",
      "Zlpuln8AAAAJ",
      "itSa94cAAAAJ",
      "CjOTm_4AAAAJ",
      "0nPi5YYAAAAJ",
      "LIJQ_ZYAAAAJ"
    ],
    "a8Y2OJMAAAAJ": [
      "W8VIEZgAAAAJ",
      "DhtAFkwAAAAJ",
      "chD5XxkAAAAJ",
      "_BPdgV0AAAAJ",
      "j29kMCwAAAAJ",
      "ZeJjFQMAAAAJ",
      "kQisE-gAAAAJ",
      "9B8PoXUAAAAJ",
      "HXowq5YAAAAJ",
      "vjZrDKQAAAAJ",
      "TpglobcAAAAJ",
      "Y2GtJkAAAAAJ",
      "bHn29ScAAAAJ",
      "9oz-dvgAAAAJ",
      "bSU7LYoAAAAJ",
      "c8IpF9gAAAAJ",
      "xOrRvKAAAAAJ",
      "n-SnMhoAAAAJ",
      "dUWUGcEAAAAJ",
      "jjEht8wAAAAJ",
      "fHfJh9cAAAAJ",
      "dYu68U8AAAAJ",
      "z76PBfYAAAAJ",
      "T94KevkAAAAJ",
      "ZdfkFuAAAAAJ",
      "krvptckAAAAJ",
      "-VgS8AIAAAAJ",
      "UKpinl8AAAAJ",
      "1HO5UacAAAAJ",
      "QBsEFvMAAAAJ",
      "SI6sQPYAAAAJ",
      "TU_s3xAAAAAJ",
      "w4fhxasAAAAJ",
      "mu5Y2rYAAAAJ",
      "duSEbnYAAAAJ",
      "vKlrdpEAAAAJ",
      "BU6f7L4AAAAJ",
      "QOO8OCcAAAAJ",
      "bh-uRFMAAAAJ",
      "OXFjRnEAAAAJ",
      "5FwRvZAAAAAJ",
      "UxuqG1EAAAAJ",
      "32w7x1cAAAAJ",
      "HzfkQy4AAAAJ",
      "cMDQJIoAAAAJ",
      "rTw-pq0AAAAJ",
      "VeTSl0wAAAAJ",
      "N_YNMIMAAAAJ",
      "5na92fcAAAAJ",
      "y1lVpBEAAAAJ",
      "vTWuk1gAAAAJ",
      "rtWKzFwAAAAJ",
      "AxzVaI8AAAAJ",
      "miAQ1Q4AAAAJ",
      "_mMeOTgAAAAJ",
      "w3fqzIYAAAAJ",
      "h8u3ll8AAAAJ",
      "E8DVVYQAAAAJ",
      "rqmw-qQAAAAJ",
      "74zyaaYAAAAJ",
      "QiJPlOIAAAAJ",
      "qsB2vcgAAAAJ",
      "SVNNgu4AAAAJ",
      "TV9sa6QAAAAJ",
      "B76dD7YAAAAJ",
      "AEsPCAUAAAAJ",
      "jTnQTBoAAAAJ",
      "JETJjHoAAAAJ",
      "_UJsz3AAAAAJ",
      "oa78zHUAAAAJ",
      "36ofBJgAAAAJ",
      "Ad6O4-0AAAAJ",
      "EqJw1-4AAAAJ",
      "8qNEbiUAAAAJ",
      "fanhk-gAAAAJ",
      "reEAEWsAAAAJ",
      "cXPscXUAAAAJ",
      "B2YRmGgAAAAJ",
      "FJ-huxgAAAAJ",
      "0mgEF28AAAAJ",
      "a7VNhCIAAAAJ",
      "mS5k4CYAAAAJ",
      "zh0Raz8AAAAJ",
      "b4MEVXsAAAAJ",
      "8kA3eDwAAAAJ",
      "_y-8nrcAAAAJ",
      "Gd9HQn2UsNoC",
      "6GDfcqEAAAAJ",
      "qvRsU00AAAAJ",
      "XTaVGqYAAAAJ",
      "kRJkDakAAAAJ",
      "76B8lrgAAAAJ",
      "7cuwdr8AAAAJ",
      "Qwm6ZOYAAAAJ",
      "WvufSLAAAAAJ",
      "oQyYH9kAAAAJ",
      "g558OVoAAAAJ",
      "ufzrGe8AAAAJ",
      "D9XHjNAAAAAJ",
      "zFafsk8AAAAJ",
      "zMqwIkIAAAAJ",
      "sPTruxEAAAAJ",
      "uH5WA4oAAAAJ",
      "-9yiQMsAAAAJ",
      "YAtwLpwAAAAJ",
      "E42NyKUAAAAJ"
    ],
    "1p3dDesAAAAJ": [
      "POlWWAsAAAAJ",
      "wnhU3KoAAAAJ",
      "_TkfqdgAAAAJ",
      "84WzBlYAAAAJ",
      "OeDgxpgAAAAJ",
      "kIsmHd4AAAAJ",
      "iyDxq0EAAAAJ",
      "aO8KpGcAAAAJ",
      "yxUduqMAAAAJ",
      "E31PR1oAAAAJ",
      "jffu6mUAAAAJ",
      "bldHpWIAAAAJ",
      "v8JEPFgAAAAJ",
      "xuSbmssAAAAJ"
    ],
    "opbZfw0AAAAJ": [
      "RiLCRDwAAAAJ",
      "SQ1eGN4AAAAJ",
      "0lZoXCUAAAAJ",
      "TJWNYtMAAAAJ",
      "tkDsIggAAAAJ",
      "oOwNKsAAAAAJ",
      "GkMfzy4AAAAJ",
      "nf_EnbAAAAAJ",
      "19qSWk8AAAAJ",
      "F_ASWCUAAAAJ",
      "2vQRGrYAAAAJ",
      "r49_E2cAAAAJ",
      "8AkztB0AAAAJ",
      "NLLMDCkAAAAJ",
      "xdTtK9IAAAAJ",
      "AdAd4QIAAAAJ",
      "QP1aKqcAAAAJ",
      "4Gw0GgEAAAAJ",
      "wAKowxMAAAAJ",
      "FsBCAfgAAAAJ",
      "5m5ds6UAAAAJ",
      "NDhlLv0AAAAJ",
      "ynJ-R00AAAAJ",
      "olerUhcAAAAJ",
      "PJQPzgcAAAAJ",
      "vVvbU7oAAAAJ",
      "hIq09eUAAAAJ",
      "TZWVRR8AAAAJ",
      "q4QmSekAAAAJ",
      "dHU6M_4AAAAJ",
      "Evgx6UkAAAAJ",
      "2FbkAzYAAAAJ",
      "jM1cT4QAAAAJ",
      "qnwjcfAAAAAJ",
      "tMBYEWAAAAAJ",
      "Iia81jAAAAAJ",
      "Jlv4MR4AAAAJ"
    ],
    "_QlCijoAAAAJ": [
      "kRJkDakAAAAJ",
      "d97bGd8AAAAJ",
      "6GDfcqEAAAAJ",
      "8R35rCwAAAAJ",
      "GhrKC1gAAAAJ",
      "vfPE6hgAAAAJ",
      "9hX-JksAAAAJ",
      "_j4M4KEAAAAJ",
      "ypBMJMgAAAAJ",
      "i5FMLA4AAAAJ",
      "6bRXWXEAAAAJ",
      "njOmQFsAAAAJ",
      "KoXUMbsAAAAJ",
      "Q0piorUAAAAJ",
      "b15vJuEAAAAJ",
      "l-xu2w0AAAAJ",
      "oBu8kMMAAAAJ",
      "BMgUIC0AAAAJ",
      "83HL5FwAAAAJ",
      "nkTd_BIAAAAJ"
    ],
    "NvKHgzkAAAAJ": [],
    "NmHgX-wAAAAJ": [
      "Q8iay0gAAAAJ",
      "GW9vw8UAAAAJ",
      "bh-uRFMAAAAJ",
      "7OTD-LEAAAAJ",
      "QX7xv3UAAAAJ",
      "Y2GtJkAAAAAJ",
      "hR4G6hoAAAAJ",
      "AP_Yd6wAAAAJ",
      "JFEHAwIAAAAJ",
      "UgK1my4AAAAJ",
      "3kDtybgAAAAJ",
      "QJZQgN8AAAAJ",
      "tE1oVQ4AAAAJ",
      "-XCiamcAAAAJ",
      "e9gUdKwAAAAJ",
      "DdCAbWwAAAAJ",
      "wYDbtFsAAAAJ",
      "O_4qYW4AAAAJ",
      "BGONmkIAAAAJ",
      "-JiwekUAAAAJ"
    ],
    "dzOd2hgAAAAJ": [
      "kg4bCpgAAAAJ",
      "47n-0mwAAAAJ",
      "bh-uRFMAAAAJ",
      "d97bGd8AAAAJ",
      "QiJPlOIAAAAJ",
      "UfbuDH8AAAAJ",
      "OZ7PjVoAAAAJ",
      "K-g2p4cAAAAJ",
      "AEsPCAUAAAAJ",
      "BHlY8ewAAAAJ",
      "Zi5KiDsAAAAJ",
      "z-oSdPoAAAAJ",
      "K-k47CMAAAAJ",
      "6_U35tAAAAAJ",
      "B_FTboQAAAAJ",
      "UdpacsMAAAAJ",
      "yn-nyJwAAAAJ",
      "Tb0ZrYwAAAAJ",
      "_0aMq28AAAAJ",
      "WvufSLAAAAAJ",
      "7cuwdr8AAAAJ",
      "uxk0GmUAAAAJ",
      "yvhVTMgAAAAJ",
      "DhtAFkwAAAAJ",
      "UxuqG1EAAAAJ",
      "W8VIEZgAAAAJ",
      "yA4rb60AAAAJ",
      "oB0g2IkAAAAJ",
      "pamL_rIAAAAJ",
      "GlArL6AAAAAJ",
      "3sbdEW4AAAAJ",
      "oyh-YNwAAAAJ",
      "kRJkDakAAAAJ",
      "76B8lrgAAAAJ",
      "0MiPsosAAAAJ",
      "--YtdhAAAAAJ",
      "A33FhJMAAAAJ",
      "RhOpyXcAAAAJ",
      "ey9AQcEAAAAJ",
      "dthSEsoAAAAJ",
      "KyNwquYAAAAJ",
      "Ro6enEEAAAAJ",
      "VNSzxhUAAAAJ",
      "-XCiamcAAAAJ",
      "dVtzVVAAAAAJ",
      "1Rf6sGcAAAAJ",
      "gCbeGRIAAAAJ",
      "84WzBlYAAAAJ",
      "fszzlckAAAAJ",
      "RUT0Hf8AAAAJ",
      "SBTxvCoAAAAJ",
      "8R35rCwAAAAJ",
      "q-buMEoAAAAJ",
      "yuNhi-8AAAAJ",
      "9v86038AAAAJ",
      "Ivot3fkAAAAJ",
      "uclqBzgAAAAJ",
      "0JH6YbEAAAAJ",
      "UD87zMYAAAAJ",
      "lVD0CNEAAAAJ",
      "VYiRfCwAAAAJ",
      "G2zXCNkAAAAJ",
      "sbbRtWwAAAAJ",
      "5akTCHoAAAAJ",
      "hsxzylEAAAAJ",
      "ojKsx6AAAAAJ",
      "eWbZJlMAAAAJ",
      "lv9ZeVUAAAAJ",
      "YTyBTmgAAAAJ",
      "4wSfAIQAAAAJ",
      "1H9CkZgAAAAJ",
      "M7EpKqsAAAAJ",
      "fWd88tEAAAAJ",
      "FY-jB3QAAAAJ",
      "nZsD8XwAAAAJ",
      "b4Kj6MIAAAAJ",
      "zr9B1YgAAAAJ",
      "rdwkreIAAAAJ",
      "v-AEFIEAAAAJ",
      "zjsSMfIAAAAJ",
      "AOdxmJYAAAAJ",
      "GweT9VUAAAAJ",
      "ls_kE0UAAAAJ",
      "xA3RcaUAAAAJ",
      "6dr5fLEAAAAJ",
      "BI8xFr4AAAAJ",
      "Zdl00bEAAAAJ",
      "HEY3UzgAAAAJ",
      "sljtWIUAAAAJ",
      "1VI_oYUAAAAJ",
      "P9FclNEAAAAJ",
      "jEANvfgAAAAJ",
      "mWGyYMsAAAAJ",
      "AscakBgAAAAJ",
      "tWcg0ZsAAAAJ",
      "nuwXTh4AAAAJ",
      "VCpSh3gAAAAJ"
    ],
    "MzD8rjoAAAAJ": [
      "lPycXNcAAAAJ",
      "BBRkKHUAAAAJ",
      "hjTzNuQAAAAJ",
      "Qhe5ua0AAAAJ",
      "3svZOGAAAAAJ",
      "RrYw5jkAAAAJ",
      "bSpGhYcAAAAJ",
      "B1guGw8AAAAJ",
      "_N7091oAAAAJ",
      "2aMqJTgAAAAJ",
      "13Tv6dkAAAAJ",
      "BGggDBwAAAAJ",
      "0DD8EREAAAAJ",
      "UztDgakAAAAJ",
      "oe3NRPQAAAAJ",
      "CFIJZwoAAAAJ",
      "D22GptUAAAAJ",
      "bZNRLNAAAAAJ",
      "GYPCqcYAAAAJ",
      "4jViXZgAAAAJ",
      "2E448xEAAAAJ",
      "fMAg4zEAAAAJ",
      "bWTPrLEAAAAJ",
      "WnFB4iEAAAAJ",
      "ObkOmdMAAAAJ",
      "xRmmtzIAAAAJ",
      "8fiH7UkAAAAJ",
      "DcV-5RAAAAAJ",
      "-EMkK7QAAAAJ",
      "MZqwE-wAAAAJ",
      "zjr6n-QAAAAJ",
      "lVIk1qIAAAAJ",
      "7Ek7pqgAAAAJ",
      "I5jS8ccAAAAJ",
      "2c3HfFAAAAAJ",
      "xlOEqOEAAAAJ",
      "0fJXXaMAAAAJ",
      "ApQt28MAAAAJ",
      "lptAmrMAAAAJ",
      "-qV-RYkAAAAJ",
      "79etgAkAAAAJ",
      "0ZA7y4UAAAAJ",
      "sJIAF-gAAAAJ",
      "r3q68rcAAAAJ",
      "rJ-biB0AAAAJ",
      "UZK1i4EAAAAJ",
      "MtxwDwoAAAAJ",
      "pqP5_PgAAAAJ",
      "1JvIQ8EAAAAJ",
      "DKfEcuEAAAAJ",
      "nc8HAeIAAAAJ",
      "hvpur7kAAAAJ",
      "6_oL_9IAAAAJ",
      "WrFQzBIAAAAJ",
      "QEqPllIAAAAJ",
      "fVo3u5wAAAAJ",
      "M8o8WaQAAAAJ",
      "9rYWg2EAAAAJ",
      "ceYJJmYAAAAJ",
      "UtAdFs8AAAAJ",
      "MT-S2QMAAAAJ",
      "iWq6Tn4AAAAJ",
      "1I0ff2cAAAAJ",
      "8J1kJhIAAAAJ",
      "NW5Y82wAAAAJ",
      "Q-idFOAAAAAJ",
      "EeYvAfIAAAAJ",
      "ofcrge8AAAAJ",
      "mpxO5ycAAAAJ",
      "cYoahsBLcjsC",
      "C0ddY2kAAAAJ",
      "3qPiYJoAAAAJ",
      "8VNhGv4AAAAJ",
      "fhLHgd8AAAAJ",
      "rPU7fz0AAAAJ",
      "1eBgIWsAAAAJ",
      "RtNVud4AAAAJ",
      "4gWt4fgAAAAJ",
      "lQbIarsAAAAJ",
      "CCToMygAAAAJ",
      "3N72KDQAAAAJ",
      "SsEHa6cAAAAJ",
      "zofVx00AAAAJ",
      "WzEQ9QwAAAAJ"
    ],
    "4pWLoJEAAAAJ": [
      "KIxRFxQAAAAJ",
      "JL4E0ZoAAAAJ",
      "_eLWTEUAAAAJ",
      "OI6ouhAAAAAJ",
      "UCsQ8VgAAAAJ",
      "GL3GjBYAAAAJ",
      "qWmCkDMAAAAJ",
      "xyrOk5EAAAAJ",
      "W56NkyoAAAAJ",
      "Q2WSQiEAAAAJ"
    ],
    "tsXh_hwAAAAJ": [],
    "Y8O9N_0AAAAJ": [
      "bqL73OkAAAAJ",
      "j4pcHV4AAAAJ",
      "8wGH7wsAAAAJ",
      "3KF3AIMAAAAJ",
      "P9FclNEAAAAJ",
      "b-o1o7cAAAAJ",
      "d97bGd8AAAAJ",
      "2GKLw94AAAAJ",
      "TDxKd6cAAAAJ",
      "1P8Zu04AAAAJ",
      "bh-uRFMAAAAJ",
      "xQM4BlMAAAAJ",
      "t9HPFawAAAAJ",
      "bioUtz4AAAAJ",
      "DhtAFkwAAAAJ",
      "W8VIEZgAAAAJ",
      "a7drwRMAAAAJ",
      "7OTD-LEAAAAJ",
      "dusV5HMAAAAJ",
      "dUWUGcEAAAAJ",
      "gdO9Gb0AAAAJ",
      "jeOFRDsAAAAJ",
      "Nav8m8gAAAAJ",
      "kNtDoX8AAAAJ",
      "nqoOetAAAAAJ",
      "nfXdXswAAAAJ",
      "nkEGpKsAAAAJ",
      "6QQX88UAAAAJ",
      "PGFk9ZgAAAAJ",
      "lL3KYmMAAAAJ",
      "eml8HfQAAAAJ",
      "j8GFD70AAAAJ",
      "HJHSuxUAAAAJ",
      "p9-ohHsAAAAJ",
      "adnTgaAAAAAJ",
      "ID9QePIAAAAJ",
      "aOklxsQAAAAJ",
      "Fykyo9gAAAAJ",
      "pmVPj94AAAAJ",
      "clTKG0QAAAAJ",
      "-9ifK0cAAAAJ",
      "ceSzF9YAAAAJ",
      "B96GkdgAAAAJ",
      "BO_b2O8AAAAJ",
      "UFokX9EAAAAJ",
      "yqqESloAAAAJ",
      "Zoiu7FsAAAAJ",
      "FLcpd34AAAAJ",
      "_egJxfMAAAAJ",
      "ma7qW2kAAAAJ",
      "0mgEF28AAAAJ",
      "UE9jz_MAAAAJ",
      "mIF9BowAAAAJ",
      "IgWjDugAAAAJ",
      "NbVfqJYAAAAJ",
      "vfTpaOAAAAAJ",
      "6Q-289IAAAAJ",
      "PUz8SCQAAAAJ",
      "_QlCijoAAAAJ",
      "iyVHKkcAAAAJ",
      "XqLiBQMAAAAJ",
      "yAWtq6QAAAAJ",
      "p9-nlRIAAAAJ",
      "bSU7LYoAAAAJ",
      "-B5JgjsAAAAJ",
      "WKO_1VYAAAAJ",
      "pw_0Z_UAAAAJ",
      "BN2Ze-QAAAAJ",
      "rUOpCEYAAAAJ",
      "XPFPohcAAAAJ",
      "R6jE0VEAAAAJ",
      "hv1LiiEAAAAJ",
      "MVanlR8AAAAJ",
      "CCV58dgAAAAJ",
      "HOngPZAAAAAJ",
      "moOv1BsAAAAJ",
      "RTkSatQAAAAJ",
      "wwswAvEAAAAJ",
      "w3GjGqoAAAAJ",
      "GkMfzy4AAAAJ",
      "5ygiTwsAAAAJ",
      "RG9pwnUAAAAJ",
      "DpLFv4gAAAAJ",
      "EaaOeJwAAAAJ",
      "7cuwdr8AAAAJ",
      "aJ_Fr4MAAAAJ",
      "kxqgE9cAAAAJ",
      "ZsgWCyMAAAAJ",
      "9y3Kd3cAAAAJ",
      "VpB8NZ8AAAAJ",
      "vtwH6GkAAAAJ",
      "-ndXYyoAAAAJ",
      "iLOoUqIAAAAJ",
      "_EJrRVAAAAAJ",
      "HwFGzZMAAAAJ",
      "o6LlkNMAAAAJ",
      "UKpinl8AAAAJ",
      "qL2ZsgcAAAAJ",
      "pxFyKAIAAAAJ",
      "WBvt5A8AAAAJ",
      "7rNyP1sAAAAJ",
      "dvplAJkAAAAJ",
      "s1X82zMAAAAJ",
      "tRLUOBIAAAAJ",
      "FJ-huxgAAAAJ",
      "9_AUwFUAAAAJ",
      "L__n1LUAAAAJ",
      "voxznZAAAAAJ",
      "nEsOOx8AAAAJ",
      "9tI89HMAAAAJ",
      "zQwXlaYAAAAJ",
      "HPfNU94AAAAJ",
      "CrfsfFSiS0kC",
      "OZ2MxEYAAAAJ",
      "EM9YhH0AAAAJ",
      "IlgMpNoAAAAJ",
      "lLMX9hcAAAAJ",
      "KWD-mmoAAAAJ",
      "WvufSLAAAAAJ",
      "JFEjS1QAAAAJ",
      "AEsPCAUAAAAJ",
      "LjTCVxAAAAAJ",
      "rEL4-fgAAAAJ",
      "OttawxUAAAAJ",
      "mGMy_kwAAAAJ",
      "BYoq_bwAAAAJ",
      "Khb7qw8AAAAJ",
      "fDHUk18AAAAJ",
      "Mfrpm_IAAAAJ",
      "iO6xAdgAAAAJ",
      "TIST9HIAAAAJ",
      "6CWng3MAAAAJ",
      "TQw8WLEAAAAJ",
      "v19p_0oAAAAJ",
      "pyBSGjgAAAAJ",
      "zYONEFQAAAAJ",
      "5lFDxsMAAAAJ",
      "71L4yYMAAAAJ",
      "LR4CHSkAAAAJ",
      "6yL0xw8AAAAJ",
      "28oeBTgAAAAJ",
      "6G5SEVkAAAAJ",
      "5JserkUAAAAJ",
      "Wk2gAZUAAAAJ",
      "GHpxNQIAAAAJ",
      "31eXgMYAAAAJ",
      "t8UduWwAAAAJ",
      "lXpi86gAAAAJ",
      "aXdjxb4AAAAJ",
      "-XCiamcAAAAJ",
      "7wuq-7AAAAAJ",
      "e9gUdKwAAAAJ",
      "Yv-H6F4AAAAJ",
      "fNl-ZkIAAAAJ",
      "DNuiPHwAAAAJ",
      "F2e_jZMAAAAJ",
      "uVsZydYAAAAJ",
      "NvjazjgAAAAJ",
      "Qirk2fYAAAAJ",
      "51I5vxkAAAAJ",
      "vCHNxFcAAAAJ",
      "mapNJjcAAAAJ",
      "WvtCacIAAAAJ",
      "lyG0vMQAAAAJ",
      "1VI_oYUAAAAJ",
      "jwkE2lgAAAAJ",
      "RyKtqiQAAAAJ",
      "5i2hUToAAAAJ",
      "t4rgICIAAAAJ",
      "1Cv6Sf4AAAAJ",
      "6UHjQQYAAAAJ",
      "NjZsLZwAAAAJ",
      "A3Fw5yMAAAAJ",
      "s5_69i0AAAAJ",
      "uJvw2KUAAAAJ",
      "Qpfxtc8AAAAJ",
      "VfEVlecAAAAJ",
      "CQ1cqKkAAAAJ",
      "IEvwT5kAAAAJ",
      "klyIBq8AAAAJ",
      "RScZCLEAAAAJ",
      "JnUevM0AAAAJ"
    ],
    "kiFd6A8AAAAJ": [
      "DZ3S--MAAAAJ",
      "ahSpJOAAAAAJ",
      "-EZBCBAAAAAJ",
      "LUAuzBAAAAAJ",
      "jiyonF0AAAAJ",
      "aHa6fz4AAAAJ",
      "_pv1sEcAAAAJ",
      "dNRKN3wAAAAJ",
      "rNpUIKAAAAAJ",
      "1MtIU9YAAAAJ"
    ],
    "6-e-ZBEAAAAJ": [],
    "QWzsNMDsvlIC": [
      "AnLxYd8AAAAJ",
      "zS3z8UgAAAAJ",
      "9TKjEuQAAAAJ",
      "XggqoHyV3KQC",
      "YAHWbtkAAAAJ",
      "B847xq8AAAAJ",
      "0iieFBwAAAAJ",
      "JOD3OtAAAAAJ",
      "8kHXJhAAAAAJ",
      "rXyRgbcAAAAJ",
      "0p--0vgAAAAJ",
      "wWWEwk0AAAAJ",
      "D6ZDEUgAAAAJ",
      "QS7Z860AAAAJ",
      "Gz1YIaUAAAAJ",
      "Y4TYXDMAAAAJ",
      "Q7ftcFEAAAAJ",
      "ftI1lBQAAAAJ",
      "wEFxCvMAAAAJ",
      "PEAQZVEAAAAJ",
      "RV-JsYEAAAAJ",
      "1U-VMCIAAAAJ",
      "Ycmx6l8AAAAJ",
      "rLepj0gAAAAJ"
    ],
    "EWJYRncAAAAJ": [
      "fNOReswAAAAJ",
      "HU1K_zsAAAAJ",
      "m_HQ-WQAAAAJ",
      "4R7_wW8AAAAJ",
      "TeuEgRkAAAAJ",
      "qFmoeNkAAAAJ",
      "PtwDrzEAAAAJ",
      "ZE5_-DIAAAAJ",
      "DYUloYkAAAAJ",
      "dK2eepUAAAAJ",
      "b_svo9QAAAAJ",
      "XV30l4MAAAAJ",
      "z3t35rcAAAAJ",
      "i0LZR2gAAAAJ",
      "0cO2nlMAAAAJ",
      "DRTIzTsAAAAJ",
      "k8nSlL4AAAAJ",
      "VoWkBjUAAAAJ",
      "a-3LnGUAAAAJ",
      "WAMYIpQAAAAJ",
      "YAHWbtkAAAAJ",
      "UzlqiSMAAAAJ",
      "mSj0LUsAAAAJ",
      "gWg00ScAAAAJ",
      "U7HnX4kAAAAJ",
      "jaGNt2sAAAAJ",
      "-2E52C0AAAAJ",
      "3jDeUlMAAAAJ",
      "GrDAbaEAAAAJ",
      "dWKDuxcAAAAJ",
      "vmLs7E8AAAAJ",
      "j0_fn9oAAAAJ",
      "00FDOS8AAAAJ",
      "eyqQt3gAAAAJ"
    ],
    "POlWWAsAAAAJ": [
      "xB42z10AAAAJ",
      "Sd8mmE0AAAAJ",
      "wnhU3KoAAAAJ",
      "kIsmHd4AAAAJ",
      "1p3dDesAAAAJ",
      "WtO-bN8AAAAJ",
      "-VQxD1UAAAAJ",
      "RivxoIcAAAAJ",
      "lMqmhpwAAAAJ",
      "_Pvgwd0AAAAJ",
      "4v5x0bUAAAAJ",
      "rUZN-zQAAAAJ",
      "KNdj9HMAAAAJ",
      "usJzGjUAAAAJ",
      "uQnBgK0AAAAJ",
      "CBLnYLEAAAAJ",
      "C7htwEIAAAAJ",
      "eO-yR-0AAAAJ",
      "4DFgv64AAAAJ"
    ],
    "n1zDCkQAAAAJ": [
      "SgNB-ioAAAAJ",
      "dZJy8_8AAAAJ",
      "VKI8EhUAAAAJ",
      "Va50YzkAAAAJ",
      "T7Wa3GQAAAAJ",
      "3rlMzwYAAAAJ",
      "A8x07E0AAAAJ",
      "LCjW058AAAAJ",
      "9jmmp5sAAAAJ",
      "mWS1pY4AAAAJ",
      "cjRV2IsAAAAJ",
      "_BiloKgAAAAJ",
      "PzoN2hgAAAAJ",
      "riuIGwIAAAAJ",
      "STftvjoAAAAJ",
      "Vjo4Tg4AAAAJ",
      "yneRh8EAAAAJ",
      "hDLBEhkAAAAJ",
      "ZP4gfYcAAAAJ",
      "Kv9AbjMAAAAJ",
      "D3nUPbYAAAAJ",
      "KGMaP18AAAAJ",
      "SqAsppUAAAAJ",
      "qO3AeDoAAAAJ",
      "D0lL1r0AAAAJ",
      "O9hYMUUAAAAJ",
      "54wdDqcAAAAJ",
      "FxEDj4wAAAAJ",
      "IiSNwnAAAAAJ",
      "TQgOjK0AAAAJ",
      "gD640BwAAAAJ",
      "vcJ4hAkAAAAJ",
      "OejqtPoAAAAJ",
      "VX7d5EQAAAAJ",
      "iKlE1A8AAAAJ",
      "AaqB_F4AAAAJ",
      "ej3Nb5wAAAAJ",
      "tL9zHywAAAAJ",
      "eLw6g-UAAAAJ",
      "lNQmMTMAAAAJ",
      "C7UqPnoAAAAJ",
      "DplAah0AAAAJ",
      "oJESe-cAAAAJ",
      "nTl5mSwAAAAJ",
      "SdPinGIAAAAJ",
      "-0YOKRoAAAAJ",
      "Ry3K3AMAAAAJ",
      "Adug-7cAAAAJ",
      "Nomi_U0AAAAJ",
      "AjKdHVMAAAAJ",
      "zr22WkQAAAAJ",
      "1FtOcrMAAAAJ",
      "JDErdKcAAAAJ",
      "0w0Dy34AAAAJ",
      "nNVDLb4AAAAJ",
      "2aqu0VMAAAAJ",
      "hon00PIAAAAJ",
      "D1LEg-YAAAAJ",
      "s3lQL7YAAAAJ",
      "dgeikT8AAAAJ",
      "nd8lQQIAAAAJ",
      "zPVItDgAAAAJ"
    ],
    "SqFoZNUAAAAJ": [],
    "3yT6IX4AAAAJ": [
      "iDq2Hu8AAAAJ",
      "Y187sPMAAAAJ",
      "abd1LXcAAAAJ",
      "1QlW92QAAAAJ",
      "FSm4igUAAAAJ",
      "UypFDoQAAAAJ",
      "BQQjcVAAAAAJ",
      "JAp-yScAAAAJ",
      "5q_ZMzYAAAAJ",
      "XpFzyRUAAAAJ",
      "asRzBf4AAAAJ",
      "oAU5b1wAAAAJ",
      "vrqzitkAAAAJ",
      "fuVZQsAAAAAJ",
      "nHPGOOgAAAAJ",
      "wOkPYS4AAAAJ",
      "4Bm4gZEAAAAJ",
      "EYtt2uQAAAAJ",
      "evR07usAAAAJ",
      "Wm0VZrQAAAAJ",
      "bAPC01sAAAAJ",
      "MobIH6EAAAAJ",
      "9-iC3BsAAAAJ"
    ],
    "_1hCq3UAAAAJ": [
      "r44N6h8AAAAJ",
      "opbZfw0AAAAJ",
      "0lZoXCUAAAAJ",
      "YAHWbtkAAAAJ",
      "zghjmDgAAAAJ",
      "zkvW8FQAAAAJ",
      "oOwNKsAAAAAJ",
      "gRxBNZoAAAAJ",
      "G1WMpcUAAAAJ",
      "XD_01h8AAAAJ",
      "2vQRGrYAAAAJ",
      "_PZKLYUAAAAJ",
      "AdAd4QIAAAAJ",
      "0MzVIUsAAAAJ",
      "CBUpEcQAAAAJ",
      "_4dnp0IAAAAJ",
      "6Ff2c8wAAAAJ",
      "SQ1eGN4AAAAJ",
      "xGbDr7YAAAAJ",
      "gWygCaAAAAAJ",
      "U6Tf0VEAAAAJ",
      "q4zv0KYAAAAJ",
      "9ZGqm5QAAAAJ",
      "wAKowxMAAAAJ",
      "GkMfzy4AAAAJ",
      "1oqm0boAAAAJ",
      "F_ASWCUAAAAJ",
      "PJQPzgcAAAAJ",
      "rXYLXJMAAAAJ",
      "SO_j4zwAAAAJ",
      "D-RwB3YAAAAJ",
      "YMmzWH7gT-oC",
      "jn-B_MoAAAAJ",
      "VDyjbagAAAAJ",
      "q3EGms8AAAAJ",
      "BSa0rkwAAAAJ",
      "JPr5FAUAAAAJ",
      "0lcJYs8AAAAJ",
      "nbZ6QlsAAAAJ",
      "Arl0IwUAAAAJ",
      "nf_EnbAAAAAJ"
    ],
    "78WTKm4AAAAJ": [
      "XqLiBQMAAAAJ",
      "hYlbtl8AAAAJ",
      "Y2GtJkAAAAAJ",
      "JfblW3MAAAAJ",
      "v6HphBcAAAAJ",
      "WLN3QrAAAAAJ",
      "7OTD-LEAAAAJ",
      "4GTpCxcAAAAJ",
      "euruCPEAAAAJ",
      "aAX0au8AAAAJ",
      "wIDVzroAAAAJ",
      "gmSwszcAAAAJ",
      "nujTx04AAAAJ",
      "zWfNZnIAAAAJ",
      "hiGI9v0AAAAJ",
      "1OJiqUQAAAAJ",
      "Iv5WU4UAAAAJ",
      "vfPE6hgAAAAJ",
      "lPaISmIAAAAJ",
      "zBUwaGkAAAAJ",
      "GdOmgYwAAAAJ",
      "xaQuPloAAAAJ",
      "vfT6-XIAAAAJ",
      "WkRojboAAAAJ",
      "usawh5oAAAAJ",
      "daslsUkAAAAJ",
      "S1YPXrgAAAAJ",
      "J5ZQ-BUAAAAJ",
      "iyVHKkcAAAAJ",
      "PqlE63kAAAAJ",
      "oN7gaqMAAAAJ",
      "WPYCnqIAAAAJ",
      "wb-DKCIAAAAJ",
      "no_BfYgAAAAJ",
      "1wLVDP4AAAAJ",
      "ZqGaKSgAAAAJ",
      "nEUGF3YAAAAJ",
      "aO8KpGcAAAAJ",
      "8jVzL_YAAAAJ",
      "5WT38A0AAAAJ",
      "qlwwdfEAAAAJ",
      "GX-PtukAAAAJ",
      "Mfrpm_IAAAAJ",
      "rzhzR-cAAAAJ",
      "GcGVcyoAAAAJ",
      "CtRMD1UAAAAJ",
      "9akH-n8AAAAJ",
      "OzMYwDIAAAAJ",
      "bZ9oyW8AAAAJ",
      "WeyLqFUAAAAJ",
      "jUAAhpMAAAAJ",
      "M7y1dj8AAAAJ"
    ],
    "znnl0kwAAAAJ": [
      "8R35rCwAAAAJ",
      "NSWI3OwAAAAJ",
      "DRnOvU8AAAAJ",
      "1wLVDP4AAAAJ",
      "zBUwaGkAAAAJ",
      "vfPE6hgAAAAJ",
      "Aok9lxwAAAAJ",
      "ZWH5jCwAAAAJ",
      "3oe0I0QAAAAJ",
      "y_sLoXoAAAAJ",
      "ZaJEZpYAAAAJ",
      "SJoRNbYAAAAJ",
      "NpOg5soAAAAJ",
      "sgsLkM0AAAAJ",
      "T9To2C0AAAAJ",
      "C2_ZXdcAAAAJ",
      "Ivot3fkAAAAJ",
      "mXtH1UYAAAAJ",
      "uv7g5kMAAAAJ",
      "UpZmJI0AAAAJ",
      "uyYPun0AAAAJ",
      "fpVf9QkAAAAJ",
      "grQ_GBgAAAAJ",
      "n4kXFdsAAAAJ",
      "_EJrRVAAAAAJ",
      "aH8AJu4AAAAJ",
      "kamjbL0AAAAJ",
      "ADkiClQAAAAJ",
      "lPaISmIAAAAJ",
      "xf_n4xUAAAAJ",
      "LmKtwk8AAAAJ",
      "Jun8c34AAAAJ",
      "U89FHq4AAAAJ",
      "kukA0LcAAAAJ",
      "-ZfwQOkAAAAJ",
      "qlwwdfEAAAAJ",
      "5NGAbT4AAAAJ",
      "edQgLXcAAAAJ",
      "UgHB5oAAAAAJ"
    ],
    "nCFeUqYAAAAJ": [],
    "LWlN_BUAAAAJ": [
      "Jlv4MR4AAAAJ",
      "_RVvnS4AAAAJ",
      "0DpK1EMAAAAJ",
      "6iUjvyMAAAAJ",
      "OEJUgwkAAAAJ",
      "MDfW21AAAAAJ",
      "wSstCv0AAAAJ",
      "Xl4E0CsAAAAJ",
      "hRggMmIAAAAJ",
      "LS6HY-gAAAAJ",
      "C6pnolkAAAAJ",
      "kMmxbbIAAAAJ",
      "fEhNO7YAAAAJ",
      "LFiqVpwAAAAJ",
      "O7p7lRAAAAAJ",
      "v474hP4AAAAJ",
      "NLLMDCkAAAAJ",
      "AdAd4QIAAAAJ",
      "8ZpV-lkAAAAJ",
      "zMLbnN4AAAAJ",
      "McgMhW0AAAAJ",
      "xdTtK9IAAAAJ",
      "hzkTiowAAAAJ",
      "ZnT-QpMAAAAJ",
      "YRPveMcAAAAJ",
      "LrsjJfwAAAAJ",
      "7b858c0AAAAJ",
      "LurWtuYAAAAJ",
      "Ar4h7jkAAAAJ",
      "iNcA81MAAAAJ",
      "wpdabDgAAAAJ",
      "TIKl_foAAAAJ",
      "3Lmd6AMAAAAJ",
      "lJCOQ1cAAAAJ",
      "T5GVHawAAAAJ",
      "m3eDp7kAAAAJ",
      "hqTu-QcAAAAJ",
      "8kA3eDwAAAAJ",
      "1KFFbEIAAAAJ",
      "luv0xMIAAAAJ",
      "TLfsJRwAAAAJ",
      "j8svx3IAAAAJ",
      "r3dW1m0AAAAJ",
      "6FWSv1EAAAAJ",
      "OttawxUAAAAJ",
      "HpQGq54AAAAJ",
      "iSL1cKsAAAAJ",
      "jUtYwE0AAAAJ",
      "NfvUWXgAAAAJ",
      "GqZBmfgAAAAJ",
      "UcuXmuwAAAAJ",
      "7qdaJT8AAAAJ",
      "m0PW6DQAAAAJ",
      "Zp2LpwUAAAAJ",
      "vGBcNVAAAAAJ",
      "SQ1eGN4AAAAJ",
      "F8_JP6sAAAAJ",
      "kLUQrrYAAAAJ",
      "gRxBNZoAAAAJ",
      "Z_WrhK8AAAAJ",
      "Tb0ZrYwAAAAJ",
      "MhQPCk8AAAAJ",
      "XD_01h8AAAAJ",
      "ixE1z7UAAAAJ",
      "FY2dQSgAAAAJ",
      "8iQk0DIAAAAJ",
      "L82mYv8AAAAJ",
      "HvI1xmUAAAAJ",
      "PVty8PUAAAAJ",
      "zvC19mQAAAAJ",
      "fE3Bs1oAAAAJ",
      "W4Y0jUIAAAAJ"
    ],
    "C2_ZXdcAAAAJ": [
      "8R35rCwAAAAJ",
      "ijpYJQwAAAAJ",
      "_bs7PqgAAAAJ",
      "iQxXG8kAAAAJ",
      "J6iSjTcAAAAJ",
      "WYkBdO0AAAAJ",
      "_twaeHkAAAAJ",
      "_EJrRVAAAAAJ",
      "t6exkOAAAAAJ"
    ],
    "ijmuZ0wAAAAJ": [
      "bh-uRFMAAAAJ",
      "mu5Y2rYAAAAJ",
      "W8VIEZgAAAAJ",
      "UfbuDH8AAAAJ",
      "-ltRSM0AAAAJ",
      "gYiCq88AAAAJ",
      "4V1nNm4AAAAJ",
      "y1lVpBEAAAAJ",
      "XnhYW0MAAAAJ",
      "ID9QePIAAAAJ",
      "9xDADY4AAAAJ",
      "ZcWO2AEAAAAJ",
      "JY-WzksAAAAJ",
      "NeW9jU8AAAAJ",
      "re00xioAAAAJ",
      "jktWnL8AAAAJ",
      "vtwH6GkAAAAJ",
      "6NjbexEAAAAJ",
      "KhnebkgAAAAJ",
      "ai8A090AAAAJ",
      "fpT49d8AAAAJ",
      "664NOb0AAAAJ",
      "CUlqK5EAAAAJ",
      "0oIAvO8AAAAJ",
      "WfzyRAUAAAAJ",
      "yc4nBNgAAAAJ",
      "3tIEZhAAAAAJ"
    ],
    "LajpoI8AAAAJ": [
      "87nZphcAAAAJ",
      "1M79iLwAAAAJ",
      "vN-is70AAAAJ",
      "nfX25MMAAAAJ",
      "Op-47sgAAAAJ",
      "iyDxq0EAAAAJ",
      "aO8KpGcAAAAJ",
      "B96GkdgAAAAJ"
    ],
    "jrfFYAIAAAAJ": [
      "LuA1j4oAAAAJ",
      "YGQs1AYAAAAJ",
      "DMTuJzAAAAAJ",
      "8R35rCwAAAAJ",
      "Izhkp4YAAAAJ",
      "_ws9LLgAAAAJ",
      "2DBmo-wAAAAJ",
      "l-la0GQAAAAJ",
      "54yrQIkAAAAJ",
      "LW7uksIAAAAJ",
      "eDQsOFMAAAAJ",
      "n-q-55wAAAAJ",
      "yy0UFOwAAAAJ",
      "WCUNvnkAAAAJ",
      "3Yjo-W8AAAAJ",
      "T7uctwYAAAAJ",
      "vfPE6hgAAAAJ",
      "ADkiClQAAAAJ",
      "OI7zFmwAAAAJ",
      "IMoAPLUAAAAJ",
      "LIJQ_ZYAAAAJ",
      "rjnJnEkAAAAJ",
      "65bIT4oAAAAJ",
      "Z3dxz9IAAAAJ",
      "lgvyqMQAAAAJ",
      "wotfaAgAAAAJ",
      "NSWI3OwAAAAJ",
      "-S_9ZRcAAAAJ",
      "_WLInT0AAAAJ",
      "6S9C8XoAAAAJ",
      "SzHPa90AAAAJ",
      "uemlfQYAAAAJ",
      "Wx62iOsAAAAJ",
      "PYLHQsYAAAAJ",
      "_Whqm1IAAAAJ",
      "yBs28hUAAAAJ"
    ],
    "62e5CygAAAAJ": [
      "UgHB5oAAAAAJ",
      "A3wg18wAAAAJ",
      "HvjirogAAAAJ",
      "r30eXmkAAAAJ",
      "-5_ksIkAAAAJ",
      "LUe32ToAAAAJ",
      "mqpjAt4AAAAJ",
      "bh-uRFMAAAAJ",
      "nABXo3sAAAAJ",
      "KgZxzjsAAAAJ",
      "sPlonWcAAAAJ",
      "I1mOQpAAAAAJ",
      "tgm2Y7oAAAAJ",
      "6QQX88UAAAAJ",
      "48Y9F-YAAAAJ",
      "DqXsbPAAAAAJ",
      "zRy-zdAAAAAJ",
      "4GpKQUIAAAAJ",
      "FodLUKcAAAAJ"
    ],
    "NOoKltoAAAAJ": [
      "7t4jbPQAAAAJ",
      "4bl7qAgAAAAJ",
      "1NyT9gQAAAAJ",
      "RCi98EAAAAAJ",
      "xxjDmR4AAAAJ",
      "UgHB5oAAAAAJ",
      "NB4pgZYAAAAJ",
      "jkwHy3AAAAAJ",
      "z7b0sKUAAAAJ",
      "8IH6kXQAAAAJ",
      "rynvwScAAAAJ",
      "UMG3OGgAAAAJ",
      "rqUJfaUAAAAJ",
      "emiAAG0AAAAJ"
    ],
    "L-diWvQAAAAJ": [],
    "YNoe5GAAAAAJ": [
      "5tyrt68AAAAJ"
    ],
    "ajIYB6wAAAAJ": [],
    "QxbpIMUAAAAJ": [],
    "DZ3S--MAAAAJ": [
      "kiFd6A8AAAAJ",
      "_pv1sEcAAAAJ",
      "aHa6fz4AAAAJ",
      "07kG-YsAAAAJ",
      "CcruPcoAAAAJ",
      "PuTDB5gAAAAJ",
      "Pczk-PQAAAAJ",
      "jiyonF0AAAAJ",
      "GJaAw1EAAAAJ",
      "jEHm-fUAAAAJ",
      "mnU3HpcAAAAJ",
      "SjjIQ24AAAAJ",
      "kSvJTg4AAAAJ",
      "1MtIU9YAAAAJ",
      "Ya3CmFcAAAAJ",
      "1RuDJX8AAAAJ",
      "eWRBqsYAAAAJ",
      "4qCGgpsAAAAJ",
      "5g3iJvYAAAAJ",
      "nUZG1SEAAAAJ",
      "IFljhlMAAAAJ",
      "cdpb5UcAAAAJ",
      "LUAuzBAAAAAJ",
      "iuRC7jgAAAAJ",
      "C1FZEtkAAAAJ",
      "Bq1dFNQAAAAJ",
      "9BHYPnUAAAAJ",
      "Y_Nmd2sAAAAJ",
      "2kfmAzEAAAAJ",
      "wBu1J2MAAAAJ",
      "EMq6KwMAAAAJ",
      "LtdHRjsAAAAJ",
      "vJxuKwgAAAAJ",
      "yfy_BGIAAAAJ",
      "70LBhKcAAAAJ",
      "7k2LuTkAAAAJ",
      "7XY3l2wAAAAJ",
      "Ey5aInIAAAAJ",
      "B3Xd8-kAAAAJ",
      "PH1aZPsAAAAJ",
      "afgNSP8AAAAJ",
      "7ZNoHJkAAAAJ",
      "Bjf-KF8AAAAJ",
      "ZZP1cXYAAAAJ",
      "BPFqibsAAAAJ",
      "6cNoBY4AAAAJ",
      "UcGN3MoAAAAJ",
      "SJi-EFwAAAAJ",
      "e65kJ08AAAAJ",
      "gd23c7MAAAAJ",
      "smm3MNcAAAAJ",
      "2NHX1bIAAAAJ",
      "_uBxMwkAAAAJ",
      "c5JFDEgAAAAJ",
      "uDG9sXQAAAAJ",
      "rNpUIKAAAAAJ",
      "QAdcBnQAAAAJ",
      "QKtoEnkAAAAJ",
      "fwJ4_WUAAAAJ",
      "Z43BgdEAAAAJ",
      "oLiBK8cAAAAJ",
      "dNRKN3wAAAAJ",
      "F3ba0dEAAAAJ",
      "qwOPQdIAAAAJ",
      "ieyW4WQAAAAJ",
      "NECavRYAAAAJ",
      "ULRIRdgAAAAJ",
      "H1JXhMIAAAAJ",
      "zeK3OSYAAAAJ",
      "LLkgMYQAAAAJ",
      "OMVTRscAAAAJ",
      "6cuNVagAAAAJ",
      "EMExrOMAAAAJ",
      "VaLB21wAAAAJ",
      "Z7d93ZYAAAAJ",
      "iD01qbkAAAAJ",
      "vI5qd9AAAAAJ",
      "_s5DZOcAAAAJ",
      "mEgZUP8AAAAJ",
      "HAgGqScAAAAJ",
      "ww-6D6wAAAAJ",
      "onJXki0AAAAJ",
      "bWBQzhQAAAAJ",
      "wstakvUAAAAJ",
      "3yT6IX4AAAAJ",
      "jEdhxGMAAAAJ",
      "n_N-PJkAAAAJ",
      "iyPP6VYAAAAJ"
    ],
    "FyQAwaEAAAAJ": [
      "bh-uRFMAAAAJ",
      "AEsPCAUAAAAJ",
      "-ltRSM0AAAAJ",
      "UpZmJI0AAAAJ",
      "aOklxsQAAAAJ",
      "d97bGd8AAAAJ"
    ],
    "-QopmQoAAAAJ": [
      "5tk1PV8AAAAJ",
      "K0kaNvkAAAAJ",
      "8R35rCwAAAAJ",
      "ySLrpsYAAAAJ",
      "wYMTld8AAAAJ",
      "zBUwaGkAAAAJ",
      "dD7EpwQAAAAJ",
      "7c1B_fIAAAAJ",
      "DsHKK-AAAAAJ",
      "8RVWMycAAAAJ",
      "PTS2AOgAAAAJ",
      "i6tMWAoAAAAJ",
      "0gp5M-kAAAAJ",
      "T9To2C0AAAAJ",
      "WNHLjp0AAAAJ",
      "MOfaB6oAAAAJ",
      "33yNvIgAAAAJ",
      "w3PrbKwAAAAJ"
    ],
    "MSCQE-YAAAAJ": [
      "NqsBRwMAAAAJ",
      "xkIcvmIAAAAJ",
      "Ha8rlUgAAAAJ",
      "pGib_yMAAAAJ",
      "XEztdZgAAAAJ",
      "pkp4VXUAAAAJ",
      "mEEklegAAAAJ",
      "wSstCv0AAAAJ",
      "syUpc-gAAAAJ",
      "OGEyrG8AAAAJ",
      "gh_fDicAAAAJ",
      "m5v0PNIAAAAJ",
      "Mbg9vJMAAAAJ",
      "175Mu2wAAAAJ"
    ],
    "vfPE6hgAAAAJ": [
      "8R35rCwAAAAJ",
      "vtwH6GkAAAAJ",
      "TwABcRgAAAAJ",
      "5VaXUQsAAAAJ",
      "_0IIzxgAAAAJ",
      "yy0UFOwAAAAJ",
      "q77J4fgAAAAJ",
      "EHSuFcwAAAAJ",
      "1zmDOdwAAAAJ",
      "OFlBL2kAAAAJ",
      "A20BZnQAAAAJ",
      "pouyVyUAAAAJ",
      "SRM4v2cAAAAJ",
      "BAAZ_ysAAAAJ",
      "bslhbWgAAAAJ",
      "ogXTOZ4AAAAJ",
      "ZaJEZpYAAAAJ",
      "bh-uRFMAAAAJ",
      "3Y4egcYAAAAJ",
      "zBUwaGkAAAAJ",
      "wfGiqXEAAAAJ",
      "_EJrRVAAAAAJ",
      "6S9C8XoAAAAJ",
      "1wLVDP4AAAAJ",
      "Nn990CkAAAAJ",
      "8-p9CLsAAAAJ",
      "DRnOvU8AAAAJ",
      "QxLpghAAAAAJ",
      "DkUUhXEAAAAJ",
      "Ivot3fkAAAAJ",
      "wb-DKCIAAAAJ",
      "-tEiRFcAAAAJ",
      "e1P1rNkAAAAJ",
      "UAwKvEsAAAAJ",
      "iYN86KEAAAAJ",
      "RhOpyXcAAAAJ",
      "I6sTssIAAAAJ"
    ],
    "nfX25MMAAAAJ": [
      "LeshmV8AAAAJ",
      "yxUduqMAAAAJ",
      "aOklxsQAAAAJ",
      "87nZphcAAAAJ",
      "vN-is70AAAAJ",
      "1M79iLwAAAAJ",
      "B96GkdgAAAAJ",
      "XYpPTpQAAAAJ",
      "-lKb3XwAAAAJ",
      "iyDxq0EAAAAJ",
      "H1d4BS8AAAAJ",
      "L_m67ywAAAAJ",
      "vEYUIioAAAAJ",
      "_7Q8uIYAAAAJ",
      "xMhGYpgAAAAJ",
      "ogtsTE4AAAAJ",
      "VOf45S0AAAAJ",
      "Z-2pv_wAAAAJ",
      "cQ1P1qoAAAAJ",
      "nRQi4O8AAAAJ",
      "LYRkQhMAAAAJ",
      "uplepqQAAAAJ",
      "lBO12XgAAAAJ",
      "fWCoyDcAAAAJ",
      "jhPhgf4AAAAJ",
      "y-RSDYYAAAAJ",
      "oo8QRmIAAAAJ",
      "k5HsbdcAAAAJ",
      "O7q6DkEAAAAJ",
      "NGdMpTYAAAAJ",
      "nxwNAEgAAAAJ",
      "uVrmjIAAAAAJ",
      "Op-47sgAAAAJ",
      "i5srt20AAAAJ",
      "Edh7brQAAAAJ",
      "OPlpj2YAAAAJ",
      "3343olgAAAAJ",
      "U9EvD0wAAAAJ",
      "LajpoI8AAAAJ",
      "EV3kaHYAAAAJ",
      "ixGMcjsAAAAJ",
      "w3DSGTIAAAAJ",
      "LUe32ToAAAAJ",
      "lDmZxTMAAAAJ",
      "uTRczaUAAAAJ",
      "X71o1ykAAAAJ",
      "gZ-RhocAAAAJ",
      "vEYl-MUAAAAJ",
      "wzifqNkAAAAJ",
      "aH5QOEcAAAAJ",
      "8fztli4AAAAJ",
      "ROILf3EAAAAJ",
      "w3KgvQIAAAAJ",
      "qq4zSmQAAAAJ",
      "gFLW9qcAAAAJ",
      "xIpN5lQAAAAJ",
      "gSLAdnEAAAAJ",
      "aO8KpGcAAAAJ",
      "6oqV3v8AAAAJ",
      "X5NSuikAAAAJ",
      "bV_IUy8AAAAJ",
      "JTtnJUIAAAAJ",
      "I1EvjZsAAAAJ",
      "1rPi_78AAAAJ",
      "_3bbpWoAAAAJ",
      "Vn3L_ioAAAAJ",
      "NMPUDa0AAAAJ",
      "oDE4I64AAAAJ",
      "ijH0-a8AAAAJ",
      "COEsqLYAAAAJ",
      "l_G2vr0AAAAJ",
      "bjdB4K8AAAAJ",
      "ljAjAcAAAAAJ",
      "k6-nvDAAAAAJ",
      "q4qDvAoAAAAJ",
      "RatgWlcAAAAJ",
      "_8rw_GMAAAAJ",
      "0wZN6hEAAAAJ",
      "N_KDBGcAAAAJ",
      "pbmjtZsAAAAJ",
      "TAAQ1LwAAAAJ",
      "eZJI5sAAAAAJ",
      "8l9BcBAAAAAJ",
      "YO5XSXwAAAAJ",
      "ElZ0iNkAAAAJ",
      "qU-JFvMAAAAJ",
      "Vy16O5UAAAAJ",
      "CylZPggAAAAJ",
      "76crpgsAAAAJ",
      "EWY1qlkAAAAJ",
      "Iz3m3v4AAAAJ",
      "94yn2j0AAAAJ",
      "YXJ-_k0AAAAJ",
      "TW7U1W0AAAAJ",
      "UE9jz_MAAAAJ",
      "MgzHAPQAAAAJ",
      "uqWkLzMAAAAJ",
      "WIAYNzMAAAAJ",
      "-2ATsToAAAAJ",
      "3yVndk0AAAAJ",
      "R4IDPnoAAAAJ",
      "KG0pbOYAAAAJ",
      "BB833ugAAAAJ",
      "BxmyKVoAAAAJ",
      "b5TVr_UAAAAJ",
      "1OJiqUQAAAAJ",
      "bh-uRFMAAAAJ",
      "JZIeZ3MAAAAJ",
      "qCmF95EAAAAJ",
      "R_2aiNIAAAAJ",
      "ykuVSuEAAAAJ",
      "Wb_lnjAAAAAJ",
      "xCYHonIAAAAJ",
      "9nnDvooAAAAJ",
      "9MSArZUAAAAJ",
      "MlDSA9sAAAAJ",
      "KsGo-_QAAAAJ",
      "5b8b5V8AAAAJ"
    ],
    "2ItLnFgAAAAJ": [
      "bhpi3vgAAAAJ",
      "msQ4KT4AAAAJ",
      "qSNAaCsAAAAJ",
      "GazEl1wAAAAJ",
      "bh-uRFMAAAAJ",
      "9xDADY4AAAAJ",
      "UfbuDH8AAAAJ",
      "LNJMblcAAAAJ",
      "mqpjAt4AAAAJ",
      "LQSNuf0AAAAJ",
      "k2AHIx8AAAAJ",
      "ZWPqDxEAAAAJ",
      "Iq0KSBYAAAAJ",
      "0IXxNKsAAAAJ",
      "SFCOJxMAAAAJ",
      "pAiIxxkAAAAJ",
      "rSuG-f4AAAAJ",
      "XCkp5uEAAAAJ",
      "MA6SDuEAAAAJ",
      "6iPoAXAAAAAJ",
      "9pI3MrEAAAAJ",
      "TVfLgPAAAAAJ",
      "gYiCq88AAAAJ",
      "GD5bzTgAAAAJ",
      "sbBPoc0AAAAJ",
      "iBGPazIAAAAJ",
      "iAdho-sAAAAJ",
      "hlLuENoAAAAJ",
      "Bk5BJ80AAAAJ",
      "t4IWpnYAAAAJ",
      "BSDXhwgAAAAJ",
      "04TxLAIAAAAJ",
      "4-ccLwEAAAAJ",
      "LfkSQW4AAAAJ",
      "IZC7zeUAAAAJ",
      "okcbLqoAAAAJ",
      "Cxh2C2oAAAAJ",
      "56EZh6YAAAAJ",
      "DplAah0AAAAJ",
      "199M69AAAAAJ",
      "LigYduEAAAAJ",
      "-R2kv9MAAAAJ",
      "bo0P2qYAAAAJ",
      "wjjDKWkAAAAJ",
      "FUiFDqUAAAAJ",
      "xG9s8HEAAAAJ",
      "SMSWgw0AAAAJ",
      "l-BJCdAAAAAJ",
      "tQuQ1FwAAAAJ",
      "lcOacs8AAAAJ",
      "B58vq_cAAAAJ",
      "-yZse64AAAAJ",
      "OYh64JwAAAAJ",
      "tQgvgxkAAAAJ",
      "fXl8n9YAAAAJ",
      "pKnD8WcAAAAJ",
      "Ae9GkVQAAAAJ",
      "9FZlpDMAAAAJ",
      "iGgOj5oAAAAJ",
      "uUuq67cAAAAJ",
      "DtV6CrMAAAAJ",
      "wqHic0AAAAAJ",
      "7qTg_1kAAAAJ",
      "6mgnauMAAAAJ",
      "Wsru2ZYAAAAJ",
      "Y3pGXxwAAAAJ",
      "Ph-fOwQAAAAJ",
      "4QvYJ00AAAAJ",
      "fF1B7mAAAAAJ",
      "4V1nNm4AAAAJ",
      "dlV-qnUAAAAJ",
      "1CLaPMEAAAAJ",
      "-LJCZMMAAAAJ",
      "JeLy9lMAAAAJ",
      "D5CISpEAAAAJ",
      "qhEK194AAAAJ",
      "YuOHpwUAAAAJ",
      "zX7fPHkAAAAJ",
      "XDsMg4YAAAAJ",
      "D-AN9vQAAAAJ",
      "am2ohp0AAAAJ",
      "lmQkD9UAAAAJ",
      "4sgWuPcAAAAJ",
      "bKlSszcAAAAJ",
      "Jg7O2scAAAAJ",
      "8RJ07aQAAAAJ"
    ],
    "aC55XVgAAAAJ": [
      "E1c2bVoAAAAJ",
      "3mQFWSYAAAAJ"
    ],
    "sRpY9TIAAAAJ": [],
    "w-xdg4sAAAAJ": [
      "a5nY-pYAAAAJ",
      "vtwH6GkAAAAJ",
      "0Y3a3M4AAAAJ",
      "JrKoQLgAAAAJ",
      "xdCvBg0AAAAJ",
      "8IMaM0QAAAAJ",
      "ebrNfPAAAAAJ",
      "CdEMlrIAAAAJ"
    ],
    "DRnOvU8AAAAJ": [
      "8R35rCwAAAAJ",
      "ITZ1e7MAAAAJ",
      "1wLVDP4AAAAJ",
      "vfPE6hgAAAAJ",
      "eGIw04UAAAAJ",
      "njAD34UAAAAJ",
      "l-la0GQAAAAJ",
      "znnl0kwAAAAJ",
      "B8wslVsAAAAJ",
      "-GduGkcAAAAJ",
      "T9To2C0AAAAJ",
      "Ivot3fkAAAAJ",
      "d5y4iKAAAAAJ",
      "xUGZX_MAAAAJ",
      "PKRe4QwAAAAJ",
      "5jIJb38AAAAJ",
      "wAxr6b8AAAAJ",
      "b2LJDtMAAAAJ",
      "ADkiClQAAAAJ",
      "yy0UFOwAAAAJ",
      "5pKTRxEAAAAJ",
      "xBH73TYAAAAJ",
      "vtwH6GkAAAAJ",
      "KCdL5B0AAAAJ",
      "vYougn0AAAAJ",
      "_QlCijoAAAAJ",
      "3MzhkFIAAAAJ",
      "8cxDHS4AAAAJ"
    ],
    "BIwrJuQAAAAJ": [
      "8R35rCwAAAAJ",
      "BsOkXDsAAAAJ",
      "5dBp2f4AAAAJ",
      "8TArOy0AAAAJ",
      "bdHgGgEAAAAJ",
      "vtwH6GkAAAAJ",
      "1O83J5MAAAAJ",
      "VT7peyEAAAAJ",
      "bBLqsgkAAAAJ",
      "jERkdhIAAAAJ",
      "Vlfz-_IAAAAJ",
      "B8wslVsAAAAJ",
      "-WZcuuwAAAAJ",
      "iBBpnUEAAAAJ",
      "BOAOkNQAAAAJ",
      "ao8r3Q4AAAAJ",
      "duOys3YAAAAJ",
      "sb3lPX8AAAAJ",
      "jbYnJLMAAAAJ",
      "SIayDoQAAAAJ",
      "6uIhh6MAAAAJ",
      "1wLVDP4AAAAJ",
      "QxLpghAAAAAJ",
      "fSXCOfEAAAAJ",
      "MbBntPgAAAAJ",
      "XYsMnBsAAAAJ",
      "pzkLOIwAAAAJ",
      "3BMRzr8AAAAJ"
    ],
    "T6PbwPIAAAAJ": [
      "wfGiqXEAAAAJ",
      "Vs-MdPcAAAAJ",
      "NkzyCvUAAAAJ",
      "rDfyQnIAAAAJ",
      "ImpbxLsAAAAJ",
      "ygFAcZwAAAAJ",
      "sUK_w2QAAAAJ",
      "dGs2BcIAAAAJ"
    ],
    "MK6zHkYAAAAJ": [
      "WfS41RAAAAAJ",
      "4zybTq4AAAAJ",
      "sqCGBtYAAAAJ",
      "gjLr_FgAAAAJ",
      "iTv2cOgAAAAJ",
      "DulpV-cAAAAJ",
      "Vb3FLmkAAAAJ",
      "s_3ZE8kAAAAJ",
      "70vJVxcAAAAJ",
      "kwnwhrgAAAAJ",
      "umFQktIAAAAJ",
      "_fxnybwAAAAJ",
      "KQaf5-wAAAAJ",
      "FcRGdiwAAAAJ",
      "mFbLNZQAAAAJ",
      "4WEQ8h0AAAAJ",
      "MbF6rTEAAAAJ",
      "jH9i188AAAAJ",
      "ke0k9PkAAAAJ",
      "bYhGFrwAAAAJ",
      "w1srHyIAAAAJ",
      "K6ef57QAAAAJ",
      "zbXIQMsAAAAJ",
      "wB01auEAAAAJ",
      "Jnei_lEAAAAJ",
      "AUJuK3AAAAAJ",
      "ijH0-a8AAAAJ",
      "BGN4egcAAAAJ",
      "LpWGWAwAAAAJ",
      "nwHfwCIAAAAJ",
      "UNHdIKoAAAAJ",
      "2kPveDIAAAAJ",
      "LKv32bgAAAAJ",
      "E_a3VB4AAAAJ",
      "2mYxmokAAAAJ",
      "y8s4ok0AAAAJ",
      "ViBqWZYAAAAJ",
      "9wibWOoAAAAJ",
      "oDwLyYUAAAAJ",
      "3I4iQioAAAAJ",
      "Jy0SwIcAAAAJ",
      "q4qDvAoAAAAJ",
      "jJ8BLgsAAAAJ",
      "m8NUgw0AAAAJ",
      "1rV69hMAAAAJ",
      "Uhf4nBkAAAAJ",
      "jr7gGB4AAAAJ",
      "_8rw_GMAAAAJ",
      "wFLYIm0AAAAJ",
      "f8RkRagAAAAJ",
      "NMPUDa0AAAAJ",
      "cGxq0cMAAAAJ",
      "NcIqQ88AAAAJ",
      "DsR4PucAAAAJ",
      "b3HMX-sAAAAJ",
      "HGNZ1fkAAAAJ",
      "lzfVm_8AAAAJ",
      "55TAOdgAAAAJ",
      "YqKbGXAAAAAJ",
      "cHAnhqcAAAAJ",
      "AjX6hisAAAAJ",
      "fkGi-JMAAAAJ",
      "NFCefosAAAAJ",
      "zkvW8FQAAAAJ",
      "_1hCq3UAAAAJ",
      "i1NrG8UAAAAJ",
      "CTT44Y0AAAAJ",
      "Zp2LpwUAAAAJ",
      "PHvnX-EAAAAJ",
      "T4DF6CAAAAAJ",
      "bVWm69gAAAAJ",
      "kezPqwoAAAAJ",
      "s1UQI6kAAAAJ",
      "X-s3kzUAAAAJ",
      "j5N3bKYAAAAJ",
      "uhFQ9WgAAAAJ",
      "rrJTgX0AAAAJ",
      "glV_LWsAAAAJ",
      "lPM8k54AAAAJ",
      "kb4ubhcAAAAJ",
      "Yh0IoBgAAAAJ",
      "y2pH4jcAAAAJ",
      "xDNZlnMAAAAJ",
      "sSPq-ZEAAAAJ",
      "M3XQkq4AAAAJ",
      "p8Y0xJEAAAAJ",
      "oYAf_hgAAAAJ",
      "k4Q3TYwAAAAJ",
      "Nh832fgAAAAJ",
      "gRxBNZoAAAAJ",
      "fEhNO7YAAAAJ",
      "soDBSE8AAAAJ",
      "BF39lMQAAAAJ",
      "NkYQr9QAAAAJ",
      "mQnBkmoAAAAJ",
      "Cl73CgcAAAAJ",
      "Nmk26z4AAAAJ",
      "x942ipYAAAAJ",
      "7YWMCDkAAAAJ",
      "is41ryYAAAAJ",
      "IFZY5fMAAAAJ",
      "JhIotuYAAAAJ",
      "QSVAzVIAAAAJ",
      "cht-q2UAAAAJ",
      "UNzFsf4AAAAJ",
      "SKaPm_QAAAAJ",
      "YK0NLaUAAAAJ"
    ],
    "NTb14PgAAAAJ": [
      "F27Q6V4AAAAJ",
      "0-YNNKUAAAAJ",
      "YtAIQ34AAAAJ",
      "9jfZ5SIAAAAJ",
      "8U7qLuIAAAAJ"
    ],
    "5MTY7-wAAAAJ": [
      "bh-uRFMAAAAJ",
      "zK33NPkAAAAJ",
      "mDNhPjAAAAAJ",
      "lXBUU7EAAAAJ",
      "TXqPY5IAAAAJ",
      "GtfVLBAAAAAJ",
      "MZHW6YMAAAAJ",
      "-QZbHHoAAAAJ",
      "ZqLIu1EAAAAJ",
      "YVfxyeQAAAAJ",
      "Yy6WaDkAAAAJ",
      "AScNRHUAAAAJ",
      "PDIstVQAAAAJ",
      "x5iJp8oAAAAJ",
      "ZxeB6xkAAAAJ",
      "RdvLNP4AAAAJ",
      "z8tUc2IAAAAJ",
      "Jp6Mz1sAAAAJ",
      "NcB2lzcAAAAJ",
      "uu7LudIAAAAJ",
      "mx0jp-YAAAAJ",
      "rftklyIAAAAJ",
      "APgaFK0AAAAJ",
      "B88-xMEAAAAJ",
      "XXUsEjsAAAAJ",
      "ZNE6TqsAAAAJ",
      "GIejbKQAAAAJ",
      "KKLUF8kAAAAJ",
      "b7JHXbgAAAAJ",
      "nRPjLBQAAAAJ",
      "Jwmp358AAAAJ"
    ],
    "85XK-uAAAAAJ": [
      "xaYqRfAAAAAJ"
    ],
    "DwdjBUUAAAAJ": [
      "B96GkdgAAAAJ",
      "K3QJPdMAAAAJ",
      "ID9QePIAAAAJ",
      "u4olrOcAAAAJ",
      "zjlFcrEAAAAJ",
      "qUt2HE8AAAAJ",
      "cEDjw_wAAAAJ",
      "3B2c31wAAAAJ",
      "mNguJ48AAAAJ",
      "_ruE6kgAAAAJ"
    ],
    "X-Sd3-8AAAAJ": [],
    "eurA6WgAAAAJ": [],
    "FFWXLHUAAAAJ": [
      "yxUduqMAAAAJ",
      "zP0S_ikAAAAJ",
      "vN-is70AAAAJ",
      "itSa94cAAAAJ",
      "8R35rCwAAAAJ",
      "vtwH6GkAAAAJ",
      "IcaU830AAAAJ",
      "7w24ptsAAAAJ",
      "7P-gZioAAAAJ",
      "MvYTnPoAAAAJ",
      "8fztli4AAAAJ",
      "FH9nKOAAAAAJ",
      "yZGlLeMAAAAJ",
      "m0WCd-4AAAAJ",
      "ROJq4g4AAAAJ",
      "zIv6YN0AAAAJ"
    ],
    "t8v3JXsAAAAJ": [],
    "Fsz9BAUAAAAJ": [
      "cYoahsBLcjsC",
      "wDltOqQAAAAJ",
      "ySwF8ioAAAAJ",
      "nTiSnwUAAAAJ",
      "B48jbeEAAAAJ",
      "0qfCL-QAAAAJ",
      "Jz1O6loAAAAJ",
      "5ZYeWgcAAAAJ",
      "FNwI36EAAAAJ",
      "k-o3JBIAAAAJ",
      "AEy91GEAAAAJ",
      "YxkMuYsAAAAJ",
      "lQbIarsAAAAJ",
      "MT-S2QMAAAAJ",
      "U8dAtsQAAAAJ",
      "56urJP0AAAAJ",
      "2E448xEAAAAJ",
      "6S09ezcAAAAJ",
      "lrzfjUQAAAAJ",
      "dJRKST0AAAAJ",
      "Ci5YRtAAAAAJ",
      "SUAT64AAAAAJ",
      "aO8KpGcAAAAJ",
      "1azFZ6cAAAAJ",
      "wfnTS8UAAAAJ",
      "lOhHz0gAAAAJ",
      "tJlviVYAAAAJ",
      "Bphl_fIAAAAJ",
      "UZK1i4EAAAAJ",
      "R-7TkKkAAAAJ",
      "eGj3ay4AAAAJ",
      "MSgWKbYAAAAJ",
      "Viv2E9AAAAAJ",
      "OdLQTz4AAAAJ",
      "LAl0EukAAAAJ",
      "YQ0GIUwAAAAJ",
      "k8uWc34AAAAJ"
    ],
    "a5nY-pYAAAAJ": [
      "oVLqz3AAAAAJ",
      "ify5zKQAAAAJ",
      "68HhxmAAAAAJ",
      "w-xdg4sAAAAJ",
      "qTCXoLQAAAAJ",
      "vtwH6GkAAAAJ",
      "bTG82acAAAAJ",
      "V6rOl-gAAAAJ",
      "Tiq0XaMAAAAJ",
      "txxQb7cAAAAJ",
      "0Y3a3M4AAAAJ",
      "1FrpQaQAAAAJ",
      "Ks1yyXYAAAAJ",
      "k0b8yXkAAAAJ",
      "ijIHem4AAAAJ",
      "VAamLcEAAAAJ",
      "GkwzzEAAAAAJ",
      "74w7FDUAAAAJ",
      "yQNhFGUAAAAJ",
      "HSPbKTAAAAAJ",
      "I1EvjZsAAAAJ",
      "P2rIVYIAAAAJ",
      "YAGjro8AAAAJ",
      "zK4uegoAAAAJ",
      "dI-eZ3sAAAAJ",
      "p0sQC6sAAAAJ",
      "hSUP-4cAAAAJ",
      "5_l9dl8AAAAJ",
      "OQHNvrEAAAAJ",
      "GExyiRkAAAAJ",
      "32gDqAYAAAAJ",
      "_2k-ppwAAAAJ"
    ],
    "gYiCq88AAAAJ": [
      "bh-uRFMAAAAJ",
      "UfbuDH8AAAAJ",
      "9xDADY4AAAAJ",
      "W8VIEZgAAAAJ",
      "MxxZkEcAAAAJ",
      "mu5Y2rYAAAAJ",
      "20_pofsAAAAJ",
      "luv0xMIAAAAJ",
      "ijmuZ0wAAAAJ",
      "-ltRSM0AAAAJ",
      "90FJPJUAAAAJ",
      "TmWYBeEAAAAJ",
      "cdP5JicAAAAJ",
      "-pu6i_4AAAAJ",
      "y3xgouMAAAAJ",
      "Y6L6ZYsAAAAJ",
      "3kDtybgAAAAJ",
      "pvyI8GkAAAAJ",
      "j3CEIuEAAAAJ",
      "p9RsPG4AAAAJ",
      "vQa7heEAAAAJ",
      "mqpjAt4AAAAJ",
      "rE7-N30AAAAJ",
      "7U_OA0oAAAAJ",
      "Zfzp_GIAAAAJ",
      "7IDZrScAAAAJ",
      "S6H-0RAAAAAJ",
      "nABXo3sAAAAJ",
      "JrX99ekAAAAJ",
      "uAsllJMAAAAJ",
      "ruHs0xMAAAAJ",
      "ZZ61SZwAAAAJ",
      "LAv0HTEAAAAJ",
      "C-ZlBWMAAAAJ",
      "6GdwHssAAAAJ",
      "9QR0uE4AAAAJ",
      "svJIv28AAAAJ",
      "Tw8DY-cAAAAJ",
      "qvrqNfwAAAAJ",
      "3MzhkFIAAAAJ",
      "mIF9BowAAAAJ",
      "jInmtEkAAAAJ",
      "4QvYJ00AAAAJ",
      "ACjYGPUAAAAJ",
      "rTw-pq0AAAAJ",
      "2ItLnFgAAAAJ",
      "8BeTDr0AAAAJ",
      "YdHW1ycAAAAJ",
      "t5Xsx0IAAAAJ",
      "eGIw04UAAAAJ",
      "Izhkp4YAAAAJ",
      "k4l-zNYAAAAJ",
      "Vzr1RukAAAAJ",
      "7c1B_fIAAAAJ",
      "Svk4ntYAAAAJ",
      "ScoZZPsAAAAJ",
      "T7uctwYAAAAJ",
      "NvMCACEAAAAJ",
      "jn5r6TsAAAAJ",
      "LLnrH8IAAAAJ",
      "9om-fCsAAAAJ",
      "CSHNLDcAAAAJ",
      "vtwH6GkAAAAJ",
      "1TqAq5AAAAAJ",
      "8R35rCwAAAAJ",
      "T9To2C0AAAAJ",
      "Lncr-VoAAAAJ",
      "Gzo8z-kAAAAJ",
      "sm1q2bYAAAAJ",
      "1HO5UacAAAAJ",
      "56EZh6YAAAAJ",
      "DplAah0AAAAJ",
      "fmSHtE8AAAAJ",
      "oUmv8xgAAAAJ",
      "v3VmgekAAAAJ",
      "MFoV3lsAAAAJ",
      "w6RxCIkAAAAJ",
      "AEsPCAUAAAAJ",
      "4hbbNREAAAAJ",
      "zHXnq0IAAAAJ",
      "L_9C4v0AAAAJ",
      "UfCI-NcAAAAJ",
      "kLqUY1gAAAAJ",
      "Cj-TQ-AAAAAJ",
      "YNGHCrAAAAAJ",
      "qqgDCDIAAAAJ",
      "Lx3Dc9cAAAAJ",
      "-yZse64AAAAJ"
    ],
    "lRUi-A8AAAAJ": [
      "o5YQMkMAAAAJ",
      "63TLsRcAAAAJ",
      "yy0UFOwAAAAJ",
      "3_WYcR4AAAAJ",
      "YGQs1AYAAAAJ",
      "vnsFRJUAAAAJ",
      "7oD5x5oAAAAJ",
      "0SQP4bwAAAAJ",
      "SUAT64AAAAAJ",
      "ZTkRs84AAAAJ",
      "Eja4Kw4AAAAJ",
      "1lHiuAQAAAAJ",
      "HEulGGsAAAAJ",
      "0dnObMUAAAAJ",
      "KtSR8_0AAAAJ",
      "XizXVNcAAAAJ",
      "aOO2tOwAAAAJ",
      "910z20QAAAAJ",
      "QXgZyjAAAAAJ",
      "X2Qs7XYAAAAJ",
      "rPCzqN4AAAAJ",
      "FUOEBDUAAAAJ",
      "ADkiClQAAAAJ",
      "BSJyuqQAAAAJ",
      "ncy_2xUAAAAJ",
      "c5HeXxsAAAAJ",
      "MNp5hwoAAAAJ",
      "ke2MEF0AAAAJ",
      "3hYIetoAAAAJ",
      "CRclm5cAAAAJ",
      "s4I2aDgAAAAJ",
      "_tbXjP4AAAAJ",
      "2pp8xosAAAAJ",
      "-BgdY0oAAAAJ",
      "EMqQUjoAAAAJ",
      "FWDKUMUAAAAJ",
      "ccksLFUAAAAJ",
      "jeb2t4AAAAAJ",
      "JHJozAYAAAAJ",
      "nQBhQawAAAAJ",
      "jqH6384AAAAJ",
      "wnePPc4AAAAJ",
      "lhpoASkAAAAJ",
      "kqW_-2gAAAAJ",
      "XxGyUpAAAAAJ",
      "ra1iQ8cAAAAJ",
      "Y7aNyh8AAAAJ",
      "pcWicN8AAAAJ",
      "bN_de_QAAAAJ",
      "PynKWyQAAAAJ",
      "1ViBXywAAAAJ",
      "-4cUri0AAAAJ",
      "EjOkyc0AAAAJ",
      "gJE5IssAAAAJ",
      "a8ZyGisAAAAJ",
      "urTiL7QAAAAJ",
      "83OxU_4AAAAJ",
      "8EDHmYkAAAAJ",
      "DqXsbPAAAAAJ",
      "aQsc6KwAAAAJ",
      "9RNcFO0AAAAJ",
      "1sqZDWIAAAAJ",
      "MDWCSOQAAAAJ",
      "3_tE6JgAAAAJ",
      "fRwcQToAAAAJ",
      "tpoh43QAAAAJ",
      "8R35rCwAAAAJ",
      "NAntFXIAAAAJ",
      "dQmvEyUAAAAJ",
      "OpAiiOAAAAAJ",
      "-EqbTXoAAAAJ",
      "Nd6tX_kAAAAJ",
      "37lzFAoAAAAJ",
      "_9G6V38AAAAJ",
      "7UCco8IAAAAJ",
      "fiM8AFsAAAAJ",
      "LuA1j4oAAAAJ",
      "XB3_I9cAAAAJ",
      "apPMLQ4AAAAJ",
      "Yipk0X4AAAAJ",
      "rjnJnEkAAAAJ",
      "TZ9DF0kAAAAJ",
      "DBLgVFQAAAAJ",
      "1e_R-xoAAAAJ",
      "Bh8bGCYAAAAJ",
      "hUWfaL0AAAAJ",
      "IxCZDBQAAAAJ",
      "x5Ig8xMAAAAJ",
      "eDHv58AAAAAJ",
      "_gfwCNwAAAAJ",
      "8fztli4AAAAJ",
      "1UEU5PEAAAAJ",
      "ijtcJ1sAAAAJ",
      "RLzWUrwAAAAJ",
      "zj6FavAAAAAJ",
      "s9eCQn4AAAAJ",
      "8M-hWKMAAAAJ",
      "aM3i_9oAAAAJ",
      "gYCRa7wAAAAJ",
      "2gpXz3IAAAAJ",
      "WSN7T_YAAAAJ",
      "dmDQklMAAAAJ",
      "haCXENgAAAAJ",
      "0h0oV7oAAAAJ",
      "SRCCuo0AAAAJ",
      "t4k2EtkAAAAJ",
      "DMsPWz0AAAAJ",
      "NOZmGq0AAAAJ",
      "ZlSVieAAAAAJ",
      "9i_MgykAAAAJ",
      "DMTuJzAAAAAJ",
      "_ws9LLgAAAAJ",
      "J5kGUDMAAAAJ",
      "Z-Qe2UUAAAAJ",
      "Vs9YD9kAAAAJ",
      "YOVZiJkAAAAJ",
      "0ytii2EAAAAJ",
      "5a9ddsQAAAAJ",
      "Kv9W_ZYAAAAJ",
      "7ShMBcwAAAAJ",
      "jEdhxGMAAAAJ",
      "K4bCJYcAAAAJ",
      "YtWK2I8AAAAJ",
      "bO45VHYAAAAJ",
      "-6ws0MoAAAAJ",
      "TrMmYPIAAAAJ",
      "r3A90uAAAAAJ",
      "aLBeFYcAAAAJ",
      "qqbRBXEAAAAJ",
      "4wXYfSUAAAAJ",
      "jV66t1kAAAAJ",
      "dASv28sAAAAJ",
      "Lf2KB6cAAAAJ",
      "9PVf18oAAAAJ",
      "10HcE2QAAAAJ",
      "mINzfREAAAAJ",
      "X6fRNfUAAAAJ",
      "xWdb5R8AAAAJ",
      "XOWZzUcAAAAJ",
      "-kIVAcAAAAAJ",
      "VQJR8WoAAAAJ",
      "b0k2tTgAAAAJ",
      "YVfr3wwAAAAJ",
      "B-4cOBMAAAAJ",
      "qrCVP0YAAAAJ",
      "8HCVx48AAAAJ",
      "838_NnIAAAAJ",
      "A8YEQMMAAAAJ",
      "Kv2Sm7oAAAAJ",
      "wOuOYO4AAAAJ",
      "edQgLXcAAAAJ",
      "Q38iIK4AAAAJ",
      "2P-Q09UAAAAJ",
      "m1VxcKcAAAAJ",
      "WQXD3uAAAAAJ",
      "tQPt2LcAAAAJ",
      "4hbasIcAAAAJ",
      "Ci5YRtAAAAAJ",
      "R1eV0ekAAAAJ",
      "ABr4UU4AAAAJ",
      "7e456ToAAAAJ",
      "DwUrFHUAAAAJ",
      "rgLGzAQAAAAJ",
      "ND0FM6EAAAAJ",
      "2jOYB6oAAAAJ",
      "dp5LnVAAAAAJ",
      "px1ffwoAAAAJ",
      "TBoc26oAAAAJ",
      "qdINILwAAAAJ",
      "jNUBLwMAAAAJ",
      "A8DhSR4AAAAJ",
      "vtwH6GkAAAAJ",
      "uVTR_eoAAAAJ",
      "AFf15XkAAAAJ",
      "L8HAaJYAAAAJ",
      "QLsu5OQAAAAJ",
      "uHhsRFgAAAAJ",
      "KCv6gOQAAAAJ",
      "mYKbo8YAAAAJ",
      "uwadDKYAAAAJ",
      "JtPSC9sAAAAJ",
      "xbHranwAAAAJ",
      "pRclXR8AAAAJ",
      "nQaxVCsAAAAJ",
      "f_gNVb8AAAAJ",
      "jERkdhIAAAAJ",
      "xOWBOKQAAAAJ"
    ],
    "W8VIEZgAAAAJ": [
      "DhtAFkwAAAAJ",
      "a8Y2OJMAAAAJ",
      "_BPdgV0AAAAJ",
      "bh-uRFMAAAAJ",
      "TpglobcAAAAJ",
      "kQisE-gAAAAJ",
      "ZeJjFQMAAAAJ",
      "UfbuDH8AAAAJ",
      "ALVSZAYAAAAJ",
      "AUhj438AAAAJ",
      "9B8PoXUAAAAJ",
      "Y2GtJkAAAAAJ",
      "bHn29ScAAAAJ",
      "k1hJzF0AAAAJ",
      "jeOFRDsAAAAJ",
      "TDk_NfkAAAAJ",
      "mu5Y2rYAAAAJ",
      "nbpafUkAAAAJ",
      "k0nZO90AAAAJ",
      "ijmuZ0wAAAAJ",
      "gYiCq88AAAAJ",
      "-ltRSM0AAAAJ",
      "6GDfcqEAAAAJ",
      "bqL73OkAAAAJ",
      "1HO5UacAAAAJ",
      "9oz-dvgAAAAJ",
      "3pyzQQ8AAAAJ",
      "mS5k4CYAAAAJ",
      "rDfyQnIAAAAJ",
      "duSEbnYAAAAJ",
      "vKlrdpEAAAAJ",
      "j5_DDM0AAAAJ",
      "qJsC_XsAAAAJ",
      "5na92fcAAAAJ",
      "WvufSLAAAAAJ",
      "YHmzvmMAAAAJ",
      "eSOXB6IAAAAJ",
      "y1lVpBEAAAAJ",
      "rTw-pq0AAAAJ",
      "mqpjAt4AAAAJ",
      "_bs7PqgAAAAJ",
      "Gd9HQn2UsNoC",
      "mIF9BowAAAAJ",
      "ScoZZPsAAAAJ",
      "0ytii2EAAAAJ",
      "N_YNMIMAAAAJ",
      "QSTd1oUAAAAJ",
      "Zdl00bEAAAAJ",
      "xY1GdVgAAAAJ",
      "Rh16nsIAAAAJ",
      "DplAah0AAAAJ",
      "ijpYJQwAAAAJ",
      "T_Q-xDkAAAAJ",
      "9xDADY4AAAAJ",
      "nABXo3sAAAAJ",
      "OOcllDwAAAAJ",
      "tDgCcOEAAAAJ",
      "AEsPCAUAAAAJ",
      "UpZmJI0AAAAJ",
      "yuB-cfoAAAAJ",
      "Bx9WGD6lBFEC",
      "yCyR-TsAAAAJ",
      "gTWUZlsAAAAJ",
      "fMEMNKMAAAAJ",
      "G_vOcFUAAAAJ",
      "l7Qx0zAAAAAJ",
      "L7lMQkQAAAAJ",
      "ZO3Ek1gAAAAJ",
      "bRT7t28AAAAJ",
      "EmmO7LcAAAAJ",
      "c4mWQPQAAAAJ",
      "SmGZwHYAAAAJ",
      "ygFAcZwAAAAJ",
      "T1iIhDEAAAAJ",
      "4hC_FYoAAAAJ",
      "4V1nNm4AAAAJ",
      "yc4nBNgAAAAJ",
      "GgQ9GEkAAAAJ",
      "WH2KmRgAAAAJ",
      "d6vuvHIAAAAJ",
      "24OOpyEAAAAJ",
      "bda1zGQAAAAJ",
      "-5pzdw4AAAAJ",
      "-9yiQMsAAAAJ"
    ],
    "YsXNU78AAAAJ": [
      "vN-is70AAAAJ",
      "I1EvjZsAAAAJ",
      "GUAoEcAAAAAJ",
      "p0sQC6sAAAAJ",
      "Bl8GgEcAAAAJ",
      "X22nUYgAAAAJ",
      "uFJi3IUAAAAJ",
      "qG1LVpQAAAAJ",
      "PkfChMgAAAAJ"
    ],
    "jM23vRsKxuIC": [
      "_TgGqhsAAAAJ",
      "QEh45NMAAAAJ",
      "Z2Kn9ucAAAAJ",
      "y9jYYRkAAAAJ",
      "5EGhZTgAAAAJ",
      "D37XAbIAAAAJ",
      "VWNTaCgAAAAJ",
      "rzwHnAcAAAAJ",
      "0aIhBb0AAAAJ",
      "tQ5vbOAAAAAJ",
      "FxU9cG0AAAAJ",
      "QOLH_TwAAAAJ",
      "pdvYP-kAAAAJ",
      "58ShSfwAAAAJ",
      "84FUioAAAAAJ",
      "cOkx0_IAAAAJ",
      "BC1Zc78AAAAJ"
    ],
    "lJwPbcUAAAAJ": [
      "5P2jxPQAAAAJ",
      "FwxfQosAAAAJ",
      "FHwvVmkAAAAJ",
      "qDsqFkMAAAAJ",
      "-WZcuuwAAAAJ",
      "SUbqiqwAAAAJ",
      "sX31JjwAAAAJ",
      "pKuBFaQAAAAJ",
      "q7FiLBkAAAAJ",
      "-NXsLG4AAAAJ",
      "fIoDWp8AAAAJ",
      "al5P0bAAAAAJ",
      "8R35rCwAAAAJ",
      "vtwH6GkAAAAJ",
      "qRXK__gAAAAJ",
      "JlX2UTEAAAAJ",
      "aHs2JHgAAAAJ",
      "_CEwIJwAAAAJ",
      "RlSbIJ4AAAAJ",
      "h4kYmRYAAAAJ",
      "l8WuQJgAAAAJ",
      "z0RoFtcAAAAJ",
      "IQSbom0AAAAJ",
      "s_5xXxQXpU0C",
      "TT-8JRsAAAAJ",
      "ZisEORUAAAAJ",
      "IJ1yaGsAAAAJ",
      "N-iYby0AAAAJ",
      "IgkGxLsAAAAJ",
      "w4XsexUAAAAJ",
      "CROZP6wWEwEC",
      "Ln5Ksv0AAAAJ",
      "Uro_AS0AAAAJ",
      "r4gezHUAAAAJ",
      "c2Att08AAAAJ",
      "fAxws1sAAAAJ",
      "JsK4KpMAAAAJ",
      "zfTbkBkAAAAJ",
      "LGo5J4IAAAAJ",
      "ZiON80cAAAAJ",
      "NJ9c4ygAAAAJ",
      "o29n55IAAAAJ",
      "EiwH233ldzsC",
      "ebNrBjYAAAAJ"
    ],
    "h3qMa1kAAAAJ": [
      "rQoKPUsAAAAJ",
      "8C2_ZVsAAAAJ"
    ],
    "siuZCjUAAAAJ": [
      "jZgjlGUAAAAJ",
      "UesKv-0AAAAJ",
      "df-THM0AAAAJ"
    ],
    "VT7peyEAAAAJ": [
      "8R35rCwAAAAJ",
      "vtwH6GkAAAAJ",
      "1O83J5MAAAAJ",
      "eVYhlDQAAAAJ",
      "neGbgzYAAAAJ",
      "Q6F3O0sAAAAJ",
      "-gJkPHIAAAAJ",
      "j_xavDQAAAAJ",
      "BIwrJuQAAAAJ",
      "M8wm74gAAAAJ",
      "vYougn0AAAAJ",
      "uv7g5kMAAAAJ",
      "o3nJb1EAAAAJ"
    ],
    "Hyhp_zUAAAAJ": [
      "A-4JUL4AAAAJ",
      "8Qu_gAMAAAAJ",
      "ydA8Q5AAAAAJ",
      "6YU6_QoAAAAJ",
      "_qr34PIAAAAJ",
      "YR1EmaAAAAAJ",
      "JS7sVyQAAAAJ",
      "LT9zh4sAAAAJ",
      "VGr54BoAAAAJ",
      "RCi98EAAAAAJ",
      "t-VqN7sAAAAJ",
      "vswo4rQAAAAJ"
    ],
    "DYUloYkAAAAJ": [
      "fNOReswAAAAJ",
      "1IPn2HgAAAAJ",
      "klxwxyUAAAAJ",
      "YAHWbtkAAAAJ",
      "B847xq8AAAAJ",
      "EWJYRncAAAAJ",
      "m_HQ-WQAAAAJ",
      "nmk3WzgAAAAJ",
      "TJF5CosAAAAJ",
      "lH1PdF8AAAAJ",
      "c_z5hWEAAAAJ",
      "b_svo9QAAAAJ",
      "HU1K_zsAAAAJ",
      "sT_qeloAAAAJ",
      "9vumoioAAAAJ",
      "0RdaaYsAAAAJ",
      "-iPZaBcAAAAJ",
      "WLN3QrAAAAAJ",
      "l-mlF7YAAAAJ",
      "DRTIzTsAAAAJ",
      "dvDLaPkAAAAJ",
      "zVAYbpYAAAAJ",
      "6KWZup8AAAAJ",
      "UGZ0jy4AAAAJ",
      "BRWwxYwAAAAJ",
      "qenoZwUAAAAJ",
      "S8Ov5d8AAAAJ",
      "eyqQt3gAAAAJ",
      "Bs0aA-UAAAAJ",
      "FLY_0BEAAAAJ",
      "WeEK60YAAAAJ",
      "DytvG6cAAAAJ",
      "j0_fn9oAAAAJ",
      "JSkBINwAAAAJ",
      "uKuvN64AAAAJ",
      "KvRjw-4AAAAJ",
      "9cBUERoAAAAJ",
      "HQDpzBoAAAAJ",
      "Me9JcfgAAAAJ"
    ],
    "ySwF8ioAAAAJ": [
      "Fsz9BAUAAAAJ",
      "lQbIarsAAAAJ",
      "lyadgWkAAAAJ",
      "ESCWolcAAAAJ",
      "2wrS35MAAAAJ",
      "FNwI36EAAAAJ",
      "iyDxq0EAAAAJ",
      "1azFZ6cAAAAJ",
      "JrnxAZUAAAAJ",
      "6S09ezcAAAAJ",
      "B48jbeEAAAAJ",
      "m4rsQCAAAAAJ",
      "tUq_v90AAAAJ",
      "mQnBkmoAAAAJ",
      "rIUE-FoAAAAJ",
      "oD8eeUYAAAAJ",
      "eRCF2KsAAAAJ",
      "EVWYEMQAAAAJ",
      "aO8KpGcAAAAJ",
      "o_J2CroAAAAJ",
      "jLPy8-4AAAAJ",
      "Owy8RMEAAAAJ",
      "IiSNwnAAAAAJ",
      "JS72sbsAAAAJ",
      "MSgWKbYAAAAJ",
      "Viv2E9AAAAAJ",
      "1t-vpJ8AAAAJ",
      "hZhJhmIAAAAJ",
      "P2mG6rcAAAAJ",
      "Xn--pmkAAAAJ",
      "HNNL22kAAAAJ",
      "10ZeC3MAAAAJ",
      "EMADq2wAAAAJ",
      "U8dAtsQAAAAJ"
    ],
    "xkH30GgAAAAJ": [],
    "ftI1lBQAAAAJ": [],
    "UE9jz_MAAAAJ": [
      "vN-is70AAAAJ",
      "ID9QePIAAAAJ",
      "0mgEF28AAAAJ",
      "vtwH6GkAAAAJ",
      "8R35rCwAAAAJ",
      "DRnOvU8AAAAJ",
      "ITZ1e7MAAAAJ",
      "I1EvjZsAAAAJ"
    ],
    "HBztuGIAAAAJ": [
      "vtwH6GkAAAAJ",
      "5tVuggUAAAAJ",
      "EMDboA4AAAAJ",
      "itSa94cAAAAJ",
      "x04W_mMAAAAJ",
      "j_xavDQAAAAJ",
      "MHQv5YUAAAAJ",
      "n9K1v-cAAAAJ",
      "65bIT4oAAAAJ",
      "UhmcQ7gAAAAJ",
      "0pOgVVAAAAAJ",
      "iVLAQysAAAAJ",
      "kde_TOYAAAAJ",
      "ROILf3EAAAAJ",
      "zMoR8AEAAAAJ",
      "VC3Z6dcAAAAJ",
      "fBXk3G4AAAAJ"
    ],
    "iVLAQysAAAAJ": [],
    "FXiSi-4AAAAJ": [
      "nTiSnwUAAAAJ",
      "t1u0f5QAAAAJ",
      "RU0ZAp4AAAAJ",
      "23ZXZvEAAAAJ",
      "hwqQOpUAAAAJ",
      "zSdOp4EAAAAJ",
      "k5RXEZYAAAAJ",
      "VXtCp7MAAAAJ",
      "uhwGITAAAAAJ",
      "7YSki00AAAAJ",
      "PGodeKsAAAAJ",
      "-mh8RQ8AAAAJ",
      "8gEhRVgAAAAJ",
      "hdTDzlQAAAAJ",
      "aO8KpGcAAAAJ",
      "DpsEpaoAAAAJ",
      "ng9o57kAAAAJ",
      "ZpWzifcAAAAJ",
      "NjZsLZwAAAAJ"
    ],
    "CpMjT0YAAAAJ": [
      "I1EvjZsAAAAJ",
      "qG1LVpQAAAAJ",
      "5ygiTwsAAAAJ",
      "FdNHp8QAAAAJ",
      "l7Ra9p8AAAAJ",
      "czyretsAAAAJ",
      "sTzb6LAAAAAJ",
      "vN-is70AAAAJ",
      "65-B1ZwAAAAJ",
      "XaYJrgoAAAAJ",
      "IzXDyR8AAAAJ",
      "OtJC70cAAAAJ",
      "Kgs3zQoAAAAJ",
      "DnnCWN0AAAAJ",
      "LKv32bgAAAAJ",
      "RLvsC94AAAAJ",
      "SZ7-g60AAAAJ",
      "4UvZdF8AAAAJ",
      "QS5CTxcAAAAJ",
      "5z2rh_oAAAAJ",
      "GaYmpIgAAAAJ",
      "DpLFv4gAAAAJ",
      "FuYln-oAAAAJ",
      "YaBPvxAAAAAJ",
      "cc4Qi_IAAAAJ",
      "G2EJz5kAAAAJ",
      "mSw8KfIAAAAJ",
      "K-KlWSsAAAAJ",
      "n5ENv9EAAAAJ",
      "OqbV4dwAAAAJ",
      "MEk1MWoAAAAJ",
      "IWPWNxkAAAAJ",
      "wm2BrUcAAAAJ"
    ],
    "Bl8GgEcAAAAJ": [
      "PkfChMgAAAAJ",
      "0VwIiIsAAAAJ",
      "p0sQC6sAAAAJ",
      "QYsnk-cAAAAJ",
      "biuxbRsAAAAJ",
      "9EFobLUAAAAJ"
    ],
    "4mVPFQ8AAAAJ": [
      "UgHB5oAAAAAJ",
      "zaF8UJcAAAAJ",
      "2oy3OXYAAAAJ",
      "vtwH6GkAAAAJ",
      "7cU2rQsAAAAJ",
      "O6NknDYAAAAJ",
      "tsXh_hwAAAAJ",
      "UAwKvEsAAAAJ",
      "rNcmwggAAAAJ",
      "VSsTq14AAAAJ",
      "3y_M1cUAAAAJ",
      "HvjirogAAAAJ",
      "4lmER2EAAAAJ",
      "eurA6WgAAAAJ",
      "7EPsnxEAAAAJ",
      "yK7yTiwAAAAJ",
      "H3ZnCqYAAAAJ",
      "MeNbzgIAAAAJ",
      "WxZ_6nsAAAAJ",
      "eEGGCiUAAAAJ",
      "Sbpra_AAAAAJ",
      "8-p9CLsAAAAJ",
      "nABXo3sAAAAJ",
      "2ylcZSsAAAAJ",
      "KgZxzjsAAAAJ",
      "gQOKAggAAAAJ",
      "23LELwEAAAAJ",
      "XnUZEcoAAAAJ"
    ],
    "dnZ8udEAAAAJ": [
      "FQHeASwAAAAJ",
      "bh-uRFMAAAAJ",
      "8cxDHS4AAAAJ",
      "RGiCLUgAAAAJ",
      "rRJ9wTJMUB8C",
      "3kDtybgAAAAJ",
      "700fyvEAAAAJ",
      "9xDADY4AAAAJ",
      "rTw-pq0AAAAJ",
      "38EC20cAAAAJ",
      "mN6_BKAAAAAJ",
      "FN2kigYAAAAJ",
      "O-vquhwAAAAJ",
      "UwLsYw8AAAAJ",
      "1qmAFhsAAAAJ",
      "8R35rCwAAAAJ",
      "sJDqACEAAAAJ",
      "n_ts4eYAAAAJ",
      "RXsYj9IAAAAJ",
      "CYI6cKgAAAAJ",
      "i38QlUwAAAAJ",
      "1wLVDP4AAAAJ",
      "vtwH6GkAAAAJ",
      "ujDhg2sAAAAJ",
      "vM8t8zwAAAAJ",
      "IlgMpNoAAAAJ",
      "OUpIbcQAAAAJ",
      "GbaikvkAAAAJ",
      "VBz8gZ4AAAAJ",
      "vHd2qAkAAAAJ",
      "WmH1GQoAAAAJ",
      "oQnyyGkAAAAJ",
      "oeg_NN4AAAAJ",
      "XT3E7RoAAAAJ",
      "8lmWWD0AAAAJ",
      "r21asW4AAAAJ",
      "910z20QAAAAJ",
      "NsuX8R8AAAAJ",
      "I1mOQpAAAAAJ",
      "1CgET20AAAAJ",
      "QBsEFvMAAAAJ",
      "gznWHL4AAAAJ",
      "_-5PSgQAAAAJ",
      "Rd18rbYAAAAJ",
      "GHpxNQIAAAAJ",
      "E6vCXjkAAAAJ",
      "APgaFK0AAAAJ",
      "D1uOAWcAAAAJ",
      "Vzr1RukAAAAJ",
      "GRMMc_MAAAAJ",
      "xaQuPloAAAAJ",
      "VOIlmnoAAAAJ",
      "lg1fT1kAAAAJ",
      "wlosgkoAAAAJ",
      "tjb2UccAAAAJ",
      "j67B9Q4AAAAJ",
      "eMwEEXUAAAAJ",
      "eQ1uJ6UAAAAJ",
      "kukA0LcAAAAJ",
      "8BeTDr0AAAAJ",
      "tmK5EPEAAAAJ",
      "ubAcojQAAAAJ",
      "1zmDOdwAAAAJ",
      "sktDNcEAAAAJ",
      "ezllEwMAAAAJ",
      "zpil5xkAAAAJ",
      "6z4lQzMAAAAJ",
      "iSI9-1oAAAAJ",
      "mWBY8aIAAAAJ",
      "6Z-RC-QAAAAJ",
      "9zeEI-cAAAAJ",
      "hDGGNYIAAAAJ",
      "_FZpPv0AAAAJ",
      "g6MislAAAAAJ",
      "EFVk-mwAAAAJ",
      "j9GCzQUAAAAJ",
      "RsZBRBQAAAAJ",
      "btoec6QAAAAJ",
      "TiF1WEsAAAAJ",
      "-Txt8vsAAAAJ",
      "bEcLezcAAAAJ",
      "HEY3UzgAAAAJ",
      "7ICTJmoAAAAJ",
      "sljtWIUAAAAJ",
      "mWGyYMsAAAAJ",
      "gdUv1PIAAAAJ",
      "iZpSjEYAAAAJ",
      "dok0514AAAAJ",
      "Uod-_B8AAAAJ",
      "53baCywAAAAJ",
      "rEL4-fgAAAAJ",
      "dHboSOoAAAAJ",
      "djLcGEQAAAAJ",
      "ghdbIsoAAAAJ",
      "6jRu5x4AAAAJ",
      "r7gAWagAAAAJ",
      "UU3N6-UAAAAJ",
      "i86O0SAAAAAJ",
      "AWNL69MAAAAJ",
      "AZboOI8AAAAJ",
      "l-xu2w0AAAAJ",
      "vspmOX8AAAAJ",
      "k0vrm6kAAAAJ",
      "tVjxANMAAAAJ",
      "YQe9pdUAAAAJ",
      "a1ngrCIAAAAJ",
      "r1quzEkAAAAJ",
      "6eHx7EgAAAAJ",
      "orxu07YAAAAJ",
      "bBnvK8cAAAAJ",
      "XjWnyM4AAAAJ",
      "tgm2Y7oAAAAJ",
      "i9-GzNYAAAAJ",
      "DqXsbPAAAAAJ",
      "G5_VFfkAAAAJ",
      "1D8C9ZkAAAAJ",
      "eBXEZxgAAAAJ",
      "QeXHxlIAAAAJ",
      "dqVBIjIAAAAJ",
      "xBX234cAAAAJ",
      "FTYtHb4AAAAJ",
      "HxMQouAAAAAJ",
      "jb__2PIAAAAJ",
      "gP9EAWkAAAAJ",
      "iJbdUkQAAAAJ",
      "7WntHrAAAAAJ",
      "3rF9gtAAAAAJ",
      "w8ZDbO8AAAAJ",
      "K-6ujU4AAAAJ",
      "oRPEEWIAAAAJ",
      "pv54dqMAAAAJ",
      "UcZbFroAAAAJ",
      "8ihSLrwAAAAJ",
      "BCKhEoAAAAAJ",
      "W69x8yYAAAAJ",
      "DwXLsT8AAAAJ",
      "4GpKQUIAAAAJ",
      "1LuGqFQAAAAJ",
      "xGGUwFsAAAAJ",
      "h1zSzecAAAAJ",
      "xBH73TYAAAAJ",
      "eAwnN44AAAAJ",
      "fJQZVyAAAAAJ",
      "8BX3BokAAAAJ",
      "50O3v1MAAAAJ",
      "oF46lMIAAAAJ",
      "RLDbLcUAAAAJ",
      "Ad6O4-0AAAAJ",
      "t5lVb6sAAAAJ",
      "UgHB5oAAAAAJ",
      "k9IJYg8AAAAJ",
      "0v1kYUEAAAAJ",
      "zV5vhUcAAAAJ",
      "jTMUPNkAAAAJ",
      "VX7d5EQAAAAJ",
      "zkvW8FQAAAAJ",
      "vfT6-XIAAAAJ",
      "xdwK2NsAAAAJ",
      "pJB4fIEAAAAJ",
      "YCoLskoAAAAJ",
      "SwNmwlcAAAAJ",
      "jdcLB8kAAAAJ",
      "LJnNKXMAAAAJ",
      "qff5rRYAAAAJ",
      "wHlw1L4AAAAJ",
      "yxUduqMAAAAJ",
      "7EPsnxEAAAAJ",
      "NjZsLZwAAAAJ",
      "Tqk2bsMAAAAJ",
      "SnQnQicAAAAJ",
      "ev8Ilx0AAAAJ",
      "F_MI0pcAAAAJ",
      "UjpbO6IAAAAJ",
      "V9JYPP0AAAAJ",
      "0uTu7fYAAAAJ",
      "UAwKvEsAAAAJ",
      "l2pAq_0AAAAJ",
      "DGb-sBwAAAAJ",
      "FKUc3vsAAAAJ",
      "auA1nNAAAAAJ",
      "AOqzUmwAAAAJ",
      "jRQtBp0AAAAJ",
      "okfWOCsAAAAJ",
      "KssJcIAAAAAJ",
      "iXOzeWUAAAAJ",
      "p8Ft6RQAAAAJ",
      "Om4Lag0AAAAJ"
    ],
    "axX7PCwAAAAJ": [
      "8R35rCwAAAAJ",
      "ZWH5jCwAAAAJ",
      "vfPE6hgAAAAJ",
      "xvOlfw8AAAAJ",
      "PpzsjioAAAAJ",
      "d5y4iKAAAAAJ",
      "zvz6LIYAAAAJ",
      "GRMMc_MAAAAJ",
      "4peEKXMAAAAJ",
      "bIUsRBQAAAAJ"
    ],
    "mnAk4HIAAAAJ": [
      "TlOMKqMAAAAJ",
      "OTk6tAoAAAAJ",
      "D22GptUAAAAJ",
      "3JrkBn4AAAAJ",
      "7cLt5PAAAAAJ",
      "urTiL7QAAAAJ",
      "1RGui4wAAAAJ",
      "wYpNpTEAAAAJ",
      "Yr2yu_sAAAAJ",
      "rzfe-vsAAAAJ",
      "2hjvDoAAAAAJ",
      "FoGc_e0AAAAJ",
      "JbkP8EwAAAAJ",
      "NHIpV98AAAAJ",
      "K4_TvQQAAAAJ",
      "XFuk24sAAAAJ",
      "7cNE8rkAAAAJ",
      "27o6cX4AAAAJ",
      "PXMOFVMAAAAJ",
      "2wG4enAAAAAJ",
      "N5rG_E0AAAAJ",
      "djRMREYAAAAJ",
      "EyhHDj4AAAAJ",
      "SU0c5P0AAAAJ",
      "3XLQbL8AAAAJ",
      "O4jW7BsAAAAJ",
      "I_YsXU4AAAAJ",
      "PkfChMgAAAAJ",
      "uA0kNBUAAAAJ",
      "reqGWxMAAAAJ",
      "EpidFw8AAAAJ",
      "DJEiH1IAAAAJ",
      "3_WYcR4AAAAJ",
      "urhvgT0AAAAJ",
      "CXJuZ5YAAAAJ",
      "xCA8j6oAAAAJ",
      "PtFGOakAAAAJ",
      "fA0rYxMAAAAJ",
      "tVS1jp0AAAAJ",
      "tRPd-vQAAAAJ",
      "8R35rCwAAAAJ",
      "04TuVhEAAAAJ",
      "By1xdxEAAAAJ",
      "lRUi-A8AAAAJ",
      "hyJ_lk8AAAAJ",
      "i3wkV_kAAAAJ",
      "KgZxzjsAAAAJ",
      "uW7jWOcAAAAJ",
      "soiDQbQAAAAJ",
      "G-xTgkgAAAAJ",
      "xADN4DUAAAAJ",
      "8tpFFEMAAAAJ",
      "8xkg8pIAAAAJ",
      "X4k8oLAAAAAJ",
      "OXtNAU4AAAAJ",
      "l8RaE9YAAAAJ",
      "Y0MyYO0AAAAJ",
      "GP64q_kAAAAJ",
      "ABSaf6IAAAAJ",
      "KkVl2qoAAAAJ",
      "PNvJsN0AAAAJ",
      "pdKcN5gAAAAJ",
      "iCdq_ZsAAAAJ",
      "RCvR5HAAAAAJ",
      "LxmQ8eIAAAAJ",
      "5K1mZq0AAAAJ",
      "gmI1-UIAAAAJ",
      "grsfoH8AAAAJ",
      "AgTN6m4AAAAJ",
      "FTe6HDoAAAAJ",
      "fgDB2BoAAAAJ",
      "Wdo9AyQAAAAJ",
      "C3-B4nwAAAAJ",
      "vKflaosAAAAJ",
      "k8bn6q4AAAAJ",
      "LTL9MjwAAAAJ",
      "nR8UJ3cAAAAJ",
      "qXVG1AEAAAAJ",
      "lu2yOLkAAAAJ",
      "LbYsy_QAAAAJ",
      "IJgXsgwAAAAJ",
      "Kia-4B0AAAAJ",
      "AhgjQ2QAAAAJ",
      "SlZavnIAAAAJ",
      "QmP0ggQAAAAJ",
      "evReMyEAAAAJ",
      "GnuEOOgAAAAJ",
      "AWKaiasAAAAJ",
      "KLFjg9EAAAAJ",
      "Bw25vHMAAAAJ",
      "rno2y00AAAAJ",
      "cnku7dQAAAAJ",
      "Hl8N_k8AAAAJ",
      "kiF6OS4AAAAJ",
      "ZT1ZkRcAAAAJ",
      "SKq6DZcAAAAJ",
      "4-AyPLsAAAAJ",
      "0RLF4vUAAAAJ",
      "5O7jjVgAAAAJ",
      "UVkOjSAAAAAJ",
      "ejyZTmEAAAAJ",
      "-ILhc-sAAAAJ",
      "cwff2XYAAAAJ",
      "OfYf-DMAAAAJ",
      "yhJQnxwAAAAJ",
      "YsKTazIAAAAJ",
      "8fztli4AAAAJ",
      "1F1k4AUAAAAJ",
      "X2Qs7XYAAAAJ",
      "myYVVuYAAAAJ",
      "JpoFnJQAAAAJ",
      "OQfkwykAAAAJ",
      "R9N6ljUAAAAJ",
      "Z_A0TDgAAAAJ",
      "Qb7xQQ0AAAAJ",
      "RKd3704AAAAJ",
      "8hU4uvEAAAAJ",
      "DcV-5RAAAAAJ",
      "a5nY-pYAAAAJ",
      "ahFqdRUAAAAJ",
      "kc3snaQAAAAJ",
      "NxN3gEsAAAAJ",
      "NILVLIAAAAAJ",
      "RQxKmJMAAAAJ"
    ],
    "CP5x1yEAAAAJ": [
      "8R35rCwAAAAJ",
      "-w5DuHgAAAAJ",
      "d5y4iKAAAAAJ",
      "WuWWdKcAAAAJ",
      "pqP5_PgAAAAJ"
    ],
    "0uTu7fYAAAAJ": [
      "yxUduqMAAAAJ",
      "SIayDoQAAAAJ",
      "YM8BRlUAAAAJ",
      "hqTu-QcAAAAJ",
      "JicYPdAAAAAJ",
      "aqgFQqMAAAAJ",
      "BEBccCQAAAAJ",
      "WOAlvmoAAAAJ",
      "s1_ay2AAAAAJ",
      "N9QGV6YAAAAJ",
      "Ao4gtsYAAAAJ",
      "EpT5sLAAAAAJ",
      "3OFgQKcAAAAJ",
      "3J4zb7gAAAAJ",
      "DgLEyZgAAAAJ",
      "sm1-TZMAAAAJ",
      "grQ_GBgAAAAJ",
      "s5-PGF8AAAAJ",
      "lAp-1WEAAAAJ",
      "qjnBu0sAAAAJ",
      "lelCr80AAAAJ",
      "UAwKvEsAAAAJ",
      "ZLpO3XQAAAAJ",
      "koQCVT4AAAAJ",
      "B8wslVsAAAAJ",
      "vA6ZQ_AAAAAJ",
      "l8dX3ssAAAAJ",
      "6T1qA5AAAAAJ",
      "a4t8q5MAAAAJ",
      "y-nUzMwAAAAJ",
      "twWX2LIAAAAJ",
      "7QmCrjcAAAAJ",
      "5Iqe53IAAAAJ",
      "g3mGoAwAAAAJ",
      "cIlDEugAAAAJ",
      "xgQd1qgAAAAJ",
      "v3JsjMYAAAAJ",
      "MUJ51_gAAAAJ",
      "4BEvaw8AAAAJ",
      "ITZ1e7MAAAAJ",
      "XjWnyM4AAAAJ",
      "I-ANa0QAAAAJ",
      "hwQtFB0AAAAJ",
      "rr8pZoUAAAAJ",
      "nd8lQQIAAAAJ",
      "Q_kKkIUAAAAJ",
      "Lt9LpLMAAAAJ",
      "cSGXgEAAAAAJ",
      "odOmEY0AAAAJ",
      "QCBdB7AAAAAJ",
      "ClSXZ4IAAAAJ",
      "Sr7jln4AAAAJ"
    ],
    "tX3YzCcAAAAJ": [],
    "LMtE3FQAAAAJ": [
      "uX9yGmAAAAAJ",
      "5Iqe53IAAAAJ",
      "bLUllHEAAAAJ",
      "vtwH6GkAAAAJ",
      "i5srt20AAAAJ"
    ],
    "eM916YMAAAAJ": [],
    "iyDxq0EAAAAJ": [
      "aO8KpGcAAAAJ",
      "yxUduqMAAAAJ",
      "1M79iLwAAAAJ",
      "vN-is70AAAAJ",
      "B96GkdgAAAAJ",
      "Op-47sgAAAAJ",
      "xMhGYpgAAAAJ",
      "87nZphcAAAAJ",
      "_7Q8uIYAAAAJ",
      "IB_jPZ0AAAAJ",
      "df-THM0AAAAJ",
      "vEYUIioAAAAJ",
      "nfX25MMAAAAJ",
      "2oy3OXYAAAAJ",
      "yDVn5LEAAAAJ",
      "H1d4BS8AAAAJ",
      "Vy16O5UAAAAJ",
      "NR59_v4AAAAJ",
      "ID9QePIAAAAJ",
      "BgQkdsYAAAAJ",
      "DcV-5RAAAAAJ",
      "LKv32bgAAAAJ",
      "kIx230gAAAAJ",
      "si-368wAAAAJ",
      "ySwF8ioAAAAJ",
      "lyadgWkAAAAJ",
      "KcPrLhIAAAAJ",
      "qR1zQHQAAAAJ",
      "ESCWolcAAAAJ",
      "57gDGpUAAAAJ",
      "8R35rCwAAAAJ",
      "LIJQ_ZYAAAAJ",
      "yy0UFOwAAAAJ",
      "-S_9ZRcAAAAJ",
      "OI7zFmwAAAAJ",
      "tJpoCUIAAAAJ",
      "czxMUzcAAAAJ",
      "POlWWAsAAAAJ",
      "84WzBlYAAAAJ",
      "_TkfqdgAAAAJ",
      "1p3dDesAAAAJ",
      "BtwmZfQAAAAJ",
      "8zyiGRoAAAAJ",
      "E3yOuvEAAAAJ",
      "LeshmV8AAAAJ",
      "gFLW9qcAAAAJ",
      "k7NgVSUAAAAJ",
      "vMW39p0AAAAJ",
      "Se7mocgAAAAJ",
      "MzD8rjoAAAAJ",
      "chICXXMAAAAJ",
      "-9geUIIAAAAJ",
      "wy0FA1cAAAAJ",
      "yE4WT_0AAAAJ",
      "xVN3UxYAAAAJ",
      "9I7kD8sAAAAJ",
      "p1DZVX8AAAAJ",
      "3F52RjoAAAAJ",
      "GR_DsT0AAAAJ",
      "LajpoI8AAAAJ",
      "wKJeOQoAAAAJ",
      "67kghxAAAAAJ",
      "UFlWdvUAAAAJ",
      "Jyqbex4AAAAJ",
      "A7gPbV8AAAAJ",
      "DnxrVXgAAAAJ",
      "UgHB5oAAAAAJ",
      "DzeJ67UAAAAJ",
      "8m8taGEAAAAJ",
      "x78TL58AAAAJ",
      "VbNwxKYAAAAJ",
      "3yQFuR4AAAAJ",
      "w4yTWwoAAAAJ",
      "UJcBAgkAAAAJ",
      "MtqfTRYAAAAJ",
      "XwutB1AAAAAJ",
      "EguGynAAAAAJ",
      "bRWa8q8AAAAJ",
      "nTiSnwUAAAAJ",
      "hdTDzlQAAAAJ",
      "GNiinUoAAAAJ",
      "0qxCVx8AAAAJ",
      "1b2kKWoAAAAJ"
    ],
    "Y9CoR7QAAAAJ": [],
    "YGQs1AYAAAAJ": [
      "-kIVAcAAAAAJ",
      "LuA1j4oAAAAJ",
      "ViYx9vMAAAAJ",
      "_ws9LLgAAAAJ",
      "JdRs1sQAAAAJ",
      "NB4pgZYAAAAJ",
      "dG9MV7oAAAAJ",
      "tM4JMcQAAAAJ",
      "e378qEIAAAAJ",
      "DMTuJzAAAAAJ",
      "ejWOgzYAAAAJ",
      "rjnJnEkAAAAJ",
      "lRUi-A8AAAAJ",
      "qg9Gd84AAAAJ",
      "7m2X0GoAAAAJ",
      "jrfFYAIAAAAJ",
      "lc7OkdAAAAAJ",
      "aHPX6PsAAAAJ",
      "Izp-zW0AAAAJ"
    ],
    "kppa2vgAAAAJ": [
      "vtwH6GkAAAAJ",
      "q1HlbIUAAAAJ",
      "dusV5HMAAAAJ",
      "Vzr1RukAAAAJ",
      "vVvbU7oAAAAJ",
      "iRgYMuEAAAAJ",
      "5Qp_0TUAAAAJ",
      "IbcqwaoAAAAJ",
      "zhQaFaMAAAAJ",
      "BFlpS-8AAAAJ",
      "Bm3pH5AAAAAJ",
      "2oy3OXYAAAAJ",
      "1YjIvioAAAAJ",
      "VAgdtpoAAAAJ",
      "8R35rCwAAAAJ",
      "0QtU-NsAAAAJ",
      "3A06cR4AAAAJ",
      "EMDboA4AAAAJ",
      "yABlzrsAAAAJ",
      "RhOpyXcAAAAJ",
      "D2K-ADYAAAAJ",
      "0mgEF28AAAAJ",
      "kQisE-gAAAAJ",
      "FiETqWQAAAAJ",
      "AgyW_90AAAAJ",
      "AvvaaJcAAAAJ",
      "SJoRNbYAAAAJ",
      "CEt6_mMAAAAJ",
      "7vLwm84AAAAJ",
      "MyTEg-8AAAAJ",
      "cGemfcYAAAAJ",
      "v84tWxsAAAAJ",
      "r3NAa9oAAAAJ",
      "DdtAyEIAAAAJ",
      "H3ZnCqYAAAAJ",
      "PfgeYGwAAAAJ",
      "9GMg6q8AAAAJ",
      "OvKEnVwAAAAJ",
      "9dXN6cMAAAAJ",
      "p1HAb2QAAAAJ",
      "5tVuggUAAAAJ",
      "Gv4kyjQAAAAJ",
      "Tq1gdBUAAAAJ"
    ],
    "UAWfBEoAAAAJ": [
      "8R35rCwAAAAJ",
      "ZzURcb4AAAAJ",
      "zBUwaGkAAAAJ",
      "C2_ZXdcAAAAJ",
      "vfPE6hgAAAAJ",
      "ZaJEZpYAAAAJ",
      "fSXCOfEAAAAJ",
      "ZWH5jCwAAAAJ",
      "n7hxT4oAAAAJ"
    ],
    "-iPZaBcAAAAJ": [
      "BadZJUsAAAAJ",
      "2GcqQgYAAAAJ",
      "WLN3QrAAAAAJ",
      "YDKPDkgAAAAJ",
      "YkjjioAAAAAJ",
      "Py69D_8AAAAJ",
      "3aYVAZEAAAAJ",
      "kbN88gsAAAAJ",
      "v-A_7UsAAAAJ",
      "GyRqJIoAAAAJ",
      "DYUloYkAAAAJ",
      "fNOReswAAAAJ",
      "YAHWbtkAAAAJ",
      "4S1Ajs8AAAAJ",
      "E6vCXjkAAAAJ",
      "0RAmmIAAAAAJ",
      "8sGC5D4AAAAJ",
      "8yGMMwcAAAAJ",
      "XSforroAAAAJ",
      "vsLT1BIAAAAJ",
      "_iu2AD4AAAAJ",
      "pxSj9JkAAAAJ",
      "J7fyX_sAAAAJ",
      "HFHcNf0AAAAJ",
      "MlFf2igAAAAJ",
      "-9yiQMsAAAAJ"
    ],
    "SaiH1MIAAAAJ": [
      "vtwH6GkAAAAJ",
      "o-PadiwAAAAJ",
      "8tflub4AAAAJ",
      "H4n-cXEAAAAJ"
    ],
    "w4yTWwoAAAAJ": [
      "OUXS8doAAAAJ",
      "8m8taGEAAAAJ",
      "PTeSCbIAAAAJ",
      "z5SPCmgAAAAJ",
      "rRJ9wTJMUB8C",
      "tbxCHJgAAAAJ",
      "726MCb8AAAAJ",
      "aXdjxb4AAAAJ",
      "WXd3dDwAAAAJ",
      "Li-BrU4AAAAJ",
      "8cxDHS4AAAAJ",
      "NjZsLZwAAAAJ",
      "ID9QePIAAAAJ",
      "6S-WgLkAAAAJ",
      "-EqbTXoAAAAJ",
      "yxUduqMAAAAJ",
      "RhOpyXcAAAAJ",
      "vfPE6hgAAAAJ",
      "ocMf7fQAAAAJ",
      "k9TsUVsAAAAJ"
    ],
    "-ltRSM0AAAAJ": [
      "bh-uRFMAAAAJ",
      "mu5Y2rYAAAAJ",
      "UfbuDH8AAAAJ",
      "W8VIEZgAAAAJ",
      "ijmuZ0wAAAAJ",
      "gYiCq88AAAAJ",
      "OZ7PjVoAAAAJ",
      "2iBYdwEAAAAJ",
      "Sx75CVsAAAAJ",
      "hlC76YUAAAAJ",
      "IUZ-7_cAAAAJ",
      "UZ5wscMAAAAJ",
      "1JQDH_AAAAAJ",
      "UZ6kI2AAAAAJ",
      "uS6-ZOMAAAAJ",
      "d97bGd8AAAAJ",
      "hOl-5zcAAAAJ",
      "e1P1rNkAAAAJ",
      "4aqK_74AAAAJ",
      "eM916YMAAAAJ",
      "-XCiamcAAAAJ",
      "AEsPCAUAAAAJ",
      "NkzyCvUAAAAJ",
      "8R35rCwAAAAJ",
      "SBTxvCoAAAAJ",
      "_VmflIEAAAAJ",
      "v4JMf6kAAAAJ",
      "FyQAwaEAAAAJ",
      "VFO9h14AAAAJ",
      "NIxD36wAAAAJ",
      "-KzSL30AAAAJ",
      "Un10q9gAAAAJ",
      "7wclGnQAAAAJ",
      "aOklxsQAAAAJ",
      "pHSC4Z0AAAAJ",
      "rRJ9wTJMUB8C",
      "kpcjFekAAAAJ",
      "7OTD-LEAAAAJ",
      "mqpjAt4AAAAJ",
      "laq9cq0AAAAJ",
      "19Ouf5MAAAAJ",
      "X3ZFZ7AAAAAJ",
      "0ZAb3tsAAAAJ",
      "bQTXRrAAAAAJ",
      "4YL23GMAAAAJ",
      "HkVy8voAAAAJ",
      "FwCqwaoAAAAJ",
      "DplAah0AAAAJ",
      "bo0P2qYAAAAJ",
      "jktWnL8AAAAJ",
      "yA4rb60AAAAJ",
      "DGr0fVoAAAAJ",
      "NmHgX-wAAAAJ",
      "swP3h24AAAAJ",
      "NjYyuQQAAAAJ",
      "EaMsuB0AAAAJ",
      "z-b7JmcAAAAJ",
      "67kghxAAAAAJ",
      "OtEdQpcAAAAJ",
      "e0nmxyIAAAAJ",
      "L7lMQkQAAAAJ",
      "9NvupxcAAAAJ",
      "nmxbwm4AAAAJ",
      "SEbcuNoAAAAJ",
      "P_luG3cAAAAJ",
      "TktX0BAAAAAJ",
      "BTZBaosAAAAJ",
      "c8wc-6YAAAAJ",
      "to3X9roAAAAJ",
      "g5CD7dQAAAAJ",
      "kgZtMGsAAAAJ",
      "0zZnyMEAAAAJ",
      "gTWUZlsAAAAJ",
      "DHJjPRAAAAAJ",
      "WeIvMTUAAAAJ",
      "CALLeYgAAAAJ",
      "IyYsKTIAAAAJ",
      "KJoJ8nMAAAAJ",
      "kxAk6AoAAAAJ",
      "_9n9mi8AAAAJ",
      "S7DELUgAAAAJ",
      "mII-l2cAAAAJ",
      "XO8T-Y4AAAAJ",
      "3YnlF3UAAAAJ"
    ],
    "gd04NQ8AAAAJ": [
      "6QWsktwAAAAJ",
      "B9g1lS8AAAAJ",
      "aCLdkF4AAAAJ",
      "Qxtj86kAAAAJ",
      "vErFKeAAAAAJ",
      "lPU_engAAAAJ",
      "JVpq7SwAAAAJ",
      "q-O4OlYAAAAJ",
      "1LgbXjEAAAAJ",
      "FeOUaQYAAAAJ",
      "9Wq1xSUAAAAJ",
      "vRM148kAAAAJ",
      "B2cTx6MAAAAJ",
      "JrWUvfEAAAAJ",
      "7mGMjnIAAAAJ",
      "y_4JsmcAAAAJ",
      "9c-_E-YAAAAJ",
      "mSO6jtEAAAAJ",
      "_pv1sEcAAAAJ",
      "6hPAjdYAAAAJ",
      "l7HQl-kAAAAJ",
      "DOg4nhoAAAAJ"
    ],
    "sJDqACEAAAAJ": [
      "wlosgkoAAAAJ",
      "iGLKl7cAAAAJ",
      "K2hRQgUAAAAJ",
      "bh-uRFMAAAAJ",
      "XUI4PMEAAAAJ",
      "ITZ1e7MAAAAJ",
      "SnQnQicAAAAJ",
      "UjpbO6IAAAAJ",
      "gFN4QUYAAAAJ",
      "APgaFK0AAAAJ",
      "8rDNIMsAAAAJ",
      "CKyX_Y8AAAAJ",
      "dnZ8udEAAAAJ",
      "t6YzEpgAAAAJ",
      "GHpxNQIAAAAJ",
      "rTw-pq0AAAAJ",
      "-3yFcsMAAAAJ",
      "bWoGh8UAAAAJ",
      "GskOShAAAAAJ",
      "jkDd-3QAAAAJ",
      "1hXyfIkAAAAJ",
      "jTMUPNkAAAAJ",
      "9xDADY4AAAAJ",
      "Mgm8xyAAAAAJ",
      "P21gHIkAAAAJ",
      "a3133-8AAAAJ",
      "5ygiTwsAAAAJ",
      "5_Fn5CIAAAAJ",
      "OI0HSa0AAAAJ",
      "KxQfzRcAAAAJ",
      "SgST3LkAAAAJ",
      "E6vCXjkAAAAJ",
      "mN6_BKAAAAAJ",
      "ov9EcNEAAAAJ",
      "Rdp-tpgAAAAJ",
      "Ch9iRwQAAAAJ",
      "tCo0KhkAAAAJ",
      "QBn7vq8AAAAJ",
      "PvDd3k4AAAAJ",
      "Q0mfsAMAAAAJ",
      "lg1fT1kAAAAJ",
      "pouyVyUAAAAJ",
      "tjb2UccAAAAJ",
      "nzA4P0oAAAAJ",
      "jtrAdywAAAAJ",
      "bBnvK8cAAAAJ",
      "LYVNrhMAAAAJ",
      "njJoC7wAAAAJ",
      "p1XHoeoAAAAJ",
      "FWJZYMYAAAAJ",
      "U2MUXuMAAAAJ",
      "vhP-tlcAAAAJ",
      "HqC4vl8AAAAJ",
      "BMydCgcAAAAJ",
      "043r6toAAAAJ",
      "RiDZxz8AAAAJ",
      "loh93ZkAAAAJ",
      "EL-QbZ4AAAAJ",
      "fKESO6sAAAAJ",
      "wRZrrqwAAAAJ",
      "W2DsnAkAAAAJ",
      "eJwbbXEAAAAJ",
      "WFKit_4AAAAJ",
      "iGWgEw8AAAAJ",
      "-xaOIZIAAAAJ",
      "IRTtnAIAAAAJ",
      "Ivot3fkAAAAJ",
      "J2Z-ChoAAAAJ",
      "ikq9m9QAAAAJ",
      "t70ydxAAAAAJ",
      "BCKhEoAAAAAJ",
      "FtdDAMoAAAAJ",
      "iEFL4-YAAAAJ",
      "zV5vhUcAAAAJ",
      "Yn59qc4AAAAJ",
      "16OCMAQAAAAJ",
      "wc1Hbl8AAAAJ",
      "o-5vyEsAAAAJ",
      "AV6nozIAAAAJ",
      "uocljD4AAAAJ",
      "niZiN38AAAAJ",
      "UgHB5oAAAAAJ",
      "gqB4u_wAAAAJ",
      "GRMLwjAAAAAJ",
      "wN9rBkcAAAAJ",
      "2QbbLJAAAAAJ",
      "Clrvw6kAAAAJ",
      "zzbWQE4AAAAJ",
      "M3BSiiQAAAAJ",
      "_VmflIEAAAAJ",
      "Lg6yyBEAAAAJ",
      "-y6SIhQAAAAJ",
      "LJnNKXMAAAAJ",
      "t41vrrQAAAAJ",
      "f1hBi5wAAAAJ",
      "bMTBja0AAAAJ",
      "IBlMTLwAAAAJ",
      "VBkk_NoAAAAJ",
      "pjLCdhIAAAAJ",
      "oIz_CYEAAAAJ",
      "PoZv5KkAAAAJ",
      "rFL468UAAAAJ",
      "S9Q7lk4AAAAJ",
      "8DeZgKkAAAAJ",
      "uU2UhGIAAAAJ",
      "YhWnhQEAAAAJ",
      "VBouyX8AAAAJ",
      "sLYXumkAAAAJ",
      "sycHskQAAAAJ",
      "LIjnUGgAAAAJ",
      "wTTF4yYAAAAJ",
      "BMo9cZ4AAAAJ",
      "s3McVn8AAAAJ",
      "OqAc0T0AAAAJ",
      "culGbtkAAAAJ",
      "s0Fof5IAAAAJ",
      "j88h_roAAAAJ",
      "mpZg3FnnHpQC",
      "CYMAfxsAAAAJ",
      "bI0cfykAAAAJ",
      "BIO5wVQAAAAJ",
      "mQIqIVwAAAAJ",
      "steJe6IAAAAJ",
      "picvdvEAAAAJ",
      "D5eyaLwAAAAJ",
      "blTzjfsAAAAJ",
      "jeNGFfQAAAAJ",
      "XT3E7RoAAAAJ",
      "I6P0SwgAAAAJ",
      "daslsUkAAAAJ",
      "yAsgeGIAAAAJ",
      "Xmv0998AAAAJ",
      "xVB9askAAAAJ",
      "C_r8d0AAAAAJ",
      "IMYgXsYAAAAJ",
      "MB0OgPEAAAAJ",
      "eAwnN44AAAAJ",
      "ZBBX5u4AAAAJ",
      "E9EgKkMAAAAJ",
      "jee2Dy0AAAAJ",
      "xj666rUAAAAJ",
      "pfqzHqUAAAAJ",
      "r1Zw-VEAAAAJ",
      "pKf5LtQAAAAJ",
      "AYbfPEAAAAAJ",
      "COEsqLYAAAAJ",
      "hCatCxMAAAAJ",
      "p7dCP-kAAAAJ",
      "3xUoKkwAAAAJ",
      "8ew3do4AAAAJ",
      "3-lTFAwAAAAJ",
      "gr_ZVSQAAAAJ",
      "PW6eQ6YAAAAJ",
      "8MFFVgEAAAAJ",
      "OENNEBIAAAAJ",
      "DP3jcx0AAAAJ",
      "ztpK4iwAAAAJ",
      "F4JYGjcAAAAJ",
      "w24_ETkAAAAJ",
      "p9RsPG4AAAAJ",
      "VcmM93MAAAAJ",
      "-mHoWKEAAAAJ",
      "Um4ZbbgAAAAJ",
      "8D_Ggb4AAAAJ",
      "QHVdvtUAAAAJ",
      "bQzoxtsAAAAJ",
      "C3NuO-AAAAAJ",
      "Pd8-ju0AAAAJ",
      "K931JfEAAAAJ",
      "3siz6_0AAAAJ",
      "qg_aiScAAAAJ",
      "NmP-rOAAAAAJ",
      "EYWzxPIAAAAJ",
      "LDpxmC8AAAAJ",
      "fOZk6agAAAAJ",
      "fVxqrBkAAAAJ",
      "84WzBlYAAAAJ",
      "eJsW6W8AAAAJ",
      "nUCWRZAAAAAJ",
      "gGcRkpYAAAAJ",
      "SNVrOLwAAAAJ",
      "hR249csAAAAJ",
      "x5QTK9YAAAAJ",
      "jxQJo9MAAAAJ",
      "TqDmo1UAAAAJ",
      "fMQZybAAAAAJ"
    ],
    "PpzsjioAAAAJ": [
      "8R35rCwAAAAJ",
      "d5y4iKAAAAAJ",
      "dG9MV7oAAAAJ"
    ],
    "Rn_BmTYAAAAJ": [],
    "YAHWbtkAAAAJ": [
      "B847xq8AAAAJ",
      "_PZKLYUAAAAJ",
      "0lZoXCUAAAAJ",
      "fNOReswAAAAJ",
      "_1hCq3UAAAAJ",
      "gRxBNZoAAAAJ",
      "SqFoZNUAAAAJ",
      "UnEHCNkAAAAJ",
      "opbZfw0AAAAJ",
      "8O8MQEUAAAAJ",
      "4DuiN7AAAAAJ",
      "r44N6h8AAAAJ",
      "4Z6vo5QAAAAJ",
      "zS3z8UgAAAAJ",
      "QWzsNMDsvlIC",
      "PS-TM94AAAAJ",
      "DYUloYkAAAAJ",
      "nP8cwkIAAAAJ",
      "DKFiD7cAAAAJ",
      "kukA0LcAAAAJ",
      "qx_e_9wAAAAJ",
      "m_HQ-WQAAAAJ",
      "65FCPpwAAAAJ",
      "y-8unsgAAAAJ",
      "H1vNRiUAAAAJ",
      "jM23vRsKxuIC",
      "zkvW8FQAAAAJ",
      "WBS6zncAAAAJ",
      "93zBpkAAAAAJ",
      "F_ASWCUAAAAJ",
      "y_wpkH8AAAAJ",
      "ajIYB6wAAAAJ",
      "hISpTpQAAAAJ",
      "osxb7aMAAAAJ",
      "pzkLOIwAAAAJ",
      "-iPZaBcAAAAJ",
      "lH1PdF8AAAAJ",
      "c_z5hWEAAAAJ",
      "WLN3QrAAAAAJ",
      "l-mlF7YAAAAJ",
      "7HCKL10AAAAJ",
      "LQR0kNcAAAAJ",
      "q4zv0KYAAAAJ",
      "fkGi-JMAAAAJ",
      "-CeUxegAAAAJ",
      "1eBgIWsAAAAJ",
      "r3q68rcAAAAJ",
      "Ajm0ijIAAAAJ"
    ],
    "23LELwEAAAAJ": [
      "UZ5wscMAAAAJ",
      "bRT7t28AAAAJ",
      "SBTxvCoAAAAJ",
      "-BO7TXUAAAAJ",
      "IUZ-7_cAAAAJ",
      "0ncQNL8AAAAJ",
      "-gFCCLMAAAAJ",
      "PtBtfawAAAAJ",
      "e0nmxyIAAAAJ",
      "yN7CEicAAAAJ",
      "ep_nM5sAAAAJ",
      "rrPyvsgAAAAJ",
      "hlC76YUAAAAJ",
      "vtwH6GkAAAAJ",
      "rLdfJ1gAAAAJ",
      "hOl-5zcAAAAJ",
      "-KzSL30AAAAJ",
      "hWzXZUMAAAAJ",
      "jUOcawkAAAAJ",
      "itSa94cAAAAJ"
    ],
    "XXUsEjsAAAAJ": [
      "a_dbdxAAAAAJ",
      "bh-uRFMAAAAJ",
      "oQsObk0AAAAJ",
      "APgaFK0AAAAJ",
      "-pyztDMAAAAJ",
      "44ANFF4AAAAJ",
      "FiTQ7UIAAAAJ",
      "wTCe1mUAAAAJ",
      "44jDM6EAAAAJ",
      "OtREFPYAAAAJ",
      "6ma-nCYAAAAJ",
      "12uhMdIAAAAJ",
      "q9UyGCIAAAAJ",
      "ysE-XbUAAAAJ",
      "Ji-VV2cAAAAJ",
      "MkxZCXsAAAAJ",
      "crlzbrMAAAAJ",
      "YCbFRsAAAAAJ",
      "aAAY3oYAAAAJ",
      "xsaakpMAAAAJ",
      "j7PrPEUAAAAJ",
      "oRkkQm4AAAAJ",
      "cITeyPkAAAAJ",
      "LuQA_vcAAAAJ",
      "STgsgLAAAAAJ",
      "dGj1KOsAAAAJ",
      "h1XZv94AAAAJ",
      "sd0Rw0YAAAAJ",
      "pL8RApYAAAAJ",
      "uO3mk-IAAAAJ",
      "yxUduqMAAAAJ",
      "RL61eA0AAAAJ",
      "44-qrTIAAAAJ",
      "1cVvrLYAAAAJ",
      "5IMEORsAAAAJ",
      "oTXlEEwAAAAJ",
      "QV8hqE4AAAAJ",
      "v8xm0csAAAAJ",
      "_AZwpCAAAAAJ",
      "iS5ADlgAAAAJ",
      "3aO6KH4AAAAJ",
      "sDjp1K8AAAAJ",
      "QzTJEdYAAAAJ"
    ],
    "chICXXMAAAAJ": [
      "GR_DsT0AAAAJ",
      "evrgC2oAAAAJ",
      "yxUduqMAAAAJ",
      "o42MH0MAAAAJ",
      "I0EoZyQAAAAJ",
      "bMDg-3cAAAAJ",
      "h1NXfKYAAAAJ",
      "RtNVud4AAAAJ",
      "aO8KpGcAAAAJ",
      "sdENOQ4AAAAJ",
      "8r2Fiv4AAAAJ",
      "kGOgaowAAAAJ",
      "nUlanA8AAAAJ",
      "zl70inwAAAAJ",
      "QIRWZf8AAAAJ",
      "wb-DKCIAAAAJ",
      "BaCR90MAAAAJ",
      "EfxwV6oAAAAJ",
      "k7NgVSUAAAAJ",
      "HSx0BgQAAAAJ",
      "2oy3OXYAAAAJ",
      "Bk8FeYwAAAAJ",
      "E3yOuvEAAAAJ"
    ],
    "23ZXZvEAAAAJ": [],
    "b957ulAAAAAJ": [],
    "jyxO2akAAAAJ": [
      "CUlqK5EAAAAJ",
      "QFpswmcAAAAJ",
      "DSKXnkkAAAAJ",
      "XcQ9WqMAAAAJ",
      "2wrS35MAAAAJ",
      "SVIdh6AAAAAJ",
      "qSo45J0AAAAJ",
      "iBeDoRAAAAAJ",
      "SrVnrPcAAAAJ",
      "3B2c31wAAAAJ",
      "ARmv8N4AAAAJ",
      "kzFmAkYAAAAJ",
      "bh-uRFMAAAAJ",
      "8cxDHS4AAAAJ",
      "_CuXgYIAAAAJ",
      "WS2-qlAAAAAJ",
      "FJ-huxgAAAAJ",
      "fqi186AAAAAJ",
      "n-B0jr4AAAAJ",
      "OeAQ2c0AAAAJ",
      "ITZ1e7MAAAAJ",
      "GMzzRRUAAAAJ",
      "CCV58dgAAAAJ",
      "njOmQFsAAAAJ",
      "YYH0BjEAAAAJ",
      "GArEeWQAAAAJ",
      "nbpafUkAAAAJ",
      "x2wyjkAAAAAJ",
      "UY7CtEwAAAAJ",
      "194wSMsAAAAJ",
      "V3kGMXUAAAAJ",
      "Lw0H0EwAAAAJ",
      "r3SJcvoAAAAJ",
      "awvsNQYAAAAJ",
      "tXJDPJAAAAAJ",
      "SlkU8ZQAAAAJ",
      "4D1n8scAAAAJ",
      "SI6sQPYAAAAJ",
      "rJotb-YAAAAJ",
      "Eclg4mwAAAAJ",
      "ACjYGPUAAAAJ",
      "Jp6Mz1sAAAAJ",
      "iAEBIB4AAAAJ",
      "2bDu3ecAAAAJ",
      "_7QgnUcAAAAJ",
      "D2VLt-8AAAAJ",
      "C6GeyOwAAAAJ",
      "CpFoJ1gAAAAJ",
      "XWhajuQAAAAJ",
      "SFCOJxMAAAAJ",
      "KNWTvgEAAAAJ",
      "ayUyj9YAAAAJ",
      "ZcWO2AEAAAAJ",
      "ijpYJQwAAAAJ",
      "Y5x2ZgQAAAAJ",
      "2oq9614AAAAJ",
      "xgQd1qgAAAAJ",
      "zCsB5XsAAAAJ",
      "pk5cKBUAAAAJ",
      "6TGwETYAAAAJ",
      "6m1ptOgAAAAJ",
      "JgTAHxkAAAAJ",
      "9yQ1tQoAAAAJ",
      "GPusciUAAAAJ",
      "DN8QtscAAAAJ",
      "TwMib_QAAAAJ",
      "dlFYlXwAAAAJ",
      "7BFEwr4AAAAJ",
      "a3K-f2YAAAAJ",
      "JycXWO0AAAAJ",
      "qvRsU00AAAAJ",
      "6Wg-hF4AAAAJ",
      "yxUduqMAAAAJ",
      "xpwMxy8AAAAJ",
      "BYrARP4AAAAJ",
      "H2JX-RQAAAAJ",
      "9BMXWA8AAAAJ",
      "lveaf5IAAAAJ",
      "-LJCZMMAAAAJ",
      "18fTep8AAAAJ",
      "YLOz1kgAAAAJ",
      "EmmO7LcAAAAJ",
      "CffJDoEAAAAJ",
      "5pKTRxEAAAAJ",
      "D1okUccAAAAJ",
      "tAK5l1IAAAAJ",
      "tvWB_yUAAAAJ",
      "ZU1fTMYAAAAJ",
      "ImpbxLsAAAAJ",
      "1k8gBxEAAAAJ",
      "wm2BrUcAAAAJ"
    ],
    "Op-47sgAAAAJ": [
      "iyDxq0EAAAAJ",
      "1M79iLwAAAAJ",
      "df-THM0AAAAJ",
      "87nZphcAAAAJ",
      "Vy16O5UAAAAJ",
      "vN-is70AAAAJ",
      "B96GkdgAAAAJ",
      "aO8KpGcAAAAJ",
      "yDVn5LEAAAAJ",
      "nfX25MMAAAAJ"
    ],
    "cnncomYAAAAJ": [
      "5pKTRxEAAAAJ",
      "tR3AZbwAAAAJ",
      "M9oUY4cAAAAJ",
      "zbXIQMsAAAAJ",
      "EY2lqD0AAAAJ",
      "6HgpyjMAAAAJ",
      "N7_xhHoAAAAJ",
      "ki5hheQAAAAJ",
      "cxM-P9UAAAAJ",
      "bniKGtgAAAAJ",
      "H1d4BS8AAAAJ",
      "tk0e5lYAAAAJ",
      "nnLiId8AAAAJ",
      "HKk8VjoAAAAJ",
      "nhNWrxkAAAAJ",
      "voxznZAAAAAJ",
      "4fK8bYIAAAAJ",
      "IKoa5qAAAAAJ",
      "23ZXZvEAAAAJ",
      "Wrfc4V8AAAAJ",
      "TmuUs30AAAAJ",
      "K6RYRTMAAAAJ",
      "Tpp9ZjoAAAAJ",
      "dM1jSoEAAAAJ",
      "MSCQE-YAAAAJ",
      "lkPKfjgAAAAJ",
      "0DX2YsQAAAAJ",
      "3xUT1e0AAAAJ",
      "ITZ1e7MAAAAJ",
      "j9jhYqQAAAAJ",
      "eETZ8vQAAAAJ",
      "U5ZZu3IAAAAJ",
      "axsP38wAAAAJ",
      "DLazAw4AAAAJ",
      "JY6hDCoAAAAJ",
      "wlosgkoAAAAJ",
      "aO8KpGcAAAAJ",
      "sUriZlUAAAAJ",
      "Lt4tmL8AAAAJ"
    ],
    "bslhbWgAAAAJ": [
      "vfPE6hgAAAAJ",
      "pouyVyUAAAAJ",
      "BAAZ_ysAAAAJ",
      "8R35rCwAAAAJ",
      "Ch9iRwQAAAAJ",
      "EHSuFcwAAAAJ",
      "qjDVoqQAAAAJ",
      "_0IIzxgAAAAJ",
      "tP5IBFkAAAAJ",
      "i7V1kJgAAAAJ",
      "L5v2PHAAAAAJ",
      "q77J4fgAAAAJ",
      "BOAOkNQAAAAJ",
      "wMcPTbEAAAAJ",
      "6S9C8XoAAAAJ"
    ],
    "bdHgGgEAAAAJ": [
      "AEsPCAUAAAAJ",
      "8R35rCwAAAAJ",
      "BsOkXDsAAAAJ",
      "5dBp2f4AAAAJ",
      "bqL73OkAAAAJ",
      "Uly5spMAAAAJ"
    ],
    "GyoKzFwAAAAJ": [
      "0RAmmIAAAAAJ",
      "kukA0LcAAAAJ",
      "km6CP8cAAAAJ",
      "ymzxRhAAAAAJ",
      "8R35rCwAAAAJ",
      "vfPE6hgAAAAJ",
      "Lncr-VoAAAAJ",
      "C-ZlBWMAAAAJ",
      "dLaR9lgAAAAJ",
      "7hwJ2ckAAAAJ",
      "CEt6_mMAAAAJ",
      "iRgYMuEAAAAJ"
    ],
    "GUAoEcAAAAAJ": [
      "vN-is70AAAAJ",
      "sAdDcvQAAAAJ",
      "I1EvjZsAAAAJ",
      "SssrcUsAAAAJ",
      "3_WYcR4AAAAJ",
      "CZyWk8kAAAAJ",
      "Qf4bw4UAAAAJ",
      "ZTkRs84AAAAJ",
      "SqMUez0AAAAJ",
      "9s9o-JcAAAAJ",
      "p0sQC6sAAAAJ",
      "YsXNU78AAAAJ",
      "hmq4rGIAAAAJ",
      "07ds-DAAAAAJ",
      "5JE9m1EAAAAJ",
      "urTiL7QAAAAJ",
      "MYqlcPgAAAAJ",
      "XRyUF6gAAAAJ",
      "du-k5BYAAAAJ",
      "KmXVOQkAAAAJ",
      "PkfChMgAAAAJ",
      "uFJi3IUAAAAJ",
      "D2K-ADYAAAAJ",
      "HvwPRJ0AAAAJ",
      "IAeKTGsAAAAJ",
      "EnCwNycAAAAJ",
      "I_YsXU4AAAAJ",
      "hwnskpoAAAAJ",
      "Cgx9W6UAAAAJ",
      "Dzh5C9EAAAAJ",
      "SaboshYAAAAJ",
      "0VwIiIsAAAAJ",
      "rXYLXJMAAAAJ",
      "vVvbU7oAAAAJ",
      "FVTgmOwAAAAJ",
      "JHwivywAAAAJ",
      "xdGKgtcAAAAJ",
      "Ikz6_Y0AAAAJ",
      "q33fP9sAAAAJ",
      "Zm0kSvgAAAAJ",
      "VuvKPiQAAAAJ",
      "HHn7118AAAAJ",
      "CZa9GB4AAAAJ",
      "2-uoevgAAAAJ",
      "X22nUYgAAAAJ",
      "-DBwBK4AAAAJ",
      "HF2G3LAAAAAJ",
      "Q9DsCL4AAAAJ",
      "whNDkmMAAAAJ",
      "nqrkC8IAAAAJ",
      "xYfYnG4AAAAJ",
      "cTGO2HoAAAAJ",
      "d_rxnzAAAAAJ",
      "BFE6IQwAAAAJ",
      "qR7R2FMAAAAJ",
      "5LLV29oAAAAJ",
      "uezRX6QAAAAJ",
      "96mJbhwAAAAJ",
      "6_cxCKQAAAAJ",
      "mQf5cE0AAAAJ",
      "HHwoC2MAAAAJ",
      "O-TV6OgAAAAJ",
      "00M1AqQAAAAJ",
      "DGcTRyEAAAAJ",
      "cc4Qi_IAAAAJ",
      "_m7uOmUAAAAJ",
      "Gzxda70AAAAJ",
      "dTkWR0MAAAAJ",
      "DSEH8XsAAAAJ",
      "TvV_SVwAAAAJ",
      "sNeVyqoAAAAJ",
      "j4UuW80AAAAJ",
      "2vQRGrYAAAAJ",
      "9RlvgLEAAAAJ",
      "J1vWqkQAAAAJ",
      "HsYH17vSXmQC",
      "hHYRga0AAAAJ",
      "9MSpWOUAAAAJ",
      "pIoPb7sAAAAJ",
      "71IXR1QAAAAJ",
      "4ZYEiVEAAAAJ",
      "QfVWndgAAAAJ",
      "2aqrWocAAAAJ",
      "qnMs-XYAAAAJ",
      "Da-s1FQAAAAJ",
      "-EMkK7QAAAAJ",
      "Sh1yq5QAAAAJ",
      "DvbPrWYAAAAJ",
      "WOrTFE0AAAAJ",
      "0irVeiQAAAAJ",
      "Wj4ZBFIAAAAJ",
      "tgfOQwEAAAAJ",
      "GXJqtYUAAAAJ",
      "MwLqCs4AAAAJ",
      "-OpGJpYAAAAJ",
      "ff0742EAAAAJ",
      "4fOVJ7UAAAAJ",
      "UphI-hIAAAAJ",
      "cbTB5-EAAAAJ",
      "vG5UNEQAAAAJ",
      "AQ6AppgAAAAJ",
      "16posrQAAAAJ",
      "5V852JcAAAAJ",
      "rQ0Zl50AAAAJ",
      "BbzYzsgAAAAJ",
      "Gwrwxa0AAAAJ",
      "in6eBIwAAAAJ",
      "rHIz0PoAAAAJ",
      "wUArfPgAAAAJ",
      "uyCsSAEAAAAJ",
      "gqkpV2kAAAAJ",
      "aSqr26EAAAAJ",
      "7SdcAiEAAAAJ",
      "1_kJPIEAAAAJ",
      "euwkGt0AAAAJ",
      "G-oLZ6wAAAAJ",
      "TxVfH8QAAAAJ",
      "VMXSblwAAAAJ",
      "MrWIWNwAAAAJ",
      "Bz3APTsAAAAJ",
      "7CohtIMAAAAJ",
      "a1ngrCIAAAAJ",
      "hbLmvo0AAAAJ",
      "81IhdxgAAAAJ",
      "-N-_kgsAAAAJ",
      "dfScyQgAAAAJ",
      "Ba_Ci9UAAAAJ",
      "MDRALDkAAAAJ",
      "5pJNSzMAAAAJ",
      "-0vALDMAAAAJ",
      "3rq29xkAAAAJ",
      "WbYQGjcAAAAJ",
      "Hd3kUc4AAAAJ",
      "VMihW8oAAAAJ",
      "AaMR6EQAAAAJ",
      "HeEBacsAAAAJ",
      "aQCRuYQAAAAJ",
      "7kaIUXoAAAAJ"
    ],
    "zUJus70AAAAJ": [],
    "uFJi3IUAAAAJ": [
      "vN-is70AAAAJ",
      "a1ngrCIAAAAJ",
      "p0sQC6sAAAAJ",
      "B96GkdgAAAAJ",
      "HF2G3LAAAAAJ",
      "TKSjVTUAAAAJ",
      "DpLFv4gAAAAJ",
      "Zmvi6PMAAAAJ",
      "ZuWlfPEAAAAJ",
      "GUAoEcAAAAAJ",
      "7SdcAiEAAAAJ",
      "qG1LVpQAAAAJ",
      "WemX9rAAAAAJ",
      "cTGO2HoAAAAJ",
      "QfVWndgAAAAJ",
      "PeCI8KcAAAAJ",
      "Q8kbUQEAAAAJ",
      "vlgs4G4AAAAJ",
      "MDRALDkAAAAJ",
      "b8OxVWUAAAAJ",
      "Wj4ZBFIAAAAJ",
      "vKlrdpEAAAAJ",
      "H3LMjtoAAAAJ",
      "muunN_AAAAAJ",
      "udZSrkYAAAAJ",
      "5Ec8ENMAAAAJ",
      "gMOBKfUAAAAJ",
      "vl8imyIAAAAJ",
      "Hs9cVRgAAAAJ",
      "urTiL7QAAAAJ",
      "WXbhp_4AAAAJ",
      "YsXNU78AAAAJ",
      "C1skWKgAAAAJ",
      "xdGKgtcAAAAJ",
      "80pKMyMAAAAJ",
      "VeB3UbcAAAAJ",
      "sAdDcvQAAAAJ",
      "m0WCd-4AAAAJ",
      "1AzRLAUAAAAJ",
      "bgmagbUAAAAJ",
      "8VkvOEEAAAAJ",
      "8fztli4AAAAJ",
      "-3XaxbkAAAAJ",
      "SKVnHakAAAAJ",
      "zdKmnYwAAAAJ",
      "yxUduqMAAAAJ",
      "qhu-DxwAAAAJ",
      "QQVlcOUAAAAJ",
      "Iiut4KYAAAAJ",
      "rXYLXJMAAAAJ",
      "84WzBlYAAAAJ",
      "BbzYzsgAAAAJ",
      "3vKjkoQAAAAJ",
      "MIfpzUQAAAAJ",
      "Yxh9WWoAAAAJ",
      "yZGlLeMAAAAJ",
      "vtwH6GkAAAAJ",
      "H-VmFU4AAAAJ",
      "sOzdfjYAAAAJ",
      "rR96kW0AAAAJ",
      "7P-gZioAAAAJ",
      "RkddXygAAAAJ",
      "wR_tv-kAAAAJ",
      "NvKHgzkAAAAJ",
      "Vn3L_ioAAAAJ",
      "DXsaMGgAAAAJ",
      "5LLV29oAAAAJ",
      "bkcNcHYAAAAJ",
      "BVD_LdgAAAAJ",
      "DnnCWN0AAAAJ",
      "TBaBNdkAAAAJ",
      "X53rkecAAAAJ",
      "BItCgjYAAAAJ",
      "I_YsXU4AAAAJ",
      "-YvgZDEAAAAJ",
      "7CohtIMAAAAJ",
      "7_RHB_gAAAAJ",
      "qj3IRU8AAAAJ",
      "NYgWyv0AAAAJ",
      "QXyvv94AAAAJ",
      "IhmK-VkAAAAJ",
      "wmZTE5gAAAAJ",
      "Nxmx29UAAAAJ",
      "zxeEF2gAAAAJ",
      "93yNuV0AAAAJ",
      "4bL3ThUAAAAJ",
      "h1XZv94AAAAJ",
      "DDxFvcIAAAAJ",
      "in6eBIwAAAAJ",
      "2vQRGrYAAAAJ",
      "YCoLskoAAAAJ",
      "MrWIWNwAAAAJ",
      "T_IyfqMAAAAJ"
    ],
    "Tsh90D8AAAAJ": [
      "8fztli4AAAAJ",
      "5lhsTYwAAAAJ",
      "1Tfui8UAAAAJ",
      "XDXw3jQAAAAJ",
      "K29Sv1EAAAAJ",
      "vtwH6GkAAAAJ",
      "xOWBOKQAAAAJ",
      "mNwCdqwAAAAJ",
      "y5uNFK0AAAAJ",
      "ucSLToQAAAAJ",
      "kUbCuLgAAAAJ",
      "ZlSVieAAAAAJ",
      "Du7j3mQAAAAJ",
      "0MiPsosAAAAJ",
      "1NyT9gQAAAAJ",
      "Yxh9WWoAAAAJ",
      "UgHB5oAAAAAJ",
      "VjsNXysAAAAJ",
      "p0sQC6sAAAAJ",
      "lsbreWwAAAAJ",
      "IoGj8UEAAAAJ",
      "J8_FdjkAAAAJ",
      "rLI9DmoAAAAJ",
      "DJ9puk8AAAAJ",
      "8-p9CLsAAAAJ",
      "jERkdhIAAAAJ",
      "5eoD8UwAAAAJ",
      "fKV65XQAAAAJ",
      "dq3yXjkAAAAJ",
      "RlSbIJ4AAAAJ",
      "ZSRwsn6tjckC",
      "KQFUVR8AAAAJ",
      "oH7drVcAAAAJ",
      "TCYAoF8AAAAJ",
      "jFekO3IAAAAJ",
      "awNOAaYAAAAJ",
      "3WEijrIAAAAJ",
      "NcEl9LwAAAAJ",
      "AC93g9kAAAAJ",
      "83OxU_4AAAAJ",
      "IcaU830AAAAJ",
      "FH9nKOAAAAAJ",
      "LAv0HTEAAAAJ",
      "ECHSnpYAAAAJ",
      "8R35rCwAAAAJ",
      "UfbuDH8AAAAJ",
      "itSa94cAAAAJ",
      "PYrd2GMAAAAJ"
    ],
    "zS3z8UgAAAAJ": [
      "Zrv4oQIAAAAJ",
      "QWzsNMDsvlIC",
      "4JsyJK8AAAAJ",
      "0iieFBwAAAAJ",
      "fdkVqrsAAAAJ",
      "u0rkSl0AAAAJ",
      "kJ9CX6sAAAAJ",
      "zMH25DoAAAAJ",
      "wJ8seI8AAAAJ",
      "GLxE-TcAAAAJ",
      "B847xq8AAAAJ",
      "0ZsqI4kAAAAJ",
      "YAHWbtkAAAAJ",
      "pCj-4VAAAAAJ",
      "GoR_32IAAAAJ",
      "vHi84IsAAAAJ",
      "D6ZDEUgAAAAJ",
      "Q7ftcFEAAAAJ",
      "4j3sGYwAAAAJ",
      "9IWk2PMAAAAJ",
      "4hda5e8AAAAJ",
      "IuKFwTsAAAAJ",
      "-8rxeRIAAAAJ",
      "pHTgOOIAAAAJ",
      "iusaOxAAAAAJ",
      "Koez6qoAAAAJ",
      "vPOv3boAAAAJ",
      "0p--0vgAAAAJ",
      "9TKjEuQAAAAJ",
      "Dfzm6hsAAAAJ",
      "nhIirs0AAAAJ",
      "NuPqqNAAAAAJ",
      "ovgLRIIAAAAJ",
      "0ZgdQZ8AAAAJ",
      "FOF_PaEAAAAJ",
      "kf8nxJ8AAAAJ",
      "5Xz6xycAAAAJ",
      "yCyrc0MAAAAJ",
      "qbzezVEAAAAJ",
      "7MZe4owAAAAJ",
      "unUhqcwAAAAJ",
      "VgbZ7z8AAAAJ",
      "AnLxYd8AAAAJ",
      "Y-C2u28AAAAJ",
      "cGgZI40AAAAJ",
      "qL9o1Y0AAAAJ",
      "AgN0kSEAAAAJ",
      "V3UXWuMAAAAJ",
      "7unNfcMAAAAJ",
      "9YnPccsAAAAJ",
      "jxBZFwQAAAAJ",
      "-OGSuAkAAAAJ",
      "-K2KHjIAAAAJ",
      "05_s28EAAAAJ",
      "QIp7IMUAAAAJ",
      "ZjyUJyIAAAAJ",
      "LWZtl74AAAAJ",
      "NjxgmeIAAAAJ",
      "sYncdvUAAAAJ",
      "Tq0P7eoAAAAJ",
      "--0WA_UAAAAJ",
      "rtfJhO0AAAAJ",
      "VP48uSEAAAAJ",
      "Akmpg4gAAAAJ",
      "SkH-ZyIAAAAJ",
      "QPlFU6oAAAAJ",
      "fAO6gAYAAAAJ",
      "_-qBW0UAAAAJ",
      "HH5gtyoAAAAJ",
      "NaThra4AAAAJ",
      "REGT0fcAAAAJ",
      "YP3gziUAAAAJ",
      "-ooGheoAAAAJ",
      "eqmeFRoAAAAJ",
      "4yk44z4AAAAJ",
      "96ciTVoAAAAJ",
      "mhpaapIAAAAJ",
      "RHXdl6EAAAAJ",
      "VFXKWYYAAAAJ",
      "iz3e3X8AAAAJ",
      "-DSn7-wAAAAJ",
      "Pskjj5AAAAAJ",
      "b7w97acAAAAJ",
      "VA4ExhYAAAAJ",
      "gaiImbAAAAAJ",
      "Fv9ag1YAAAAJ",
      "zIjCVzAAAAAJ",
      "W_BvHWoAAAAJ",
      "1fNDr6wAAAAJ",
      "0L8vKCwAAAAJ",
      "7MoHiJ8AAAAJ",
      "bOlnJwcAAAAJ",
      "HAG5Og4AAAAJ",
      "rFB25cgAAAAJ",
      "66s6LkAAAAAJ",
      "y-8unsgAAAAJ",
      "EzMN4zkAAAAJ",
      "plQDn_wAAAAJ",
      "0J6vYkEAAAAJ",
      "SjP9OAoAAAAJ",
      "MpuRqeQAAAAJ"
    ],
    "87nZphcAAAAJ": [],
    "OttawxUAAAAJ": [
      "GR_DsT0AAAAJ",
      "n8ZpnWMAAAAJ",
      "ZybgAqkAAAAJ",
      "vGBcNVAAAAAJ",
      "5vVjpBsAAAAJ",
      "sUriZlUAAAAJ",
      "RUP4S68AAAAJ",
      "ITZ1e7MAAAAJ",
      "VZHxoh8AAAAJ",
      "Q21P3fsAAAAJ",
      "umivlPQAAAAJ",
      "0mgEF28AAAAJ",
      "wb-DKCIAAAAJ",
      "un0eGzEAAAAJ",
      "dq3yXjkAAAAJ",
      "HpQGq54AAAAJ",
      "yxUduqMAAAAJ",
      "AnSVkUYAAAAJ",
      "9sHizzsAAAAJ",
      "IuMFxFUAAAAJ",
      "o7yFQXUAAAAJ",
      "eV2tuR8AAAAJ",
      "vlN_kRoAAAAJ",
      "dusV5HMAAAAJ",
      "vK0-CDcAAAAJ",
      "gTWUZlsAAAAJ",
      "DWERCmsAAAAJ",
      "2_gFWe4AAAAJ",
      "9TbXgQ0AAAAJ",
      "BaCR90MAAAAJ",
      "1yB0eLMAAAAJ",
      "K0kaNvkAAAAJ",
      "Uhf4nBkAAAAJ",
      "NdY_HacAAAAJ",
      "OsSiEMEAAAAJ",
      "KJLJstYAAAAJ",
      "GINhGvwAAAAJ",
      "kGOgaowAAAAJ",
      "6JZ3R6wAAAAJ",
      "jQeFWdoAAAAJ",
      "m8m9nD0AAAAJ",
      "df-THM0AAAAJ",
      "yDZct7UAAAAJ",
      "t9HPFawAAAAJ",
      "r1Fn_YsAAAAJ",
      "RtNVud4AAAAJ",
      "jCNJhFcAAAAJ",
      "IURWCt4AAAAJ",
      "r-mWYj0AAAAJ",
      "nUlanA8AAAAJ",
      "9nnDvooAAAAJ",
      "LFiqVpwAAAAJ",
      "wYMTld8AAAAJ",
      "ym8AZSIAAAAJ",
      "f6JF7BkAAAAJ",
      "iOLC30YAAAAJ",
      "i38QlUwAAAAJ",
      "UwLsYw8AAAAJ",
      "Rqy5KDEAAAAJ",
      "Bk5q_pAAAAAJ",
      "6qWcDTAAAAAJ",
      "UnuEcZEAAAAJ",
      "Ry0Bdt8AAAAJ",
      "xQqZt2AAAAAJ",
      "843JJtgAAAAJ",
      "XTqgW-EAAAAJ",
      "-hW6cvgAAAAJ",
      "j_SEFF8AAAAJ",
      "EJXN6tYAAAAJ",
      "2efgcS0AAAAJ",
      "4zybTq4AAAAJ",
      "3tNXqMIAAAAJ",
      "fn13u8IAAAAJ",
      "9cboKEYAAAAJ",
      "yStEfeIAAAAJ",
      "VgNDYeYAAAAJ",
      "1wLVDP4AAAAJ",
      "TR6GqIgAAAAJ",
      "h1NXfKYAAAAJ",
      "vzr_L0EAAAAJ",
      "XBg0AAkAAAAJ",
      "-P9LwcgAAAAJ",
      "upMvIv4AAAAJ",
      "qjJg6akAAAAJ",
      "c73wW0kAAAAJ",
      "QgETxGoAAAAJ",
      "2HJu9wgAAAAJ",
      "kpQGGFUAAAAJ",
      "cHN3PVYAAAAJ",
      "bDrXQPUAAAAJ",
      "F24vXggAAAAJ",
      "LWlN_BUAAAAJ",
      "qU9WvTgAAAAJ",
      "LTKmex0AAAAJ",
      "GU9HgNAAAAAJ",
      "NIpOwa8AAAAJ",
      "R6jE0VEAAAAJ",
      "rEL4-fgAAAAJ",
      "Y8O9N_0AAAAJ",
      "mGMy_kwAAAAJ",
      "BYoq_bwAAAAJ",
      "ZLyJRxoAAAAJ",
      "O-DazBUAAAAJ",
      "TIKl_foAAAAJ",
      "lc6CVqEAAAAJ",
      "8cxDHS4AAAAJ",
      "mXtH1UYAAAAJ",
      "ROILf3EAAAAJ",
      "14HASnUAAAAJ",
      "eFVB3ksAAAAJ",
      "4QZgrj0AAAAJ",
      "okKw87MAAAAJ",
      "b8i9J_QAAAAJ",
      "QIRWZf8AAAAJ",
      "rRJ9wTJMUB8C",
      "rDfyQnIAAAAJ",
      "C8bGfr0AAAAJ",
      "mWGyYMsAAAAJ",
      "RlaKKWAAAAAJ",
      "bvDRaVcAAAAJ",
      "2uG5ut4AAAAJ",
      "LI7rp1QAAAAJ",
      "U71Ps4kAAAAJ",
      "E08IHhoAAAAJ",
      "Hi7ZdhQAAAAJ",
      "jrazNCQAAAAJ",
      "KfxoN50AAAAJ",
      "gkG4z3IAAAAJ",
      "QXyvv94AAAAJ",
      "iwN7GtoAAAAJ",
      "BO_b2O8AAAAJ",
      "puDkuLoAAAAJ",
      "2oy3OXYAAAAJ",
      "Z1OtYmAAAAAJ",
      "L-lz7CUAAAAJ",
      "5Ysgg7AAAAAJ",
      "EzCLa-4AAAAJ",
      "l4ffN_QAAAAJ",
      "cKtU3eAAAAAJ",
      "dHjYcrgAAAAJ",
      "bSU7LYoAAAAJ",
      "4VlAkPUAAAAJ",
      "pxFyKAIAAAAJ",
      "LBJv1gsAAAAJ",
      "fqf2tBsAAAAJ",
      "YiUWYl0AAAAJ",
      "0na-wa0AAAAJ",
      "Zqz4CQoAAAAJ",
      "Q4DTPw4AAAAJ",
      "K7Q4GWQAAAAJ",
      "uvrIWrUAAAAJ",
      "1B0l7U8AAAAJ",
      "HQCpSJMAAAAJ",
      "Tlt5xsYAAAAJ",
      "VU4chlsAAAAJ",
      "sioumZAAAAAJ",
      "CypbdCkAAAAJ",
      "9fPuoP4AAAAJ",
      "wZFmjwYAAAAJ",
      "wSstCv0AAAAJ",
      "sYza2XwAAAAJ",
      "U5ZZu3IAAAAJ",
      "33yNvIgAAAAJ",
      "e1ucbCYAAAAJ",
      "MVxcjEoAAAAJ",
      "L4bNmsMAAAAJ",
      "Spe0xdkAAAAJ",
      "EkREu_QAAAAJ",
      "3L333oYAAAAJ",
      "_lnL4aQAAAAJ",
      "joR1Z4UAAAAJ",
      "xUOx0loAAAAJ",
      "WvtCacIAAAAJ",
      "2J051LYAAAAJ",
      "BYXqAlwAAAAJ",
      "hklOXvkAAAAJ",
      "Kt1aSnAAAAAJ",
      "dw5f9yIAAAAJ",
      "rQoKPUsAAAAJ",
      "k2ZQE1IAAAAJ",
      "5mnT2ocAAAAJ",
      "8TkJbjgAAAAJ",
      "HSx0BgQAAAAJ",
      "aO8KpGcAAAAJ",
      "k7NgVSUAAAAJ",
      "8MliTo4AAAAJ"
    ],
    "mnU3HpcAAAAJ": [
      "DZ3S--MAAAAJ",
      "Pczk-PQAAAAJ",
      "_pv1sEcAAAAJ",
      "7k2LuTkAAAAJ",
      "jiyonF0AAAAJ",
      "F3ba0dEAAAAJ",
      "vRkNXhwAAAAJ",
      "f31mvPsAAAAJ",
      "PuTDB5gAAAAJ",
      "6nKHDKYAAAAJ",
      "eWRBqsYAAAAJ",
      "EMq6KwMAAAAJ",
      "4YhNJBEAAAAJ",
      "IS4VSXAAAAAJ",
      "1h_mxPMAAAAJ",
      "-PIq1igAAAAJ",
      "kcTK_FAAAAAJ",
      "Bq1dFNQAAAAJ",
      "u7GirtIAAAAJ",
      "Y_Nmd2sAAAAJ",
      "urLZUHwAAAAJ",
      "aHa6fz4AAAAJ",
      "RvtEObEAAAAJ",
      "2zHG0dwAAAAJ",
      "kiFd6A8AAAAJ",
      "nUZG1SEAAAAJ",
      "B3Xd8-kAAAAJ",
      "yfy_BGIAAAAJ",
      "lWDq-ygAAAAJ",
      "zTy9cUwAAAAJ",
      "jaNr8IoAAAAJ",
      "57BFBY0AAAAJ",
      "JDaHecMAAAAJ",
      "DD1MSdMAAAAJ",
      "_uBxMwkAAAAJ",
      "vJxuKwgAAAAJ",
      "FVKgcAsAAAAJ",
      "NZUdzyIAAAAJ",
      "71rMURwAAAAJ"
    ],
    "oizZKrsAAAAJ": [
      "0v5utcwAAAAJ",
      "J8YyZugAAAAJ",
      "yqt5PeEAAAAJ",
      "66qppJsAAAAJ",
      "Q8WGJtQAAAAJ",
      "9aw_QGAAAAAJ",
      "1c5IZ0QAAAAJ",
      "Rh16nsIAAAAJ",
      "c4XKzcIAAAAJ",
      "bh-uRFMAAAAJ",
      "todsDfQAAAAJ",
      "0zZnyMEAAAAJ",
      "w0OodaEAAAAJ",
      "wc0FCZUAAAAJ",
      "EKNrHzQAAAAJ",
      "ZlNq4_4AAAAJ",
      "NW_lLBUAAAAJ",
      "aN4IwM4AAAAJ",
      "cbQB0MMAAAAJ",
      "NJ9c4ygAAAAJ",
      "wbIMbL8AAAAJ",
      "q0MzO6cAAAAJ",
      "XhyKVFMAAAAJ",
      "9xDADY4AAAAJ",
      "JepH3ckAAAAJ",
      "j7uL6VEAAAAJ",
      "VWX-GMAAAAAJ",
      "rArDMRMAAAAJ",
      "pUB0nnwhGVAC",
      "RaScARwAAAAJ",
      "2R22h84AAAAJ",
      "eMwEEXUAAAAJ",
      "6S-WgLkAAAAJ",
      "i0n7VXwAAAAJ",
      "15g03MoAAAAJ",
      "WH2KmRgAAAAJ",
      "d6vuvHIAAAAJ",
      "vC2vywcAAAAJ",
      "KzSKtNUAAAAJ",
      "gxL7aZQAAAAJ",
      "kzFmAkYAAAAJ",
      "E_ejWvYAAAAJ"
    ],
    "eIWg8NMAAAAJ": [
      "s2Ibok8AAAAJ",
      "st_GV1QAAAAJ",
      "eUtEs6YAAAAJ",
      "28sDUWIAAAAJ",
      "ArKKNxwAAAAJ",
      "cx4AaqoAAAAJ",
      "0wIdMGEAAAAJ",
      "qIvZT74AAAAJ",
      "AZH_wV0AAAAJ",
      "Ex3pgLAAAAAJ",
      "pDvg7X4AAAAJ",
      "49ovzE4AAAAJ",
      "w2Bt-vwAAAAJ",
      "hkCVqYkAAAAJ",
      "_z41TLwAAAAJ",
      "DJRhzzYAAAAJ",
      "ogXIdlYAAAAJ",
      "P9FclNEAAAAJ",
      "hdMznfMAAAAJ",
      "CHAajY4AAAAJ",
      "uggxDWIAAAAJ",
      "-xjeTa8AAAAJ",
      "2R22h84AAAAJ",
      "elmWdycAAAAJ",
      "BDYIAe4AAAAJ",
      "oj0A7FoAAAAJ",
      "ZfUyYtEAAAAJ",
      "qq3TxtcAAAAJ",
      "sQ6l4sMAAAAJ",
      "JQ939pQAAAAJ",
      "PtIe6OkAAAAJ",
      "_tzVqLEAAAAJ",
      "4fN_h5QAAAAJ",
      "XW6MbmAAAAAJ",
      "IWwCuGAAAAAJ",
      "8R35rCwAAAAJ",
      "kg4bCpgAAAAJ",
      "oREmACAAAAAJ",
      "8SZ79v4AAAAJ",
      "kA_rSy4AAAAJ",
      "51ZIHGIAAAAJ",
      "kfYJVXEAAAAJ",
      "eomC7sIAAAAJ",
      "J6iSjTcAAAAJ",
      "O25d8jcAAAAJ",
      "QCH7hIEAAAAJ",
      "Pkj8OSoAAAAJ",
      "GnTX_20AAAAJ",
      "Sh28erYAAAAJ",
      "YYH0BjEAAAAJ",
      "I1D9ig8AAAAJ"
    ],
    "QxLpghAAAAAJ": [
      "Jp6Mz1sAAAAJ",
      "cZzmemAAAAAJ",
      "cxYepGkAAAAJ",
      "8R35rCwAAAAJ",
      "vfPE6hgAAAAJ",
      "fA0rYxMAAAAJ",
      "K-2OXMIAAAAJ",
      "md3U-GEAAAAJ",
      "OFlBL2kAAAAJ",
      "CQEyVPMAAAAJ",
      "o67NTxYAAAAJ",
      "l19pn2sAAAAJ",
      "p-PC50wAAAAJ",
      "G5M9nYwAAAAJ",
      "so6uzIwAAAAJ",
      "sljtWIUAAAAJ",
      "mWGyYMsAAAAJ",
      "bo0P2qYAAAAJ",
      "mXtH1UYAAAAJ",
      "t9eduncAAAAJ",
      "fSXCOfEAAAAJ",
      "-WZcuuwAAAAJ",
      "Nr_yTQgAAAAJ",
      "au4CYXQAAAAJ",
      "n4YG-zkAAAAJ",
      "p6DCMrQAAAAJ",
      "1ctl60EAAAAJ",
      "jPD85m0AAAAJ",
      "Y3eqab0AAAAJ",
      "JbhCpzkAAAAJ",
      "Ivot3fkAAAAJ",
      "jTnQTBoAAAAJ",
      "bQTXRrAAAAAJ",
      "9hX-JksAAAAJ",
      "SNqm6doAAAAJ",
      "todsDfQAAAAJ",
      "aOklxsQAAAAJ",
      "bEcLezcAAAAJ",
      "HEY3UzgAAAAJ",
      "QDmEj4MAAAAJ",
      "HDHOS0QAAAAJ",
      "AZeK-REAAAAJ",
      "TApLOhkAAAAJ",
      "HZPnJ9gAAAAJ",
      "zr9B1YgAAAAJ",
      "ixp-vqMAAAAJ",
      "i02oEgMAAAAJ",
      "W7fLMpsAAAAJ",
      "d97bGd8AAAAJ",
      "y3MnZUEAAAAJ",
      "3oe0I0QAAAAJ",
      "397EbTsAAAAJ",
      "dGs2BcIAAAAJ",
      "iH2BZ8UAAAAJ",
      "7N-ethYAAAAJ",
      "nrcJfPEAAAAJ",
      "5n9CN80AAAAJ",
      "bh-uRFMAAAAJ",
      "xUGZX_MAAAAJ",
      "SLRYlKsAAAAJ",
      "Ml6RzmEAAAAJ",
      "QIZWnnQAAAAJ",
      "TqjSyUgAAAAJ",
      "fpx2AWYAAAAJ",
      "RYLugBwAAAAJ",
      "h_q7XhoAAAAJ",
      "Hxic_iwAAAAJ",
      "7oxkHYYAAAAJ",
      "H8FJlJoAAAAJ",
      "MRYnqOEAAAAJ",
      "V-HiOnUAAAAJ",
      "Zcv_mIoAAAAJ",
      "YgFOewgAAAAJ",
      "x0NU7KEAAAAJ",
      "FehGbqYAAAAJ",
      "gV_XNa0AAAAJ",
      "DZ-WjTIAAAAJ",
      "9B8PoXUAAAAJ",
      "-pgIngUAAAAJ",
      "vjZrDKQAAAAJ",
      "b4qKr7gAAAAJ",
      "X3cGY7wAAAAJ",
      "XsYoY2QAAAAJ",
      "XAhGkq8AAAAJ",
      "BIwrJuQAAAAJ",
      "NGqfK2wAAAAJ",
      "ZDPCh_EAAAAJ",
      "_0_p13YAAAAJ",
      "F_RBceUAAAAJ",
      "1wLVDP4AAAAJ",
      "pe1ArKwAAAAJ",
      "vKflaosAAAAJ",
      "M2diIJYAAAAJ",
      "dlm2DaAAAAAJ",
      "fMgMCaoAAAAJ",
      "M3WZP7YAAAAJ",
      "JC0I3vgAAAAJ",
      "J5hwfPwAAAAJ",
      "KzxURf4AAAAJ",
      "yPgtxnkAAAAJ",
      "_P954XkAAAAJ",
      "nXaOKoYAAAAJ",
      "hscMk9AAAAAJ",
      "IeuLakwAAAAJ",
      "qPlUgrgAAAAJ",
      "B0MzhZwAAAAJ",
      "5031vK4AAAAJ",
      "5vSCuk0AAAAJ",
      "CRNmfCAAAAAJ",
      "JnTrJCQAAAAJ",
      "I6x_9IoAAAAJ",
      "dNOBQ1sAAAAJ",
      "uvyYzagAAAAJ",
      "D6P3KdMAAAAJ",
      "DCSFMuAAAAAJ",
      "9c4G6GkAAAAJ",
      "FUOEBDUAAAAJ",
      "W8f0d6oAAAAJ",
      "LFiqVpwAAAAJ",
      "BFzFy1YAAAAJ",
      "CotFJJsAAAAJ",
      "u8f4WQ0AAAAJ",
      "GPJ2qqgAAAAJ",
      "P0CpOFwAAAAJ",
      "Ja-8AFsAAAAJ",
      "7mrPM4kAAAAJ",
      "VIZvaGsAAAAJ",
      "ZvLa1RIAAAAJ",
      "x6zfRbcAAAAJ",
      "kSnFGqkAAAAJ",
      "hm9dWCsAAAAJ"
    ],
    "0Qr2IGwAAAAJ": [
      "eZr-ai0AAAAJ",
      "UKqIqRsAAAAJ",
      "1WSaBBsAAAAJ",
      "tlh8i7gAAAAJ",
      "DRt16WsAAAAJ",
      "H_1utcUAAAAJ",
      "a3K-f2YAAAAJ",
      "i28fU0MAAAAJ",
      "HaN8b2YAAAAJ",
      "ZcWO2AEAAAAJ",
      "8R35rCwAAAAJ",
      "78OLNd4AAAAJ",
      "vZkXCcsAAAAJ",
      "orqXipgAAAAJ",
      "fZinJ_AAAAAJ",
      "Vzr1RukAAAAJ",
      "QCBdB7AAAAAJ",
      "8E442bkAAAAJ",
      "IWDmHggAAAAJ",
      "-6cOYcYAAAAJ",
      "Db4BCX8AAAAJ",
      "MU5tFcQAAAAJ",
      "YPzKczYAAAAJ",
      "vswo4rQAAAAJ",
      "BaY_Ie8AAAAJ",
      "uJHvcMMAAAAJ",
      "9ZGqm5QAAAAJ",
      "oQ6AeyEAAAAJ"
    ],
    "7HPdnqEAAAAJ": [
      "MzD8rjoAAAAJ",
      "8ablIzIAAAAJ",
      "GAdPpe0AAAAJ",
      "zqRN1ZEAAAAJ",
      "fMAg4zEAAAAJ",
      "sCEl8r-n5VEC",
      "DcV-5RAAAAAJ",
      "aSAS-aAAAAAJ",
      "aO8KpGcAAAAJ",
      "qArWV_wAAAAJ"
    ],
    "lH1PdF8AAAAJ": [
      "LiwtZz4AAAAJ",
      "28p_eLYAAAAJ",
      "w_XDRRsAAAAJ",
      "XqLiBQMAAAAJ",
      "CZiW6c8AAAAJ",
      "9Pl5k60AAAAJ",
      "j29kMCwAAAAJ",
      "KgZxzjsAAAAJ",
      "DQOT0OMAAAAJ",
      "sQ6l4sMAAAAJ",
      "bRT7t28AAAAJ",
      "K9_XuM8AAAAJ",
      "c_z5hWEAAAAJ",
      "ReEG0FwAAAAJ",
      "KFeN73wAAAAJ",
      "IMAwpekAAAAJ",
      "gYk4eAgAAAAJ",
      "r2tKnV4AAAAJ",
      "9oz-dvgAAAAJ",
      "uT8fgagAAAAJ",
      "cXQciMEAAAAJ",
      "OCdJxC8AAAAJ",
      "ojKsx6AAAAAJ",
      "Z2Mhh2UAAAAJ",
      "YNi1eSQAAAAJ",
      "JId76kkAAAAJ",
      "3P1gs1sAAAAJ",
      "Y-I1X9QAAAAJ",
      "l78nduAAAAAJ",
      "d3UtiX8AAAAJ",
      "uRrSKVIAAAAJ",
      "2Q6fIuAAAAAJ",
      "yLQF4mkAAAAJ",
      "xGI18C0AAAAJ",
      "6FV7CNAAAAAJ",
      "l7Qx0zAAAAAJ",
      "7k_1QFIAAAAJ",
      "dvQXYW0AAAAJ",
      "3_WYcR4AAAAJ",
      "v6o-fksAAAAJ",
      "xfgXYZ0AAAAJ",
      "E2Ur1NwAAAAJ",
      "gopF7iMAAAAJ",
      "p9-ohHsAAAAJ",
      "n9fRgvkAAAAJ",
      "v3w4IYUAAAAJ",
      "VJPRn1oAAAAJ",
      "BNEeEosAAAAJ",
      "6V1dbO0AAAAJ",
      "5NUgdPcAAAAJ",
      "SM-2GN4AAAAJ",
      "dRShpScAAAAJ",
      "mukR7ccAAAAJ",
      "B847xq8AAAAJ",
      "iCiUflEAAAAJ",
      "8qsuHEoAAAAJ",
      "X2Qs7XYAAAAJ",
      "BAtMB04AAAAJ",
      "qosS83IAAAAJ",
      "wcr5g6oAAAAJ",
      "9IpdcgMAAAAJ",
      "MR3fFXoAAAAJ",
      "-Ve9sJ0AAAAJ",
      "DYUloYkAAAAJ",
      "fNOReswAAAAJ",
      "7KgIMosAAAAJ",
      "l-mlF7YAAAAJ",
      "bEctTN0AAAAJ",
      "wGNIr6oAAAAJ",
      "8bwdGesAAAAJ",
      "8JGG3KcAAAAJ",
      "tbAlI9kAAAAJ",
      "WH2KmRgAAAAJ",
      "U3KDpBUAAAAJ",
      "WLN3QrAAAAAJ",
      "YAHWbtkAAAAJ",
      "KNcECJQAAAAJ",
      "LPAZlL8AAAAJ",
      "sdNtK6QAAAAJ",
      "9cBUERoAAAAJ",
      "nVsOPtQAAAAJ",
      "A6yjdJAAAAAJ",
      "XlqTD2UAAAAJ",
      "Ih29F_QAAAAJ",
      "UO7McmEAAAAJ",
      "h6eAkFwAAAAJ",
      "Nv6G5DwAAAAJ",
      "CG9yOXoAAAAJ",
      "Sb4o_0IAAAAJ",
      "VWCMVn4AAAAJ",
      "Tb0ZrYwAAAAJ",
      "yVnCUg0AAAAJ",
      "-1nmmKgAAAAJ",
      "6yls9oMAAAAJ",
      "KZpZTTQAAAAJ",
      "0FSlSt4AAAAJ",
      "KL6_oegAAAAJ",
      "ZO3Ek1gAAAAJ",
      "F4FxpRoAAAAJ",
      "E8_P8_wAAAAJ",
      "fvr-J3sAAAAJ",
      "ni3EbYgAAAAJ",
      "IolN_okAAAAJ",
      "1ed1sPkAAAAJ",
      "UDRtJsEAAAAJ",
      "_PhjyLoAAAAJ",
      "Yk6keUoAAAAJ",
      "o500TjwAAAAJ",
      "uK53FGQAAAAJ",
      "eAHAxi0AAAAJ",
      "tjI54N0AAAAJ",
      "xViwZ0QAAAAJ",
      "SC9wV2kAAAAJ",
      "pbmjtZsAAAAJ",
      "9aQUYVQAAAAJ",
      "L4bNmsMAAAAJ",
      "1ytghtEAAAAJ",
      "akuWIJQAAAAJ",
      "bkALdvsAAAAJ",
      "V_VpLksAAAAJ",
      "htt9T1AAAAAJ",
      "hbNllP0AAAAJ",
      "FwNaHxQAAAAJ",
      "hV5D8GYAAAAJ",
      "c-cuO9cAAAAJ",
      "Zo_TuDUAAAAJ",
      "IvqCXP4AAAAJ",
      "ofoABP8AAAAJ",
      "d0KQ9z0AAAAJ",
      "aMkW638AAAAJ",
      "9pSK04MAAAAJ",
      "uGdPyZQAAAAJ",
      "oUK2gu8AAAAJ",
      "soanB6MAAAAJ",
      "MnOal0UAAAAJ",
      "LYt_4uIAAAAJ",
      "EcgjIi4AAAAJ",
      "-kX87sgAAAAJ",
      "044QzjcAAAAJ",
      "P8NRbbYAAAAJ",
      "zzG75zEAAAAJ",
      "KmSuVtgAAAAJ",
      "wADiNucAAAAJ",
      "10RVXDQAAAAJ",
      "P2oSOR0AAAAJ",
      "0W9XZ0cAAAAJ",
      "yREBSy0AAAAJ",
      "dwi5wvYAAAAJ",
      "55swP8AAAAAJ",
      "0lO_16kAAAAJ",
      "MIEaoNEAAAAJ",
      "qkIp7AEAAAAJ",
      "N4sca6EAAAAJ",
      "SazwWasAAAAJ",
      "JR7F__MAAAAJ",
      "R0bnqaAAAAAJ",
      "Zd2MrfUAAAAJ",
      "J8YyZugAAAAJ",
      "9j-6i_oAAAAJ",
      "YHxZLlwAAAAJ",
      "XYy_Nm4AAAAJ",
      "T8LkBTYAAAAJ",
      "ErvkcKcAAAAJ",
      "d3JgIc8AAAAJ",
      "eBooFDEAAAAJ",
      "GSHmKZkAAAAJ",
      "zh0Raz8AAAAJ",
      "Ggudr9EAAAAJ",
      "qB0jk_EAAAAJ",
      "Y-KJRwoAAAAJ",
      "w0Vl_lsAAAAJ",
      "TW7U1W0AAAAJ",
      "0T7HVEIAAAAJ",
      "wmx7KVUAAAAJ",
      "6OZMoP0AAAAJ",
      "Br80hVMAAAAJ",
      "Fhs-sfkAAAAJ",
      "FJ-huxgAAAAJ",
      "gX7rSCcAAAAJ",
      "xL45YGMAAAAJ",
      "8mA9QpUAAAAJ",
      "F_KIfrsAAAAJ"
    ],
    "hdTDzlQAAAAJ": [
      "nTiSnwUAAAAJ",
      "aO8KpGcAAAAJ",
      "13Tv6dkAAAAJ",
      "OP6ejqgAAAAJ",
      "hiGI9v0AAAAJ",
      "D8dLtRMAAAAJ",
      "HQRnt54AAAAJ",
      "U_L2uiwAAAAJ",
      "1mDpUSgAAAAJ",
      "uqesapEAAAAJ",
      "DcV-5RAAAAAJ",
      "ZvX1hXcAAAAJ",
      "X3gGi_0AAAAJ",
      "qRd8Hh4AAAAJ",
      "E__5Lr0AAAAJ",
      "-j0q9B4AAAAJ",
      "C6pnolkAAAAJ",
      "M-y2aLUAAAAJ",
      "OTFnifoAAAAJ",
      "jhyC8TsAAAAJ",
      "ULgz3noAAAAJ",
      "ZNquLr8AAAAJ",
      "70vJVxcAAAAJ",
      "O24CcQQAAAAJ",
      "uy43gzcAAAAJ",
      "BgOXDogAAAAJ",
      "llcGIZ8AAAAJ",
      "OGweeKgAAAAJ",
      "dYt8FGcAAAAJ",
      "gjLr_FgAAAAJ",
      "RU0ZAp4AAAAJ",
      "FXiSi-4AAAAJ",
      "Ylp9SPUAAAAJ",
      "6S09ezcAAAAJ",
      "VLb_0NYAAAAJ",
      "fnDzqzIAAAAJ",
      "iyDxq0EAAAAJ",
      "Du5t4FYAAAAJ"
    ],
    "LIJQ_ZYAAAAJ": [
      "8R35rCwAAAAJ",
      "yy0UFOwAAAAJ",
      "ZaJEZpYAAAAJ",
      "vfPE6hgAAAAJ",
      "NSWI3OwAAAAJ",
      "pqP5_PgAAAAJ",
      "iyEuK8kAAAAJ",
      "-w5DuHgAAAAJ",
      "U_Jw8DUAAAAJ",
      "OI7zFmwAAAAJ",
      "ADkiClQAAAAJ",
      "0nPi5YYAAAAJ",
      "C_AP8XAAAAAJ",
      "q7nFtUcAAAAJ",
      "bDq7MZMAAAAJ",
      "K29Sv1EAAAAJ",
      "0tLCTHYAAAAJ",
      "21W5L1YAAAAJ",
      "1bF2s2kAAAAJ",
      "2DBmo-wAAAAJ",
      "RM2vMNcAAAAJ",
      "rE7-N30AAAAJ",
      "Z3dxz9IAAAAJ",
      "mIlaYj0AAAAJ",
      "hYVMrzsAAAAJ",
      "d5y4iKAAAAAJ",
      "uemlfQYAAAAJ",
      "SzHPa90AAAAJ",
      "NLOh3SUAAAAJ",
      "neGbgzYAAAAJ",
      "cXT3p6cAAAAJ",
      "YfPA4YsAAAAJ",
      "Vzr1RukAAAAJ",
      "YH1v2uYAAAAJ",
      "79k7bGEAAAAJ",
      "jrfFYAIAAAAJ",
      "-S_9ZRcAAAAJ",
      "wotfaAgAAAAJ",
      "KsocBp8AAAAJ",
      "UJcm1MoAAAAJ",
      "1P8Zu04AAAAJ",
      "Izhkp4YAAAAJ",
      "2efgcS0AAAAJ",
      "DRnOvU8AAAAJ",
      "8C2_ZVsAAAAJ",
      "5VaXUQsAAAAJ",
      "SnTMyGUAAAAJ",
      "snHVatUAAAAJ",
      "gVFnjOcAAAAJ",
      "CjOTm_4AAAAJ",
      "l-la0GQAAAAJ",
      "KcPrLhIAAAAJ",
      "iyDxq0EAAAAJ",
      "aO8KpGcAAAAJ",
      "IB_jPZ0AAAAJ",
      "-5_ksIkAAAAJ",
      "3mOq4dcAAAAJ",
      "fA0rYxMAAAAJ",
      "ibu3FwsAAAAJ",
      "wr9RgmcAAAAJ",
      "T6PbwPIAAAAJ",
      "vcw0TJIAAAAJ",
      "l2FS2_IAAAAJ",
      "GNzbVIsAAAAJ",
      "TP0epB8AAAAJ",
      "ncJWfs0AAAAJ",
      "PJSVA_QAAAAJ"
    ],
    "IcaU830AAAAJ": [
      "vN-is70AAAAJ",
      "zP0S_ikAAAAJ",
      "FFWXLHUAAAAJ",
      "8fztli4AAAAJ",
      "yxUduqMAAAAJ",
      "7P-gZioAAAAJ",
      "zp8V7ZMAAAAJ",
      "Yxh9WWoAAAAJ"
    ],
    "6Q-289IAAAAJ": [
      "bh-uRFMAAAAJ",
      "5JserkUAAAAJ",
      "Wk2gAZUAAAAJ",
      "xt3XLjcAAAAJ",
      "XOfA8ckAAAAJ",
      "Y8O9N_0AAAAJ",
      "9xDADY4AAAAJ"
    ],
    "56EZh6YAAAAJ": [
      "u7Kad50AAAAJ",
      "dpLLZIAAAAAJ",
      "DplAah0AAAAJ",
      "bh-uRFMAAAAJ",
      "lc0ARagAAAAJ",
      "oQsObk0AAAAJ",
      "gPKDZtwAAAAJ",
      "BEHcR-IAAAAJ",
      "j29kMCwAAAAJ",
      "PxYY_nsAAAAJ",
      "PA9La6oAAAAJ",
      "H6ArRNYAAAAJ",
      "KJNUEgkAAAAJ",
      "M1IgIyMAAAAJ",
      "2aEdHz0AAAAJ",
      "8hpOmVgAAAAJ",
      "y1lVpBEAAAAJ",
      "oyWpVa8AAAAJ",
      "vPoTuLQAAAAJ",
      "2ItLnFgAAAAJ",
      "9xDADY4AAAAJ",
      "gYiCq88AAAAJ",
      "UfbuDH8AAAAJ",
      "NcIqQ88AAAAJ",
      "RoGOW9AAAAAJ",
      "WH2KmRgAAAAJ",
      "Mtho-7EAAAAJ",
      "JnUevM0AAAAJ",
      "8hU3dn8AAAAJ",
      "1_BWn8IAAAAJ",
      "UV9LxSEAAAAJ"
    ],
    "s_3ZE8kAAAAJ": [
      "Vb3FLmkAAAAJ",
      "DulpV-cAAAAJ",
      "MK6zHkYAAAAJ",
      "umFQktIAAAAJ",
      "4zybTq4AAAAJ",
      "_rUcw0EAAAAJ",
      "_pPy-pAAAAAJ",
      "gjLr_FgAAAAJ",
      "LKv32bgAAAAJ",
      "YR_MYrAAAAAJ",
      "loxOHhoAAAAJ",
      "lVoOIv4AAAAJ"
    ],
    "7P-gZioAAAAJ": [
      "l6oz33MAAAAJ",
      "RPWFQlAAAAAJ",
      "vN-is70AAAAJ",
      "B96GkdgAAAAJ",
      "IcaU830AAAAJ",
      "PkfChMgAAAAJ",
      "zP0S_ikAAAAJ",
      "FFWXLHUAAAAJ",
      "7w24ptsAAAAJ",
      "yxUduqMAAAAJ",
      "tfKeplgAAAAJ",
      "Ooc7UNUAAAAJ",
      "EhCg54EAAAAJ",
      "94RFSSsAAAAJ",
      "uFJi3IUAAAAJ",
      "F9kqUXkAAAAJ",
      "a4HRDBEAAAAJ",
      "KfGfDvcAAAAJ",
      "MFZC4EgAAAAJ",
      "INd48rQAAAAJ",
      "aApop70AAAAJ",
      "wb9DYOEAAAAJ",
      "WYctQAQAAAAJ",
      "hcVpBCIAAAAJ",
      "5pKTRxEAAAAJ",
      "7XyGUGkAAAAJ",
      "78KBaPsAAAAJ",
      "1LbWyf4AAAAJ"
    ],
    "6QWsktwAAAAJ": [],
    "wKJeOQoAAAAJ": [
      "r1TJBr8AAAAJ",
      "8l-mDfQAAAAJ",
      "70lgwYwAAAAJ",
      "ktwwLjsAAAAJ",
      "gZgQLkgAAAAJ",
      "K6ef57QAAAAJ",
      "rIAYxaMAAAAJ",
      "yxUduqMAAAAJ",
      "KKQCt30AAAAJ",
      "t9PEVrkAAAAJ",
      "eyCw9goAAAAJ",
      "UA9Hb2EAAAAJ",
      "8NudxYsAAAAJ",
      "08CNqrYAAAAJ",
      "zbcN_QIAAAAJ",
      "aIRUO8AAAAAJ",
      "ldJpvE8AAAAJ",
      "QE9pa_cAAAAJ",
      "Qhe5ua0AAAAJ",
      "bZ9oyW8AAAAJ",
      "FXacC3oAAAAJ",
      "w3DSGTIAAAAJ",
      "8hpOmVgAAAAJ",
      "P2CPNr8AAAAJ",
      "C5IpcRYAAAAJ",
      "6IFj7SkAAAAJ",
      "CPuApzoAAAAJ",
      "RIBv3lgAAAAJ",
      "2z2camUAAAAJ",
      "ajJxXnEAAAAJ",
      "j8svx3IAAAAJ",
      "n8ysVHUAAAAJ",
      "ge-OinUAAAAJ",
      "ct4ViZMAAAAJ",
      "gOkjmJcAAAAJ",
      "IRyM3b8AAAAJ",
      "4HHWesEAAAAJ",
      "WDB4HqIAAAAJ",
      "l7GidmgAAAAJ",
      "YGnty0AAAAAJ",
      "6EgqGRwAAAAJ",
      "j7Z1Zm8AAAAJ",
      "chICXXMAAAAJ",
      "XqLiBQMAAAAJ",
      "Bj1tRlsAAAAJ",
      "wQanfTIAAAAJ",
      "wpdabDgAAAAJ",
      "tQuQ1FwAAAAJ",
      "DZ-fHPgAAAAJ",
      "Hanjxs8AAAAJ",
      "DnRJBwUAAAAJ",
      "opbZfw0AAAAJ",
      "eIdQR5oAAAAJ",
      "BB833ugAAAAJ",
      "d5wGxRsAAAAJ",
      "rxxutcgAAAAJ",
      "npq3yLIAAAAJ",
      "T_mPgZIAAAAJ",
      "JZqo39cAAAAJ",
      "iyDxq0EAAAAJ",
      "aO8KpGcAAAAJ",
      "S1a25sEAAAAJ",
      "P2NN0PAAAAAJ",
      "ZurKqVkAAAAJ",
      "dJg1TUEAAAAJ",
      "Uo0aIHAAAAAJ",
      "S_6zsEwAAAAJ",
      "SY6gzIgAAAAJ",
      "HCH-T5UAAAAJ",
      "N1q-egYAAAAJ",
      "U9EvD0wAAAAJ",
      "xVFrEDwAAAAJ",
      "pVnRW0YAAAAJ",
      "U7yzfCkAAAAJ",
      "pwUdiCYAAAAJ",
      "7o1I4IkAAAAJ",
      "QI-eVvkAAAAJ",
      "I9r2zF0AAAAJ",
      "JjASH4UAAAAJ",
      "yvdSr4AAAAAJ",
      "4gE_vYgAAAAJ",
      "yqIoH34AAAAJ",
      "7b_ipvgAAAAJ",
      "mKia7Y4AAAAJ",
      "nCFeUqYAAAAJ"
    ],
    "uemlfQYAAAAJ": [
      "OI7zFmwAAAAJ",
      "yy0UFOwAAAAJ",
      "wotfaAgAAAAJ",
      "pqP5_PgAAAAJ",
      "vfPE6hgAAAAJ",
      "NSWI3OwAAAAJ",
      "LIJQ_ZYAAAAJ",
      "NLOh3SUAAAAJ",
      "SzHPa90AAAAJ",
      "iyEuK8kAAAAJ",
      "-w5DuHgAAAAJ",
      "C_AP8XAAAAAJ",
      "vcw0TJIAAAAJ",
      "jTnQTBoAAAAJ",
      "bDq7MZMAAAAJ",
      "l-la0GQAAAAJ",
      "_WLInT0AAAAJ",
      "rEL4-fgAAAAJ",
      "mIlaYj0AAAAJ",
      "21W5L1YAAAAJ",
      "1bF2s2kAAAAJ",
      "YH1v2uYAAAAJ",
      "1P8Zu04AAAAJ",
      "fQVZ28cAAAAJ",
      "rE7-N30AAAAJ",
      "Cybj4ysAAAAJ",
      "jrfFYAIAAAAJ",
      "5VaXUQsAAAAJ",
      "8R35rCwAAAAJ",
      "3oe0I0QAAAAJ",
      "ADkiClQAAAAJ",
      "C-ZlBWMAAAAJ",
      "sUb_eyUAAAAJ",
      "zBUwaGkAAAAJ",
      "PRl_gWUAAAAJ",
      "Q5CBlNcAAAAJ",
      "EPfOJwQAAAAJ",
      "GuU6oA4AAAAJ",
      "0nPi5YYAAAAJ",
      "YfPA4YsAAAAJ",
      "fMN7wNwAAAAJ",
      "fz7LJPIAAAAJ",
      "4gVbilMMp-AC",
      "RNdGVHoAAAAJ",
      "Cmf2HdcAAAAJ",
      "LIG-4BcAAAAJ",
      "_AoZDGEAAAAJ",
      "U8QXoYkAAAAJ",
      "DSKzTCAAAAAJ",
      "p28z3SQAAAAJ",
      "ExGkzjQAAAAJ",
      "l2FS2_IAAAAJ"
    ],
    "_7Q8uIYAAAAJ": [
      "xMhGYpgAAAAJ",
      "vN-is70AAAAJ",
      "B96GkdgAAAAJ",
      "8zyiGRoAAAAJ",
      "H1d4BS8AAAAJ",
      "7nlvOMQAAAAJ",
      "KzESVKwAAAAJ",
      "DpLFv4gAAAAJ",
      "H4Rq5LwAAAAJ",
      "jWRhmqoAAAAJ",
      "NvBZp6MAAAAJ",
      "E3yOuvEAAAAJ",
      "Vn3L_ioAAAAJ",
      "di5RZ1MAAAAJ",
      "Qzss0GEAAAAJ",
      "-84M1m0AAAAJ"
    ],
    "i5srt20AAAAJ": [
      "yxUduqMAAAAJ",
      "dyXX1EgAAAAJ",
      "kTKmpT0AAAAJ",
      "9nnDvooAAAAJ",
      "XbjOzyQAAAAJ",
      "ZCa4VDcAAAAJ",
      "QGcz9-kAAAAJ",
      "SWqd2rgAAAAJ",
      "pouyVyUAAAAJ",
      "FiBMfBsAAAAJ",
      "LnhCGNMAAAAJ",
      "Ch9iRwQAAAAJ",
      "uYVc9koAAAAJ",
      "bc0aQ7YAAAAJ",
      "kUcBGSgAAAAJ",
      "jr7gGB4AAAAJ",
      "EBNa5IEAAAAJ",
      "Olj9jQgAAAAJ",
      "yQNhFGUAAAAJ",
      "Py_StfUAAAAJ",
      "nxNkEiYAAAAJ",
      "BfDKicQAAAAJ",
      "-mrh5AIAAAAJ",
      "xBRQVAcAAAAJ",
      "vq4lx5YAAAAJ",
      "uy43gzcAAAAJ",
      "EMrV8BIAAAAJ",
      "5ygiTwsAAAAJ",
      "5Iqe53IAAAAJ",
      "WoSEVJUAAAAJ",
      "TW7U1W0AAAAJ",
      "p0sQC6sAAAAJ",
      "biuxbRsAAAAJ",
      "RqwU8xsAAAAJ",
      "ImpbxLsAAAAJ",
      "v5TPCXFtkUgC",
      "SWMKy70AAAAJ",
      "erv7TP0AAAAJ",
      "ttbl4FsAAAAJ",
      "BnQdO2UAAAAJ",
      "wQSRT18AAAAJ",
      "DnnCWN0AAAAJ",
      "jTLiOiMAAAAJ",
      "iKPWydkAAAAJ",
      "k5HsbdcAAAAJ",
      "HOzdZp0AAAAJ",
      "YvdzeM8AAAAJ",
      "ea6cjVUAAAAJ",
      "oavgGaMAAAAJ",
      "wVGqmWkAAAAJ",
      "LKv32bgAAAAJ",
      "LMtE3FQAAAAJ",
      "c4Gcje4AAAAJ",
      "Ukl64ggAAAAJ",
      "UoATnWEAAAAJ",
      "Om4Lag0AAAAJ",
      "YkeS_SoAAAAJ"
    ],
    "2oy3OXYAAAAJ": [],
    "pfGI-KcAAAAJ": [
      "C0kDOzcAAAAJ",
      "t1UaPDgAAAAJ",
      "K-6ujU4AAAAJ",
      "N5HDmqoAAAAJ",
      "DmIG_WoAAAAJ",
      "43nqWTUAAAAJ",
      "EilVnKwAAAAJ",
      "DfXsKZ4AAAAJ",
      "G43gXjIAAAAJ",
      "t0gYEjAAAAAJ",
      "SvKKBy4AAAAJ",
      "-SfNafoAAAAJ",
      "ICNU7sAAAAAJ",
      "pLwOQV4AAAAJ",
      "9xDADY4AAAAJ",
      "0IBt8msAAAAJ",
      "K-BdgNwAAAAJ",
      "vYUDlsEAAAAJ",
      "7xEd0ZIAAAAJ",
      "tPdzoqYAAAAJ",
      "GQWTo4MAAAAJ",
      "ROU76KkAAAAJ",
      "I6sTssIAAAAJ",
      "bh-uRFMAAAAJ",
      "23rIjfwAAAAJ",
      "k4k05hcAAAAJ",
      "Mb40Pw0AAAAJ",
      "YGxUJXkAAAAJ",
      "oK5EzZsAAAAJ",
      "ZZGpQG4AAAAJ",
      "aM3i_9oAAAAJ",
      "gX7rSCcAAAAJ",
      "8JGG3KcAAAAJ",
      "Vu-Zb7EAAAAJ",
      "yMszfuMAAAAJ",
      "ZTe13LgAAAAJ",
      "5pKdNQkAAAAJ",
      "BffFdd0AAAAJ",
      "ILVcer0AAAAJ",
      "CKXeqHoAAAAJ",
      "e-c3R8QAAAAJ",
      "-CbjdL8AAAAJ",
      "tYazD-8AAAAJ",
      "GwGsvm0AAAAJ",
      "0Gqc1vIAAAAJ",
      "P6MosQgAAAAJ",
      "qbjHRA8AAAAJ",
      "U9nP_RcAAAAJ",
      "L9QufAsAAAAJ",
      "NfyVi8AAAAAJ",
      "AQcftaEAAAAJ",
      "ITZ1e7MAAAAJ",
      "jG0AYyEAAAAJ",
      "rRJ9wTJMUB8C",
      "Pd8-ju0AAAAJ",
      "hR249csAAAAJ",
      "ekic9BkAAAAJ",
      "pRBbU7wAAAAJ",
      "WgAGy7wAAAAJ",
      "S1F-gScAAAAJ",
      "U5xRA6QAAAAJ",
      "BzJ_GboAAAAJ",
      "yyG8xWcAAAAJ",
      "xPhnaK0AAAAJ",
      "ct3WjtoAAAAJ",
      "dXBtN0cAAAAJ"
    ],
    "_EJrRVAAAAAJ": [
      "vtwH6GkAAAAJ",
      "8R35rCwAAAAJ",
      "vfPE6hgAAAAJ",
      "Vzr1RukAAAAJ",
      "QCBdB7AAAAAJ",
      "wb-DKCIAAAAJ",
      "1wLVDP4AAAAJ",
      "ejsX7D0AAAAJ",
      "itSa94cAAAAJ",
      "nGUcGrYAAAAJ"
    ],
    "12uhMdIAAAAJ": [
      "6ma-nCYAAAAJ",
      "bh-uRFMAAAAJ",
      "tsdD0N4AAAAJ",
      "FJ-huxgAAAAJ",
      "S-J_ItYAAAAJ",
      "KdA9qBkAAAAJ"
    ],
    "_PZKLYUAAAAJ": [
      "0lZoXCUAAAAJ",
      "YAHWbtkAAAAJ",
      "8eB7Q1kAAAAJ",
      "VDyjbagAAAAJ",
      "TZWVRR8AAAAJ",
      "btkSHDwAAAAJ",
      "F_ASWCUAAAAJ",
      "PS-TM94AAAAJ",
      "r3q68rcAAAAJ",
      "5m5ds6UAAAAJ",
      "rXYLXJMAAAAJ",
      "S39CcbQAAAAJ",
      "BgOXDogAAAAJ",
      "kmeUhO8AAAAJ",
      "_1hCq3UAAAAJ",
      "MhQPCk8AAAAJ",
      "pWRtbiMAAAAJ",
      "JnWSU4oAAAAJ",
      "qzIHHMEAAAAJ",
      "opbZfw0AAAAJ",
      "l9Or8EMAAAAJ",
      "GcuxcLYAAAAJ",
      "5t2myD8AAAAJ",
      "eQ9_vDAAAAAJ",
      "SQ1eGN4AAAAJ",
      "BBKfx4oAAAAJ",
      "16posrQAAAAJ",
      "GExyiRkAAAAJ",
      "rmxKTn4AAAAJ",
      "QkWtGNkAAAAJ",
      "Sz01Ye0AAAAJ",
      "SupjsEUAAAAJ",
      "nf_EnbAAAAAJ",
      "8ZpV-lkAAAAJ",
      "4_i_4TkAAAAJ",
      "tMBYEWAAAAAJ"
    ],
    "B_FTboQAAAAJ": [
      "LW8ze_UAAAAJ",
      "0B8uuBkAAAAJ",
      "NINFXC0AAAAJ",
      "d97bGd8AAAAJ",
      "4H4bRkcAAAAJ",
      "5hJNWakAAAAJ",
      "UdpacsMAAAAJ",
      "ROILf3EAAAAJ",
      "R0bnqaAAAAAJ",
      "jN2Y51YAAAAJ",
      "a959F6AAAAAJ",
      "j7uL6VEAAAAJ",
      "JlX2UTEAAAAJ",
      "haahCZ4AAAAJ",
      "rs0a3IQAAAAJ",
      "_dVzmiYAAAAJ",
      "bh-uRFMAAAAJ",
      "3RuMCpcAAAAJ",
      "Bt4uDWMAAAAJ",
      "LDur_VYAAAAJ",
      "d6vuvHIAAAAJ",
      "4g-njrYAAAAJ",
      "_SVdR44AAAAJ",
      "gp6HUP0AAAAJ",
      "9_H57VkAAAAJ",
      "InutcIUAAAAJ",
      "NCtKHnQAAAAJ",
      "NLxrmYQAAAAJ",
      "YZcVsRMAAAAJ",
      "JY-WzksAAAAJ",
      "P97vI1EAAAAJ",
      "MqWYTj0AAAAJ",
      "PUSWc4EAAAAJ",
      "ZcWO2AEAAAAJ",
      "Rh16nsIAAAAJ",
      "DQOT0OMAAAAJ",
      "tiu7twQAAAAJ",
      "HWFvq_wAAAAJ",
      "dzOd2hgAAAAJ",
      "BxbKTYkAAAAJ",
      "pp848fYAAAAJ",
      "lwlYARMAAAAJ",
      "5S1kGcAAAAAJ",
      "E_ejWvYAAAAJ",
      "rQ2WAxoAAAAJ",
      "pvyI8GkAAAAJ",
      "a7VNhCIAAAAJ",
      "OXFjRnEAAAAJ",
      "0TGDhHsAAAAJ",
      "gKJ3MfIAAAAJ",
      "AEsPCAUAAAAJ",
      "-6cOYcYAAAAJ",
      "jkm1ipUAAAAJ",
      "ADMVEmsAAAAJ",
      "0z0fNxUAAAAJ",
      "tjjniXEAAAAJ",
      "vmAe35UAAAAJ",
      "kMFnJxgAAAAJ",
      "p9-ohHsAAAAJ",
      "NFeigSoAAAAJ",
      "jpIFgToAAAAJ",
      "mFC0wp8AAAAJ",
      "8GxAlSUAAAAJ",
      "X0EXfT8AAAAJ",
      "VgYU_m8AAAAJ",
      "BW2Xix4AAAAJ",
      "9RnyW0cAAAAJ",
      "ZvIdLmYAAAAJ",
      "miE8bYkAAAAJ",
      "0VQ1sjcAAAAJ",
      "LDb4tb0AAAAJ",
      "yGPH-nAAAAAJ",
      "XPAkzTEAAAAJ",
      "ntGll74AAAAJ",
      "PeMuphgAAAAJ",
      "0eQjcEEAAAAJ",
      "yO82m38AAAAJ",
      "xEFh0AgAAAAJ",
      "YLOz1kgAAAAJ",
      "_zLn05oAAAAJ",
      "6ZDIdEAAAAAJ",
      "MliblMQAAAAJ",
      "gsv5xicAAAAJ",
      "N_maL_AAAAAJ",
      "GBU568oAAAAJ",
      "TmAQaboAAAAJ",
      "VWX-GMAAAAAJ",
      "hpItE1QAAAAJ",
      "LGo5J4IAAAAJ",
      "Voph3LUAAAAJ",
      "RIeAomMAAAAJ",
      "gnR4zf8AAAAJ",
      "q0AgQ2MAAAAJ",
      "bel5BBcAAAAJ",
      "ft85d8kAAAAJ",
      "0fqAIGAAAAAJ",
      "pxFyKAIAAAAJ",
      "R2lPbLQAAAAJ",
      "PKSWrbwAAAAJ",
      "s4Q8hbUAAAAJ"
    ],
    "pvyI8GkAAAAJ": [
      "bh-uRFMAAAAJ",
      "9xDADY4AAAAJ",
      "3kDtybgAAAAJ",
      "TmWYBeEAAAAJ",
      "jQl9RtkAAAAJ",
      "z76PBfYAAAAJ",
      "UfbuDH8AAAAJ",
      "gYiCq88AAAAJ",
      "p9RsPG4AAAAJ",
      "0B8uuBkAAAAJ",
      "NCtKHnQAAAAJ",
      "B_FTboQAAAAJ",
      "3RuMCpcAAAAJ"
    ],
    "LAv0HTEAAAAJ": [],
    "gzpWXPcAAAAJ": [
      "kssA7YwAAAAJ",
      "l7WEDAcAAAAJ",
      "HMyXWb4AAAAJ",
      "63WN_bEAAAAJ",
      "YOVZiJkAAAAJ",
      "Lf3tYKYAAAAJ",
      "2eWscBQAAAAJ",
      "2yHJIP0AAAAJ",
      "Ssdg9-sAAAAJ",
      "hcAHEDYAAAAJ",
      "dQ0dT2sAAAAJ",
      "QpClwb8AAAAJ",
      "eD9_J3wAAAAJ",
      "DFAzHK8AAAAJ",
      "0uCgFkkAAAAJ",
      "AMFWWyMAAAAJ",
      "bamP5BMAAAAJ",
      "FMTai3oAAAAJ",
      "ZiEaIpUAAAAJ",
      "Gi6ksZoAAAAJ",
      "h60zIiUAAAAJ",
      "EPLEf60AAAAJ",
      "kz2aIc8AAAAJ",
      "9dF2BdMAAAAJ",
      "fDmPEMYAAAAJ",
      "OjWXOSsAAAAJ",
      "BQD1XlcAAAAJ",
      "SlLz8KoAAAAJ",
      "pPaf4pkAAAAJ",
      "UpCGVSAAAAAJ",
      "kJPmYCcAAAAJ",
      "h2L2Xp0AAAAJ",
      "uaQdhE4AAAAJ",
      "PMd9DyQAAAAJ",
      "D2EdRScAAAAJ",
      "Sxi1xgkAAAAJ",
      "_75LDyMAAAAJ",
      "Qlq7GEQAAAAJ",
      "hou2DHoAAAAJ",
      "RZOjMYMAAAAJ",
      "_DEJi28AAAAJ",
      "hKlHPt0AAAAJ",
      "NEBWPbsAAAAJ",
      "J_5y3HMAAAAJ",
      "AkJyLCAAAAAJ",
      "FXw6xXcAAAAJ",
      "btk7o4MAAAAJ",
      "4dPt9-4AAAAJ",
      "s9RsYfcAAAAJ",
      "5MdxFjAAAAAJ",
      "eU0C31YAAAAJ",
      "4v73L2AAAAAJ",
      "52f6rLIAAAAJ",
      "Fe-VhGoAAAAJ",
      "MrOv72wAAAAJ",
      "CPQdYCQAAAAJ",
      "o6m4948AAAAJ",
      "s165sfUAAAAJ",
      "AdG54z4AAAAJ",
      "o8TlyGMAAAAJ",
      "HxYWiHsAAAAJ",
      "zSZt9K0AAAAJ",
      "eaZS9_YAAAAJ",
      "siiL_PUAAAAJ",
      "cOQW8gkAAAAJ",
      "j3UHaFoAAAAJ",
      "aGpw2rYAAAAJ",
      "3FsCV_IAAAAJ",
      "W_ZjnTUAAAAJ",
      "fadRi1YAAAAJ",
      "91WQXlIAAAAJ",
      "4Cqm82UAAAAJ",
      "keSzZQIAAAAJ",
      "XM2WLE8AAAAJ",
      "R4DiePwAAAAJ",
      "Dmrm4skAAAAJ",
      "C6BeHCMAAAAJ",
      "U5LkFfYAAAAJ",
      "PfaeD-8AAAAJ",
      "-nsG4ZUAAAAJ",
      "fAVYK4wAAAAJ",
      "SotYphoAAAAJ",
      "wdbul0gAAAAJ",
      "NRlzPgIAAAAJ",
      "tRJvzU0AAAAJ",
      "A3GVtGAAAAAJ",
      "vnGywSsAAAAJ",
      "3A098eMAAAAJ",
      "y3ry4kcAAAAJ",
      "3FwavwMAAAAJ",
      "usd_zgsAAAAJ",
      "AcrgWZIAAAAJ",
      "6aNMdbsAAAAJ",
      "cdx_NQIAAAAJ",
      "heTXnBYAAAAJ",
      "j-DQLQgAAAAJ",
      "hTkUgG0AAAAJ",
      "57jIWn8AAAAJ",
      "O2nUrQIAAAAJ",
      "eesxmR0AAAAJ",
      "SzemdlUAAAAJ",
      "w1_KlvoAAAAJ",
      "Zl9ZzTAAAAAJ",
      "fNUgQjMAAAAJ",
      "UK-VpDoAAAAJ",
      "9lT6OOEAAAAJ",
      "51it_LkAAAAJ",
      "NG5jzCkAAAAJ",
      "U8nclXkAAAAJ",
      "c4FeOJQAAAAJ",
      "YjPIezoAAAAJ",
      "Q-v0BgUAAAAJ",
      "Du51uRIAAAAJ",
      "_pv1sEcAAAAJ",
      "KRQ53ysAAAAJ",
      "x0NsQm0AAAAJ",
      "C-NftTgAAAAJ",
      "WKpjMHsAAAAJ",
      "5NtH-JcAAAAJ",
      "lfRiJ8YAAAAJ",
      "6ZYVPEoAAAAJ",
      "ryE3jpMAAAAJ",
      "afp6_lsAAAAJ",
      "lWadInsAAAAJ",
      "oGqXzKAAAAAJ",
      "yd-4aEIAAAAJ",
      "8DvzhZMAAAAJ",
      "l_pScqkAAAAJ",
      "dGSrRTYAAAAJ",
      "qCAslJ8AAAAJ",
      "KeltSA4AAAAJ",
      "8_he8cUAAAAJ",
      "uND_5REAAAAJ",
      "2f6t6hYAAAAJ",
      "CQVb2IgAAAAJ",
      "NDrCCokAAAAJ",
      "NhJMwocAAAAJ",
      "l1taidEAAAAJ",
      "CA3Z5zcAAAAJ",
      "jI3_2koAAAAJ",
      "ILkESaUAAAAJ",
      "1JvIQ8EAAAAJ",
      "Gua_MdkAAAAJ",
      "g0neHX8AAAAJ",
      "66cQtjcAAAAJ",
      "IVpn1mkAAAAJ",
      "3kKjoMEAAAAJ",
      "pM1yxtsAAAAJ",
      "mM9e90oAAAAJ",
      "a4bPXeYAAAAJ",
      "JzKCTBgAAAAJ",
      "wb-DKCIAAAAJ",
      "LFiqVpwAAAAJ",
      "TJVj26YAAAAJ",
      "t1Xf7NQAAAAJ",
      "BD2lkwIAAAAJ",
      "kc_fImQAAAAJ",
      "HDzOsYAAAAAJ",
      "JEky9g0AAAAJ",
      "_1KUuDQAAAAJ",
      "MhXqCRAAAAAJ",
      "GgJdsl4AAAAJ",
      "XRsGhZ4AAAAJ",
      "4C9Bm9YAAAAJ",
      "spWVns8AAAAJ",
      "WufbXzIAAAAJ",
      "KP-DwH0AAAAJ",
      "nxXheggAAAAJ",
      "KWqO1CgAAAAJ",
      "ez_F5gcAAAAJ",
      "dkW3lTAAAAAJ",
      "wMcK4TQAAAAJ",
      "_KpeoVgAAAAJ",
      "bD4hIqcAAAAJ",
      "pw0LluEAAAAJ",
      "CsQTBwsAAAAJ",
      "SO1MfpcAAAAJ",
      "gzPWwdIAAAAJ",
      "fDvQyegAAAAJ",
      "s5hQAPwAAAAJ",
      "vEqE_rUAAAAJ",
      "HBjME2gAAAAJ",
      "dB4mKx4AAAAJ",
      "tMNWtzkAAAAJ",
      "t1cX3kcAAAAJ",
      "PgGOyOUAAAAJ",
      "5RJ6wXAAAAAJ",
      "cCXHHSkAAAAJ",
      "inYyDE4AAAAJ",
      "yV03lm0AAAAJ",
      "55sPPYMAAAAJ",
      "fup4pNsAAAAJ"
    ],
    "vKlrdpEAAAAJ": [],
    "_qr34PIAAAAJ": [
      "Hyhp_zUAAAAJ",
      "8Qu_gAMAAAAJ",
      "NNr46G8AAAAJ",
      "ydA8Q5AAAAAJ",
      "A-4JUL4AAAAJ",
      "RCi98EAAAAAJ",
      "DdNAgNwAAAAJ",
      "sPlonWcAAAAJ",
      "UgHB5oAAAAAJ",
      "zmLNe4AAAAAJ",
      "yFEHsv4AAAAJ",
      "t-VqN7sAAAAJ",
      "LT9zh4sAAAAJ",
      "dnMoAsUAAAAJ",
      "O1LZbI4AAAAJ",
      "HKGYvu4AAAAJ",
      "YgtBXP0AAAAJ"
    ],
    "-WZcuuwAAAAJ": [
      "8R35rCwAAAAJ",
      "FwxfQosAAAAJ",
      "lJwPbcUAAAAJ",
      "ouSpgSkAAAAJ",
      "o9aFV8cAAAAJ",
      "vtwH6GkAAAAJ",
      "vfPE6hgAAAAJ",
      "Ivot3fkAAAAJ",
      "xUGZX_MAAAAJ",
      "QxLpghAAAAAJ",
      "5P2jxPQAAAAJ",
      "YArRsvEAAAAJ",
      "qDsqFkMAAAAJ",
      "1wLVDP4AAAAJ",
      "xBH73TYAAAAJ",
      "BsOkXDsAAAAJ",
      "BIwrJuQAAAAJ",
      "UgHB5oAAAAAJ",
      "bdHgGgEAAAAJ",
      "bBLqsgkAAAAJ",
      "MyKLYVMAAAAJ",
      "1ScWJOoAAAAJ",
      "a5nY-pYAAAAJ",
      "H9xADK0AAAAJ"
    ],
    "rIjeeRsAAAAJ": [
      "iIFHZ1UAAAAJ",
      "Lh7VfoMAAAAJ",
      "9RyeFYwAAAAJ",
      "B1lAghgAAAAJ",
      "71P8yv4AAAAJ",
      "5xL774wAAAAJ",
      "gFN4QUYAAAAJ",
      "YtUDgPIAAAAJ",
      "OnVgcOkAAAAJ",
      "6aWRAPkAAAAJ",
      "ihFmK4cAAAAJ",
      "VrFFU84AAAAJ",
      "n_ts4eYAAAAJ",
      "ID2aN3QAAAAJ",
      "D3BKoHMAAAAJ",
      "yc4nBNgAAAAJ",
      "UtBcznsAAAAJ",
      "Ke6ex0wAAAAJ",
      "u8SnUUgAAAAJ",
      "br990A8AAAAJ",
      "tQuRm1AAAAAJ",
      "zW32dXsAAAAJ",
      "7Xko5sYAAAAJ",
      "VUOMP_EAAAAJ",
      "hVUVOTIAAAAJ",
      "Ftz0NHIAAAAJ",
      "SlLz8KoAAAAJ",
      "aCFYAEsAAAAJ",
      "LE3ctn0AAAAJ",
      "_pv1sEcAAAAJ",
      "WFtyBCwAAAAJ",
      "39VDRnoAAAAJ",
      "v7G4QvIAAAAJ",
      "PyuaaWAAAAAJ",
      "w3KgvQIAAAAJ",
      "9MsdbKoAAAAJ",
      "elXOB1sAAAAJ",
      "8Mlyv3oAAAAJ",
      "Im_m9I8AAAAJ",
      "SHQikPwAAAAJ",
      "PwdervMAAAAJ",
      "M6-o86kAAAAJ",
      "qrgWqjYAAAAJ",
      "1UNlyTcAAAAJ",
      "GhzAXmIAAAAJ",
      "ZwmIw4EAAAAJ",
      "0_bSbIoAAAAJ",
      "tAxVl44AAAAJ",
      "xmp9PZoAAAAJ",
      "am5XqsQAAAAJ",
      "yhGqdMgAAAAJ",
      "8-nvcSQAAAAJ",
      "cEepZOEAAAAJ",
      "8YrBnPsAAAAJ",
      "VK4ytuIAAAAJ",
      "ELiOV2IAAAAJ",
      "43nqWTUAAAAJ",
      "pfGI-KcAAAAJ",
      "3ar1DOwAAAAJ",
      "RSIlobgAAAAJ",
      "y8O77DYAAAAJ",
      "dEfp5vQAAAAJ",
      "kssA7YwAAAAJ",
      "jBvRff0AAAAJ",
      "P7LuLZMAAAAJ",
      "95NLzC4AAAAJ",
      "KpK7n2EAAAAJ",
      "wziaKmQAAAAJ",
      "aAe-LN0AAAAJ",
      "AkffLRcAAAAJ",
      "xMOPRkQAAAAJ",
      "CKyX_Y8AAAAJ",
      "n8w3bg8AAAAJ",
      "Ancx9LMAAAAJ",
      "wFgLdqUAAAAJ",
      "NDyEvlQAAAAJ",
      "TwifRtcAAAAJ",
      "yV_Ws-QAAAAJ",
      "O50gXqUAAAAJ",
      "zKaxWRIAAAAJ",
      "Efs3XxQAAAAJ",
      "MiI7lj0AAAAJ",
      "yFLmPsoAAAAJ",
      "73IbXtsAAAAJ",
      "EH4ASmUAAAAJ",
      "qRp1xZwAAAAJ",
      "gEM0njwAAAAJ",
      "Lyx4TNIAAAAJ",
      "k1tEBf0AAAAJ",
      "KGvc3jwAAAAJ",
      "Km0qjY8AAAAJ",
      "dMjagUIAAAAJ",
      "63WN_bEAAAAJ",
      "-fPI9LgAAAAJ",
      "0eR4Lt0AAAAJ",
      "dy4WeeIAAAAJ",
      "6G8BRLsAAAAJ",
      "d8pmohMAAAAJ",
      "jB66t5YAAAAJ",
      "xA3RcaUAAAAJ",
      "IZrh2CkAAAAJ",
      "eMzW3TwAAAAJ",
      "01Ja8EUAAAAJ",
      "LNtKWuIAAAAJ",
      "0iZls38AAAAJ",
      "FkKFiE8AAAAJ",
      "VecEj6kAAAAJ",
      "ROILf3EAAAAJ",
      "SIHPQ28AAAAJ",
      "KmHKvzsAAAAJ",
      "CzOD0S4AAAAJ",
      "pzw1-J4AAAAJ",
      "Mp1C17IAAAAJ",
      "Y04UhM4AAAAJ",
      "gfklepYAAAAJ",
      "D6nN2NcAAAAJ",
      "fXxhg5EAAAAJ",
      "riuIGwIAAAAJ",
      "IwGLficAAAAJ",
      "YC4WABEAAAAJ",
      "uztQCmMAAAAJ",
      "JmzhiYAAAAAJ",
      "DEncVcYAAAAJ",
      "peqnQjMAAAAJ",
      "lsYXBx8AAAAJ",
      "sqWpn2AAAAAJ",
      "gOUeu2IAAAAJ",
      "p87Sl34AAAAJ",
      "uBkIL7YAAAAJ",
      "WPFAXNAAAAAJ",
      "TLyT0NwAAAAJ",
      "TTnfnugAAAAJ",
      "vNBuX24AAAAJ",
      "q7Yn0UwAAAAJ",
      "vjPJvwYAAAAJ",
      "C-NftTgAAAAJ",
      "LNXEjT8AAAAJ",
      "8xaTRNsAAAAJ",
      "146OneEAAAAJ",
      "HTf7H58AAAAJ",
      "psuwztYAAAAJ",
      "6w3KEiEAAAAJ",
      "kPxa2w0AAAAJ",
      "Q4j2laYAAAAJ",
      "rVsGTeEAAAAJ",
      "GVzdGe8AAAAJ",
      "caAyffEAAAAJ",
      "GkkMuvQAAAAJ",
      "COrJW_gAAAAJ",
      "O0lONMkAAAAJ",
      "yiWlY9IAAAAJ",
      "v80j6o0AAAAJ",
      "qfbPQ1YAAAAJ",
      "pxFyKAIAAAAJ",
      "OZDGXgwAAAAJ",
      "6z_XWYcAAAAJ",
      "kXbo1twAAAAJ",
      "G3OMbFSm858C",
      "LYbs7Q8AAAAJ",
      "IrM4gpwAAAAJ",
      "zMspIjIAAAAJ",
      "tMY31_gAAAAJ",
      "AgqvtZkAAAAJ",
      "93ZjIs0AAAAJ",
      "Ggy4_UcAAAAJ",
      "1cj23VYAAAAJ",
      "TqblqYcAAAAJ",
      "Um_KuoYAAAAJ",
      "0z0fNxUAAAAJ",
      "YC-3YaYAAAAJ",
      "jQl9RtkAAAAJ",
      "-lnWdScAAAAJ",
      "IFINq2QAAAAJ",
      "a_z5a5wAAAAJ",
      "E7bRAPkAAAAJ",
      "Xy1QFMAAAAAJ",
      "ADxG8S4AAAAJ",
      "Jz_PoUQAAAAJ",
      "YdiZoJgAAAAJ",
      "SQpJmOgAAAAJ",
      "EzQhcfwAAAAJ",
      "ASf9Q04AAAAJ",
      "szP4pC0AAAAJ",
      "RBTNWv4AAAAJ",
      "obgiWfUAAAAJ",
      "w_wosd4AAAAJ",
      "VaaScNkAAAAJ",
      "n82TkYwAAAAJ",
      "YgoU6w0AAAAJ",
      "nnK-WMMAAAAJ",
      "_Lw8tJ8AAAAJ",
      "OO-2710AAAAJ",
      "xkH30GgAAAAJ"
    ],
    "adnTgaAAAAAJ": [
      "a_dbdxAAAAAJ",
      "l_G2vr0AAAAJ",
      "rEjgIskAAAAJ",
      "0Bi5CMgAAAAJ",
      "TD9RhcgAAAAJ",
      "UqtDdZUAAAAJ",
      "Vs-MdPcAAAAJ",
      "y1bnRg4AAAAJ",
      "NkzyCvUAAAAJ",
      "UE6z_m8AAAAJ",
      "kLUQrrYAAAAJ",
      "SWMKy70AAAAJ",
      "iBeDoRAAAAAJ",
      "IQ2eTA8AAAAJ",
      "tsXh_hwAAAAJ",
      "HjmSOFEAAAAJ",
      "ZnT-QpMAAAAJ",
      "ogtsTE4AAAAJ",
      "a7drwRMAAAAJ",
      "n1EE3-8AAAAJ",
      "DZ19008AAAAJ",
      "NcR_PmwAAAAJ",
      "iYN86KEAAAAJ",
      "Ml_vQ8MAAAAJ",
      "aGXkhcwAAAAJ",
      "F2SAhnQAAAAJ",
      "xhKqjpYAAAAJ",
      "TeBmXz4AAAAJ",
      "7OTD-LEAAAAJ",
      "d97bGd8AAAAJ",
      "Y8O9N_0AAAAJ",
      "i38QlUwAAAAJ",
      "uQZjTq4AAAAJ",
      "dq3yXjkAAAAJ",
      "TW7U1W0AAAAJ",
      "kq2kOfEAAAAJ",
      "LiH53A8AAAAJ",
      "sDHHglIAAAAJ",
      "dDsbkAoAAAAJ",
      "XD_01h8AAAAJ",
      "I0fbJ6cAAAAJ",
      "UgHB5oAAAAAJ",
      "ZRjM4EgAAAAJ",
      "O-3bc_EAAAAJ",
      "1zCDX_UAAAAJ",
      "DZ-fHPgAAAAJ",
      "ThJ-Ju4AAAAJ",
      "WfS41RAAAAAJ",
      "IEvwT5kAAAAJ",
      "PqQAVcAAAAAJ",
      "YYJ3aycAAAAJ",
      "EJfvPHYAAAAJ",
      "rXYLXJMAAAAJ",
      "kEOeI2gAAAAJ",
      "koQCVT4AAAAJ",
      "asj41ygAAAAJ",
      "wAaJqPYAAAAJ",
      "umFQktIAAAAJ",
      "XW62DrcAAAAJ",
      "cUkE7OgAAAAJ",
      "9xF7M6wAAAAJ",
      "FR8zF_4AAAAJ",
      "1nLn7pcAAAAJ",
      "n5vSK6YAAAAJ",
      "Ytks8n0AAAAJ",
      "aYHq31IAAAAJ",
      "kMmxbbIAAAAJ",
      "g87CIwgAAAAJ",
      "Jlv4MR4AAAAJ",
      "AB0CIBAAAAAJ",
      "upz0NPIAAAAJ",
      "FUSSkq0AAAAJ",
      "UoATnWEAAAAJ",
      "FzJ6CXsAAAAJ",
      "Vb3FLmkAAAAJ",
      "YpxRngIAAAAJ",
      "ZTWrzykAAAAJ",
      "gZgQLkgAAAAJ",
      "T2U5sGIAAAAJ",
      "3-gk0ioAAAAJ",
      "xuDZ9-sAAAAJ",
      "t5KSayQAAAAJ",
      "x7cbdTcAAAAJ",
      "Djtri0kAAAAJ",
      "yE6LvhMAAAAJ",
      "ctk2MhUAAAAJ",
      "GQdnFXQAAAAJ",
      "6ReT2voAAAAJ",
      "5ZTO0uMAAAAJ",
      "2sFj-kcAAAAJ",
      "OY1lJEAAAAAJ",
      "pv54dqMAAAAJ",
      "GvXDNsYAAAAJ",
      "FZOxxvcAAAAJ",
      "_hrEN-sAAAAJ",
      "Bz3APTsAAAAJ",
      "rKv_MJ4AAAAJ",
      "eFkBvOgAAAAJ",
      "G6txDBYAAAAJ",
      "cePtsyAAAAAJ",
      "5A0Sg-8AAAAJ",
      "NzCaPZsAAAAJ",
      "ZCN03-cAAAAJ",
      "s_atrm8AAAAJ",
      "fDW6YA0AAAAJ",
      "xPSkgtIAAAAJ",
      "F-ytPfAAAAAJ",
      "vCHNxFcAAAAJ",
      "nnCmyBoAAAAJ",
      "nfLC9S0AAAAJ",
      "nzO_5FMAAAAJ",
      "PYZ_Xb0AAAAJ",
      "-oESmhEAAAAJ",
      "AUuGgYgAAAAJ",
      "j7zKTIIAAAAJ",
      "0AUIC-8AAAAJ",
      "yQ32avUAAAAJ",
      "qArWV_wAAAAJ"
    ],
    "kXB8FBoAAAAJ": [
      "bMZFLZ_V4goC",
      "DqXsbPAAAAAJ",
      "yYpm9LoAAAAJ",
      "8LcYFjEAAAAJ",
      "6ujRH5UAAAAJ",
      "6Q6TCkkAAAAJ",
      "dG9MV7oAAAAJ",
      "4bl7qAgAAAAJ",
      "ZxXBaswAAAAJ",
      "IdkhB44AAAAJ",
      "7t4jbPQAAAAJ",
      "aorYJGcAAAAJ",
      "iOLC30YAAAAJ",
      "99RVk_MAAAAJ",
      "-ki9u4sAAAAJ",
      "0dQzZH8AAAAJ",
      "Th4PuGkAAAAJ",
      "tgm2Y7oAAAAJ",
      "Xl4E0CsAAAAJ",
      "Nt4rO1EAAAAJ",
      "RCi98EAAAAAJ",
      "neGbgzYAAAAJ",
      "I1IiJCAAAAAJ",
      "zCaMimYAAAAJ",
      "uGkQKUIAAAAJ",
      "8kA3eDwAAAAJ",
      "EYo_WkEAAAAJ",
      "-0ASVXUAAAAJ",
      "NC16W1kAAAAJ",
      "ACZeu8cAAAAJ",
      "_bKTUqAAAAAJ",
      "XM97iScAAAAJ",
      "0ytii2EAAAAJ",
      "gSYxbCYAAAAJ",
      "Lkrx2SkAAAAJ",
      "d8gdZR4AAAAJ",
      "UXh1I6UAAAAJ",
      "-wflT2wAAAAJ",
      "gO-31VYAAAAJ",
      "sCTJI-0AAAAJ",
      "TIKl_foAAAAJ",
      "iNcA81MAAAAJ",
      "qDsqFkMAAAAJ",
      "OUv7J6QAAAAJ",
      "Tb0ZrYwAAAAJ",
      "UgHB5oAAAAAJ",
      "eiBfCmUAAAAJ",
      "J8OgouwAAAAJ",
      "nY6P_nwAAAAJ",
      "xRuVTW4AAAAJ",
      "_JjIgGcAAAAJ",
      "02FGPmwAAAAJ",
      "JwiByPoAAAAJ",
      "zMLbnN4AAAAJ",
      "G5_VFfkAAAAJ",
      "hYMvCbwAAAAJ",
      "FAv6Nd8AAAAJ",
      "J8_FdjkAAAAJ",
      "8fztli4AAAAJ",
      "GDabimYAAAAJ",
      "-CzfgbwAAAAJ",
      "i28fU0MAAAAJ",
      "yv3sH74AAAAJ",
      "xUGZX_MAAAAJ",
      "pmVPj94AAAAJ",
      "shkKxnQAAAAJ",
      "snDpfA0AAAAJ",
      "6VJaD6EAAAAJ",
      "403nNzMAAAAJ",
      "-6s0HQ4AAAAJ",
      "D_JpQnAAAAAJ",
      "AtfVA6wAAAAJ",
      "Z6gnDIEAAAAJ",
      "tWoesqcAAAAJ",
      "O3gezzcAAAAJ",
      "jM1cT4QAAAAJ",
      "R5AmmGwAAAAJ",
      "IaNhZ9AAAAAJ",
      "-JPZ21IAAAAJ",
      "8sqAOOoAAAAJ"
    ],
    "UWZA0v4AAAAJ": [
      "vswo4rQAAAAJ",
      "5H0arvkAAAAJ",
      "LAIIfV0AAAAJ",
      "fArWdfAAAAAJ",
      "Q_4d9N0AAAAJ",
      "sM41KiAAAAAJ",
      "4RpscjwAAAAJ",
      "3oUgDKQAAAAJ",
      "84WzBlYAAAAJ",
      "3OKn_UYAAAAJ",
      "q0MzO6cAAAAJ",
      "Smr99uEAAAAJ",
      "_6SjdyMAAAAJ",
      "9B8PoXUAAAAJ",
      "iHpqfoQAAAAJ",
      "-sGaL8sAAAAJ",
      "KyPheRMAAAAJ",
      "-XEZA0UAAAAJ",
      "uXNnBTUAAAAJ",
      "0RiypNsAAAAJ",
      "5FrMEXQAAAAJ",
      "qoj5YaYAAAAJ",
      "8fztli4AAAAJ",
      "vtwH6GkAAAAJ",
      "uHIYS6UAAAAJ",
      "TKUlJukAAAAJ",
      "62RXlNoAAAAJ",
      "zBdo-BoAAAAJ",
      "hI4XguUAAAAJ",
      "ZeG4wDgAAAAJ",
      "Mz6M9j0AAAAJ",
      "Xod5HrAAAAAJ",
      "6Wo3XX4AAAAJ",
      "piSbEjwAAAAJ",
      "28sDUWIAAAAJ",
      "CZiTv0gAAAAJ",
      "NyY8ztoAAAAJ",
      "C1H80hoAAAAJ",
      "y1aC-CMAAAAJ",
      "czzhE8wAAAAJ",
      "5QC_CV4AAAAJ",
      "VYiRfCwAAAAJ",
      "MaSXNhUAAAAJ",
      "6Ff2c8wAAAAJ",
      "AbyxansAAAAJ",
      "dyD6nsgAAAAJ",
      "vPEmzqYAAAAJ",
      "bkG57aEAAAAJ",
      "z0RoFtcAAAAJ",
      "tnimPrsAAAAJ",
      "HPoaHyQAAAAJ",
      "QGc-TQkAAAAJ",
      "rgf7oH4AAAAJ",
      "4Vwt9AEAAAAJ",
      "f7hypjsAAAAJ",
      "5SUDRqsAAAAJ",
      "4H4bRkcAAAAJ",
      "f_fKey0AAAAJ",
      "Kv2pL8YAAAAJ",
      "9akH-n8AAAAJ",
      "wnK9jX8AAAAJ"
    ],
    "UAwKvEsAAAAJ": [
      "rRJ9wTJMUB8C",
      "JscQvlUAAAAJ",
      "szUb_isAAAAJ",
      "ncbyhdMAAAAJ",
      "2tt6ZJ0AAAAJ",
      "OUpIbcQAAAAJ",
      "oX7L_mMAAAAJ",
      "Zbo61UMAAAAJ",
      "KS4uI1sAAAAJ",
      "yK7yTiwAAAAJ",
      "IpkkT5oAAAAJ",
      "6MfHyuMAAAAJ",
      "NCkkQAMAAAAJ",
      "S9xCl8EAAAAJ",
      "xZal_nUAAAAJ",
      "Jrn-jxQAAAAJ",
      "e4peJmoAAAAJ",
      "euc0GX4AAAAJ",
      "OSg3D9MAAAAJ",
      "6S0sCwgAAAAJ",
      "Olalwx8AAAAJ",
      "zLjnC5MAAAAJ",
      "_ZxvlzoAAAAJ",
      "h-pwCMUAAAAJ",
      "7EPsnxEAAAAJ",
      "4LRxXyIAAAAJ",
      "pH1PDwYAAAAJ",
      "2ylcZSsAAAAJ",
      "fJsSvzkAAAAJ",
      "fwKsGokAAAAJ",
      "zyR_DF4AAAAJ",
      "YDLkVDoAAAAJ",
      "yxUduqMAAAAJ",
      "8R35rCwAAAAJ",
      "FvRFQZ8AAAAJ",
      "Z_kok3sAAAAJ",
      "MA7j1gkAAAAJ",
      "Ajec0lYAAAAJ",
      "vfa1cToAAAAJ",
      "5_9v0CIAAAAJ",
      "SJE16yoAAAAJ",
      "0uTu7fYAAAAJ",
      "OsoQ-dcAAAAJ",
      "4MrZ9zMAAAAJ",
      "8OYE6iEAAAAJ",
      "tX0GARYAAAAJ",
      "_A7rrswAAAAJ",
      "SkkDQgMAAAAJ",
      "0gyS3z0AAAAJ",
      "nSZG-vcAAAAJ",
      "jKcs76MAAAAJ",
      "eJt6cSIAAAAJ",
      "eGgZmPgAAAAJ",
      "1Wlj18oAAAAJ",
      "JNXWWkIAAAAJ",
      "pa7de7wAAAAJ",
      "_8gD7Y4AAAAJ",
      "a_OQrYoAAAAJ",
      "8Qv3HRoAAAAJ",
      "Ay8t8DEAAAAJ",
      "vgfGtykAAAAJ",
      "HUi6F7wAAAAJ",
      "ggLoicQAAAAJ",
      "bh-uRFMAAAAJ",
      "UgHB5oAAAAAJ",
      "Amg6a3MAAAAJ",
      "FWJZYMYAAAAJ",
      "-Txt8vsAAAAJ",
      "9-eaUCMAAAAJ",
      "Gdow0U4AAAAJ",
      "dErAioMAAAAJ",
      "2dCb2U0AAAAJ",
      "lDzimQIAAAAJ",
      "KjYNz88AAAAJ",
      "MiFqJGcAAAAJ",
      "lelCr80AAAAJ",
      "LaLilZ8AAAAJ",
      "UPvWSMYAAAAJ",
      "RlNm1d4AAAAJ",
      "MTmii2YAAAAJ",
      "2oy3OXYAAAAJ",
      "vfPE6hgAAAAJ",
      "KoJrMIAAAAAJ",
      "8TIMnwEAAAAJ",
      "eM916YMAAAAJ",
      "WOAlvmoAAAAJ",
      "zfCmRZkAAAAJ",
      "nHCB2CkAAAAJ",
      "hhm6ZzUAAAAJ",
      "KgZxzjsAAAAJ",
      "gbY_w1IAAAAJ",
      "nQ7Ij30AAAAJ",
      "aDKi5l8AAAAJ",
      "FJ-huxgAAAAJ",
      "0HuMHFwAAAAJ",
      "c_ssivMAAAAJ",
      "i86O0SAAAAAJ",
      "UpZmJI0AAAAJ",
      "d97bGd8AAAAJ",
      "tCUvC4oAAAAJ",
      "VJODuGkAAAAJ",
      "m2RVgR0AAAAJ",
      "d4yNzXIAAAAJ",
      "pS-idGwAAAAJ",
      "mu5Y2rYAAAAJ",
      "WV8GXcsAAAAJ",
      "rRcthW0AAAAJ",
      "gOTxTaoAAAAJ",
      "TMuSMXoAAAAJ",
      "1nBmV3cAAAAJ",
      "7peUPbIAAAAJ",
      "07IPOvMAAAAJ",
      "HaN8b2YAAAAJ",
      "nicnuy4AAAAJ",
      "FijpZG8AAAAJ",
      "NBKWzkkAAAAJ",
      "SZ3_FMQAAAAJ",
      "pouyVyUAAAAJ",
      "Lkl8nQYAAAAJ",
      "AEsPCAUAAAAJ",
      "AMb1WywAAAAJ",
      "6GpZV0YAAAAJ",
      "YRWfuEIAAAAJ",
      "s2Y3qnwAAAAJ",
      "gY1w14YAAAAJ",
      "DxmHk08AAAAJ",
      "N9t6-RUAAAAJ",
      "I1EvjZsAAAAJ",
      "S1F-gScAAAAJ",
      "SB6_-GAAAAAJ",
      "QPH_lRIAAAAJ",
      "1lORpNsAAAAJ",
      "wBMdXsgAAAAJ",
      "BkTebL0AAAAJ",
      "HHmGYdEAAAAJ",
      "XnUZEcoAAAAJ"
    ],
    "UFlWdvUAAAAJ": [],
    "3Y4egcYAAAAJ": [
      "wfGiqXEAAAAJ",
      "8R35rCwAAAAJ",
      "2ftJYXMAAAAJ",
      "oFIvUSQAAAAJ",
      "qQMFzBgAAAAJ",
      "ktKXDuMAAAAJ",
      "rGF6-WkAAAAJ",
      "PGZLZFUAAAAJ",
      "J_1GGJsAAAAJ",
      "PCJJ8LkAAAAJ",
      "P9FclNEAAAAJ",
      "18O0OAwAAAAJ",
      "r21asW4AAAAJ",
      "RNdGVHoAAAAJ",
      "DNuiPHwAAAAJ",
      "sZrw0v0AAAAJ",
      "AYpm7KcAAAAJ",
      "VINmGpYAAAAJ",
      "Rr643xYAAAAJ",
      "7BM1uyYAAAAJ",
      "fT30bHMAAAAJ",
      "4Nzf_IcAAAAJ",
      "df3XoJIAAAAJ",
      "ETGZXo4AAAAJ",
      "NTAsObMAAAAJ",
      "TyfMgeQAAAAJ"
    ],
    "eml8HfQAAAAJ": [
      "9xDADY4AAAAJ",
      "bh-uRFMAAAAJ",
      "Y8O9N_0AAAAJ",
      "TmWYBeEAAAAJ",
      "L4yEk2UAAAAJ",
      "P2mG6rcAAAAJ",
      "nXBQn7gAAAAJ",
      "eLFhiSYAAAAJ",
      "LBEIm8gAAAAJ",
      "kqVZxpYAAAAJ",
      "t4dSV4YAAAAJ",
      "AbzGfgoAAAAJ",
      "mqpjAt4AAAAJ",
      "QwL4z2UAAAAJ",
      "Ilx8WNkAAAAJ",
      "C6kPjgwAAAAJ",
      "jEf5Q-4AAAAJ",
      "AiuGlVQAAAAJ"
    ],
    "wy0FA1cAAAAJ": [],
    "qwCO618AAAAJ": [],
    "DMTuJzAAAAAJ": [
      "_ws9LLgAAAAJ",
      "YGQs1AYAAAAJ",
      "8R35rCwAAAAJ",
      "LuA1j4oAAAAJ",
      "ncJWfs0AAAAJ",
      "jrfFYAIAAAAJ",
      "SzHPa90AAAAJ",
      "l-la0GQAAAAJ",
      "ejWOgzYAAAAJ",
      "hczHVxEAAAAJ",
      "lgvyqMQAAAAJ",
      "wtRVnsYAAAAJ",
      "dG9MV7oAAAAJ",
      "e378qEIAAAAJ",
      "T7uctwYAAAAJ",
      "Izhkp4YAAAAJ",
      "S2vB4tAAAAAJ",
      "2DBmo-wAAAAJ",
      "OXtG-isAAAAJ",
      "vfPE6hgAAAAJ",
      "ADkiClQAAAAJ",
      "DXpZ1lkAAAAJ",
      "eDQsOFMAAAAJ",
      "n-q-55wAAAAJ",
      "ZKDLDQoAAAAJ",
      "7oxkHYYAAAAJ",
      "_WLInT0AAAAJ",
      "_bs7PqgAAAAJ",
      "cGrUZpwAAAAJ",
      "BZBkjNYAAAAJ",
      "rjnJnEkAAAAJ",
      "izKFQycAAAAJ",
      "aOklxsQAAAAJ",
      "neGbgzYAAAAJ",
      "JEr3qVwAAAAJ",
      "65bIT4oAAAAJ",
      "nyicsDgAAAAJ",
      "_EJrRVAAAAAJ",
      "-dCETaQAAAAJ",
      "yYpm9LoAAAAJ",
      "Q0YEc-QAAAAJ",
      "9bt2Z5QAAAAJ",
      "7EWrVYIAAAAJ",
      "aHPX6PsAAAAJ",
      "I1mOQpAAAAAJ",
      "VsTyEcQAAAAJ",
      "p6DCMrQAAAAJ",
      "lRUi-A8AAAAJ",
      "KtSR8_0AAAAJ",
      "bX__wkYAAAAJ",
      "PIq7jcUAAAAJ",
      "6h1O4AMAAAAJ",
      "Z3dxz9IAAAAJ",
      "3PJeg1wAAAAJ",
      "27eupmsAAAAJ",
      "pSmh9tkAAAAJ",
      "yy0UFOwAAAAJ",
      "rebEn8oAAAAJ",
      "6S9C8XoAAAAJ",
      "uv7g5kMAAAAJ",
      "uWfcPkkAAAAJ",
      "ImpbxLsAAAAJ",
      "SJoRNbYAAAAJ",
      "tWoesqcAAAAJ",
      "-S_9ZRcAAAAJ",
      "n6zUuaQAAAAJ",
      "IEPhQd4AAAAJ",
      "Yfo9_boAAAAJ",
      "iVavvW8AAAAJ",
      "FR8zF_4AAAAJ",
      "JdRs1sQAAAAJ",
      "bH1k38AAAAAJ",
      "keDqjK0AAAAJ",
      "JEXV__kAAAAJ",
      "Eja4Kw4AAAAJ",
      "bfec5vAAAAAJ",
      "c9QnkJMAAAAJ"
    ],
    "b0ehAgIAAAAJ": [
      "ID9QePIAAAAJ",
      "QXyvv94AAAAJ",
      "zQABr7QAAAAJ",
      "czxMUzcAAAAJ",
      "O4_jWCsAAAAJ",
      "BCKhEoAAAAAJ",
      "B96GkdgAAAAJ",
      "-xQ-C1sAAAAJ",
      "K3QJPdMAAAAJ",
      "mc-_DrEAAAAJ",
      "RId1qZ8AAAAJ",
      "j4DDmQ0AAAAJ",
      "hRB3wSgAAAAJ",
      "vN-is70AAAAJ",
      "vtwH6GkAAAAJ"
    ],
    "-9geUIIAAAAJ": [],
    "Vdu_sqwAAAAJ": [
      "LnB5_AcAAAAJ",
      "jW9ts2cAAAAJ",
      "4Fw2ma4AAAAJ",
      "8DKNKhkAAAAJ",
      "IqcCDXkAAAAJ",
      "MlZq4XwAAAAJ",
      "HmBa_6gAAAAJ",
      "owcAYmEAAAAJ",
      "Ac6n5pQAAAAJ",
      "iccBxJIAAAAJ",
      "QBn7vq8AAAAJ",
      "1c7hIUIAAAAJ",
      "WxlqsisAAAAJ",
      "25HL3QcAAAAJ",
      "uIQ2vHQAAAAJ",
      "UZIKgasAAAAJ",
      "P__ztgcAAAAJ",
      "yhli360AAAAJ",
      "LiqLdKYAAAAJ",
      "54KhKdEAAAAJ",
      "avJO4EcAAAAJ",
      "mATAz-wAAAAJ",
      "6d8ODpwAAAAJ",
      "9uWuZkUAAAAJ",
      "o-5vyEsAAAAJ",
      "YuFcRF0AAAAJ",
      "cEM1a5gAAAAJ",
      "YoR3IugAAAAJ",
      "MYsIXF4AAAAJ",
      "7XyGUGkAAAAJ",
      "ZgqVLuMAAAAJ",
      "WUCu45YAAAAJ",
      "ZKEDQXYAAAAJ",
      "5JtQbw0AAAAJ",
      "52f5kGIAAAAJ",
      "wlosgkoAAAAJ",
      "S3gQoMgAAAAJ",
      "n1grp7EAAAAJ",
      "yx0pEmYAAAAJ",
      "KzESVKwAAAAJ",
      "NSbws80AAAAJ",
      "IrixA8MAAAAJ",
      "8yGMMwcAAAAJ",
      "I1w51gUAAAAJ",
      "CPMS_csAAAAJ",
      "_8Egwg8AAAAJ",
      "6POeyBoAAAAJ",
      "7zp9arUAAAAJ",
      "qXi2lyMAAAAJ",
      "JI5QYBwAAAAJ",
      "l6IizNwAAAAJ",
      "X7a38bAAAAAJ",
      "2v1cPRsAAAAJ",
      "zMKzi8kAAAAJ",
      "8R35rCwAAAAJ",
      "mfk62y8AAAAJ",
      "H8yqlRYAAAAJ",
      "gy4UVGcAAAAJ",
      "OXZC0mQAAAAJ",
      "ZjuMpLoAAAAJ",
      "DCP9rQgAAAAJ",
      "cxYepGkAAAAJ",
      "XK7HXzMAAAAJ",
      "zBUwaGkAAAAJ",
      "dio8IesAAAAJ",
      "cyfI_XQAAAAJ",
      "Th4PuGkAAAAJ",
      "wE5ee_kAAAAJ",
      "17TY2TMAAAAJ",
      "9R7Gl8YAAAAJ",
      "f3V6gZMAAAAJ",
      "JrBgRKUAAAAJ",
      "FHiQmOoAAAAJ",
      "O0W9jEQAAAAJ",
      "1hLMcNsAAAAJ",
      "mtejbKYAAAAJ",
      "nBcay4oAAAAJ",
      "7tr3iQkAAAAJ",
      "75q-6ZQAAAAJ",
      "JgO4NqIAAAAJ"
    ],
    "x04W_mMAAAAJ": [
      "JicYPdAAAAAJ",
      "xegzhJcAAAAJ",
      "dOad5HoAAAAJ",
      "XCZpOcAAAAAJ",
      "NMS69lQAAAAJ",
      "NkzyCvUAAAAJ",
      "s1PgoeUAAAAJ",
      "2O3IZlkAAAAJ",
      "vfT6-XIAAAAJ",
      "oBu8kMMAAAAJ",
      "ITZ1e7MAAAAJ",
      "w68-7AYAAAAJ",
      "eC3VWhAAAAAJ",
      "fzLxuAIAAAAJ",
      "x4JAvwMAAAAJ",
      "QJ9ThJ0AAAAJ",
      "TKvd_Z4AAAAJ",
      "8UZIqcoAAAAJ",
      "6-e-ZBEAAAAJ",
      "HBtozdUAAAAJ",
      "5fU-QMwAAAAJ",
      "NYOJzM4AAAAJ",
      "astFxkwAAAAJ",
      "LlK_saMAAAAJ",
      "MoX2ERkAAAAJ",
      "-8DNE4UAAAAJ",
      "WjCG3owAAAAJ",
      "5tVuggUAAAAJ",
      "vtwH6GkAAAAJ",
      "vWTI60AAAAAJ",
      "0kVh58wAAAAJ",
      "iYN86KEAAAAJ",
      "GgQ9GEkAAAAJ",
      "wfGiqXEAAAAJ",
      "L4bNmsMAAAAJ",
      "bnQMuzgAAAAJ",
      "0pOgVVAAAAAJ",
      "cItVg2MAAAAJ",
      "itSa94cAAAAJ",
      "EMDboA4AAAAJ",
      "EemUE4gAAAAJ",
      "sRId4vsAAAAJ",
      "htPVdRMAAAAJ",
      "iyD9aw8AAAAJ",
      "UhmcQ7gAAAAJ",
      "AQzIwI4AAAAJ",
      "euc0GX4AAAAJ",
      "sGFyDIUAAAAJ",
      "LFyg0tAAAAAJ",
      "yNNIKJsAAAAJ",
      "7Ma_PNAAAAAJ",
      "zBdo-BoAAAAJ",
      "V358UyMAAAAJ",
      "0KF6ZC8AAAAJ",
      "yp4Gk3kAAAAJ",
      "9700p4IAAAAJ",
      "q34R9psAAAAJ",
      "Jjp8eYUAAAAJ",
      "W8yZCNsAAAAJ",
      "rT11mdcAAAAJ",
      "TrdtzgwAAAAJ",
      "6gd_QS0AAAAJ",
      "TAomEzQAAAAJ",
      "HBztuGIAAAAJ",
      "E_oZZj8AAAAJ",
      "PNH24toAAAAJ",
      "x2PfbDEAAAAJ",
      "1KvNUWgAAAAJ",
      "AiH3_CkAAAAJ",
      "JWmiQR0AAAAJ",
      "Br8UEzAAAAAJ",
      "xQAoHP0AAAAJ",
      "TvdMDhwAAAAJ",
      "SgbbTp4AAAAJ",
      "2FmzuDMAAAAJ",
      "HbChXx0AAAAJ",
      "ghbWy-0AAAAJ",
      "SAW3KDUAAAAJ",
      "beiWcokAAAAJ",
      "iVLAQysAAAAJ",
      "Amky96kAAAAJ",
      "ygTCc6cAAAAJ",
      "lEV5F5kAAAAJ",
      "yyIoQu4AAAAJ",
      "UFsTIAEAAAAJ",
      "bMfPYdYAAAAJ",
      "kmUgTboAAAAJ",
      "Bmbkv6sAAAAJ",
      "8R35rCwAAAAJ",
      "B8wslVsAAAAJ",
      "r6mBY50AAAAJ",
      "wldNQHoAAAAJ",
      "stCljMYAAAAJ",
      "S5x4xYUAAAAJ",
      "0o470HsAAAAJ",
      "ZLpO3XQAAAAJ",
      "ZbClz98AAAAJ",
      "7MxQd6UAAAAJ",
      "ipb9-GEAAAAJ",
      "n9K1v-cAAAAJ",
      "8200InoAAAAJ",
      "hHPeXmYAAAAJ",
      "Vzr1RukAAAAJ",
      "-ZpM8jUAAAAJ",
      "oD_Ea7EAAAAJ",
      "kjMNMLkAAAAJ",
      "IrixA8MAAAAJ",
      "yQNhFGUAAAAJ",
      "uj1OljkAAAAJ",
      "I0fbJ6cAAAAJ",
      "zithBbUAAAAJ",
      "cSTLkv8AAAAJ",
      "o_J2CroAAAAJ",
      "Vs-MdPcAAAAJ",
      "mxiO4IkAAAAJ",
      "xWrOthYAAAAJ",
      "PUeKU8kAAAAJ",
      "_N2COeAAAAAJ",
      "x7iwG1UAAAAJ",
      "iUe4TdgAAAAJ",
      "bOQGfFIAAAAJ",
      "NbXF7T8AAAAJ",
      "uRlPu-4AAAAJ",
      "ebBgMSkAAAAJ",
      "wjkaNgcAAAAJ",
      "rRJ9wTJMUB8C",
      "aQmpeAEAAAAJ",
      "oavgGaMAAAAJ",
      "iBeDoRAAAAAJ",
      "zDy4jSYAAAAJ",
      "YGGcq5EAAAAJ",
      "r1Fn_YsAAAAJ",
      "84WzBlYAAAAJ",
      "VTe4SGUAAAAJ",
      "RnoIxUwAAAAJ",
      "Cul0g2YAAAAJ",
      "grQ_GBgAAAAJ",
      "aka4LuAAAAAJ",
      "UE6z_m8AAAAJ",
      "-gJkPHIAAAAJ",
      "8xSYX9IAAAAJ",
      "wVazIm8AAAAJ",
      "rtWKzFwAAAAJ",
      "dYpPMQEAAAAJ",
      "C7zfAI4AAAAJ",
      "ghfkSasAAAAJ",
      "1TTFBEkAAAAJ",
      "NvMCACEAAAAJ",
      "pv54dqMAAAAJ",
      "T7uctwYAAAAJ",
      "XD_01h8AAAAJ",
      "UJb3uKgAAAAJ",
      "GvXDNsYAAAAJ"
    ],
    "hRB3wSgAAAAJ": [
      "cl7CnNYAAAAJ",
      "93yNuV0AAAAJ",
      "bs5MttgAAAAJ",
      "9jK5lfsAAAAJ",
      "aPNDep0AAAAJ",
      "By1xdxEAAAAJ",
      "uIpPgJEAAAAJ",
      "B8bCdHsAAAAJ",
      "5f3dXLkAAAAJ",
      "WIk2v1QAAAAJ",
      "ag_2UqcAAAAJ",
      "xxYMJlUAAAAJ",
      "EtGdFOMAAAAJ",
      "xrUwjlQAAAAJ",
      "UZLC4TYAAAAJ",
      "cjr90bEAAAAJ",
      "3bL-H00AAAAJ",
      "0FuZRPYAAAAJ",
      "bYI7VMwAAAAJ",
      "B96GkdgAAAAJ",
      "BST6b8AAAAAJ",
      "PjAQATEAAAAJ",
      "gWBoNCsAAAAJ",
      "wTppKvQAAAAJ",
      "C4QFdvAAAAAJ",
      "uwrwLJcAAAAJ",
      "huV-_rsAAAAJ",
      "RuDNWj8AAAAJ",
      "eH-qW3gAAAAJ",
      "Dk0fJHIAAAAJ",
      "z_1mfIkAAAAJ",
      "0xWltyAAAAAJ",
      "QYesEdIAAAAJ",
      "SZ_vC90AAAAJ",
      "3ZLk60QAAAAJ",
      "hwn3OPIAAAAJ",
      "Bjpb27sAAAAJ",
      "_Fah5fwAAAAJ",
      "nRKhCa8AAAAJ",
      "w19KkekAAAAJ",
      "wIhJS60AAAAJ",
      "_z-DXRIAAAAJ",
      "WNSPregAAAAJ",
      "e4I7ihkAAAAJ",
      "CfLHDYgAAAAJ",
      "kFXm6DQAAAAJ",
      "YmXg5xMAAAAJ",
      "EWi-CL4AAAAJ",
      "ZcguQt4AAAAJ",
      "vP2to0MAAAAJ",
      "N4XAItcAAAAJ",
      "7XBJiZsAAAAJ",
      "UcWOl8YAAAAJ",
      "ID9QePIAAAAJ",
      "b0ehAgIAAAAJ",
      "29qQmWIAAAAJ",
      "tQU8xu0AAAAJ",
      "1z6dv-MAAAAJ",
      "qIfpDL0AAAAJ",
      "dCheWDEAAAAJ",
      "0cKXP7cAAAAJ",
      "VO62HkEAAAAJ",
      "mSvrb54AAAAJ",
      "GXJqtYUAAAAJ",
      "1sB4m_wAAAAJ",
      "dfsJMOYAAAAJ",
      "gNMqz_4AAAAJ",
      "ilbKQMYAAAAJ",
      "VIu8KZfWuM0C",
      "Hz4oXAYAAAAJ",
      "UKqIqRsAAAAJ",
      "1ZT-nZEAAAAJ",
      "jF4dPZwAAAAJ",
      "6UIvmp4AAAAJ",
      "9KRGFbYAAAAJ",
      "BMFlkT8AAAAJ",
      "Lum6DhoAAAAJ",
      "7HoFN1wAAAAJ",
      "C9sg_B8AAAAJ",
      "TGDrPLOkJIIC",
      "v5TPCXFtkUgC",
      "u_H-BTQAAAAJ",
      "0zQdH0oAAAAJ",
      "s1IzhYMAAAAJ",
      "P2Joz5sAAAAJ",
      "5vUydbcAAAAJ",
      "5X5c8OkAAAAJ",
      "qTnlYokAAAAJ",
      "WAleKq0AAAAJ",
      "im_BJdIAAAAJ",
      "09bl0GIAAAAJ",
      "_DSRMYIAAAAJ",
      "B88-PigAAAAJ",
      "rTJTJJ4AAAAJ",
      "urTiL7QAAAAJ",
      "heSjtpgAAAAJ",
      "WsRIDokAAAAJ",
      "zg9zDcsAAAAJ",
      "9vMpR9UAAAAJ",
      "GYUuR_sAAAAJ",
      "EpdF_GQAAAAJ",
      "cQ5w0L0AAAAJ",
      "yzcxu7oAAAAJ",
      "f8ByXgEAAAAJ",
      "57QIaiQAAAAJ",
      "_Wb6s7cAAAAJ",
      "BXGfZq4AAAAJ"
    ],
    "fA0rYxMAAAAJ": [
      "8R35rCwAAAAJ",
      "-kIVAcAAAAAJ",
      "GDabimYAAAAJ",
      "p6DCMrQAAAAJ",
      "O4jW7BsAAAAJ",
      "aOklxsQAAAAJ",
      "6uIhh6MAAAAJ",
      "mXtH1UYAAAAJ",
      "Ou5x9LkAAAAJ",
      "QxLpghAAAAAJ",
      "mnAk4HIAAAAJ",
      "-5_ksIkAAAAJ",
      "9hX-JksAAAAJ",
      "SNqm6doAAAAJ",
      "todsDfQAAAAJ",
      "8HYQ1tgAAAAJ",
      "vfPE6hgAAAAJ"
    ],
    "lPycXNcAAAAJ": [
      "MzD8rjoAAAAJ",
      "55TAOdgAAAAJ",
      "RrYw5jkAAAAJ",
      "Rn_BmTYAAAAJ"
    ],
    "fMDLYCUAAAAJ": [],
    "c_z5hWEAAAAJ": [
      "lH1PdF8AAAAJ",
      "Tb0ZrYwAAAAJ",
      "nVsOPtQAAAAJ",
      "RId1qZ8AAAAJ",
      "i_X02A0AAAAJ",
      "MN9Kfg8AAAAJ",
      "wCa6nygAAAAJ",
      "FUOEBDUAAAAJ",
      "8JGG3KcAAAAJ",
      "kZQQFE4AAAAJ",
      "MIjWr_8AAAAJ",
      "28p_eLYAAAAJ",
      "fNOReswAAAAJ",
      "DYUloYkAAAAJ",
      "WXOaxKMAAAAJ",
      "Z_WrhK8AAAAJ",
      "Mo8VdkoAAAAJ",
      "IyoEsBQAAAAJ",
      "l-mlF7YAAAAJ",
      "WLN3QrAAAAAJ",
      "-iPZaBcAAAAJ",
      "YAHWbtkAAAAJ",
      "B847xq8AAAAJ",
      "HeVcLzAAAAAJ",
      "LPAZlL8AAAAJ",
      "646vnpUAAAAJ",
      "MpdsJF0AAAAJ",
      "DIKwHRsAAAAJ",
      "Qyk0paAAAAAJ",
      "Vu-Zb7EAAAAJ",
      "Pd4pbaAAAAAJ",
      "d3UtiX8AAAAJ",
      "PMh2ysEAAAAJ",
      "qxMVu4cAAAAJ",
      "H4sNIhwAAAAJ",
      "7IwA14gAAAAJ",
      "YtfPZDAAAAAJ",
      "a3Uhp58AAAAJ",
      "W8BMhsgAAAAJ",
      "bOElZi8AAAAJ",
      "BNEeEosAAAAJ",
      "Y-I1X9QAAAAJ",
      "dRShpScAAAAJ",
      "KFeN73wAAAAJ",
      "jTluf5cAAAAJ",
      "umAny5UAAAAJ",
      "dSIEUlEAAAAJ",
      "VBNFtRkAAAAJ",
      "910z20QAAAAJ",
      "eh9yS-QAAAAJ",
      "m5dFh6YAAAAJ",
      "PmrXZ8oAAAAJ",
      "odQWZoEAAAAJ",
      "pjPtYgEAAAAJ",
      "I0nj-TcAAAAJ",
      "ltj3BwwAAAAJ",
      "dGs2BcIAAAAJ",
      "yWJ9BqEAAAAJ",
      "ElqwScwAAAAJ",
      "fgRMGc4AAAAJ",
      "IVxQvz0AAAAJ",
      "jd1S28YAAAAJ",
      "5kvESDsAAAAJ",
      "JiW8z50AAAAJ",
      "5weaWuMAAAAJ",
      "EMrV8BIAAAAJ",
      "7bgABaoAAAAJ",
      "Kia-4B0AAAAJ",
      "n7Rh7mgAAAAJ",
      "Cy_VZ3QAAAAJ",
      "RNiP4hsAAAAJ",
      "-2qyBJEAAAAJ",
      "S9LHLKEAAAAJ",
      "DWPfdT4AAAAJ",
      "xqhwEGIAAAAJ",
      "dGKi9Q4AAAAJ",
      "hPhvZI0AAAAJ",
      "IO8BmHUAAAAJ",
      "Sm14jYIAAAAJ",
      "uvZ63bMAAAAJ",
      "3t2upi8AAAAJ",
      "JbBpeE0AAAAJ",
      "d1O4KssAAAAJ",
      "TW7U1W0AAAAJ",
      "MM4XdKsAAAAJ",
      "c7hk0RwAAAAJ",
      "E2kpqtkAAAAJ",
      "9sqduWYAAAAJ",
      "pJ8vEo8AAAAJ",
      "dkSYtIIAAAAJ",
      "13Puu8AAAAAJ",
      "dsb5VjkAAAAJ",
      "ApKpgeMAAAAJ",
      "zvBNFb0AAAAJ",
      "1OwERREAAAAJ",
      "9cCaIAwAAAAJ",
      "1NQRXHQAAAAJ",
      "RTkSatQAAAAJ",
      "P7nTj5EAAAAJ",
      "clTVC4UAAAAJ",
      "DwTxLXAAAAAJ",
      "OI6ouhAAAAAJ",
      "lL5jPysAAAAJ",
      "RohTif4AAAAJ",
      "FQn7YigAAAAJ",
      "X11hfvIAAAAJ",
      "7PC01c0AAAAJ",
      "EP_omZQAAAAJ",
      "DFwje0AAAAAJ",
      "FN3Lb2gAAAAJ",
      "A4-oSJIAAAAJ",
      "CdJ2xRIAAAAJ",
      "HR0uwyIAAAAJ",
      "r50jBCUAAAAJ",
      "7R_id0YAAAAJ",
      "q1G89okAAAAJ",
      "fbvYwZcAAAAJ",
      "Sp6mXKsAAAAJ",
      "o-kMCtAAAAAJ",
      "kroHjvEAAAAJ",
      "ZTRGztgAAAAJ",
      "qPMJxq0AAAAJ",
      "p2az0gkAAAAJ",
      "QcsE_ZYAAAAJ",
      "STHWcmIAAAAJ",
      "u1CHA2sAAAAJ",
      "v5F-I34AAAAJ",
      "rZtxlqAAAAAJ",
      "a068aTEAAAAJ",
      "2uJEkY4AAAAJ",
      "IfqsDyYAAAAJ",
      "M-X3Q-UAAAAJ",
      "u3ogi00AAAAJ",
      "7KgIMosAAAAJ",
      "x7b5TJMAAAAJ",
      "_ZAnS78AAAAJ",
      "CcLMQagAAAAJ",
      "NC1KaRwAAAAJ",
      "XAhGkq8AAAAJ",
      "_S7LGEEAAAAJ",
      "3s52I10AAAAJ",
      "LyQ0SoMAAAAJ",
      "bOnw_44AAAAJ",
      "kfdwrbYAAAAJ",
      "do7yT8MAAAAJ",
      "eF34OvgAAAAJ",
      "W6bign0AAAAJ",
      "ENIyTF8AAAAJ",
      "aGvH4yMAAAAJ",
      "rxg0zB4AAAAJ",
      "idC8YcsAAAAJ",
      "O8CIQXcAAAAJ",
      "t3mQx_kAAAAJ",
      "nfWGSK0AAAAJ",
      "22DYUdgAAAAJ",
      "1x2nwykAAAAJ",
      "GtxZI1MAAAAJ",
      "vJJFv3YAAAAJ",
      "6hHbBwwAAAAJ",
      "qYYPst0AAAAJ",
      "k-DMEhAAAAAJ"
    ],
    "czxMUzcAAAAJ": [
      "ID9QePIAAAAJ",
      "QXyvv94AAAAJ",
      "b0ehAgIAAAAJ",
      "zQABr7QAAAAJ",
      "uG6vN6QAAAAJ",
      "Kq0feJIAAAAJ",
      "bjNCUt8AAAAJ",
      "aUdg4P0AAAAJ",
      "mimrFAMAAAAJ",
      "DUNGEAIAAAAJ",
      "5KZ-7BAAAAAJ",
      "BCKhEoAAAAAJ",
      "DdCAbWwAAAAJ",
      "pcLld3wAAAAJ",
      "j4DDmQ0AAAAJ",
      "CpMjT0YAAAAJ",
      "hdnpRKsAAAAJ",
      "GLSQo5gAAAAJ",
      "Q8iay0gAAAAJ",
      "OZ7PjVoAAAAJ",
      "h1-3lSoAAAAJ",
      "NvBZp6MAAAAJ",
      "NZmIA9oAAAAJ",
      "eOLxyqUAAAAJ",
      "K3QJPdMAAAAJ",
      "y1lVpBEAAAAJ",
      "iyDxq0EAAAAJ",
      "jCNJhFcAAAAJ",
      "m3f70oYAAAAJ",
      "bdwy3iIAAAAJ",
      "aO8KpGcAAAAJ",
      "DNuiPHwAAAAJ",
      "MtqfTRYAAAAJ",
      "6fqNXooAAAAJ",
      "j8JGVvoAAAAJ",
      "HWxGEesAAAAJ",
      "voqw10cAAAAJ",
      "cbuy0ocAAAAJ",
      "wm2BrUcAAAAJ",
      "0zX2pcwAAAAJ",
      "n1zDCkQAAAAJ"
    ],
    "Q-v0BgUAAAAJ": [],
    "kg4bCpgAAAAJ": [
      "cwKg158AAAAJ",
      "dzOd2hgAAAAJ",
      "FXNJRDoAAAAJ",
      "zfTbkBkAAAAJ",
      "lLMX9hcAAAAJ",
      "DLVP3PcAAAAJ",
      "UXh1I6UAAAAJ",
      "_3q6KBIAAAAJ",
      "-XCiamcAAAAJ",
      "8R35rCwAAAAJ",
      "6hB2vJUAAAAJ",
      "SC9wV2kAAAAJ",
      "3LYW1zMAAAAJ",
      "BI8xFr4AAAAJ",
      "4D2vsdYAAAAJ",
      "NamIygIAAAAJ",
      "DO3quJYAAAAJ",
      "ZWC33cYAAAAJ",
      "ayUyj9YAAAAJ",
      "E_UlAVQAAAAJ",
      "8gfs8XIAAAAJ",
      "cXQciMEAAAAJ",
      "X-VK_5EAAAAJ",
      "uDFb6OcAAAAJ",
      "QMc-grEAAAAJ",
      "0VAe-TQAAAAJ",
      "ndOMZXMAAAAJ",
      "3Q5zpJwAAAAJ",
      "0yDoR0AAAAAJ",
      "OwT_8sQAAAAJ",
      "8TwcVQcAAAAJ",
      "Vzr1RukAAAAJ",
      "K2INPyYAAAAJ",
      "MaSXNhUAAAAJ",
      "pamL_rIAAAAJ",
      "5Iqe53IAAAAJ",
      "eIWg8NMAAAAJ",
      "OEivUAQAAAAJ",
      "2BNtbXMAAAAJ",
      "kA_rSy4AAAAJ",
      "rXYLXJMAAAAJ",
      "GGcjtCsAAAAJ",
      "QCBdB7AAAAAJ"
    ],
    "4Z6vo5QAAAAJ": [
      "wUJ2bXgAAAAJ",
      "gb2r2ssAAAAJ",
      "YTQnGJsAAAAJ",
      "lazJixIAAAAJ",
      "QSTd1oUAAAAJ",
      "TM6oPEUAAAAJ",
      "VIFfuYgAAAAJ",
      "Li0F9VAAAAAJ"
    ],
    "DulpV-cAAAAJ": [
      "Vb3FLmkAAAAJ",
      "s_3ZE8kAAAAJ",
      "W6gQqWcAAAAJ",
      "f6JF7BkAAAAJ",
      "4zybTq4AAAAJ",
      "MK6zHkYAAAAJ",
      "umFQktIAAAAJ",
      "kMmxbbIAAAAJ",
      "kALYnggAAAAJ",
      "UE6z_m8AAAAJ",
      "6Ff2c8wAAAAJ",
      "DLiKRkgAAAAJ",
      "EnEiF7oAAAAJ",
      "YHSRCCsAAAAJ",
      "fb2-dasAAAAJ",
      "K6-JprYAAAAJ",
      "UD87zMYAAAAJ",
      "cF2lHxgAAAAJ",
      "-3VoT8cAAAAJ",
      "B7ngg6QAAAAJ",
      "7dQo6WcAAAAJ",
      "g2nxKt0AAAAJ",
      "TFx_gLQAAAAJ",
      "yKGD9ggAAAAJ",
      "i2OSovEAAAAJ",
      "ytQV4UcAAAAJ"
    ],
    "ZQ1Bbb8AAAAJ": [],
    "wmZTE5gAAAAJ": [
      "vN-is70AAAAJ",
      "zP0S_ikAAAAJ",
      "FFWXLHUAAAAJ",
      "IcaU830AAAAJ",
      "7w24ptsAAAAJ",
      "B96GkdgAAAAJ",
      "yZGlLeMAAAAJ",
      "5tVuggUAAAAJ",
      "yxUduqMAAAAJ",
      "FH9nKOAAAAAJ",
      "vtwH6GkAAAAJ",
      "Nxmx29UAAAAJ",
      "rb6gXycAAAAJ",
      "EMDboA4AAAAJ",
      "7P-gZioAAAAJ",
      "p0sQC6sAAAAJ",
      "dB6ftCcAAAAJ",
      "X22nUYgAAAAJ",
      "I1EvjZsAAAAJ",
      "wRw-e8EAAAAJ",
      "WXbhp_4AAAAJ",
      "biuxbRsAAAAJ",
      "Bl8GgEcAAAAJ",
      "Wj4ZBFIAAAAJ"
    ],
    "xUGZX_MAAAAJ": [
      "8R35rCwAAAAJ",
      "yv3sH74AAAAJ",
      "6uIhh6MAAAAJ",
      "daYjNkAAAAAJ",
      "d5y4iKAAAAAJ",
      "dthSEsoAAAAJ",
      "-WZcuuwAAAAJ",
      "vfPE6hgAAAAJ",
      "SIayDoQAAAAJ",
      "E9ITYW0AAAAJ",
      "SGjYdrEAAAAJ",
      "jERkdhIAAAAJ",
      "DRnOvU8AAAAJ",
      "qR4O45oAAAAJ",
      "QxLpghAAAAAJ",
      "Ivot3fkAAAAJ",
      "gCbeGRIAAAAJ",
      "B96GkdgAAAAJ",
      "C2_ZXdcAAAAJ",
      "mPabwyYAAAAJ",
      "ZzURcb4AAAAJ",
      "-1iyBukAAAAJ",
      "wwW4HRQAAAAJ",
      "zBUwaGkAAAAJ",
      "BDmtLHsAAAAJ",
      "zp8V7ZMAAAAJ",
      "AYPlwA0AAAAJ",
      "0ytii2EAAAAJ",
      "7t4jbPQAAAAJ",
      "BC8TixYAAAAJ",
      "KNQoLcMAAAAJ",
      "6GhZedEAAAAJ",
      "9zeEI-cAAAAJ",
      "xPWCLvEAAAAJ",
      "O3jMNPkAAAAJ",
      "T04c3fwAAAAJ",
      "2StUgf4AAAAJ",
      "AGPooMYAAAAJ",
      "PTS2AOgAAAAJ",
      "Cvn7Y5YAAAAJ",
      "xBH73TYAAAAJ",
      "VINmGpYAAAAJ",
      "36qnUD4AAAAJ",
      "gB87zD4AAAAJ",
      "On-ONT4AAAAJ",
      "u8K7nOwAAAAJ",
      "p9zVBV4AAAAJ",
      "U_R0PWEAAAAJ",
      "vbhA9hwAAAAJ",
      "6zXsZtEAAAAJ",
      "Vf0BonwAAAAJ",
      "e9gUdKwAAAAJ",
      "cAYgoH4AAAAJ",
      "8iCb2TwAAAAJ",
      "NACSmGwAAAAJ",
      "2oy3OXYAAAAJ",
      "bBFN_qwAAAAJ",
      "vgfGtykAAAAJ",
      "BzyVxVUAAAAJ",
      "N_vPIhoAAAAJ",
      "stQ_JksAAAAJ",
      "8rU1AaQAAAAJ",
      "VxpypngAAAAJ",
      "Q8yp6zQAAAAJ",
      "qzLr75IAAAAJ",
      "8erqrHcAAAAJ",
      "xmUDkvQAAAAJ"
    ],
    "hhm6ZzUAAAAJ": [
      "Dxiw1K8AAAAJ",
      "vQ1dKQwAAAAJ",
      "UgHB5oAAAAAJ",
      "KgZxzjsAAAAJ",
      "UAwKvEsAAAAJ",
      "2ylcZSsAAAAJ",
      "HvjirogAAAAJ",
      "HK4x3fkAAAAJ",
      "x58fnLQAAAAJ",
      "23sOkXYAAAAJ",
      "7y6i1SQAAAAJ",
      "hNy1aBgAAAAJ",
      "UWnwlu4AAAAJ",
      "WQnQm0IAAAAJ",
      "AvvaaJcAAAAJ",
      "ho3H9IsAAAAJ",
      "5mUoFN0AAAAJ",
      "NqkgsjoAAAAJ",
      "z7tPc9IAAAAJ",
      "4mVPFQ8AAAAJ"
    ],
    "xOWBOKQAAAAJ": [
      "8fztli4AAAAJ",
      "vtwH6GkAAAAJ",
      "-XEZA0UAAAAJ",
      "VjsNXysAAAAJ",
      "itSa94cAAAAJ",
      "X08l_4IAAAAJ",
      "ugFNit4AAAAJ",
      "EuCFFwYAAAAJ",
      "ivApfKcAAAAJ",
      "lD4Yjn4AAAAJ",
      "FUOEBDUAAAAJ",
      "LWmEzL0AAAAJ",
      "JtHZL24AAAAJ",
      "fxYQWPAAAAAJ",
      "IoGj8UEAAAAJ",
      "aVg7BRwAAAAJ",
      "ZlSVieAAAAAJ",
      "8R35rCwAAAAJ",
      "iOLC30YAAAAJ",
      "XDXw3jQAAAAJ",
      "lRUi-A8AAAAJ",
      "1NyT9gQAAAAJ"
    ],
    "QXyvv94AAAAJ": [
      "Yw2PquQAAAAJ",
      "FoDWxx8AAAAJ",
      "plJC8R0AAAAJ",
      "Q_kKkIUAAAAJ",
      "K-SafJUAAAAJ",
      "dB6ftCcAAAAJ",
      "9vAv0c4AAAAJ",
      "5m5ds6UAAAAJ",
      "kMmxbbIAAAAJ",
      "KVPQoQgAAAAJ",
      "tWoesqcAAAAJ",
      "xCJ8lboAAAAJ",
      "dT7yOrwAAAAJ",
      "0dIBL4AAAAAJ",
      "DnnCWN0AAAAJ",
      "cjx8PKUAAAAJ",
      "U7svaOMAAAAJ",
      "hSyfNekAAAAJ",
      "BGh9WU4AAAAJ",
      "c4YtO-MAAAAJ",
      "oPDVmsgAAAAJ",
      "xT19Jc0AAAAJ",
      "Ao-FJHwAAAAJ",
      "vCuk0SQAAAAJ",
      "SPUjpAwAAAAJ",
      "J_XhIsgAAAAJ",
      "e6JywScAAAAJ",
      "7C7SiMEAAAAJ",
      "p_Ua-sIAAAAJ",
      "WgSVkNwAAAAJ",
      "hlEPkxAAAAAJ",
      "PVcaULkAAAAJ",
      "iBl-QgEAAAAJ",
      "i4ahyPMAAAAJ",
      "5M5nkGAAAAAJ",
      "VoyeryMAAAAJ",
      "MzauO7cAAAAJ",
      "kCxHiwUAAAAJ",
      "N0Rq-XAAAAAJ",
      "wKjXRn0AAAAJ",
      "GFvVRzwAAAAJ",
      "rUiWchkAAAAJ",
      "kllQz-YAAAAJ",
      "OZlvV6kAAAAJ",
      "hlO3qqkAAAAJ",
      "JyABkTwAAAAJ",
      "WhMzaJwAAAAJ",
      "OttawxUAAAAJ",
      "1e6XV-YAAAAJ",
      "yQNhFGUAAAAJ"
    ],
    "x78TL58AAAAJ": [
      "8m8taGEAAAAJ",
      "xVN3UxYAAAAJ",
      "VbNwxKYAAAAJ",
      "qnwjcfAAAAAJ",
      "O_PbKNMAAAAJ",
      "mIlaYj0AAAAJ",
      "Yk3s7HUAAAAJ",
      "9oDqFwkAAAAJ",
      "jcewpCIAAAAJ",
      "4ME93EEAAAAJ",
      "jfu5EP4AAAAJ",
      "RpqvaTUAAAAJ",
      "Uxb6wbkAAAAJ",
      "hfqXASoAAAAJ",
      "2F8T0yAAAAAJ",
      "uOIgTt8AAAAJ",
      "XOJE8OEAAAAJ",
      "OYZrsIQAAAAJ",
      "Rcjr4UYAAAAJ",
      "FUEBroEAAAAJ",
      "luv0xMIAAAAJ",
      "ID9QePIAAAAJ",
      "SNTbGfIAAAAJ",
      "Jd2A44wAAAAJ",
      "Dxiw1K8AAAAJ",
      "w5T0phcAAAAJ",
      "BitIg-YAAAAJ",
      "iSFDVj4AAAAJ",
      "QIZZA0oAAAAJ",
      "7yn5-VEAAAAJ",
      "4LAT5WYAAAAJ",
      "fb-yr1YAAAAJ",
      "vvzAfOwAAAAJ",
      "uggA5n4AAAAJ",
      "EzoDsIMAAAAJ",
      "A_x6bjQAAAAJ",
      "iyDxq0EAAAAJ",
      "aO8KpGcAAAAJ",
      "uY4D8-wAAAAJ",
      "xmUDkvQAAAAJ",
      "0rFlyFgAAAAJ",
      "2IzviGMAAAAJ",
      "C5D_E04AAAAJ"
    ],
    "neGbgzYAAAAJ": [
      "1bF2s2kAAAAJ",
      "i28fU0MAAAAJ",
      "Q_4d9N0AAAAJ",
      "kXB8FBoAAAAJ",
      "uh7PNBoAAAAJ",
      "Ksm6fEUAAAAJ",
      "gI5FMw8AAAAJ",
      "qDsqFkMAAAAJ",
      "xkLdn4gAAAAJ"
    ],
    "1HO5UacAAAAJ": [
      "aOklxsQAAAAJ",
      "bqL73OkAAAAJ",
      "k0nZO90AAAAJ",
      "1MSpdmQAAAAJ",
      "QBsEFvMAAAAJ",
      "W8VIEZgAAAAJ",
      "ZeJjFQMAAAAJ",
      "a8Y2OJMAAAAJ",
      "5na92fcAAAAJ",
      "8R35rCwAAAAJ",
      "s5-hnX8AAAAJ",
      "W5WbqgoAAAAJ",
      "GQWTo4MAAAAJ",
      "8F1GBF4AAAAJ",
      "_BPdgV0AAAAJ",
      "bSU7LYoAAAAJ",
      "v1CRzeAAAAAJ",
      "TpglobcAAAAJ",
      "ITZ1e7MAAAAJ",
      "AzcmAtgAAAAJ",
      "lx-5mjUAAAAJ",
      "mqpjAt4AAAAJ",
      "y1lVpBEAAAAJ",
      "vTWuk1gAAAAJ",
      "CQ1cqKkAAAAJ",
      "rtWKzFwAAAAJ",
      "06rffEkAAAAJ",
      "bmZbi_UNs-oC",
      "JFEjS1QAAAAJ",
      "qrqim7kAAAAJ",
      "YzxIuqwAAAAJ",
      "PGFk9ZgAAAAJ",
      "FLcpd34AAAAJ",
      "QFpswmcAAAAJ",
      "gdUv1PIAAAAJ",
      "bh-uRFMAAAAJ",
      "r5mA7Q8AAAAJ",
      "FXNJRDoAAAAJ",
      "8gfs8XIAAAAJ",
      "kg4bCpgAAAAJ",
      "sQ6l4sMAAAAJ",
      "4D2vsdYAAAAJ",
      "CCV58dgAAAAJ",
      "RKjEFukAAAAJ",
      "N0Lv5FUAAAAJ",
      "3vKjkoQAAAAJ",
      "qXTt3dUAAAAJ",
      "UhDW6jkAAAAJ",
      "OXFjRnEAAAAJ",
      "Te3H6mMAAAAJ",
      "d9s3sbQAAAAJ",
      "pmVPj94AAAAJ",
      "EZdKx4IAAAAJ",
      "rNcmwggAAAAJ",
      "FWp7728AAAAJ",
      "8fztli4AAAAJ",
      "Tsh90D8AAAAJ",
      "5lhsTYwAAAAJ",
      "1Tfui8UAAAAJ",
      "b957ulAAAAAJ",
      "Oj-2ZNEAAAAJ",
      "d3rRkqcAAAAJ",
      "5dBp2f4AAAAJ",
      "96mJbhwAAAAJ",
      "-5_ksIkAAAAJ",
      "3mOq4dcAAAAJ",
      "wTGk7TIAAAAJ",
      "pouyVyUAAAAJ",
      "DUgsNccAAAAJ",
      "d97bGd8AAAAJ",
      "6-ojl1EAAAAJ",
      "gYiCq88AAAAJ",
      "lAiZXhYAAAAJ",
      "pf2zAXkAAAAJ",
      "peIOOn8AAAAJ",
      "UbtCA90AAAAJ",
      "h-EphF0AAAAJ",
      "IUZ-7_cAAAAJ",
      "kQisE-gAAAAJ",
      "TIpmrtoAAAAJ",
      "kI2nR5gAAAAJ",
      "jeOFRDsAAAAJ",
      "RScZCLEAAAAJ",
      "M7S3soEAAAAJ",
      "lgHhJQ8AAAAJ",
      "9rYWAhsAAAAJ",
      "O8ALPlkAAAAJ",
      "IDItm6cAAAAJ",
      "OB6vAtkAAAAJ",
      "iILS6kQAAAAJ",
      "-oy5DaIAAAAJ",
      "lmsiq6oAAAAJ",
      "jXfleiEAAAAJ",
      "sAdDcvQAAAAJ",
      "RBwpd88AAAAJ",
      "vh9KxEIAAAAJ",
      "Z8-UfkUAAAAJ",
      "9B8PoXUAAAAJ",
      "UuwugFEAAAAJ",
      "MgppzFwAAAAJ",
      "-SWUwoIAAAAJ",
      "MbsEFrYAAAAJ",
      "T3Tt0S8AAAAJ",
      "bdHgGgEAAAAJ",
      "AEsPCAUAAAAJ",
      "NpOg5soAAAAJ",
      "0QtU-NsAAAAJ",
      "HxJTHvMAAAAJ",
      "28oeBTgAAAAJ",
      "ozaKHIIAAAAJ",
      "keDqjK0AAAAJ",
      "qR4O45oAAAAJ",
      "tMrZjn0AAAAJ",
      "-9Y7xbAAAAAJ",
      "D2K-ADYAAAAJ",
      "9HRLi20AAAAJ",
      "fDtoo50AAAAJ",
      "-sGaL8sAAAAJ",
      "5m-oAesAAAAJ",
      "S21bOvsAAAAJ",
      "0qUErHAAAAAJ",
      "ouSpgSkAAAAJ",
      "2efgcS0AAAAJ",
      "FwxfQosAAAAJ",
      "o9aFV8cAAAAJ",
      "KgZxzjsAAAAJ",
      "BO_b2O8AAAAJ",
      "_U-HwfkAAAAJ",
      "QGpxkvkAAAAJ",
      "QNRj_g8AAAAJ",
      "ZcULDB0AAAAJ",
      "eLFhiSYAAAAJ",
      "xNxlvjEAAAAJ",
      "3TggrEkAAAAJ",
      "gI55gF0AAAAJ",
      "WNIxd2UAAAAJ",
      "ZQFp_3MAAAAJ",
      "VEUW-qIAAAAJ",
      "Mz1fab8AAAAJ",
      "ryoyucAAAAAJ",
      "-LJCZMMAAAAJ",
      "oPV20eMAAAAJ",
      "jZXvcOsAAAAJ",
      "-epU9OsAAAAJ",
      "z2SoXI8AAAAJ",
      "dVswVTEAAAAJ",
      "LcOIFHEAAAAJ",
      "KIgj3WQAAAAJ",
      "ygQznUQAAAAJ",
      "-XWZKZAAAAAJ",
      "9OdMvbAAAAAJ",
      "WlA92lcAAAAJ",
      "MS1P6hcAAAAJ",
      "JSv1FOYAAAAJ",
      "5H0arvkAAAAJ",
      "kc-qetAAAAAJ",
      "PF-RPpEfa-0C",
      "kWAlOAkAAAAJ",
      "22oxVYkAAAAJ",
      "_bs7PqgAAAAJ",
      "dkRTvvcAAAAJ",
      "-o8kQPwAAAAJ",
      "GwKF9rMAAAAJ",
      "I1mOQpAAAAAJ"
    ],
    "3F52RjoAAAAJ": [],
    "AIZoRQIAAAAJ": [
      "j6bKU_kAAAAJ",
      "oeuqAuQAAAAJ",
      "zkc9pukAAAAJ",
      "skcZ-JwAAAAJ",
      "02hyl6AAAAAJ"
    ],
    "8fztli4AAAAJ": [
      "vtwH6GkAAAAJ",
      "jdSlREMAAAAJ",
      "RlSbIJ4AAAAJ",
      "VjsNXysAAAAJ",
      "LAv0HTEAAAAJ",
      "p0sQC6sAAAAJ",
      "vPEmzqYAAAAJ",
      "x-n9rIMAAAAJ",
      "XmLMNyUAAAAJ",
      "D_JpQnAAAAAJ",
      "V6LJpwgAAAAJ",
      "-sGaL8sAAAAJ",
      "qoIuyMoAAAAJ",
      "MDIyLnwAAAAJ",
      "UtmQJt8AAAAJ",
      "UWZA0v4AAAAJ",
      "AxFrw0sAAAAJ",
      "jkwHy3AAAAAJ",
      "HdEjj2MAAAAJ",
      "K__JmtcAAAAJ",
      "fxYQWPAAAAAJ",
      "TkayRqQAAAAJ",
      "sLXafasAAAAJ",
      "2s9_ZWgAAAAJ",
      "NpccCXwAAAAJ",
      "_KxkI6UAAAAJ",
      "tk3X1QkAAAAJ",
      "uDP7UX0AAAAJ"
    ],
    "ZcWO2AEAAAAJ": [
      "njOmQFsAAAAJ",
      "JY-WzksAAAAJ",
      "tlh8i7gAAAAJ",
      "JlX2UTEAAAAJ",
      "NGI_giYAAAAJ",
      "3Q5zpJwAAAAJ",
      "G8dMSvAAAAAJ",
      "-6cOYcYAAAAJ",
      "8TwcVQcAAAAJ",
      "8E442bkAAAAJ",
      "EpT5sLAAAAAJ",
      "VJlCMGYAAAAJ",
      "0Qr2IGwAAAAJ",
      "MVGcpRsAAAAJ",
      "GgQ9GEkAAAAJ",
      "0zZnyMEAAAAJ",
      "3RuMCpcAAAAJ",
      "NeW9jU8AAAAJ",
      "3M9mssIAAAAJ",
      "CqqvouwAAAAJ",
      "B_FTboQAAAAJ",
      "avCEoT8AAAAJ",
      "cagVT0AAAAAJ",
      "BVde3Y0AAAAJ",
      "TGRPKRIAAAAJ",
      "ss8KR5gAAAAJ",
      "5JlEyTAAAAAJ",
      "lCwsfosAAAAJ",
      "g5vDxv8AAAAJ",
      "DQOT0OMAAAAJ",
      "yBl_j4gAAAAJ",
      "Vu1OqIsAAAAJ",
      "bh-uRFMAAAAJ",
      "Vpr6s3sAAAAJ",
      "7ja8HqUAAAAJ",
      "x2wyjkAAAAAJ",
      "0z0fNxUAAAAJ",
      "ADMVEmsAAAAJ",
      "rRCnB0wAAAAJ",
      "PeMuphgAAAAJ",
      "ntGll74AAAAJ",
      "Vzr1RukAAAAJ",
      "i28fU0MAAAAJ",
      "uiqXutMAAAAJ",
      "uGDQoU0AAAAJ",
      "8B9EaL8AAAAJ",
      "OAtUvx0AAAAJ",
      "NJ9c4ygAAAAJ",
      "d97bGd8AAAAJ",
      "5v0elikAAAAJ",
      "jyxO2akAAAAJ",
      "TkVHKDgAAAAJ",
      "UdpacsMAAAAJ",
      "LW8ze_UAAAAJ",
      "YPzKczYAAAAJ",
      "ijmuZ0wAAAAJ",
      "re00xioAAAAJ",
      "02nHF0gAAAAJ",
      "VgYU_m8AAAAJ",
      "PUSWc4EAAAAJ",
      "4H4bRkcAAAAJ",
      "BghVDhgAAAAJ",
      "BaY_Ie8AAAAJ",
      "2k18_1IAAAAJ",
      "VWX-GMAAAAAJ",
      "PgSzKsgAAAAJ",
      "vjZrDKQAAAAJ",
      "nCZ2PMcAAAAJ",
      "fSgLUqYAAAAJ",
      "d10sXc8AAAAJ",
      "EEre0EcAAAAJ",
      "eSOXB6IAAAAJ",
      "kzFmAkYAAAAJ",
      "qSGlX6UAAAAJ",
      "FHtM5MUAAAAJ",
      "TfWlMTYAAAAJ",
      "UyZL660AAAAJ",
      "XPAkzTEAAAAJ",
      "g3VILNEAAAAJ",
      "QY5OAIMAAAAJ",
      "yVnCUg0AAAAJ",
      "jeOFRDsAAAAJ",
      "uDuLNHkAAAAJ",
      "OwA3zyMAAAAJ",
      "5S1kGcAAAAAJ",
      "nrsWSt4AAAAJ",
      "IYUPj9MAAAAJ",
      "EareJO0AAAAJ",
      "8kYedXEAAAAJ",
      "hkCVqYkAAAAJ",
      "9HoiYnYAAAAJ",
      "j-cSRNIAAAAJ",
      "-tzn_AsAAAAJ",
      "WPYCnqIAAAAJ",
      "gXgEgeoAAAAJ",
      "lwlYARMAAAAJ",
      "-KN-O0sAAAAJ",
      "RTVRTSsAAAAJ",
      "p9-ohHsAAAAJ",
      "2-P1M2IAAAAJ",
      "eZr-ai0AAAAJ",
      "YAtwLpwAAAAJ",
      "OpXMNnMAAAAJ",
      "1P8Zu04AAAAJ",
      "Yi5nK1EAAAAJ",
      "4NUg-zkAAAAJ",
      "RjQ7YnMAAAAJ",
      "ma2bi00AAAAJ",
      "1ROPmVQAAAAJ",
      "qRXIUuMAAAAJ",
      "kuIqfXkAAAAJ",
      "h-JEcQ8AAAAJ",
      "PghQbXMAAAAJ",
      "FHwvVmkAAAAJ",
      "-qSroKoAAAAJ",
      "Rh16nsIAAAAJ",
      "EPO5_f4AAAAJ",
      "v0DNZWUAAAAJ",
      "zO6kmIAAAAAJ",
      "LF-IGAEAAAAJ",
      "6rjdDasAAAAJ",
      "KdX5MN4AAAAJ",
      "0xroV7wAAAAJ",
      "IeHKeGYAAAAJ",
      "QW_JZnsAAAAJ",
      "Y2q1wVEAAAAJ",
      "s4Q8hbUAAAAJ",
      "GwKF9rMAAAAJ",
      "TmZ3howAAAAJ"
    ],
    "Ob0bNAUAAAAJ": [],
    "ckZ7q_gAAAAJ": [],
    "TmWYBeEAAAAJ": [
      "9xDADY4AAAAJ",
      "3kDtybgAAAAJ",
      "bh-uRFMAAAAJ",
      "p9RsPG4AAAAJ",
      "pvyI8GkAAAAJ",
      "UfbuDH8AAAAJ",
      "gYiCq88AAAAJ",
      "ZDL6ITwAAAAJ",
      "QwdY5EIAAAAJ",
      "8BeTDr0AAAAJ",
      "begDaeQAAAAJ"
    ],
    "3XLQbL8AAAAJ": [
      "wKvaIJgAAAAJ",
      "GExyiRkAAAAJ",
      "XeDv_1IAAAAJ",
      "JEEwSlQAAAAJ",
      "3Oiv9FwAAAAJ",
      "yxUduqMAAAAJ",
      "acmtRMAAAAAJ",
      "3QxoymwAAAAJ",
      "p_ALSeoAAAAJ"
    ],
    "KcPrLhIAAAAJ": [
      "iyDxq0EAAAAJ",
      "IB_jPZ0AAAAJ",
      "-S_9ZRcAAAAJ",
      "8R35rCwAAAAJ",
      "aO8KpGcAAAAJ",
      "OI7zFmwAAAAJ",
      "bDq7MZMAAAAJ",
      "LIJQ_ZYAAAAJ",
      "yy0UFOwAAAAJ",
      "yQKlLTQAAAAJ",
      "ejchAEYAAAAJ",
      "GZA3M2AAAAAJ",
      "egq785sAAAAJ"
    ],
    "AIy7QHIAAAAJ": [
      "Qhe5ua0AAAAJ",
      "2z2camUAAAAJ",
      "MDeIveMAAAAJ",
      "FLJ86DwAAAAJ",
      "vcGuNDYAAAAJ",
      "DRA4zoUAAAAJ",
      "e7rXLKAAAAAJ",
      "JjASH4UAAAAJ",
      "K6J_DvgAAAAJ"
    ],
    "EjtpMaoAAAAJ": [],
    "qlwwdfEAAAAJ": [
      "8R35rCwAAAAJ",
      "xgQd1qgAAAAJ",
      "zvz6LIYAAAAJ",
      "1VDV6ZEAAAAJ",
      "QMfeRz0AAAAJ",
      "gnBwBZ4AAAAJ",
      "Qp2pme4AAAAJ",
      "cI0dYX4AAAAJ",
      "AYaHBAQAAAAJ",
      "c1FYGAQAAAAJ",
      "zBUwaGkAAAAJ",
      "ewqmB6sAAAAJ",
      "OZk7X80AAAAJ",
      "Xr_hCJMAAAAJ",
      "PTS2AOgAAAAJ",
      "XqLiBQMAAAAJ",
      "78WTKm4AAAAJ",
      "uodw8PQAAAAJ",
      "_j5XWygAAAAJ",
      "RjPS_lUAAAAJ",
      "YDCsS5EAAAAJ",
      "QKNeRFsAAAAJ",
      "Nf48jqcAAAAJ",
      "bOQGfFIAAAAJ",
      "vtwH6GkAAAAJ",
      "92M8xv4AAAAJ",
      "yABlzrsAAAAJ",
      "Ih7iLuUAAAAJ",
      "GhrKC1gAAAAJ"
    ],
    "1M79iLwAAAAJ": [
      "iyDxq0EAAAAJ",
      "87nZphcAAAAJ",
      "vN-is70AAAAJ",
      "B96GkdgAAAAJ",
      "nfX25MMAAAAJ",
      "Op-47sgAAAAJ",
      "_7Q8uIYAAAAJ",
      "Vy16O5UAAAAJ",
      "vEYUIioAAAAJ",
      "yxUduqMAAAAJ",
      "df-THM0AAAAJ",
      "LajpoI8AAAAJ",
      "aO8KpGcAAAAJ",
      "bh-uRFMAAAAJ",
      "qCmF95EAAAAJ"
    ],
    "no_BfYgAAAAJ": [
      "J8OgouwAAAAJ",
      "yQNhFGUAAAAJ",
      "yxUduqMAAAAJ",
      "j4VWFL4AAAAJ",
      "J8_FdjkAAAAJ",
      "RiDdF2YAAAAJ",
      "GAvF3gUAAAAJ",
      "FuGllAwAAAAJ",
      "tWoesqcAAAAJ",
      "5Cm8L90AAAAJ",
      "Ek4hM10AAAAJ",
      "oWcFfZcAAAAJ",
      "-0U84zMAAAAJ",
      "-D0EgMIAAAAJ"
    ],
    "2k5j4eMAAAAJ": [
      "oIz_CYEAAAAJ",
      "wlosgkoAAAAJ",
      "lMkTx0EAAAAJ",
      "ri1sE34AAAAJ",
      "0RAmmIAAAAAJ",
      "vg_IkckAAAAJ",
      "H3Uq3FcAAAAJ",
      "P-md_yYAAAAJ"
    ],
    "VbNwxKYAAAAJ": [
      "8m8taGEAAAAJ",
      "xVN3UxYAAAAJ",
      "x78TL58AAAAJ",
      "1_f79vUAAAAJ",
      "BitIg-YAAAAJ",
      "aO8KpGcAAAAJ",
      "iyDxq0EAAAAJ"
    ],
    "rBJV6QUAAAAJ": [],
    "PkfChMgAAAAJ": [
      "Wj4ZBFIAAAAJ",
      "xdGKgtcAAAAJ",
      "vN-is70AAAAJ",
      "GXJqtYUAAAAJ",
      "0VwIiIsAAAAJ",
      "I1EvjZsAAAAJ",
      "QYsnk-cAAAAJ",
      "WYctQAQAAAAJ",
      "0irVeiQAAAAJ",
      "Bl8GgEcAAAAJ"
    ],
    "l-la0GQAAAAJ": [
      "8R35rCwAAAAJ",
      "_ws9LLgAAAAJ",
      "2DBmo-wAAAAJ",
      "DMTuJzAAAAAJ",
      "eDQsOFMAAAAJ",
      "jrfFYAIAAAAJ",
      "wtRVnsYAAAAJ",
      "vfPE6hgAAAAJ",
      "T7uctwYAAAAJ",
      "wotfaAgAAAAJ",
      "iYN86KEAAAAJ",
      "zIv6YN0AAAAJ",
      "SzHPa90AAAAJ",
      "n-q-55wAAAAJ",
      "M5zMoh4AAAAJ",
      "DRnOvU8AAAAJ",
      "xegzhJcAAAAJ",
      "hczHVxEAAAAJ",
      "lgvyqMQAAAAJ",
      "neGbgzYAAAAJ",
      "MKSTPN8AAAAJ",
      "1wLVDP4AAAAJ",
      "Z3dxz9IAAAAJ",
      "C-ZlBWMAAAAJ",
      "fftO_HsAAAAJ",
      "tfN6V84AAAAJ",
      "OXtG-isAAAAJ",
      "Q0YEc-QAAAAJ",
      "2Dymb8oAAAAJ",
      "y5fsjDAAAAAJ",
      "MxxZkEcAAAAJ",
      "svJIv28AAAAJ",
      "90FJPJUAAAAJ",
      "MyPTNBgAAAAJ",
      "B8wslVsAAAAJ",
      "kjMNMLkAAAAJ",
      "JFEjS1QAAAAJ",
      "k_u5ULgAAAAJ",
      "lKvYBwkAAAAJ",
      "Te3H6mMAAAAJ",
      "SYvhSBcAAAAJ",
      "qOtlP1AAAAAJ"
    ],
    "T7uctwYAAAAJ": [
      "bnQMuzgAAAAJ",
      "T04c3fwAAAAJ",
      "0nPi5YYAAAAJ",
      "wfGiqXEAAAAJ",
      "mu5Y2rYAAAAJ",
      "jEANvfgAAAAJ",
      "yOcNQVgAAAAJ",
      "17fLjgQAAAAJ",
      "yFMX138AAAAJ",
      "351ivuQAAAAJ",
      "sm1q2bYAAAAJ",
      "38fqeIYAAAAJ",
      "JicYPdAAAAAJ",
      "r9JOIloAAAAJ",
      "90FJPJUAAAAJ",
      "tMY31_gAAAAJ",
      "kjMNMLkAAAAJ",
      "68hTs9wAAAAJ",
      "ghbWy-0AAAAJ",
      "aMeteU4AAAAJ",
      "ss8KR5gAAAAJ",
      "5oa_2lgAAAAJ",
      "C6UAIHEAAAAJ",
      "8R35rCwAAAAJ",
      "WwqlChAAAAAJ",
      "iJENOG8AAAAJ",
      "HQbrO2kAAAAJ",
      "tJ_PrzgAAAAJ",
      "l-la0GQAAAAJ",
      "DMTuJzAAAAAJ",
      "q7nFtUcAAAAJ",
      "Izhkp4YAAAAJ",
      "lgvyqMQAAAAJ",
      "nkmDOPgAAAAJ",
      "e8ZEb4wAAAAJ",
      "OqUlGZwAAAAJ",
      "_ws9LLgAAAAJ",
      "YfPA4YsAAAAJ",
      "NbXF7T8AAAAJ",
      "NMS69lQAAAAJ",
      "n-q-55wAAAAJ",
      "qOFs67oAAAAJ",
      "RM2vMNcAAAAJ",
      "neGbgzYAAAAJ",
      "E_82W3EAAAAJ",
      "VINmGpYAAAAJ",
      "t2X4Mg8AAAAJ",
      "U_Jw8DUAAAAJ",
      "hYVMrzsAAAAJ",
      "ADkiClQAAAAJ",
      "rHF25YEAAAAJ",
      "7KDSCpQAAAAJ",
      "KsocBp8AAAAJ",
      "OcownLgAAAAJ",
      "Vzr1RukAAAAJ",
      "yy0UFOwAAAAJ",
      "NSWI3OwAAAAJ",
      "2fWmq-4AAAAJ",
      "5VaXUQsAAAAJ",
      "cXT3p6cAAAAJ",
      "pqP5_PgAAAAJ",
      "hczHVxEAAAAJ",
      "wtRVnsYAAAAJ",
      "SzHPa90AAAAJ",
      "DXpZ1lkAAAAJ",
      "jrfFYAIAAAAJ",
      "eDQsOFMAAAAJ",
      "2DBmo-wAAAAJ",
      "tWoesqcAAAAJ",
      "AjkTOkAAAAAJ",
      "kbZqRLkAAAAJ",
      "NRoF0iwAAAAJ",
      "xegzhJcAAAAJ",
      "J7p1Fx4AAAAJ",
      "vfT6-XIAAAAJ",
      "a2KklUoAAAAJ",
      "W8yZCNsAAAAJ",
      "ipTsozQAAAAJ",
      "pEKw_vtA1pcC",
      "BbfIggwAAAAJ",
      "8fztli4AAAAJ",
      "TFsE4BIAAAAJ",
      "vcw0TJIAAAAJ",
      "J8OgouwAAAAJ",
      "sI0DsP8AAAAJ",
      "rQTHsloAAAAJ",
      "-w5DuHgAAAAJ",
      "6Hk7QdkAAAAJ",
      "4EOqqUsAAAAJ",
      "jk17mo8AAAAJ",
      "fKBmhcUAAAAJ",
      "LLnrH8IAAAAJ",
      "QRYX59sAAAAJ",
      "9om-fCsAAAAJ",
      "CSHNLDcAAAAJ",
      "jTnQTBoAAAAJ",
      "1Tfui8UAAAAJ",
      "IOxo6sIAAAAJ",
      "Ivot3fkAAAAJ",
      "XqAe43gAAAAJ",
      "NvMCACEAAAAJ",
      "jn5r6TsAAAAJ",
      "gYiCq88AAAAJ",
      "20_pofsAAAAJ",
      "5GLvj20AAAAJ",
      "h0pQOHgAAAAJ",
      "WzkYR-0AAAAJ",
      "NmDY9BMAAAAJ",
      "JjID4s0AAAAJ",
      "CdRAIEkAAAAJ",
      "rT11mdcAAAAJ",
      "NkzyCvUAAAAJ",
      "57XwZeYAAAAJ",
      "eaigsKkAAAAJ",
      "VJFrfM0AAAAJ",
      "HylrshMAAAAJ",
      "7CKFg9EAAAAJ",
      "JFEjS1QAAAAJ",
      "AMReihwAAAAJ",
      "N_KDBGcAAAAJ",
      "ywv6tDUAAAAJ",
      "qjgsTnwAAAAJ",
      "o7zbCEsAAAAJ",
      "qAWS07wAAAAJ",
      "2TTqpGQAAAAJ",
      "2trZ2IYAAAAJ",
      "cjUid0YAAAAJ",
      "5ErX8dMAAAAJ",
      "oxyHy1MAAAAJ",
      "c26ONgMAAAAJ",
      "4U1XK1gAAAAJ",
      "cAy9G6oAAAAJ",
      "1rM2RFoAAAAJ",
      "GQWTo4MAAAAJ",
      "Wt0ndFIAAAAJ",
      "zBdo-BoAAAAJ",
      "V358UyMAAAAJ",
      "0KF6ZC8AAAAJ",
      "vWTI60AAAAAJ",
      "yp4Gk3kAAAAJ",
      "9700p4IAAAAJ",
      "EemUE4gAAAAJ",
      "q34R9psAAAAJ",
      "Jjp8eYUAAAAJ",
      "HBtozdUAAAAJ",
      "O27t9j4AAAAJ",
      "XD_01h8AAAAJ",
      "x04W_mMAAAAJ",
      "pv54dqMAAAAJ",
      "UJb3uKgAAAAJ",
      "GvXDNsYAAAAJ",
      "TrdtzgwAAAAJ",
      "wxnzyjwAAAAJ",
      "JWmiQR0AAAAJ",
      "iYN86KEAAAAJ",
      "VOWP8TUAAAAJ",
      "nb8wjsoAAAAJ"
    ],
    "ThJ-Ju4AAAAJ": [
      "E_a3VB4AAAAJ",
      "RUP4S68AAAAJ",
      "adnTgaAAAAAJ",
      "5ZTO0uMAAAAJ",
      "j4Fshz0AAAAJ",
      "z28rttMAAAAJ",
      "3-gk0ioAAAAJ",
      "zmDJrh0AAAAJ",
      "6WYsaqMAAAAJ",
      "xuDZ9-sAAAAJ",
      "fb2-dasAAAAJ",
      "n0QrdEMAAAAJ",
      "x7viPbgAAAAJ",
      "3TlBVXkAAAAJ",
      "Klc6YZcAAAAJ",
      "0xWltyAAAAAJ",
      "umFQktIAAAAJ",
      "Z8U0BwcAAAAJ",
      "tokXOxkAAAAJ",
      "4yuKD_AAAAAJ",
      "h0_3SjAAAAAJ",
      "iTv2cOgAAAAJ",
      "IGDs4HwAAAAJ",
      "T2U5sGIAAAAJ",
      "qLtTKNwAAAAJ",
      "AB0CIBAAAAAJ",
      "Es6jE1kAAAAJ",
      "W4Y0jUIAAAAJ",
      "aXWFB2UdJUUC",
      "e3hldDEAAAAJ"
    ],
    "AEsPCAUAAAAJ": [
      "bh-uRFMAAAAJ",
      "d97bGd8AAAAJ",
      "UpZmJI0AAAAJ",
      "vtwH6GkAAAAJ",
      "dzOd2hgAAAAJ",
      "bqL73OkAAAAJ",
      "UfbuDH8AAAAJ",
      "Vzr1RukAAAAJ",
      "UdpacsMAAAAJ",
      "LW8ze_UAAAAJ",
      "-ltRSM0AAAAJ",
      "VINmGpYAAAAJ",
      "dGs2BcIAAAAJ",
      "CQEyVPMAAAAJ",
      "3Rlc8EAAAAAJ",
      "a8Y2OJMAAAAJ",
      "W8VIEZgAAAAJ",
      "TpglobcAAAAJ",
      "mqpjAt4AAAAJ",
      "2tt6ZJ0AAAAJ",
      "UAwKvEsAAAAJ",
      "ROILf3EAAAAJ",
      "IbcqwaoAAAAJ",
      "8R35rCwAAAAJ",
      "wYMTld8AAAAJ"
    ],
    "SaboshYAAAAJ": [
      "vN-is70AAAAJ",
      "p0sQC6sAAAAJ",
      "B96GkdgAAAAJ",
      "I1EvjZsAAAAJ",
      "GUAoEcAAAAAJ",
      "5JE9m1EAAAAJ",
      "X22nUYgAAAAJ",
      "Dzh5C9EAAAAJ",
      "94RFSSsAAAAJ",
      "NvKHgzkAAAAJ",
      "OeDgxpgAAAAJ",
      "Mj1QkjkAAAAJ"
    ],
    "Wewcpo4AAAAJ": [
      "rQ68pVwAAAAJ",
      "8y9rrq0AAAAJ",
      "x8UpLZUAAAAJ",
      "xvnfpkMAAAAJ",
      "XXeNb58AAAAJ",
      "7MxQd6UAAAAJ",
      "TTLOfXIAAAAJ",
      "twWX2LIAAAAJ",
      "beXm1FwAAAAJ",
      "pCe3nQgAAAAJ",
      "vyteiT4AAAAJ",
      "TnJqhXIAAAAJ",
      "-8QcdvgAAAAJ",
      "oNQRPLYAAAAJ",
      "VX7d5EQAAAAJ",
      "m1wGy3gAAAAJ",
      "zkhHirIAAAAJ",
      "0TJZPj0AAAAJ",
      "2fwi6UIAAAAJ",
      "5Rp2lKIAAAAJ",
      "KlhDpG0AAAAJ",
      "TJSHa2IAAAAJ",
      "7EoDBR0AAAAJ",
      "8t3Ex0QAAAAJ",
      "SW4wc24AAAAJ",
      "N5HDmqoAAAAJ",
      "xqyoorYAAAAJ",
      "7lP7XcMAAAAJ",
      "SC1L3uAAAAAJ",
      "DL6Gk3AAAAAJ",
      "5wiSTtUAAAAJ",
      "gkCjy_UAAAAJ",
      "eQujqDgAAAAJ",
      "_vjPh4UAAAAJ",
      "YAHWbtkAAAAJ",
      "B847xq8AAAAJ",
      "EsoKTawAAAAJ",
      "761-alkAAAAJ",
      "EaYZfmoAAAAJ",
      "sOrBUWAAAAAJ",
      "lmDy04wAAAAJ",
      "1ZHcGwIAAAAJ",
      "0YstIVMAAAAJ",
      "EIX2jGQAAAAJ",
      "Iz9v6dcAAAAJ",
      "XK_ktwQAAAAJ",
      "2Dt0VJ4AAAAJ",
      "6GDfcqEAAAAJ",
      "0gp5M-kAAAAJ",
      "X8H76XIAAAAJ",
      "KDqGTIUAAAAJ",
      "CUkAtC4AAAAJ",
      "5LubxuUAAAAJ",
      "0gkajvEAAAAJ",
      "5bQjLz4AAAAJ",
      "c4yK72IAAAAJ",
      "wWaA2QwAAAAJ",
      "qzC5Gh0AAAAJ",
      "SfN31P4AAAAJ",
      "oa78zHUAAAAJ",
      "SiCHxTkAAAAJ",
      "o_1YtVoAAAAJ",
      "nIEep3cAAAAJ",
      "yd0R-5MAAAAJ",
      "0YPGwhgAAAAJ",
      "QrXQQ2kAAAAJ",
      "-lKb3XwAAAAJ",
      "dYwbc9sAAAAJ",
      "YlmiyYkAAAAJ",
      "wnTOU6AAAAAJ",
      "wY1PiLwAAAAJ",
      "VhL7NugAAAAJ",
      "B1RixPAAAAAJ",
      "GNwyyrsAAAAJ",
      "JZ0snAcAAAAJ",
      "_CNYi6MAAAAJ",
      "rUZN-zQAAAAJ",
      "QdTErIEAAAAJ",
      "sPTruxEAAAAJ",
      "G0x9hZkAAAAJ"
    ],
    "Uly5spMAAAAJ": [
      "AEsPCAUAAAAJ",
      "8R35rCwAAAAJ",
      "vtwH6GkAAAAJ",
      "bdHgGgEAAAAJ",
      "1wLVDP4AAAAJ",
      "vfPE6hgAAAAJ",
      "zUJus70AAAAJ",
      "VINmGpYAAAAJ",
      "vYougn0AAAAJ"
    ],
    "3_toKJ4AAAAJ": [],
    "Vzr1RukAAAAJ": [],
    "MN9Kfg8AAAAJ": [
      "WXOaxKMAAAAJ",
      "bEcLezcAAAAJ",
      "im5aMngAAAAJ",
      "uDdA-r4AAAAJ",
      "Tb0ZrYwAAAAJ",
      "Odek140AAAAJ",
      "SAnJ1hIAAAAJ",
      "icbo4M0AAAAJ",
      "Sg3jtCgAAAAJ",
      "yteZM6AAAAAJ",
      "o7yFQXUAAAAJ",
      "Z_WrhK8AAAAJ",
      "SLISZFAAAAAJ",
      "UXh1I6UAAAAJ",
      "CQ1cqKkAAAAJ",
      "Rqy5KDEAAAAJ",
      "JpSx3EMAAAAJ",
      "5pKTRxEAAAAJ",
      "zmbW4iUAAAAJ",
      "JKJ99B0AAAAJ",
      "2jPsTDgAAAAJ",
      "sYixPw8AAAAJ",
      "DFqp8NkAAAAJ",
      "0d59fEcAAAAJ",
      "mKzKZfUAAAAJ",
      "GQWTo4MAAAAJ",
      "hJS2TXwAAAAJ",
      "uoDW9hkAAAAJ",
      "wlosgkoAAAAJ",
      "LKv32bgAAAAJ",
      "KTzRHmwAAAAJ",
      "nZxJGeUAAAAJ",
      "ZA0KnX0AAAAJ",
      "xhUvqK8AAAAJ",
      "xBJ-7n4AAAAJ",
      "GPRnVkMAAAAJ",
      "BKkK2DoAAAAJ",
      "HPfNU94AAAAJ",
      "HJDxXUsAAAAJ",
      "UMZrl1cAAAAJ",
      "laKl8acAAAAJ",
      "xMne5ZUAAAAJ",
      "646vnpUAAAAJ",
      "HGNZ1fkAAAAJ",
      "MgzHAPQAAAAJ",
      "W4oOmZEAAAAJ",
      "TSj_8nYAAAAJ",
      "jqHoz9EAAAAJ",
      "RljePdcAAAAJ",
      "zl70inwAAAAJ",
      "npqoAWwAAAAJ",
      "T5hu6dsAAAAJ",
      "NMIU_S4AAAAJ",
      "9lh2gH8AAAAJ",
      "5rjfy4AAAAAJ",
      "chD5XxkAAAAJ",
      "AMHNjTIAAAAJ",
      "Kz5C0p0AAAAJ",
      "v9-IuzwAAAAJ",
      "8ys-38kAAAAJ",
      "J6_5toMAAAAJ",
      "SW_WaQ0AAAAJ",
      "nxd3mDcAAAAJ",
      "pYPowr8AAAAJ",
      "d7_f7LsAAAAJ",
      "LQ5RRNkAAAAJ",
      "W1kXLwYAAAAJ",
      "LVOGjXYAAAAJ",
      "_9GX96fDWAMC",
      "GpXyLGwAAAAJ",
      "psuwztYAAAAJ",
      "r493814AAAAJ",
      "AaauqDAAAAAJ",
      "_Y_XvN4AAAAJ",
      "BbdF4ysAAAAJ",
      "OEJUgwkAAAAJ",
      "wUArfPgAAAAJ",
      "NWPDSEsAAAAJ",
      "YMaEuzoAAAAJ",
      "Q4DTPw4AAAAJ",
      "fZKJdb0AAAAJ",
      "UliV3XQAAAAJ",
      "i7V1kJgAAAAJ",
      "uvsSrnoAAAAJ",
      "YXJ-_k0AAAAJ",
      "P4G6H7oAAAAJ",
      "ZOkQ-PoAAAAJ",
      "YRbB4CgAAAAJ",
      "Bq9Osr8AAAAJ",
      "GbVC5NYAAAAJ",
      "MiI7lj0AAAAJ",
      "jQLg-_UAAAAJ",
      "KBHW5wsAAAAJ",
      "SuH4Z2gAAAAJ",
      "zyQAdTwAAAAJ",
      "e1ucbCYAAAAJ",
      "BrWvx00AAAAJ",
      "uW8JaBsAAAAJ",
      "SEDPkrsAAAAJ",
      "GgD-B68AAAAJ",
      "gcS68oUAAAAJ",
      "RPWFQlAAAAAJ",
      "l6oz33MAAAAJ",
      "yqIoH34AAAAJ",
      "D-CVv_QAAAAJ",
      "NMS69lQAAAAJ",
      "PF-7nJMAAAAJ",
      "Hd80zWMAAAAJ",
      "BF39lMQAAAAJ",
      "C3s1jqIAAAAJ",
      "DxoenfgAAAAJ",
      "8LDlwEwAAAAJ",
      "h5IXxToAAAAJ",
      "GkMfzy4AAAAJ",
      "lUnt8X4AAAAJ",
      "I0nj-TcAAAAJ",
      "cXhAfX0AAAAJ",
      "hfZRGpgAAAAJ",
      "I2LNwZgAAAAJ",
      "1lORpNsAAAAJ",
      "ej9SRrAAAAAJ",
      "lJol4lAAAAAJ",
      "lm55cKIAAAAJ",
      "hNI5rEIAAAAJ",
      "4mVPFQ8AAAAJ",
      "-xwtUkYAAAAJ",
      "HFwSkGIAAAAJ",
      "P5g-cYwAAAAJ",
      "9B8PoXUAAAAJ",
      "SEAowdYAAAAJ",
      "mXtH1UYAAAAJ",
      "CEt6_mMAAAAJ",
      "rebEn8oAAAAJ",
      "56vtsXMAAAAJ",
      "ypaqepYAAAAJ",
      "VECFLiAAAAAJ",
      "bM4pEGoAAAAJ",
      "gTuG8BsAAAAJ",
      "VGfczTIAAAAJ",
      "X57uzqcAAAAJ",
      "x-pMK90AAAAJ",
      "IKUm624AAAAJ",
      "NrOA9QoAAAAJ",
      "ITZ1e7MAAAAJ",
      "Q0piorUAAAAJ",
      "8rDNIMsAAAAJ",
      "u0eUsYsAAAAJ",
      "O8eqJA4AAAAJ",
      "Npd4ZzgAAAAJ",
      "6NFzfAgAAAAJ",
      "_M5OBVkAAAAJ",
      "HaN8b2YAAAAJ",
      "DSmxHuMAAAAJ",
      "GGHVmOsAAAAJ",
      "-GduGkcAAAAJ",
      "9fxv1zwAAAAJ",
      "jQeFWdoAAAAJ",
      "HeVcLzAAAAAJ",
      "nVsOPtQAAAAJ",
      "MnfzuPYAAAAJ",
      "abn9WWMAAAAJ",
      "SmuY2sMAAAAJ",
      "IuOS8TkAAAAJ",
      "Nd6DvD4AAAAJ",
      "8R35rCwAAAAJ",
      "DRnOvU8AAAAJ",
      "B8wslVsAAAAJ",
      "qhgWjNkAAAAJ",
      "V5FDxaAAAAAJ",
      "zx4X0fwAAAAJ",
      "MhoS1_oAAAAJ",
      "c_z5hWEAAAAJ",
      "k0ZTfQoAAAAJ"
    ],
    "BDmtLHsAAAAJ": [
      "BSORuFoAAAAJ",
      "zp8V7ZMAAAAJ",
      "H9xADK0AAAAJ",
      "kcr8134AAAAJ",
      "wwW4HRQAAAAJ",
      "KXkVpr4AAAAJ",
      "04dL0akAAAAJ",
      "KjfpioYAAAAJ",
      "l7X99s0AAAAJ",
      "CUlqK5EAAAAJ",
      "QAPgF4kAAAAJ",
      "nCZ2PMcAAAAJ",
      "gFwEytkAAAAJ",
      "KDTyloUAAAAJ",
      "QMfeRz0AAAAJ",
      "DVuM2KsAAAAJ",
      "qvRf9xsAAAAJ",
      "V9EUwCEAAAAJ",
      "bC-gapAAAAAJ",
      "PPCRqZUAAAAJ",
      "RLOXUngAAAAJ",
      "tgZPkzkAAAAJ",
      "1EW9Jt4AAAAJ",
      "TOzQO_UAAAAJ",
      "MD2-gPcAAAAJ",
      "dy_JBs0AAAAJ",
      "wYDYIYkAAAAJ",
      "cgaU4UkAAAAJ",
      "vDn8bXAAAAAJ",
      "goCW1d8AAAAJ",
      "00RihbwAAAAJ"
    ],
    "LUe32ToAAAAJ": [],
    "Dtw3YBoAAAAJ": [
      "IWPWNxkAAAAJ",
      "SupjsEUAAAAJ",
      "QMkbFp8AAAAJ",
      "ghfkSasAAAAJ",
      "Kr8JjF0AAAAJ",
      "aUeGl58AAAAJ",
      "xak5mK4AAAAJ",
      "dzyzDRIAAAAJ",
      "lTXMC44AAAAJ",
      "YMAOvHYAAAAJ",
      "iTv2cOgAAAAJ",
      "t_iLVOoAAAAJ",
      "jTMUPNkAAAAJ",
      "t8RKSJsAAAAJ",
      "xblGvQgAAAAJ",
      "BA1kFjMAAAAJ",
      "LKv32bgAAAAJ",
      "G1WMpcUAAAAJ",
      "5z2rh_oAAAAJ",
      "JSFmVQEAAAAJ",
      "ePC7IC0AAAAJ",
      "oC8YKjUAAAAJ",
      "6hsn3EYAAAAJ",
      "PnaHFhUAAAAJ",
      "2BTuWpgAAAAJ",
      "4VpTwzIAAAAJ",
      "nc6hvFgAAAAJ",
      "tBAp1-gAAAAJ",
      "haO4sKoAAAAJ",
      "E_UlAVQAAAAJ",
      "Xz4RAJkAAAAJ",
      "3VZ_E64AAAAJ",
      "IKRu39AAAAAJ",
      "9RyeFYwAAAAJ",
      "k4Q3TYwAAAAJ",
      "VUOMP_EAAAAJ",
      "a1ngrCIAAAAJ",
      "_ambxJIAAAAJ",
      "bBHxY_MAAAAJ",
      "D_d_d8wAAAAJ",
      "v1rY3BYAAAAJ",
      "V3NQnJoAAAAJ",
      "lWzkIg4AAAAJ",
      "QkpYowMAAAAJ",
      "3q8ivkoAAAAJ",
      "XOJE8OEAAAAJ",
      "ogtsTE4AAAAJ",
      "nRQi4O8AAAAJ",
      "26eh1jAAAAAJ"
    ],
    "5pKTRxEAAAAJ": [
      "ivUi2T0AAAAJ",
      "yxUduqMAAAAJ",
      "WYctQAQAAAAJ",
      "axsP38wAAAAJ",
      "TjdFs3EAAAAJ",
      "9LcxwsMAAAAJ",
      "tBbUAfsAAAAJ",
      "Wb_lnjAAAAAJ",
      "8OYE6iEAAAAJ",
      "XKCyZk0AAAAJ",
      "rDfyQnIAAAAJ",
      "mT7ppvwAAAAJ",
      "CiSdOV0AAAAJ",
      "8ys-38kAAAAJ",
      "S-pd0NwAAAAJ",
      "6HVq8KMAAAAJ",
      "vRI2blsAAAAJ",
      "Lt9LpLMAAAAJ",
      "V4LXxrQAAAAJ",
      "fEhNO7YAAAAJ",
      "qjJg6akAAAAJ",
      "nd8lQQIAAAAJ",
      "cSxeVz0AAAAJ",
      "sPtFRB8AAAAJ",
      "Tb0ZrYwAAAAJ",
      "feX1fWAAAAAJ",
      "Py54GcEAAAAJ",
      "O-tJRckAAAAJ",
      "1P8Zu04AAAAJ",
      "qQLlBH4AAAAJ",
      "mZcPPW4AAAAJ",
      "NIIQFrEAAAAJ",
      "Wj3t9l0AAAAJ",
      "Dj3gptkAAAAJ",
      "MlZq4XwAAAAJ",
      "UUKLPMYAAAAJ",
      "N9MkuMwAAAAJ",
      "60ITZUkAAAAJ",
      "bEn7ySYAAAAJ",
      "Xlv5PDYAAAAJ"
    ],
    "mu5Y2rYAAAAJ": [
      "wfGiqXEAAAAJ",
      "jEANvfgAAAAJ",
      "bh-uRFMAAAAJ",
      "0nPi5YYAAAAJ",
      "T04c3fwAAAAJ",
      "bnQMuzgAAAAJ",
      "T7uctwYAAAAJ",
      "yOcNQVgAAAAJ",
      "yFMX138AAAAJ",
      "UfbuDH8AAAAJ",
      "W8VIEZgAAAAJ",
      "ijmuZ0wAAAAJ",
      "-ltRSM0AAAAJ",
      "gYiCq88AAAAJ",
      "GL9M37YAAAAJ",
      "NkzyCvUAAAAJ",
      "nABXo3sAAAAJ",
      "mqpjAt4AAAAJ",
      "duSEbnYAAAAJ",
      "DhtAFkwAAAAJ",
      "vKlrdpEAAAAJ",
      "a8Y2OJMAAAAJ",
      "j5_DDM0AAAAJ",
      "9xDADY4AAAAJ",
      "DplAah0AAAAJ",
      "eqQQkM4AAAAJ",
      "K3QJPdMAAAAJ",
      "o37mElYAAAAJ",
      "u4olrOcAAAAJ",
      "RNj18KkAAAAJ",
      "2oB4nAIAAAAJ",
      "sUK_w2QAAAAJ",
      "0mgEF28AAAAJ",
      "ID9QePIAAAAJ",
      "0ggsACEAAAAJ",
      "CKqzOqsAAAAJ",
      "T6PbwPIAAAAJ",
      "4V1nNm4AAAAJ",
      "z5SPCmgAAAAJ",
      "6G-l4o0AAAAJ",
      "LXSkrXkAAAAJ",
      "eteU0U4AAAAJ",
      "Vs-MdPcAAAAJ",
      "f9_wq_kAAAAJ",
      "MxxZkEcAAAAJ",
      "r2E5Ak8AAAAJ",
      "fWd88tEAAAAJ",
      "bmZbi_UNs-oC",
      "jjEht8wAAAAJ",
      "7hf-iAEAAAAJ",
      "DNuiPHwAAAAJ",
      "n-B0jr4AAAAJ",
      "vXHA_XYAAAAJ",
      "3PuVdYEAAAAJ",
      "36ofBJgAAAAJ",
      "QLjltcIAAAAJ",
      "x9K4md8AAAAJ",
      "1YduZuMAAAAJ",
      "zMvBdmQAAAAJ",
      "jktWnL8AAAAJ",
      "U3Eub-EAAAAJ",
      "IyyEKyIAAAAJ",
      "Jrn-jxQAAAAJ",
      "UAwKvEsAAAAJ",
      "NiJYYkkAAAAJ",
      "1mKHwfIAAAAJ",
      "R-z1R84AAAAJ",
      "ZMLhZJ8AAAAJ",
      "s7ky8QUAAAAJ",
      "_zo4uhoAAAAJ",
      "sjF5p5wAAAAJ",
      "V358UyMAAAAJ",
      "0KF6ZC8AAAAJ",
      "vWTI60AAAAAJ",
      "EemUE4gAAAAJ",
      "q34R9psAAAAJ",
      "Jjp8eYUAAAAJ",
      "NvMCACEAAAAJ",
      "JWmiQR0AAAAJ",
      "iYN86KEAAAAJ",
      "zLjnC5MAAAAJ",
      "vtwH6GkAAAAJ",
      "1TqAq5AAAAAJ",
      "v8PeLGgAAAAJ",
      "j1okDGUAAAAJ",
      "GQWTo4MAAAAJ",
      "6CAfoBgAAAAJ",
      "meFUbHIAAAAJ",
      "NMS69lQAAAAJ",
      "TrdtzgwAAAAJ",
      "HBtozdUAAAAJ",
      "0hHqYoAAAAAJ",
      "hqNhUCYAAAAJ",
      "Jp6Mz1sAAAAJ",
      "5Iqe53IAAAAJ",
      "4GTpCxcAAAAJ",
      "rDfyQnIAAAAJ",
      "jzsx52EAAAAJ",
      "64zxhRUAAAAJ",
      "1bG8fLEAAAAJ",
      "ENJA2f8AAAAJ",
      "tWew360AAAAJ",
      "mS5k4CYAAAAJ",
      "zxFuDvsAAAAJ",
      "nh5a4LQAAAAJ",
      "-yZse64AAAAJ",
      "h1Z5hk8AAAAJ",
      "5waf3bkAAAAJ",
      "KFhCWUcAAAAJ",
      "foTQUXwAAAAJ",
      "V_VEjLUAAAAJ",
      "XKFJHycAAAAJ",
      "P28bgJMAAAAJ",
      "JFEHAwIAAAAJ",
      "vfTpaOAAAAAJ",
      "H1d4BS8AAAAJ",
      "e38fTZQAAAAJ",
      "pvyI8GkAAAAJ",
      "p9RsPG4AAAAJ",
      "QqfCvsgAAAAJ",
      "-9yiQMsAAAAJ",
      "zBdo-BoAAAAJ",
      "yp4Gk3kAAAAJ",
      "9700p4IAAAAJ",
      "W8yZCNsAAAAJ",
      "rT11mdcAAAAJ",
      "L7lMQkQAAAAJ",
      "UZ5wscMAAAAJ"
    ],
    "vboGT0EAAAAJ": [
      "Hz7KBrIAAAAJ",
      "VEkbdjcAAAAJ",
      "qbTyWP4AAAAJ",
      "cLCHds0AAAAJ",
      "B_IufdEAAAAJ",
      "IkrviqEAAAAJ",
      "4EKKyosAAAAJ",
      "HXfCKiQAAAAJ",
      "MYIW1psAAAAJ",
      "rifOKt4AAAAJ",
      "jQnTUZEAAAAJ",
      "vpo0U3QAAAAJ",
      "_k2LvcEAAAAJ",
      "nwPxp24AAAAJ",
      "JTfD4akAAAAJ",
      "-ViviVsAAAAJ",
      "aQUQU10AAAAJ",
      "5KLRGb0AAAAJ",
      "gicJpX8AAAAJ",
      "ej68QYkAAAAJ",
      "WQA9GckAAAAJ",
      "xazEr4oAAAAJ",
      "0P1J-m8AAAAJ",
      "uBial08AAAAJ",
      "Thz9yCEAAAAJ",
      "IuhidDAAAAAJ",
      "4XMv5IoAAAAJ",
      "l2IhA2IAAAAJ",
      "lvPdFJUAAAAJ",
      "-rlnZrMAAAAJ",
      "1i6vsBYAAAAJ",
      "9PvqaoEAAAAJ",
      "f8sVvG0AAAAJ",
      "ju7dyZMAAAAJ",
      "eln2A94AAAAJ",
      "deCmCVgAAAAJ",
      "fiRkCU0AAAAJ",
      "fKcFF-gAAAAJ",
      "MnBxiMsAAAAJ",
      "M2GyttIAAAAJ",
      "CM5qHwQAAAAJ"
    ],
    "wIDVzroAAAAJ": [
      "8R35rCwAAAAJ",
      "zBUwaGkAAAAJ",
      "vfPE6hgAAAAJ"
    ],
    "ZvX1hXcAAAAJ": [
      "DcV-5RAAAAAJ",
      "aO8KpGcAAAAJ",
      "Bdy3OD0AAAAJ",
      "hdTDzlQAAAAJ",
      "umivlPQAAAAJ",
      "MDfW21AAAAAJ",
      "JKVR2ksAAAAJ"
    ],
    "F_ASWCUAAAAJ": [
      "_PZKLYUAAAAJ",
      "opbZfw0AAAAJ",
      "k9uWzAIAAAAJ",
      "osxb7aMAAAAJ",
      "0lZoXCUAAAAJ",
      "YAHWbtkAAAAJ",
      "fVcFAiIAAAAJ",
      "vLbYPtwAAAAJ",
      "RUTPdHcAAAAJ",
      "wb-DKCIAAAAJ",
      "cNSbfGQAAAAJ",
      "_1hCq3UAAAAJ",
      "QxbpIMUAAAAJ",
      "JnWSU4oAAAAJ",
      "B_rKfusAAAAJ"
    ],
    "7ShMBcwAAAAJ": [
      "8R35rCwAAAAJ",
      "vfPE6hgAAAAJ",
      "vtwH6GkAAAAJ",
      "EBNa5IEAAAAJ",
      "T9To2C0AAAAJ",
      "Nn990CkAAAAJ",
      "9EnJFEEAAAAJ",
      "zvz6LIYAAAAJ",
      "BOAOkNQAAAAJ",
      "wjRRS3YAAAAJ",
      "vYougn0AAAAJ",
      "_Uzh_ucAAAAJ",
      "4PMCkasAAAAJ",
      "JjID4s0AAAAJ",
      "nxd3mDcAAAAJ",
      "lsbreWwAAAAJ",
      "YGQs1AYAAAAJ",
      "lRUi-A8AAAAJ",
      "ADkiClQAAAAJ",
      "yy0UFOwAAAAJ"
    ],
    "5JE9m1EAAAAJ": [
      "I1EvjZsAAAAJ",
      "vN-is70AAAAJ",
      "GUAoEcAAAAAJ",
      "p0sQC6sAAAAJ",
      "Bl8GgEcAAAAJ",
      "SaboshYAAAAJ",
      "X22nUYgAAAAJ",
      "Dzh5C9EAAAAJ",
      "CZa9GB4AAAAJ",
      "jo2C_wkAAAAJ",
      "B96GkdgAAAAJ",
      "ae1ve-EAAAAJ",
      "1FrpQaQAAAAJ",
      "mQf5cE0AAAAJ",
      "dB6ftCcAAAAJ",
      "YsXNU78AAAAJ",
      "5LLV29oAAAAJ",
      "0P35aLUAAAAJ",
      "WXbhp_4AAAAJ",
      "TuT3_UwAAAAJ",
      "9rAYhr8AAAAJ",
      "FnD5B1QAAAAJ",
      "xhbf6_oAAAAJ",
      "HUIAm4UAAAAJ",
      "PkfChMgAAAAJ",
      "HCHLK5wAAAAJ",
      "hCbFmUUAAAAJ",
      "ywWy5NIAAAAJ"
    ],
    "fNOReswAAAAJ": [
      "m_HQ-WQAAAAJ",
      "DYUloYkAAAAJ",
      "HU1K_zsAAAAJ",
      "D83Vz00AAAAJ",
      "J6LkBeUAAAAJ",
      "YAHWbtkAAAAJ",
      "k8nSlL4AAAAJ",
      "utY1nToAAAAJ",
      "1IPn2HgAAAAJ",
      "qlKWTsUAAAAJ",
      "TJF5CosAAAAJ",
      "9vumoioAAAAJ",
      "TeuEgRkAAAAJ",
      "lH1PdF8AAAAJ",
      "c_z5hWEAAAAJ",
      "WLN3QrAAAAAJ",
      "5MeSMfAAAAAJ",
      "JSkBINwAAAAJ"
    ],
    "p9RsPG4AAAAJ": [
      "0kV69XQAAAAJ",
      "bniKGtgAAAAJ",
      "fi4HWW8AAAAJ",
      "9xDADY4AAAAJ",
      "w8JK9v0AAAAJ",
      "TmWYBeEAAAAJ",
      "qnwjcfAAAAAJ",
      "4kOdChQAAAAJ",
      "8BeTDr0AAAAJ",
      "bh-uRFMAAAAJ",
      "Xnk4W5cAAAAJ",
      "5222Mu8AAAAJ",
      "3kDtybgAAAAJ",
      "jTUvYSAAAAAJ",
      "KxmUmKkAAAAJ",
      "h9E2XBi3aTAC",
      "MeZLMbkAAAAJ",
      "RY7cuPAAAAAJ",
      "tJGm3-YAAAAJ",
      "-mHoWKEAAAAJ",
      "UfbuDH8AAAAJ",
      "v7kFHRoAAAAJ",
      "M7EpKqsAAAAJ",
      "8hxMm5UAAAAJ",
      "okf5bmQAAAAJ",
      "AdSEuYcAAAAJ",
      "w_GMSlcAAAAJ",
      "pvyI8GkAAAAJ",
      "eIRG81YAAAAJ",
      "YH7PDvEAAAAJ",
      "jkV6H1gAAAAJ",
      "DEtQ_YAAAAAJ",
      "gYiCq88AAAAJ",
      "zyqZgm8AAAAJ",
      "cTPU9HcAAAAJ",
      "KjR3yVQAAAAJ",
      "SUAbOcgAAAAJ",
      "bxAIuu4AAAAJ",
      "ScxqPn4AAAAJ",
      "xBv5ZfkAAAAJ",
      "bOM9qN8AAAAJ",
      "FABZCeAAAAAJ",
      "vlDYiZoAAAAJ",
      "okcbLqoAAAAJ",
      "eml8HfQAAAAJ",
      "H50SekAAAAAJ",
      "VSc-eTAAAAAJ",
      "OZKad_UAAAAJ",
      "-Km63D4AAAAJ",
      "tT9mhNMAAAAJ",
      "D0pzuNoAAAAJ",
      "8ys-38kAAAAJ",
      "Q4DTPw4AAAAJ",
      "3dxS1VYAAAAJ",
      "3HSzhHoAAAAJ",
      "9ZRcemUAAAAJ",
      "TH5szrcAAAAJ",
      "3HAa8ni1oGUC",
      "JYaJjE8AAAAJ",
      "cbm9vaUAAAAJ",
      "CLZ9dLoAAAAJ",
      "22TE5qkAAAAJ",
      "pamL_rIAAAAJ",
      "X3JCGVIAAAAJ",
      "rIh5OqoAAAAJ",
      "ex9BQiIAAAAJ",
      "NFJ9kUEAAAAJ",
      "Pd8-ju0AAAAJ",
      "J2Z-ChoAAAAJ",
      "V49BsgMAAAAJ",
      "u11FXaoAAAAJ",
      "s0OErVYAAAAJ",
      "rs1M7CAAAAAJ",
      "AvH7tJwAAAAJ",
      "bG5-ZzIAAAAJ",
      "AIncPrIAAAAJ",
      "iAG5Mj0AAAAJ",
      "k5NbHlEAAAAJ",
      "FuOqWNEAAAAJ",
      "GwR1fdsAAAAJ",
      "23uzLe0AAAAJ",
      "Vj8SG_oAAAAJ",
      "_X6fpR8AAAAJ",
      "naoTbnIAAAAJ",
      "NvIcXEYAAAAJ",
      "OxrRSKsAAAAJ",
      "1S7VwIcAAAAJ",
      "H1XVLwsAAAAJ",
      "Dl949GoAAAAJ",
      "8PUwH9gAAAAJ",
      "1-pt7zMAAAAJ",
      "n2ohF50AAAAJ",
      "9rHwD8wAAAAJ",
      "ZzURcb4AAAAJ",
      "ljDY868AAAAJ",
      "X6UshLwAAAAJ",
      "KOrhfVMAAAAJ",
      "DxyeQ5L6RTkJ",
      "PCDSl2sAAAAJ",
      "aMxXkWkAAAAJ",
      "OM1hDLcAAAAJ",
      "F--ov6gAAAAJ",
      "0fA9EQcAAAAJ",
      "Jp6Mz1sAAAAJ",
      "qxkui7UAAAAJ",
      "ABPKRkAAAAAJ",
      "k4oSgRkAAAAJ",
      "hdXvVdgAAAAJ",
      "69JJbWoAAAAJ",
      "M4AKMC4AAAAJ",
      "bRGcMbIAAAAJ",
      "hIETYPwAAAAJ",
      "9uWuZkUAAAAJ",
      "0cAcheMAAAAJ",
      "jN2DeKcAAAAJ",
      "hEhQmT8AAAAJ",
      "xXQq8AIAAAAJ",
      "1V8AeXYAAAAJ",
      "3D_o3JUAAAAJ",
      "XOJE8OEAAAAJ",
      "L6xKfHkAAAAJ",
      "KXSlX3sAAAAJ",
      "HtNfeKYAAAAJ",
      "NRQftjIAAAAJ",
      "tUTVVjAAAAAJ",
      "DSEH8XsAAAAJ",
      "idOI-IAAAAAJ",
      "jyF9UHAAAAAJ",
      "KGgOhbAAAAAJ",
      "JL5DcncAAAAJ",
      "ijpYJQwAAAAJ",
      "8cxDHS4AAAAJ",
      "_bs7PqgAAAAJ",
      "CYI6cKgAAAAJ",
      "vW3djsoAAAAJ",
      "f1lspM0AAAAJ",
      "9xLaU5MAAAAJ",
      "j7ZI1WUAAAAJ",
      "2TUruWMAAAAJ",
      "RiiYXH0AAAAJ",
      "ns4fY0sAAAAJ",
      "dDr8RIgAAAAJ",
      "hGM6Go4AAAAJ",
      "UB5EoOEAAAAJ",
      "dPsQR14AAAAJ",
      "CAfsMIsAAAAJ",
      "_EJDz50AAAAJ",
      "C0kDOzcAAAAJ",
      "pWJ0SocAAAAJ",
      "R-Cc2h8AAAAJ",
      "Ihyz20wAAAAJ",
      "Um4ZbbgAAAAJ",
      "bQzoxtsAAAAJ",
      "C3NuO-AAAAAJ",
      "K931JfEAAAAJ",
      "f1feDTMAAAAJ",
      "-d6aNP0AAAAJ",
      "7l1HdzYAAAAJ",
      "-mEAM68AAAAJ",
      "ppaEV-8AAAAJ"
    ],
    "8-p9CLsAAAAJ": [
      "vtwH6GkAAAAJ",
      "8R35rCwAAAAJ",
      "vfPE6hgAAAAJ",
      "OFlBL2kAAAAJ",
      "itSa94cAAAAJ",
      "iVLAQysAAAAJ",
      "8fztli4AAAAJ",
      "xOWBOKQAAAAJ",
      "ExXP2_AAAAAJ",
      "LW8ze_UAAAAJ",
      "EMDboA4AAAAJ",
      "NpOg5soAAAAJ",
      "YYT8-7kAAAAJ",
      "1wLVDP4AAAAJ",
      "DkUUhXEAAAAJ",
      "DNQTSwsAAAAJ",
      "cCYTVWQAAAAJ",
      "wtRVnsYAAAAJ",
      "3dYhzNQAAAAJ",
      "Ivot3fkAAAAJ",
      "jERkdhIAAAAJ",
      "Tsh90D8AAAAJ",
      "4mVPFQ8AAAAJ",
      "eurA6WgAAAAJ",
      "nABXo3sAAAAJ",
      "VjsNXysAAAAJ",
      "lsbreWwAAAAJ",
      "HmCZLyoAAAAJ",
      "MGXJkIAAAAAJ"
    ],
    "OSg3D9MAAAAJ": [
      "UAwKvEsAAAAJ",
      "FWJZYMYAAAAJ",
      "eJt6cSIAAAAJ",
      "aDKi5l8AAAAJ",
      "WOAlvmoAAAAJ",
      "oX7L_mMAAAAJ",
      "N_rVVG8AAAAJ",
      "qiFEpzIAAAAJ",
      "HM_8xZYAAAAJ",
      "xSavR6cAAAAJ",
      "PRtkZzYAAAAJ",
      "5mJDXjoAAAAJ",
      "bbfGi6sAAAAJ",
      "ncbyhdMAAAAJ",
      "N1Gjo24AAAAJ",
      "zyR_DF4AAAAJ",
      "MfGgaT0AAAAJ",
      "Ns8jBNsAAAAJ",
      "zLjnC5MAAAAJ",
      "fJsSvzkAAAAJ",
      "XpO6-kEAAAAJ",
      "euc0GX4AAAAJ"
    ],
    "yA4rb60AAAAJ": [
      "d97bGd8AAAAJ",
      "UdpacsMAAAAJ",
      "ROILf3EAAAAJ",
      "Db4BCX8AAAAJ",
      "WZfM0qsAAAAJ",
      "8vs5HGYAAAAJ",
      "06rffEkAAAAJ",
      "dzOd2hgAAAAJ",
      "f_fKey0AAAAJ",
      "8cxDHS4AAAAJ",
      "RCTeTV0AAAAJ",
      "75x4pdcAAAAJ",
      "0MiPsosAAAAJ",
      "pamL_rIAAAAJ",
      "ISRNX3gAAAAJ",
      "VRsNu-EAAAAJ",
      "RY7cuPAAAAAJ",
      "4GTpCxcAAAAJ",
      "uqWkLzMAAAAJ"
    ],
    "q4zv0KYAAAAJ": [
      "ho_asq8AAAAJ",
      "0lZoXCUAAAAJ",
      "_1hCq3UAAAAJ",
      "YAHWbtkAAAAJ",
      "4yuKD_AAAAAJ",
      "dGuYytYAAAAJ",
      "aLdQvEAAAAAJ",
      "h2hT0XcAAAAJ",
      "_21CagYAAAAJ",
      "5t2myD8AAAAJ",
      "1Lozhc4AAAAJ",
      "q3EGms8AAAAJ",
      "lPM8k54AAAAJ",
      "5ZTO0uMAAAAJ",
      "kW-hl3YAAAAJ",
      "MCZpAkEAAAAJ",
      "nscLxl4AAAAJ",
      "R_bC8bkAAAAJ",
      "JDMpCRAAAAAJ"
    ],
    "-zaDQ10AAAAJ": [
      "TKmKZSAAAAAJ",
      "0LEOL50AAAAJ"
    ],
    "hiGI9v0AAAAJ": [],
    "gFLW9qcAAAAJ": [
      "8OYE6iEAAAAJ",
      "yxUduqMAAAAJ",
      "88cU_4UAAAAJ",
      "p_P5DAcAAAAJ",
      "ZZwLZ8UAAAAJ",
      "6mD3I24AAAAJ",
      "OkOGR_8AAAAJ"
    ],
    "ExXP2_AAAAAJ": [
      "vtwH6GkAAAAJ",
      "8-p9CLsAAAAJ",
      "itSa94cAAAAJ",
      "EMDboA4AAAAJ",
      "8fztli4AAAAJ",
      "YYT8-7kAAAAJ"
    ],
    "lMkTx0EAAAAJ": [
      "jWWx33IAAAAJ",
      "32w7x1cAAAAJ",
      "DZ-fHPgAAAAJ",
      "kbN88gsAAAAJ",
      "ETU-ePAAAAAJ",
      "2PIkUqgAAAAJ",
      "VeRSO8EAAAAJ",
      "ri1sE34AAAAJ",
      "u3-FxUgAAAAJ",
      "pfqzHqUAAAAJ",
      "plt2_DsAAAAJ",
      "tYro5N8AAAAJ",
      "Q0piorUAAAAJ",
      "vtegaJgAAAAJ",
      "yXdK2wYAAAAJ",
      "vYRgxJ8AAAAJ",
      "22TE5qkAAAAJ",
      "8LN5NoQAAAAJ",
      "GfcBlpUAAAAJ",
      "e25-lgUAAAAJ",
      "3b0l5LEAAAAJ",
      "Vs-MdPcAAAAJ",
      "kukA0LcAAAAJ",
      "EgVWuhAAAAAJ",
      "UwLsYw8AAAAJ",
      "v8QhiOwAAAAJ",
      "GgQ9GEkAAAAJ",
      "tQuQ1FwAAAAJ",
      "sGFyDIUAAAAJ",
      "Fg7TcjEAAAAJ",
      "jplQac8AAAAJ",
      "8FfrHw0AAAAJ",
      "eXKdSu0AAAAJ",
      "VBXG4CwAAAAJ",
      "I1fl4oAAAAAJ",
      "dto2FacAAAAJ",
      "Tb0ZrYwAAAAJ",
      "_VhMIOIAAAAJ",
      "xpwMxy8AAAAJ",
      "aZALISYAAAAJ",
      "icweOB0AAAAJ",
      "_WnkXlkAAAAJ",
      "WLN3QrAAAAAJ",
      "KjOV76MAAAAJ",
      "ataejQQAAAAJ",
      "WgAGy7wAAAAJ",
      "lcOacs8AAAAJ",
      "WmH1GQoAAAAJ",
      "ktwwLjsAAAAJ",
      "U_IVY50AAAAJ",
      "k8Rs4JcAAAAJ",
      "OUv7J6QAAAAJ",
      "jNCbl2IAAAAJ",
      "RuvHkikAAAAJ",
      "GSHmKZkAAAAJ"
    ],
    "wMcPTbEAAAAJ": [
      "vfPE6hgAAAAJ",
      "AEsPCAUAAAAJ",
      "aOklxsQAAAAJ",
      "neGbgzYAAAAJ",
      "8R35rCwAAAAJ",
      "Qzss0GEAAAAJ",
      "Al8dyb4AAAAJ"
    ],
    "8iCb2TwAAAAJ": [
      "8PiZdy4AAAAJ",
      "cNLW5O4AAAAJ",
      "bLb3VdIAAAAJ",
      "CkfQy2gAAAAJ",
      "B8wslVsAAAAJ",
      "jsy-VxMAAAAJ",
      "P_luG3cAAAAJ",
      "DgLEyZgAAAAJ",
      "ndv95w0AAAAJ",
      "Ytp9oFQAAAAJ",
      "BEBccCQAAAAJ",
      "Sc7qOfcAAAAJ",
      "Nq0dVMcAAAAJ",
      "vKDycp8AAAAJ",
      "m7Jr-b4AAAAJ",
      "eg6u4X8AAAAJ"
    ],
    "r81Ss1cAAAAJ": [
      "OMo39G8AAAAJ",
      "o5YQMkMAAAAJ",
      "2uwoiuIAAAAJ",
      "G0JugenpCgwC",
      "xT8PQ0IAAAAJ",
      "WXV9HW4AAAAJ",
      "P4nfoKYAAAAJ",
      "5PS-lv8AAAAJ",
      "bh-uRFMAAAAJ",
      "BCGgwlEAAAAJ",
      "6-YuY60AAAAJ"
    ],
    "xaYqRfAAAAAJ": [
      "a58cNycAAAAJ",
      "3zP4ag0AAAAJ",
      "HEO-wOQAAAAJ",
      "BAD30S8AAAAJ",
      "_FeYgnUAAAAJ",
      "85XK-uAAAAAJ",
      "QpTmnC4AAAAJ",
      "Q-dQhygAAAAJ",
      "OcjvsmoAAAAJ",
      "eTOMoMYAAAAJ",
      "2B_o_MIAAAAJ",
      "U66RsYsAAAAJ",
      "ZYoaQYcAAAAJ",
      "qPtFfKAAAAAJ",
      "N3wwcYYAAAAJ",
      "gzn3C3oAAAAJ",
      "49PCVw0AAAAJ",
      "yvWIqcQAAAAJ",
      "1-6y9qoAAAAJ",
      "SFffUYgAAAAJ",
      "8n5W2FMAAAAJ",
      "PlOGerYAAAAJ",
      "5nn3fN0AAAAJ",
      "nQjxbScAAAAJ",
      "i17FWMMAAAAJ",
      "gl3ZczYAAAAJ",
      "pTEtZCYAAAAJ",
      "c7GoaV8AAAAJ",
      "Ai1cvB8AAAAJ",
      "38fYqeYAAAAJ",
      "PM5ZWS4AAAAJ",
      "QLuPP70AAAAJ",
      "HTfEll0AAAAJ",
      "Uq4lu9YAAAAJ",
      "cPcOoY4AAAAJ",
      "Sn8fzegAAAAJ",
      "g2HE3PsAAAAJ",
      "ozaonZMAAAAJ",
      "HiyW7J4AAAAJ",
      "QsI17JQAAAAJ",
      "bCuYVE4AAAAJ",
      "ZN0NeWMAAAAJ",
      "KED9FsgAAAAJ",
      "jFnb_-EAAAAJ",
      "tX56UKEAAAAJ",
      "3i8wNscAAAAJ",
      "axvGyXoAAAAJ",
      "9QmGHaYAAAAJ",
      "VSI-8CwAAAAJ",
      "XeDtzHEAAAAJ",
      "KgZxzjsAAAAJ",
      "O2gmsKAAAAAJ",
      "5IFSlsIAAAAJ",
      "UnDvzw0AAAAJ",
      "V9KyKCwAAAAJ",
      "Ga4j7UIAAAAJ",
      "vtwH6GkAAAAJ",
      "tW21GGYAAAAJ",
      "kosv_k0AAAAJ",
      "KWH1qbsAAAAJ",
      "5F5LBT8AAAAJ",
      "arXWx_oAAAAJ",
      "HIcgaZEAAAAJ",
      "ASLQHz8AAAAJ",
      "Ab_XjfQAAAAJ",
      "ImQ7ceQAAAAJ",
      "GuhpBxMAAAAJ",
      "Z21g5_wAAAAJ",
      "cyp0fCAAAAAJ",
      "ZOF0KysAAAAJ",
      "IH3HEbkAAAAJ",
      "j4XdW_EAAAAJ",
      "VnJUnMoAAAAJ",
      "HuZ6F6QAAAAJ",
      "hEOInHkAAAAJ",
      "l1uvSZIAAAAJ",
      "Z_WO2w0AAAAJ",
      "OVkZUYoAAAAJ",
      "CmoWrcIAAAAJ",
      "lueKv2oAAAAJ",
      "Zhb-VjwAAAAJ",
      "7aJVFS8AAAAJ",
      "rXqA5nYAAAAJ",
      "tGK7hLEAAAAJ",
      "i5FepLsAAAAJ",
      "E8aZ_q4AAAAJ",
      "kdi99YAAAAAJ",
      "8MJh6JcAAAAJ",
      "XC3nc68AAAAJ",
      "rvIjH9IAAAAJ",
      "60HNWsYAAAAJ",
      "8juM0fYAAAAJ",
      "0IzM_20AAAAJ",
      "53OPcJ4AAAAJ",
      "19xIGUUAAAAJ",
      "WmFoofMAAAAJ",
      "Sql50pkAAAAJ",
      "HSlEhqwAAAAJ",
      "R1eV0ekAAAAJ",
      "DyABVI0AAAAJ",
      "cDduRqwAAAAJ",
      "l4lTuMcAAAAJ",
      "fIEuk78AAAAJ",
      "asmcUBEAAAAJ",
      "BTn-nikAAAAJ",
      "OJPj4t0AAAAJ",
      "MDDx3Q4AAAAJ",
      "ReXgGMEAAAAJ",
      "s5Aqlw4AAAAJ",
      "rupmL3kAAAAJ",
      "0iktJ5sAAAAJ",
      "5br3h-UAAAAJ",
      "TaZaMGkAAAAJ",
      "y_PW-TcAAAAJ"
    ],
    "tk3X1QkAAAAJ": [
      "5hlRYCIAAAAJ",
      "eXnKggEAAAAJ",
      "vh0_vJ4AAAAJ",
      "LZUyMg8AAAAJ",
      "qU1NHTwAAAAJ",
      "NTozWbQAAAAJ",
      "izeB4QsAAAAJ",
      "Pgor6i8AAAAJ",
      "u7oMoQMAAAAJ",
      "NAGHvJIAAAAJ",
      "HeaQbWsAAAAJ",
      "zXsQ3CkAAAAJ",
      "JJWWPjsAAAAJ",
      "twSIZSEAAAAJ",
      "JHNm8PMAAAAJ",
      "yCaVmHIAAAAJ",
      "iAEBIB4AAAAJ",
      "bgpBDU4AAAAJ",
      "raAzOHoAAAAJ",
      "ePfXtkoAAAAJ",
      "oZGA-rAAAAAJ",
      "uMPWVtIAAAAJ",
      "kRdfhVQAAAAJ",
      "QKw1XxAAAAAJ",
      "KhAJWroAAAAJ",
      "H_e0wfMAAAAJ",
      "H28xhwQAAAAJ",
      "b4NaZMoAAAAJ",
      "Snxa14EAAAAJ",
      "Tlm978oAAAAJ",
      "aajhzaQAAAAJ",
      "vtwH6GkAAAAJ",
      "8fztli4AAAAJ",
      "mqpjAt4AAAAJ",
      "HcB81j4AAAAJ",
      "m1eoR-cAAAAJ",
      "Hm0UA64AAAAJ",
      "LxsF51oAAAAJ",
      "ItkapK8AAAAJ",
      "WsNt9VoAAAAJ",
      "5u4IlBYAAAAJ",
      "cplKIP8AAAAJ",
      "SJctjYgAAAAJ",
      "wC19wG0AAAAJ",
      "lrOLKgQAAAAJ",
      "JEwMX6wAAAAJ",
      "kzFmAkYAAAAJ",
      "2mOtJU4AAAAJ",
      "1GgfFDUAAAAJ",
      "pn1-9nIAAAAJ",
      "vdMXuXgAAAAJ",
      "TucFZBUAAAAJ",
      "PvoHev4AAAAJ",
      "joagTAoAAAAJ",
      "9UAk6Y0AAAAJ"
    ],
    "5lB_d78AAAAJ": [
      "gxoPfIYAAAAJ",
      "RCi98EAAAAAJ",
      "7t4jbPQAAAAJ",
      "-lONjNgAAAAJ",
      "of_W1_MAAAAJ",
      "ucSLToQAAAAJ",
      "-ki9u4sAAAAJ",
      "238DAAEAAAAJ",
      "IxCZDBQAAAAJ",
      "WFgFAB8AAAAJ",
      "PryclcMAAAAJ",
      "uIBzJWIAAAAJ",
      "4D1n8scAAAAJ",
      "wCNY8ZYAAAAJ",
      "m4QAC_EAAAAJ",
      "kXB8FBoAAAAJ",
      "9W1jAhEAAAAJ",
      "N_vPIhoAAAAJ",
      "gd8q19oAAAAJ",
      "th3BO8MAAAAJ",
      "DJ6mzSUAAAAJ",
      "xRuVTW4AAAAJ",
      "vPnu7C4AAAAJ",
      "HPoaHyQAAAAJ",
      "W7yeGUoAAAAJ"
    ],
    "H3Uq3FcAAAAJ": [],
    "2ylcZSsAAAAJ": [
      "nQ7Ij30AAAAJ",
      "Uva82JYAAAAJ",
      "pCOmQzsAAAAJ",
      "6_i63vgAAAAJ",
      "xSC3VSAAAAAJ",
      "Actb5ZYAAAAJ",
      "7zk-lgMAAAAJ",
      "rRJ9wTJMUB8C",
      "o_ARklQAAAAJ",
      "QZW0vl8AAAAJ",
      "UAwKvEsAAAAJ",
      "IIci8lAAAAAJ",
      "d1oQ8NcAAAAJ",
      "LZxqcX4AAAAJ",
      "95mnc80AAAAJ",
      "jNtH2WUAAAAJ",
      "1h_mxPMAAAAJ",
      "kpcjFekAAAAJ",
      "3oUgDKQAAAAJ",
      "UgHB5oAAAAAJ",
      "hhm6ZzUAAAAJ",
      "KgZxzjsAAAAJ",
      "HvjirogAAAAJ",
      "79k7bGEAAAAJ",
      "6nKHDKYAAAAJ",
      "KKVV2nMAAAAJ",
      "_9pmXcsAAAAJ",
      "Op4nexcAAAAJ",
      "aXNBOywAAAAJ",
      "z7inLV8AAAAJ",
      "lXiXiHAAAAAJ",
      "4wcx4HMAAAAJ",
      "Lkl8nQYAAAAJ",
      "KqVuUA0AAAAJ",
      "GzqY7SAAAAAJ",
      "LAv0HTEAAAAJ",
      "2tt6ZJ0AAAAJ",
      "qa4M89wAAAAJ",
      "QOmjMZ0AAAAJ",
      "22LTQSMAAAAJ",
      "SZ3_FMQAAAAJ",
      "kcTK_FAAAAAJ",
      "8Qv3HRoAAAAJ",
      "S9xCl8EAAAAJ",
      "eurA6WgAAAAJ",
      "NkzyCvUAAAAJ",
      "syjQhAMAAAAJ",
      "3pyzQQ8AAAAJ",
      "SBTxvCoAAAAJ",
      "fwKsGokAAAAJ",
      "RahgPAEAAAAJ",
      "lpswgyIAAAAJ",
      "0dR_wD0AAAAJ",
      "HEozmkMAAAAJ",
      "4mVPFQ8AAAAJ",
      "iyD9aw8AAAAJ",
      "sfvCNiEAAAAJ",
      "-cCry1cAAAAJ",
      "Ksz7c7YAAAAJ",
      "K4OcFXUAAAAJ",
      "dD-3S4QAAAAJ",
      "1zCDX_UAAAAJ",
      "K1GoYW8AAAAJ",
      "JscQvlUAAAAJ",
      "c_ssivMAAAAJ",
      "2oy3OXYAAAAJ",
      "Z1OtYmAAAAAJ",
      "4MrZ9zMAAAAJ",
      "dErAioMAAAAJ",
      "OUpIbcQAAAAJ",
      "dxwPYhQAAAAJ",
      "NUv7u80AAAAJ",
      "Jv1FrfwAAAAJ",
      "AiH3_CkAAAAJ",
      "O7MZStwAAAAJ",
      "jWIWqfcAAAAJ",
      "zLjnC5MAAAAJ",
      "AEsPCAUAAAAJ",
      "UpZmJI0AAAAJ",
      "cIlDEugAAAAJ",
      "jM6Y0yAAAAAJ",
      "DdFjaEEAAAAJ",
      "XcRQkcEAAAAJ",
      "uebYofUAAAAJ",
      "fMN7wNwAAAAJ",
      "oX7L_mMAAAAJ",
      "9-eaUCMAAAAJ",
      "8RgDBoEAAAAJ",
      "mnVqk28AAAAJ",
      "5SF-hRsAAAAJ",
      "IpkkT5oAAAAJ",
      "d0TfP8EAAAAJ",
      "eJt6cSIAAAAJ",
      "74Cj5GYAAAAJ",
      "_y14JooAAAAJ",
      "FF6YBwwAAAAJ",
      "TJEUdh4AAAAJ",
      "RJeVHPYAAAAJ",
      "eEGGCiUAAAAJ",
      "eM916YMAAAAJ",
      "MfGgaT0AAAAJ",
      "88xDcnoAAAAJ",
      "ftEx984AAAAJ",
      "XnUZEcoAAAAJ",
      "mM_5lrMAAAAJ"
    ],
    "-gJkPHIAAAAJ": [
      "8R35rCwAAAAJ",
      "zBUwaGkAAAAJ",
      "T9To2C0AAAAJ",
      "C-ZlBWMAAAAJ",
      "bYjKaowAAAAJ",
      "1O83J5MAAAAJ",
      "Lncr-VoAAAAJ",
      "8xSYX9IAAAAJ",
      "yZbch0cAAAAJ",
      "VT7peyEAAAAJ",
      "neGbgzYAAAAJ",
      "Q6F3O0sAAAAJ",
      "WjCG3owAAAAJ",
      "JWmiQR0AAAAJ",
      "vfPE6hgAAAAJ",
      "mxiO4IkAAAAJ",
      "YdHW1ycAAAAJ",
      "wfGiqXEAAAAJ",
      "-3zYIjQAAAAJ",
      "QkYiDCwAAAAJ",
      "WuWWdKcAAAAJ",
      "3Y4egcYAAAAJ",
      "Se68XecAAAAJ",
      "i5FMLA4AAAAJ",
      "TqUN-LwAAAAJ",
      "O7MZStwAAAAJ",
      "68hTs9wAAAAJ",
      "79k7bGEAAAAJ",
      "QESJSgMAAAAJ",
      "Xc4IOBEAAAAJ",
      "-OVm5iMAAAAJ",
      "F36qnN0AAAAJ",
      "Yc94070AAAAJ",
      "JicYPdAAAAAJ",
      "y-nUzMwAAAAJ",
      "FM2DTXwAAAAJ",
      "Es2BBeYAAAAJ",
      "H2JX-RQAAAAJ",
      "cojpd10AAAAJ"
    ],
    "Yxh9WWoAAAAJ": [
      "8fztli4AAAAJ",
      "p0sQC6sAAAAJ",
      "fKV65XQAAAAJ",
      "X53rkecAAAAJ",
      "vtwH6GkAAAAJ",
      "vN-is70AAAAJ",
      "biuxbRsAAAAJ",
      "YG6mTEIAAAAJ",
      "ivApfKcAAAAJ",
      "yxUduqMAAAAJ",
      "bh-uRFMAAAAJ",
      "GFQzUKoAAAAJ",
      "UgHB5oAAAAAJ"
    ],
    "4D1n8scAAAAJ": [
      "V4OPEAgAAAAJ",
      "uIBzJWIAAAAJ",
      "PnaHFhUAAAAJ",
      "J5Nwk-UAAAAJ",
      "1PEHzesAAAAJ",
      "hH3DA2YAAAAJ",
      "Zq4ioqu5yb8C",
      "WFgFAB8AAAAJ",
      "FlY-U3kAAAAJ",
      "DSgKHOQAAAAJ",
      "aSJthdEAAAAJ",
      "LHkrpqEAAAAJ",
      "hma0WFAAAAAJ",
      "gxoPfIYAAAAJ",
      "IHPRZuMAAAAJ",
      "Kr8JjF0AAAAJ",
      "T0qnS1oAAAAJ",
      "ShGrv3kAAAAJ",
      "bh-uRFMAAAAJ",
      "4F9L0-cAAAAJ",
      "XBjhKdoAAAAJ",
      "xlSoLCYAAAAJ",
      "jyxO2akAAAAJ",
      "B3ywvIcAAAAJ",
      "iOLC30YAAAAJ",
      "IWPWNxkAAAAJ",
      "Dtw3YBoAAAAJ",
      "SupjsEUAAAAJ",
      "Xy8kb5gAAAAJ",
      "ZaJEZpYAAAAJ",
      "PryclcMAAAAJ",
      "Jp6Mz1sAAAAJ",
      "E_UlAVQAAAAJ",
      "B2U8EUwAAAAJ",
      "nek5vXMAAAAJ",
      "-EqbTXoAAAAJ",
      "5lB_d78AAAAJ",
      "YOVZiJkAAAAJ",
      "jB66t5YAAAAJ",
      "9huOSj4AAAAJ",
      "7Xko5sYAAAAJ",
      "Xz4RAJkAAAAJ",
      "1hqOg28AAAAJ",
      "9nnDvooAAAAJ",
      "ogXTOZ4AAAAJ",
      "rjqOWi4AAAAJ",
      "SC9wV2kAAAAJ",
      "EsIJmL0AAAAJ",
      "UXh1I6UAAAAJ",
      "wCZbouUAAAAJ",
      "-pu6i_4AAAAJ",
      "QKhjs2YAAAAJ",
      "nVWQwHkAAAAJ",
      "eUW2DUEAAAAJ",
      "DpLFv4gAAAAJ",
      "HqGW4HIAAAAJ",
      "FUOEBDUAAAAJ",
      "qWGk7FUAAAAJ",
      "APgaFK0AAAAJ",
      "Ec8g_QwAAAAJ",
      "Ao4gtsYAAAAJ",
      "-fUDeigAAAAJ",
      "7mrPM4kAAAAJ",
      "ZoW-xfcAAAAJ",
      "lQn_FEoAAAAJ"
    ],
    "eVYhlDQAAAAJ": [
      "8R35rCwAAAAJ",
      "VT7peyEAAAAJ",
      "52T2LYoAAAAJ",
      "vtwH6GkAAAAJ",
      "1wLVDP4AAAAJ",
      "1O83J5MAAAAJ",
      "neGbgzYAAAAJ",
      "C2_ZXdcAAAAJ",
      "9zeEI-cAAAAJ",
      "vfPE6hgAAAAJ",
      "vYougn0AAAAJ",
      "rFcdDJEAAAAJ",
      "lEzcLFwAAAAJ",
      "WsRunnEAAAAJ",
      "bHsjbLwAAAAJ",
      "yMGBji4AAAAJ",
      "7TVJf1gAAAAJ",
      "2m-p8FcAAAAJ",
      "9b64ixMAAAAJ"
    ],
    "MO7qaUIAAAAJ": [
      "55TAOdgAAAAJ",
      "lPycXNcAAAAJ",
      "rQkl8gIAAAAJ",
      "IQ3hcw4AAAAJ",
      "uK5wa_EAAAAJ",
      "mZMaDgEAAAAJ",
      "l96zhjwAAAAJ",
      "GR_DsT0AAAAJ",
      "r1TJBr8AAAAJ",
      "RrYw5jkAAAAJ",
      "HQRnt54AAAAJ",
      "EnNwKLgAAAAJ",
      "0ei9XEUAAAAJ",
      "DcV-5RAAAAAJ",
      "Rn_BmTYAAAAJ",
      "aO8KpGcAAAAJ",
      "Jr2CK6QAAAAJ",
      "ZvX1hXcAAAAJ",
      "F6x3R1oAAAAJ",
      "KKQCt30AAAAJ",
      "3B2c31wAAAAJ",
      "Km1V8WwAAAAJ"
    ],
    "MDeIveMAAAAJ": [],
    "0nPi5YYAAAAJ": [
      "wfGiqXEAAAAJ",
      "jEANvfgAAAAJ",
      "T7uctwYAAAAJ",
      "mu5Y2rYAAAAJ",
      "T04c3fwAAAAJ",
      "yFMX138AAAAJ",
      "bnQMuzgAAAAJ",
      "yOcNQVgAAAAJ",
      "WLN3QrAAAAAJ",
      "cXT3p6cAAAAJ",
      "U_Jw8DUAAAAJ",
      "8R35rCwAAAAJ",
      "EPfOJwQAAAAJ",
      "ADkiClQAAAAJ",
      "sGFyDIUAAAAJ",
      "SSTIBK0AAAAJ",
      "yy0UFOwAAAAJ",
      "Q0YEc-QAAAAJ",
      "LIJQ_ZYAAAAJ",
      "YfPA4YsAAAAJ",
      "KsocBp8AAAAJ",
      "GgQ9GEkAAAAJ",
      "uRlPu-4AAAAJ",
      "UZ5wscMAAAAJ",
      "spAJDzYAAAAJ",
      "0ncQNL8AAAAJ",
      "pqP5_PgAAAAJ",
      "n4QjVfoAAAAJ",
      "hYVMrzsAAAAJ",
      "q7nFtUcAAAAJ",
      "Vzr1RukAAAAJ",
      "Z3dxz9IAAAAJ",
      "NSWI3OwAAAAJ",
      "-w5DuHgAAAAJ",
      "0tLCTHYAAAAJ",
      "36ofBJgAAAAJ",
      "WcXt6YQAAAAJ",
      "YGQs1AYAAAAJ",
      "Izhkp4YAAAAJ",
      "5VaXUQsAAAAJ",
      "7KDSCpQAAAAJ",
      "t2X4Mg8AAAAJ",
      "2fWmq-4AAAAJ",
      "_AoZDGEAAAAJ",
      "K29Sv1EAAAAJ",
      "GuU6oA4AAAAJ",
      "GfcBlpUAAAAJ",
      "QUJ0kPMAAAAJ",
      "X9AjIugAAAAJ",
      "lgvyqMQAAAAJ",
      "Cmf2HdcAAAAJ",
      "f9_wq_kAAAAJ",
      "ipTsozQAAAAJ",
      "GyoKzFwAAAAJ",
      "kukA0LcAAAAJ",
      "TqUN-LwAAAAJ",
      "O7MZStwAAAAJ",
      "ZaJEZpYAAAAJ",
      "UQBRs7EAAAAJ",
      "4gVbilMMp-AC",
      "uemlfQYAAAAJ",
      "LIG-4BcAAAAJ",
      "OI7zFmwAAAAJ",
      "C_AP8XAAAAAJ",
      "RNdGVHoAAAAJ",
      "fMN7wNwAAAAJ",
      "fz7LJPIAAAAJ",
      "DSKzTCAAAAAJ",
      "8fztli4AAAAJ",
      "DJ9puk8AAAAJ",
      "G7XaqUcAAAAJ",
      "0NHagNQAAAAJ",
      "FJO1bnsAAAAJ",
      "Lc9GwgwAAAAJ",
      "6Hk7QdkAAAAJ",
      "sI0DsP8AAAAJ",
      "ibu3FwsAAAAJ",
      "tWoesqcAAAAJ",
      "rjnJnEkAAAAJ",
      "dFdEHskAAAAJ",
      "2DBmo-wAAAAJ",
      "u3u16tgAAAAJ",
      "kwTTDPMAAAAJ",
      "NbXF7T8AAAAJ",
      "ETU-ePAAAAAJ",
      "ZGpE5cYAAAAJ",
      "u3-FxUgAAAAJ",
      "dh03btIAAAAJ",
      "90FJPJUAAAAJ",
      "wxnzyjwAAAAJ",
      "rRJ9wTJMUB8C",
      "vtwH6GkAAAAJ",
      "7c1B_fIAAAAJ",
      "GRMMc_MAAAAJ",
      "FBVwO5wAAAAJ"
    ],
    "Wk2gAZUAAAAJ": [
      "VJZj2MsAAAAJ",
      "4v8uJrIAAAAJ",
      "928yXx4AAAAJ",
      "5JserkUAAAAJ",
      "Vs-MdPcAAAAJ",
      "zLuqh-0AAAAJ",
      "q1HlbIUAAAAJ",
      "aeGDj-IAAAAJ",
      "L3KXa3cAAAAJ",
      "fAxws1sAAAAJ",
      "R0kl_BUAAAAJ",
      "EPO5_f4AAAAJ",
      "N-sME4wAAAAJ",
      "5Iqe53IAAAAJ",
      "ZYEgD7wAAAAJ",
      "UQIBiUcAAAAJ",
      "_CWxQ1gAAAAJ",
      "6Q-289IAAAAJ",
      "-SlS0mgAAAAJ",
      "6_UmGu0AAAAJ",
      "uvaPP80AAAAJ",
      "NfJiSMMAAAAJ",
      "VSCSNhMAAAAJ",
      "7eLKa3IAAAAJ",
      "xCYHonIAAAAJ",
      "DdtAyEIAAAAJ",
      "rArDMRMAAAAJ",
      "UA9Hb2EAAAAJ",
      "bqL73OkAAAAJ",
      "chD5XxkAAAAJ",
      "sJJamz4AAAAJ",
      "bh-uRFMAAAAJ",
      "L__n1LUAAAAJ",
      "C4i_vUMAAAAJ",
      "MxxZkEcAAAAJ",
      "kwZTvH4AAAAJ",
      "qWak04oAAAAJ",
      "GHpxNQIAAAAJ",
      "d-3sFxQAAAAJ",
      "fsqz49kAAAAJ",
      "YY7Rql4AAAAJ",
      "Ihs8dwsAAAAJ",
      "4QvYJ00AAAAJ",
      "jHCgT18AAAAJ",
      "vQa7heEAAAAJ",
      "Sc2tw28AAAAJ",
      "qWDmIgIAAAAJ",
      "IwSe1-MAAAAJ",
      "IhMQa-MAAAAJ",
      "qQgUtucAAAAJ",
      "vtwH6GkAAAAJ",
      "wVGqmWkAAAAJ",
      "aLl3rYoAAAAJ",
      "P9FclNEAAAAJ",
      "p9-nlRIAAAAJ",
      "opVT1qkAAAAJ",
      "9DXQi8gAAAAJ",
      "2EaTkYEAAAAJ",
      "_JFStaIAAAAJ",
      "dNHNpxoAAAAJ",
      "vfTpaOAAAAAJ",
      "Vz8AQ6oAAAAJ",
      "NQgRwKAAAAAJ",
      "ijpYJQwAAAAJ",
      "v1CRzeAAAAAJ",
      "zblQKM8AAAAJ",
      "jNCbl2IAAAAJ",
      "C7cw4msAAAAJ",
      "vgzrOK4AAAAJ",
      "7Mxp9d4AAAAJ",
      "lyh8wacAAAAJ",
      "wJR3IY4AAAAJ",
      "sQHdOycAAAAJ",
      "VBXG4CwAAAAJ",
      "lMkTx0EAAAAJ",
      "jWWx33IAAAAJ",
      "kukA0LcAAAAJ",
      "ItOvQJ4AAAAJ",
      "SkkDQgMAAAAJ",
      "VBMuQbsAAAAJ",
      "9XJL-qMAAAAJ"
    ],
    "JWmiQR0AAAAJ": [
      "wsGvgA8AAAAJ",
      "mOG0bwsAAAAJ",
      "oR9sCGYAAAAJ",
      "2oq9614AAAAJ",
      "3SyxFIAAAAAJ",
      "NkzyCvUAAAAJ",
      "Vs-MdPcAAAAJ",
      "dN9QZfEAAAAJ",
      "lLTdYUYAAAAJ",
      "mvojJ2MAAAAJ",
      "YdHW1ycAAAAJ",
      "x04W_mMAAAAJ",
      "MmX7K38AAAAJ",
      "e1GAF6sAAAAJ",
      "QkYiDCwAAAAJ",
      "-gJkPHIAAAAJ",
      "Se68XecAAAAJ",
      "VfYhf2wAAAAJ",
      "MiHOX3QAAAAJ",
      "vfT6-XIAAAAJ",
      "JicYPdAAAAAJ",
      "NvMCACEAAAAJ",
      "4TbxnY0AAAAJ",
      "ipb9-GEAAAAJ",
      "vfPE6hgAAAAJ",
      "8R35rCwAAAAJ",
      "2ftJYXMAAAAJ",
      "WuWWdKcAAAAJ",
      "3Y4egcYAAAAJ",
      "wfGiqXEAAAAJ",
      "wVazIm8AAAAJ",
      "Lh_ZqdcAAAAJ",
      "ygTCc6cAAAAJ",
      "Yc94070AAAAJ",
      "cSTLkv8AAAAJ",
      "VWEg9YQAAAAJ",
      "Bmbkv6sAAAAJ",
      "EemUE4gAAAAJ",
      "AxGhhfsAAAAJ",
      "LFyg0tAAAAAJ",
      "es9clvEAAAAJ",
      "8AtDeScAAAAJ",
      "V358UyMAAAAJ",
      "0KF6ZC8AAAAJ",
      "vWTI60AAAAAJ",
      "Jjp8eYUAAAAJ",
      "q34R9psAAAAJ",
      "sybphw0AAAAJ",
      "TrdtzgwAAAAJ",
      "NMS69lQAAAAJ",
      "zBdo-BoAAAAJ",
      "yp4Gk3kAAAAJ",
      "9700p4IAAAAJ",
      "W8yZCNsAAAAJ",
      "rT11mdcAAAAJ"
    ],
    "kZh8vUMAAAAJ": [],
    "_ws9LLgAAAAJ": [
      "YGQs1AYAAAAJ",
      "DMTuJzAAAAAJ",
      "7m2X0GoAAAAJ",
      "ejWOgzYAAAAJ",
      "65bIT4oAAAAJ",
      "e378qEIAAAAJ",
      "rjnJnEkAAAAJ",
      "A8YEQMMAAAAJ",
      "tM4JMcQAAAAJ"
    ],
    "ID9QePIAAAAJ": [
      "b0ehAgIAAAAJ",
      "y80AokkAAAAJ",
      "czxMUzcAAAAJ",
      "QXyvv94AAAAJ",
      "y1lVpBEAAAAJ",
      "XnhYW0MAAAAJ",
      "K3QJPdMAAAAJ",
      "uG6vN6QAAAAJ",
      "LJiQRJIAAAAJ",
      "zQABr7QAAAAJ",
      "BCKhEoAAAAAJ",
      "-xQ-C1sAAAAJ",
      "RpqvaTUAAAAJ",
      "8m8taGEAAAAJ",
      "bh-uRFMAAAAJ",
      "AhgjQ2QAAAAJ",
      "B96GkdgAAAAJ",
      "-lQSzAwAAAAJ",
      "E0iCaa4AAAAJ",
      "By1xdxEAAAAJ",
      "YZHj-Y4AAAAJ",
      "MV8KGT0AAAAJ",
      "UZ6kI2AAAAAJ",
      "3ACMPEQAAAAJ",
      "e4I7ihkAAAAJ",
      "POm0zXkAAAAJ",
      "xVN3UxYAAAAJ",
      "Wj4ZBFIAAAAJ",
      "si-368wAAAAJ",
      "v-ab1_kAAAAJ",
      "1ZT-nZEAAAAJ",
      "Wy89g4IAAAAJ",
      "jF4dPZwAAAAJ",
      "Kq0feJIAAAAJ",
      "zT8cqLkAAAAJ",
      "YrihYtsAAAAJ",
      "9HiV_AEAAAAJ",
      "1_zc1-IAAAAJ",
      "hdnpRKsAAAAJ",
      "eqQQkM4AAAAJ",
      "MBiIblMAAAAJ",
      "vae65B0AAAAJ",
      "93yNuV0AAAAJ",
      "SormeOgAAAAJ",
      "GP64q_kAAAAJ",
      "DZ19008AAAAJ"
    ],
    "T9To2C0AAAAJ": [
      "8R35rCwAAAAJ",
      "-gJkPHIAAAAJ",
      "zBUwaGkAAAAJ",
      "7ShMBcwAAAAJ",
      "znnl0kwAAAAJ",
      "zvz6LIYAAAAJ",
      "qlmK27YAAAAJ",
      "xBH73TYAAAAJ",
      "vtwH6GkAAAAJ",
      "C2_ZXdcAAAAJ",
      "gYiCq88AAAAJ",
      "20_pofsAAAAJ",
      "5VaXUQsAAAAJ",
      "vfPE6hgAAAAJ"
    ],
    "42m4tGIAAAAJ": [],
    "CzOD0S4AAAAJ": [],
    "zxB06pcAAAAJ": [
      "Zrs0wpEAAAAJ",
      "-zaDQ10AAAAJ",
      "YI1SAjUAAAAJ",
      "hbriwLcAAAAJ",
      "dSU9MtYAAAAJ",
      "hhu_TQsAAAAJ",
      "EdV_R7oAAAAJ",
      "O0VelhkAAAAJ",
      "l92sxGEAAAAJ",
      "azSz1VYAAAAJ",
      "lZ9KLP0AAAAJ",
      "wmjk13MAAAAJ",
      "67eC0RcAAAAJ",
      "PP6LKtYAAAAJ",
      "cVHKEaoAAAAJ",
      "iX-72m8AAAAJ",
      "dzP4uYEAAAAJ",
      "k6-1woQAAAAJ",
      "WNYs930AAAAJ"
    ],
    "67kghxAAAAAJ": [
      "q4qDvAoAAAAJ",
      "EjXmTH4AAAAJ",
      "WN9t4n0AAAAJ",
      "G7_tE4wAAAAJ",
      "84WzBlYAAAAJ",
      "_7x84lgAAAAJ",
      "bsDeOEoAAAAJ",
      "n-Oret4AAAAJ",
      "bzsYmwYAAAAJ",
      "mdPnGScAAAAJ",
      "AxUAEQ4AAAAJ",
      "jjXriQwAAAAJ",
      "6qE0tdAAAAAJ",
      "4VJre9IAAAAJ",
      "MnsxqAcAAAAJ",
      "zRQMWrkAAAAJ",
      "BbzYzsgAAAAJ",
      "tP5rH0wAAAAJ",
      "gUEkPQEAAAAJ",
      "YYcTN2EAAAAJ",
      "EASHOTUAAAAJ",
      "YayQtGUAAAAJ",
      "hOlkT4sAAAAJ",
      "-tTv7oYAAAAJ",
      "ghfkSasAAAAJ",
      "QWPwfsgAAAAJ",
      "xVzAml0AAAAJ",
      "HvwPRJ0AAAAJ",
      "gqB23VMAAAAJ",
      "zc920lAAAAAJ",
      "cTGO2HoAAAAJ",
      "9cFCY5wAAAAJ",
      "lRwkspgAAAAJ",
      "2oclnIwAAAAJ",
      "d87RjDgAAAAJ",
      "0MkHY9cAAAAJ",
      "7D7IaJ4AAAAJ",
      "E3wyDhUAAAAJ",
      "1GjHPkcAAAAJ",
      "KWez2_sAAAAJ",
      "kZch-sMAAAAJ",
      "sDiiVkcAAAAJ",
      "kek70IwAAAAJ",
      "ICzsaEsAAAAJ",
      "3vKjkoQAAAAJ",
      "v4UZWmcAAAAJ",
      "eUHFqm4AAAAJ",
      "jyk2KYEAAAAJ",
      "flCzpwcAAAAJ",
      "ZcPi_0wAAAAJ",
      "BxkylVAAAAAJ",
      "Nr6E_rIAAAAJ",
      "MvKQ0B4AAAAJ",
      "TXTlU3sAAAAJ",
      "s_YDrrgAAAAJ",
      "o3PQcYgAAAAJ",
      "b32YyLIAAAAJ",
      "XD_01h8AAAAJ",
      "sTwMEA8AAAAJ",
      "5V852JcAAAAJ",
      "P1XH4nkAAAAJ",
      "uf0D-uoAAAAJ",
      "9RlvgLEAAAAJ",
      "_JhgbioAAAAJ",
      "mmEb3AwAAAAJ",
      "JvY2c4YAAAAJ",
      "RPPi79MAAAAJ",
      "HfGUt6AAAAAJ",
      "SlZavnIAAAAJ",
      "yKzSdygAAAAJ",
      "JvUypEMAAAAJ",
      "B7xbi_QAAAAJ",
      "GveGRr0AAAAJ",
      "RivxoIcAAAAJ",
      "FANRIhwAAAAJ",
      "wTCe1mUAAAAJ",
      "Sdz9YPMAAAAJ",
      "OtEdQpcAAAAJ",
      "u4epKYoAAAAJ",
      "UIM7nGwAAAAJ",
      "h6yXnyEAAAAJ",
      "jyF9UHAAAAAJ",
      "_rJCgzIAAAAJ",
      "ca7sXDUAAAAJ",
      "5EMVIoEAAAAJ",
      "h1FDASIAAAAJ",
      "_4i-G3YAAAAJ",
      "PswI6pYAAAAJ",
      "ehv7qvIAAAAJ",
      "_jOpRuIAAAAJ",
      "01YOPpAAAAAJ",
      "RGtMwTgAAAAJ",
      "YTmGBNsAAAAJ",
      "FIpwvjsAAAAJ",
      "uy8T6BYAAAAJ",
      "VLft_T4AAAAJ",
      "wR84XY1kACcC",
      "7CohtIMAAAAJ",
      "81IhdxgAAAAJ",
      "471mb4wAAAAJ",
      "_MsNwIsAAAAJ",
      "DcV-5RAAAAAJ",
      "4e2pnKYAAAAJ",
      "IyGPTacAAAAJ",
      "NozmrNYAAAAJ",
      "E0NwK2AAAAAJ",
      "AFGPpWoAAAAJ",
      "OBiA-IAAAAAJ",
      "664NOb0AAAAJ",
      "O5jENBMAAAAJ",
      "DC7FtVYAAAAJ",
      "K0kaNvkAAAAJ",
      "wPNgzO4AAAAJ",
      "MlPFWbgAAAAJ",
      "XFtrWVsAAAAJ",
      "BEGRf_EAAAAJ",
      "891RunEAAAAJ",
      "-Z4XFnEAAAAJ",
      "zBQxZrcAAAAJ",
      "RYvdtGcAAAAJ",
      "IQosWycAAAAJ",
      "1Aa3qxIAAAAJ",
      "ku59ZJoAAAAJ"
    ],
    "xaQuPloAAAAJ": [
      "UwLsYw8AAAAJ",
      "TIKl_foAAAAJ",
      "obpl7GQAAAAJ",
      "NyoUvosAAAAJ",
      "Rn7APGIAAAAJ",
      "zvC19mQAAAAJ",
      "7c1B_fIAAAAJ",
      "Lncr-VoAAAAJ",
      "C-ZlBWMAAAAJ",
      "g2uX6_gAAAAJ",
      "Q7VKnRYAAAAJ",
      "-WFwzjoAAAAJ",
      "MsuY1TsAAAAJ",
      "zbXIQMsAAAAJ",
      "cXkm3rsAAAAJ",
      "jrkrn3sAAAAJ",
      "35zn-2cAAAAJ",
      "PYtPCHoAAAAJ",
      "dKNkD3sAAAAJ",
      "EBeIYOwAAAAJ",
      "t5zdD_IAAAAJ",
      "9IRFiEQAAAAJ",
      "i0oFmt0AAAAJ",
      "KhAJWroAAAAJ",
      "E9ZX2lgAAAAJ",
      "fXRXgPMAAAAJ",
      "VvdtcWcAAAAJ",
      "WXbhp_4AAAAJ",
      "d9s3sbQAAAAJ",
      "tqcSvFIAAAAJ",
      "XSgTV7gAAAAJ",
      "GnR3Y60AAAAJ",
      "3_002c0AAAAJ",
      "I-rLzGcAAAAJ",
      "nrE1OroAAAAJ",
      "d32BmwcAAAAJ",
      "__CwaPMAAAAJ",
      "TNr_OWMAAAAJ"
    ],
    "rMDVDA8AAAAJ": [
      "kV4N4zoAAAAJ",
      "ZDG9RD8AAAAJ",
      "84WzBlYAAAAJ",
      "O__9HOwAAAAJ",
      "qALDmfcAAAAJ",
      "aO8KpGcAAAAJ",
      "df-THM0AAAAJ",
      "DcV-5RAAAAAJ",
      "LjsKfKYAAAAJ"
    ],
    "l-mlF7YAAAAJ": [],
    "JKVR2ksAAAAJ": [
      "ofcrge8AAAAJ",
      "ErVxNWkAAAAJ",
      "xRmmtzIAAAAJ",
      "3Ir65ZkAAAAJ",
      "FL61g6wAAAAJ",
      "6S09ezcAAAAJ",
      "Do8MrDYAAAAJ",
      "oVxK8g0AAAAJ",
      "U_L2uiwAAAAJ",
      "13Tv6dkAAAAJ",
      "EzvMOjkAAAAJ",
      "MBKRLlgAAAAJ",
      "DcV-5RAAAAAJ",
      "hdTDzlQAAAAJ",
      "aO8KpGcAAAAJ",
      "ZvX1hXcAAAAJ",
      "5t2myD8AAAAJ",
      "Dq93mOUAAAAJ",
      "Y6vuiBUAAAAJ",
      "oCw8EScAAAAJ",
      "Atc5w-4AAAAJ"
    ],
    "bQowYEYAAAAJ": [
      "8R35rCwAAAAJ",
      "VatfufAAAAAJ",
      "ZWH5jCwAAAAJ",
      "f28F1YUAAAAJ",
      "wIDVzroAAAAJ",
      "unQVOJkAAAAJ"
    ],
    "SlZavnIAAAAJ": [
      "AhgjQ2QAAAAJ",
      "AFgYa68AAAAJ",
      "wPNgzO4AAAAJ",
      "zwA5eokAAAAJ",
      "-TFCgqsAAAAJ",
      "Kia-4B0AAAAJ",
      "0PzT1VoAAAAJ",
      "EqIVfYcAAAAJ",
      "qVzY4XYAAAAJ",
      "h0R3z64AAAAJ",
      "Jok8C54AAAAJ",
      "67kghxAAAAAJ",
      "5o111aIAAAAJ",
      "pbhFW1kAAAAJ",
      "friM_CIAAAAJ",
      "V828uG8AAAAJ",
      "cTGO2HoAAAAJ",
      "4e2pnKYAAAAJ"
    ],
    "t2X4Mg8AAAAJ": [
      "bQKreEMAAAAJ",
      "0tWX-EMAAAAJ",
      "JdRs1sQAAAAJ",
      "cabvCW8AAAAJ",
      "ToU9KBUAAAAJ",
      "kqkq_coAAAAJ",
      "MNuTR9YAAAAJ",
      "d-jF4zIAAAAJ",
      "ODdBJAcAAAAJ",
      "GrpsKVsAAAAJ",
      "SyACgDAAAAAJ",
      "YGQs1AYAAAAJ",
      "oU2jyxMAAAAJ",
      "IDF-ar0AAAAJ",
      "3Rlc8EAAAAAJ",
      "xk1gsM8AAAAJ",
      "VzJAvWEAAAAJ",
      "zStLMKIAAAAJ",
      "jk0gVL8AAAAJ",
      "83OxU_4AAAAJ",
      "k9Hczv4AAAAJ",
      "q_n7d6EAAAAJ",
      "4bl7qAgAAAAJ",
      "QY-earAAAAAJ",
      "WHZiLTIAAAAJ",
      "iGLS8hMAAAAJ",
      "nxNkEiYAAAAJ",
      "9kzHZssAAAAJ",
      "ZyA-aKQAAAAJ",
      "rjnJnEkAAAAJ",
      "rRJ9wTJMUB8C",
      "KhAJWroAAAAJ",
      "JJWWPjsAAAAJ",
      "cMHsYdcAAAAJ",
      "TA2fG64AAAAJ",
      "rvKJDbIAAAAJ",
      "uDLRZQMAAAAJ",
      "RHYFcckAAAAJ",
      "eM916YMAAAAJ",
      "TApLOhkAAAAJ",
      "kpcjFekAAAAJ",
      "Cul0g2YAAAAJ",
      "wxnzyjwAAAAJ"
    ],
    "LQR0kNcAAAAJ": [
      "p_837e0AAAAJ",
      "D83Vz00AAAAJ",
      "fNOReswAAAAJ",
      "CUqzFcEAAAAJ",
      "j2yC2GQAAAAJ",
      "quhI7uQAAAAJ",
      "VvgVKVYAAAAJ",
      "UW3tRn8AAAAJ"
    ],
    "todsDfQAAAAJ": [
      "0zZnyMEAAAAJ",
      "MplR7_cAAAAJ",
      "GlIyobYAAAAJ",
      "9DXQi8gAAAAJ",
      "SNqm6doAAAAJ",
      "4Ma6NAYAAAAJ",
      "6ggnUzYAAAAJ",
      "k1eaag4AAAAJ",
      "GTmdNU0AAAAJ",
      "j7MW4iYAAAAJ"
    ],
    "Rne0FzEAAAAJ": [
      "nzEluBwAAAAJ",
      "79k7bGEAAAAJ",
      "jEANvfgAAAAJ",
      "Vwas7kAAAAAJ",
      "K4OcFXUAAAAJ",
      "oFIvUSQAAAAJ",
      "W80oBMkAAAAJ",
      "vDimc-4AAAAJ",
      "XrKLUO0AAAAJ",
      "Tom5l8EAAAAJ",
      "odVYodIAAAAJ",
      "0ncQNL8AAAAJ",
      "gVFnjOcAAAAJ",
      "IrixA8MAAAAJ",
      "grQ_GBgAAAAJ",
      "CjOTm_4AAAAJ",
      "E_oZZj8AAAAJ",
      "95mnc80AAAAJ",
      "n2osZaoAAAAJ",
      "fAWKizAAAAAJ",
      "-8DNE4UAAAAJ",
      "skyUvycAAAAJ",
      "mWGyYMsAAAAJ",
      "TqUN-LwAAAAJ",
      "3oUgDKQAAAAJ",
      "yy0UFOwAAAAJ",
      "iW_lUIkAAAAJ",
      "LFyg0tAAAAAJ",
      "rLdfJ1gAAAAJ",
      "OvKEnVwAAAAJ",
      "sGFyDIUAAAAJ",
      "afpYZisAAAAJ",
      "YUrxwrkAAAAJ",
      "uc4Q6bYAAAAJ",
      "9dAjSlYAAAAJ",
      "MMRpEk0AAAAJ",
      "Q0YEc-QAAAAJ",
      "Tb0ZrYwAAAAJ",
      "zeX8KGAAAAAJ",
      "Xl4E0CsAAAAJ",
      "siCYLcUAAAAJ",
      "cIlDEugAAAAJ",
      "c_mh0i0AAAAJ",
      "DwHtHE8AAAAJ",
      "lZKlDFcAAAAJ",
      "47sihrsAAAAJ",
      "eJwbbXEAAAAJ",
      "dxBYu1AAAAAJ",
      "MGXJkIAAAAAJ"
    ],
    "SiBVfPUAAAAJ": [
      "A33FhJMAAAAJ",
      "CZaDvPgAAAAJ",
      "aPqcyU4AAAAJ",
      "Bo-wyrkAAAAJ",
      "cXkm3rsAAAAJ",
      "ivUi2T0AAAAJ",
      "BFlpS-8AAAAJ",
      "hYtGXD0AAAAJ",
      "5kVcNS4AAAAJ",
      "iZ5cY0AAAAAJ",
      "mJB-HiIAAAAJ"
    ],
    "94RFSSsAAAAJ": [],
    "vgfGtykAAAAJ": [
      "8R35rCwAAAAJ",
      "UAwKvEsAAAAJ",
      "rRJ9wTJMUB8C",
      "5SF-hRsAAAAJ",
      "8cxDHS4AAAAJ",
      "gLnCTgIAAAAJ",
      "i-AStBYAAAAJ",
      "OcownLgAAAAJ",
      "FwxfQosAAAAJ",
      "vtwH6GkAAAAJ",
      "I3mSZFEAAAAJ",
      "2efgcS0AAAAJ",
      "xBH73TYAAAAJ",
      "zvz6LIYAAAAJ",
      "BU79wO4AAAAJ",
      "vfPE6hgAAAAJ",
      "OSg3D9MAAAAJ",
      "oX7L_mMAAAAJ",
      "JscQvlUAAAAJ",
      "1wLVDP4AAAAJ",
      "BiCxWC0AAAAJ",
      "rrPyvsgAAAAJ",
      "aQcYWDMAAAAJ",
      "CBUpEcQAAAAJ",
      "tCUvC4oAAAAJ",
      "fwKsGokAAAAJ",
      "8iCb2TwAAAAJ",
      "NACSmGwAAAAJ",
      "2oy3OXYAAAAJ",
      "bBFN_qwAAAAJ",
      "-WZcuuwAAAAJ",
      "xUGZX_MAAAAJ",
      "mXtH1UYAAAAJ",
      "7oxkHYYAAAAJ",
      "MbXKAK8AAAAJ",
      "R-z1R84AAAAJ",
      "tuBQ_uwAAAAJ",
      "V42yp08AAAAJ"
    ],
    "1eBgIWsAAAAJ": [],
    "BZBkjNYAAAAJ": [
      "ImpbxLsAAAAJ",
      "8R35rCwAAAAJ",
      "rDfyQnIAAAAJ",
      "mWGyYMsAAAAJ",
      "jTnQTBoAAAAJ",
      "zp8V7ZMAAAAJ",
      "vtwH6GkAAAAJ",
      "rjnJnEkAAAAJ"
    ],
    "mDNhPjAAAAAJ": [
      "bh-uRFMAAAAJ",
      "e-c3R8QAAAAJ",
      "BC8TixYAAAAJ",
      "KBRHCEEAAAAJ",
      "lc0ARagAAAAJ",
      "DFqp8NkAAAAJ",
      "6IvhxBkAAAAJ",
      "klWjaQIAAAAJ",
      "Nv2jil0AAAAJ",
      "EdROb6UAAAAJ",
      "D9LfKkAe7d0C",
      "2COOamwAAAAJ",
      "LBfy6oMAAAAJ",
      "7ftnjtEAAAAJ",
      "CXB-29IAAAAJ",
      "59O0DBIAAAAJ",
      "-9acvogAAAAJ",
      "_4EISRwAAAAJ",
      "MnnERiQAAAAJ",
      "9UoNgkYAAAAJ",
      "0EWw1z8AAAAJ",
      "Jp6Mz1sAAAAJ",
      "6YU6_QoAAAAJ",
      "mhmvCgsAAAAJ",
      "xSZXqZQAAAAJ",
      "IcW1vJEAAAAJ",
      "AkEXTbIAAAAJ",
      "s9B5sagAAAAJ",
      "I2W13z0AAAAJ",
      "FdNuUb8AAAAJ",
      "UOv-ce4AAAAJ",
      "jgqZbREAAAAJ",
      "VJlCMGYAAAAJ",
      "k8Ovqo8AAAAJ",
      "3SDKldkAAAAJ",
      "X3FwUngAAAAJ",
      "xjzc-TwAAAAJ",
      "V8RKLEsAAAAJ"
    ],
    "LfcroyAAAAAJ": [
      "ml-AyBQAAAAJ",
      "sU6x0E0AAAAJ",
      "W69x8yYAAAAJ",
      "R4Q7jzgAAAAJ",
      "aeGDj-IAAAAJ",
      "n_ts4eYAAAAJ",
      "AK_7EBgAAAAJ",
      "_xWMxrQAAAAJ",
      "Ao4gtsYAAAAJ",
      "o1IZjggAAAAJ",
      "LIjnUGgAAAAJ",
      "ilJgXHkAAAAJ",
      "5JserkUAAAAJ",
      "XCfZyIkAAAAJ",
      "lr1JM5MAAAAJ",
      "Du51uRIAAAAJ",
      "4Ea9RSkAAAAJ",
      "-lnWdScAAAAJ",
      "jHD1kUsAAAAJ",
      "_U02AlsAAAAJ",
      "U69fiZMAAAAJ",
      "AIncPrIAAAAJ",
      "q__pgY9AkUQJ",
      "opBkPOgAAAAJ",
      "V0K3gs0AAAAJ",
      "0RAmmIAAAAAJ",
      "UUKLPMYAAAAJ",
      "f6uvd6kAAAAJ",
      "Q0iwucYAAAAJ",
      "okjycNEAAAAJ",
      "29FPauoAAAAJ",
      "RdPknzsAAAAJ",
      "9Kz5vKYAAAAJ",
      "2vQRGrYAAAAJ",
      "xEWgxBsAAAAJ",
      "omfoflQAAAAJ",
      "2oy3OXYAAAAJ",
      "_td9cSEAAAAJ",
      "glNJx5zYUbsC",
      "hwQtFB0AAAAJ",
      "kssA7YwAAAAJ",
      "tokXOxkAAAAJ",
      "KMBgMs0AAAAJ",
      "uBFV6SUAAAAJ",
      "MVxcjEoAAAAJ",
      "umFQktIAAAAJ",
      "RUP4S68AAAAJ",
      "DzSgRSoAAAAJ",
      "r4ldy4AAAAAJ",
      "3JfHObUAAAAJ",
      "DxoenfgAAAAJ",
      "eoBHpj4AAAAJ",
      "YYUK51oAAAAJ",
      "iBeDoRAAAAAJ",
      "xrSUChoAAAAJ",
      "8200InoAAAAJ",
      "Td3_kIwAAAAJ",
      "Ek4hM10AAAAJ",
      "RNC-GC0AAAAJ",
      "FjCbjDYAAAAJ",
      "f1wmyEkAAAAJ",
      "1E7m_VsAAAAJ",
      "K2WfIlsAAAAJ",
      "kddKBCsAAAAJ",
      "x8dED5cAAAAJ",
      "dEbld0EAAAAJ",
      "9DXQi8gAAAAJ",
      "B9g1lS8AAAAJ",
      "_-KE7lIAAAAJ",
      "vA6ZQ_AAAAAJ",
      "or0oVL0AAAAJ",
      "zbRUiLgAAAAJ",
      "X3RNgQMAAAAJ",
      "SDavuPAAAAAJ",
      "cSTLkv8AAAAJ",
      "lCgSjYAAAAAJ",
      "CkfQy2gAAAAJ",
      "iUgCzvgAAAAJ",
      "GgQ9GEkAAAAJ",
      "j3CEIuEAAAAJ",
      "0lcJYs8AAAAJ",
      "kV9XRxYAAAAJ",
      "l-mlF7YAAAAJ",
      "n63DmP8AAAAJ",
      "wUArfPgAAAAJ",
      "HzxnwocAAAAJ",
      "oejm5IUAAAAJ",
      "j5o1jkEAAAAJ",
      "Wmr3UIMAAAAJ",
      "206DEM0AAAAJ",
      "Dn_qYK8AAAAJ",
      "8bVtuOwAAAAJ",
      "x5wW5WIAAAAJ",
      "Xnk4W5cAAAAJ",
      "EkREu_QAAAAJ",
      "HqGW4HIAAAAJ",
      "-0U84zMAAAAJ",
      "w_GMSlcAAAAJ",
      "mDLwSZAAAAAJ",
      "WLN3QrAAAAAJ",
      "hFjNgPEAAAAJ",
      "anxumroAAAAJ",
      "SUNF5HMAAAAJ",
      "x_OUOncAAAAJ",
      "KtnTuq8AAAAJ"
    ],
    "yE4WT_0AAAAJ": [
      "fopP3AsAAAAJ",
      "KkkebI8AAAAJ",
      "U6AIrqwAAAAJ",
      "EZ4qNDUAAAAJ",
      "6THqxEoAAAAJ"
    ],
    "8O8MQEUAAAAJ": [
      "_2ofK_kAAAAJ",
      "YAHWbtkAAAAJ",
      "B847xq8AAAAJ",
      "uNsqlqYAAAAJ",
      "1nxepREAAAAJ",
      "H1vNRiUAAAAJ",
      "KntSJpQAAAAJ",
      "Ne3wr9oAAAAJ",
      "CigslP0AAAAJ",
      "qPP9-msAAAAJ",
      "b55hlmIAAAAJ",
      "IYqleYUAAAAJ",
      "okx33sUAAAAJ",
      "iLJcSEsAAAAJ",
      "6ywZAeEAAAAJ",
      "5HACNJ0AAAAJ",
      "zkvW8FQAAAAJ",
      "cPDxYXMAAAAJ",
      "KA8dgpMAAAAJ",
      "RnVPcI0AAAAJ",
      "9uRDTmUAAAAJ",
      "6mxddyMAAAAJ",
      "zC9ANdcAAAAJ",
      "iFYov5EAAAAJ",
      "-V1rJ8wAAAAJ",
      "xEidIpMAAAAJ",
      "-PWcE1YAAAAJ",
      "lfJmfM0AAAAJ",
      "XBk56N0AAAAJ",
      "yORoyhsAAAAJ",
      "0-I8YNgAAAAJ",
      "MY1FRYUAAAAJ",
      "xkn_XZgAAAAJ",
      "t3COq84AAAAJ",
      "D6h2cTYAAAAJ",
      "jxrHPD4AAAAJ",
      "nqalmtQAAAAJ",
      "ZQ1Bbb8AAAAJ",
      "3IUE2yQAAAAJ",
      "1pFBWgoAAAAJ",
      "zujScxwAAAAJ",
      "UDKpJ0IAAAAJ",
      "OHoU9Y4AAAAJ",
      "DqKSB-kAAAAJ"
    ],
    "Zldo9CAAAAAJ": [
      "yxUduqMAAAAJ",
      "qyPWUBcAAAAJ",
      "GwEdlMkAAAAJ",
      "wRXPnP8AAAAJ",
      "B96GkdgAAAAJ",
      "hYi6i9sAAAAJ",
      "DcV-5RAAAAAJ",
      "a_dbdxAAAAAJ",
      "W8yZCNsAAAAJ",
      "Vs-MdPcAAAAJ",
      "q9alvsoAAAAJ",
      "i16X9rUAAAAJ",
      "TW7U1W0AAAAJ",
      "bldHpWIAAAAJ",
      "p0sQC6sAAAAJ",
      "biuxbRsAAAAJ",
      "gTWUZlsAAAAJ",
      "Djtri0kAAAAJ",
      "sUXvfjUAAAAJ",
      "910z20QAAAAJ",
      "-spRnaQAAAAJ",
      "AY6InkoAAAAJ",
      "dPX0wQcAAAAJ",
      "GkXqbmMAAAAJ",
      "JQcDmB8AAAAJ",
      "DnnCWN0AAAAJ",
      "9QO16LcAAAAJ",
      "n41KN9AAAAAJ",
      "5LLV29oAAAAJ",
      "i5srt20AAAAJ",
      "zZNKHdEAAAAJ",
      "Py_StfUAAAAJ",
      "r0wOAikAAAAJ",
      "Hs3AnAkAAAAJ",
      "C7zfAI4AAAAJ",
      "0tPCcKEAAAAJ"
    ],
    "i7V1kJgAAAAJ": [
      "bldHpWIAAAAJ",
      "8R35rCwAAAAJ",
      "sUriZlUAAAAJ",
      "wlosgkoAAAAJ",
      "Es-YRKMAAAAJ",
      "ITZ1e7MAAAAJ",
      "jW9ts2cAAAAJ",
      "MlZq4XwAAAAJ",
      "8OVA7ucAAAAJ",
      "MN9Kfg8AAAAJ",
      "8DKNKhkAAAAJ",
      "DRnOvU8AAAAJ",
      "Sg3jtCgAAAAJ",
      "rtpoh5wAAAAJ",
      "wHHgs8UAAAAJ",
      "myi68A4AAAAJ",
      "7N4J31IAAAAJ",
      "Hu2Ht28AAAAJ"
    ],
    "zp8V7ZMAAAAJ": [
      "8fztli4AAAAJ",
      "ImpbxLsAAAAJ",
      "DqXsbPAAAAAJ",
      "mWGyYMsAAAAJ",
      "rDfyQnIAAAAJ",
      "MEz23joAAAAJ",
      "bEcLezcAAAAJ",
      "BDmtLHsAAAAJ",
      "T_mJiHoAAAAJ",
      "vtwH6GkAAAAJ",
      "Yxh9WWoAAAAJ",
      "i9-GzNYAAAAJ",
      "rjnJnEkAAAAJ",
      "Ag_6KEgAAAAJ",
      "V9EUwCEAAAAJ",
      "RhN6jKIAAAAJ",
      "XOJE8OEAAAAJ",
      "HEY3UzgAAAAJ",
      "FwFFVdIAAAAJ",
      "eFsEy1YAAAAJ",
      "iWmtv7gAAAAJ",
      "HYHTg_0AAAAJ",
      "hqNhUCYAAAAJ",
      "8BeTDr0AAAAJ",
      "U89FHq4AAAAJ",
      "OYd3hjYAAAAJ",
      "iopH6wIAAAAJ",
      "HSx0BgQAAAAJ",
      "I1mOQpAAAAAJ",
      "kXB8FBoAAAAJ",
      "DO3quJYAAAAJ",
      "3Tj5lWEAAAAJ",
      "mCjP0bAAAAAJ",
      "BZBkjNYAAAAJ",
      "6TGwETYAAAAJ",
      "krrh6OUAAAAJ",
      "m9I8jgcAAAAJ",
      "jTnQTBoAAAAJ",
      "ivApfKcAAAAJ",
      "UZ6kI2AAAAAJ",
      "ZaJEZpYAAAAJ",
      "Ja-8AFsAAAAJ",
      "3Br8x_gAAAAJ",
      "oYlo1ycAAAAJ",
      "boebIUcAAAAJ",
      "lJwPbcUAAAAJ",
      "7wfzKHam13MC",
      "8cxDHS4AAAAJ",
      "Nuw1Y4oAAAAJ",
      "83HL5FwAAAAJ",
      "OcownLgAAAAJ",
      "lSJavJUAAAAJ",
      "bh-uRFMAAAAJ",
      "8R35rCwAAAAJ",
      "SAdQhg4AAAAJ",
      "q1HlbIUAAAAJ",
      "-kIVAcAAAAAJ",
      "XuQW7ogAAAAJ",
      "qnwjcfAAAAAJ",
      "HwFGzZMAAAAJ",
      "x-n9rIMAAAAJ",
      "1Yu0vQkAAAAJ",
      "eJVXK_EAAAAJ",
      "9zeEI-cAAAAJ",
      "WlA92lcAAAAJ",
      "t9HPFawAAAAJ",
      "wbIMbL8AAAAJ",
      "RhOpyXcAAAAJ",
      "ciragesAAAAJ",
      "G5SAV7gAAAAJ",
      "JYMjWq8AAAAJ",
      "iVXG-IkAAAAJ",
      "O-oICE8AAAAJ",
      "sCTJI-0AAAAJ",
      "1vEw_kgAAAAJ",
      "ogXTOZ4AAAAJ",
      "9D4aG8AAAAAJ",
      "WzmDQTMAAAAJ",
      "VINmGpYAAAAJ",
      "jCNJhFcAAAAJ",
      "P9FclNEAAAAJ",
      "qKz0qpoAAAAJ",
      "4FeC1wQAAAAJ",
      "QZVQEWAAAAAJ",
      "G5_VFfkAAAAJ",
      "PHi0YEQAAAAJ",
      "9aG3giMAAAAJ",
      "B8sRETUAAAAJ",
      "0zKusWIAAAAJ",
      "bD8DWiEAAAAJ",
      "1RmD-YsAAAAJ",
      "l8wQ39EAAAAJ",
      "-1i9yccAAAAJ",
      "kl4jZpAAAAAJ",
      "U3w720cAAAAJ",
      "N_vPIhoAAAAJ",
      "QMfeRz0AAAAJ",
      "B96GkdgAAAAJ",
      "6z4lQzMAAAAJ",
      "8wGH7wsAAAAJ",
      "Bgv4hAUAAAAJ",
      "2efgcS0AAAAJ",
      "-xaOIZIAAAAJ",
      "RgIBwboAAAAJ",
      "Zb0NwBUAAAAJ",
      "_zSP7YMAAAAJ",
      "wnweG9UAAAAJ",
      "K6-M7A4AAAAJ",
      "2z7iDDUAAAAJ",
      "NzjKoWIAAAAJ",
      "kcr8134AAAAJ",
      "Lqc4cdAAAAAJ",
      "U_Jw8DUAAAAJ",
      "H9xADK0AAAAJ",
      "Qzss0GEAAAAJ",
      "fTgRyn4AAAAJ",
      "SKq6DZcAAAAJ",
      "uxsLx-0AAAAJ",
      "Q_kKkIUAAAAJ",
      "3MzhkFIAAAAJ",
      "4HTITaMAAAAJ",
      "23ZXZvEAAAAJ",
      "7soDcboAAAAJ",
      "KVUCqGwAAAAJ",
      "6HwMeesAAAAJ",
      "ghpLm2cAAAAJ",
      "ugFNit4AAAAJ",
      "uVsZydYAAAAJ",
      "ONuIPv0AAAAJ",
      "b8d5wS-QfscC",
      "IaNhZ9AAAAAJ",
      "sPlonWcAAAAJ",
      "_bKTUqAAAAAJ",
      "1P8Zu04AAAAJ",
      "4l2EoB0AAAAJ",
      "mMANqk8AAAAJ",
      "-A4wqWEAAAAJ",
      "4OBGbW0AAAAJ",
      "H1v0ztEAAAAJ",
      "-L0XFlMAAAAJ",
      "vPEmzqYAAAAJ"
    ],
    "dYt8FGcAAAAJ": [],
    "-5_ksIkAAAAJ": [],
    "Ci-_QYIAAAAJ": [
      "aOklxsQAAAAJ",
      "l0Bj7U8AAAAJ",
      "6NjbexEAAAAJ",
      "WH2KmRgAAAAJ",
      "UFo0PcAAAAAJ",
      "iH2BZ8UAAAAJ",
      "k6fOmQgAAAAJ",
      "d97bGd8AAAAJ",
      "LltfiXgAAAAJ",
      "Db4BCX8AAAAJ",
      "zw1TzeEAAAAJ",
      "ypBMJMgAAAAJ",
      "Ecy6lXwAAAAJ",
      "o_M5CBMAAAAJ",
      "ODr5lMgAAAAJ",
      "8fztli4AAAAJ",
      "NFeigSoAAAAJ",
      "-d7Ib5UAAAAJ",
      "a_dbdxAAAAAJ",
      "9xF7M6wAAAAJ",
      "IolN_okAAAAJ",
      "Wx62iOsAAAAJ",
      "vtwH6GkAAAAJ",
      "OT1uf7kAAAAJ",
      "IkpNZAoAAAAJ",
      "wp1MXzsAAAAJ",
      "bh-uRFMAAAAJ",
      "1WYrlLkAAAAJ",
      "mlSE-YwAAAAJ",
      "0Ozzy4IAAAAJ",
      "8R35rCwAAAAJ",
      "FwxfQosAAAAJ",
      "Ctp3igcAAAAJ",
      "j56HgqYAAAAJ",
      "VdmfIeUAAAAJ",
      "siW2DBoAAAAJ",
      "RqOzJR0AAAAJ",
      "6H0mhLUAAAAJ",
      "K1CAbGwAAAAJ",
      "QLW0lzcAAAAJ",
      "cwXx4EQAAAAJ",
      "06rffEkAAAAJ",
      "WLk8ZikAAAAJ",
      "4B-C50EAAAAJ",
      "0vZ20kgAAAAJ",
      "B3FqpjQAAAAJ",
      "UKpinl8AAAAJ",
      "UV0IzT4AAAAJ",
      "u8p5Y1EAAAAJ",
      "yh7H1fIAAAAJ",
      "2efgcS0AAAAJ",
      "g1n-MOEAAAAJ",
      "eQ8ZIG4AAAAJ",
      "YMgdDBwAAAAJ",
      "bQNISbAAAAAJ",
      "8EVs9AEAAAAJ",
      "1Cv6Sf4AAAAJ",
      "OWDai70AAAAJ",
      "J7QDRmwAAAAJ",
      "Id8SJl8AAAAJ",
      "jxf3Qv0AAAAJ",
      "FLcpd34AAAAJ",
      "J8E8GQYAAAAJ",
      "J8YyZugAAAAJ",
      "-9AvWrwAAAAJ",
      "C3KJzwEAAAAJ",
      "AFD2rD4AAAAJ",
      "tZprM8IAAAAJ",
      "Hq28JM0AAAAJ",
      "Ja-8AFsAAAAJ",
      "2sKLll8AAAAJ",
      "18fTep8AAAAJ",
      "D04RyEcAAAAJ",
      "9B8PoXUAAAAJ",
      "3RuMCpcAAAAJ",
      "t4dSV4YAAAAJ",
      "l9iNFaMAAAAJ",
      "36NmvrMAAAAJ",
      "-gFCCLMAAAAJ",
      "gz1zcR4AAAAJ",
      "d6vuvHIAAAAJ",
      "_wds938AAAAJ",
      "ceSzF9YAAAAJ",
      "jQl9RtkAAAAJ",
      "0gEOJSEAAAAJ",
      "7QmEsOwAAAAJ",
      "Tw8DY-cAAAAJ",
      "SvinO8kAAAAJ"
    ],
    "DxoenfgAAAAJ": [],
    "_DNzXTcAAAAJ": [
      "jIs-Y2gAAAAJ",
      "ED5iKYYAAAAJ",
      "1TqAq5AAAAAJ"
    ],
    "yy0UFOwAAAAJ": [
      "8R35rCwAAAAJ",
      "vfPE6hgAAAAJ",
      "ADkiClQAAAAJ",
      "lRUi-A8AAAAJ",
      "5VaXUQsAAAAJ",
      "pqP5_PgAAAAJ",
      "LIJQ_ZYAAAAJ",
      "YGQs1AYAAAAJ",
      "-w5DuHgAAAAJ",
      "NSWI3OwAAAAJ",
      "q7nFtUcAAAAJ",
      "OI7zFmwAAAAJ",
      "8C2_ZVsAAAAJ",
      "YfPA4YsAAAAJ",
      "hYVMrzsAAAAJ",
      "U_Jw8DUAAAAJ",
      "0nPi5YYAAAAJ",
      "1wLVDP4AAAAJ",
      "Vzr1RukAAAAJ",
      "jTnQTBoAAAAJ",
      "_0IIzxgAAAAJ",
      "79k7bGEAAAAJ",
      "1gVfqpcAAAAJ",
      "lhpoASkAAAAJ",
      "dQmvEyUAAAAJ",
      "jV66t1kAAAAJ",
      "RUWfW-kAAAAJ",
      "mINzfREAAAAJ",
      "VGBlCk4AAAAJ",
      "ke2MEF0AAAAJ",
      "4wXYfSUAAAAJ",
      "8fztli4AAAAJ",
      "vtwH6GkAAAAJ",
      "MGXJkIAAAAAJ",
      "wxnzyjwAAAAJ"
    ],
    "wtRVnsYAAAAJ": [
      "wfGiqXEAAAAJ",
      "_MEuWIMAAAAJ",
      "j3CEIuEAAAAJ",
      "WL_xXbQAAAAJ",
      "8R35rCwAAAAJ",
      "l-la0GQAAAAJ",
      "DMTuJzAAAAAJ",
      "SzHPa90AAAAJ",
      "QKOH5iYAAAAJ",
      "ygpxbK8AAAAJ",
      "iZ5cY0AAAAAJ",
      "TxKNCSoAAAAJ",
      "T7uctwYAAAAJ",
      "hczHVxEAAAAJ",
      "APgaFK0AAAAJ",
      "_ws9LLgAAAAJ",
      "EpLo4l4AAAAJ",
      "lLTdYUYAAAAJ",
      "MxxZkEcAAAAJ",
      "P9-oT8AAAAAJ",
      "0uTu7fYAAAAJ",
      "CUD7V78AAAAJ"
    ]
  },
  "author_abstracts": {
    "8R35rCwAAAAJ": [
      {
        "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
        "abstract": "We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.",
        "year": 2017,
        "authors": "Chelsea Finn and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Trust region policy optimization",
        "abstract": "In this article, we describe a method for optimizing control policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified scheme, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters.",
        "year": 2015,
        "authors": "John Schulman and Sergey Levine and Philipp Moritz and Michael I Jordan and Pieter Abbeel"
      }
    ],
    "bh-uRFMAAAAJ": [
      {
        "title": "Fully convolutional networks for semantic segmentation",
        "abstract": "Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build\" fully convolutional\" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.",
        "year": 2015,
        "authors": "Jonathan Long and Evan Shelhamer and Trevor Darrell"
      },
      {
        "title": "Rich feature hierarchies for accurate object detection and semantic segmentation",
        "abstract": "Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012---achieving a mAP of 53.3%. Our approach combines two key insights:(1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www. cs. berkeley. edu/~ rbg/rcnn.",
        "year": 2014,
        "authors": "Ross Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik"
      },
      {
        "title": "Caffe: Convolutional architecture for fast feature embedding",
        "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community …",
        "year": 2014,
        "authors": "Yangqing Jia and Evan Shelhamer and Jeff Donahue and Sergey Karayev and Jonathan Long and Ross Girshick and Sergio Guadarrama and Trevor Darrell"
      }
    ],
    "a4unsk4AAAAJ": [
      {
        "title": "A Deep Learning Mammography-based Model for Improved Breast Cancer Risk Prediction",
        "abstract": "Mammographic density improves the accuracy of breast cancer risk models.                            However, the use of breast density is limited by subjective assessment,                            variation across radiologists, and restricted data. A mammography-based                            deep learning (DL) model may provide more accurate risk prediction.To develop a mammography-based DL breast cancer risk model that is more                            accurate than established clinical breast cancer risk models.This retrospective study included 88 994 consecutive screening mammograms                            in 39 571 women between January 1, 2009, and December 31, 2012. For each                            patient, all examinations were assigned to either training …",
        "year": 2019,
        "authors": "Adam Yala and Constance Lehman and Tal Schuster and Tally Portnoi and Regina Barzilay"
      },
      {
        "title": "Toward robust mammography-based models for breast cancer risk",
        "abstract": "Improved breast cancer risk models enable targeted screening strategies that achieve earlier detection and less screening harm than existing guidelines. To bring deep learning risk models to clinical practice, we need to further refine their accuracy, validate them across diverse populations, and demonstrate their potential to improve clinical workflows. We developed Mirai, a mammography-based deep learning model designed to predict risk at multiple timepoints, leverage potentially missing risk factor information, and produce predictions that are consistent across mammography machines. Mirai was trained on a large dataset from Massachusetts General Hospital (MGH) in the United States and tested on held-out test sets from MGH, Karolinska University Hospital in Sweden, and Chang Gung Memorial Hospital (CGMH) in Taiwan, obtaining C-indices of 0.76 (95% confidence interval, 0.74 to 0.80), 0.81 (0.79 to 0 …",
        "year": 2021,
        "authors": "Adam Yala and Peter G Mikhael and Fredrik Strand and Gigin Lin and Kevin Smith and Yung-Liang Wan and Leslie Lamb and Kevin Hughes and Constance Lehman and Regina Barzilay"
      }
    ],
    "84WzBlYAAAAJ": [
      {
        "title": "Advances and open problems in federated learning",
        "abstract": "Federated learning (FL) is a machine learning setting where many clients (eg, mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (eg, service provider), while keeping the training data decentralized. FL embodies the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches. Motivated by the explosive growth in FL research, this monograph discusses recent advances and presents an extensive collection of open problems and challenges.",
        "year": 2021,
        "authors": "Peter Kairouz and H Brendan McMahan and Brendan Avent and Aurélien Bellet and Mehdi Bennis and Arjun Nitin Bhagoji and Kallista Bonawitz and Zachary Charles and Graham Cormode and Rachel Cummings and Rafael GL D’Oliveira and Hubert Eichner and Salim El Rouayheb and David Evans and Josh Gardner and Zachary Garrett and Adrià Gascón and Badih Ghazi and Phillip B Gibbons and Marco Gruteser and Zaid Harchaoui and Chaoyang He and Lie He and Zhouyuan Huo and Ben Hutchinson and Justin Hsu and Martin Jaggi and Tara Javidi and Gauri Joshi and Mikhail Khodak and Jakub Konecný and Aleksandra Korolova and Farinaz Koushanfar and Sanmi Koyejo and Tancrède Lepoint and Yang Liu and Prateek Mittal and Mehryar Mohri and Richard Nock and Ayfer Özgür and Rasmus Pagh and Hang Qi and Daniel Ramage and Ramesh Raskar and Mariana Raykova and Dawn Song and Weikang Song and Sebastian U Stich and Ziteng Sun and Ananda Theertha Suresh and Florian Tramèr and Praneeth Vepakomma and Jianyu Wang and Li Xiong and Zheng Xu and Qiang Yang and Felix X Yu and Han Yu and Sen Zhao"
      },
      {
        "title": "Practical techniques for searches on encrypted data",
        "abstract": "It is desirable to store data on data storage servers such as mail servers and file servers in encrypted form to reduce security and privacy risks. But this usually implies that one has to sacrifice functionality for security. For example, if a client wishes to retrieve only documents containing certain words, it was not previously known how to let the data storage server perform the search and answer the query, without loss of data confidentiality. We describe our cryptographic schemes for the problem of searching on encrypted data and provide proofs of security for the resulting crypto systems. Our techniques have a number of crucial advantages. They are provably secure: they provide provable secrecy for encryption, in the sense that the untrusted server cannot learn anything about the plaintext when only given the ciphertext; they provide query isolation for searches, meaning that the untrusted server cannot learn …",
        "year": 2000,
        "authors": "Dawn Xiaoding Song and David Wagner and Adrian Perrig"
      },
      {
        "title": "Measuring massive multitask language understanding",
        "abstract": "We propose a new test to measure a text model's multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have near-random accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model's academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings.",
        "year": 2020,
        "authors": "Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt"
      }
    ],
    "a_dbdxAAAAAJ": [
      {
        "title": "Exact matrix completion via convex optimization",
        "abstract": "Suppose that one observes an incomplete subset of entries selected from a low-rank matrix. When is it possible to complete the matrix and recover the entries that have not been seen? We demonstrate that in very general settings, one can perfectly recover all of the missing entries from most sufficiently large subsets by solving a convex programming problem that finds the matrix with the minimum nuclear norm agreeing with the observed entries. The techniques used in this analysis draw upon parallels in the field of compressed sensing, demonstrating that objects other than signals and images can be perfectly reconstructed from very limited information.",
        "year": 2012,
        "authors": "Emmanuel Candes and Benjamin Recht"
      },
      {
        "title": "Understanding deep learning requires rethinking generalization",
        "abstract": "Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models.",
        "year": 2016,
        "authors": "Chiyuan Zhang and Samy Bengio and Moritz Hardt and Benjamin Recht and Oriol Vinyals"
      },
      {
        "title": "Random features for large-scale kernel machines",
        "abstract": "To accelerate the training of kernel machines, we propose to map the input data to a randomized low-dimensional feature space and then apply existing fast linear methods. The features are designed so that the inner products of the transformed data are approximately equal to those in the feature space of a user specified shiftinvariant kernel. We explore two sets of random features, provide convergence bounds on their ability to approximate various radial basis kernels, and show that in large-scale classification and regression tasks linear machine learning algorithms applied to these features outperform state-of-the-art large-scale kernel machines.",
        "year": 2007,
        "authors": "Ali Rahimi and Benjamin Recht"
      }
    ],
    "aO8KpGcAAAAJ": [
      {
        "title": "Theoretically principled trade-off between robustness and accuracy",
        "abstract": "We identify a trade-off between robustness and accuracy that serves as a guiding principle in the design of defenses against adversarial examples. Although this problem has been widely studied empirically, much remains unknown concerning the theory underlying this trade-off. In this work, we decompose the prediction error for adversarial examples (robust error) as the sum of the natural (classification) error and boundary error, and provide a differentiable upper bound using the theory of classification-calibrated loss, which is shown to be the tightest possible upper bound uniform over all probability distributions and measurable predictors. Inspired by our theoretical analysis, we also design a new defense method, TRADES, to trade adversarial robustness off against accuracy. Our proposed algorithm performs well experimentally in real-world datasets. The methodology is the foundation of our entry to the NeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of 2,000 submissions, surpassing the runner-up approach by 11.41% in terms of mean L_2 perturbation distance.",
        "year": 2019,
        "authors": "Hongyang Zhang and Yaodong Yu and Jiantao Jiao and Eric P Xing and Laurent El Ghaoui and Michael I Jordan"
      },
      {
        "title": "Bridging offline reinforcement learning and imitation learning: A tale of pessimism",
        "abstract": "Offline (or batch) reinforcement learning (RL) algorithms seek to learn an optimal policy from a fixed dataset without active data collection. Based on the composition of the offline dataset, two main methods are used: imitation learning which is suitable for expert datasets, and vanilla offline RL which often requires uniform coverage datasets. From a practical standpoint, datasets often deviate from these two extremes and the exact data composition is usually unknown. To bridge this gap, we present a new offline RL framework that smoothly interpolates between the two extremes of data composition, hence unifying imitation learning and vanilla offline RL. The new framework is centered around a weak version of the concentrability coefficient that measures the deviation of the behavior policy from the expert policy alone. Under this new framework, we ask: can one develop an algorithm that achieves a minimax optimal rate adaptive to unknown data composition? To address this question, we consider a lower confidence bound (LCB) algorithm developed based on pessimism in the face of uncertainty in offline RL. We study finite-sample properties of LCB as well as information-theoretic limits in multi-armed bandits, contextual bandits, and Markov decision processes (MDPs). Our analysis reveals surprising facts about optimality rates. In particular, in both contextual bandits and RL, LCB achieves a faster rate of  for nearly-expert datasets compared to the usual rate of  in offline RL, where  is the batch dataset sample size. In contextual bandits with at least two contexts, we prove that LCB is adaptively optimal for the entire data composition …",
        "year": 2021,
        "authors": "Paria Rashidinejad and Banghua Zhu and Cong Ma and Jiantao Jiao and Stuart Russell"
      },
      {
        "title": "Minimax estimation of functionals of discrete distributions",
        "abstract": "We propose a general methodology for the construction and analysis of essentially minimax estimators for a wide class of functionals of finite dimensional parameters, and elaborate on the case of discrete distributions, where the support size S is unknown and may be comparable with or even much larger than the number of observations n. We treat the respective regions where the functional is nonsmooth and smooth separately. In the nonsmooth regime, we apply an unbiased estimator for the best polynomial approximation of the functional whereas, in the smooth regime, we apply a bias-corrected version of the maximum likelihood estimator (MLE). We illustrate the merit of this approach by thoroughly analyzing the performance of the resulting schemes for estimating two important information measures: 1) the entropy H(P) = ΣSi=1 -pi ln pi and 2) Fα(P) = ΣSi=1 pαi, α > 0. We obtain the minimax L2 rates for …",
        "year": 2015,
        "authors": "Jiantao Jiao and Kartik Venkat and Yanjun Han and Tsachy Weissman"
      }
    ],
    "LKv32bgAAAAJ": [
      {
        "title": "Measuring massive multitask language understanding",
        "abstract": "We propose a new test to measure a text model's multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have near-random accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model's academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings.",
        "year": 2020,
        "authors": "Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt"
      },
      {
        "title": "Concrete problems in AI safety",
        "abstract": "Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function (\"avoiding side effects\" and \"avoiding reward hacking\"), an objective function that is too expensive to evaluate frequently (\"scalable supervision\"), or undesirable behavior during the learning process (\"safe exploration\" and \"distributional shift\"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.",
        "year": 2016,
        "authors": "Dario Amodei and Chris Olah and Jacob Steinhardt and Paul Christiano and John Schulman and Dan Mané"
      },
      {
        "title": "Measuring mathematical problem solving with the math dataset",
        "abstract": "Many intellectual endeavors require mathematical problem solving, but this skill remains beyond the capabilities of computers. To measure this ability in machine learning models, we introduce MATH, a new dataset of 12,500 challenging competition mathematics problems. Each problem in MATH has a full step-by-step solution which can be used to teach models to generate answer derivations and explanations. To facilitate future research and increase accuracy on MATH, we also contribute a large auxiliary pretraining dataset which helps teach models the fundamentals of mathematics. Even though we are able to increase accuracy on MATH, our results show that accuracy remains relatively low, even with enormous Transformer models. Moreover, we find that simply increasing budgets and model parameter counts will be impractical for achieving strong mathematical reasoning if scaling trends continue. While scaling Transformers is automatically solving most other text-based tasks, scaling is not currently solving MATH. To have more traction on mathematical problem solving we will likely need new algorithmic advancements from the broader research community.",
        "year": 2021,
        "authors": "Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt"
      }
    ],
    "vtwH6GkAAAAJ": [
      {
        "title": "Denoising diffusion probabilistic models",
        "abstract": "We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.",
        "year": 2020,
        "authors": "Jonathan Ho and Ajay Jain and Pieter Abbeel"
      },
      {
        "title": "Model-agnostic meta-learning for fast adaptation of deep networks",
        "abstract": "We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.",
        "year": 2017,
        "authors": "Chelsea Finn and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine"
      }
    ],
    "B96GkdgAAAAJ": [
      {
        "title": "Judging llm-as-a-judge with mt-bench and chatbot arena",
        "abstract": "Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80\\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github. com/lm-sys/FastChat/tree/main/fastchat/llm_judge.",
        "year": 2023,
        "authors": "Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric Xing and Hao Zhang and Joseph E Gonzalez and Ion Stoica"
      },
      {
        "title": "{PowerGraph}: Distributed {Graph-Parallel} computation on natural graphs",
        "abstract": "Large-scale graph-structured computation is central to tasks ranging from targeted advertising to natural language processing and has led to the development of several graph-parallel abstractions including Pregel and GraphLab. However, the natural graphs commonly found in the real-world have highly skewed power-law degree distributions, which challenge the assumptions made by these abstractions, limiting performance and scalability.",
        "year": 2012,
        "authors": "Joseph E Gonzalez and Yucheng Low and Haijie Gu and Danny Bickson and Carlos Guestrin"
      },
      {
        "title": "Apache spark: a unified engine for big data processing",
        "abstract": "This open source computing framework unifies streaming, batch, and interactive big data workloads to unlock new applications.",
        "year": 2016,
        "authors": "Matei Zaharia and Reynold S Xin and Patrick Wendell and Tathagata Das and Michael Armbrust and Ankur Dave and Xiangrui Meng and Josh Rosen and Shivaram Venkataraman and Michael J Franklin and Ali Ghodsi and Joseph Gonzalez and Scott Shenker and Ion Stoica"
      }
    ],
    "_pv1sEcAAAAJ": [
      {
        "title": "Cardiovascular disease risk prediction using automated machine learning: A prospective study of 423,604 UK Biobank participants",
        "abstract": "Identifying people at risk of cardiovascular diseases (CVD) is a cornerstone of preventative cardiology. Risk prediction models currently recommended by clinical guidelines are typically based on a limited number of predictors with sub-optimal performance across all patient groups. Data-driven techniques based on machine learning (ML) might improve the performance of risk predictions by agnostically discovering novel risk predictors and learning the complex interactions between them. We tested (1) whether ML techniques based on a state-of-the-art automated ML framework (AutoPrognosis) could improve CVD risk prediction compared to traditional approaches, and (2) whether considering non-traditional variables could increase the accuracy of CVD risk predictions.Using data on 423,604 participants without CVD at baseline in UK Biobank, we developed a ML-based model for predicting CVD risk based on 473 available variables. Our ML-based model was derived using AutoPrognosis, an algorithmic tool that automatically selects and tunes ensembles of ML modeling pipelines (comprising data imputation, feature processing, classification and calibration algorithms). We compared our model with a well-established risk prediction algorithm based on conventional CVD risk factors (Framingham score), a Cox proportional hazards (PH) model based on familiar risk factors (i.e, age, gender, smoking status, systolic blood pressure, history of diabetes, reception of treatments for hypertension and body mass index), and a Cox PH model based on all of the 473 available variables. Predictive performances were …",
        "year": 2019,
        "authors": "Ahmed M Alaa and Thomas Bolton and Emanuele Di Angelantonio and James HF Rudd and Mihaela Van der Schaar"
      },
      {
        "title": "Bayesian Inference of Individualized Treatment Effects using Multi-task Gaussian Processes",
        "abstract": "Predicated on the increasing abundance of electronic health records, we investigate the problem of inferring individualized treatment effects using observational data. Stemming from the potential outcomes model, we propose a novel multi-task learning framework in which factual and counterfactual outcomes are modeled as the outputs of a function in a vector-valued reproducing kernel Hilbert space (vvRKHS). We develop a nonparametric Bayesian method for learning the treatment effects using a multi-task Gaussian process (GP) with a linear coregionalization kernel as a prior over the vvRKHS. The Bayesian approach allows us to compute individualized measures of confidence in our estimates via pointwise credible intervals, which are crucial for realizing the full potential of precision medicine. The impact of selection bias is alleviated via a risk-based empirical Bayes method for adapting the multi-task GP prior, which jointly minimizes the empirical error in factual outcomes and the uncertainty in (unobserved) counterfactual outcomes. We conduct experiments on observational datasets for an interventional social program applied to premature infants, and a left ventricular assist device applied to cardiac patients wait-listed for a heart transplant. In both experiments, we show that our method significantly outperforms the state-of-the-art.",
        "year": 2017,
        "authors": "Ahmed M Alaa and Mihaela van der Schaar"
      },
      {
        "title": "How faithful is your synthetic data? sample-level metrics for evaluating and auditing generative models",
        "abstract": "Devising domain-and model-agnostic evaluation metrics for generative models is an important and as yet unresolved problem. Most existing metrics, which were tailored solely to the image synthesis setup, exhibit a limited capacity for diagnosing the different modes of failure of generative models across broader application domains. In this paper, we introduce a 3-dimensional evaluation metric,(-Precision, -Recall, Authenticity), that characterizes the fidelity, diversity and generalization performance of any generative model in a domain-agnostic fashion. Our metric unifies statistical divergence measures with precision-recall analysis, enabling sample-and distribution-level diagnoses of model fidelity and diversity. We introduce generalization as an additional, independent dimension (to the fidelity-diversity trade-off) that quantifies the extent to which a model copies training data {—} a crucial performance indicator when modeling sensitive data with requirements on privacy. The three metric components correspond to (interpretable) probabilistic quantities, and are estimated via sample-level binary classification. The sample-level nature of our metric inspires a novel use case which we call model auditing, wherein we judge the quality of individual samples generated by a (black-box) model, discarding low-quality samples and hence improving the overall model performance in a post-hoc manner.",
        "year": 2022,
        "authors": "Ahmed M Alaa and Boris van Breugel and Evgeny Saveliev and Mihaela van der Schaar"
      }
    ],
    "Wi25oKoAAAAJ": [
      {
        "title": "Ultralight, ultrastiff mechanical metamaterials",
        "abstract": "The mechanical properties of ordinary materials degrade substantially with reduced density because their structural elements bend under applied load. We report a class of microarchitected materials that maintain a nearly constant stiffness per unit mass density, even at ultralow density. This performance derives from a network of nearly isotropic microscale unit cells with high structural connectivity and nanoscale features, whose structural members are designed to carry loads in tension or compression. Production of these microlattices, with polymers, metals, or ceramics as constituent materials, is made possible by projection microstereolithography (an additive micromanufacturing technique) combined with nanoscale coating and postprocessing. We found that these materials exhibit ultrastiff properties across more than three orders of magnitude in density, regardless of the constituent material.",
        "year": 2014,
        "authors": "Xiaoyu Zheng and Howon Lee and Todd H Weisgraber and Maxim Shusteff and Joshua DeOtte and Eric B Duoss and Joshua D Kuntz and Monika M Biener and Qi Ge and Julie A Jackson and Sergei O Kucheyev and Nicholas X Fang and Christopher M Spadaccini"
      },
      {
        "title": "Multiscale metallic metamaterials",
        "abstract": "Materials with three-dimensional micro- and nanoarchitectures exhibit many beneficial mechanical, energy conversion and optical properties. However, these three-dimensional microarchitectures are significantly limited by their scalability. Efforts have only been successful only in demonstrating overall structure sizes of hundreds of micrometres, or contain size-scale gaps of several orders of magnitude. This results in degraded mechanical properties at the macroscale. Here we demonstrate hierarchical metamaterials with disparate three-dimensional features spanning seven orders of magnitude, from nanometres to centimetres. At the macroscale they achieve high tensile elasticity (>20%) not found in their brittle-like metallic constituents, and a near-constant specific strength. Creation of these materials is enabled by a high-resolution, large-area additive manufacturing technique with scalability not achievable by …",
        "year": 2016,
        "authors": "Xiaoyu Zheng and William Smith and Julie Jackson and Bryan Moran and Huachen Cui and Da Chen and Jianchao Ye and Nicholas Fang and Nicholas Rodriguez and Todd Weisgraber and Christopher M Spadaccini"
      },
      {
        "title": "A general method to synthesize and sinter bulk ceramics in seconds",
        "abstract": "Ceramics are an important class of materials with widespread applications because of their high thermal, mechanical, and chemical stability. Computational predictions based on first principles methods can be a valuable tool in accelerating materials discovery to develop improved ceramics. It is essential to experimentally confirm the material properties of such predictions. However, materials screening rates are limited by the long processing times and the poor compositional control from volatile element loss in conventional ceramic sintering techniques. To overcome these limitations, we developed an ultrafast high-temperature sintering (UHS) process for the fabrication of ceramic materials by radiative heating under an inert atmosphere. We provide several examples of the UHS process to demonstrate its potential utility and applications, including advancements in solid-state electrolytes, multicomponent …",
        "year": 2020,
        "authors": "Chengwei Wang and Weiwei Ping and Qiang Bai and Huachen Cui and Ryan Hensleigh and Ruiliu Wang and Alexandra H Brozena and Zhenpeng Xu and Jiaqi Dai and Yong Pei and Chaolun Zheng and Glenn Pastel and Jinlong Gao and Xizheng Wang and Howard Wang and Ji-Cheng Zhao and Bao Yang and Xiaoyu Zheng and Jian Luo and Yifei Mo and Bruce Dunn and Liangbing Hu"
      }
    ],
    "B847xq8AAAAJ": [
      {
        "title": "Maximizing social influence in nearly optimal time",
        "abstract": "Diffusion is a fundamental graph process, underpinning such phenomena as epidemic disease contagion and the spread of innovation by word-of-mouth. We address the algorithmic problem of finding a set of k initial seed nodes in a network so that the expected size of the resulting cascade is maximized, under the standard independent cascade model of network diffusion. Runtime is a primary consideration for this problem due to the massive size of the relevant input networks.We provide a fast algorithm for the influence maximization problem, obtaining the near-optimal approximation factor of , for any ∊ > 0, in time O((m + n)∊−3 log n). Our algorithm is runtime-optimal (up to a logarithmic factor) and substantially improves upon the previously best-known algorithms which run in time Ω(mnk · POLY(∊−1)). Furthermore, our algorithm can be modified to allow early termination: if it is terminated after O(β(m + n) logn …",
        "year": 2014,
        "authors": "Christian Borgs and Michael Brautbar and Jennifer Chayes and Brendan Lucier"
      },
      {
        "title": "Entropy-sgd: Biasing gradient descent into wide valleys",
        "abstract": "This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in the sharp valleys. Conceptually, our algorithm resembles two nested loops of SGD where we use Langevin dynamics in the inner loop to compute the gradient of the local entropy before each update of the weights. We show that the new objective has a smoother energy landscape and show improved generalization over SGD using uniform stability, under …",
        "year": 2019,
        "authors": "Pratik Chaudhari and Anna Choromanska and Stefano Soatto and Yann LeCun and Carlo Baldassi and Christian Borgs and Jennifer Chayes and Levent Sagun and Riccardo Zecchina"
      },
      {
        "title": "Convergent sequences of dense graphs I: Subgraph frequencies, metric properties and testing",
        "abstract": "We consider sequences of graphs (Gn) and define various notions of convergence related to these sequences: “left convergence” defined in terms of the densities of homomorphisms from small graphs into Gn; “right convergence” defined in terms of the densities of homomorphisms from Gn into small graphs; and convergence in a suitably defined metric. In Part I of this series, we show that left convergence is equivalent to convergence in metric, both for simple graphs Gn, and for graphs Gn with nodeweights and edgeweights. One of the main steps here is the introduction of a cut-distance comparing graphs, not necessarily of the same size. We also show how these notions of convergence provide natural formulations of Szemerédi partitions, sampling and testing of large graphs.",
        "year": 2008,
        "authors": "Christian Borgs and Jennifer T Chayes and László Lovász and Vera T Sós and Katalin Vesztergombi"
      }
    ],
    "_tNCgxMAAAAJ": [
      {
        "title": "Provably safe and robust learning-based model predictive control",
        "abstract": "Controller design faces a trade-off between robustness and performance, and the reliability of linear controllers has caused many practitioners to focus on the former. However, there is renewed interest in improving system performance to deal with growing energy constraints. This paper describes a learning-based model predictive control (LBMPC) scheme that provides deterministic guarantees on robustness, while statistical identification tools are used to identify richer models of the system in order to improve performance; the benefits of this framework are that it handles state and input constraints, optimizes system performance with respect to a cost function, and can be designed to use a wide variety of parametric or nonparametric statistical tools. The main insight of LBMPC is that safety and performance can be decoupled under reasonable conditions in an optimization framework by maintaining two models of …",
        "year": 2013,
        "authors": "Anil Aswani and Humberto Gonzalez and S Shankar Sastry and Claire Tomlin"
      },
      {
        "title": "Reducing transient and steady state electricity consumption in HVAC using learning-based model-predictive control",
        "abstract": "Heating, ventilation, and air conditioning (HVAC) systems are an important target for efficiency improvements through new equipment and retrofitting because of their large energy footprint. One type of equipment that is common in homes and some offices is an electrical, single-stage heat pump air conditioner (AC). To study this setup, we have built the Berkeley Retrofitted and Inexpensive HVAC Testbed for Energy Efficiency (BRITE) platform. This platform allows us to actuate an AC unit that controls the room temperature of a computer laboratory on the Berkeley campus that is actively used by students, while sensors record room temperature and AC energy consumption. We build a mathematical model of the temperature dynamics of the room, and combining this model with statistical methods allows us to compute the heating load due to occupants and equipment using only a single temperature sensor. Next, we …",
        "year": 2011,
        "authors": "Anil Aswani and Neal Master and Jay Taneja and David Culler and Claire Tomlin"
      },
      {
        "title": "Expression-level optimization of a multi-enzyme pathway in the absence of a high-throughput assay",
        "abstract": "Engineered metabolic pathways often suffer from flux imbalances that can overburden the cell and accumulate intermediate metabolites, resulting in reduced product titers. One way to alleviate such imbalances is to adjust the expression levels of the constituent enzymes using a combinatorial expression library. Typically, this approach requires high-throughput assays, which are unfortunately unavailable for the vast majority of desirable target compounds. To address this, we applied regression modeling to enable expression optimization using only a small number of measurements. We characterized a set of constitutive promoters in Saccharomyces cerevisiae that spanned a wide range of expression and maintained their relative strengths irrespective of the coding sequence. We used a standardized assembly strategy to construct a combinatorial library and express for the first time in yeast the five-enzyme …",
        "year": 2013,
        "authors": "Michael E Lee and Anil Aswani and Audrey S Han and Claire J Tomlin and John E Dueber"
      }
    ],
    "UgHB5oAAAAAJ": [
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien MR Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan"
      },
      {
        "title": "Gemma 2: Improving open language models at a practical size",
        "abstract": "In this work, we introduce Gemma 2, a new addition to the Gemma family of lightweight, state-of-the-art open models, ranging in scale from 2 billion to 27 billion parameters. In this new version, we apply several known technical modifications to the Transformer architecture, such as interleaving local-global attentions (Beltagy et al., 2020a) and group-query attention (Ainslie et al., 2023). We also train the 2B and 9B models with knowledge distillation (Hinton et al., 2015) instead of next token prediction. The resulting models deliver the best performance for their size, and even offer competitive alternatives to models that are 2-3 times bigger. We release all our models to the community.",
        "year": 2024,
        "authors": "Gemma Team and Morgane Riviere and Shreya Pathak and Pier Giuseppe Sessa and Cassidy Hardin and Surya Bhupatiraju and Léonard Hussenot and Thomas Mesnard and Bobak Shahriari and Alexandre Ramé and Johan Ferret and Peter Liu and Pouya Tafti and Abe Friesen and Michelle Casbon and Sabela Ramos and Ravin Kumar and Charline Le Lan and Sammy Jerome and Anton Tsitsulin and Nino Vieillard and Piotr Stanczyk and Sertan Girgin and Nikola Momchev and Matt Hoffman and Shantanu Thakoor and Jean-Bastien Grill and Behnam Neyshabur and Olivier Bachem and Alanna Walton and Aliaksei Severyn and Alicia Parrish and Aliya Ahmad and Allen Hutchison and Alvin Abdagic and Amanda Carl and Amy Shen and Andy Brock and Andy Coenen and Anthony Laforge and Antonia Paterson and Ben Bastian and Bilal Piot and Bo Wu and Brandon Royal and Charlie Chen and Chintu Kumar and Chris Perry and Chris Welty and Christopher A Choquette-Choo and Danila Sinopalnikov and David Weinberger and Dimple Vijaykumar and Dominika Rogozińska and Dustin Herbison and Elisa Bandy and Emma Wang and Eric Noland and Erica Moreira and Evan Senter and Evgenii Eltyshev and Francesco Visin and Gabriel Rasskin and Gary Wei and Glenn Cameron and Gus Martins and Hadi Hashemi and Hanna Klimczak-Plucińska and Harleen Batra and Harsh Dhand and Ivan Nardini and Jacinda Mein and Jack Zhou and James Svensson and Jeff Stanway and Jetha Chan and Jin Peng Zhou and Joana Carrasqueira and Joana Iljazi and Jocelyn Becker and Joe Fernandez and Joost van Amersfoort and Josh Gordon and Josh Lipschultz and Josh Newlan and Ju-yeong Ji and Kareem Mohamed and Kartikeya Badola and Kat Black and Katie Millican and Keelin McDonell and Kelvin Nguyen and Kiranbir Sodhia and Kish Greene and Lars Lowe Sjoesund and Lauren Usui and Laurent Sifre and Lena Heuermann and Leticia Lago and Lilly McNealus and Livio Baldini Soares and Logan Kilpatrick and Lucas Dixon and Luciano Martins and Machel Reid and Manvinder Singh and Mark Iverson and Martin Görner and Mat Velloso and Mateo Wirth and Matt Davidow and Matt Miller and Matthew Rahtz and Matthew Watson and Meg Risdal and Mehran Kazemi and Michael Moynihan and Ming Zhang and Minsuk Kahng and Minwoo Park and Mofi Rahman and Mohit Khatwani and Natalie Dao and Nenshad Bardoliwalla and Nesh Devanathan and Neta Dumai and Nilay Chauhan and Oscar Wahltinez and Pankil Botarda and Parker Barnes and Paul Barham and Paul Michel and Pengchong Jin and Petko Georgiev and Phil Culliton and Pradeep Kuppala and Ramona Comanescu and Ramona Merhej and Reena Jana and Reza Ardeshir Rokni and Rishabh Agarwal and Ryan Mullins and Samaneh Saadat and Sara Mc Carthy and Sarah Cogan and Sarah Perrin and Sébastien MR Arnold and Sebastian Krause and Shengyang Dai and Shruti Garg"
      },
      {
        "title": "Legibility and predictability of robot motion",
        "abstract": "A key requirement for seamless human-robot collaboration is for the robot to make its intentions clear to its human collaborator. A collaborative robot's motion must be legible, or intent-expressive. Legibility is often described in the literature as and effect of predictable, unsurprising, or expected motion. Our central insight is that predictability and legibility are fundamentally different and often contradictory properties of motion. We develop a formalism to mathematically define and distinguish predictability and legibility of motion. We formalize the two based on inferences between trajectories and goals in opposing directions, drawing the analogy to action interpretation in psychology. We then propose mathematical models for these inferences based on optimizing cost, drawing the analogy to the principle of rational action. Our experiments validate our formalism's prediction that predictability and legibility can contradict …",
        "year": 2013,
        "authors": "Anca D Dragan and Kenton CT Lee and Siddhartha S Srinivasa"
      }
    ],
    "iYN86KEAAAAJ": [
      {
        "title": "Generative adversarial networks",
        "abstract": "We propose a new framework for estimating generative models via adversarial nets, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitatively evaluation of the generated samples.",
        "year": 2014,
        "authors": "Ian Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio"
      },
      {
        "title": "Deep learning",
        "abstract": "Kwang Gi Kim https://doi. org/10.4258/hir. 2016.22. 4.351 ing those who are beginning their careers in deep learning and artificial intelligence research. The other target audience consists of software engineers who may not have a background in machine learning or statistics but who nonetheless want to acquire this knowledge rapidly and begin using deep learning in their fields. Deep learning has already proven useful in many software disciplines, including computer vision, speech and audio processing, natural language processing, robotics, bioinformatics and chemistry, video games, search engines, online advertising and finance. This book has been organized into three parts so as to best accommodate a variety of readers. In Part I, the author intro duces basic mathematical tools and machine learning concepts. Part II describes the most established deep learning …",
        "year": 2016,
        "authors": "Ian Goodfellow"
      },
      {
        "title": "Explaining and Harnessing Adversarial Examples",
        "abstract": "Several machine learning models, including neural networks, consistently misclassify adversarial examples---inputs formed by applying small but intentionally worst-case perturbations to examples from the dataset, such that the perturbed input results in the model outputting an incorrect answer with high confidence. Early attempts at explaining this phenomenon focused on nonlinearity and overfitting. We argue instead that the primary cause of neural networks' vulnerability to adversarial perturbation is their linear nature. This explanation is supported by new quantitative results while giving the first explanation of the most intriguing fact about them: their generalization across architectures and training sets. Moreover, this view yields a simple and fast method of generating adversarial examples. Using this approach to provide examples for adversarial training, we reduce the test set error of a maxout network on the MNIST dataset.",
        "year": 2014,
        "authors": "Ian Goodfellow and Jon Shlens and Christian Szegedy"
      }
    ],
    "qTCXoLQAAAAJ": [
      {
        "title": "Secure control: Towards survivable cyber-physical systems",
        "abstract": "In this position paper we investigate the security of cyber-physical systems. We (1) identify and define the problem of secure control, (2) investigate the defenses that information security and control theory can provide, and (3) propose a set of challenges that need to be addressed to improve the survivability of cyber-physical systems.",
        "year": 2008,
        "authors": "Alvaro A Cardenas and Saurabh Amin and Shankar Sastry"
      },
      {
        "title": "Attacks against process control systems: risk assessment, detection, and response",
        "abstract": "In the last years there has been an increasing interest in the security of process control and SCADA systems. Furthermore, recent computer attacks such as the Stuxnet worm, have shown there are parties with the motivation and resources to effectively attack control systems.While previous work has proposed new security mechanisms for control systems, few of them have explored new and fundamentally different research problems for securing control systems when compared to securing traditional information technology (IT) systems. In particular, the sophistication of new malware attacking control systems--malware including zero-days attacks, rootkits created for control systems, and software signed by trusted certificate authorities--has shown that it is very difficult to prevent and detect these attacks based solely on IT system information.In this paper we show how, by incorporating knowledge of the physical …",
        "year": 2011,
        "authors": "Alvaro A Cárdenas and Saurabh Amin and Zong-Syun Lin and Yu-Lun Huang and Chi-Yen Huang and Shankar Sastry"
      },
      {
        "title": "Research challenges for the security of control systems.",
        "abstract": "In this paper we attempt to answer two questions:(1) Why should we be interested in the security of control systems? And (2) What are the new and fundamentally different requirements and problems for the security of control systems? We also propose a new mathematical framework to analyze attacks against control systems. Within this framework we formulate specific research problems to (1) detect attacks, and (2) survive attacks.",
        "year": 2008,
        "authors": "Alvaro A Cárdenas and Saurabh Amin and Shankar Sastry"
      }
    ],
    "Pk-959EAAAAJ": [
      {
        "title": "CNN architectures for large-scale audio classification",
        "abstract": "Convolutional Neural Networks (CNNs) have proven very effective in image classification and show promise for audio. We use various CNN architectures to classify the soundtracks of a dataset of 70M training videos (5.24 million hours) with 30,871 video-level labels. We examine fully connected Deep Neural Networks (DNNs), AlexNet [1], VGG [2], Inception [3], and ResNet [4]. We investigate varying the size of both training set and label vocabulary, finding that analogs of the CNNs used in image classification do well on our audio classification task, and larger training and label sets help up to a point. A model using embeddings from these classifiers does much better than raw features on the Audio Set [5] Acoustic Event Detection (AED) classification task.",
        "year": 2017,
        "authors": "Shawn Hershey and Sourish Chaudhuri and Daniel PW Ellis and Jort F Gemmeke and Aren Jansen and R Channing Moore and Manoj Plakal and Devin Platt and Rif A Saurous and Bryan Seybold and Malcolm Slaney and Ron J Weiss and Kevin Wilson"
      },
      {
        "title": "Looking to listen at the cocktail party: A speaker-independent audio-visual model for speech separation",
        "abstract": "We present a joint audio-visual model for isolating a single speech signal from a mixture of sounds such as other speakers and background noise. Solving this task using only audio as input is extremely challenging and does not provide an association of the separated speech signals with speakers in the video. In this paper, we present a deep network-based model that incorporates both visual and auditory signals to solve this task. The visual features are used to \"focus\" the audio on desired speakers in a scene and to improve the speech separation quality. To train our joint audio-visual model, we introduce AVSpeech, a new dataset comprised of thousands of hours of video segments from the Web. We demonstrate the applicability of our method to classic speech separation tasks, as well as real-world scenarios involving heated interviews, noisy bars, and screaming children, only requiring the user to specify the face of the person in the video whose speech they want to isolate. Our method shows clear advantage over state-of-the-art audio-only speech separation in cases of mixed speech. In addition, our model, which is speaker-independent (trained once, applicable to any speaker), produces better results than recent audio-visual speech separation methods that are speaker-dependent (require training a separate model for each speaker of interest).",
        "year": 2018,
        "authors": "Ariel Ephrat and Inbar Mosseri and Oran Lang and Tali Dekel and Kevin Wilson and Avinatan Hassidim and William T Freeman and Michael Rubinstein"
      },
      {
        "title": "Learning the speech front-end with raw waveform CLDNNs.",
        "abstract": "Learning an acoustic model directly from the raw waveform has been an active area of research. However, waveformbased models have not yet matched the performance of logmel trained neural networks. We will show that raw waveform features match the performance of log-mel filterbank energies when used with a state-of-the-art CLDNN acoustic model trained on over 2,000 hours of speech. Specifically, we will show the benefit of the CLDNN, namely the time convolution layer in reducing temporal variations, the frequency convolution layer for preserving locality and reducing frequency variations, as well as the LSTM layers for temporal modeling. In addition, by stacking raw waveform features with log-mel features, we achieve a 3% relative reduction in word error rate.",
        "year": 2015,
        "authors": "Tara N Sainath and Ron J Weiss and Andrew W Senior and Kevin W Wilson and Oriol Vinyals"
      }
    ],
    "S8D-DqEAAAAJ": [
      {
        "title": "Whole-home gesture recognition using wireless signals",
        "abstract": "This paper presents WiSee, a novel gesture recognition system that leverages wireless signals (e.g., Wi-Fi) to enable whole-home sensing and recognition of human gestures. Since wireless signals do not require line-of-sight and can traverse through walls, WiSee can enable whole-home gesture recognition using few wireless sources. Further, it achieves this goal without requiring instrumentation of the human body with sensing devices. We implement a proof-of-concept prototype of WiSee using USRP-N210s and evaluate it in both an office environment and a two- bedroom apartment. Our results show that WiSee can identify and classify a set of nine gestures with an average accuracy of 94%.",
        "year": 2013,
        "authors": "Qifan Pu and Sidhant Gupta and Shyamnath Gollakota and Shwetak Patel"
      },
      {
        "title": "Cloud Programming Simplified: A Berkeley View on Serverless Computing",
        "abstract": "Serverless cloud computing handles virtually all the system administration operations needed to make it easier for programmers to use the cloud. It provides an interface that greatly simplifies cloud programming, and represents an evolution that parallels the transition from assembly language to high-level programming languages. This paper gives a quick history of cloud computing, including an accounting of the predictions of the 2009 Berkeley View of Cloud Computing paper, explains the motivation for serverless computing, describes applications that stretch the current limits of serverless, and then lists obstacles and research opportunities required for serverless computing to fulfill its full potential. Just as the 2009 paper identified challenges for the cloud and predicted they would be addressed and that cloud use would accelerate, we predict these issues are solvable and that serverless computing will grow to dominate the future of cloud computing.",
        "year": 2019,
        "authors": "Eric Jonas and Johann Schleier-Smith and Vikram Sreekanti and Chia-Che Tsai and Anurag Khandelwal and Qifan Pu and Vaishaal Shankar and Joao Carreira and Karl Krauth and Neeraja Yadwadkar and Joseph E Gonzalez and Raluca Ada Popa and Ion Stoica and David A Patterson"
      },
      {
        "title": "Occupy the cloud: distributed computing for the 99%",
        "abstract": "Distributed computing remains inaccessible to a large number of users, in spite of many open source platforms and extensive commercial offerings. While distributed computation frameworks have moved beyond a simple map-reduce model, many users are still left to struggle with complex cluster management and configuration tools, even for running simple embarrassingly parallel jobs. We argue that stateless functions represent a viable platform for these users, eliminating cluster management overhead, fulfilling the promise of elasticity. Furthermore, using our prototype implementation, PyWren, we show that this model is general enough to implement a number of distributed computing models, such as BSP, efficiently. Extrapolating from recent trends in network bandwidth and the advent of disaggregated storage, we suggest that stateless functions are a natural fit for data processing in future computing …",
        "year": 2017,
        "authors": "Eric Jonas and Qifan Pu and Shivaram Venkataraman and Ion Stoica and Benjamin Recht"
      }
    ],
    "Kzj3HC8AAAAJ": [
      {
        "title": "Deterministic matrices matching the compressed sensing phase transitions of Gaussian random matrices",
        "abstract": "In compressed sensing, one takes samples of an N-dimensional vector using an matrix A, obtaining undersampled measurements. For random matrices with independent standard Gaussian entries, it is known that, when is k-sparse, there is a precisely determined phase transition: for a certain region in the (,)-phase diagram, convex optimization typically finds the sparsest solution, whereas outside that region, it typically fails. It has been shown empirically that the same property—with the same phase transition location—holds for a wide range of non-Gaussian random matrix ensembles. We report extensive experiments showing that the Gaussian phase transition also describes numerous deterministic matrices, including Spikes and Sines, Spikes and Noiselets, Paley Frames, Delsarte-Goethals Frames, Chirp Sensing Matrices, and Grassmannian Frames. Namely, for each of these deterministic matrices in turn, for …",
        "year": 2013,
        "authors": "Hatef Monajemi and Sina Jafarpour and Matan Gavish and Stat 330/CME 362 Collaboration and David L Donoho and Sivaram Ambikasaran and Sergio Bacallado and Dinesh Bharadia and Yuxin Chen and Young Choi and Mainak Chowdhury and Soham Chowdhury and Anil Damle and Will Fithian and Georges Goetz and Logan Grosenick and Sam Gross and Gage Hills and Michael Hornstein and Milinda Lakkam and Jason Lee and Jian Li and Linxi Liu and Carlos Sing-Long and Mike Marx and Akshay Mittal and Hatef Monajemi and Albert No and Reza Omrani and Leonid Pekelis and Junjie Qin and Kevin Raines and Ernest Ryu and Andrew Saxe and Dai Shi and Keith Siilats and David Strauss and Gary Tang and Chaojun Wang and Zoey Zhou and Zhen Zhu"
      },
      {
        "title": "Markov decision policies for dynamic video delivery in wireless caching networks",
        "abstract": "This paper proposes a video delivery strategy for dynamic streaming services which maximizes time-average streaming quality under a playback delay constraint in wireless caching networks. The network where popular videos encoded by scalable video coding are already stored in randomly distributed caching nodes is considered under adaptive video streaming concepts, and distance-based interference management is investigated in this paper. In this network model, a streaming user makes delay-constrained decisions depending on stochastic network states: 1) caching node for video delivery, 2) video quality, and 3) the quantity of video chunks to receive. Since wireless link activation for video delivery may introduce delays, different timescales for updating caching node association, video quality adaptation, and chunk amounts are considered. After associating with a caching node for video delivery, the …",
        "year": 2019,
        "authors": "Minseok Choi and Albert No and Mingyue Ji and Joongheon Kim"
      },
      {
        "title": "An information-theoretic justification for model pruning",
        "abstract": "We study the neural network (NN) compression problem, viewing the tension between the compression ratio and NN performance through the lens of rate-distortion theory. We choose a distortion metric that reflects the effect of NN compression on the model output and then derive the tradeoff between rate (compression ratio) and distortion. In addition to characterizing theoretical limits of NN compression, this formulation shows that pruning, implicitly or explicitly, must be a part of a good compression algorithm. This observation bridges a gap between parts of the literature pertaining to NN and data compression, respectively, providing insight into the empirical success of pruning for NN compression. Finally, we propose a novel pruning strategy derived from our information-theoretic formulation and show that it outperforms the relevant baselines on CIFAR-10 and ImageNet datasets.",
        "year": 2022,
        "authors": "Berivan Isik and Tsachy Weissman and Albert No"
      }
    ],
    "1FrpQaQAAAAJ": [
      {
        "title": "Discretized Streams: Fault-tolerant streaming computation at scale",
        "abstract": "Many \"big data\" applications must act on data in real time. Running these applications at ever-larger scales requires parallel platforms that automatically handle faults and stragglers. Unfortunately, current distributed stream processing models provide fault recovery in an expensive manner, requiring hot replication or long recovery times, and do not handle stragglers. We propose a new processing model, discretized streams (D-Streams), that overcomes these challenges. D-Streams enable a parallel recovery mechanism that improves efficiency over traditional replication and backup schemes, and tolerates stragglers. We show that they support a rich set of operators while attaining high per-node throughput similar to single-node systems, linear scaling to 100 nodes, sub-second latency, and sub-second fault recovery. Finally, D-Streams can easily be composed with batch and interactive query models like …",
        "year": 2013,
        "authors": "Matei Zaharia and Tathagata Das and Haoyuan Li and Timothy Hunter and Scott Shenker and Ion Stoica"
      },
      {
        "title": "Understanding Road Usage Patterns in Urban Areas",
        "abstract": "In this paper, we combine the most complete record of daily mobility, based on large-scale mobile phone data, with detailed Geographic Information System (GIS) data, uncovering previously hidden patterns in urban road usage. We find that the major usage of each road segment can be traced to its own - surprisingly few - driver sources. Based on this finding we propose a network of road usage by defining a bipartite network framework, demonstrating that in contrast to traditional approaches, which define road importance solely by topological measures, the role of a road segment depends on both: its betweeness and its degree in the road usage network. Moreover, our ability to pinpoint the few driver sources contributing to the major traffic flow allows us to create a strategy that achieves a significant reduction of the travel time across the entire road system, compared to a benchmark approach.",
        "year": 2012,
        "authors": "Pu Wang and Timothy Hunter and Alexandre M Bayen and Katja Schechtner and Marta C González"
      },
      {
        "title": "Path and travel time inference from GPS probe vehicle data",
        "abstract": "We consider the problem of estimating real-time traffic conditions from sparse, noisy GPS probe vehicle data. We specifically address arterial roads, which are also known as the secondary road network (highways are considered the primary road network). We consider several estimation problems: historical traffic patterns, real-time traffic conditions, and forecasting future traffic conditions. We assume that the data available for these estimation problems is a small set of sparsely traced vehicle trajectories, which represents a small fraction of the total vehicle flow through the network. We present an expectation maximization algorithm that simultaneously learns the likely paths taken by probe vehicles as well as the travel time distributions through the network. A case study using data from San Francisco taxis is used to illustrate the performance of the algorithm.",
        "year": 2009,
        "authors": "Timothy Hunter and Ryan Herring and Pieter Abbeel and Alexandre Bayen"
      }
    ],
    "jQl9RtkAAAAJ": [
      {
        "title": "Generative adversarial text to image synthesis",
        "abstract": "Automatic synthesis of realistic images from text would be interesting and useful, but current AI systems are still far from this goal. However, in recent years generic and powerful recurrent neural network architectures have been developed to learn discriminative text feature representations. Meanwhile, deep convolutional generative adversarial networks (GANs) have begun to generate highly compelling images of specific categories such as faces, album covers, room interiors and flowers. In this work, we develop a novel deep architecture and GAN formulation to effectively bridge these advances in text and image modeling, translating visual concepts from characters to pixels. We demonstrate the capability of our model to generate plausible images of birds and flowers from detailed text descriptions.",
        "year": 2016,
        "authors": "Scott Reed and Zeynep Akata and Xinchen Yan and Lajanugen Logeswaran and Bernt Schiele and Honglak Lee"
      },
      {
        "title": "Zero-shot learning-A comprehensive evaluation of the good, the bad and the ugly",
        "abstract": "Due to the importance of zero-shot learning, i.e., classifying images where there is a lack of labeled training data, the number of proposed approaches has recently increased steadily. We argue that it is time to take a step back and to analyze the status quo of the area. The purpose of this paper is three-fold. First, given the fact that there is no agreed upon zero-shot learning benchmark, we first define a new benchmark by unifying both the evaluation protocols and data splits of publicly available datasets used for this task. This is an important contribution as published results are often not comparable and sometimes even flawed due to, e.g., pre-training on zero-shot test classes. Moreover, we propose a new zero-shot learning dataset, the Animals with Attributes 2 (AWA2) dataset which we make publicly available both in terms of image features and the images themselves. Second, we compare and analyze a …",
        "year": 2019,
        "authors": "Yongqin Xian and Christoph H Lampert and Bernt Schiele and Zeynep Akata"
      },
      {
        "title": "Evaluation of Output Embeddings for Fine-Grained Image Classification",
        "abstract": "Image classification has advanced significantly in recent years with the availability of large-scale image sets. However, fine-grained classification remains a major challenge due to the annotation cost of large numbers of fine-grained categories. This project shows that compelling classification performance can be achieved on such categories even without labeled training data. Given image and class embeddings, we learn a compatibility function such that matching embeddings are assigned a higher score than mismatching ones; zero-shot classification of an image proceeds by finding the label yielding the highest joint compatibility score. We use state-of-the-art image features and focus on different supervised attributes and unsupervised output embeddings either derived from hierarchies or learned from unlabeled text corpora. We establish a substantially improved state-of-the-art on the Animals with Attributes and Caltech-UCSD Birds datasets. Most encouragingly, we demonstrate that purely unsupervised output embeddings (learned from Wikipedia and improved with fine-grained text) achieve compelling results, even outperforming the previous supervised state-of-the-art. By combining different output embeddings, we further improve results.",
        "year": 2015,
        "authors": "Zeynep Akata and Scott Reed and Daniel Walter and Honglak Lee and Bernt Schiele"
      }
    ],
    "zvz6LIYAAAAJ": [
      {
        "title": "When to trust your model: Model-based policy optimization",
        "abstract": "Designing effective model-based reinforcement learning algorithms is difficult because the ease of data generation must be weighed against the bias of model-generated data. In this paper, we study the role of model usage in policy optimization both theoretically and empirically. We first formulate and analyze a model-based reinforcement learning algorithm with a guarantee of monotonic improvement at each step. In practice, this analysis is overly pessimistic and suggests that real off-policy data is always preferable to model-generated on-policy data, but we show that an empirical estimate of model generalization can be incorporated into such analysis to justify model usage. Motivated by this analysis, we then demonstrate that a simple procedure of using short model-generated rollouts branched from real data has the benefits of more complicated model-based algorithms without the usual pitfalls. In particular, this approach surpasses the sample efficiency of prior model-based methods, matches the asymptotic performance of the best model-free algorithms, and scales to horizons that cause other model-based methods to fail entirely.",
        "year": 2019,
        "authors": "Michael Janner and Justin Fu and Marvin Zhang and Sergey Levine"
      },
      {
        "title": "Offline Reinforcement Learning as One Big Sequence Modeling Problem",
        "abstract": "Reinforcement learning (RL) is typically viewed as the problem of estimating single-step policies (for model-free RL) or single-step models (for model-based RL), leveraging the Markov property to factorize the problem in time. However, we can also view RL as a sequence modeling problem: predict a sequence of actions that leads to a sequence of high rewards. Viewed in this way, it is tempting to consider whether powerful, high-capacity sequence prediction models that work well in other supervised learning domains, such as natural-language processing, can also provide simple and effective solutions to the RL problem. To this end, we explore how RL can be reframed as\" one big sequence modeling\" problem, using state-of-the-art Transformer architectures to model distributions over sequences of states, actions, and rewards. Addressing RL as a sequence modeling problem significantly simplifies a range of design decisions: we no longer require separate behavior policy constraints, as is common in prior work on offline model-free RL, and we no longer require ensembles or other epistemic uncertainty estimators, as is common in prior work on model-based RL. All of these roles are filled by the same Transformer sequence model. In our experiments, we demonstrate the flexibility of this approach across imitation learning, goal-conditioned RL, and offline RL.",
        "year": 2021,
        "authors": "Michael Janner and Qiyang Li and Sergey Levine"
      }
    ],
    "okcbLqoAAAAJ": [
      {
        "title": "Adapting visual category models to new domains",
        "abstract": "Domain adaptation is an important emerging topic in computer vision. In this paper, we present one of the first studies of domain shift in the context of object recognition. We introduce a method that adapts object models acquired in a particular visual domain to new imaging conditions by learning a transformation that minimizes the effect of domain-induced changes in the feature distribution. The transformation is learned in a supervised manner and can be applied to categories for which there are no labeled examples in the new domain. While we focus our evaluation on object recognition tasks, the transform-based adaptation technique we develop is general and could be applied to non-image data. Another contribution is a new multi-domain object database, freely available for download. We experimentally demonstrate the ability of our method to improve recognition on categories with few or no target …",
        "year": 2010,
        "authors": "Kate Saenko and Brian Kulis and Mario Fritz and Trevor Darrell"
      },
      {
        "title": "Information-theoretic metric learning",
        "abstract": "In this paper, we present an information-theoretic approach to learning a Mahalanobis distance function. We formulate the problem as that of minimizing the differential relative entropy between two multivariate Gaussians under constraints on the distance function. We express this problem as a particular Bregman optimization problem---that of minimizing the LogDet divergence subject to linear constraints. Our resulting algorithm has several advantages over existing methods. First, our method can handle a wide variety of constraints and can optionally incorporate a prior on the distance function. Second, it is fast and scalable. Unlike most existing methods, no eigenvalue computations or semi-definite programming are required. We also present an online version and derive regret bounds for the resulting algorithm. Finally, we evaluate our method on a recent error reporting system for software called Clarify, in the …",
        "year": 2007,
        "authors": "Jason V Davis and Brian Kulis and Prateek Jain and Suvrit Sra and Inderjit S Dhillon"
      },
      {
        "title": "Kernel k-means: spectral clustering and normalized cuts",
        "abstract": "Kernel k-means and spectral clustering have both been used to identify clusters that are non-linearly separable in input space. Despite significant research, these methods have remained only loosely related. In this paper, we give an explicit theoretical connection between them. We show the generality of the weighted kernel k-means objective function, and derive the spectral clustering objective of normalized cut as a special case. Given a positive definite similarity matrix, our results lead to a novel weighted kernel k-means algorithm that monotonically decreases the normalized cut. This has important implications: a) eigenvector-based algorithms, which can be computationally prohibitive, are not essential for minimizing normalized cuts, b) various techniques, such as local search and acceleration schemes, may be used to improve the quality as well as speed of kernel k-means. Finally, we present results on …",
        "year": 2004,
        "authors": "Inderjit S Dhillon and Yuqiang Guan and Brian Kulis"
      }
    ],
    "X22nUYgAAAAJ": [
      {
        "title": "Apache Spark: a unified engine for big data processing",
        "abstract": "This open source computing framework unifies streaming, batch, and interactive big data workloads to unlock new applications.",
        "year": 2016,
        "authors": "Matei Zaharia and Reynold S Xin and Patrick Wendell and Tathagata Das and Michael Armbrust and Ankur Dave and Xiangrui Meng and Josh Rosen and Shivaram Venkataraman and Michael J Franklin and Ali Ghodsi and Joseph Gonzalez and Scott Shenker and Ion Stoica"
      },
      {
        "title": "MLlib: Machine Learning in Apache Spark",
        "abstract": "On-line portfolio selection is a practical financial engineering problem, which aims to sequentially allocate capital among a set of assets in order to maximize long-term return. In recent years, a variety of machine learning algorithms have been proposed to address this challenging problem, but no comprehensive open-source toolbox has been released for various reasons. This article presents the first open-source toolbox for \"On-Line Portfolio Selection\" (OLPS), which implements a collection of classical and state-of-the-art strategies powered by machine learning algorithms. We hope that OLPS can facilitate the development of new learning methods and enable the performance benchmarking and comparisons of different strategies. OLPS is an open-source project released under Apache License (version 2.0), which is available at https://github.com/OLPS/ or http://OLPS.stevenhoi.org/.",
        "year": 2016,
        "authors": "Xiangrui Meng and Joseph Bradley and Burak Yavuz and Evan Sparks and Shivaram Venkataraman and Davies Liu and Jeremy Freeman and DB Tsai and Manish Amde and Sean Owen and Doris Xin and Reynold Xin and Michael J Franklin and Reza Zadeh and Matei Zaharia and Ameet Talwalkar"
      },
      {
        "title": "Spark SQL: Relational Data Processing in Spark",
        "abstract": "Spark SQL is a new module in Apache Spark that integrates relational processing with Spark's functional programming API. Built on our experience with Shark, Spark SQL lets Spark programmers leverage the benefits of relational processing (e.g. declarative queries and optimized storage), and lets SQL users call complex analytics libraries in Spark (e.g. machine learning). Compared to previous systems, Spark SQL makes two main additions. First, it offers much tighter integration between relational and procedural processing, through a declarative DataFrame API that integrates with procedural Spark code. Second, it includes a highly extensible optimizer, Catalyst, built using features of the Scala programming language, that makes it easy to add composable rules, control code generation, and define extension points. Using Catalyst, we have built a variety of features (e.g. schema inference for JSON, machine …",
        "year": 2015,
        "authors": "Michael Armbrust and Reynold S Xin and Cheng Lian and Yin Huai and Davies Liu and Joseph K Bradley and Xiangrui Meng and Tomer Kaftan and Michael J Franklin and Ali Ghodsi and Matei Zaharia"
      }
    ],
    "nGUcGrYAAAAJ": [
      {
        "title": "Epopt: Learning robust neural network policies using model ensembles",
        "abstract": "Sample complexity and safety are major challenges when learning policies with reinforcement learning for real-world tasks, especially when the policies are represented using rich function approximators like deep neural networks. Model-based methods where the real-world target domain is approximated using a simulated source domain provide an avenue to tackle the above challenges by augmenting real data with simulated data. However, discrepancies between the simulated source domain and the target domain pose a challenge for simulated training. We introduce the EPOpt algorithm, which uses an ensemble of simulated source domains and a form of adversarial training to learn policies that are robust and generalize to a broad range of possible target domains, including unmodeled effects. Further, the probability distribution over source domains in the ensemble can be adapted using data from target domain and approximate Bayesian methods, to progressively make it a better approximation. Thus, learning on a model ensemble, along with source domain adaptation, provides the benefit of both robustness and learning/adaptation.",
        "year": 2016,
        "authors": "Aravind Rajeswaran and Sarvjeet Ghotra and Balaraman Ravindran and Sergey Levine"
      },
      {
        "title": "An autoencoder approach to learning bilingual word representations",
        "abstract": "Cross-language learning allows us to use training data from one language to build models for a different language. Many approaches to bilingual learning require that we have word-level alignment of sentences from parallel corpora. In this work we explore the use of autoencoder-based methods for cross-language learning of vectorial word representations that are aligned between two languages, while not relying on word-level alignments. We show that by simply learning to reconstruct the bag-of-words representations of aligned sentences, within and between languages, we can in fact learn high-quality representations and do without word alignments. We empirically investigate the success of our approach on the problem of cross-language text classification, where a classifier trained on a given language (eg, English) must learn to generalize to a different language (eg, German). In experiments on 3 language pairs, we show that our approach achieves state-of-the-art performance, outperforming a method exploiting word alignments and a strong machine translation baseline.",
        "year": 2014,
        "authors": "Sarath Chandar AP and Stanislas Lauly and Hugo Larochelle and Mitesh Khapra and Balaraman Ravindran and Vikas C Raykar and Amrita Saha"
      },
      {
        "title": "Efficient computation of the Shapley value for game-theoretic network centrality",
        "abstract": "The Shapley value---probably the most important normative payoff division scheme in coalitional games---has recently been advocated as a useful measure of centrality in networks. However, although this approach has a variety of real-world applications (including social and organisational networks, biological networks and communication networks), its computational properties have not been widely studied. To date, the only practicable approach to compute Shapley value-based centrality has been via Monte Carlo simulations which are computationally expensive and not guaranteed to give an exact answer. Against this background, this paper presents the first study of the computational aspects of the Shapley value for network centralities. Specifically, we develop exact analytical formulae for Shapley value-based centrality in both weighted and unweighted networks and develop efficient (polynomial time) and exact algorithms based on them. We empirically evaluate these algorithms on two real-life examples (an infrastructure network representing the topology of the Western States Power Grid and a collaboration network from the field of astrophysics) and demonstrate that they deliver significant speedups over the Monte Carlo approach. For instance, in the case of unweighted networks our algorithms are able to return the exact solution about 1600 times faster than the Monte Carlo approximation, even if we allow for a generous 10% error margin for the latter method.",
        "year": 2013,
        "authors": "Tomasz P Michalak and Karthik V Aadithya and Piotr L Szczepanski and Balaraman Ravindran and Nicholas R Jennings"
      }
    ],
    "fkGi-JMAAAAJ": [
      {
        "title": "Calibrating noise to sensitivity in private data analysis",
        "abstract": "We continue a line of research initiated in [10,11]on privacy-preserving statistical databases. Consider a trusted server that holds a database of sensitive information. Given a query function f mapping databases to reals, the so-called true answer is the result of applying f to the database. To protect privacy, the true answer is perturbed by the addition of random noise generated according to a carefully chosen distribution, and this response, the true answer plus noise, is returned to the user.Previous work focused on the case of noisy sums, in which f = ∑ i  g(x  i ), where x  i  denotes the ith row of the database and g maps database rows to [0,1]. We extend the study to general functions f, proving that privacy can be preserved by calibrating the standard deviation of the noise according to the sensitivity of the function f …",
        "year": 2006,
        "authors": "Cynthia Dwork and Frank McSherry and Kobbi Nissim and Adam Smith"
      },
      {
        "title": "Fuzzy extractors: How to generate strong keys from biometrics and other noisy data",
        "abstract": "We provide formal definitions and efficient secure techniques for    turning biometric information into keys usable for any cryptographic application, and   reliably and securely authenticating biometric data.   turning biometric information into keys usable for any cryptographic application, andreliably and securely authenticating biometric data.Our techniques apply not just to biometric information, but to any keying material that, unlike traditional cryptographic keys, is (1) not reproducible precisely and (2) not distributed uniformly. We propose two primitives: a fuzzy extractor extracts nearly uniform randomness R from its biometric input; the extraction is error-tolerant in the sense that R will be the same even if the input changes, as long as it remains reasonably close to the original. Thus, R can be used as a key in any cryptographic application. A secure sketch produces public information about its biometric input w that does not reveal w, and yet allows exact …",
        "year": 2004,
        "authors": "Yevgeniy Dodis and Leonid Reyzin and Adam Smith"
      },
      {
        "title": "What can we learn privately?",
        "abstract": "Learning problems form an important category of computational tasks that generalizes many of the computations researchers apply to large real-life data sets. We ask, What concept classes can be learned privately, namely, by an algorithm whose output does not depend too heavily on any one input or specific training example? More precisely, we investigate learning algorithms that satisfy differential privacy, a notion that provides strong confidentiality guarantees in contexts where aggregate information is released about a database containing sensitive information about individuals. Our goal is a broad understanding of the resources required for private learning in terms of samples, computation time, and interaction. We demonstrate that, ignoring computational constraints, it is possible to privately agnostically learn any concept class using a sample size approximately logarithmic in the cardinality of the concept …",
        "year": 2008,
        "authors": "Shiva Prasad Kasiviswanathan and Homin K Lee and Kobbi Nissim and Sofya Raskhodnikova and Adam Smith"
      }
    ],
    "jH_7A6gAAAAJ": [
      {
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models",
        "abstract": "Large, high-capacity models trained on diverse datasets have shown remarkable successes on efficiently tackling downstream applications. In domains from NLP to Computer Vision, this has led to a consolidation of pretrained models, with general pretrained backbones serving as a starting point for many applications. Can such a consolidation happen in robotics? Conventionally, robotic learning methods train a separate model for every application, every robot, and even every environment. Can we instead train \"generalist\" X-robot policy that can be adapted efficiently to new robots, tasks, and environments? In this paper, we provide datasets in standardized data formats and models to make it possible to explore this possibility in the context of robotic manipulation, alongside experimental results that provide an example of effective X-robot policies. We assemble a dataset from 22 different robots collected through …",
        "year": 2024,
        "authors": "Abby O’Neill and Abdul Rehman and Abhiram Maddukuri and Abhishek Gupta and Abhishek Padalkar and Abraham Lee and Acorn Pooley and Agrim Gupta and Ajay Mandlekar and Ajinkya Jain and Albert Tung and Alex Bewley and Alex Herzog and Alex Irpan and Alexander Khazatsky and Anant Rai and Anchit Gupta and Andrew Wang and Anikait Singh and Animesh Garg and Aniruddha Kembhavi and Annie Xie and Anthony Brohan and Antonin Raffin and Archit Sharma and Arefeh Yavary and Arhan Jain and Ashwin Balakrishna and Ayzaan Wahid and Ben Burgess-Limerick and Beomjoon Kim and Bernhard Schölkopf and Blake Wulfe and Brian Ichter and Cewu Lu and Charles Xu and Charlotte Le and Chelsea Finn and Chen Wang and Chenfeng Xu and Cheng Chi and Chenguang Huang and Christine Chan and Christopher Agia and Chuer Pan and Chuyuan Fu and Coline Devin and Danfei Xu and Daniel Morton and Danny Driess and Daphne Chen and Deepak Pathak and Dhruv Shah and Dieter Büchler and Dinesh Jayaraman and Dmitry Kalashnikov and Dorsa Sadigh and Edward Johns and Ethan Foster and Fangchen Liu and Federico Ceola and Fei Xia and Feiyu Zhao and Freek Stulp and Zhou"
      },
      {
        "title": "FMB: A functional manipulation benchmark for generalizable robotic learning",
        "abstract": "In this paper, we propose a real-world benchmark for studying robotic learning in the context of functional manipulation: a robot needs to accomplish complex long-horizon behaviors by composing individual manipulation skills in functionally relevant ways. The core design principles of our Functional Manipulation Benchmark (FMB) emphasize a harmonious balance between complexity and accessibility. Tasks are deliberately scoped to be narrow, ensuring that models and datasets of manageable scale can be utilized effectively to track progress. Simultaneously, they are diverse enough to pose a significant generalization challenge. Furthermore, the benchmark is designed to be easily replicable, encompassing all essential hardware and software components. To achieve this goal, FMB consists of a variety of 3D-printed objects designed for easy and accurate replication by other researchers. The objects are …",
        "year": 2023,
        "authors": "Jianlan Luo and Charles Xu and Fangchen Liu and Liam Tan and Zipeng Lin and Jeffrey Wu and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Action-quantized offline reinforcement learning for robotic skill learning",
        "abstract": "The offline reinforcement learning (RL) paradigm provides a general recipe to convert static behavior datasets into policies that can perform better than the policy that collected the data. While policy constraints, conservatism, and other methods for mitigating distributional shifts have made offline reinforcement learning more effective, the continuous action setting often necessitates various approximations for applying these techniques. Many of these challenges are greatly alleviated in discrete action settings, where offline RL constraints and regularizers can often be computed more precisely or even exactly. In this paper, we propose an adaptive scheme for action quantization. We use a VQ-VAE to learn state-conditioned action quantization, avoiding the exponential blowup that comes with naïve discretization of the action space. We show that several state-of-the-art offline RL methods such as IQL, CQL, and BRAC improve in performance on benchmarks when combined with our proposed discretization scheme. We further validate our approach on a set of challenging long-horizon complex robotic manipulation tasks in the Robomimic environment, where our discretized offline RL algorithms are able to improve upon their continuous counterparts by 2-3x. Our project page is at saqrl. github. io",
        "year": 2023,
        "authors": "Jianlan Luo and Perry Dong and Jeffrey Wu and Aviral Kumar and Xinyang Geng and Sergey Levine"
      }
    ],
    "Sbpra_AAAAAJ": [
      {
        "title": "Of Moments and Matching: A Game-Theoretic Framework for Closing the Imitation Gap",
        "abstract": "We provide a unifying view of a large family of previous imitation learning algorithms through the lens of moment matching. At its core, our classification scheme is based on whether the learner attempts to match (1) reward or (2) action-value moments of the expert’s behavior, with each option leading to differing algorithmic approaches. By considering adversarially chosen divergences between learner and expert behavior, we are able to derive bounds on policy performance that apply for all algorithms in each of these classes, the first to our knowledge. We also introduce the notion of moment recoverability, implicit in many previous analyses of imitation learning, which allows us to cleanly delineate how well each algorithmic family is able to mitigate compounding errors. We derive three novel algorithm templates (AdVIL, AdRIL, and DAeQuIL) with strong guarantees, simple implementation, and competitive empirical performance.",
        "year": 2021,
        "authors": "Gokul Swamy and Sanjiban Choudhury and J Andrew Bagnell and Zhiwei Steven Wu"
      },
      {
        "title": "A Minimaximalist Approach to Reinforcement Learning from Human Feedback",
        "abstract": "We present Self-Play Preference Optimization (SPO), an algorithm for reinforcement learning from human feedback. Our approach is minimalist in that it does not require training a reward model nor unstable adversarial training and is therefore rather simple to implement. Our approach is maximalist in that it provably handles non-Markovian, intransitive, and stochastic preferences while being robust to the compounding errors that plague offline approaches to sequential prediction. To achieve the preceding qualities, we build upon the concept of a Minimax Winner (MW), a notion of preference aggregation from the social choice theory literature that frames learning from preferences as a zero-sum game between two policies. By leveraging the symmetry of this game, we prove that rather than using the traditional technique of dueling two policies to compute the MW, we can simply have a single agent play against itself while maintaining strong convergence guarantees. Practically, this corresponds to sampling multiple trajectories from a policy, asking a preference or teacher model to compare them, and then using the proportion of wins as the reward for a particular trajectory. We demonstrate that on a suite of continuous control tasks, we are able to learn significantly more efficiently than reward-model based approaches while maintaining robustness to the intransitive and stochastic preferences that frequently occur in practice when aggregating human judgments.",
        "year": 2024,
        "authors": "Gokul Swamy and Christoph Dann and Rahul Kidambi and Zhiwei Steven Wu and Alekh Agarwal"
      },
      {
        "title": "On the Utility of Model Learning in HRI",
        "abstract": "Fundamental to robotics is the debate between model-based and model-free learning: should the robot build an explicit model of the world, or learn a policy directly? In the context of HRI, part of the world to be modeled is the human. One option is for the robot to treat the human as a black box and learn a policy for how they act directly. But it can also model the human as an agent, and rely on a \"theory of mind\" to guide or bias the learning (grey box). We contribute a characterization of the performance of these methods for an autonomous driving task under the optimistic case of having an ideal theory of mind, as well as under different scenarios in which the assumptions behind the robot's theory of mind for the human are wrong, as they inevitably will be in practice.",
        "year": 2019,
        "authors": "Gokul Swamy and Jens Schulz and Rohan Choudhury and Dylan Hadfield-Menell and Anca Dragan"
      }
    ],
    "65FCPpwAAAAJ": [
      {
        "title": "R-max-a general polynomial time algorithm for near-optimal reinforcement learning",
        "abstract": "R-MAX is a very simple model-based reinforcement learning algorithm which can attain near-optimal average reward in polynomial time. In R-MAX, the agent always maintains a complete, but possibly inaccurate model of its environment and acts based on the optimal policy derived from this model. The model is initialized in an optimistic fashion: all actions in all states return the maximal possible reward (hence the name). During execution, it is updated based on the agent's observations. R-MAX improves upon several previous algorithms:(1) It is simpler and more general than Kearns and Singh's E^ 3 algorithm, covering zero-sum stochastic games.(2) It has a built-in mechanism for resolving the exploration vs. exploitation dilemma.(3) It formally justifies the``optimism under uncertainty''bias used in many RL algorithms.(4) It is simpler, more general, and more efficient than Brafman and Tennenholtz's LSG algorithm for learning in single controller stochastic games.(5) It generalizes the algorithm by Monderer and Tennenholtz for learning in repeated games.(6) It is the only algorithm for learning in repeated games, to date, which is provably efficient, considerably improving and simplifying previous algorithms by Banos and by Megiddo.",
        "year": 2002,
        "authors": "Ronen I Brafman and Moshe Tennenholtz"
      },
      {
        "title": "On social laws for artificial agent societies: off-line design",
        "abstract": "We are concerned with the utility of social laws in a computational environment, laws which guarantee the successful coexistence of multiple programs and programmers. In this paper we are interested in the off-line design of social laws, where we as designers must decide ahead of time on useful social laws. In the first part of this paper we suggest the use of social laws in the domain of mobile robots, and prove analytic results about the usefulness of this approach in that setting. In the second part of this paper we present a general model of social law in a computational system, and investigate some of its properties. This includes a definition of the basic computational problem involved with the design of multi-agent systems, and an investigation of the automatic synthesis of useful social laws in the framework of a model which refers explicitly to social laws.",
        "year": 1995,
        "authors": "Yoav Shoham and Moshe Tennenholtz"
      },
      {
        "title": "On the synthesis of useful social laws for artificial agent societies",
        "abstract": "We present a general model of social law in a computational system, and investigate some of its properties. The contribution of this paper is twofold. First, we argue that the notion of social law is not epiphenomenal, but rather should be built into the action representation; we then offer such a representation. Second, we investigate the complexity of automatically deriving useful social laws in this model, given descriptions of the agents' capabilities, and the goals they might encounter. We show that in general the problem is NP-complete, and identify precise conditions under which it becomes polynomial.",
        "year": 1992,
        "authors": "Yoav Shoham and Moshe Tennenholtz"
      }
    ],
    "wfGiqXEAAAAJ": [
      {
        "title": "Going deeper with convolutions",
        "abstract": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation of this architecture, GoogLeNet, a 22 layers deep network, was used to assess its quality in the context of object detection and classification.",
        "year": 2015,
        "authors": "Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich"
      },
      {
        "title": "Ssd: Single shot multibox detector",
        "abstract": "We present a method for detecting objects in images using a single deep neural network. Our approach, named SSD, discretizes the output space of bounding boxes into a set of default boxes over different aspect ratios and scales per feature map location. At prediction time, the network generates scores for the presence of each object category in each default box and produces adjustments to the box to better match the object shape. Additionally, the network combines predictions from multiple feature maps with different resolutions to naturally handle objects of various sizes. SSD is simple relative to methods that require object proposals because it completely eliminates proposal generation and subsequent pixel or feature resampling stages and encapsulates all computation in a single network. This makes SSD easy to train and straightforward to integrate into systems that require a detection component …",
        "year": 2016,
        "authors": "Wei Liu and Dragomir Anguelov and Dumitru Erhan and Christian Szegedy and Scott Reed and Cheng-Yang Fu and Alexander C Berg"
      },
      {
        "title": "Intriguing properties of neural networks",
        "abstract": "Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties. First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks. Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.",
        "year": 2013,
        "authors": "Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian Goodfellow and Rob Fergus"
      }
    ],
    "p0sQC6sAAAAJ": [
      {
        "title": "Spark: Cluster computing with working sets",
        "abstract": "MapReduce and its variants have been highly successful in implementing large-scale data-intensive applications on commodity clusters. However, most of these systems are built around an acyclic data flow model that is not suitable for other popular applications. This paper focuses on one such class of applications: those that reuse a working set of data across multiple parallel operations. This includes many iterative machine learning algorithms, as well as interactive data analysis tools. We propose a new framework called Spark that supports these applications while retaining the scalability and fault tolerance of MapReduce. To achieve these goals, Spark introduces an abstraction called resilient distributed datasets (RDDs). An RDD is a read-only collection of objects partitioned across a set of machines that can be rebuilt if a partition is lost. Spark can outperform Hadoop by 10x in iterative machine learning jobs, and can be used to interactively query a 39 GB dataset with sub-second response time.",
        "year": 2010,
        "authors": "Matei Zaharia and Mosharaf Chowdhury and Michael J Franklin and Scott Shenker and Ion Stoica"
      },
      {
        "title": "Resilient distributed datasets: A {Fault-Tolerant} abstraction for {In-Memory} cluster computing",
        "abstract": "We present Resilient Distributed Datasets (RDDs), a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a fault-tolerant manner. RDDs are motivated by two types of applications that current computing frameworks handle inefficiently: iterative algorithms and interactive data mining tools. In both cases, keeping data in memory can improve performance by an order of magnitude. To achieve fault tolerance efficiently, RDDs provide a restricted form of shared memory, based on coarse-grained transformations rather than fine-grained updates to shared state. However, we show that RDDs are expressive enough to capture a wide class of computations, including recent specialized programming models for iterative jobs, such as Pregel, and new applications that these models do not capture. We have implemented RDDs in a system called Spark, which we evaluate through a variety of user applications and benchmarks.",
        "year": 2012,
        "authors": "Matei Zaharia and Mosharaf Chowdhury and Tathagata Das and Ankur Dave and Justin Ma and Murphy McCauly and Michael J Franklin and Scott Shenker and Ion Stoica"
      },
      {
        "title": "TAG: A tiny aggregation service for ad-hoc sensor networks",
        "abstract": "We present the Tiny AGgregation (TAG) service for aggregation in low-power, distributed, wireless environments. TAG allows users to express simple, declarative queries and have them distributed and executed efficiently in networks of low-power, wireless sensors. We discuss various generic properties of aggregates, and show how those properties affect the performance of our in network approach. We include a performance study demonstrating the advantages of our approach over traditional centralized, out-of-network methods, and discuss a variety of optimizations for improving the performance and fault tolerance of the basic solution.",
        "year": 2002,
        "authors": "Samuel Madden and Michael J Franklin and Joseph M Hellerstein and Wei Hong"
      }
    ],
    "QCBdB7AAAAAJ": [
      {
        "title": "Mujoco: A physics engine for model-based control",
        "abstract": "We describe a new physics engine tailored to model-based control. Multi-joint dynamics are represented in generalized coordinates and computed via recursive algorithms. Contact responses are computed via efficient new algorithms we have developed, based on the modern velocity-stepping approach which avoids the difficulties with spring-dampers. Models are specified using either a high-level C++ API or an intuitive XML file format. A built-in compiler transforms the user model into an optimized data structure used for runtime computation. The engine can compute both forward and inverse dynamics. The latter are well-defined even in the presence of contacts and equality constraints. The model can include tendon wrapping as well as actuator activation states (e.g. pneumatic cylinders or muscles). To facilitate optimal control applications and in particular sampling and finite differencing, the dynamics can be …",
        "year": 2012,
        "authors": "Emanuel Todorov and Tom Erez and Yuval Tassa"
      },
      {
        "title": "Optimal feedback control as a theory of motor coordination",
        "abstract": "A central problem in motor control is understanding how the many biomechanical degrees of freedom are coordinated to achieve a common goal. An especially puzzling aspect of coordination is that behavioral goals are achieved reliably and repeatedly with movements rarely reproducible in their detail. Existing theoretical frameworks emphasize either goal achievement or the richness of motor variability, but fail to reconcile the two. Here we propose an alternative theory based on stochastic optimal feedback control. We show that the optimal strategy in the face of uncertainty is to allow variability in redundant (task-irrelevant) dimensions. This strategy does not enforce a desired trajectory, but uses feedback more intelligently, correcting only those deviations that interfere with task goals. From this framework, task-constrained variability, goal-directed corrections, motor synergies, controlled parameters, simplifying …",
        "year": 2002,
        "authors": "Emanuel Todorov and Michael I Jordan"
      },
      {
        "title": "Optimality principles in sensorimotor control",
        "abstract": "The sensorimotor system is a product of evolution, development, learning and adaptation—which work on different time scales to improve behavioral performance. Consequently, many theories of motor function are based on 'optimal performance': they quantify task goals as cost functions, and apply the sophisticated tools of optimal control theory to obtain detailed behavioral predictions. The resulting models, although not without limitations, have explained more empirical phenomena than any other class. Traditional emphasis has been on optimizing desired movement trajectories while ignoring sensory feedback. Recent work has redefined optimality in terms of feedback control laws, and focused on the mechanisms that generate behavior online. This approach has allowed researchers to fit previously unrelated concepts and observations into what may become a unified theoretical framework for interpreting …",
        "year": 2004,
        "authors": "Emanuel Todorov"
      }
    ],
    "zP0S_ikAAAAJ": [
      {
        "title": "Ray: A distributed framework for emerging {AI} applications",
        "abstract": "The next generation of AI applications will continuously interact with the environment and learn from these interactions. These applications impose new and demanding systems requirements, both in terms of performance and flexibility. In this paper, we consider these requirements and present Ray—a distributed system to address them. Ray implements a unified interface that can express both task-parallel and actor-based computations, supported by a single dynamic execution engine. To meet the performance requirements, Ray employs a distributed scheduler and a distributed and fault-tolerant store to manage the system’s control state. In our experiments, we demonstrate scaling beyond 1.8 million tasks per second and better performance than existing specialized systems for several challenging reinforcement learning applications.",
        "year": 2018,
        "authors": "Philipp Moritz and Robert Nishihara and Stephanie Wang and Alexey Tumanov and Richard Liaw and Eric Liang and Melih Elibol and Zongheng Yang and William Paul and Michael I Jordan and Ion Stoica"
      },
      {
        "title": "RLlib: Abstractions for distributed reinforcement learning",
        "abstract": "Reinforcement learning (RL) algorithms involve the deep nesting of highly irregular computation patterns, each of which typically exhibits opportunities for distributed computation. We argue for distributing RL components in a composable way by adapting algorithms for top-down hierarchical control, thereby encapsulating parallelism and resource requirements within short-running compute tasks. We demonstrate the benefits of this principle through RLlib: a library that provides scalable software primitives for RL. These primitives enable a broad range of algorithms to be implemented with high performance, scalability, and substantial code reuse. RLlib is available as part of the open source Ray project at http://rllib. io/.",
        "year": 2018,
        "authors": "Eric Liang and Richard Liaw and Robert Nishihara and Philipp Moritz and Roy Fox and Ken Goldberg and Joseph Gonzalez and Michael Jordan and Ion Stoica"
      },
      {
        "title": "Tune: A research platform for distributed model selection and training",
        "abstract": "Modern machine learning algorithms are increasingly computationally demanding, requiring specialized hardware and distributed computation to achieve high performance in a reasonable time frame. Many hyperparameter search algorithms have been proposed for improving the efficiency of model selection, however their adaptation to the distributed compute environment is often ad-hoc. We propose Tune, a unified framework for model selection and training that provides a narrow-waist interface between training scripts and search algorithms. We show that this interface meets the requirements for a broad range of hyperparameter search algorithms, allows straightforward scaling of search to large clusters, and simplifies algorithm implementation. We demonstrate the implementation of several state-of-the-art hyperparameter search algorithms in Tune. Tune is available at http://ray.readthedocs.io/en/latest/tune.html.",
        "year": 2018,
        "authors": "Richard Liaw and Eric Liang and Robert Nishihara and Philipp Moritz and Joseph E Gonzalez and Ion Stoica"
      }
    ],
    "U89FHq4AAAAJ": [
      {
        "title": "Practical bayesian optimization of machine learning algorithms",
        "abstract": "The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a “black art” requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm’s generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expert-level performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including Latent Dirichlet Allocation, Structured SVMs and convolutional neural networks.",
        "year": 2012,
        "authors": "Jasper Snoek and Hugo Larochelle and Ryan P Adams"
      },
      {
        "title": "Domain-adversarial training of neural networks",
        "abstract": "We consider the recovery of a low rank real-valued matrix M given a subset of noisy discrete (or quantized) measurements. Such problems arise in several applications such as collaborative filtering, learning and content analytics, and sensor network localization. We consider constrained maximum likelihood estimation of M, under a constraint on the entry-wise infinity-norm of M and an exact rank constraint. We provide upper bounds on the Frobenius norm of matrix estimation error under this model. Previous theoretical investigations have focused on binary (1-bit) quantizers, and been based on convex relaxation of the rank. Compared to the existing binary results, our performance upper bound has faster convergence rate with matrix dimensions when the fraction of revealed observations is fixed. We also propose a globally convergent optimization algorithm based on low rank factorization of M and validate the method on synthetic and real data, with improved performance over previous methods.",
        "year": 2016,
        "authors": "Yaroslav Ganin and Evgeniya Ustinova and Hana Ajakan and Pascal Germain and Hugo Larochelle and François Laviolette and Mario March and Victor Lempitsky"
      },
      {
        "title": "Extracting and composing robust features with denoising autoencoders",
        "abstract": "Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite.",
        "year": 2008,
        "authors": "Pascal Vincent and Hugo Larochelle and Yoshua Bengio and Pierre-Antoine Manzagol"
      }
    ],
    "gRxBNZoAAAAJ": [
      {
        "title": "Man is to computer programmer as woman is to homemaker? Debiasing word embeddings",
        "abstract": "The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is first shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender definition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between the words receptionist and female, while maintaining desired associations such as between the words queen and female. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias.",
        "year": 2016,
        "authors": "Tolga Bolukbasi and Kai-Wei Chang and James Y Zou and Venkatesh Saligrama and Adam T Kalai"
      },
      {
        "title": "Online convex optimization in the bandit setting: gradient descent without a gradient",
        "abstract": "We consider a the general online convex optimization framework introduced by Zinkevich. In this setting, there is a sequence of convex functions. Each period, we must choose a signle point (from some feasible set) and pay a cost equal to the value of the next function on our chosen point. Zinkevich shows that, if the each function is revealed after the choice is made, then one can achieve vanishingly small regret relative the best single decision chosen in hindsight. We extend this to the bandit setting where we do not find out the entire functions but rather just their value at our chosen point. We show how to get vanishingly small regret in this setting. Our approach uses a simple approximation of the gradient that is computed from evaluating a function at a single (random) point. We show that this estimate is sufficient to mimic Zinkevich's gradient descent online analysis, with access to the gradient (only being able to evaluate the function at a single point).",
        "year": 2005,
        "authors": "Abraham D Flaxman and Adam Tauman Kalai and H Brendan McMahan"
      },
      {
        "title": "Efficient algorithms for online decision problems",
        "abstract": "In an online decision problem, one makes a sequence of decisions without knowledge of the future. Each period, one pays a cost based on the decision and observed state. We give a simple approach for doing nearly as well as the best single decision, where the best is chosen with the benefit of hindsight. A natural idea is to follow the leader, i.e. each period choose the decision which has done best so far. We show that by slightly perturbing the totals and then choosing the best decision, the expected performance is nearly as good as the best decision in hindsight. Our approach, which is very much like Hannan's original game-theoretic approach from the 1950s, yields guarantees competitive with the more modern exponential weighting algorithms like Weighted Majority. More importantly, these follow-the-leader style algorithms extend naturally to a large class of structured online problems for which the …",
        "year": 2005,
        "authors": "Adam Kalai and Santosh Vempala"
      }
    ],
    "a3K-f2YAAAAJ": [
      {
        "title": "Deformation transfer for triangle meshes",
        "abstract": "Deformation transfer applies the deformation exhibited by a source triangle mesh onto a different target triangle mesh. Our approach is general and does not require the source and target to share the same number of vertices or triangles, or to have identical connectivity. The user builds a correspondence map between the triangles of the source and those of the target by specifying a small set of vertex markers. Deformation transfer computes the set of transformations induced by the deformation of the source mesh, maps the transformations through the correspondence from the source to the target, and solves an optimization problem to consistently apply the transformations to the target shape. The resulting system of linear equations can be factored once, after which transferring a new deformation to the target mesh requires only a backsubstitution step. Global properties such as foot placement can be achieved by …",
        "year": 2004,
        "authors": "Robert W Sumner and Jovan Popović"
      },
      {
        "title": "Real-time hand-tracking with a color glove",
        "abstract": "Articulated hand-tracking systems have been widely used in virtual reality but are rarely deployed in consumer applications due to their price and complexity. In this paper, we propose an easy-to-use and inexpensive system that facilitates 3-D articulated user-input using the hands. Our approach uses a single camera to track a hand wearing an ordinary cloth glove that is imprinted with a custom pattern. The pattern is designed to simplify the pose estimation problem, allowing us to employ a nearest-neighbor approach to track hands at interactive rates. We describe several proof-of-concept applications enabled by our system that we hope will provide a foundation for new interactions in modeling, animation control and augmented reality.",
        "year": 2009,
        "authors": "Robert Y Wang and Jovan Popović"
      },
      {
        "title": "Automatic rigging and animation of 3d characters",
        "abstract": "Animating an articulated 3D character currently requires manual rigging to specify its internal skeletal structure and to define how the input motion deforms its surface. We present a method for animating characters automatically. Given a static character mesh and a generic skeleton, our method adapts the skeleton to the character and attaches it to the surface, allowing skeletal motion data to animate the character. Because a single skeleton can be used with a wide range of characters, our method, in conjunction with a library of motions for a few skeletons, enables a user-friendly animation system for novices and children. Our prototype implementation, called Pinocchio, typically takes under a minute to rig a character on a modern midrange PC.",
        "year": 2007,
        "authors": "Ilya Baran and Jovan Popović"
      }
    ],
    "bo0P2qYAAAAJ": [
      {
        "title": "End-to-end learning of driving models from large-scale video datasets",
        "abstract": "Robust perception-action models should be learned from training data with diverse visual appearances and realistic behaviors, yet current approaches to deep visuomotor policy learning have been generally limited to in-situ models learned from a single vehicle or simulation environment. We advocate learning a generic vehicle motion model from large scale crowd-sourced video data, and develop an end-to-end trainable architecture for learning to predict a distribution over future vehicle egomotion from instantaneous monocular camera observations and previous vehicle state. Our model incorporates a novel FCN-LSTM architecture, which can be learned from large-scale crowd-sourced vehicle action data, and leverages available scene segmentation side tasks to improve performance under a privileged learning paradigm. We provide a novel large-scale dataset of crowd-sourced driving behavior suitable for training our model, and report results predicting the driver action on held out sequences across diverse conditions.",
        "year": 2017,
        "authors": "Huazhe Xu and Yang Gao and Fisher Yu and Trevor Darrell"
      },
      {
        "title": "Compact bilinear pooling",
        "abstract": "Bilinear models has been shown to achieve impressive performance on a wide range of visual tasks, such as semantic segmentation, fine grained recognition and face recognition. However, bilinear features are high dimensional, typically on the order of hundreds of thousands to a few million, which makes them impractical for subsequent analysis. We propose two compact bilinear representations with the same discriminative power as the full bilinear representation but with only a few thousand dimensions. Our compact representations allow back-propagation of classification errors enabling an end-to-end optimization of the visual recognition system. The compact bilinear representations are derived through a novel kernelized analysis of bilinear pooling which provide insights into the discriminative power of bilinear pooling, and a platform for further research in compact pooling methods. Experimentation illustrate the utility of the proposed representations for image classification and few-shot learning across several datasets.",
        "year": 2016,
        "authors": "Yang Gao and Oscar Beijbom and Ning Zhang and Trevor Darrell"
      },
      {
        "title": "Deep learning for tactile understanding from visual and haptic data",
        "abstract": "Robots which interact with the physical world will benefit from a fine-grained tactile understanding of objects and surfaces. Additionally, for certain tasks, robots may need to know the haptic properties of an object before touching it. To enable better tactile understanding for robots, we propose a method of classifying surfaces with haptic adjectives (e.g., compressible or smooth) from both visual and physical interaction data. Humans typically combine visual predictions and feedback from physical interactions to accurately predict haptic properties and interact with the world. Inspired by this cognitive pattern, we propose and explore a purely visual haptic prediction model. Purely visual models enable a robot to “feel” without physical interaction. Furthermore, we demonstrate that using both visual and physical interaction signals together yields more accurate haptic classification. Our models take advantage of recent …",
        "year": 2016,
        "authors": "Yang Gao and Lisa Anne Hendricks and Katherine J Kuchenbecker and Trevor Darrell"
      }
    ],
    "FWp7728AAAAJ": [
      {
        "title": "Recurrent network models for human dynamics",
        "abstract": "We propose the Encoder-Recurrent-Decoder (ERD) model for recognition and prediction of human body pose in videos and motion capture. The ERD model is a recurrent neural network that incorporates nonlinear encoder and decoder networks before and after recurrent layers. We test instantiations of ERD architectures in the tasks of motion capture (mocap) generation, body pose labeling and body pose forecasting in videos. Our model handles mocap training data across multiple subjects and activity domains, and synthesizes novel motions while avoiding drifting for long periods of time. For human pose labeling, ERD outperforms a per frame body part detector by resolving left-right body part confusions. For video pose forecasting, ERD predicts body joint displacements across a temporal horizon of 400ms and outperforms a first order motion model based on optical flow. ERDs extend previous Long Short Term Memory (LSTM) models in the literature to jointly learn representations and their dynamics. Our experiments show such representation learning is crucial for both labeling and prediction in space-time. We find this is a distinguishing feature between the spatio-temporal visual domain in comparison to 1D text, speech or handwriting, where straightforward hard coded representations have shown excellent results when directly combined with recurrent units.",
        "year": 2015,
        "authors": "Katerina Fragkiadaki and Sergey Levine and Panna Felsen and Jitendra Malik"
      },
      {
        "title": "Human pose estimation with iterative error feedback",
        "abstract": "Hierarchical feature extractors such as Convolutional Networks (ConvNets) have achieved impressive performance on a variety of classification tasks using purely feedforward processing. Feedforward architectures can learn rich representations of the input space but do not explicitly model dependencies in the output spaces, that are quite structured for tasks such as articulated human pose estimation or object segmentation. Here we propose a framework that expands the expressive power of hierarchical feature extractors to encompass both input and output spaces, by introducing top-down feedback. Instead of directly predicting the outputs in one go, we use a self-correcting model that progressively changes an initial solution by feeding back error predictions, in a process we call Iterative Error Feedback (IEF). IEF shows excellent performance on the task of articulated pose estimation in the challenging MPII and LSP benchmarks, matching the state-of-the-art without requiring ground truth scale annotation.",
        "year": 2016,
        "authors": "Joao Carreira and Pulkit Agrawal and Katerina Fragkiadaki and Jitendra Malik"
      },
      {
        "title": "Sfm-net: Learning of structure and motion from video",
        "abstract": "We propose SfM-Net, a geometry-aware neural network for motion estimation in videos that decomposes frame-to-frame pixel motion in terms of scene and object depth, camera motion and 3D object rotations and translations. Given a sequence of frames, SfM-Net predicts depth, segmentation, camera and rigid object motions, converts those into a dense frame-to-frame motion field (optical flow), differentiably warps frames in time to match pixels and back-propagates. The model can be trained with various degrees of supervision: 1) self-supervised by the re-projection photometric error (completely unsupervised), 2) supervised by ego-motion (camera motion), or 3) supervised by depth (e.g., as provided by RGBD sensors). SfM-Net extracts meaningful depth estimates and successfully estimates frame-to-frame camera rotations and translations. It often successfully segments the moving objects in the scene, even though such supervision is never provided.",
        "year": 2017,
        "authors": "Sudheendra Vijayanarasimhan and Susanna Ricco and Cordelia Schmid and Rahul Sukthankar and Katerina Fragkiadaki"
      }
    ],
    "5bc-9A4AAAAJ": [
      {
        "title": "Nomad: Goal masked diffusion policies for navigation and exploration",
        "abstract": "Robotic learning for navigation in unfamiliar environments needs to provide policies for both task-oriented navigation (i.e., reaching a goal that the robot has located), and task-agnostic exploration (i.e., searching for a goal in a novel setting). Typically, these roles are handled by separate models, for example by using subgoal proposals, planning, or separate navigation strategies. In this paper, we describe how we can train a single unified diffusion policy to handle both goal-directed navigation and goal-agnostic exploration, with the latter providing the ability to search novel environments, and the former providing the ability to reach a user-specified goal once it has been located. We show that this unified policy results in better overall performance when navigating to visually indicated goals in novel environments, as compared to approaches that use subgoal proposals from generative models, or prior methods …",
        "year": 2024,
        "authors": "Ajay Sridhar and Dhruv Shah and Catherine Glossop and Sergey Levine"
      },
      {
        "title": "Pushing the limits of cross-embodiment learning for manipulation and navigation",
        "abstract": "Recent years in robotics and imitation learning have shown remarkable progress in training large-scale foundation models by leveraging data across a multitude of embodiments. The success of such policies might lead us to wonder: just how diverse can the robots in the training set be while still facilitating positive transfer? In this work, we study this question in the context of heterogeneous embodiments, examining how even seemingly very different domains, such as robotic navigation and manipulation, can provide benefits when included in the training data for the same model. We train a single goal-conditioned policy that is capable of controlling robotic arms, quadcopters, quadrupeds, and mobile bases. We then investigate the extent to which transfer can occur across navigation and manipulation on these embodiments by framing them as a single goal-reaching task. We find that co-training with navigation data can enhance robustness and performance in goal-conditioned manipulation with a wrist-mounted camera. We then deploy our policy trained only from navigation-only and static manipulation-only data on a mobile manipulator, showing that it can control a novel embodiment in a zero-shot manner. These results provide evidence that large-scale robotic policies can benefit from data collected across various embodiments. Further information and robot videos can be found on our project website http://extreme-cross-embodiment.github.io.",
        "year": 2024,
        "authors": "Jonathan Yang and Catherine Glossop and Arjun Bhorkar and Dhruv Shah and Quan Vuong and Chelsea Finn and Dorsa Sadigh and Sergey Levine"
      },
      {
        "title": "Lelan: Learning a language-conditioned navigation policy from in-the-wild videos",
        "abstract": "The world is filled with a wide variety of objects. For robots to be useful, they need the ability to find arbitrary objects described by people. In this paper, we present LeLaN(Learning Language-conditioned Navigation policy), a novel approach that consumes unlabeled, action-free egocentric data to learn scalable, language-conditioned object navigation. Our framework, LeLaN leverages the semantic knowledge of large vision-language models, as well as robotic foundation models, to label in-the-wild data from a variety of indoor and outdoor environments. We label over 130 hours of data collected in real-world indoor and outdoor environments, including robot observations, YouTube video tours, and human walking data. Extensive experiments with over 1000 real-world trials show that our approach enables training a policy from unlabeled action-free videos that outperforms state-of-the-art robot navigation methods, while being capable of inference at 4 times their speed on edge compute. We open-source our models, datasets and provide supplementary videos on our project page (https://learning-language-navigation.github.io/).",
        "year": 2024,
        "authors": "Noriaki Hirose and Catherine Glossop and Ajay Sridhar and Dhruv Shah and Oier Mees and Sergey Levine"
      }
    ],
    "osxb7aMAAAAJ": [
      {
        "title": "Bayesian learning in social networks",
        "abstract": "We study the (perfect Bayesian) equilibrium of a sequential learning model over a general social network. Each individual receives a signal about the underlying state of the world, observes the past actions of a stochastically generated neighbourhood of individuals, and chooses one of two possible actions. The stochastic process generating the neighbourhoods defines the network topology. We characterize pure strategy equilibria for arbitrary stochastic and deterministic social networks and characterize the conditions under which there will be asymptotic learning—convergence (in probability) to the right action as the social network becomes large. We show that when private beliefs are unbounded (meaning that the implied likelihood ratios are unbounded), there will be asymptotic learning as long as there is some minimal amount of “expansion in observations”. We also characterize conditions under which …",
        "year": 2011,
        "authors": "Daron Acemoglu and Munther A Dahleh and Ilan Lobel and Asuman Ozdaglar"
      },
      {
        "title": "Distributed subgradient methods for convex optimization over random networks",
        "abstract": "We consider the problem of cooperatively minimizing the sum of convex functions, where the functions represent local objective functions of the agents. We assume that each agent has information about his local function, and communicate with the other agents over a time-varying network topology. For this problem, we propose a distributed subgradient method that uses averaging algorithms for locally sharing information among the agents. In contrast to previous works on multi-agent optimization that make worst-case assumptions about the connectivity of the agents (such as bounded communication intervals between nodes), we assume that links fail according to a given stochastic process. Under the assumption that the link failures are independent and identically distributed over time (possibly correlated across links), we provide almost sure convergence results for our subgradient algorithm.",
        "year": 2011,
        "authors": "Ilan Lobel and Asuman Ozdaglar"
      },
      {
        "title": "Feature-based dynamic pricing",
        "abstract": "We consider the problem faced by a firm that receives highly differentiated products in an online fashion. The firm needs to price these products to sell them to its customer base. Products are described by vectors of features and the market value of each product is linear in the values of the features. The firm does not initially know the values of the different features, but can learn the values of the features based on whether products were sold at the posted prices in the past. This model is motivated by applications such as online marketplaces, online flash sales, and loan pricing. We first consider a multidimensional version of binary search over polyhedral sets and show that it has a worst-case regret which is exponential in the dimension of the feature space. We then propose a modification of the prior algorithm where uncertainty sets are replaced by their Löwner-John ellipsoids. We show that this algorithm has a …",
        "year": 2020,
        "authors": "Maxime C Cohen and Ilan Lobel and Renato Paes Leme"
      }
    ],
    "nTiSnwUAAAAJ": [
      {
        "title": "The Human Pangenome Project: a global resource to map genomic diversity",
        "abstract": "The human reference genome is the most widely used resource in human genetics and is due for a major update. Its current structure is a linear composite of merged haplotypes from more than 20 people, with a single individual comprising most of the sequence. It contains biases and errors within a framework that does not represent global human genomic variation. A high-quality reference with global representation of common variants, including single-nucleotide variants, structural variants and functional elements, is needed. The Human Pangenome Reference Consortium aims to create a more sophisticated and complete human reference genome with a graph-based, telomere-to-telomere representation of global genomic diversity. Here we leverage innovations in technology, study design and global partnerships with the goal of constructing the highest-possible quality human pangenome reference. Our goal …",
        "year": 2022,
        "authors": "Ting Wang and Lucinda Antonacci-Fulton and Kerstin Howe and Heather A Lawson and Julian K Lucas and Adam M Phillippy and Alice B Popejoy and Mobin Asri and Caryn Carson and Mark JP Chaisson and Xian Chang and Robert Cook-Deegan and Adam L Felsenfeld and Robert S Fulton and Erik P Garrison and Nanibaa’A Garrison and Tina A Graves-Lindsay and Hanlee Ji and Eimear E Kenny and Barbara A Koenig and Daofeng Li and Tobias Marschall and Joshua F McMichael and Adam M Novak and Deepak Purushotham and Valerie A Schneider and Baergen I Schultz and Michael W Smith and Heidi J Sofia and Tsachy Weissman and Paul Flicek and Heng Li and Karen H Miga and Benedict Paten and Erich D Jarvis and Ira M Hall and Evan E Eichler and David Haussler and Human Pangenome Reference Consortium"
      },
      {
        "title": "Inequalities for the L1 deviation of the empirical distribution",
        "abstract": "We derive bounds on the probability that the L1 distance between the empirical distribution of a sequence of independent identically distributed random variables and the true distribution is more than a specified value. We also derive a generalization of Pinsker’s inequality relating the L1 distance to the divergence.",
        "year": 2003,
        "authors": "Tsachy Weissman and Erik Ordentlich and Gadiel Seroussi and Sergio Verdu and Marcelo J Weinberger"
      },
      {
        "title": "Minimax estimation of functionals of discrete distributions",
        "abstract": "We propose a general methodology for the construction and analysis of essentially minimax estimators for a wide class of functionals of finite dimensional parameters, and elaborate on the case of discrete distributions, where the support size S is unknown and may be comparable with or even much larger than the number of observations n. We treat the respective regions where the functional is nonsmooth and smooth separately. In the nonsmooth regime, we apply an unbiased estimator for the best polynomial approximation of the functional whereas, in the smooth regime, we apply a bias-corrected version of the maximum likelihood estimator (MLE). We illustrate the merit of this approach by thoroughly analyzing the performance of the resulting schemes for estimating two important information measures: 1) the entropy H(P) = ΣSi=1 -pi ln pi and 2) Fα(P) = ΣSi=1 pαi, α > 0. We obtain the minimax L2 rates for …",
        "year": 2015,
        "authors": "Jiantao Jiao and Kartik Venkat and Yanjun Han and Tsachy Weissman"
      }
    ],
    "sgsLkM0AAAAJ": [
      {
        "title": "Visual Language Maps for Robot Navigation",
        "abstract": "Grounding language to the visual observations of a navigating agent can be performed using off-the-shelf visual-language models pretrained on Internet-scale data (e.g., image captions). While this is useful for matching images to natural language descriptions of object goals, it remains disjoint from the process of mapping the environment, so that it lacks the spatial precision of classic geometric maps. To address this problem, we propose VLMaps, a spatial map representation that directly fuses pretrained visual-language features with a 3D reconstruction of the physical world. VLMaps can be autonomously built from video feed on robots using standard exploration approaches and enables natural language indexing of the map without additional labeled data. Specifically, when combined with large language models (LLMs), VLMaps can be used to (i) translate natural language commands into a sequence of open …",
        "year": 2023,
        "authors": "Chenguang Huang and Oier Mees and Andy Zeng and Wolfram Burgard"
      }
    ],
    "BtwmZfQAAAAJ": [
      {
        "title": "Reluplex: An efficient SMT solver for verifying deep neural networks",
        "abstract": "Deep neural networks have emerged as a widely used and effective means for tackling complex, real-world problems. However, a major obstacle in applying them to safety-critical systems is the great difficulty in providing formal guarantees about their behavior. We present a novel, scalable, and efficient technique for verifying properties of deep neural networks (or providing counter-examples). The technique is based on the simplex method, extended to handle the non-convex Rectified Linear Unit (ReLU) activation function, which is a crucial ingredient in many modern neural networks. The verification procedure tackles neural networks as a whole, without making any simplifying assumptions. We evaluated our technique on a prototype deep neural network implementation of the next-generation airborne collision avoidance system for unmanned aircraft (ACAS Xu). Results show that our technique can …",
        "year": 2017,
        "authors": "Guy Katz and Clark Barrett and David L Dill and Kyle Julian and Mykel J Kochenderfer"
      },
      {
        "title": "Satisfiability Modulo Theories",
        "abstract": "Satisfiability Modulo Theories (SMT) refers to the problem of determining whether a first-order formula is satisfiable with respect to some logical theory. Solvers based on SMT are used as back-end engines in model-checking applications such as bounded, interpolation-based, and predicate-abstraction-based model checking. After a brief illustration of these uses, we survey the predominant techniques for solving SMT problems with an emphasis on the lazy approach, in which a propositional satisfiability (SAT) solver is combined with one or more theory solvers. We discuss the architecture of a lazy SMT solver, give examples of theory solvers, show how to combine such solvers modularly, and mention several extensions of the lazy approach. We also briefly describe the eager approach in which the SMT problem is reduced to a SAT problem. Finally, we discuss how the basic framework for determining …",
        "year": 2018,
        "authors": "Clark Barrett and Cesare Tinelli"
      }
    ],
    "euc0GX4AAAAJ": [
      {
        "title": "Tree of thoughts: Deliberate problem solving with large language models",
        "abstract": "Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models’ problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\\% of tasks, our method achieved a success rate of 74\\%. Code repo with all prompts: https://github. com/princeton-nlp/tree-of-thought-llm.",
        "year": 2023,
        "authors": "Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L Griffiths and Yuan Cao and Karthik Narasimhan"
      },
      {
        "title": "React: Synergizing reasoning and acting in language models",
        "abstract": "While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples.",
        "year": 2023,
        "authors": "Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik Narasimhan and Yuan Cao"
      }
    ],
    "uA0kNBUAAAAJ": [
      {
        "title": "Adhesive force of a single gecko foot-hair",
        "abstract": "Geckos are exceptional in their ability to climb rapidly up smooth vertical surfaces,,. Microscopy has shown that a gecko's foot has nearly five hundred thousand keratinous hairs or setae. Each 30–130 µm long seta is only one-tenth the diameter of a human hair and contains hundreds of projections terminating in 0.2–0.5 µm spatula-shaped structures,. After nearly a century of anatomical description,,,, here we report the first direct measurements of single setal force by using a two-dimensional micro-electro-mechanical systems force sensor and a wire as a force gauge. Measurements revealed that a seta is ten times more effective at adhesion than predicted from maximal estimates on whole animals. Adhesive force values support the hypothesis that individual seta operate by van der Waals forces,. The gecko's peculiar behaviour of toe uncurling and peeling led us to discover two aspects of setal function which …",
        "year": 2000,
        "authors": "Kellar Autumn and Yiching A Liang and S Tonia Hsieh and Wolfgang Zesch and Wai Pang Chan and Thomas W Kenny and Ronald Fearing and Robert J Full"
      },
      {
        "title": "Evidence for van der Waals adhesion in gecko setae",
        "abstract": "Geckos have evolved one of the most versatile and effective adhesives known. The mechanism of dry adhesion in the millions of setae on the toes of geckos has been the focus of scientific study for over a century. We provide the first direct experimental evidence for dry adhesion of gecko setae by van der Waals forces, and reject the use of mechanisms relying on high surface polarity, including capillary adhesion. The toes of live Tokay geckos were highly hydrophobic, and adhered equally well to strongly hydrophobic and strongly hydrophilic, polarizable surfaces. Adhesion of a single isolated gecko seta was equally effective on the hydrophobic and hydrophilic surfaces of a microelectro-mechanical systems force sensor. A van der Waals mechanism implies that the remarkable adhesive properties of gecko setae are merely a result of the size and shape of the tips, and are not strongly affected by surface chemistry …",
        "year": 2002,
        "authors": "Kellar Autumn and Metin Sitti and Yiching A Liang and Anne M Peattie and Wendy R Hansen and Simon Sponberg and Thomas W Kenny and Ronald Fearing and Jacob N Israelachvili and Robert J Full"
      },
      {
        "title": "Nanowire active-matrix circuitry for low-voltage macroscale artificial skin",
        "abstract": "Large-scale integration of high-performance electronic components on mechanically flexible substrates may enable new applications in electronics, sensing and energy,,,,,,,. Over the past several years, tremendous progress in the printing and transfer of single-crystalline, inorganic micro- and nanostructures on plastic substrates has been achieved through various process schemes,,,,,. For instance, contact printing of parallel arrays of semiconductor nanowires (NWs) has been explored as a versatile route to enable fabrication of high-performance, bendable transistors and sensors,,,. However, truly macroscale integration of ordered NW circuitry has not yet been demonstrated, with the largest-scale active systems being of the order of 1 cm2 (refs ,). This limitation is in part due to assembly- and processing-related obstacles, although larger-scale integration has been demonstrated for randomly oriented NWs (ref …",
        "year": 2010,
        "authors": "Kuniharu Takei and Toshitake Takahashi and Johnny C Ho and Hyunhyub Ko and Andrew G Gillies and Paul W Leu and Ronald S Fearing and Ali Javey"
      }
    ],
    "jERkdhIAAAAJ": [
      {
        "title": "Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning",
        "abstract": "Model-free deep reinforcement learning algorithms have been shown to be capable of learning a wide range of robotic skills, but typically require a very large number of samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that neural network dynamics models can in fact be combined with model predictive control (MPC) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits that accomplish various complex locomotion tasks. We further propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free …",
        "year": 2018,
        "authors": "Anusha Nagabandi and Gregory Kahn and Ronald S Fearing and Sergey Levine"
      },
      {
        "title": "Learning deep control policies for autonomous aerial vehicles with mpc-guided policy search",
        "abstract": "Model predictive control (MPC) is an effective method for controlling robotic systems, particularly autonomous aerial vehicles such as quadcopters. However, application of MPC can be computationally demanding, and typically requires estimating the state of the system, which can be challenging in complex, unstructured environments. Reinforcement learning can in principle forego the need for explicit state estimation and acquire a policy that directly maps sensor readings to actions, but is difficult to apply to unstable systems that are liable to fail catastrophically during training before an effective policy has been found. We propose to combine MPC with reinforcement learning in the framework of guided policy search, where MPC is used to generate data at training time, under full state observations provided by an instrumented training environment. This data is used to train a deep neural network policy, which is …",
        "year": 2016,
        "authors": "Tianhao Zhang and Gregory Kahn and Sergey Levine and Pieter Abbeel"
      }
    ],
    "MbF6rTEAAAAJ": [
      {
        "title": "Preventing Fairness Gerrymandering: Auditing and Learning for Subgroup Fairness",
        "abstract": "The most prevalent notions of fairness in machine learning fix a small collection of pre-defined groups (such as race or gender), and then ask for approximate parity of some statistic of the classifier (such as false positive rate) across these groups. Constraints of this form are susceptible to fairness gerrymandering, in which a classifier is fair on each individual group, but badly violates the fairness constraint on structured subgroups, such as certain combinations of protected attribute values. We thus consider fairness across exponentially or infinitely many subgroups, defined by a structured class of functions over the protected attributes. We first prove that the problem of auditing subgroup fairness for both equality of false positive rates and statistical parity is computationally equivalent to the problem of weak agnostic learning—which means it is hard in the worst case, even for simple structured subclasses. However, it also suggests that common heuristics for learning can be applied to successfully solve the auditing problem in practice. We then derive an algorithm that provably converges in a polynomial number of steps to the best subgroup-fair distribution over classifiers, given access to an oracle which can solve the agnostic learning problem. The algorithm is based on a formulation of subgroup fairness as a zero-sum game between a Learner (the primal player) and an Auditor (the dual player). We implement a variant of this algorithm using heuristic oracles, and show that we can effectively both audit and learn fair classifiers on a real dataset.",
        "year": 2017,
        "authors": "Michael Kearns and Seth Neel and Aaron Roth and Zhiwei Steven Wu"
      },
      {
        "title": "Privacy-preserving generative deep neural networks support clinical data sharing",
        "abstract": "Data sharing accelerates scientific progress but sharing individual-level data while preserving patient privacy presents a barrier.Using pairs of deep neural networks, we generated simulated, synthetic participants that closely resemble participants of the SPRINT trial (Systolic Blood Pressure Trial). We showed that such paired networks can be trained with differential privacy, a formal privacy framework that limits the likelihood that queries of the synthetic participants’ data could identify a real a participant in the trial. Machine learning predictors built on the synthetic population generalize to the original data set. This finding suggests that the synthetic data can be shared with others, enabling them to perform hypothesis-generating analyses as though they had the original trial data.Deep neural networks that generate synthetic participants facilitate secondary analyses …",
        "year": 2019,
        "authors": "Brett K Beaulieu-Jones and Zhiwei Steven Wu and Chris Williams and Ran Lee and Sanjeev P Bhavnani and James Brian Byrd and Casey S Greene"
      },
      {
        "title": "Fair regression: Quantitative definitions and reduction-based algorithms",
        "abstract": "In this paper, we study the prediction of a real-valued target, such as a risk score or recidivism rate, while guaranteeing a quantitative notion of fairness with respect to a protected attribute such as gender or race. We call this class of problems fair regression. We propose general schemes for fair regression under two notions of fairness:(1) statistical parity, which asks that the prediction be statistically independent of the protected attribute, and (2) bounded group loss, which asks that the prediction error restricted to any protected group remain below some pre-determined level. While we only study these two notions of fairness, our schemes are applicable to arbitrary Lipschitz-continuous losses, and so they encompass least-squares regression, logistic regression, quantile regression, and many other tasks. Our schemes only require access to standard risk minimization algorithms (such as standard classification or least-squares regression) while providing theoretical guarantees on the optimality and fairness of the obtained solutions. In addition to analyzing theoretical properties of our schemes, we empirically demonstrate their ability to uncover fairness–accuracy frontiers on several standard datasets.",
        "year": 2019,
        "authors": "Alekh Agarwal and Miroslav Dudík and Zhiwei Steven Wu"
      }
    ],
    "o6LlkNMAAAAJ": [
      {
        "title": "Scale-MAE: A Scale-Aware Masked Autoencoder for Multiscale Geospatial Representation Learning",
        "abstract": "Large, pretrained models are commonly finetuned with imagery that is heavily augmented to mimic different conditions and scales, with the resulting models used for various tasks with imagery from a range of spatial scales. Such models overlook scale-specific information in the data for scale-dependent domains, such as remote sensing. In this paper, we present Scale-MAE, a pretraining method that explicitly learns relationships between data at different, known scales throughout the pretraining process. Scale-MAE pretrains a network by masking an input image at a known input scale, where the area of the Earth covered by the image determines the scale of the ViT positional encoding, not the image resolution. Scale-MAE encodes the masked image with a standard ViT backbone, and then decodes the masked image through a bandpass filter to reconstruct low/high frequency images at lower/higher scales. We find that tasking the network with reconstructing both low/high frequency images leads to robust multiscale representations for remote sensing imagery. Scale-MAE achieves an average of a 2.4-5.6% non-parametric kNN classification improvement across eight remote sensing datasets compared to current state-of-the-art and obtains a 0.9 mIoU to 1.7 mIoU improvement on the SpaceNet building segmentation transfer task for a range of evaluation scales.",
        "year": 2023,
        "authors": "Colorado J Reed and Ritwik Gupta and Shufan Li and Sarah Brockman and Christopher Funk and Brian Clipp and Salvatore Candido and Matt Uyttendaele and Trevor Darrell"
      },
      {
        "title": "Detreg: Unsupervised pretraining with region priors for object detection",
        "abstract": "Recent self-supervised pretraining methods for object detection largely focus on pretraining the backbone of the object detector, neglecting key parts of detection architecture. Instead, we introduce DETReg, a new self-supervised method that pretrains the entire object detection network, including the object localization and embedding components. During pretraining, DETReg predicts object localizations to match the localizations from an unsupervised region proposal generator and simultaneously aligns the corresponding feature embeddings with embeddings from a self-supervised image encoder. We implement DETReg using the DETR family of detectors and show that it improves over competitive baselines when finetuned on COCO, PASCAL VOC, and Airbus Ship benchmarks. In low-data regimes, including semi-supervised and few-shot learning settings, DETReg establishes many state-of-the-art results, eg, on COCO we see a+ 6.0 AP improvement for 10-shot detection and+ 3.5 AP improvement when training with only 1% of the labels.",
        "year": 2022,
        "authors": "Amir Bar and Xin Wang and Vadim Kantorov and Colorado J Reed and Roei Herzig and Gal Chechik and Anna Rohrbach and Trevor Darrell and Amir Globerson"
      },
      {
        "title": "Multi-source Domain Adaptation in the Deep Learning Era: A Systematic Survey",
        "abstract": "In many practical applications, it is often difficult and expensive to obtain enough large-scale labeled data to train deep neural networks to their full capability. Therefore, transferring the learned knowledge from a separate, labeled source domain to an unlabeled or sparsely labeled target domain becomes an appealing alternative. However, direct transfer often results in significant performance decay due to domain shift. Domain adaptation (DA) addresses this problem by minimizing the impact of domain shift between the source and target domains. Multi-source domain adaptation (MDA) is a powerful extension in which the labeled data may be collected from multiple sources with different distributions. Due to the success of DA methods and the prevalence of multi-source data, MDA has attracted increasing attention in both academia and industry. In this survey, we define various MDA strategies and summarize available datasets for evaluation. We also compare modern MDA methods in the deep learning era, including latent space transformation and intermediate domain generation. Finally, we discuss future research directions for MDA.",
        "year": 2020,
        "authors": "Sicheng Zhao and Bo Li and Colorado J Reed and Pengfei Xu and Kurt Keutzer"
      }
    ],
    "sPlonWcAAAAJ": [
      {
        "title": "Power to the people: The role of humans in interactive machine learning",
        "abstract": "Intelligent systems that learn interactively from their end-users are quickly becoming widespread. Until recently, this progress has been fueled mostly by advances in machine learning; however, more and more researchers are realizing the importance of studying users of these systems. In this article we promote this approach and demonstrate how it can result in better user experiences and more effective learning systems. We present a number of case studies that characterize the impact of interactivity, demonstrate ways in which some existing systems fail to account for the user, and explore new ways for learning systems to interact with their users. We argue that the design process for interactive machine learning systems should involve users at all stages: explorations that reveal human interaction patterns and inspire novel interaction methods, as well as refinement stages to tune details of the interface and choose among alternatives. After giving a glimpse of the progress that has been made so far, we discuss the challenges that we face in moving the field forward.",
        "year": 2014,
        "authors": "Saleema Amershi and Maya Cakmak and William Bradley Knox and Todd Kulesza"
      },
      {
        "title": "To afford or not to afford: A new formalization of affordances toward affordance-based robot control",
        "abstract": "The concept of affordances was introduced by J. J. Gibson to eXplain how inherent “values” and “meanings” of things in the environment can be directly perceived and how this information can be linked to the action possibilities offered to the organism by the environment. Although introduced in psychology, the concept influenced studies in other fields ranging from human—computer interaction to autonomous robotics. In this article, we first introduce the concept of affordances as conceived by J. J. Gibson and review the use of the term in different fields, with particular emphasis on its use in autonomous robotics. Then, we summarize four of the major formalization proposals for the affordance term. We point out that there are three, not one, perspectives from which to view affordances and that much of the confusion regarding discussions on the concept has arisen from this. We propose a new formalism for …",
        "year": 2007,
        "authors": "Erol Şahin and Maya Cakmak and Mehmet R Doğar and Emre Uğur and Göktürk Üçoluk"
      },
      {
        "title": "Vision-and-dialog navigation",
        "abstract": "Robots navigating in human environments should use language to ask for assistance and be able to understand human responses. To study this challenge, we introduce Cooperative Vision-and-Dialog Navigation, a dataset of over 2k embodied, human-human dialogs situated in simulated, photorealistic home environments. The Navigator asks questions to their partner, the Oracle, who has privileged access to the best next steps the Navigator should take according to a shortest path planner. To train agents that search an environment for a goal location, we define the Navigation from Dialog History task. An agent, given a target object and a dialog history between humans cooperating to find that object, must infer navigation actions towards the goal in unexplored environments. We establish an initial, multi-modal sequence-to-sequence model and demonstrate that looking farther back in the dialog history improves performance. Sourcecode and a live interface demo can be found at https://cvdn. dev/",
        "year": 2020,
        "authors": "Jesse Thomason and Michael Murray and Maya Cakmak and Luke Zettlemoyer"
      }
    ],
    "krrh6OUAAAAJ": [
      {
        "title": "The llama 3 herd of models",
        "abstract": "Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.",
        "year": 2024,
        "authors": "Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and Akhil Mathur and Alan Schelten and Alex Vaughan and Amy Yang and Angela Fan and Anirudh Goyal and Anthony Hartshorn and Aobo Yang and Archi Mitra and Archie Sravankumar and Artem Korenev and Arthur Hinsvark and Arun Rao and Aston Zhang and Aurelien Rodriguez and Austen Gregerson and Ava Spataru and Baptiste Roziere and Bethany Biron and Binh Tang and Bobbie Chern and Charlotte Caucheteux and Chaya Nayak and Chloe Bi and Chris Marra and Chris McConnell and Christian Keller and Christophe Touret and Chunyang Wu and Corinne Wong and Cristian Canton Ferrer and Cyrus Nikolaidis and Damien Allonsius and Daniel Song and Danielle Pintz and Danny Livshits and Danny Wyatt and David Esiobu and Dhruv Choudhary and Dhruv Mahajan and Diego Garcia-Olano and Diego Perino and Dieuwke Hupkes and Egor Lakomkin and Ehab AlBadawy and Elina Lobanova and Emily Dinan and Eric Michael Smith and Filip Radenovic and Francisco Guzmán and Frank Zhang and Gabriel Synnaeve and Gabrielle Lee and Georgia Lewis Anderson and Govind Thattai and Graeme Nail and Gregoire Mialon and Guan Pang and Guillem Cucurell and Hailey Nguyen and Hannah Korevaar and Hu Xu and Hugo Touvron and Iliyan Zarov and Imanol Arrieta Ibarra and Isabel Kloumann and Ishan Misra and Ivan Evtimov and Jack Zhang and Jade Copet and Jaewon Lee and Jan Geffert and Jana Vranes and Jason Park and Jay Mahadeokar and Jeet Shah and Jelmer van der Linde and Jennifer Billock and Jenny Hong and Jenya Lee and Jeremy Fu and Jianfeng Chi and Jianyu Huang and Jiawen Liu and Jie Wang and Jiecao Yu and Joanna Bitton and Joe Spisak and Jongsoo Park and Joseph Rocca and Joshua Johnstun and Joshua Saxe and Junteng Jia and Kalyan Vasuden Alwala and Karthik Prasad and Kartikeya Upasani and Kate Plawiak and Ke Li and Kenneth Heafield and Kevin Stone and Khalid El-Arini and Krithika Iyer and Kshitiz Malik and Kuenley Chiu and Kunal Bhalla and Kushal Lakhotia and Lauren Rantala-Yeary and Laurens van der Maaten and Lawrence Chen and Liang Tan and Liz Jenkins and Louis Martin and Lovish Madaan and Lubo Malo and Lukas Blecher and Lukas Landzaat and Luke de Oliveira and Madeline Muzzi and Mahesh Pasupuleti and Mannat Singh and Manohar Paluri and Marcin Kardas and Maria Tsimpoukelli and Mathew Oldham and Mathieu Rita and Maya Pavlova and Melanie Kambadur and Mike Lewis and Min Si and Mitesh Kumar Singh and Mona Hassan and Naman Goyal and Narjes Torabi and Nikolay Bashlykov and Nikolay Bogoychev and Niladri Chatterji and Ning Zhang and Olivier Duchenne and Onur Çelebi and Patrick Alrassy and Pengchuan Zhang and Pengwei Li and Petar Vasic"
      },
      {
        "title": "Gemini: a family of highly capable multimodal models",
        "abstract": "This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.",
        "year": 2023,
        "authors": "Gemini Team and Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M Dai and Anja Hauth and Katie Millican and David Silver and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Jack Krawczyk and Cosmo Du and Ed Chi and Heng-Tze Cheng and Eric Ni and Purvi Shah and Patrick Kane and Betty Chan and Manaal Faruqui and Aliaksei Severyn and Hanzhao Lin and YaGuang Li and Yong Cheng and Abe Ittycheriah and Mahdis Mahdieh and Mia Chen and Pei Sun and Dustin Tran and Sumit Bagri and Balaji Lakshminarayanan and Jeremiah Liu and Andras Orban and Fabian Güra and Hao Zhou and Xinying Song and Aurelien Boffy and Harish Ganapathy and Steven Zheng and HyunJeong Choe and Ágoston Weisz and Tao Zhu and Yifeng Lu and Siddharth Gopal and Jarrod Kahn and Maciej Kula and Jeff Pitman and Rushin Shah and Emanuel Taropa and Majd Al Merey and Martin Baeuml and Zhifeng Chen and Laurent El Shafey and Yujing Zhang and Olcan Sercinoglu and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Anaïs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Gaurav Singh Tomar and Evan Senter and Martin Chadwick and Ilya Kornakov and Nithya Attaluri and Iñaki Iturrate and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Xavier Garcia and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco"
      },
      {
        "title": "Toward causal representation learning",
        "abstract": "The two fields of machine learning and graphical causality arose and are developed separately. However, there is, now, cross-pollination and increasing interest in both fields to benefit from the advances of the other. In this article, we review fundamental concepts of causal inference and relate them to crucial open problems of machine learning, including transfer and generalization, thereby assaying how causality can contribute to modern machine learning research. This also applies in the opposite direction: we note that most work in causality starts from the premise that the causal variables are given. A central problem for AI and causality is, thus, causal representation learning, that is, the discovery of high-level causal variables from low-level observations. Finally, we delineate some implications of causality for machine learning and propose key research areas at the intersection of both communities.",
        "year": 2021,
        "authors": "Bernhard Schölkopf and Francesco Locatello and Stefan Bauer and Nan Rosemary Ke and Nal Kalchbrenner and Anirudh Goyal and Yoshua Bengio"
      }
    ],
    "odFQXSYAAAAJ": [
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien MR Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan"
      },
      {
        "title": "On the utility of learning about humans for human-AI coordination",
        "abstract": "While we would like agents that can coordinate with humans, current algorithms such as self-play and population-based training create agents that can coordinate with themselves. Agents that assume their partner to be optimal or similar to them can converge to coordination protocols that fail to understand and be understood by humans. To demonstrate this, we introduce a simple environment that requires challenging coordination, based on the popular game Overcooked, and learn a simple model that mimics human play. We evaluate the performance of agents trained via self-play and population-based training. These agents perform very well when paired with themselves, but when paired with our human model, they are significantly worse than agents designed to play with the human model. An experiment with a planning algorithm yields the same conclusion, though only when the human-aware planner is given the exact human model that it is playing with. A user study with real humans shows this pattern as well, though less strongly. Qualitatively, we find that the gains come from having the agent adapt to the human's gameplay. Given this result, we suggest several approaches for designing agents that learn about humans in order to better coordinate with them. Code is available at https://github. com/HumanCompatibleAI/overcooked_ai.",
        "year": 2019,
        "authors": "Micah Carroll and Rohin Shah and Mark K Ho and Tom Griffiths and Sanjit Seshia and Pieter Abbeel and Anca Dragan"
      },
      {
        "title": "Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2",
        "abstract": "Sparse autoencoders (SAEs) are an unsupervised method for learning a sparse decomposition of a neural network's latent representations into seemingly interpretable features. Despite recent excitement about their potential, research applications outside of industry are limited by the high cost of training a comprehensive suite of SAEs. In this work, we introduce Gemma Scope, an open suite of JumpReLU SAEs trained on all layers and sub-layers of Gemma 2 2B and 9B and select layers of Gemma 2 27B base models. We primarily train SAEs on the Gemma 2 pre-trained models, but additionally release SAEs trained on instruction-tuned Gemma 2 9B for comparison. We evaluate the quality of each SAE on standard metrics and release these results. We hope that by releasing these SAE weights, we can help make more ambitious safety and interpretability research easier for the community. Weights and a tutorial can be found at https://huggingface.co/google/gemma-scope and an interactive demo can be found at https://www.neuronpedia.org/gemma-scope",
        "year": 2024,
        "authors": "Tom Lieberum and Senthooran Rajamanoharan and Arthur Conmy and Lewis Smith and Nicolas Sonnerat and Vikrant Varma and János Kramár and Anca Dragan and Rohin Shah and Neel Nanda"
      }
    ],
    "UfbuDH8AAAAJ": [
      {
        "title": "Rich feature hierarchies for accurate object detection and semantic segmentation",
        "abstract": "Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012---achieving a mAP of 53.3%. Our approach combines two key insights:(1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www. cs. berkeley. edu/~ rbg/rcnn.",
        "year": 2014,
        "authors": "Ross Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik"
      },
      {
        "title": "Caffe: Convolutional architecture for fast feature embedding",
        "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community …",
        "year": 2014,
        "authors": "Yangqing Jia and Evan Shelhamer and Jeff Donahue and Sergey Karayev and Jonathan Long and Ross Girshick and Sergio Guadarrama and Trevor Darrell"
      },
      {
        "title": "Long-term recurrent convolutional networks for visual recognition and description",
        "abstract": "Models comprised of deep convolutional network layers have dominated recent image interpretation tasks; we investigate whether models which are also compositional, or\" deep\", temporally are effective on tasks involving visual sequences or label sequences. We develop a novel recurrent convolutional architecture suitable for large-scale visual learning which is end-to-end trainable, and demonstrate the value of these models on benchmark video recognition tasks, image to sentence generation problems, and video narration challenges. In contrast to current models which assume a fixed spatio-temporal receptive field or simple temporal averaging for sequential processing, recurrent convolutional models are\" doubly deep\" in that they can be compositional in spatial and temporal\" layers\". Such models may have advantages when target concepts are complex and/or training data are limited. Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. Long-term RNN models are appealing in that they directly can map variable length inputs (ie video frames) to variable length outputs (ie natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent long-term models are directly connected to state-of-the-art visual convnet models and can jointly trained, updating temporal dynamics and convolutional perceptual representations simultaneously. Our results show such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined and/or optimized.",
        "year": 2015,
        "authors": "Jeffrey Donahue and Lisa Anne Hendricks and Sergio Guadarrama and Marcus Rohrbach and Subhashini Venugopalan and Kate Saenko and Trevor Darrell"
      }
    ],
    "Ch9iRwQAAAAJ": [
      {
        "title": "On the opportunities and risks of foundation models",
        "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",
        "year": 2021,
        "authors": "Rishi Bommasani and Drew A Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher Ré and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W Thomas and Florian Tramèr and Rose E Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang"
      },
      {
        "title": "Certified defenses against adversarial examples",
        "abstract": "While neural networks have achieved high accuracy on standard image classification benchmarks, their accuracy drops to nearly zero in the presence of small adversarial perturbations to test inputs. Defenses based on regularization and adversarial training have been proposed, but often followed by new, stronger attacks that defeat these defenses. Can we somehow end this arms race? In this work, we study this problem for neural networks with one hidden layer. We first propose a method based on a semidefinite relaxation that outputs a certificate that for a given network and test input, no attack can force the error to exceed a certain value. Second, as this certificate is differentiable, we jointly optimize it with the network parameters, providing an adaptive regularizer that encourages robustness against all attacks. On MNIST, our approach produces a network and a certificate that no attack that perturbs each pixel by at most \\epsilon = 0.1 can cause more than 35% test error.",
        "year": 2018,
        "authors": "Aditi Raghunathan and Jacob Steinhardt and Percy Liang"
      },
      {
        "title": "Unlabeled data improves adversarial robustness",
        "abstract": "We demonstrate, theoretically and empirically, that adversarial robustness can significantly benefit from semisupervised learning. Theoretically, we revisit the simple Gaussian model of Schmidt et al. that shows a sample complexity gap between standard and robust classification. We prove that unlabeled data bridges this gap: a simple semisupervised learning procedure (self-training) achieves high robust accuracy using the same number of labels required for achieving high standard accuracy. Empirically, we augment CIFAR-10 with 500K unlabeled images sourced from 80 Million Tiny Images and use robust self-training to outperform state-of-the-art robust accuracies by over 5 points in (i)  robustness against several strong attacks via adversarial training and (ii) certified  and  robustness via randomized smoothing. On SVHN, adding the dataset's own extra training set with the labels removed provides gains of 4 to 10 points, within 1 point of the gain from using the extra labels.",
        "year": 2019,
        "authors": "Yair Carmon and Aditi Raghunathan and Ludwig Schmidt and John C Duchi and Percy S Liang"
      }
    ],
    "k-nF0qgAAAAJ": [
      {
        "title": "Resection of the liver for colorectal carcinoma metastases: a multi-institutional study of indications for resection",
        "abstract": "In an investigation of the indications for hepatic resection in the treatment of colorectal carcinoma metastases, the records of 859 patients who had undergone this procedure were reviewed. This patient group, from 24 institutions, was found to have a 5-year actuarial survival of 33% and a 5-year actuarial disease-free survival of 21%. The only factors that might by themselves be considered contraindications to hepatic resection are the presence of positive hepatic nodes, the presence of resectable extrahepatic metastases, or the presence of four or more metastases. Other factors that had a negative effect on long-term survival were margins of resection on the liver metastases less than or equal to 1 cm (S [5-year actuarial survival = 23%), the presence of positive mesenteric nodes in the primary tumor specimen (S = 23%), and a disease-free interval of less than 1 year (S = 24%). The effect of any one of these factors was not great enough to contraindicate resection. However, combinations of prognostic factors must be considered before resection is recommended. The overall 5-year survival rate for this large series has been very satisfying. Decision making in the future must take into account such factors as number of metastases, extrahepatic involvement, and stage of the primary tumor.",
        "year": 1988,
        "authors": "Kevin S Hughes"
      },
      {
        "title": "Lumpectomy plus tamoxifen with or without irradiation in women age 70 years or older with early breast cancer: long-term follow-up of CALGB 9343",
        "abstract": "To determine whether there is a benefit to adjuvant radiation therapy after breast-conserving surgery and tamoxifen in women age ≥ 70 years with early-stage breast cancer.Between July 1994 and February 1999, 636 women (age ≥ 70 years) who had clinical stage I (T1N0M0 according to TNM classification) estrogen receptor (ER) –positive breast carcinoma treated by lumpectomy were randomly assigned to receive tamoxifen plus radiation therapy (TamRT; 317 women) or tamoxifen alone (Tam; 319 women). Primary end points were time to local or regional recurrence, frequency of mastectomy, breast cancer–specific survival, time to distant metastasis, and overall survival (OS).Median follow-up for treated patients is now 12.6 years. At 10 years, 98% of patients receiving TamRT (95% CI, 96% to 99%) compared with 90% of those receiving Tam (95% CI, 85% to 93 …",
        "year": 2013,
        "authors": "Kevin S Hughes and Lauren A Schnaper and Jennifer R Bellon and Constance T Cirrincione and Donald A Berry and Beryl McCormick and Hyman B Muss and Barbara L Smith and Clifford A Hudis and Eric P Winer and William C Wood"
      },
      {
        "title": "Lumpectomy plus tamoxifen with or without irradiation in women 70 years of age or older with early breast cancer",
        "abstract": "In women 70 years of age or older who have early breast cancer, it is unclear whether lumpectomy plus tamoxifen is as effective as lumpectomy followed by tamoxifen plus radiation therapy.Between July 1994 and February 1999, we randomly assigned 636 women who were 70 years of age or older and who had clinical stage I (T1N0M0 according to the tumor–node–metastasis classification), estrogen-receptor–positive breast carcinoma treated by lumpectomy to receive tamoxifen plus radiation therapy (317 women) or tamoxifen alone (319 women). Primary end points were the time to local or regional recurrence, the frequency of mastectomy for recurrence, breast-cancer–specific survival, the time to distant metastasis, and overall survival.The only significant difference between the two groups was in the rate of local or regional recurrence at five years (1 percent in the group given …",
        "year": 2004,
        "authors": "Kevin S Hughes and Lauren A Schnaper and Donald Berry and Constance Cirrincione and Beryl McCormick and Brenda Shank and Judith Wheeler and Lorraine A Champion and Thomas J Smith and Barbara L Smith and Charles Shapiro and Hyman B Muss and Eric Winer and Clifford Hudis and William Wood and David Sugarbaker and I Craig Henderson and Larry Norton"
      }
    ],
    "ZKRs0oEAAAAJ": [
      {
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models",
        "abstract": "DSpace at KOASAS: Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nKOASAS menu About KOASAS KAIST Library 검색 Advanced Search KOASAS About \nKOASAS Open Access Policy Browse Communities & Collections Researchers at KAIST Titles \nSubject By Date rss_1.0 rss_2.0 atom_1.0 sherpa SEARCH DSpace at KOASAS College of \nEngineering(공과대학)Kim Jaechul Graduate School of AI(김재철AI대학원)AI-Conference \nPapers(학술대회논문) Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nCited 0 time in webofscience Cited 0 time in scopus Hit : 2 Download : 0 Export DC(XML) Excel \nLim, Joseph Jaewhanresearcher Publisher IEEE Issue Date 2024-05-15 Citation IEEE \nInternational Conference on Robotics and Automation URI http://hdl.handle.net/10203/326144 \nAppears in Collection AI-Conference Papers(학술대회논문) Files in This Item There are no files …",
        "year": 2024,
        "authors": "Joseph Jaewhan Lim"
      },
      {
        "title": "Openvla: An open-source vision-language-action model",
        "abstract": "Large policies pretrained on a combination of Internet-scale vision-language data and diverse robot demonstrations have the potential to change how we teach robots new skills: rather than training new behaviors from scratch, we can fine-tune such vision-language-action (VLA) models to obtain robust, generalizable policies for visuomotor control. Yet, widespread adoption of VLAs for robotics has been challenging as 1) existing VLAs are largely closed and inaccessible to the public, and 2) prior work fails to explore methods for efficiently fine-tuning VLAs for new tasks, a key component for adoption. Addressing these challenges, we introduce OpenVLA, a 7B-parameter open-source VLA trained on a diverse collection of 970k real-world robot demonstrations. OpenVLA builds on a Llama 2 language model combined with a visual encoder that fuses pretrained features from DINOv2 and SigLIP. As a product of the added data diversity and new model components, OpenVLA demonstrates strong results for generalist manipulation, outperforming closed models such as RT-2-X (55B) by 16.5% in absolute task success rate across 29 tasks and multiple robot embodiments, with 7x fewer parameters. We further show that we can effectively fine-tune OpenVLA for new settings, with especially strong generalization results in multi-task environments involving multiple objects and strong language grounding abilities, and outperform expressive from-scratch imitation learning methods such as Diffusion Policy by 20.4%. We also explore compute efficiency; as a separate contribution, we show that OpenVLA can be fine-tuned on consumer GPUs via modern …",
        "year": 2024,
        "authors": "Moo Jin Kim and Karl Pertsch and Siddharth Karamcheti and Ted Xiao and Ashwin Balakrishna and Suraj Nair and Rafael Rafailov and Ethan Foster and Grace Lam and Pannag Sanketi and Quan Vuong and Thomas Kollar and Benjamin Burchfiel and Russ Tedrake and Dorsa Sadigh and Sergey Levine and Percy Liang and Chelsea Finn"
      },
      {
        "title": "Bridgedata v2: A dataset for robot learning at scale",
        "abstract": "We introduce BridgeData V2, a large and diverse dataset of robotic manipulation behaviors designed to facilitate research in scalable robot learning. BridgeData V2 contains 53,896 trajectories collected across 24 environments on a publicly available low-cost robot. Unlike many existing robotic manipulation datasets, BridgeData V2 provides enough task and environment variability that skills learned from the data generalize across institutions, making the dataset a useful resource for a broad range of researchers. Additionally, the dataset is compatible with a wide variety of open-vocabulary, multi-task learning methods conditioned on goal images or natural language instructions. In our experiments, we apply 6 state-of-the-art imitation learning and offline reinforcement learning methods to the data and find that they succeed on a suite of tasks requiring varying amounts of generalization. We also demonstrate that the performance of these methods improves with more data and higher capacity models. By publicly sharing BridgeData V2 and our pre-trained models, we aim to accelerate research in scalable robot learning methods.",
        "year": 2023,
        "authors": "Homer Rich Walke and Kevin Black and Tony Z Zhao and Quan Vuong and Chongyi Zheng and Philippe Hansen-Estruch and Andre Wang He and Vivek Myers and Moo Jin Kim and Max Du and Abraham Lee and Kuan Fang and Chelsea Finn and Sergey Levine"
      }
    ],
    "KCdL5B0AAAAJ": [
      {
        "title": "On the opportunities and risks of foundation models",
        "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",
        "year": 2021,
        "authors": "Rishi Bommasani and Drew A Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher Ré and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W Thomas and Florian Tramèr and Rose E Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang"
      },
      {
        "title": "Unsupervised learning via meta-learning",
        "abstract": "A central goal of unsupervised learning is to acquire representations from unlabeled data or experience that can be used for more effective learning of downstream tasks from modest amounts of labeled data. Many prior unsupervised learning works aim to do so by developing proxy objectives based on reconstruction, disentanglement, prediction, and other metrics. Instead, we develop an unsupervised meta-learning method that explicitly optimizes for the ability to learn a variety of tasks from small amounts of data. To do so, we construct tasks from unlabeled data in an automatic way and run meta-learning over the constructed tasks. Surprisingly, we find that, when integrated with meta-learning, relatively simple task construction mechanisms, such as clustering embeddings, lead to good performance on a variety of downstream, human-specified tasks. Our experiments across four image datasets indicate that our unsupervised meta-learning approach acquires a learning algorithm without any labeled data that is applicable to a wide range of downstream classification tasks, improving upon the embedding learned by four prior unsupervised learning methods.",
        "year": 2019,
        "authors": "Kyle Hsu and Sergey Levine and Chelsea Finn"
      }
    ],
    "oAlCitYAAAAJ": [
      {
        "title": "How will the presence of autonomous vehicles affect the equilibrium state of traffic networks?",
        "abstract": "It is known that connected and autonomous vehicles are capable of maintaining shorter headway and distances when they form platoons of vehicles. Thus, such technologies can potentially increase the road capacities of traffic networks. Consequently, it is envisioned that their deployment will also increase the overall network mobility. In this paper, we examine the validity of this expected impact, assuming that drivers select their routes selfishly, in traffic networks with mixed vehicle autonomy, that is, traffic networks with both regular and autonomous vehicles. We consider a nonatomic routing game on a network with inelastic (fixed) demands for a set of network origin destination (O/D) pairs, and study how replacing a fraction of regular vehicles by autonomous vehicles will affect the mobility of the network. Using well-known U.S. Bureau of Public Roads traffic delay models, we show that the resulting Wardrop …",
        "year": 2019,
        "authors": "Negar Mehr and Roberto Horowitz"
      },
      {
        "title": "Maximum-entropy multi-agent dynamic games: Forward and inverse solutions",
        "abstract": "In this article, we study the problem of multiple stochastic agents interacting in a dynamic game scenario with continuous state and action spaces. We define a new notion of stochastic Nash equilibrium for boundedly rational agents, which we call the entropic cost equilibrium (ECE). We show that ECE is a natural extension to multiple agents of maximum entropy optimality for a single agent. We solve both the “forward” and “inverse” problems for the multi-agent ECE game. For the forward problem, we provide a Riccati algorithm to compute closed-form ECE feedback policies for the agents, which are exact in the linear-quadratic-gaussian case. We give an iterative variant to find locally ECE feedback policies for the nonlinear case. For the inverse problem, we present an algorithm to infer the cost functions of the multiple interacting agents given noisy, boundedly rational input and state trajectory examples from agents …",
        "year": 2023,
        "authors": "Negar Mehr and Mingyu Wang and Maulik Bhatt and Mac Schwager"
      },
      {
        "title": "Game-theoretic planning for risk-aware interactive agents",
        "abstract": "Modeling the stochastic behavior of interacting agents is key for safe motion planning. In this paper, we study the interaction of risk-aware agents in a game-theoretical framework. Under the entropic risk measure, we derive an iterative algorithm for approximating the intractable feedback Nash equilibria of a risk-sensitive dynamic game. We use an iteratively linearized approximation of the system dynamics and a quadratic approximation of the cost function in solving a backward recursion for finding feedback Nash equilibria. In this respect, the algorithm shares a similar structure with DDP and iLQR methods. We conduct experiments in a set of challenging scenarios such as roundabouts. Compared to ignoring the game interaction or the risk sensitivity, we show that our risk-sensitive game-theoretic framework leads to more timeefficient, intuitive, and safe behaviors when facing underlying risks and uncertainty.",
        "year": 2020,
        "authors": "Mingyu Wang and Negar Mehr and Adrien Gaidon and Mac Schwager"
      }
    ],
    "E__5Lr0AAAAJ": [
      {
        "title": "Estimating mutual information for discrete-continuous mixtures",
        "abstract": "Estimation of mutual information from observed samples is a basic primitive in machine learning, useful in several learning tasks including correlation mining, information bottleneck, Chow-Liu tree, and conditional independence testing in (causal) graphical models. While mutual information is a quantity well-defined for general probability spaces, estimators have been developed only in the special case of discrete or continuous pairs of random variables. Most of these estimators operate using the 3H-principle, ie, by calculating the three (differential) entropies of X, Y and the pair (X, Y). However, in general mixture spaces, such individual entropies are not well defined, even though mutual information is. In this paper, we develop a novel estimator for estimating mutual information in discrete-continuous mixtures. We prove the consistency of this estimator theoretically as well as demonstrate its excellent empirical performance. This problem is relevant in a wide-array of applications, where some variables are discrete, some continuous, and others are a mixture between continuous and discrete components.",
        "year": 2017,
        "authors": "Weihao Gao and Sreeram Kannan and Sewoong Oh and Pramod Viswanath"
      },
      {
        "title": "Demystifying fixed k-nearest neighbor information estimators",
        "abstract": "Estimating mutual information from independent identically distributed samples drawn from an unknown joint density function is a basic statistical problem of broad interest with multitudinous applications. The most popular estimator is the one proposed by Kraskov, Stögbauer, and Grassberger (KSG) in 2004 and is nonparametric and based on the distances of each sample to its kth nearest neighboring sample, where k is a fixed small integer. Despite of its widespread use (part of scientific software packages), theoretical properties of this estimator have been largely unexplored. In this paper, we demonstrate that the estimator is consistent and also identify an upper bound on the rate of convergence of the ℓ2 error as a function of a number of samples. We argue that the performance benefits of the KSG estimator stems from a curious “correlation boosting” effect and build on this intuition to modify the KSG estimator in …",
        "year": 2017,
        "authors": "Weihao Gao and Sewoong Oh and Pramod Viswanath"
      },
      {
        "title": "Label leakage and protection in two-party split learning",
        "abstract": "Two-party split learning is a popular technique for learning a model across feature-partitioned data. In this work, we explore whether it is possible for one party to steal the private label information from the other party during split training, and whether there are methods that can protect against such attacks. Specifically, we first formulate a realistic threat model and propose a privacy loss metric to quantify label leakage in split learning. We then show that there exist two simple yet effective methods within the threat model that can allow one party to accurately recover private ground-truth labels owned by the other party. To combat these attacks, we propose several random perturbation techniques, including , an approach that strategically finds the structure of the noise perturbation by minimizing the amount of label leakage (measured through our quantification metric) of a worst-case adversary. We empirically demonstrate the effectiveness of our protection techniques against the identified attacks, and show that  in particular has improved privacy-utility tradeoffs relative to baseline approaches.",
        "year": 2021,
        "authors": "Oscar Li and Jiankai Sun and Xin Yang and Weihao Gao and Hongyi Zhang and Junyuan Xie and Virginia Smith and Chong Wang"
      }
    ],
    "MaSXNhUAAAAJ": [
      {
        "title": "A geometric approach to robotic laundry folding",
        "abstract": "We consider the problem of autonomous robotic laundry folding, and propose a solution to the perception and manipulation challenges inherent to the task. At the core of our approach is a quasi-static cloth model which allows us to neglect the complex dynamics of cloth under significant parts of the state space, allowing us to reason instead in terms of simple geometry. We present an algorithm which, given a 2D cloth polygon and a desired sequence of folds, outputs a motion plan for executing the corresponding manipulations, deemed g-folds, on a minimal number of robot grippers. We define parametrized fold sequences for four clothing categories: towels, pants, short-sleeved shirts, and long-sleeved shirts, each represented as polygons. We then devise a model-based optimization approach for visually inferring the class and pose of a spread-out or folded clothing article from a single image, such that the …",
        "year": 2012,
        "authors": "Stephen Miller and Jur Van Den Berg and Mario Fritz and Trevor Darrell and Ken Goldberg and Pieter Abbeel"
      },
      {
        "title": "Superhuman performance of surgical tasks by robots using iterative learning from human-guided demonstrations",
        "abstract": "In the future, robotic surgical assistants may assist surgeons by performing specific subtasks such as retraction and suturing to reduce surgeon tedium and reduce the duration of some operations. We propose an apprenticeship learning approach that has potential to allow robotic surgical assistants to autonomously execute specific trajectories with superhuman performance in terms of speed and smoothness. In the first step, we record a set of trajectories using human-guided backdriven motions of the robot. These are then analyzed to extract a smooth reference trajectory, which we execute at gradually increasing speeds using a variant of iterative learning control. We evaluate this approach on two representative tasks using the Berkeley Surgical Robots: a figure eight trajectory and a two handed knot-tie, a tedious suturing sub-task required in many surgical procedures. Results suggest that the approach enables (i …",
        "year": 2010,
        "authors": "Jur Van Den Berg and Stephen Miller and Daniel Duckworth and Humphrey Hu and Andrew Wan and Xiao-Yu Fu and Ken Goldberg and Pieter Abbeel"
      },
      {
        "title": "A large dataset of object scans",
        "abstract": "We have created a dataset of more than ten thousand 3D scans of real objects. To create the dataset, we recruited 70 operators, equipped them with consumer-grade mobile 3D scanning setups, and paid them to scan objects in their environments. The operators scanned objects of their choosing, outside the laboratory and without direct supervision by computer vision professionals. The result is a large and diverse collection of object scans: from shoes, mugs, and toys to grand pianos, construction vehicles, and large outdoor sculptures. We worked with an attorney to ensure that data acquisition did not violate privacy constraints. The acquired data was irrevocably placed in the public domain and is available freely at http://redwood-data.org/3dscan .",
        "year": 2016,
        "authors": "Sungjoon Choi and Qian-Yi Zhou and Stephen Miller and Vladlen Koltun"
      }
    ],
    "4bl7qAgAAAAJ": [
      {
        "title": "CHOMP: Gradient optimization techniques for efficient motion planning",
        "abstract": "Existing high-dimensional motion planning algorithms are simultaneously overpowered and underpowered. In domains sparsely populated by obstacles, the heuristics used by sampling-based planners to navigate “narrow passages” can be needlessly complex; furthermore, additional post-processing is required to remove the jerky or extraneous motions from the paths that such planners generate. In this paper, we present CHOMP, a novel method for continuous path refinement that uses covariant gradient techniques to improve the quality of sampled trajectories. Our optimization technique both optimizes higher-order dynamics and is able to converge over a wider range of input paths relative to previous path optimization strategies. In particular, we relax the collision-free feasibility prerequisite on input paths required by those strategies. As a result, CHOMP can be used as a standalone motion planner in many …",
        "year": 2009,
        "authors": "Nathan Ratliff and Matt Zucker and J Andrew Bagnell and Siddhartha Srinivasa"
      },
      {
        "title": "Maximum margin planning",
        "abstract": "Imitation learning of sequential, goal-directed behavior by standard supervised techniques is often difficult. We frame learning such behaviors as a maximum margin structured prediction problem over a space of policies. In this approach, we learn mappings from features to cost so an optimal policy in an MDP with these cost mimics the expert's behavior. Further, we demonstrate a simple, provably efficient approach to structured maximum margin learning, based on the subgradient method, that leverages existing fast algorithms for inference. Although the technique is general, it is particularly relevant in problems where A* and dynamic programming approaches make learning policies tractable in problems beyond the limitations of a QP formulation. We demonstrate our approach applied to route planning for outdoor mobile robots, where the behavior a designer wishes a planner to execute is often clear, while …",
        "year": 2006,
        "authors": "Nathan D Ratliff and J Andrew Bagnell and Martin A Zinkevich"
      },
      {
        "title": "Chomp: Covariant hamiltonian optimization for motion planning",
        "abstract": "In this paper, we present CHOMP (covariant Hamiltonian optimization for motion planning), a method for trajectory optimization invariant to reparametrization. CHOMP uses functional gradient techniques to iteratively improve the quality of an initial trajectory, optimizing a functional that trades off between a smoothness and an obstacle avoidance component. CHOMP can be used to locally optimize feasible trajectories, as well as to solve motion planning queries, converging to low-cost trajectories even when initialized with infeasible ones. It uses Hamiltonian Monte Carlo to alleviate the problem of convergence to high-cost local minima (and for probabilistic completeness), and is capable of respecting hard constraints along the trajectory. We present extensive experiments with CHOMP on manipulation and locomotion tasks, using seven-degree-of-freedom manipulators and a rough-terrain quadruped robot.",
        "year": 2013,
        "authors": "Matt Zucker and Nathan Ratliff and Anca D Dragan and Mihail Pivtoraiko and Matthew Klingensmith and Christopher M Dellin and J Andrew Bagnell and Siddhartha S Srinivasa"
      }
    ],
    "fn13u8IAAAAJ": [
      {
        "title": "Gradient projection for sparse reconstruction: Application to compressed sensing and other inverse problems",
        "abstract": "Many problems in signal processing and statistical inference involve finding sparse solutions to under-determined, or ill-conditioned, linear systems of equations. A standard approach consists in minimizing an objective function which includes a quadratic (squared ) error term combined with a sparseness-inducing regularization term. Basis pursuit, the least absolute shrinkage and selection operator (LASSO), wavelet-based deconvolution, and compressed sensing are a few well-known examples of this approach. This paper proposes gradient projection (GP) algorithms for the bound-constrained quadratic programming (BCQP) formulation of these problems. We test variants of this approach that select the line search parameters in different ways, including techniques based on the Barzilai-Borwein method. Computational experiments show that these GP approaches perform well in a wide range of applications …",
        "year": 2008,
        "authors": "Mário AT Figueiredo and Robert D Nowak and Stephen J Wright"
      },
      {
        "title": "Wavelet-based statistical signal processing using hidden Markov models",
        "abstract": "Wavelet-based statistical signal processing techniques such as denoising and detection typically model the wavelet coefficients as independent or jointly Gaussian. These models are unrealistic for many real-world signals. We develop a new framework for statistical signal processing based on wavelet-domain hidden Markov models (HMMs) that concisely models the statistical dependencies and non-Gaussian statistics encountered in real-world signals. Wavelet-domain HMMs are designed with the intrinsic properties of the wavelet transform in mind and provide powerful, yet tractable, probabilistic signal models. Efficient expectation maximization algorithms are developed for fitting the HMMs to observational signal data. The new framework is suitable for a wide range of applications, including signal estimation, detection, classification, prediction, and even synthesis. To demonstrate the utility of wavelet-domain …",
        "year": 2002,
        "authors": "Matthew S Crouse and Robert D Nowak and Richard G Baraniuk"
      },
      {
        "title": "Sparse reconstruction by separable approximation",
        "abstract": "Finding sparse approximate solutions to large underdetermined linear systems of equations is a common problem in signal/image processing and statistics. Basis pursuit, the least absolute shrinkage and selection operator (LASSO), wavelet-based deconvolution and reconstruction, and compressed sensing (CS) are a few well-known areas in which problems of this type appear. One standard approach is to minimize an objective function that includes a quadratic (lscr 2) error term added to a sparsity-inducing (usually lscr1) regularizater. We present an algorithmic framework for the more general problem of minimizing the sum of a smooth convex function and a nonsmooth, possibly nonconvex regularizer. We propose iterative methods in which each step is obtained by solving an optimization subproblem involving a quadratic term with diagonal Hessian (i.e., separable in the unknowns) plus the original sparsity …",
        "year": 2009,
        "authors": "Stephen J Wright and Robert D Nowak and Mário AT Figueiredo"
      }
    ],
    "-j0q9B4AAAAJ": [
      {
        "title": "Q-learning with logarithmic regret",
        "abstract": "This paper presents the first non-asymptotic result showing a model-free algorithm can achieve logarithmic cumulative regret for episodic tabular reinforcement learning if there exists a strictly positive sub-optimality gap. We prove that the optimistic Q-learning studied in [Jin et al. 2018] enjoys a  cumulative regret bound where  is the number of states,  is the number of actions,  is the planning horizon,  is the total number of steps, and  is the minimum sub-optimality gap of the optimal Q-function. This bound matches the information theoretical lower bound in terms of  up to a  factor. We further extend our analysis to the discounted setting and obtain a similar logarithmic cumulative regret bound.",
        "year": 2021,
        "authors": "Kunhe Yang and Lin Yang and Simon Du"
      },
      {
        "title": "Optimal conservative offline rl with general function approximation via augmented lagrangian",
        "abstract": "Offline reinforcement learning (RL), which refers to decision-making from a previously-collected dataset of interactions, has received significant attention over the past years. Much effort has focused on improving offline RL practicality by addressing the prevalent issue of partial data coverage through various forms of conservative policy learning. While the majority of algorithms do not have finite-sample guarantees, several provable conservative offline RL algorithms are designed and analyzed within the single-policy concentrability framework that handles partial coverage. Yet, in the nonlinear function approximation setting where confidence intervals are difficult to obtain, existing provable algorithms suffer from computational intractability, prohibitively strong assumptions, and suboptimal statistical rates. In this paper, we leverage the marginalized importance sampling (MIS) formulation of RL and present the first set of offline RL algorithms that are statistically optimal and practical under general function approximation and single-policy concentrability, bypassing the need for uncertainty quantification. We identify that the key to successfully solving the sample-based approximation of the MIS problem is ensuring that certain occupancy validity constraints are nearly satisfied. We enforce these constraints by a novel application of the augmented Lagrangian method and prove the following result: with the MIS formulation, augmented Lagrangian is enough for statistically optimal offline RL. In stark contrast to prior algorithms that induce additional conservatism through methods such as behavior regularization, our approach provably eliminates this need …",
        "year": 2022,
        "authors": "Paria Rashidinejad and Hanlin Zhu and Kunhe Yang and Stuart Russell and Jiantao Jiao"
      },
      {
        "title": "Oracle-efficient online learning for smoothed adversaries",
        "abstract": "We study the design of computationally efficient online learning algorithms under smoothed analysis. In this setting, at every step, an adversary generates a sample from an adaptively chosen distribution whose density is upper bounded by  times the uniform density. Given access to an offline optimization (ERM) oracle, we give the first computationally efficient online algorithms whose sublinear regret depends only on the pseudo/VC dimension  of the class and the smoothness parameter . In particular, we achieve\\emph {oracle-efficient} regret bounds of  for learning real-valued functions and  for learning binary-valued functions. Our results establish that online learning is computationally as easy as offline learning, under the smoothed analysis framework. This contrasts the computational separation between online learning with worst-case adversaries and offline learning established by [HK16]. Our algorithms also achieve improved bounds for some settings with binary-valued functions and worst-case adversaries. These include an oracle-efficient algorithm with  regret that refines the earlier  bound of [DS16] for finite domains, and an oracle-efficient algorithm with  regret for the transductive setting.",
        "year": 2022,
        "authors": "Nika Haghtalab and Yanjun Han and Abhishek Shetty and Kunhe Yang"
      }
    ],
    "oOwNKsAAAAAJ": [
      {
        "title": "Approximate nearest neighbors: towards removing the curse of dimensionality",
        "abstract": "The nearest neighbor problem is the follolving: Given a set of n points P=(PI,..., p,} in some metric space X, preprocess P so as to efficiently answer queries which require finding bhe point in P closest to a query point q E X. We focus on the particularly interesting case of the d-dimensional Euclidean space where X= Wd under some Zp norm. Despite decades of effort, t, he current solutions are far from saabisfactory; in fact, for large d, in theory or in practice, they provide litt, le improvement over the brute-force algorithm which compares the query point to each data point. Of late, t, here has been some interest in the approximate newest neighbors problem, which is: Find a point p EP that is an c-approximate nearest neighbor of the query q in t, hat for all p’EP, d (p, q)<(1+ e) d (p’, q).We present two algorithmic results for the approximate version t, hat significantly improve the known bounds:(a) preprocessing cost …",
        "year": 1998,
        "authors": "Piotr Indyk and Rajeev Motwani"
      },
      {
        "title": "Similarity search in high dimensions via hashing",
        "abstract": "The nearest-or near-neighbor query problems arise in a large variety of database applications, usually in the context of similarity searching. Of late, there has been increasing interest in building search/index structures for performing similarity search over high-dimensional data, eg, image databases, document collections, time-series databases, and genome databases. Unfortunately, all known techniques for solving this problem fall prey to the\\curse of dimensionality.\" That is, the data structures scale poorly with data dimensionality; in fact, if the number of dimensions exceeds 10 to 20, searching in k-d trees and related structures involves the inspection of a large fraction of the database, thereby doing no better than brute-force linear search. It has been suggested that since the selection of features and the choice of a distance metric in typical applications is rather heuristic, determining an approximate nearest neighbor should suffice for most practical purposes. In this paper, we examine a novel scheme for approximate similarity search based on hashing. The basic idea is to hash the points",
        "year": 1999,
        "authors": "Aristides Gionis and Piotr Indyk and Rajeev Motwani"
      },
      {
        "title": "Locality-sensitive hashing scheme based on p-stable distributions",
        "abstract": "We present a novel Locality-Sensitive Hashing scheme for the Approximate Nearest Neighbor Problem under lp norm, based on p-stable distributions.Our scheme improves the running time of the earlier algorithm for the case of the lp norm. It also yields the first known provably efficient approximate NN algorithm for the case p<1. We also show that the algorithm finds the exact near neigbhor in O(log n) time for data satisfying certain \"bounded growth\" condition.Unlike earlier schemes, our LSH scheme works directly on points in the Euclidean space without embeddings. Consequently, the resulting query time bound is free of large factors and is simple and easy to implement. Our experiments (on synthetic data sets) show that the our data structure is up to 40 times faster than kd-tree.",
        "year": 2004,
        "authors": "Mayur Datar and Nicole Immorlica and Piotr Indyk and Vahab S Mirrokni"
      }
    ],
    "zBUwaGkAAAAJ": [
      {
        "title": "Gemini: a family of highly capable multimodal models",
        "abstract": "This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.",
        "year": 2023,
        "authors": "Gemini Team and Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M Dai and Anja Hauth and Katie Millican and David Silver and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Jack Krawczyk and Cosmo Du and Ed Chi and Heng-Tze Cheng and Eric Ni and Purvi Shah and Patrick Kane and Betty Chan and Manaal Faruqui and Aliaksei Severyn and Hanzhao Lin and YaGuang Li and Yong Cheng and Abe Ittycheriah and Mahdis Mahdieh and Mia Chen and Pei Sun and Dustin Tran and Sumit Bagri and Balaji Lakshminarayanan and Jeremiah Liu and Andras Orban and Fabian Güra and Hao Zhou and Xinying Song and Aurelien Boffy and Harish Ganapathy and Steven Zheng and HyunJeong Choe and Ágoston Weisz and Tao Zhu and Yifeng Lu and Siddharth Gopal and Jarrod Kahn and Maciej Kula and Jeff Pitman and Rushin Shah and Emanuel Taropa and Majd Al Merey and Martin Baeuml and Zhifeng Chen and Laurent El Shafey and Yujing Zhang and Olcan Sercinoglu and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Anaïs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Gaurav Singh Tomar and Evan Senter and Martin Chadwick and Ilya Kornakov and Nithya Attaluri and Iñaki Iturrate and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Xavier Garcia and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco"
      },
      {
        "title": "Offline reinforcement learning: Tutorial, review, and perspectives on open problems",
        "abstract": "In this tutorial article, we aim to provide the reader with the conceptual tools needed to get started on research on offline reinforcement learning algorithms: reinforcement learning algorithms that utilize previously collected data, without additional online data collection. Offline reinforcement learning algorithms hold tremendous promise for making it possible to turn large datasets into powerful decision making engines. Effective offline reinforcement learning methods would be able to extract policies with the maximum possible utility out of the available data, thereby allowing automation of a wide range of decision-making domains, from healthcare and education to robotics. However, the limitations of current algorithms make this difficult. We will aim to provide the reader with an understanding of these challenges, particularly in the context of modern deep reinforcement learning methods, and describe some potential solutions that have been explored in recent work to mitigate these challenges, along with recent applications, and a discussion of perspectives on open problems in the field.",
        "year": 2020,
        "authors": "Sergey Levine and Aviral Kumar and George Tucker and Justin Fu"
      },
      {
        "title": "Conservative q-learning for offline reinforcement learning",
        "abstract": "Effectively leveraging large, previously collected datasets in reinforcement learn-ing (RL) is a key challenge for large-scale real-world applications. Offline RL algorithms promise to learn effective policies from previously-collected, static datasets without further interaction. However, in practice, offline RL presents a major challenge, and standard off-policy RL methods can fail due to overestimation of values induced by the distributional shift between the dataset and the learned policy, especially when training on complex and multi-modal data distributions. In this paper, we propose conservative Q-learning (CQL), which aims to address these limitations by learning a conservative Q-function such that the expected value of a policy under this Q-function lower-bounds its true value. We theoretically show that CQL produces a lower bound on the value of the current policy and that it can be incorporated into a policy learning procedure with theoretical improvement guarantees. In practice, CQL augments the standard Bellman error objective with a simple Q-value regularizer which is straightforward to implement on top of existing deep Q-learning and actor-critic implementations. On both discrete and continuous control domains, we show that CQL substantially outperforms existing offline RL methods, often learning policies that attain 2-5 times higher final return, especially when learning from complex and multi-modal data distributions.",
        "year": 2020,
        "authors": "Aviral Kumar and Aurick Zhou and George Tucker and Sergey Levine"
      }
    ],
    "OI7zFmwAAAAJ": [
      {
        "title": "Do as i can, not as i say: Grounding language in robotic affordances",
        "abstract": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model’s “hands and eyes,” while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project’s website, video, and open source can be …",
        "year": 2022,
        "authors": "Anthony Brohan and Yevgen Chebotar and Chelsea Finn and Karol Hausman and Alexander Herzog and Daniel Ho and Julian Ibarz and Alex Irpan and Eric Jang and Ryan Julian and Dmitry Kalashnikov and Sergey Levine and Yao Lu and Carolina Parada and Kanishka Rao and Pierre Sermanet and Alexander T Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Mengyuan Yan and Noah Brown and Michael Ahn and Omar Cortes and Nicolas Sievers and Clayton Tan and Sichun Xu and Diego Reyes and Jarek Rettinghouse and Jornell Quiambao and Peter Pastor and Linda Luu and Kuang-Huei Lee and Yuheng Kuang and Sally Jesmonth and Kyle Jeffrey and Rosario Jauregui Ruano and Jasmine Hsu and Keerthana Gopalakrishnan and Byron David and Andy Zeng and Chuyuan Kelly Fu"
      },
      {
        "title": "RT-2: Vision-language-action models transfer web knowledge to robotic control",
        "abstract": "We study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robotic trajectory data and Internet-scale vision-language tasks, such as visual question answering. In contrast to other approaches, we propose a simple, general recipe to achieve this goal: in order to fit both natural language responses and robotic actions into the same format, we express the actions as text tokens and incorporate them directly into the training set of the model in the same way as natural language tokens. We refer to such category of models as vision-language-action models (VLA) and instantiate an example of such a model, which we call RT-2. Our extensive evaluation (6k evaluation trials) shows that our approach leads to performant robotic policies and enables RT-2 to obtain a range of emergent capabilities from Internet-scale training. This includes significantly improved generalization to novel objects, the ability to interpret commands not present in the robot training data (such as placing an object onto a particular number or icon), and the ability to perform rudimentary reasoning in response to user commands (such as picking up the smallest or largest object, or the one closest to another object). We further show that incorporating chain of …",
        "year": 2023,
        "authors": "Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Xi Chen and Krzysztof Choromanski and Tianli Ding and Danny Driess and Avinava Dubey and Chelsea Finn and Pete Florence and Chuyuan Fu and Montse Gonzalez Arenas and Keerthana Gopalakrishnan and Kehang Han and Karol Hausman and Alexander Herzog and Jasmine Hsu and Brian Ichter and Alex Irpan and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Lisa Lee and Tsang-Wei Edward Lee and Sergey Levine and Yao Lu and Henryk Michalewski and Igor Mordatch and Karl Pertsch and Kanishka Rao and Krista Reymann and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Pierre Sermanet and Jaspiar Singh and Anikait Singh and Radu Soricut and Huong Tran and Vincent Vanhoucke and Quan Vuong and Ayzaan Wahid and Stefan Welker and Paul Wohlhart and Jialin Wu and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich"
      },
      {
        "title": "RT-1: Robotics Transformer for Real-World Control at Scale",
        "abstract": "By transferring knowledge from large, diverse, task-agnostic datasets, modern machine learning models can solve specific downstream tasks either zero-shot or with small task-specific datasets to a high level of performance. While this capability has been demonstrated in other fields such as computer vision, natural language processing or speech recognition, it remains to be shown in robotics, where the generalization capabilities of the models are particularly critical due to the difficulty of collecting real-world robotic data. We argue that one of the keys to the success of such general robotic models lies with open-ended task-agnostic training, combined with high-capacity architectures that can absorb all of the diverse, robotic data. In this paper, we present a model class, dubbed Robotics Transformer, that exhibits promising scalable model properties. We verify our conclusions in a study of different model classes and their ability to generalize as a function of the data size, model size, and data diversity based on a large-scale data collection on real robots performing real-world tasks. The project's website and videos can be found at robotics-transformer1.github.io",
        "year": 2022,
        "authors": "Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Joseph Dabis and Chelsea Finn and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Tomas Jackson and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Kuang-Huei Lee and Sergey Levine and Yao Lu and Utsav Malla and Deeksha Manjunath and Igor Mordatch and Ofir Nachum and Carolina Parada and Jodilyn Peralta and Emily Perez and Karl Pertsch and Jornell Quiambao and Kanishka Rao and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Kevin Sayed and Jaspiar Singh and Sumedh Sontakke and Austin Stone and Clayton Tan and Huong Tran and Vincent Vanhoucke and Steve Vega and Quan Vuong and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich"
      }
    ],
    "0lZoXCUAAAAJ": [
      {
        "title": "Influence and correlation in social networks",
        "abstract": "In many online social systems, social ties between users play an important role in dictating their behavior. One of the ways this can happen is through social influence, the phenomenon that the actions of a user can induce his/her friends to behave in a similar way. In systems where social influence exists, ideas, modes of behavior, or new technologies can diffuse through the network like an epidemic. Therefore, identifying and understanding social influence is of tremendous interest from both analysis and design points of view.This is a difficult task in general, since there are factors such as homophily or unobserved confounding variables that can induce statistical correlation between the actions of friends in a social network. Distinguishing influence from these is essentially the problem of distinguishing correlation from causality, a notoriously hard statistical problem.In this paper we study this problem systematically …",
        "year": 2008,
        "authors": "Aris Anagnostopoulos and Ravi Kumar and Mohammad Mahdian"
      },
      {
        "title": "Greedy Facility Location Algorithms Analyzed using Dual Fitting with Factor-Revealing LP",
        "abstract": "In this article, we will formalize the method of dual fitting and the idea of factor-revealing LP. This combination is used to design and analyze two greedy algorithms for the metric uncapacitated facility location problem. Their approximation factors are 1.861 and 1.61, with running times of O(m log m) and O(n3), respectively, where n is the total number of vertices and m is the number of edges in the underlying complete bipartite graph between cities and facilities. The algorithms are used to improve recent results for several variants of the problem.",
        "year": 2003,
        "authors": "K Jain and M Mahdian and E Markakis and A Saberi and VV Vazirani"
      },
      {
        "title": "A new greedy approach for facility location problems",
        "abstract": "We present a simple and natural greedy algorithm for the metric uncapacitated facility location problem achieving an approximation guarantee of 1.61. We use this algorithm to find better approximation algorithms for the capacitated facility location problem with soft capacities and for a common generalization of the k-median and facility location problems. We also prove a lower bound of 1+2/e on the approximability of the k-median problem. At the end, we present a discussion about the techniques we have used in the analysis of our algorithm, including a computer-aided method for proving bounds on the approximation factor.",
        "year": 2002,
        "authors": "Kamal Jain and Mohammad Mahdian and Amin Saberi"
      }
    ],
    "XqLiBQMAAAAJ": [
      {
        "title": "Robust face recognition via sparse representation",
        "abstract": "We consider the problem of automatically recognizing human faces from frontal views with varying expression and illumination, as well as occlusion and disguise. We cast the recognition problem as one of classifying among multiple linear regression models and argue that new theory from sparse signal representation offers the key to addressing this problem. Based on a sparse representation computed by \\ell^{1}-minimization, we propose a general classification algorithm for (image-based) object recognition. This new framework provides new insights into two crucial issues in face recognition: feature extraction and robustness to occlusion. For feature extraction, we show that if sparsity in the recognition problem is properly harnessed, the choice of features is no longer critical. What is critical, however, is whether the number of features is sufficiently large and whether the sparse representation is correctly …",
        "year": 2008,
        "authors": "John Wright and Allen Y Yang and Arvind Ganesh and S Shankar Sastry and Yi Ma"
      },
      {
        "title": "Robust principal component analysis?",
        "abstract": "This article is about a curious phenomenon. Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Can we recover each component individually? We prove that under some suitable assumptions, it is possible to recover both the low-rank and the sparse components exactly by solving a very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the ℓ1 norm. This suggests the possibility of a principled approach to robust principal component analysis since our methodology and results assert that one can recover the principal components of a data matrix even though a positive fraction of its entries are arbitrarily corrupted. This extends to the situation where a fraction of the entries are missing as well. We discuss an algorithm for solving this …",
        "year": 2011,
        "authors": "Emmanuel J Candes and Xiaodong Li and Yi Ma and John Wright"
      },
      {
        "title": "Image super-resolution via sparse representation",
        "abstract": "This paper presents a new approach to single-image superresolution, based upon sparse signal representation. Research on image statistics suggests that image patches can be well-represented as a sparse linear combination of elements from an appropriately chosen over-complete dictionary. Inspired by this observation, we seek a sparse representation for each patch of the low-resolution input, and then use the coefficients of this representation to generate the high-resolution output. Theoretical results from compressed sensing suggest that under mild conditions, the sparse representation can be correctly recovered from the downsampled signals. By jointly training two dictionaries for the low- and high-resolution image patches, we can enforce the similarity of sparse representations between the low-resolution and high-resolution image patch pair with respect to their own dictionaries. Therefore, the sparse …",
        "year": 2010,
        "authors": "Jianchao Yang and John Wright and Thomas S Huang and Yi Ma"
      }
    ],
    "pzw1-J4AAAAJ": [
      {
        "title": "Model cards for model reporting",
        "abstract": "Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type [15]) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended …",
        "year": 2019,
        "authors": "Margaret Mitchell and Simone Wu and Andrew Zaldivar and Parker Barnes and Lucy Vasserman and Ben Hutchinson and Elena Spitzer and Inioluwa Deborah Raji and Timnit Gebru"
      },
      {
        "title": "Closing the AI Accountability Gap: Defining an End-to-End Framework for Internal Algorithmic Auditing",
        "abstract": "Rising concern for the societal implications of artificial intelligence systems has inspired a wave of academic and journalistic literature in which deployed systems are audited for harm by investigators from outside the organizations deploying the algorithms. However, it remains challenging for practitioners to identify the harmful repercussions of their own systems prior to deployment, and, once deployed, emergent issues can become difficult or impossible to trace back to their source.In this paper, we introduce a framework for algorithmic auditing that supports artificial intelligence system development end-to-end, to be applied throughout the internal organization development life-cycle. Each stage of the audit yields a set of documents that together form an overall audit report, drawing on an organization's values or principles to assess the fit of decisions made throughout the process. The proposed auditing …",
        "year": 2020,
        "authors": "Inioluwa Deborah Raji and Andrew Smart and Rebecca N White and Margaret Mitchell and Timnit Gebru and Ben Hutchinson and Jamila Smith-Loud and Daniel Theron and Parker Barnes"
      },
      {
        "title": "Actionable auditing: Investigating the impact of publicly naming biased performance results of commercial ai products",
        "abstract": "Although algorithmic auditing has emerged as a key strategy to expose systematic biases embedded in software platforms, we struggle to understand the real-world impact of these audits, as scholarship on the impact of algorithmic audits on increasing algorithmic fairness and transparency in commercial systems is nascent. To analyze the impact of publicly naming and disclosing performance results of biased AI systems, we investigate the commercial impact of Gender Shades, the first algorithmic audit of gender and skin type performance disparities in commercial facial analysis models. This paper 1) outlines the audit design and structured disclosure procedure used in the Gender Shades study, 2) presents new performance metrics from targeted companies IBM, Microsoft and Megvii (Face++) on the Pilot Parliaments Benchmark (PPB) as of August 2018, 3) provides performance results on PPB by non-target …",
        "year": 2019,
        "authors": "Inioluwa Deborah Raji and Joy Buolamwini"
      }
    ],
    "y1lVpBEAAAAJ": [
      {
        "title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5 MB model size",
        "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet). The SqueezeNet architecture is available for download here: https://github.com/DeepScale/SqueezeNet",
        "year": 2016,
        "authors": "Forrest N Iandola and Song Han and Matthew W Moskewicz and Khalid Ashraf and William J Dally and Kurt Keutzer"
      },
      {
        "title": "From captions to visual concepts and back",
        "abstract": "This paper presents a novel approach for automatically generating image descriptions: visual detectors, language models, and multimodal similarity models learnt directly from a dataset of image captions. We use multiple instance learning to train visual detectors for words that commonly occur in captions, including many different parts of speech such as nouns, verbs, and adjectives. The word detector outputs serve as conditional inputs to a maximum-entropy language model. The language model learns from a set of over 400,000 image descriptions to capture the statistics of word usage. We capture global semantics by re-ranking caption candidates using sentence-level features and a deep multimodal similarity model. Our system is state-of-the-art on the official Microsoft COCO benchmark, producing a BLEU-4 score of 29.1%. When human judges compare the system captions to ones written by other people on our held-out test set, the system captions have equal or better quality 34% of the time.",
        "year": 2015,
        "authors": "Hao Fang and Saurabh Gupta and Forrest Iandola and Rupesh K Srivastava and Li Deng and Piotr Dollár and Jianfeng Gao and Xiaodong He and Margaret Mitchell and John C Platt and C Lawrence Zitnick and Geoffrey Zweig"
      },
      {
        "title": "Densenet: Implementing efficient convnet descriptor pyramids.",
        "abstract": "Convolutional Neural Networks (CNNs) can provide accurate object classification. They can be extended to perform object detection by iterating over dense or selected proposed object regions. However, the runtime of such detectors scales as the total number and/or area of regions to examine per image, and training such detectors may be prohibitively slow. However, for some CNN classifier topologies, it is possible to share significant work among overlapping regions to be classified. This paper presents DenseNet, an open source system that computes dense, multiscale features from the convolutional layers of a CNN based object classifier. Future work will involve training efficient object detectors with DenseNet feature descriptors.",
        "year": 2014,
        "authors": "F Iandola and M Moskewicz and S Karayev and R Girshick and T Darrell and K Keutzer"
      }
    ],
    "xRmmtzIAAAAJ": [
      {
        "title": "Design of energy-and cost-efficient massive MIMO arrays",
        "abstract": "Large arrays of radios have been exploited for beamforming and null steering in both radar and communication applications, but cost and form factor limitations have precluded their use in commercial systems. This paper discusses how to build arrays that enable multiuser massive multiple-input-multiple-output (MIMO) and aggressive spatial multiplexing with many users sharing the same spectrum. The focus of the paper is the energy- and cost-efficient realization of these arrays in order to enable new applications. Distributed algorithms for beamforming are proposed, and the optimum array size is considered as a function of the performance of the receiver, transmitter, frequency synthesizer, and signal distribution within the array. The effects of errors such as phase noise and synchronization skew across the array are analyzed. The paper discusses both RF frequencies below 10 GHz, where fully digital techniques …",
        "year": 2015,
        "authors": "Antonio Puglielli and Andrew Townley and Greg LaCaille and Vladimir Milovanović and Pengpeng Lu and Konstantin Trotskovsky and Amy Whitcombe and Nathan Narevsky and Gregory Wright and Thomas Courtade and Elad Alon and Borivoje Nikolić and Ali M Niknejad"
      },
      {
        "title": "Multiterminal source coding under logarithmic loss",
        "abstract": "We consider the classical two-encoder multiterminal source coding problem where distortion is measured under logarithmic loss. We provide a single-letter description of the achievable rate distortion region for all discrete memoryless sources with finite alphabets. By doing so, we also give the rate distortion region for the -encoder CEO problem (also under logarithmic loss). Several applications and examples are given.",
        "year": 2013,
        "authors": "Thomas A Courtade and Tsachy Weissman"
      },
      {
        "title": "Soft information for LDPC decoding in flash: Mutual-information optimized quantization",
        "abstract": "High-capacity NAND flash memory can achieve high density storage by using multi-level cells (MLC) to store more than one bit per cell. Although this larger storage capacity is certainly beneficial, the increased density also increases the raw bit error rate (BER), making powerful error correction coding necessary. Traditional flash memories employ simple algebraic codes, such as BCH codes, that can correct a fixed, specified number of errors. This paper investigates the application of low-density parity-check (LDPC) codes which are well known for their ability to approach capacity in the AWGN channel. We obtain soft information for the LDPC decoder by performing multiple cell reads with distinct word-line voltages. The values of the word-line voltages (also called reference voltages) are optimized by maximizing the mutual information between the input and output of the multiple-read channel. Our results show that …",
        "year": 2011,
        "authors": "Jiadong Wang and Thomas Courtade and Hari Shankar and Richard D Wesel"
      }
    ],
    "APgaFK0AAAAJ": [
      {
        "title": "Multimodal machine learning: A survey and taxonomy",
        "abstract": "Our experience of the world is multimodal - we see objects, hear sounds, feel texture, smell odors, and taste flavors. Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities. In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together. Multimodal machine learning aims to build models that can process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy. We go beyond the typical early and late fusion categorization and identify broader challenges …",
        "year": 2018,
        "authors": "Tadas Baltrušaitis and Chaitanya Ahuja and Louis-Philippe Morency"
      },
      {
        "title": "Openface: an open source facial behavior analysis toolkit",
        "abstract": "Over the past few years, there has been an increased interest in automatic facial behavior analysis and understanding. We present OpenFace - an open source tool intended for computer vision and machine learning researchers, affective computing community and people interested in building interactive applications based on facial behavior analysis. OpenFace is the first open source tool capable of facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation. The computer vision algorithms which represent the core of OpenFace demonstrate state-of-the-art results in all of the above mentioned tasks. Furthermore, our tool is capable of real-time performance and is able to run from a simple webcam without any specialist hardware. Finally, OpenFace allows for easy integration with other applications and devices through a lightweight messaging system.",
        "year": 2016,
        "authors": "Tadas Baltrušaitis and Peter Robinson and Louis-Philippe Morency"
      },
      {
        "title": "Tensor fusion network for multimodal sentiment analysis",
        "abstract": "Multimodal sentiment analysis is an increasingly popular research area, which extends the conventional language-based definition of sentiment analysis to a multimodal setup where other relevant modalities accompany language. In this paper, we pose the problem of multimodal sentiment analysis as modeling intra-modality and inter-modality dynamics. We introduce a novel model, termed Tensor Fusion Network, which learns both such dynamics end-to-end. The proposed approach is tailored for the volatile nature of spoken language in online videos as well as accompanying gestures and voice. In the experiments, our model outperforms state-of-the-art approaches for both multimodal and unimodal sentiment analysis.",
        "year": 2017,
        "authors": "Amir Zadeh and Minghai Chen and Soujanya Poria and Erik Cambria and Louis-Philippe Morency"
      }
    ],
    "BsOkXDsAAAAJ": [
      {
        "title": "Offline reinforcement learning with implicit q-learning",
        "abstract": "Offline reinforcement learning requires reconciling two conflicting aims: learning a policy that improves over the behavior policy that collected the dataset, while at the same time minimizing the deviation from the behavior policy so as to avoid errors due to distributional shift. This trade-off is critical, because most current offline reinforcement learning methods need to query the value of unseen actions during training to improve the policy, and therefore need to either constrain these actions to be in-distribution, or else regularize their values. We propose an offline RL method that never needs to evaluate actions outside of the dataset, but still enables the learned policy to improve substantially over the best behavior in the data through generalization. The main insight in our work is that, instead of evaluating unseen actions from the latest policy, we can approximate the policy improvement step implicitly by treating the state value function as a random variable, with randomness determined by the action (while still integrating over the dynamics to avoid excessive optimism), and then taking a state conditional upper expectile of this random variable to estimate the value of the best actions in that state. This leverages the generalization capacity of the function approximator to estimate the value of the best available action at a given state without ever directly querying a Q-function with this unseen action. Our algorithm alternates between fitting this upper expectile value function and backing it up into a Q-function. Then, we extract the policy via advantage-weighted behavioral cloning. We dub our method implicit Q-learning (IQL). IQL demonstrates the state-of …",
        "year": 2021,
        "authors": "Ilya Kostrikov and Ashvin Nair and Sergey Levine"
      },
      {
        "title": "Overcoming exploration in reinforcement learning with demonstrations",
        "abstract": "Exploration in environments with sparse rewards has been a persistent problem in reinforcement learning (RL). Many tasks are natural to specify with a sparse reward, and manually shaping a reward function can result in suboptimal performance. However, finding a non-zero reward is exponentially more difficult with increasing task horizon or action dimensionality. This puts many real-world tasks out of practical reach of RL methods. In this work, we use demonstrations to overcome the exploration problem and successfully learn to perform long-horizon, multi-step robotics tasks with continuous control such as stacking blocks with a robot arm. Our method, which builds on top of Deep Deterministic Policy Gradients and Hindsight Experience Replay, provides an order of magnitude of speedup over RL on simulated robotics tasks. It is simple to implement and makes only the additional assumption that we can collect a …",
        "year": 2017,
        "authors": "Ashvin Nair and Bob McGrew and Marcin Andrychowicz and Wojciech Zaremba and Pieter Abbeel"
      }
    ],
    "1wLVDP4AAAAJ": [
      {
        "title": "Soft actor-critic algorithms and applications",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Diversity is all you need: Learning skills without a reward function",
        "abstract": "Intelligent creatures can explore their environments and learn useful skills without supervision. In this paper, we propose DIAYN ('Diversity is All You Need'), a method for learning useful skills without a reward function. Our proposed method learns skills by maximizing an information theoretic objective using a maximum entropy policy. On a variety of simulated robotic tasks, we show that this simple objective results in the unsupervised emergence of diverse skills, such as walking and jumping. In a number of reinforcement learning benchmark environments, our method is able to learn a skill that solves the benchmark task despite never receiving the true task reward. We show how pretrained skills can provide a good parameter initialization for downstream tasks, and can be composed hierarchically to solve complex, sparse reward tasks. Our results suggest that unsupervised discovery of skills can serve as an effective pretraining mechanism for overcoming challenges of exploration and data efficiency in reinforcement learning.",
        "year": 2018,
        "authors": "Benjamin Eysenbach and Abhishek Gupta and Julian Ibarz and Sergey Levine"
      },
      {
        "title": "Gradient surgery for multi-task learning",
        "abstract": "While deep learning and deep reinforcement learning (RL) systems have demonstrated impressive results in domains such as image classification, game playing, and robotic control, data efficiency remains a major challenge. Multi-task learning has emerged as a promising approach for sharing structure across multiple tasks to enable more efficient learning. However, the multi-task setting presents a number of optimization challenges, making it difficult to realize large efficiency gains compared to learning tasks independently. The reasons why multi-task learning is so challenging compared to single-task learning are not fully understood. In this work, we identify a set of three conditions of the multi-task optimization landscape that cause detrimental gradient interference, and develop a simple yet general approach for avoiding such interference between task gradients. We propose a form of gradient surgery that projects a task's gradient onto the normal plane of the gradient of any other task that has a gradient. On a series of challenging multi-task supervised and multi-task RL problems, this approach leads to substantial gains in efficiency and performance. Further, it is model-agnostic and can be combined with previously-proposed multi-task architectures for enhanced performance.",
        "year": 2020,
        "authors": "Tianhe Yu and Saurabh Kumar and Abhishek Gupta and Sergey Levine and Karol Hausman and Chelsea Finn"
      }
    ],
    "5LLV29oAAAAJ": [
      {
        "title": "Apache spark: a unified engine for big data processing",
        "abstract": "This open source computing framework unifies streaming, batch, and interactive big data workloads to unlock new applications.",
        "year": 2016,
        "authors": "Matei Zaharia and Reynold S Xin and Patrick Wendell and Tathagata Das and Michael Armbrust and Ankur Dave and Xiangrui Meng and Josh Rosen and Shivaram Venkataraman and Michael J Franklin and Ali Ghodsi and Joseph Gonzalez and Scott Shenker and Ion Stoica"
      },
      {
        "title": "Mllib: Machine learning in apache spark",
        "abstract": "On-line portfolio selection is a practical financial engineering problem, which aims to sequentially allocate capital among a set of assets in order to maximize long-term return. In recent years, a variety of machine learning algorithms have been proposed to address this challenging problem, but no comprehensive open-source toolbox has been released for various reasons. This article presents the first open-source toolbox for \"On-Line Portfolio Selection\" (OLPS), which implements a collection of classical and state-of-the-art strategies powered by machine learning algorithms. We hope that OLPS can facilitate the development of new learning methods and enable the performance benchmarking and comparisons of different strategies. OLPS is an open-source project released under Apache License (version 2.0), which is available at https://github.com/OLPS/ or http://OLPS.stevenhoi.org/.",
        "year": 2016,
        "authors": "Xiangrui Meng and Joseph Bradley and Burak Yavuz and Evan Sparks and Shivaram Venkataraman and Davies Liu and Jeremy Freeman and DB Tsai and Manish Amde and Sean Owen and Doris Xin and Reynold Xin and Michael J Franklin and Reza Zadeh and Matei Zaharia and Ameet Talwalkar"
      },
      {
        "title": "{CherryPick}: Adaptively unearthing the best cloud configurations for big data analytics",
        "abstract": "Picking the right cloud configuration for recurring big data analytics jobs running in clouds is hard, because there can be tens of possible VM instance types and even more cluster sizes to pick from. Choosing poorly can significantly degrade performance and increase the cost to run a job by 2-3x on average, and as much as 12x in the worst-case. However, it is challenging to automatically identify the best configuration for a broad spectrum of applications and cloud configurations with low search cost. CherryPick is a system that leverages Bayesian Optimization to build performance models for various applications, and the models are just accurate enough to distinguish the best or close-to-the-best configuration from the rest with only a few test runs. Our experiments on five analytic applications in AWS EC2 show that CherryPick has a 45-90% chance to find optimal configurations, otherwise near-optimal, saving up to 75% search cost compared to existing solutions.",
        "year": 2017,
        "authors": "Omid Alipourfard and Hongqiang Harry Liu and Jianshu Chen and Shivaram Venkataraman and Minlan Yu and Ming Zhang"
      }
    ],
    "nXBQn7gAAAAJ": [
      {
        "title": "Photobook: Content-based manipulation of image databases",
        "abstract": "We describe the Photobook system, which is a set of interactive tools for browsing and searching images and image sequences. These query tools differ from those used in standard image databases in that they make direct use of the image content rather than relying on text annotations. Direct search on image content is made possible by use of semantics-preserving image compression, which reduces images to a small set of perceptually-significant coefficients. We discuss three types of Photobook descriptions in detail: one that allows search based on appearance, one that uses 2-D shape, and a third that allows search based on textural properties. These image content descriptions can be combined with each other and with text-based descriptions to provide a sophisticated browsing and search capability. In this paper we demonstrate Photobook on databases containing images of people, video …",
        "year": 1996,
        "authors": "A Pentland and RW Picard and S Sclaroff"
      },
      {
        "title": "Photobook: tools for content-based manipulation of image databases",
        "abstract": "We describe the Photobook system, which is a set of interactive tools for browsing and searching images and image sequences. These tools differ from those used in standard image databases in that they make direct use of the image content rather than relying on annotations. Direct search on image content is made possible by use of semantics-preserving image compression, which reduces images to a small set of perceptually significant coefficients. We describe three Photobook tools in particular: one that allows search based on gray-level appearance, one that uses 2-D shape, and a third that allows search based on textural properties.",
        "year": 1994,
        "authors": "Alexander P. Pentland and W Picard and Rosalind and S Sclaroff"
      },
      {
        "title": "MEEM: robust tracking via multiple experts using entropy minimization",
        "abstract": "We propose a multi-expert restoration scheme to address the model drift problem in online tracking. In the proposed scheme, a tracker and its historical snapshots constitute an expert ensemble, where the best expert is selected to restore the current tracker when needed based on a minimum entropy criterion, so as to correct undesirable model updates. The base tracker in our formulation exploits an online SVM on a budget algorithm and an explicit feature mapping method for efficient model update and inference. In experiments, our tracking method achieves substantially better overall performance than 32 trackers on a benchmark dataset of 50 video sequences under various evaluation settings. In addition, in experiments with a newly collected dataset of challenging sequences, we show that the proposed multi-expert restoration scheme significantly improves the robustness of our base tracker, especially …",
        "year": 2014,
        "authors": "Jianming Zhang and Shugao Ma and Stan Sclaroff"
      }
    ],
    "4zybTq4AAAAJ": [
      {
        "title": "QSGD: Communication-Efficient SGD via Gradient Quantization and Encoding",
        "abstract": "Parallel implementations of stochastic gradient descent (SGD) have received significant research attention, thanks to its excellent scalability properties. A fundamental barrier when parallelizing SGD is the high bandwidth cost of communicating gradient updates between nodes; consequently, several lossy compresion heuristics have been proposed, by which nodes only communicate quantized gradients. Although effective in practice, these heuristics do not always guarantee convergence, and it is not clear whether they can be improved. In this paper, we propose Quantized SGD (QSGD), a family of compression schemes for gradient updates which provides convergence guarantees. QSGD allows the user to smoothly trade off\\emph {communication bandwidth} and\\emph {convergence time}: nodes can adjust the number of bits sent per iteration, at the cost of possibly higher variance. We show that this trade-off is inherent, in the sense that improving it past some threshold would violate information-theoretic lower bounds. QSGD guarantees convergence for convex and non-convex objectives, under asynchrony, and can be extended to stochastic variance-reduced techniques. When applied to training deep neural networks for image classification and automated speech recognition, QSGD leads to significant reductions in end-to-end training time. For example, on 16GPUs, we can train the ResNet152 network to full accuracy on ImageNet 1.8 x faster than the full-precision variant.",
        "year": 2017,
        "authors": "Dan Alistarh and Demjan Grubic and Jerry Li and Ryota Tomioka and Milan Vojnovic"
      },
      {
        "title": "Spectral signatures in backdoor attacks",
        "abstract": "A recent line of work has uncovered a new form of data poisoning: so-called backdoor attacks. These attacks are particularly dangerous because they do not affect a network's behavior on typical, benign data. Rather, the network only deviates from its expected output when triggered by an adversary's planted perturbation.",
        "year": 2018,
        "authors": "Brandon Tran and Jerry Li and Aleksander Madry"
      },
      {
        "title": "Provably robust deep learning via adversarially trained smoothed classifiers",
        "abstract": "Recent works have shown the effectiveness of randomized smoothing as a scalable technique for building neural network-based classifiers that are provably robust to -norm adversarial perturbations. In this paper, we employ adversarial training to improve the performance of randomized smoothing. We design an adapted attack for smoothed classifiers, and we show how this attack can be used in an adversarial training setting to boost the provable robustness of smoothed classifiers. We demonstrate through extensive experimentation that our method consistently outperforms all existing provably -robust classifiers by a significant margin on ImageNet and CIFAR-10, establishing the state-of-the-art for provable -defenses. Moreover, we find that pre-training and semi-supervised learning boost adversarially trained smoothed classifiers even further. Our code and trained models are available at http://github. com/Hadisalman/smoothing-adversarial.",
        "year": 2019,
        "authors": "Hadi Salman and Jerry Li and Ilya Razenshteyn and Pengchuan Zhang and Huan Zhang and Sebastien Bubeck and Greg Yang"
      }
    ],
    "H1vNRiUAAAAJ": [
      {
        "title": "An 𝐿^{𝑝} theory of sparse graph convergence I: Limits, sparse random graph models, and power law distributions",
        "abstract": "We introduce and develop a theory of limits for sequences of sparse graphs based on  graphons, which generalizes both the existing  theory of dense graph limits and its extension by Bollobás and Riordan to sparse graphs without dense spots. In doing so, we replace the no dense spots hypothesis with weaker assumptions, which allow us to analyze graphs with power law degree distributions. This gives the first broadly applicable limit theory for sparse graphs with unbounded average degrees. In this paper, we lay the foundations of the  theory of graphons, characterize convergence, and develop corresponding random graph models, while we prove the equivalence of several alternative metrics in a companion paper. References",
        "year": 2019,
        "authors": "Christian Borgs and Jennifer Chayes and Henry Cohn and Yufei Zhao"
      },
      {
        "title": "The number of independent sets in a regular graph",
        "abstract": "We show that the number of independent sets in an N-vertex, d-regular graph is at most (2d+1 − 1)N/2d, where the bound is sharp for a disjoint union of complete d-regular bipartite graphs. This settles a conjecture of Alon in 1991 and Kahn in 2001. Kahn proved the bound when the graph is assumed to be bipartite. We give a short proof that reduces the general case to the bipartite case. Our method also works for a weighted generalization, i.e., an upper bound for the independence polynomial of a regular graph.",
        "year": 2010,
        "authors": "Yufei Zhao"
      },
      {
        "title": "An Lp theory of sparse graph convergence II: LD convergence, quotients, and right convergence",
        "abstract": "We extend the  theory of sparse graph limits, which was introduced in a companion paper, by analyzing different notions of convergence. Under suitable restrictions on node weights, we prove the equivalence of metric convergence, quotient convergence, microcanonical ground state energy convergence, microcanonical free energy convergence and large deviation convergence. Our theorems extend the broad applicability of dense graph convergence to all sparse graphs with unbounded average degree, while the proofs require new techniques based on uniform upper regularity. Examples to which our theory applies include stochastic block models, power law graphs and sparse versions of -random graphs.",
        "year": 2018,
        "authors": "Christian Borgs and Jennifer T Chayes and Henry Cohn and Yufei Zhao"
      }
    ],
    "jo2C_wkAAAAJ": [
      {
        "title": "Apache spark: a unified engine for big data processing",
        "abstract": "This open source computing framework unifies streaming, batch, and interactive big data workloads to unlock new applications.",
        "year": 2016,
        "authors": "Matei Zaharia and Reynold S Xin and Patrick Wendell and Tathagata Das and Michael Armbrust and Ankur Dave and Xiangrui Meng and Josh Rosen and Shivaram Venkataraman and Michael J Franklin and Ali Ghodsi and Joseph Gonzalez and Scott Shenker and Ion Stoica"
      },
      {
        "title": "Sparrow: distributed, low latency scheduling",
        "abstract": "Large-scale data analytics frameworks are shifting towards shorter task durations and larger degrees of parallelism to provide low latency. Scheduling highly parallel jobs that complete in hundreds of milliseconds poses a major challenge for task schedulers, which will need to schedule millions of tasks per second on appropriate machines while offering millisecond-level latency and high availability. We demonstrate that a decentralized, randomized sampling approach provides near-optimal performance while avoiding the throughput and availability limitations of a centralized design. We implement and deploy our scheduler, Sparrow, on a 110-machine cluster and demonstrate that Sparrow performs within 12% of an ideal scheduler.",
        "year": 2013,
        "authors": "Kay Ousterhout and Patrick Wendell and Matei Zaharia and Ion Stoica"
      },
      {
        "title": "Learning spark: lightning-fast big data analysis",
        "abstract": "Data in all domains is getting bigger. How can you work with it efficiently? Recently updated for Spark 1.3, this book introduces Apache Spark, the open source cluster computing system that makes data analytics fast to write and fast to run. With Spark, you can tackle big datasets quickly through simple APIs in Python, Java, and Scala. This edition includes new information on Spark SQL, Spark Streaming, setup, and Maven coordinates. Written by the developers of Spark, this book will have data scientists and engineers up and running in no time. You’ll learn how to express parallel jobs with just a few lines of code, and cover applications from simple batch jobs to stream processing and machine learning. Quickly dive into Spark capabilities such as distributed datasets, in-memory caching, and the interactive shell Leverage Spark’s powerful built-in libraries, including Spark SQL, Spark Streaming, and MLlib Use one programming paradigm instead of mixing and matching tools like Hive, Hadoop, Mahout, and Storm Learn how to deploy interactive, batch, and streaming applications Connect to data sources including HDFS, Hive, JSON, and S3 Master advanced topics like data partitioning and shared variables",
        "year": 2015,
        "authors": "Holden Karau and Andy Konwinski and Patrick Wendell and Matei Zaharia"
      }
    ],
    "r3q68rcAAAAJ": [
      {
        "title": "Message-passing algorithms for compressed sensing",
        "abstract": "Compressed sensing aims to undersample certain high-dimensional signals yet accurately reconstruct them by exploiting signal characteristics. Accurate reconstruction is possible when the object to be recovered is sufficiently sparse in a known basis. Currently, the best known sparsity–undersampling tradeoff is achieved when reconstructing by convex optimization, which is expensive in important large-scale applications. Fast iterative thresholding algorithms have been intensively studied as alternatives to convex optimization for large-scale problems. Unfortunately known fast algorithms offer substantially worse sparsity–undersampling tradeoffs than convex optimization. We introduce a simple costless modification to iterative thresholding making the sparsity–undersampling tradeoff of the new algorithms equivalent to that of the corresponding convex optimization procedures. The new iterative-thresholding …",
        "year": 2009,
        "authors": "David L Donoho and Arian Maleki and Andrea Montanari"
      },
      {
        "title": "Information, physics, and computation",
        "abstract": "This book presents a unified approach to a rich and rapidly evolving research domain at the interface between statistical physics, theoretical computer science/discrete mathematics, and coding/information theory. It is accessible to graduate students and researchers without a specific training in any of these fields. The selected topics include spin glasses, error correcting codes, satisfiability, and are central to each field. The approach focuses on large random instances and adopts a common probabilistic formulation in terms of graphical models. It presents message passing algorithms like belief propagation and survey propagation, and their use in decoding and constraint satisfaction solving. It also explains analysis techniques like density evolution and the cavity method, and uses them to study phase transitions.",
        "year": 2009,
        "authors": "Marc Mezard and Andrea Montanari"
      },
      {
        "title": "Matrix completion from a few entries",
        "abstract": "Let M be an n¿ × n matrix of rank r, and assume that a uniformly random subset E of its entries is observed. We describe an efficient algorithm, which we call OptSpace, that reconstructs M from |E| = O(rn) observed entries with relative root mean square error 1/2 RMSE ¿ C(¿) (nr/|E|)1/2 with probability larger than 1 - 1/n3. Further, if r = O(1) and M is sufficiently unstructured, then OptSpace reconstructs it exactly from |E| = O(n log n) entries with probability larger than 1 - 1/n3. This settles (in the case of bounded rank) a question left open by Candes and Recht and improves over the guarantees for their reconstruction algorithm. The complexity of our algorithm is O(|E|r log n), which opens the way to its use for massive data sets. In the process of proving these statements, we obtain a generalization of a celebrated result by Friedman-Kahn-Szemeredi and Feige-Ofek on the spectrum of sparse random matrices.",
        "year": 2010,
        "authors": "Raghunandan H Keshavan and Andrea Montanari and Sewoong Oh"
      }
    ],
    "mqpjAt4AAAAJ": [
      {
        "title": "Decaf: A deep convolutional activation feature for generic visual recognition",
        "abstract": "We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.",
        "year": 2013,
        "authors": "Jeff Donahue and Yangqing Jia and Oriol Vinyals and Judy Hoffman and Ning Zhang and Eric Tzeng and Trevor Darrell"
      },
      {
        "title": "Adversarial discriminative domain adaptation",
        "abstract": "Adversarial learning methods are a promising approach to training robust deep networks, and can generate complex samples across diverse domains. They can also improve recognition despite the presence of domain shift or dataset bias: recent adversarial approaches to unsupervised domain adaptation reduce the difference between the training and test domain distributions and thus improve generalization performance. However, while generative adversarial networks (GANs) show compelling visualizations, they are not optimal on discriminative tasks and can be limited to smaller shifts. On the other hand, discriminative approaches can handle larger domain shifts, but impose tied weights on the model and do not exploit a GAN-based loss. In this work, we first outline a novel generalized framework for adversarial adaptation, which subsumes recent state-of-the-art approaches as special cases, and use this generalized view to better relate prior approaches. We then propose a previously unexplored instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss, which we call Adversarial Discriminative Domain Adaptation (ADDA). We show that ADDA is more effective yet considerably simpler than competing domain-adversarial methods, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results on standard domain adaptation tasks as well as a difficult cross-modality object classification task.",
        "year": 2017,
        "authors": "Eric Tzeng and Judy Hoffman and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Cycada: Cycle-consistent adversarial domain adaptation",
        "abstract": "Domain adaptation is critical for success in new, unseen environments. Adversarial adaptation models have shown tremendous progress towards adapting to new environments by focusing either on discovering domain invariant representations or by mapping between unpaired image domains. While feature space methods are difficult to interpret and sometimes fail to capture pixel-level and low-level domain shifts, image space methods sometimes fail to incorporate high level semantic knowledge relevant for the end task. We propose a model which adapts between domains using both generative image space alignment and latent representation space alignment. Our approach, Cycle-Consistent Adversarial Domain Adaptation (CyCADA), guides transfer between domains according to a specific discriminatively trained task and avoids divergence by enforcing consistency of the relevant semantics before and after adaptation. We evaluate our method on a variety of visual recognition and prediction settings, including digit classification and semantic segmentation of road scenes, advancing state-of-the-art performance for unsupervised adaptation from synthetic to real world driving domains.",
        "year": 2018,
        "authors": "Judy Hoffman and Eric Tzeng and Taesung Park and Jun-Yan Zhu and Phillip Isola and Kate Saenko and Alexei A Efros and Trevor Darrell"
      }
    ],
    "YLOz1kgAAAAJ": [
      {
        "title": "Deep back-projection networks for super-resolution",
        "abstract": "The feed-forward architectures of recently proposed deep super-resolution networks learn representations of low-resolution inputs, and the non-linear mapping from those to high-resolution output. However, this approach does not fully address the mutual dependencies of low-and high-resolution images. We propose Deep Back-Projection Networks (DBPN), that exploit iterative up-and down-sampling layers, providing an error feedback mechanism for projection errors at each stage. We construct mutually-connected up-and down-sampling stages each of which represents different types of image degradation and high-resolution components. We show that extending this idea to allow concatenation of features across up-and down-sampling stages (Dense DBPN) allows us to reconstruct further improve super-resolution, yielding superior results and in particular establishing new state of the art results for large scaling factors such as 8x across multiple data sets.",
        "year": 2018,
        "authors": "Muhammad Haris and Gregory Shakhnarovich and Norimichi Ukita"
      },
      {
        "title": "Fractalnet: Ultra-deep neural networks without residuals",
        "abstract": "We introduce a design strategy for neural network macro-architecture based on self-similarity. Repeated application of a simple expansion rule generates deep networks whose structural layouts are precisely truncated fractals. These networks contain interacting subpaths of different lengths, but do not include any pass-through or residual connections; every internal signal is transformed by a filter and nonlinearity before being seen by subsequent layers. In experiments, fractal networks match the excellent performance of standard residual networks on both CIFAR and ImageNet classification tasks, thereby demonstrating that residual representations may not be fundamental to the success of extremely deep convolutional neural networks. Rather, the key may be the ability to transition, during training, from effectively shallow to deep. We note similarities with student-teacher behavior and develop drop-path, a natural extension of dropout, to regularize co-adaptation of subpaths in fractal architectures. Such regularization allows extraction of high-performance fixed-depth subnetworks. Additionally, fractal networks exhibit an anytime property: shallow subnetworks provide a quick answer, while deeper subnetworks, with higher latency, provide a more accurate answer.",
        "year": 2017,
        "authors": "Gustav Larsson and Michael Maire and Gregory Shakhnarovich"
      },
      {
        "title": "Learning representations for automatic colorization",
        "abstract": "We develop a fully automatic image colorization system. Our approach leverages recent advances in deep networks, exploiting both low-level and semantic representations. As many scene elements naturally appear according to multimodal color distributions, we train our model to predict per-pixel color histograms. This intermediate output can be used to automatically generate a color image, or further manipulated prior to image formation. On both fully and partially automatic colorization tasks, we outperform existing methods. We also explore colorization as a vehicle for self-supervised visual representation learning.",
        "year": 2016,
        "authors": "Gustav Larsson and Michael Maire and Gregory Shakhnarovich"
      }
    ],
    "7t4jbPQAAAAJ": [
      {
        "title": "Reinforcement learning in robotics: A survey",
        "abstract": "Reinforcement learning offers to robotics a framework and set of tools for the design of sophisticated and hard-to-engineer behaviors. Conversely, the challenges of robotic problems provide both inspiration, impact, and validation for developments in reinforcement learning. The relationship between disciplines has sufficient promise to be likened to that between physics and mathematics. In this article, we attempt to strengthen the links between the two research communities by providing a survey of work in reinforcement learning for behavior generation in robots. We highlight both key challenges in robot reinforcement learning as well as notable successes. We discuss how contributions tamed the complexity of the domain and study the role of algorithms, representations, and prior knowledge in achieving these successes. As a result, a particular focus of our paper lies on the choice between model-based and …",
        "year": 2013,
        "authors": "Jens Kober and J Andrew Bagnell and Jan Peters"
      },
      {
        "title": "A reduction of imitation learning and structured prediction to no-regret online learning",
        "abstract": "Sequential prediction problems such as imitation learning, where future observations depend on previous predictions (actions), violate the common iid assumptions made in statistical learning. This leads to poor performance in theory and often in practice. Some recent approaches provide stronger guarantees in this setting, but remain somewhat unsatisfactory as they train either non-stationary or stochastic policies and require a large number of iterations. In this paper, we propose a new iterative algorithm, which trains a stationary deterministic policy, that can be seen as a no regret algorithm in an online learning setting. We show that any such no regret algorithm, combined with additional reduction assumptions, must find a policy with good performance under the distribution of observations it induces in such sequential settings. We demonstrate that this new approach outperforms previous approaches on two challenging imitation learning problems and a benchmark sequence labeling problem.",
        "year": 2011,
        "authors": "Stéphane Ross and Geoffrey Gordon and Drew Bagnell"
      },
      {
        "title": "Maximum entropy inverse reinforcement learning.",
        "abstract": "Recent research has shown the benefit of framing problems of imitation learning as solutions to Markov Decision Problems. This approach reduces learning to the problem of recovering a utility function that makes the behavior induced by a near-optimal policy closely mimic demonstrated behavior. In this work, we develop a probabilistic approach based on the principle of maximum entropy. Our approach provides a well-defined, globally normalized distribution over decision sequences, while providing the same performance guarantees as existing methods.We develop our technique in the context of modeling realworld navigation and driving behaviors where collected data is inherently noisy and imperfect. Our probabilistic approach enables modeling of route preferences as well as a powerful new approach to inferring destinations and routes based on partial trajectories.",
        "year": 2008,
        "authors": "Brian D Ziebart and Andrew L Maas and J Andrew Bagnell and Anind K Dey"
      }
    ],
    "grQ_GBgAAAAJ": [
      {
        "title": "Practical bayesian optimization of machine learning algorithms",
        "abstract": "The use of machine learning algorithms frequently involves careful tuning of learning parameters and model hyperparameters. Unfortunately, this tuning is often a “black art” requiring expert experience, rules of thumb, or sometimes brute-force search. There is therefore great appeal for automatic approaches that can optimize the performance of any given learning algorithm to the problem at hand. In this work, we consider this problem through the framework of Bayesian optimization, in which a learning algorithm’s generalization performance is modeled as a sample from a Gaussian process (GP). We show that certain choices for the nature of the GP, such as the type of kernel and the treatment of its hyperparameters, can play a crucial role in obtaining a good optimizer that can achieve expert-level performance. We describe new algorithms that take into account the variable cost (duration) of learning algorithm experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization for many algorithms including Latent Dirichlet Allocation, Structured SVMs and convolutional neural networks.",
        "year": 2012,
        "authors": "Jasper Snoek and Hugo Larochelle and Ryan P Adams"
      },
      {
        "title": "Taking the human out of the loop: A review of Bayesian optimization",
        "abstract": "Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involve many tunable configuration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some …",
        "year": 2015,
        "authors": "Bobak Shahriari and Kevin Swersky and Ziyu Wang and Ryan P Adams and Nando De Freitas"
      },
      {
        "title": "Convolutional networks on graphs for learning molecular fingerprints",
        "abstract": "We introduce a convolutional neural network that operates directly on graphs. These networks allow end-to-end learning of prediction pipelines whose inputs are graphs of arbitrary size and shape. The architecture we present generalizes standard molecular feature extraction methods based on circular fingerprints. We show that these data-driven features are more interpretable, and have better predictive performance on a variety of tasks.",
        "year": 2015,
        "authors": "David K Duvenaud and Dougal Maclaurin and Jorge Iparraguirre and Rafael Bombarell and Timothy Hirzel and Alán Aspuru-Guzik and Ryan P Adams"
      }
    ],
    "WX0pI3wAAAAJ": [
      {
        "title": "Gauge field theories on a lattice",
        "abstract": "We begin a rigorous, nonperturbative investigation of quantum field theories with local internal symmetries. We discuss the lattice approximation of Yang-Mills fields and of fermion fields in the Euclidean setup and we verify physical positivity for the Schwinger functions of these approximations. This implies the existence of a positive self-adjoint transfer matrix. We then prove existence and analyticity of the infinite volume limit of strongly coupled Yang-Mills theories on the lattice and we verify Wilson's confinement bound. Finally we present a rigorous treatment of the Higgs mechanism in lattice gauge theories.",
        "year": 1978,
        "authors": "Konrad Osterwalder and Erhard Seiler"
      },
      {
        "title": "Gauge theories as a problem of constructive quantum field theory and statistical mechanics",
        "abstract": "GAUGE THEORIES AS A PROBLEM OF CONSTRUCTIVE QUANTUM FIELD THEORY \nAND STATISTICAL MECHANICS CNRS Inist Pascal-Francis CNRS Pascal and Francis \nBibliographic Databases Simple search Advanced search Search by classification Search \nby vocabulary My Account Home > Search results Help Export Export Selection : Selected \nitems (1) Format : Permanent link CopyPermanent link Copy http://pascal-francis.inist.fr/vibad/index.php?action=getRecordDetail&idt=PASCAL82X0257841 \nGAUGE THEORIES AS A PROBLEM OF CONSTRUCTIVE QUANTUM FIELD THEORY \nAND STATISTICAL MECHANICS Author SEILER E MAX-PLANCK INST. PHYS./MUENCHEN \n8000/DEU Source LECT. NOTES PHYS.; ISSN 0075-8450; DEU; DA. 1982; NO 159; PP. 1-192; \nBIBL. 79 REF. Document type Article Language English Keyword (fr) THEORIE \nQUANTIQUE CHAMP THEORIE JAUGE THEORIE …",
        "year": 1982,
        "authors": "Erhard Seiler"
      },
      {
        "title": "Complex Langevin method: When can it be trusted?",
        "abstract": "We analyze to what extent the complex Langevin method, which is in principle capable of solving the so-called sign problems, can be considered as reliable. We give a formal derivation of the correctness and then point out various mathematical loopholes. The detailed study of some simple examples leads to practical suggestions about the application of the method.",
        "year": 2010,
        "authors": "Gert Aarts and Erhard Seiler and Ion-Olimpiu Stamatescu"
      }
    ],
    "mAo_lUwAAAAJ": [
      {
        "title": "Extractive Summarization as Text Matching",
        "abstract": "This paper creates a paradigm shift with regard to the way we build neural extractive summarization systems. Instead of following the commonly used framework of extracting sentences individually and modeling the relationship between sentences, we formulate the extractive summarization task as a semantic text matching problem, in which a source document and candidate summaries will be (extracted from the original text) matched in a semantic space. Notably, this paradigm shift to semantic matching framework is well-grounded in our comprehensive analysis of the inherent gap between sentence-level and summary-level extractors based on the property of the dataset. Besides, even instantiating the framework with a simple form of a matching model, we have driven the state-of-the-art extractive result on CNN/DailyMail to a new level (44.41 in ROUGE-1). Experiments on the other five datasets also show the effectiveness of the matching framework. We believe the power of this matching-based summarization framework has not been fully exploited. To encourage more instantiations in the future, we have released our codes, processed dataset, as well as generated summaries in https://github.com/maszhongming/MatchSum.",
        "year": 2020,
        "authors": "Ming Zhong and Pengfei Liu and Yiran Chen and Danqing Wang and Xipeng Qiu and Xuanjing Huang"
      },
      {
        "title": "Heterogeneous Graph Neural Networks for Extractive Document Summarization",
        "abstract": "As a crucial step in extractive document summarization, learning cross-sentence relations has been explored by a plethora of approaches. An intuitive way is to put them in the graph-based neural network, which has a more complex structure for capturing inter-sentence relationships. In this paper, we present a heterogeneous graph-based neural network for extractive summarization (HeterSumGraph), which contains semantic nodes of different granularity levels apart from sentences. These additional nodes act as the intermediary between sentences and enrich the cross-sentence relations. Besides, our graph structure is flexible in natural extension from a single-document setting to multi-document via introducing document nodes. To our knowledge, we are the first one to introduce different types of nodes into graph-based neural networks for extractive document summarization and perform a comprehensive qualitative analysis to investigate their benefits. The code will be released on Github",
        "year": 2020,
        "authors": "Danqing Wang and Pengfei Liu and Yining Zheng and Xipeng Qiu and Xuanjing Huang"
      },
      {
        "title": "Searching for Effective Neural Extractive Summarization: What Works and What's Next",
        "abstract": "The recent years have seen remarkable success in the use of deep neural networks on text summarization. However, there is no clear understanding of \\textit{why} they perform so well, or \\textit{how} they might be improved. In this paper, we seek to better understand how neural extractive summarization systems could benefit from different types of model architectures, transferable knowledge and learning schemas. Additionally, we find an effective way to improve current frameworks and achieve the state-of-the-art result on CNN/DailyMail by a large margin based on our observations and analyses. Hopefully, our work could provide more clues for future research on extractive summarization.",
        "year": 2019,
        "authors": "Ming Zhong and Pengfei Liu and Danqing Wang and Xipeng Qiu and Xuanjing Huang"
      }
    ],
    "WLN3QrAAAAAJ": [
      {
        "title": "Deep learning",
        "abstract": "Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.",
        "year": 2015,
        "authors": "Yann LeCun and Yoshua Bengio and Geoffrey Hinton"
      },
      {
        "title": "Gradient-based learning applied to document recognition",
        "abstract": "Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows …",
        "year": 2002,
        "authors": "Yann LeCun and Léon Bottou and Yoshua Bengio and Patrick Haffner"
      },
      {
        "title": "Backpropagation applied to handwritten zip code recognition",
        "abstract": "The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.",
        "year": 1989,
        "authors": "Yann LeCun and Bernhard Boser and John S Denker and Donnie Henderson and Richard E Howard and Wayne Hubbard and Lawrence D Jackel"
      }
    ],
    "z76PBfYAAAAJ": [
      {
        "title": "The cityscapes dataset for semantic urban scene understanding",
        "abstract": "Visual understanding of complex urban street scenes is an enabling factor for a wide range of applications. Object detection has benefited enormously from large-scale datasets, especially in the context of deep learning. For semantic urban scene understanding, however, no current dataset adequately captures the complexity of real-world urban scenes. To address this, we introduce Cityscapes, a benchmark suite and large-scale dataset to train and test approaches for pixel-level and instance-level semantic labeling. Cityscapes is comprised of a large, diverse set of stereo video sequences recorded in streets from 50 different cities. 5000 of these images have high quality pixel-level annotations; 20000 additional images have coarse annotations to enable methods that leverage large volumes of weakly-labeled data. Crucially, our effort exceeds previous attempts in terms of dataset size, annotation richness, scene variability, and complexity. Our accompanying empirical study provides an in-depth analysis of the dataset characteristics, as well as a performance evaluation of several state-of-the-art approaches based on our benchmark.",
        "year": 2016,
        "authors": "Marius Cordts and Mohamed Omran and Sebastian Ramos and Timo Rehfeld and Markus Enzweiler and Rodrigo Benenson and Uwe Franke and Stefan Roth and Bernt Schiele"
      },
      {
        "title": "Generative adversarial text to image synthesis",
        "abstract": "Automatic synthesis of realistic images from text would be interesting and useful, but current AI systems are still far from this goal. However, in recent years generic and powerful recurrent neural network architectures have been developed to learn discriminative text feature representations. Meanwhile, deep convolutional generative adversarial networks (GANs) have begun to generate highly compelling images of specific categories such as faces, album covers, room interiors and flowers. In this work, we develop a novel deep architecture and GAN formulation to effectively bridge these advances in text and image modeling, translating visual concepts from characters to pixels. We demonstrate the capability of our model to generate plausible images of birds and flowers from detailed text descriptions.",
        "year": 2016,
        "authors": "Scott Reed and Zeynep Akata and Xinchen Yan and Lajanugen Logeswaran and Bernt Schiele and Honglak Lee"
      },
      {
        "title": "Pedestrian detection: An evaluation of the state of the art",
        "abstract": "Pedestrian detection is a key problem in computer vision, with several applications that have the potential to positively impact quality of life. In recent years, the number of approaches to detecting pedestrians in monocular images has grown steadily. However, multiple data sets and widely varying evaluation protocols are used, making direct comparisons difficult. To address these shortcomings, we perform an extensive evaluation of the state of the art in a unified framework. We make three primary contributions: 1) We put together a large, well-annotated, and realistic monocular pedestrian detection data set and study the statistics of the size, position, and occlusion patterns of pedestrians in urban scenes, 2) we propose a refined per-frame evaluation methodology that allows us to carry out probing and informative comparisons, including measuring performance in relation to scale and occlusion, and 3) we evaluate …",
        "year": 2012,
        "authors": "Piotr Dollar and Christian Wojek and Bernt Schiele and Pietro Perona"
      }
    ],
    "QZCU3NkAAAAJ": [
      {
        "title": "Pinpoint: Problem determination in large, dynamic internet services",
        "abstract": "Traditional problem determination techniques rely on static dependency models that are difficult to generate accurately in today's large, distributed, and dynamic application environments such as e-commerce systems. We present a dynamic analysis methodology that automates problem determination in these environments by 1) coarse-grained tagging of numerous real client requests as they travel through the system and 2) using data mining techniques to correlate the believed failures and successes of these requests to determine which components are most likely to be at fault. To validate our methodology, we have implemented Pinpoint, a framework for root cause analysis on the J2EE platform that requires no knowledge of the application components. Pinpoint consists of three parts: a communications layer that traces client requests, a failure detector that uses traffic-sniffing and middleware instrumentation …",
        "year": 2002,
        "authors": "Mike Y Chen and Emre Kiciman and Eugene Fratkin and Armando Fox and Eric Brewer"
      },
      {
        "title": "Social data: Biases, methodological pitfalls, and ethical boundaries",
        "abstract": "Social data in digital form—including user-generated content, expressed or implicit relations between people, and behavioral traces—are at the core of popular applications and platforms, driving the research agenda of many researchers. The promises of social data are many, including understanding “what the world thinks” about a social issue, brand, celebrity, or other entity, as well as enabling better decision-making in a variety of fields including public policy, healthcare, and economics. Many academics and practitioners have warned against the naïve usage of social data. There are biases and inaccuracies occurring at the source of the data, but also introduced during processing. There are methodological limitations and pitfalls, as well as ethical boundaries and unexpected consequences that are often overlooked. This paper recognizes the rigor with which these issues are addressed by different researchers varies across a wide range. We identify a variety of menaces in the practices around social data use, and organize them in a framework that helps to identify them.“For your own sanity, you have to remember that not all problems can be solved. Not all problems can be solved, but all problems can be illuminated.” –Ursula Franklin",
        "year": 2019,
        "authors": "Alexandra Olteanu and Carlos Castillo and Fernando Diaz and Emre Kıcıman"
      },
      {
        "title": "Discovering shifts to suicidal ideation from mental health content in social media",
        "abstract": "History of mental illness is a major factor behind suicide risk and ideation. However research efforts toward characterizing and forecasting this risk is limited due to the paucity of information regarding suicide ideation, exacerbated by the stigma of mental illness. This paper fills gaps in the literature by developing a statistical methodology to infer which individuals could undergo transitions from mental health discourse to suicidal ideation. We utilize semi-anonymous support communities on Reddit as unobtrusive data sources to infer the likelihood of these shifts. We develop language and interactional measures for this purpose, as well as a propensity score matching based statistical approach. Our approach allows us to derive distinct markers of shifts to suicidal ideation. These markers can be modeled in a prediction framework to identify individuals likely to engage in suicidal ideation in the future. We discuss …",
        "year": 2016,
        "authors": "Munmun De Choudhury and Emre Kiciman and Mark Dredze and Glen Coppersmith and Mrinal Kumar"
      }
    ],
    "y-8unsgAAAAJ": [
      {
        "title": "Quenched invariance principle for simple random walk on percolation clusters",
        "abstract": "We consider the simple random walk on the (unique) infinite cluster of super-critical bond percolation in ℤ d  with d≥2. We prove that, for almost every percolation configuration, the path distribution of the walk converges weakly to that of non-degenerate, isotropic Brownian motion. Our analysis is based on the consideration of a harmonic deformation of the infinite cluster on which the random walk becomes a square-integrable martingale. The size of the deformation, expressed by the so called corrector, is estimated by means of ergodicity arguments.",
        "year": 2007,
        "authors": "Noam Berger and Marek Biskup"
      },
      {
        "title": "Recent progress on the random conductance model",
        "abstract": " Recent progress on the understanding of the Random Conductance Model is reviewed and             commented. A particular emphasis is on the results on the scaling limit of the random             walk among random conductances for almost every realization of the environment,             observations on the behavior of the effective resistance as well as the scaling limit of             certain models of gradient fields with non-convex interactions. The text is an expanded             version of the lecture notes for a course delivered at the 2011 Cornell Summer School on             Probability. ",
        "year": 2011,
        "authors": "Marek Biskup"
      },
      {
        "title": "On the scaling of the chemical distance in long-range percolation models",
        "abstract": "We consider the (unoriented) long-range percolation on ℤd in dimensions d≥1, where distinct sites x,y∈ℤd get connected with probability pxy∈[0,1]. Assuming pxy=|x−y|−s+o(1) as |x−y|→∞, where s>0 and |⋅| is a norm distance on ℤd, and supposing that the resulting random graph contains an infinite connected component C∞, we let D(x,y) be the graph distance between x and y measured on C∞. Our main result is that, for s∈(d,2d), D(x,y)=(log|x−y|)Δ+o(1),  x,y∈C∞, |x−y|→∞, where Δ−1 is the binary logarithm of 2d/s and o(1) is a quantity tending to zero in probability as |x−y|→∞. Besides its interest for general percolation theory, this result sheds some light on a question that has recently surfaced in the context of “small-world” phenomena. As part of the proof we also establish tight bounds on the probability that the largest connected component in a finite box contains a positive fraction of all sites in the …",
        "year": 2004,
        "authors": "Marek Biskup"
      }
    ],
    "n7hxT4oAAAAJ": [
      {
        "title": "Fully autonomous real-world reinforcement learning with applications to mobile manipulation",
        "abstract": "We study how robots can autonomously learn skills that require a combination of navigation and grasping. Learning robotic skills in the real world remains challenging without large scale data collection and supervision. Our aim is to devise a robotic reinforcement learning system for learning navigation and manipulation together, in an autonomous way without human intervention, enabling continual learning under realistic assumptions. Specifically, our system, ReLMM, can learn continuously on a real-world platform without any environment instrumentation, without human intervention, and without access to privileged information, such as maps, objects positions, or a global view of the environment. Our method employs a modularized policy with components for manipulation and navigation, where uncertainty over the manipulation success drives exploration for the navigation controller, and the manipulation module provides rewards for navigation. We evaluate our method on a room cleanup task, where the robot must navigate to and pick up items of scattered on the floor. After a grasp curriculum training phase, ReLMM can learn navigation and grasping together fully automatically, in around 40 hours of real-world training.",
        "year": 2022,
        "authors": "Charles Sun and Jȩdrzej Orbik and Coline Manon Devin and Brian H Yang and Abhishek Gupta and Glen Berseth and Sergey Levine"
      },
      {
        "title": "Don’t start from scratch: Leveraging prior data to automate robotic reinforcement learning",
        "abstract": "Reinforcement learning (RL) algorithms hold the promise of enabling autonomous skill acquisition for robotic systems. However, in practice, real-world robotic RL typically requires time consuming data collection and frequent human intervention to reset the environment. Moreover, robotic policies learned with RL often fail when deployed beyond the carefully controlled setting in which they were learned. In this work, we study how these challenges of real-world robotic learning can all be tackled by effective utilization of diverse offline datasets collected from previously seen tasks. When faced with a new task, our system adapts previously learned skills to quickly learn to both perform the new task and return the environment to an initial state, effectively performing its own environment reset. Our empirical results demonstrate that incorporating prior data into robotic reinforcement learning enables autonomous learning, substantially improves sample-efficiency of learning, and enables better generalization.",
        "year": 2023,
        "authors": "Homer Rich Walke and Jonathan Heewon Yang and Albert Yu and Aviral Kumar and Jędrzej Orbik and Avi Singh and Sergey Levine"
      },
      {
        "title": "Inverse reinforcement learning for dexterous hand manipulation",
        "abstract": "The success of deep reinforcement learning approaches to learn dexterous manipulation skills strongly hinges on the rewards assigned to actions during task execution. The usual approach is to handcraft the reward function but due to the high complexity of dexterous manipulations the reward definition demands large engineering effort for each particular task. To avoid this burden, we use an inverse reinforcement learning (IRL) approach to automatically learn the reward function using samples obtained from demonstrations of desired behaviours. We have identified that the learned rewards using existing IRL approaches are strongly biased towards demonstrated actions due to the scarcity of samples in the vast state-action space of dexterous manipulation applications. This significantly hinders performance due to unreliable reward estimations in regions unexplored during demonstration. We use statistical tools …",
        "year": 2021,
        "authors": "Jedrzej Orbik and Alejandro Agostini and Dongheui Lee"
      }
    ],
    "-S_9ZRcAAAAJ": [
      {
        "title": "Volumetric and multi-view cnns for object classification on 3d data",
        "abstract": "3D shape models are becoming widely available and easier to capture, making available 3D information crucial for progress in object classification. Current state-of-the-art methods rely on CNNs to address this problem. Recently, we witness two types of CNNs being developed: CNNs based upon volumetric representations versus CNNs based upon multi-view representations. Empirical results from these two types of CNNs exhibit a large gap, indicating that existing volumetric CNN architectures and approaches are unable to fully exploit the power of 3D representations. In this paper, we aim to improve both volumetric CNNs and multi-view CNNs according to extensive analysis of existing approaches. To this end, we introduce two distinct network architectures of volumetric CNNs. In addition, we examine multi-view CNNs, where we introduce multi-resolution filtering in 3D. Overall, we are able to outperform current state-of-the-art methods for both volumetric CNNs and multi-view CNNs. We provide extensive experiments designed to evaluate underlying design choices, thus providing a better understanding of the space of methods available for object classification on 3D data.",
        "year": 2016,
        "authors": "Charles R Qi and Hao Su and Matthias Nießner and Angela Dai and Mengyuan Yan and Leonidas J Guibas"
      },
      {
        "title": "Do as i can, not as i say: Grounding language in robotic affordances",
        "abstract": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model's \"hands and eyes,\" while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally-extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project's website and the video can be found at https …",
        "year": 2022,
        "authors": "Michael Ahn and Anthony Brohan and Noah Brown and Yevgen Chebotar and Omar Cortes and Byron David and Chelsea Finn and Chuyuan Fu and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Daniel Ho and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Eric Jang and Rosario Jauregui Ruano and Kyle Jeffrey and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Kuang-Huei Lee and Sergey Levine and Yao Lu and Linda Luu and Carolina Parada and Peter Pastor and Jornell Quiambao and Kanishka Rao and Jarek Rettinghouse and Diego Reyes and Pierre Sermanet and Nicolas Sievers and Clayton Tan and Alexander Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Mengyuan Yan and Andy Zeng"
      },
      {
        "title": "A scalable active framework for region annotation in 3d shape collections",
        "abstract": "Large repositories of 3D shapes provide valuable input for data-driven analysis and modeling tools. They are especially powerful once annotated with semantic information such as salient regions and functional parts. We propose a novel active learning method capable of enriching massive geometric datasets with accurate semantic region annotations. Given a shape collection and a user-specified region label our goal is to correctly demarcate the corresponding regions with minimal manual work. Our active framework achieves this goal by cycling between manually annotating the regions, automatically propagating these annotations across the rest of the shapes, manually verifying both human and automatic annotations, and learning from the verification results to improve the automatic propagation algorithm. We use a unified utility function that explicitly models the time cost of human input across all steps of our …",
        "year": 2016,
        "authors": "Li Yi and Vladimir G Kim and Duygu Ceylan and I-Chao Shen and Mengyan Yan and Hao Su and Cewu Lu and Qixing Huang and Alla Sheffer and Leonidas Guibas"
      }
    ],
    "e1P1rNkAAAAJ": [
      {
        "title": "Efficient off-policy meta-reinforcement learning via probabilistic context variables",
        "abstract": "Deep reinforcement learning algorithms require large amounts of experience to learn an individual task. While meta-reinforcement learning (meta-RL) algorithms can enable agents to learn new skills from small amounts of experience, several major challenges preclude their practicality. Current methods rely heavily on on-policy experience, limiting their sample efficiency. They also lack mechanisms to reason about task uncertainty when adapting to new tasks, limiting their effectiveness on sparse reward problems. In this paper, we address these challenges by developing an off-policy meta-RL algorithm that disentangles task inference and control. In our approach, we perform online probabilistic filtering of latent task variables to infer how to solve a new task from small amounts of experience. This probabilistic interpretation enables posterior sampling for structured and efficient exploration. We demonstrate how to integrate these task variables with off-policy RL algorithms to achieve both meta-training and adaptation efficiency. Our method outperforms prior algorithms in sample efficiency by 20-100X as well as in asymptotic performance on several meta-RL benchmarks.",
        "year": 2019,
        "authors": "Kate Rakelly and Aurick Zhou and Chelsea Finn and Sergey Levine and Deirdre Quillen"
      },
      {
        "title": "Few-shot segmentation propagation with guided networks",
        "abstract": "Learning-based methods for visual segmentation have made progress on particular types of segmentation tasks, but are limited by the necessary supervision, the narrow definitions of fixed tasks, and the lack of control during inference for correcting errors. To remedy the rigidity and annotation burden of standard approaches, we address the problem of few-shot segmentation: given few image and few pixel supervision, segment any images accordingly. We propose guided networks, which extract a latent task representation from any amount of supervision, and optimize our architecture end-to-end for fast, accurate few-shot segmentation. Our method can switch tasks without further optimization and quickly update when given more guidance. We report the first results for segmentation from one pixel per concept and show real-time interactive video segmentation. Our unified approach propagates pixel annotations across space for interactive segmentation, across time for video segmentation, and across scenes for semantic segmentation. Our guided segmentor is state-of-the-art in accuracy for the amount of annotation and time. See http://github.com/shelhamer/revolver for code, models, and more details.",
        "year": 2018,
        "authors": "Kate Rakelly and Evan Shelhamer and Trevor Darrell and Alexei A Efros and Sergey Levine"
      },
      {
        "title": "Clockwork convnets for video semantic segmentation",
        "abstract": "Recent years have seen tremendous progress in still-image segmentation; however the naïve application of these state-of-the-art algorithms to every video frame requires considerable computation and ignores the temporal continuity inherent in video. We propose a video recognition framework that relies on two key observations: (1) while pixels may change rapidly from frame to frame, the semantic content of a scene evolves more slowly, and (2) execution can be viewed as an aspect of architecture, yielding purpose-fit computation schedules for networks. We define a novel family of “clockwork” convnets driven by fixed or adaptive clock signals that schedule the processing of different layers at different update rates according to their semantic stability. We design a pipeline schedule to reduce latency for real-time recognition and a fixed-rate schedule to reduce overall computation. Finally, we extend …",
        "year": 2016,
        "authors": "Evan Shelhamer and Kate Rakelly and Judy Hoffman and Trevor Darrell"
      }
    ],
    "izZZAegAAAAJ": [
      {
        "title": "Nonparametric belief propagation for self-calibration in sensor networks",
        "abstract": "Automatic self-calibration of ad-hoc sensor networks is a critical need for their use in military or civilian applications. In general, self-calibration involves the combination of absolute location information (e.g. GPS) with relative calibration information (e.g. time delay or received signal strength between sensors) over regions of the network. Furthermore, it is generally desirable to distribute the computational burden across the network and minimize the amount of inter-sensor communication. We demonstrate that the information used for sensor calibration is fundamentally local with regard to the network topology and use this observation to reformulate the problem within a graphical model framework. We then demonstrate the utility of nonparametric belief propagation (NBP), a recent generalization of particle filtering, for both estimating sensor locations and representing location uncertainties. NBP has the advantage that …",
        "year": 2004,
        "authors": "Alexander T Ihler and John W Fisher III and Randolph L Moses and Alan S Willsky"
      },
      {
        "title": "Loopy belief propagation: convergence and effects of message errors.",
        "abstract": "Belief propagation (BP) is an increasingly popular method of performing approximate inference on arbitrary graphical models. At times, even further approximations are required, whether due to quantization of the messages or model parameters, from other simplified message or model representations, or from stochastic approximation methods. The introduction of such errors into the BP message computations has the potential to affect the solution obtained adversely. We analyze the effect resulting from message approximation under two particular measures of error, and show bounds on the accumulation of errors in the system. This analysis leads to convergence conditions for traditional BP message passing, and both strict bounds and estimates of the resulting error in systems of approximate BP message passing.",
        "year": 2005,
        "authors": "Alexander T Ihler and John W Fisher III and Alan S Willsky and David Maxwell Chickering"
      },
      {
        "title": "A nonparametric statistical method for image segmentation using information theory and curve evolution",
        "abstract": "In this paper, we present a new information-theoretic approach to image segmentation. We cast the segmentation problem as the maximization of the mutual information between the region labels and the image pixel intensities, subject to a constraint on the total length of the region boundaries. We assume that the probability densities associated with the image pixel intensities within each region are completely unknown a priori, and we formulate the problem based on nonparametric density estimates. Due to the nonparametric structure, our method does not require the image regions to have a particular type of probability distribution and does not require the extraction and use of a particular statistic. We solve the information-theoretic optimization problem by deriving the associated gradient flows and applying curve evolution techniques. We use level-set methods to implement the resulting evolution. The …",
        "year": 2005,
        "authors": "Junmo Kim and John W Fisher and Anthony Yezzi and Müjdat Çetin and Alan S Willsky"
      }
    ],
    "aOklxsQAAAAJ": [
      {
        "title": "Rich feature hierarchies for accurate object detection and semantic segmentation",
        "abstract": "Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012---achieving a mAP of 53.3%. Our approach combines two key insights:(1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www. cs. berkeley. edu/~ rbg/rcnn.",
        "year": 2014,
        "authors": "Ross Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik"
      },
      {
        "title": "Normalized cuts and image segmentation",
        "abstract": "We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We applied this approach to segmenting static images, as well as motion sequences, and found the results to be very encouraging.",
        "year": 2000,
        "authors": "Jianbo Shi and Jitendra Malik"
      },
      {
        "title": "Scale-space and edge detection using anisotropic diffusion",
        "abstract": "A new definition of scale-space is suggested, and a class of algorithms used to realize a diffusion process is introduced. The diffusion coefficient is chosen to vary spatially in such a way as to encourage intraregion smoothing rather than interregion smoothing. It is shown that the 'no new maxima should be generated at coarse scales' property of conventional scale space is preserved. As the region boundaries in the approach remain sharp, a high-quality edge detector which successfully exploits global information is obtained. Experimental results are shown on a number of images. Parallel hardware implementations are made feasible because the algorithm involves elementary, local operations replicated over the image.<>",
        "year": 2002,
        "authors": "Pietro Perona and Jitendra Malik"
      }
    ],
    "xVN3UxYAAAAJ": [
      {
        "title": "Sparse R-CNN: End-to-End Object Detection with Learnable Proposals",
        "abstract": "We present Sparse R-CNN, a purely sparse method for object detection in images. Existing works on object detection heavily rely on dense object candidates, such as k anchor boxes pre-defined on all grids of image feature map of size HxW. In our method, however, a fixed sparse set of learned object proposals, total length of N, are provided to object recognition head to perform classification and location. By eliminating HWk (up to hundreds of thousands) hand-designed object candidates to N (eg 100) learnable proposals, Sparse R-CNN completely avoids all efforts related to object candidates design and many-to-one label assignment. More importantly, final predictions are directly output without non-maximum suppression post-procedure. Sparse R-CNN demonstrates accuracy, run-time and training convergence performance on par with the well-established detector baselines on the challenging COCO dataset, eg, achieving 45.0 AP in standard 3x training schedule and running at 22 fps using ResNet-50 FPN model. We hope our work could inspire re-thinking the convention of dense prior in object detectors. The code is available at: https://github. com/PeizeSun/SparseR-CNN.",
        "year": 2021,
        "authors": "Peize Sun and Rufeng Zhang and Yi Jiang and Tao Kong and Chenfeng Xu and Wei Zhan and Masayoshi Tomizuka and Lei Li and Zehuan Yuan and Changhu Wang and Ping Luo"
      },
      {
        "title": "Open X-Embodiment: Robotic Learning Datasets and RT-X Models : Open X-Embodiment Collaboration0",
        "abstract": "Large, high-capacity models trained on diverse datasets have shown remarkable successes on efficiently tackling downstream applications. In domains from NLP to Computer Vision, this has led to a consolidation of pretrained models, with general pretrained backbones serving as a starting point for many applications. Can such a consolidation happen in robotics? Conventionally, robotic learning methods train a separate model for every application, every robot, and even every environment. Can we instead train \"generalist\" X-robot policy that can be adapted efficiently to new robots, tasks, and environments? In this paper, we provide datasets in standardized data formats and models to make it possible to explore this possibility in the context of robotic manipulation, alongside experimental results that provide an example of effective X-robot policies. We assemble a dataset from 22 different robots collected through …",
        "year": 2024,
        "authors": "Abby O’Neill and Abdul Rehman and Abhiram Maddukuri and Abhishek Gupta and Abhishek Padalkar and Abraham Lee and Acorn Pooley and Agrim Gupta and Ajay Mandlekar and Ajinkya Jain and Albert Tung and Alex Bewley and Alex Herzog and Alex Irpan and Alexander Khazatsky and Anant Rai and Anchit Gupta and Andrew Wang and Anikait Singh and Animesh Garg and Aniruddha Kembhavi and Annie Xie and Anthony Brohan and Antonin Raffin and Archit Sharma and Arefeh Yavary and Arhan Jain and Ashwin Balakrishna and Ayzaan Wahid and Ben Burgess-Limerick and Beomjoon Kim and Bernhard Schölkopf and Blake Wulfe and Brian Ichter and Cewu Lu and Charles Xu and Charlotte Le and Chelsea Finn and Chen Wang and Chenfeng Xu and Cheng Chi and Chenguang Huang and Christine Chan and Christopher Agia and Chuer Pan and Chuyuan Fu and Coline Devin and Danfei Xu and Daniel Morton and Danny Driess and Daphne Chen and Deepak Pathak and Dhruv Shah and Dieter Büchler and Dinesh Jayaraman and Dmitry Kalashnikov and Dorsa Sadigh and Edward Johns and Ethan Foster and Fangchen Liu and Federico Ceola and Fei Xia and Feiyu Zhao and Freek Stulp and Gaoyue Zhou and Gaurav S Sukhatme and Gautam Salhotra and Ge Yan and Gilbert Feng and Giulio Schiavi and Glen Berseth and Gregory Kahn and Guanzhi Wang and Hao Su and Hao-Shu Fang and Haochen Shi and Henghui Bao and Heni Ben Amor and Henrik I Christensen and Hiroki Furuta and Homer Walke and Hongjie Fang and Huy Ha and Igor Mordatch and Ilija Radosavovic and Isabel Leal and Jacky Liang and Jad Abou-Chakra and Jaehyung Kim and Jaimyn Drake and Jan Peters and Jan Schneider and Jasmine Hsu and Jeannette Bohg and Jeffrey Bingham and Jeffrey Wu and Jensen Gao and Jiaheng Hu and Jiajun Wu and Jialin Wu and Jiankai Sun and Jianlan Luo and Jiayuan Gu and Jie Tan and Jihoon Oh and Jimmy Wu and Jingpei Lu and Jingyun Yang and Jitendra Malik and João Silvério and Joey Hejna and Jonathan Booher and Jonathan Tompson and Jonathan Yang and Jordi Salvador and Joseph J Lim and Junhyek Han and Kaiyuan Wang and Kanishka Rao and Karl Pertsch and Karol Hausman and Keegan Go and Keerthana Gopalakrishnan and Ken Goldberg and Kendra Byrne and Kenneth Oslund and Kento Kawaharazuka and Kevin Black and Kevin Lin and Kevin Zhang and Kiana Ehsani and Kiran Lekkala and Kirsty Ellis and Krishan Rana and Krishnan Srinivasan and Kuan Fang and Kunal Pratap Singh and Kuo-Hao Zeng and Kyle Hatch and Kyle Hsu and Laurent Itti and Lawrence Yunliang Chen and Lerrel Pinto and Li Fei-Fei and Liam Tan and Linxi Jim Fan and Lionel Ott and Lisa Lee and Luca Weihs and Magnum Chen"
      },
      {
        "title": "INTERACTION Dataset: An INTERnational, Adversarial and Cooperative moTION Dataset in Interactive Driving Scenarios with Semantic Maps",
        "abstract": "Behavior-related research areas such as motion prediction/planning, representation/imitation learning, behavior modeling/generation, and algorithm testing, require support from high-quality motion datasets containing interactive driving scenarios with different driving cultures. In this paper, we present an INTERnational, Adversarial and Cooperative moTION dataset (INTERACTION dataset) in interactive driving scenarios with semantic maps. Five features of the dataset are highlighted. 1) The interactive driving scenarios are diverse, including urban/highway/ramp merging and lane changes, roundabouts with yield/stop signs, signalized intersections, intersections with one/two/all-way stops, etc. 2) Motion data from different countries and different continents are collected so that driving preferences and styles in different cultures are naturally included. 3) The driving behavior is highly interactive and complex with adversarial and cooperative motions of various traffic participants. Highly complex behavior such as negotiations, aggressive/irrational decisions and traffic rule violations are densely contained in the dataset, while regular behavior can also be found from cautious car-following, stop, left/right/U-turn to rational lane-change and cycling and pedestrian crossing, etc. 4) The levels of criticality span wide, from regular safe operations to dangerous, near-collision maneuvers. Real collision, although relatively slight, is also included. 5) Maps with complete semantic information are provided with physical layers, reference lines, lanelet connections and traffic rules. The data is recorded from drones and traffic cameras. Statistics of the dataset in terms …",
        "year": 2019,
        "authors": "Wei Zhan and Liting Sun and Di Wang and Haojie Shi and Aubrey Clausse and Maximilian Naumann and Julius Kummerle and Hendrik Konigshof and Christoph Stiller and Arnaud de La Fortelle and Masayoshi Tomizuka"
      }
    ],
    "YYT8-7kAAAAJ": [
      {
        "title": "Motion planning with sequential convex optimization and convex collision checking",
        "abstract": "We present a new optimization-based approach for robotic motion planning among obstacles. Like CHOMP (Covariant Hamiltonian Optimization for Motion Planning), our algorithm can be used to find collision-free trajectories from naïve, straight-line initializations that might be in collision. At the core of our approach are (a) a sequential convex optimization procedure, which penalizes collisions with a hinge loss and increases the penalty coefficients in an outer loop as necessary, and (b) an efficient formulation of the no-collisions constraint that directly considers continuous-time safety Our algorithm is implemented in a software package called TrajOpt.We report results from a series of experiments comparing TrajOpt with CHOMP and randomized planners from OMPL, with regard to planning time and path quality. We consider motion planning for 7 DOF robot arms, 18 DOF full-body robots, statically stable walking …",
        "year": 2014,
        "authors": "John Schulman and Yan Duan and Jonathan Ho and Alex Lee and Ibrahim Awwal and Henry Bradlow and Jia Pan and Sachin Patil and Ken Goldberg and Pieter Abbeel"
      },
      {
        "title": "FCL: A general purpose library for collision and proximity queries",
        "abstract": "We present a new collision and proximity library that integrates several techniques for fast and accurate collision checking and proximity computation. Our library is based on hierarchical representations and designed to perform multiple proximity queries on different model representations. The set of queries includes discrete collision detection, continuous collision detection, separation distance computation and penetration depth estimation. The input models may correspond to triangulated rigid or deformable models and articulated models. Moreover, FCL can perform probabilistic collision checking between noisy point clouds that are captured using cameras or LIDAR sensors. The main benefit of FCL lies in the fact that it provides a unified interface that can be used by various applications. Furthermore, its flexible architecture makes it easier to implement new algorithms within this framework. The runtime …",
        "year": 2012,
        "authors": "Jia Pan and Sachin Chitta and Dinesh Manocha"
      },
      {
        "title": "Towards optimally decentralized multi-robot collision avoidance via deep reinforcement learning",
        "abstract": "Developing a safe and efficient collision avoidance policy for multiple robots is challenging in the decentralized scenarios where each robot generates its paths without observing other robots' states and intents. While other distributed multi-robot collision avoidance systems exist, they often require extracting agent-level features to plan a local collision-free action, which can be computationally prohibitive and not robust. More importantly, in practice the performance of these methods are much lower than their centralized counterparts. We present a decentralized sensor-level collision avoidance policy for multi-robot systems, which directly maps raw sensor measurements to an agent's steering commands in terms of movement velocity. As a first step toward reducing the performance gap between decentralized and centralized methods, we present a multi-scenario multi-stage training framework to learn an optimal …",
        "year": 2018,
        "authors": "Pinxin Long and Tingxiang Fan and Xinyi Liao and Wenxi Liu and Hao Zhang and Jia Pan"
      }
    ],
    "GBQ6w8IAAAAJ": [
      {
        "title": "Database-friendly random projections: Johnson-Lindenstrauss with binary coins",
        "abstract": "A classic result of Johnson and Lindenstrauss asserts that any set of n points in d-dimensional Euclidean space can be embedded into k-dimensional Euclidean space—where k is logarithmic in n and independent of d—so that all pairwise distances are maintained within an arbitrarily small factor. All known constructions of such embeddings involve projecting the n points onto a spherically random k-dimensional hyperplane through the origin. We give two constructions of such embeddings with the property that all elements of the projection matrix belong in {−1,0,+1}. Such constructions are particularly well suited for database environments, as the computation of the embedding reduces to evaluating a single aggregate over k random partitions of the attributes.",
        "year": 2003,
        "authors": "Dimitris Achlioptas"
      },
      {
        "title": "Database-friendly random projections",
        "abstract": "A classic result of Johnson and Lindenstrauss asserts that any set of n points in d-dimensional Euclidean space can be embedded into k-dimensional Euclidean space where k is logarithmic in n and independent of d so that all pairwise distances are maintained within an arbitrarily small factor. All known constructions of such embeddings involve projecting the n points onto a random k-dimensional hyperplane. We give a novel construction of the embedding, suitable for database applications, which amounts to computing a simple aggregate over k random attribute partitions.",
        "year": 2001,
        "authors": "Dimitris Achlioptas"
      },
      {
        "title": "Explosive percolation in random networks",
        "abstract": "Networks in which the formation of connections is governed by a random process often undergo a percolation transition, wherein around a critical point, the addition of a small number of connections causes a sizable fraction of the network to suddenly become linked together. Typically such transitions are continuous, so that the percentage of the network linked together tends to zero right above the transition point. Whether percolation transitions could be discontinuous has been an open question. Here, we show that incorporating a limited amount of choice in the classic Erdös-Rényi network formation model causes its percolation transition to become discontinuous.",
        "year": 2009,
        "authors": "Dimitris Achlioptas and Raissa M D'souza and Joel Spencer"
      }
    ],
    "wSstCv0AAAAJ": [
      {
        "title": "Theoretically principled trade-off between robustness and accuracy",
        "abstract": "We identify a trade-off between robustness and accuracy that serves as a guiding principle in the design of defenses against adversarial examples. Although this problem has been widely studied empirically, much remains unknown concerning the theory underlying this trade-off. In this work, we decompose the prediction error for adversarial examples (robust error) as the sum of the natural (classification) error and boundary error, and provide a differentiable upper bound using the theory of classification-calibrated loss, which is shown to be the tightest possible upper bound uniform over all probability distributions and measurable predictors. Inspired by our theoretical analysis, we also design a new defense method, TRADES, to trade adversarial robustness off against accuracy. Our proposed algorithm performs well experimentally in real-world datasets. The methodology is the foundation of our entry to the NeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of 2,000 submissions, surpassing the runner-up approach by 11.41% in terms of mean L_2 perturbation distance.",
        "year": 2019,
        "authors": "Hongyang Zhang and Yaodong Yu and Jiantao Jiao and Eric Xing and Laurent El Ghaoui and Michael Jordan"
      },
      {
        "title": "A closer look at accuracy vs. robustness",
        "abstract": "Current methods for training robust networks lead to a drop in test accuracy, which has led prior works to posit that a robustness-accuracy tradeoff may be inevitable in deep learning. We take a closer look at this phenomenon and first show that real image datasets are actually separated. With this property in mind, we then prove that robustness and accuracy should both be achievable for benchmark datasets through locally Lipschitz functions, and hence, there should be no inherent tradeoff between robustness and accuracy. Through extensive experiments with robustness methods, we argue that the gap between theory and practice arises from two limitations of current methods: either they fail to impose local Lipschitzness or they are insufficiently generalized. We explore combining dropout with robust training methods and obtain better generalization. We conclude that achieving robustness and accuracy in practice may require using methods that impose local Lipschitzness and augmenting them with deep learning generalization techniques.",
        "year": 2020,
        "authors": "Yao-Yuan Yang and Cyrus Rashtchian and Hongyang Zhang and Ruslan Salakhutdinov and Kamalika Chaudhuri"
      },
      {
        "title": "On the applications of robust PCA in image and video processing",
        "abstract": "Robust principal component analysis (RPCA) via decomposition into low-rank plus sparse matrices offers a powerful framework for a large variety of applications such as image processing, video processing, and 3-D computer vision. Indeed, most of the time these applications require to detect sparse outliers from the observed imagery data that can be approximated by a low-rank matrix. Moreover, most of the time experiments show that RPCA with additional spatial and/or temporal constraints often outperforms the state-of-the-art algorithms in these applications. Thus, the aim of this paper is to survey the applications of RPCA in computer vision. In the first part of this paper, we review representative image processing applications as follows: 1) low-level imaging such as image recovery and denoising, image composition, image colorization, image alignment and rectification, multifocus image, and face recognition; 2 …",
        "year": 2018,
        "authors": "Thierry Bouwmans and Sajid Javed and Hongyang Zhang and Zhouchen Lin and Ricardo Otazo"
      }
    ],
    "eWRBqsYAAAAJ": [
      {
        "title": "Nonparametric estimation of heterogeneous treatment effects: From theory to learning algorithms",
        "abstract": "The need to evaluate treatment effectiveness is ubiquitous in most of empirical science, and interest in flexibly investigating effect heterogeneity is growing rapidly. To do so, a multitude of model-agnostic, nonparametric meta-learners have been proposed in recent years. Such learners decompose the treatment effect estimation problem into separate sub-problems, each solvable using standard supervised learning methods. Choosing between different meta-learners in a data-driven manner is difficult, as it requires access to counterfactual information. Therefore, with the ultimate goal of building better understanding of the conditions under which some learners can be expected to perform better than others a priori, we theoretically analyze four broad meta-learning strategies which rely on plug-in estimation and pseudo-outcome regression. We highlight how this theoretical reasoning can be used to guide principled algorithm design and translate our analyses into practice by considering a variety of neural network architectures as base-learners for the discussed meta-learning strategies. In a simulation study, we showcase the relative strengths of the learners under different data-generating processes.",
        "year": 2021,
        "authors": "Alicia Curth and Mihaela Van der Schaar"
      },
      {
        "title": "Causal machine learning for predicting treatment outcomes",
        "abstract": "Causal machine learning (ML) offers flexible, data-driven methods for predicting treatment outcomes including efficacy and toxicity, thereby supporting the assessment and safety of drugs. A key benefit of causal ML is that it allows for estimating individualized treatment effects, so that clinical decision-making can be personalized to individual patient profiles. Causal ML can be used in combination with both clinical trial data and real-world data, such as clinical registries and electronic health records, but caution is needed to avoid biased or incorrect predictions. In this Perspective, we discuss the benefits of causal ML (relative to traditional statistical or ML approaches) and outline the key components and steps. Finally, we provide recommendations for the reliable use of causal ML and effective translation into the clinic.",
        "year": 2024,
        "authors": "Stefan Feuerriegel and Dennis Frauen and Valentyn Melnychuk and Jonas Schweisthal and Konstantin Hess and Alicia Curth and Stefan Bauer and Niki Kilbertus and Isaac S Kohane and Mihaela van der Schaar"
      },
      {
        "title": "On Inductive Biases for Heterogeneous Treatment Effect Estimation",
        "abstract": "We investigate how to exploit structural similarities of an individual's potential outcomes (POs) under different treatments to obtain better estimates of conditional average treatment effects in finite samples. Especially when it is unknown whether a treatment has an effect at all, it is natural to hypothesize that the POs are similar--yet, some existing strategies for treatment effect estimation employ regularization schemes that implicitly encourage heterogeneity even when it does not exist and fail to fully make use of shared structure. In this paper, we investigate and compare three end-to-end learning strategies to overcome this problem--based on regularization, reparametrization and a flexible multi-task architecture--each encoding inductive bias favoring shared behavior across POs. To build understanding of their relative strengths, we implement all strategies using neural networks and conduct a wide range of semi-synthetic experiments. We observe that all three approaches can lead to substantial improvements upon numerous baselines and gain insight into performance differences across various experimental settings.",
        "year": 2021,
        "authors": "Alicia Curth and Mihaela van der Schaar"
      }
    ],
    "d97bGd8AAAAJ": [
      {
        "title": "Unpaired image-to-image translation using cycle-consistent adversarial networks",
        "abstract": "Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G: X-> Y such that the distribution of images from G (X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F: Y-> X and introduce a cycle consistency loss to push F (G (X))~ X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.",
        "year": 2017,
        "authors": "Jun-Yan Zhu and Taesung Park and Phillip Isola and Alexei A Efros"
      },
      {
        "title": "Image-to-image translation with conditional adversarial networks",
        "abstract": "We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Moreover, since the release of the pix2pix software associated with this paper, hundreds of twitter users have posted their own artistic experiments using our system. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without handengineering our loss functions either.",
        "year": 2017,
        "authors": "Phillip Isola and Jun-Yan Zhu and Tinghui Zhou and Alexei A Efros"
      },
      {
        "title": "The unreasonable effectiveness of deep features as a perceptual metric",
        "abstract": "While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, the underlying processes are thought to be quite complex. Despite this, the most widely used perceptual metrics today, such as PSNR and SSIM, are simple, shallow functions, and fail to account for many nuances of human perception. Recently, the deep learning community has found that features of the VGG network trained on ImageNet classification has been remarkably useful as a training loss for image synthesis. But how perceptual are these so-called``perceptual losses\"? What elements are critical for their success? To answer these questions, we introduce a new dataset of human perceptual similarity judgments. We systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. We find that deep features outperform all previous metrics by large margins on our dataset. More surprisingly, this result is not restricted to ImageNet-trained VGG features, but holds across different deep architectures and levels of supervision (supervised, self-supervised, or even unsupervised). Our results suggest that perceptual similarity is an emergent property shared across deep visual representations.",
        "year": 2018,
        "authors": "Richard Zhang and Phillip Isola and Alexei A Efros and Eli Shechtman and Oliver Wang"
      }
    ],
    "Vb3FLmkAAAAJ": [
      {
        "title": "Robust estimators in high-dimensions without the computational intractability",
        "abstract": "We study high-dimensional distribution learning in an agnostic setting where an adversary is allowed to arbitrarily corrupt an -fraction of the samples. Such questions have a rich history spanning statistics, machine learning, and theoretical computer science. Even in the most basic settings, the only known approaches are either computationally inefficient or lose dimension-dependent factors in their error guarantees. This raises the following question: Is high-dimensional agnostic distribution learning even possible, algorithmically? In this work, we obtain the first computationally efficient algorithms with dimension-independent error guarantees for agnostically learning several fundamental classes of high-dimensional distributions: (1) a single Gaussian, (2) a product distribution on the hypercube, (3) mixtures of two product distributions (under a natural balancedness condition), and (4) mixtures of spherical …",
        "year": 2019,
        "authors": "Ilias Diakonikolas and Gautam Kamath and Daniel Kane and Jerry Li and Ankur Moitra and Alistair Stewart"
      },
      {
        "title": "Sever: A robust meta-algorithm for stochastic optimization",
        "abstract": "In high dimensions, most machine learning methods are brittle to even a small fraction of structured outliers. To address this, we introduce a new meta-algorithm that can take in a base learner such as least squares or stochastic gradient descent, and harden the learner to be resistant to outliers. Our method, Sever, possesses strong theoretical guarantees yet is also highly scalable–beyond running the base learner itself, it only requires computing the top singular vector of a certain n {\\texttimes} d matrix. We apply Sever on a drug design dataset and a spam classification dataset, and find that in both cases it has substantially greater robustness than several baselines. On the spam dataset, with 1% corruptions, we achieved 7.4% test error, compared to 13.4%-20.5% for the baselines, and 3% error on the uncorrupted dataset. Similarly, on the drug design dataset, with 10% corruptions, we achieved 1.42 mean-squared error test error, compared to 1.51-2.33 for the baselines, and 1.23 error on the uncorrupted dataset.",
        "year": 2019,
        "authors": "Ilias Diakonikolas and Gautam Kamath and Daniel Kane and Jerry Li and Jacob Steinhardt and Alistair Stewart"
      },
      {
        "title": "Being robust (in high dimensions) can be practical",
        "abstract": "Robust estimation is much more challenging in high-dimensions than it is in one-dimension: Most techniques either lead to intractable optimization problems or estimators that can tolerate only a tiny fraction of errors. Recent work in theoretical computer science has shown that, in appropriate distributional models, it is possible to robustly estimate the mean and covariance with polynomial time algorithms that can tolerate a constant fraction of corruptions, independent of the dimension. However, the sample and time complexity of these algorithms is prohibitively large for high-dimensional applications. In this work, we address both of these issues by establishing sample complexity bounds that are optimal, up to logarithmic factors, as well as giving various refinements that allow the algorithms to tolerate a much larger fraction of corruptions. Finally, we show on both synthetic and real data that our algorithms have state-of-the-art performance and suddenly make high-dimensional robust estimation a realistic possibility.",
        "year": 2017,
        "authors": "Ilias Diakonikolas and Gautam Kamath and Daniel M Kane and Jerry Li and Ankur Moitra and Alistair Stewart"
      }
    ],
    "wMjQdBcAAAAJ": [
      {
        "title": "Trust region policy optimisation in multi-agent reinforcement learning",
        "abstract": "Trust region methods rigorously enabled reinforcement learning (RL) agents to learn monotonically improving policies, leading to superior performance on a variety of tasks. Unfortunately, when it comes to multi-agent reinforcement learning (MARL), the property of monotonic improvement may not simply apply; this is because agents, even in cooperative games, could have conflicting directions of policy updates. As a result, achieving a guaranteed improvement on the joint policy where each agent acts individually remains an open challenge. In this paper, we extend the theory of trust region learning to MARL. Central to our findings are the multi-agent advantage decomposition lemma and the sequential policy update scheme. Based on these, we develop Heterogeneous-Agent Trust Region Policy Optimisation (HATPRO) and Heterogeneous-Agent Proximal Policy Optimisation (HAPPO) algorithms. Unlike many existing MARL algorithms, HATRPO/HAPPO do not need agents to share parameters, nor do they need any restrictive assumptions on decomposibility of the joint value function. Most importantly, we justify in theory the monotonic improvement property of HATRPO/HAPPO. We evaluate the proposed methods on a series of Multi-Agent MuJoCo and StarCraftII tasks. Results show that HATRPO and HAPPO significantly outperform strong baselines such as IPPO, MAPPO and MADDPG on all tested tasks, therefore establishing a new state of the art.",
        "year": 2021,
        "authors": "Jakub Grudzien Kuba and Ruiqing Chen and Munning Wen and Ying Wen and Fanglei Sun and Jun Wang and Yaodong Yang"
      },
      {
        "title": "Multi-agent reinforcement learning is a sequence modeling problem",
        "abstract": "Large sequence models (SM) such as GPT series and BERT have displayed outstanding performance and generalization capabilities in natural language process, vision and recently reinforcement learning. A natural follow-up question is how to abstract multi-agent decision making also as an sequence modeling problem and benefit from the prosperous development of the SMs. In this paper, we introduce a novel architecture named Multi-Agent Transformer (MAT) that effectively casts cooperative multi-agent reinforcement learning (MARL) into SM problems wherein the objective is to map agents' observation sequences to agents' optimal action sequences. Our goal is to build the bridge between MARL and SMs so that the modeling power of modern sequence models can be unleashed for MARL. Central to our MAT is an encoder-decoder architecture which leverages the multi-agent advantage decomposition theorem to transform the joint policy search problem into a sequential decision making process; this renders only linear time complexity for multi-agent problems and, most importantly, endows MAT with monotonic performance improvement guarantee. Unlike prior arts such as Decision Transformer fit only pre-collected offline data, MAT is trained by online trial and error from the environment in an on-policy fashion. To validate MAT, we conduct extensive experiments on StarCraftII, Multi-Agent MuJoCo, Dexterous Hands Manipulation, and Google Research Football benchmarks. Results demonstrate that MAT achieves superior performance and data efficiency compared to strong baselines including MAPPO and HAPPO. Furthermore, we …",
        "year": 2022,
        "authors": "Muning Wen and Jakub Kuba and Runji Lin and Weinan Zhang and Ying Wen and Jun Wang and Yaodong Yang"
      },
      {
        "title": "Safe multi-agent reinforcement learning for multi-robot control",
        "abstract": "A challenging problem in robotics is how to control multiple robots cooperatively and safely in real-world applications. Yet, developing multi-robot control methods from the perspective of safe multi-agent reinforcement learning (MARL) has merely been studied. To fill this gap, in this study, we investigate safe MARL for multi-robot control on cooperative tasks, in which each individual robot has to not only meet its own safety constraints while maximising their reward, but also consider those of others to guarantee safe team behaviours. Firstly, we formulate the safe MARL problem as a constrained Markov game and employ policy optimisation to solve it theoretically. The proposed algorithm guarantees monotonic improvement in reward and satisfaction of safety constraints at every iteration. Secondly, as approximations to the theoretical solution, we propose two safe multi-agent policy gradient methods: Multi-Agent …",
        "year": 2023,
        "authors": "Shangding Gu and Jakub Grudzien Kuba and Yuanpei Chen and Yali Du and Long Yang and Alois Knoll and Yaodong Yang"
      }
    ],
    "NDyEvlQAAAAJ": [
      {
        "title": "Reference-based analysis of lung single-cell sequencing reveals a transitional profibrotic macrophage",
        "abstract": "Tissue fibrosis is a major cause of mortality that results from the deposition of matrix proteins by an activated mesenchyme. Macrophages accumulate in fibrosis, but the role of specific subgroups in supporting fibrogenesis has not been investigated in vivo. Here, we used single-cell RNA sequencing (scRNA-seq) to characterize the heterogeneity of macrophages in bleomycin-induced lung fibrosis in mice. A novel computational framework for the annotation of scRNA-seq by reference to bulk transcriptomes (SingleR) enabled the subclustering of macrophages and revealed a disease-associated subgroup with a transitional gene expression profile intermediate between monocyte-derived and alveolar macrophages. These CX3CR1+SiglecF+ transitional macrophages localized to the fibrotic niche and had a profibrotic effect in vivo. Human orthologs of genes expressed by the transitional macrophages were …",
        "year": 2019,
        "authors": "Dvir Aran and Agnieszka P Looney and Leqian Liu and Esther Wu and Valerie Fong and Austin Hsu and Suzanna Chak and Ram P Naikawadi and Paul J Wolters and Adam R Abate and Atul J Butte and Mallar Bhattacharya"
      },
      {
        "title": "xCell: digitally portraying the tissue cellular heterogeneity landscape",
        "abstract": "Tissues are complex milieus consisting of numerous cell types. Several recent methods have attempted to enumerate cell subsets from transcriptomes. However, the available methods have used limited sources for training and give only a partial portrayal of the full cellular landscape. Here we present xCell, a novel gene signature-based method, and use it to infer 64 immune and stromal cell types. We harmonized 1822 pure human cell type transcriptomes from various sources and employed a curve fitting approach for linear comparison of cell types and introduced a novel spillover compensation technique for separating them. Using extensive in silico analyses and comparison to cytometry immunophenotyping, we show that xCell outperforms other methods. xCell is available at                    http://xCell.ucsf.edu/                                    .",
        "year": 2017,
        "authors": "Dvir Aran and Zicheng Hu and Atul J Butte"
      },
      {
        "title": "The repertoire of mutational signatures in human cancer",
        "abstract": "Somatic mutations in cancer genomes are caused by multiple mutational processes, each of which generates a characteristic mutational signature. Here, as part of the Pan-Cancer Analysis of Whole Genomes (PCAWG) Consortium of the International Cancer Genome Consortium (ICGC) and The Cancer Genome Atlas (TCGA), we characterized mutational signatures using 84,729,690 somatic mutations from 4,645 whole-genome and 19,184 exome sequences that encompass most types of cancer. We identified 49 single-base-substitution, 11 doublet-base-substitution, 4 clustered-base-substitution and 17 small insertion-and-deletion signatures. The substantial size of our dataset, compared with previous analyses, , , , , , , , , , , –, enabled the discovery of new signatures, the separation of overlapping signatures and the decomposition of signatures into components that may represent associated—but distinct—DNA …",
        "year": 2020,
        "authors": "Ludmil B Alexandrov and Jaegil Kim and Nicholas J Haradhvala and Mi Ni Huang and Alvin Wei Tian Ng and Yang Wu and Arnoud Boot and Kyle R Covington and Dmitry A Gordenin and Erik N Bergstrom and SM Ashiqul Islam and Nuria Lopez-Bigas and Leszek J Klimczak and John R McPherson and Sandro Morganella and Radhakrishnan Sabarinathan and David A Wheeler and Ville Mustonen and Gad Getz and Steven G Rozen and Michael R Stratton"
      }
    ],
    "nxNkEiYAAAAJ": [
      {
        "title": "Efficient bipedal robots based on passive-dynamic walkers",
        "abstract": "Passive-dynamic walkers are simple mechanical devices, composed of solid parts connected by joints, that walk stably down a slope. They have no motors or controllers, yet can have remarkably humanlike motions. This suggests that these machines are useful models of human locomotion; however, they cannot walk on level ground. Here we present three robots based on passive-dynamics, with small active power sources substituted for gravity, which can walk on level ground. These robots use less control and less energy than other powered robots, yet walk more naturally, further suggesting the importance of passive-dynamics in human locomotion.",
        "year": 2005,
        "authors": "Steve Collins and Andy Ruina and Russ Tedrake and Martijn Wisse"
      },
      {
        "title": "Evaluating robustness of neural networks with mixed integer programming",
        "abstract": "Neural networks have demonstrated considerable success on a wide variety of real-world problems. However, networks trained only to optimize for training accuracy can often be fooled by adversarial examples - slightly perturbed inputs that are misclassified with high confidence. Verification of networks enables us to gauge their vulnerability to such adversarial examples. We formulate verification of piecewise-linear neural networks as a mixed integer program. On a representative task of finding minimum adversarial distortions, our verifier is two to three orders of magnitude quicker than the state-of-the-art. We achieve this computational speedup via tight formulations for non-linearities, as well as a novel presolve algorithm that makes full use of all information available. The computational speedup allows us to verify properties on convolutional networks with an order of magnitude more ReLUs than networks previously verified by any complete verifier. In particular, we determine for the first time the exact adversarial accuracy of an MNIST classifier to perturbations with bounded  norm : for this classifier, we find an adversarial example for 4.38% of samples, and a certificate of robustness (to perturbations with bounded norm) for the remainder. Across all robust training procedures and network architectures considered, we are able to certify more samples than the state-of-the-art and find more adversarial examples than a strong first-order attack.",
        "year": 2017,
        "authors": "Vincent Tjeng and Kai Xiao and Russ Tedrake"
      },
      {
        "title": "Optimization-based locomotion planning, estimation, and control design for the atlas humanoid robot",
        "abstract": "This paper describes a collection of optimization algorithms for achieving dynamic planning, control, and state estimation for a bipedal robot designed to operate reliably in complex environments. To make challenging locomotion tasks tractable, we describe several novel applications of convex, mixed-integer, and sparse nonlinear optimization to problems ranging from footstep placement to whole-body planning and control. We also present a state estimator formulation that, when combined with our walking controller, permits highly precise execution of extended walking plans over non-flat terrain. We describe our complete system integration and experiments carried out on Atlas, a full-size hydraulic humanoid robot built by Boston Dynamics, Inc.",
        "year": 2016,
        "authors": "Scott Kuindersma and Robin Deits and Maurice Fallon and Andrés Valenzuela and Hongkai Dai and Frank Permenter and Twan Koolen and Pat Marion and Russ Tedrake"
      }
    ],
    "8C2_ZVsAAAAJ": [
      {
        "title": "Do As I Can, Not As I Say: Grounding Language in Robotic Affordances",
        "abstract": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model’s “hands and eyes,” while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project’s website, video, and open source can be …",
        "year": 2023,
        "authors": "Anthony Brohan and Yevgen Chebotar and Chelsea Finn and Karol Hausman and Alexander Herzog and Daniel Ho and Julian Ibarz and Alex Irpan and Eric Jang and Ryan Julian and Dmitry Kalashnikov and Sergey Levine and Yao Lu and Carolina Parada and Kanishka Rao and Pierre Sermanet and Alexander T Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Mengyuan Yan and Noah Brown and Michael Ahn and Omar Cortes and Nicolas Sievers and Clayton Tan and Sichun Xu and Diego Reyes and Jarek Rettinghouse and Jornell Quiambao and Peter Pastor and Linda Luu and Kuang-Huei Lee and Yuheng Kuang and Sally Jesmonth and Nikhil J Joshi and Kyle Jeffrey and Rosario Jauregui Ruano and Jasmine Hsu and Keerthana Gopalakrishnan and Byron David and Andy Zeng and Chuyuan Kelly Fu"
      },
      {
        "title": "RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control",
        "abstract": "We study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robotic trajectory data and Internet-scale vision-language tasks, such as visual question answering. In contrast to other approaches, we propose a simple, general recipe to achieve this goal: in order to fit both natural language responses and robotic actions into the same format, we express the actions as text tokens and incorporate them directly into the training set of the model in the same way as natural language tokens. We refer to such category of models as vision-language-action models (VLA) and instantiate an example of such a model, which we call RT-2. Our extensive evaluation (6k evaluation trials) shows that our approach leads to performant robotic policies and enables RT-2 to obtain a range of emergent capabilities from Internet-scale training. This includes significantly improved generalization to novel objects, the ability to interpret commands not present in the robot training data (such as placing an object onto a particular number or icon), and the ability to perform rudimentary reasoning in response to user commands (such as picking up the smallest or largest object, or the one closest to another object). We further show that incorporating chain of …",
        "year": 2023,
        "authors": "Brianna Zitkovich and Tianhe Yu and Sichun Xu and Peng Xu and Ted Xiao and Fei Xia and Jialin Wu and Paul Wohlhart and Stefan Welker and Ayzaan Wahid and Quan Vuong and Vincent Vanhoucke and Huong Tran and Radu Soricut and Anikait Singh and Jaspiar Singh and Pierre Sermanet and Pannag R Sanketi and Grecia Salazar and Michael S Ryoo and Krista Reymann and Kanishka Rao and Karl Pertsch and Igor Mordatch and Henryk Michalewski and Yao Lu and Sergey Levine and Lisa Lee and Tsang-Wei Edward Lee and Isabel Leal and Yuheng Kuang and Dmitry Kalashnikov and Ryan Julian and Nikhil J Joshi and Alex Irpan and Brian Ichter and Jasmine Hsu and Alexander Herzog and Karol Hausman and Keerthana Gopalakrishnan and Chuyuan Fu and Pete Florence and Chelsea Finn and Kumar Avinava Dubey and Danny Driess and Tianli Ding and Krzysztof Marcin Choromanski and Xi Chen and Yevgen Chebotar and Justice Carbajal and Noah Brown and Anthony Brohan and Montserrat Gonzalez Arenas and Kehang Han"
      },
      {
        "title": "Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning",
        "abstract": "Meta-reinforcement learning algorithms can enable robots to acquire new skills much more quickly, by leveraging prior experience to learn how to learn. However, much of the current research on meta-reinforcement learning focuses on task distributions that are very narrow. For example, a commonly used meta-reinforcement learning benchmark uses different running velocities for a simulated robot as different tasks. When policies are meta-trained on such narrow task distributions, they cannot possibly generalize to more quickly acquire entirely new tasks. Therefore, if the aim of these methods is enable faster acquisition of entirely new behaviors, we must evaluate them on task distributions that are sufficiently broad to enable generalization to new behaviors. In this paper, we propose an open-source simulated benchmark for meta-reinforcement learning and multitask learning consisting of 50 distinct robotic manipulation tasks. Our aim is to make it possible to develop algorithms that generalize to accelerate the acquisition of entirely new, held-out tasks. We evaluate 6 state-of-the-art meta-reinforcement learning and multi-task learning algorithms on these tasks. Surprisingly, while each task and its variations (eg, with different object positions) can be learned with reasonable success, these algorithms struggle to learn with multiple tasks at the same time, even with as few as ten distinct training tasks. Our analysis and open-source environments pave the way for future research in multi-task learning and meta-learning that can enable meaningful generalization, thereby unlocking the full potential of these methods. 1.",
        "year": 2020,
        "authors": "Tianhe Yu and Deirdre Quillen and Zhanpeng He and Ryan Julian and Karol Hausman and Chelsea Finn and Sergey Levine"
      }
    ],
    "yABlzrsAAAAJ": [
      {
        "title": "Learning to adapt in dynamic, real-world environments through meta-reinforcement learning",
        "abstract": "Although reinforcement learning methods can achieve impressive results in simulation, the real world presents two major challenges: generating samples is exceedingly expensive, and unexpected perturbations or unseen situations cause proficient but specialized policies to fail at test time. Given that it is impractical to train separate policies to accommodate all situations the agent may see in the real world, this work proposes to learn how to quickly and effectively adapt online to new tasks. To enable sample-efficient learning, we consider learning online adaptation in the context of model-based reinforcement learning. Our approach uses meta-learning to train a dynamics model prior such that, when combined with recent data, this prior can be rapidly adapted to the local context. Our experiments demonstrate online adaptation for continuous control tasks on both simulated and real-world agents. We first show simulated agents adapting their behavior online to novel terrains, crippled body parts, and highly-dynamic environments. We also illustrate the importance of incorporating online adaptation into autonomous agents that operate in the real world by applying our method to a real dynamic legged millirobot. We demonstrate the agent's learned ability to quickly adapt online to a missing leg, adjust to novel terrains and slopes, account for miscalibration or errors in pose estimation, and compensate for pulling payloads.",
        "year": 2018,
        "authors": "Anusha Nagabandi and Ignasi Clavera and Simin Liu and Ronald S Fearing and Pieter Abbeel and Sergey Levine and Chelsea Finn"
      },
      {
        "title": "Openai o1 system card",
        "abstract": "The o1 model series is trained with large-scale reinforcement learning to reason using chain of thought. These advanced reasoning capabilities provide new avenues for improving the safety and robustness of our models. In particular, our models can reason about our safety policies in context when responding to potentially unsafe prompts, through deliberative alignment. This leads to state-of-the-art performance on certain benchmarks for risks such as generating illicit advice, choosing stereotyped responses, and succumbing to known jailbreaks. Training models to incorporate a chain of thought before answering has the potential to unlock substantial benefits, while also increasing potential risks that stem from heightened intelligence. Our results underscore the need for building robust alignment methods, extensively stress-testing their efficacy, and maintaining meticulous risk management protocols. This report outlines the safety work carried out for the OpenAI o1 and OpenAI o1-mini models, including safety evaluations, external red teaming, and Preparedness Framework evaluations.",
        "year": 2024,
        "authors": "Aaron Jaech and Adam Kalai and Adam Lerer and Adam Richardson and Ahmed El-Kishky and Aiden Low and Alec Helyar and Aleksander Madry and Alex Beutel and Alex Carney and Alex Iftimie and Alex Karpenko and Alex Tachard Passos and Alexander Neitz and Alexander Prokofiev and Alexander Wei and Allison Tam and Ally Bennett and Ananya Kumar and Andre Saraiva and Andrea Vallone and Andrew Duberstein and Andrew Kondrich and Andrey Mishchenko and Andy Applebaum and Angela Jiang and Ashvin Nair and Barret Zoph and Behrooz Ghorbani and Ben Rossen and Benjamin Sokolowsky and Boaz Barak and Bob McGrew and Borys Minaiev and Botao Hao and Bowen Baker and Brandon Houghton and Brandon McKinzie and Brydon Eastman and Camillo Lugaresi and Cary Bassin and Cary Hudson and Chak Ming Li and Charles de Bourcy and Chelsea Voss and Chen Shen and Chong Zhang and Chris Koch and Chris Orsinger and Christopher Hesse and Claudia Fischer and Clive Chan and Dan Roberts and Daniel Kappler and Daniel Levy and Daniel Selsam and David Dohan and David Farhi and David Mely and David Robinson and Dimitris Tsipras and Doug Li and Dragos Oprica and Eben Freeman and Eddie Zhang and Edmund Wong and Elizabeth Proehl and Enoch Cheung and Eric Mitchell and Eric Wallace and Erik Ritter and Evan Mays and Fan Wang and Felipe Petroski Such and Filippo Raso and Florencia Leoni and Foivos Tsimpourlas and Francis Song and Fred von Lohmann and Freddie Sulit and Geoff Salmon and Giambattista Parascandolo and Gildas Chabot and Grace Zhao and Greg Brockman and Guillaume Leclerc and Hadi Salman and Haiming Bao and Hao Sheng and Hart Andrin and Hessam Bagherinezhad and Hongyu Ren and Hunter Lightman and Hyung Won Chung and Ian Kivlichan and Ian O'Connell and Ian Osband and Ignasi Clavera Gilaberte and Ilge Akkaya and Ilya Kostrikov and Ilya Sutskever and Irina Kofman and Jakub Pachocki and James Lennon and Jason Wei and Jean Harb and Jerry Twore and Jiacheng Feng and Jiahui Yu and Jiayi Weng and Jie Tang and Jieqi Yu and Joaquin Quiñonero Candela and Joe Palermo and Joel Parish and Johannes Heidecke and John Hallman and John Rizzo and Jonathan Gordon and Jonathan Uesato and Jonathan Ward and Joost Huizinga and Julie Wang and Kai Chen and Kai Xiao and Karan Singhal and Karina Nguyen and Karl Cobbe and Katy Shi and Kayla Wood and Kendra Rimbach and Keren Gu-Lemberg and Kevin Liu and Kevin Lu and Kevin Stone and Kevin Yu and Lama Ahmad and Lauren Yang and Leo Liu and Leon Maksin and Leyton Ho and Liam Fedus and Lilian Weng and Linden Li and Lindsay McCallum and Lindsey Held and Lorenz Kuhn and Lukas Kondraciuk and Lukasz Kaiser and Luke Metz"
      },
      {
        "title": "Model-ensemble trust-region policy optimization",
        "abstract": "Model-free reinforcement learning (RL) methods are succeeding in a growing number of tasks, aided by recent advances in deep learning. However, they tend to suffer from high sample complexity, which hinders their use in real-world domains. Alternatively, model-based reinforcement learning promises to reduce sample complexity, but tends to require careful tuning and to date have succeeded mainly in restrictive domains where simple models are sufficient for learning. In this paper, we analyze the behavior of vanilla model-based reinforcement learning methods when deep neural networks are used to learn both the model and the policy, and show that the learned policy tends to exploit regions where insufficient data is available for the model to be learned, causing instability in training. To overcome this issue, we propose to use an ensemble of models to maintain the model uncertainty and regularize the learning process. We further show that the use of likelihood ratio derivatives yields much more stable learning than backpropagation through time. Altogether, our approach Model-Ensemble Trust-Region Policy Optimization (ME-TRPO) significantly reduces the sample complexity compared to model-free deep RL methods on challenging continuous control benchmark tasks.",
        "year": 2018,
        "authors": "Thanard Kurutach and Ignasi Clavera and Yan Duan and Aviv Tamar and Pieter Abbeel"
      }
    ],
    "PTS2AOgAAAAJ": [
      {
        "title": "Gpt-4o system card",
        "abstract": "GPT-4o is an autoregressive omni model that accepts as input any combination of text, audio, image, and video, and generates any combination of text, audio, and image outputs. It's trained end-to-end across text, vision, and audio, meaning all inputs and outputs are processed by the same neural network. GPT-4o can respond to audio inputs in as little as 232 milliseconds, with an average of 320 milliseconds, which is similar to human response time in conversation. It matches GPT-4 Turbo performance on text in English and code, with significant improvement on text in non-English languages, while also being much faster and 50\\% cheaper in the API. GPT-4o is especially better at vision and audio understanding compared to existing models. In line with our commitment to building AI safely and consistent with our voluntary commitments to the White House, we are sharing the GPT-4o System Card, which includes our Preparedness Framework evaluations. In this System Card, we provide a detailed look at GPT-4o's capabilities, limitations, and safety evaluations across multiple categories, focusing on speech-to-speech while also evaluating text and image capabilities, and measures we've implemented to ensure the model is safe and aligned. We also include third-party assessments on dangerous capabilities, as well as discussion of potential societal impacts of GPT-4o's text and vision capabilities.",
        "year": 2024,
        "authors": "Aaron Hurst and Adam Lerer and Adam P Goucher and Adam Perelman and Aditya Ramesh and Aidan Clark and AJ Ostrow and Akila Welihinda and Alan Hayes and Alec Radford and Aleksander Mądry and Alex Baker-Whitcomb and Alex Beutel and Alex Borzunov and Alex Carney and Alex Chow and Alex Kirillov and Alex Nichol and Alex Paino and Alex Renzin and Alex Tachard Passos and Alexander Kirillov and Alexi Christakis and Alexis Conneau and Ali Kamali and Allan Jabri and Allison Moyer and Allison Tam and Amadou Crookes and Amin Tootoochian and Amin Tootoonchian and Ananya Kumar and Andrea Vallone and Andrej Karpathy and Andrew Braunstein and Andrew Cann and Andrew Codispoti and Andrew Galu and Andrew Kondrich and Andrew Tulloch and Andrey Mishchenko and Angela Baek and Angela Jiang and Antoine Pelisse and Antonia Woodford and Anuj Gosalia and Arka Dhar and Ashley Pantuliano and Avi Nayak and Avital Oliver and Barret Zoph and Behrooz Ghorbani and Ben Leimberger and Ben Rossen and Ben Sokolowsky and Ben Wang and Benjamin Zweig and Beth Hoover and Blake Samic and Bob McGrew and Bobby Spero and Bogo Giertler and Bowen Cheng and Brad Lightcap and Brandon Walkin and Brendan Quinn and Brian Guarraci and Brian Hsu and Bright Kellogg and Brydon Eastman and Camillo Lugaresi and Carroll Wainwright and Cary Bassin and Cary Hudson and Casey Chu and Chad Nelson and Chak Li and Chan Jun Shern and Channing Conger and Charlotte Barette and Chelsea Voss and Chen Ding and Cheng Lu and Chong Zhang and Chris Beaumont and Chris Hallacy and Chris Koch and Christian Gibson and Christina Kim and Christine Choi and Christine McLeavey and Christopher Hesse and Claudia Fischer and Clemens Winter and Coley Czarnecki and Colin Jarvis and Colin Wei and Constantin Koumouzelis and Dane Sherburn and Daniel Kappler and Daniel Levin and Daniel Levy and David Carr and David Farhi and David Mely and David Robinson and David Sasaki and Denny Jin and Dev Valladares and Dimitris Tsipras and Doug Li and Duc Phong Nguyen and Duncan Findlay and Edede Oiwoh and Edmund Wong and Ehsan Asdar and Elizabeth Proehl and Elizabeth Yang and Eric Antonow and Eric Kramer and Eric Peterson and Eric Sigler and Eric Wallace and Eugene Brevdo and Evan Mays and Farzad Khorasani and Felipe Petroski Such and Filippo Raso and Francis Zhang and Fred von Lohmann and Freddie Sulit and Gabriel Goh and Gene Oden and Geoff Salmon and Giulio Starace and Greg Brockman and Hadi Salman and Haiming Bao and Haitang Hu and Hannah Wong and Haoyu Wang and Heather Schmidt and Heather Whitney and Heewoo Jun and Hendrik Kirchner and Henrique Ponde de Oliveira Pinto and Hongyu Ren and Huiwen Chang and Hyung Won Chung and Ian Kivlichan"
      },
      {
        "title": "Offline reinforcement learning with implicit q-learning",
        "abstract": "Offline reinforcement learning requires reconciling two conflicting aims: learning a policy that improves over the behavior policy that collected the dataset, while at the same time minimizing the deviation from the behavior policy so as to avoid errors due to distributional shift. This trade-off is critical, because most current offline reinforcement learning methods need to query the value of unseen actions during training to improve the policy, and therefore need to either constrain these actions to be in-distribution, or else regularize their values. We propose an offline RL method that never needs to evaluate actions outside of the dataset, but still enables the learned policy to improve substantially over the best behavior in the data through generalization. The main insight in our work is that, instead of evaluating unseen actions from the latest policy, we can approximate the policy improvement step implicitly by treating the state value function as a random variable, with randomness determined by the action (while still integrating over the dynamics to avoid excessive optimism), and then taking a state conditional upper expectile of this random variable to estimate the value of the best actions in that state. This leverages the generalization capacity of the function approximator to estimate the value of the best available action at a given state without ever directly querying a Q-function with this unseen action. Our algorithm alternates between fitting this upper expectile value function and backing it up into a Q-function. Then, we extract the policy via advantage-weighted behavioral cloning. We dub our method implicit Q-learning (IQL). IQL demonstrates the state-of …",
        "year": 2021,
        "authors": "Ilya Kostrikov and Ashvin Nair and Sergey Levine"
      },
      {
        "title": "Image augmentation is all you need: Regularizing deep reinforcement learning from pixels",
        "abstract": "We propose a simple data augmentation technique that can be applied to standard model-free reinforcement learning algorithms, enabling robust learning directly from pixels without the need for auxiliary losses or pre-training. The approach leverages input perturbations commonly used in computer vision tasks to regularize the value function. Existing model-free approaches, such as Soft Actor-Critic (SAC), are not able to train deep networks effectively from image pixels. However, the addition of our augmentation method dramatically improves SAC's performance, enabling it to reach state-of-the-art performance on the DeepMind control suite, surpassing model-based (Dreamer, PlaNet, and SLAC) methods and recently proposed contrastive learning (CURL). Our approach can be combined with any model-free reinforcement learning algorithm, requiring only minor modifications. An implementation can be found at https://sites.google.com/view/data-regularized-q.",
        "year": 2020,
        "authors": "Ilya Kostrikov* and Denis Yarats* and Rob Fergus"
      }
    ],
    "nABXo3sAAAAJ": [
      {
        "title": "Decaf: A deep convolutional activation feature for generic visual recognition",
        "abstract": "We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.",
        "year": 2014,
        "authors": "Jeff Donahue and Yangqing Jia and Oriol Vinyals and Judy Hoffman and Ning Zhang and Eric Tzeng and Trevor Darrell"
      },
      {
        "title": "Adversarial discriminative domain adaptation",
        "abstract": "Adversarial learning methods are a promising approach to training robust deep networks, and can generate complex samples across diverse domains. They can also improve recognition despite the presence of domain shift or dataset bias: recent adversarial approaches to unsupervised domain adaptation reduce the difference between the training and test domain distributions and thus improve generalization performance. However, while generative adversarial networks (GANs) show compelling visualizations, they are not optimal on discriminative tasks and can be limited to smaller shifts. On the other hand, discriminative approaches can handle larger domain shifts, but impose tied weights on the model and do not exploit a GAN-based loss. In this work, we first outline a novel generalized framework for adversarial adaptation, which subsumes recent state-of-the-art approaches as special cases, and use this generalized view to better relate prior approaches. We then propose a previously unexplored instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss, which we call Adversarial Discriminative Domain Adaptation (ADDA). We show that ADDA is more effective yet considerably simpler than competing domain-adversarial methods, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results on standard domain adaptation tasks as well as a difficult cross-modality object classification task.",
        "year": 2017,
        "authors": "Eric Tzeng and Judy Hoffman and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Cycada: Cycle-consistent adversarial domain adaptation",
        "abstract": "Domain adaptation is critical for success in new, unseen environments. Adversarial adaptation models have shown tremendous progress towards adapting to new environments by focusing either on discovering domain invariant representations or by mapping between unpaired image domains. While feature space methods are difficult to interpret and sometimes fail to capture pixel-level and low-level domain shifts, image space methods sometimes fail to incorporate high level semantic knowledge relevant for the end task. We propose a model which adapts between domains using both generative image space alignment and latent representation space alignment. Our approach, Cycle-Consistent Adversarial Domain Adaptation (CyCADA), guides transfer between domains according to a specific discriminatively trained task and avoids divergence by enforcing consistency of the relevant semantics before and after adaptation. We evaluate our method on a variety of visual recognition and prediction settings, including digit classification and semantic segmentation of road scenes, advancing state-of-the-art performance for unsupervised adaptation from synthetic to real world driving domains.",
        "year": 2018,
        "authors": "Judy Hoffman and Eric Tzeng and Taesung Park and Jun-Yan Zhu and Phillip Isola and Kate Saenko and Alexei Efros and Trevor Darrell"
      }
    ],
    "Nn990CkAAAAJ": [
      {
        "title": "On the opportunities and risks of foundation models",
        "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",
        "year": 2021,
        "authors": "Rishi Bommasani and Drew A Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher Ré and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W Thomas and Florian Tramèr and Rose E Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang"
      },
      {
        "title": "Understanding black-box predictions via influence functions",
        "abstract": "How can we explain the predictions of a black-box model? In this paper, we use influence functions—a classic technique from robust statistics—to trace a model’s prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks.",
        "year": 2017,
        "authors": "Pang Wei Koh and Percy Liang"
      },
      {
        "title": "Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization",
        "abstract": "Overparameterized neural networks can be highly accurate on average on an i.i.d. test set yet consistently fail on atypical groups of the data (e.g., by learning spurious correlations that hold on average but not in such groups). Distributionally robust optimization (DRO) allows us to learn models that instead minimize the worst-case training loss over a set of pre-defined groups. However, we find that naively applying group DRO to overparameterized neural networks fails: these models can perfectly fit the training data, and any model with vanishing average training loss also already has vanishing worst-case training loss. Instead, the poor worst-case performance arises from poor generalization on some groups. By coupling group DRO models with increased regularization---a stronger-than-typical L2 penalty or early stopping---we achieve substantially higher worst-group accuracies, with 10-40 percentage point improvements on a natural language inference task and two image tasks, while maintaining high average accuracies. Our results suggest that regularization is important for worst-group generalization in the overparameterized regime, even if it is not needed for average generalization. Finally, we introduce a stochastic optimization algorithm, with convergence guarantees, to efficiently train group DRO models.",
        "year": 2019,
        "authors": "Shiori Sagawa* and Pang Wei Koh* and Tatsunori B Hashimoto and Percy Liang"
      }
    ],
    "HPoaHyQAAAAJ": [
      {
        "title": "Shared autonomy via hindsight optimization for teleoperation and teaming",
        "abstract": "In shared autonomy, a user and autonomous system work together to achieve shared goals. To collaborate effectively, the autonomous system must know the user’s goal. As such, most prior works follow a predict-then-act model, first predicting the user’s goal with high confidence, then assisting given that goal. Unfortunately, confidently predicting the user’s goal may not be possible until they have nearly achieved it, causing predict-then-act methods to provide little assistance. However, the system can often provide useful assistance even when confidence for any single goal is low (e.g. move towards multiple goals). In this work, we formalize this insight by modeling shared autonomy as a partially observable Markov decision process (POMDP), providing assistance that minimizes the expected cost-to-go with an unknown goal. As solving this POMDP optimally is intractable, we use hindsight optimization to …",
        "year": 2018,
        "authors": "Shervin Javdani and Henny Admoni and Stefania Pellegrinelli and Siddhartha S Srinivasa and J Andrew Bagnell"
      },
      {
        "title": "Shared Autonomy via Hindsight Optimization",
        "abstract": "In shared autonomy, user input and robot autonomy are combined to control a robot to achieve a goal. Often, the robot does not know a priori which goal the user wants to achieve, and must both predict the user’s intended goal, and assist in achieving that goal. We formulate the problem of shared autonomy as a Partially Observable Markov Decision Process with uncertainty over the user’s goal. We utilize maximum entropy inverse optimal control to estimate a distribution over the user’s goal based on the history of inputs. Ideally, the robot assists the user by solving for an action which minimizes the expected cost-to-go for the (unknown) goal. As solving the POMDP to select the optimal action is intractable, we use hindsight optimization to approximate the solution. In a user study, we compare our method to a standard predict-then-blend approach. We find that our method enables users to accomplish tasks more …",
        "year": 2015,
        "authors": "Shervin Javdani and J Andrew Bagnell and Siddhartha Srinivasa"
      },
      {
        "title": "Autonomy infused teleoperation with application to brain computer interface controlled manipulation",
        "abstract": "Robot teleoperation systems face a common set of challenges including latency, low-dimensional user commands, and asymmetric control inputs. User control with Brain–Computer Interfaces (BCIs) exacerbates these problems through especially noisy and erratic low-dimensional motion commands due to the difficulty in decoding neural activity. We introduce a general framework to address these challenges through a combination of computer vision, user intent inference, and arbitration between the human input and autonomous control schemes. Adjustable levels of assistance allow the system to balance the operators capabilities and their perception of control authority. Additionally, a custom servo controller design allow for safe interactions of the robotic arm with the environment. We present experimental results demonstrating significant performance improvement using our shared-control assistance …",
        "year": 2017,
        "authors": "Katharina Muelling and Arun Venkatraman and Jean-Sebastien Valois and John E Downey and Jeffrey Weiss and Shervin Javdani and Martial Hebert and Andrew B Schwartz and Jennifer L Collinger and J Andrew Bagnell"
      }
    ],
    "1TqAq5AAAAAJ": [
      {
        "title": "Combined task and motion planning through an extensible planner-independent interface layer",
        "abstract": "The need for combined task and motion planning in robotics is well understood. Solutions to this problem have typically relied on special purpose, integrated implementations of task planning and motion planning algorithms. We propose a new approach that uses off-the-shelf task planners and motion planners and makes no assumptions about their implementation. Doing so enables our approach to directly build on, and benefit from, the vast literature and latest advances in task planning and motion planning. It uses a novel representational abstraction and requires only that failures in computing a motion plan for a high-level action be identifiable and expressible in the form of logical predicates at the task level. We evaluate the approach and illustrate its robustness through a number of experiments using a state-of-the-art robotics simulator and a PR2 robot. These experiments show the system accomplishing a …",
        "year": 2014,
        "authors": "Siddharth Srivastava and Eugene Fang and Lorenzo Riano and Rohan Chitnis and Stuart Russell and Pieter Abbeel"
      },
      {
        "title": "Grounding Spatial Relations for Human-Robot Interaction",
        "abstract": "We propose a system for human-robot interaction that learns both models for spatial prepositions and for object recognition. Our system grounds the meaning of an input sentence in terms of visual percepts coming from the robot's sensors in order to send an appropriate command to the PR2 or respond to spatial queries. To perform this grounding, the system recognizes the objects in the scene, determines which spatial relations hold between those objects, and semantically parses the input sentence. The proposed system uses the visual and spatial information in conjunction with the semantic parse to interpret statements that refer to objects (nouns), their spatial relationships (prepositions), and to execute commands (actions). The semantic parse is inherently compositional, allowing the robot to understand complex commands that refer to multiple objects and relations such as: “Move the cup close to the robot to …",
        "year": 2013,
        "authors": "Sergio Guadarrama and Lorenzo Riano and Dave Golland and Daniel Göhring and Yangqing Jia and Dan Klein and Pieter Abbeel and Trevor Darrell"
      },
      {
        "title": "Robotic learning of haptic adjectives through physical interaction",
        "abstract": "To perform useful tasks in everyday human environments, robots must be able to both understand and communicate the sensations they experience during haptic interactions with objects. Toward this goal, we augmented the Willow Garage PR2 robot with a pair of SynTouch BioTac sensors to capture rich tactile signals during the execution of four exploratory procedures on 60 household objects. In a parallel experiment, human subjects blindly touched the same objects and selected binary haptic adjectives from a predetermined set of 25 labels. We developed several machine-learning algorithms to discover the meaning of each adjective from the robot’s sensory data. The most successful algorithms were those that intelligently combine static and dynamic components of the data recorded during all four exploratory procedures. The best of our approaches produced an average adjective classification F 1 score of 0 …",
        "year": 2015,
        "authors": "Vivian Chu and Ian McMahon and Lorenzo Riano and Craig G McDonald and Qin He and Jorge Martinez Perez-Tejada and Michael Arrigo and Trevor Darrell and Katherine J Kuchenbecker"
      }
    ],
    "ygFAcZwAAAAJ": [
      {
        "title": "Introduction to Statistical Relational Learning",
        "abstract": "Advanced statistical modeling and knowledge representation techniques for a newly emerging area of machine learning and probabilistic reasoning; includes introductory material, tutorials for different proposed approaches, and applications. Handling inherent uncertainty and exploiting compositional structure are fundamental to understanding and designing large-scale systems. Statistical relational learning builds on ideas from probability theory and statistics to address uncertainty while incorporating tools from logic, databases and programming languages to represent structure. In Introduction to Statistical Relational Learning, leading researchers in this emerging area of machine learning describe current formalisms, models, and algorithms that enable effective and robust reasoning about richly structured systems and data. The early chapters provide tutorials for material used in later chapters, offering introductions to representation, inference and learning in graphical models, and logic. The book then describes object-oriented approaches, including probabilistic relational models, relational Markov networks, and probabilistic entity-relationship models as well as logic-based formalisms including Bayesian logic programs, Markov logic, and stochastic logic programs. Later chapters discuss such topics as probabilistic models with unknown objects, relational dependency networks, reinforcement learning in relational domains, and information extraction. By presenting a variety of approaches, the book highlights commonalities and clarifies important differences among proposed approaches and, along the way, identifies important …",
        "year": 2007,
        "authors": "L Getoor and B Taskar"
      },
      {
        "title": "Max-margin Markov networks",
        "abstract": "In typical classification tasks, we seek a function which assigns a label to a single object. Kernel-based approaches, such as support vector machines (SVMs), which maximize the margin of confidence of the classifier, are the method of choice for many such tasks. Their popularity stems both from the ability to use high-dimensional feature spaces, and from their strong theoretical guarantees. However, many real-world tasks involve sequential, spatial, or structured data, where multiple labels must be assigned. Existing kernel-based methods ignore structure in the problem, assigning labels independently to each object, losing much useful information. Conversely, probabilistic graphical models, such as Markov networks, can represent correlations between labels, by exploiting problem structure, but cannot handle high-dimensional feature spaces, and lack strong theoretical generalization guarantees. In this paper, we present a new framework that combines the advantages of both approaches: Maximum margin Markov (M3) networks incorporate both kernels, which efficiently deal with high-dimensional features, and the ability to capture correlations in structured data. We present an efficient algorithm for learning M3 networks based on a compact quadratic program formulation. We provide a new theoretical bound for generalization in structured domains. Experiments on the task of handwritten character recognition and collective hypertext classification demonstrate very significant gains over previous approaches.",
        "year": 2003,
        "authors": "Ben Taskar and Carlos Guestrin and Daphne Koller"
      },
      {
        "title": "Determinantal point processes for machine learning",
        "abstract": "Determinantal point processes (DPPs) are elegant probabilistic models of repulsion that arise in quantum physics and random matrix theory. In contrast to traditional structured models like Markov random fields, which become intractable and hard to approximate in the presence of negative correlations, DPPs offer efficient and exact algorithms for sampling, marginalization, conditioning, and other inference tasks. We provide a gentle introduction to DPPs, focusing on the intuitions, algorithms, and extensions that are most relevant to the machine learning community, and show how DPPs can be applied to real-world applications like finding diverse sets of high-quality search results, building informative summaries by selecting diverse sentences from documents, modeling nonoverlapping human poses in images or video, and automatically building timelines of important news stories.",
        "year": 2012,
        "authors": "Alex Kulesza and Ben Taskar"
      }
    ],
    "5NGAbT4AAAAJ": [
      {
        "title": "Bridgedata v2: A dataset for robot learning at scale",
        "abstract": "We introduce BridgeData V2, a large and diverse dataset of robotic manipulation behaviors designed to facilitate research in scalable robot learning. BridgeData V2 contains 53,896 trajectories collected across 24 environments on a publicly available low-cost robot. Unlike many existing robotic manipulation datasets, BridgeData V2 provides enough task and environment variability that skills learned from the data generalize across institutions, making the dataset a useful resource for a broad range of researchers. Additionally, the dataset is compatible with a wide variety of open-vocabulary, multi-task learning methods conditioned on goal images or natural language instructions. In our experiments, we apply 6 state-of-the-art imitation learning and offline reinforcement learning methods to the data and find that they succeed on a suite of tasks requiring varying amounts of generalization. We also demonstrate that the performance of these methods improves with more data and higher capacity models. By publicly sharing BridgeData V2 and our pre-trained models, we aim to accelerate research in scalable robot learning methods.",
        "year": 2023,
        "authors": "Homer Rich Walke and Kevin Black and Tony Z Zhao and Quan Vuong and Chongyi Zheng and Philippe Hansen-Estruch and Andre Wang He and Vivek Myers and Moo Jin Kim and Max Du and Abraham Lee and Kuan Fang and Chelsea Finn and Sergey Levine"
      },
      {
        "title": "Learning multimodal rewards from rankings",
        "abstract": "Learning from human feedback has shown to be a useful approach in acquiring robot reward functions. However, expert feedback is often assumed to be drawn from an underlying unimodal reward function. This assumption does not always hold including in settings where multiple experts provide data or when a single expert provides data for different tasks—we thus go beyond learning a unimodal reward and focus on learning a multimodal reward function. We formulate the multimodal reward learning as a mixture learning problem and develop a novel ranking-based learning approach, where the experts are only required to rank a given set of trajectories. Furthermore, as access to interaction data is often expensive in robotics, we develop an active querying approach to accelerate the learning process. We conduct experiments and user studies using a multi-task variant of OpenAI’s LunarLander and a real Fetch robot, where we collect data from multiple users with different preferences. The results suggest that our approach can efficiently learn multimodal reward functions, and improve data-efficiency over benchmark methods that we adapt to our learning problem.",
        "year": 2022,
        "authors": "Vivek Myers and Erdem Biyik and Nima Anari and Dorsa Sadigh"
      },
      {
        "title": "Toward grounded commonsense reasoning",
        "abstract": "Consider a robot tasked with tidying a desk with a meticulously constructed Lego sports car. A human may recognize that it is not appropriate to disassemble the sports car and put it away as part of the \"tidying.\" How can a robot reach that conclusion? Although large language models (LLMs) have recently been used to enable commonsense reasoning, grounding this reasoning in the real world has been challenging. To reason in the real world, robots must go beyond passively querying LLMs and actively gather information from the environment that is required to make the right decision. For instance, after detecting that there is an occluded car, the robot may need to actively perceive the car to know whether it is an advanced model car made out of Legos or a toy car built by a toddler. We propose an approach that leverages an LLM and vision language model (VLM) to help a robot actively perceive its environment …",
        "year": 2024,
        "authors": "Minae Kwon and Hengyuan Hu and Vivek Myers and Siddharth Karamcheti and Anca Dragan and Dorsa Sadigh"
      }
    ],
    "mQf5cE0AAAAJ": [
      {
        "title": "Apache Spark: a unified engine for big data processing",
        "abstract": "This open source computing framework unifies streaming, batch, and interactive big data workloads to unlock new applications.",
        "year": 2016,
        "authors": "Matei Zaharia and Reynold S Xin and Patrick Wendell and Tathagata Das and Michael Armbrust and Ankur Dave and Xiangrui Meng and Josh Rosen and Shivaram Venkataraman and Michael J Franklin and Ali Ghodsi and Joseph Gonzalez and Scott Shenker and Ion Stoica"
      },
      {
        "title": "Shark: SQL and rich analytics at scale",
        "abstract": "Shark is a new data analysis system that marries query processing with complex analytics on large clusters. It leverages a novel distributed memory abstraction to provide a unified engine that can run SQL queries and sophisticated analytics functions (e.g. iterative machine learning) at scale, and efficiently recovers from failures mid-query. This allows Shark to run SQL queries up to 100X faster than Apache Hive, and machine learning programs more than 100X faster than Hadoop. Unlike previous systems, Shark shows that it is possible to achieve these speedups while retaining a MapReduce-like execution engine, and the fine-grained fault tolerance properties that such engine provides. It extends such an engine in several ways, including column-oriented in-memory storage and dynamic mid-query replanning, to effectively execute SQL. The result is a system that matches the speedups reported for MPP analytic …",
        "year": 2013,
        "authors": "Reynold S Xin and Josh Rosen and Matei Zaharia and Michael J Franklin and Scott Shenker and Ion Stoica"
      },
      {
        "title": "Mapping brain activity at scale with cluster computing",
        "abstract": "Understanding brain function requires monitoring and interpreting the activity of large networks of neurons during behavior. Advances in recording technology are greatly increasing the size and complexity of neural data. Analyzing such data will pose a fundamental bottleneck for neuroscience. We present a library of analytical tools called Thunder built on the open-source Apache Spark platform for large-scale distributed computing. The library implements a variety of univariate and multivariate analyses with a modular, extendable structure well-suited to interactive exploration and analysis development. We demonstrate how these analyses find structure in large-scale neural data, including whole-brain light-sheet imaging data from fictively behaving larval zebrafish, and two-photon imaging data from behaving mouse. The analyses relate neuronal responses to sensory input and behavior, run in minutes or less …",
        "year": 2014,
        "authors": "Jeremy Freeman and Nikita Vladimirov and Takashi Kawashima and Yu Mu and Nicholas J Sofroniew and Davis V Bennett and Joshua Rosen and Chao-Tsung Yang and Loren L Looger and Misha B Ahrens"
      }
    ],
    "xMhGYpgAAAAJ": [
      {
        "title": "Judging llm-as-a-judge with mt-bench and chatbot arena",
        "abstract": "Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80\\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github. com/lm-sys/FastChat/tree/main/fastchat/llm_judge.",
        "year": 2023,
        "authors": "Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric Xing and Hao Zhang and Joseph E Gonzalez and Ion Stoica"
      },
      {
        "title": "Efficient memory management for large language model serving with pagedattention",
        "abstract": "High throughput serving of large language models (LLMs) requires batching sufficiently many requests at a time. However, existing systems struggle because the key-value cache (KV cache) memory for each request is huge and grows and shrinks dynamically. When managed inefficiently, this memory can be significantly wasted by fragmentation and redundant duplication, limiting the batch size. To address this problem, we propose PagedAttention, an attention algorithm inspired by the classical virtual memory and paging techniques in operating systems. On top of it, we build vLLM, an LLM serving system that achieves (1) near-zero waste in KV cache memory and (2) flexible sharing of KV cache within and across requests to further reduce memory usage. Our evaluations show that vLLM improves the throughput of popular LLMs by 2--4× with the same level of latency compared to the state-of-the-art systems …",
        "year": 2023,
        "authors": "Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph Gonzalez and Hao Zhang and Ion Stoica"
      }
    ],
    "ScoZZPsAAAAJ": [
      {
        "title": "Deep metric learning via lifted structured feature embedding",
        "abstract": "Learning the distance metric between pairs of examples is of great importance for learning and visual recognition. With the remarkable success from the state of the art convolutional neural networks, recent works have shown promising results on discriminatively training the networks to learn semantic feature embeddings where similar examples are mapped close to each other and dissimilar examples are mapped farther apart. In this paper, we describe an algorithm for taking full advantage of the training batches in the neural network training by lifting the vector of pairwise distances within the batch to the matrix of pairwise distances. This step enables the algorithm to learn the state of the art feature embedding by optimizing a novel structured prediction objective for active hard negative mining on the lifted problem. Additionally, we collected Online Products dataset: 120k images of 23k classes of online products for metric learning. Our experiments on the CUB-200-2011, CARS196, and Online Products datasets demonstrate significant improvement over existing deep feature embedding methods on all experimented embedding sizes with the GoogLeNet network. The source code and the dataset are available at: https://github. com/rksltnl/Deep-Metric-Learning-CVPR16",
        "year": 2016,
        "authors": "Hyun Oh Song and Yu Xiang and Stefanie Jegelka and Silvio Savarese"
      },
      {
        "title": "Puzzle mix: Exploiting saliency and local statistics for optimal mixup",
        "abstract": "While deep neural networks achieve great performance on fitting the training distribution, the learned networks are prone to overfitting and are susceptible to adversarial attacks. In this regard, a number of mixup based augmentation methods have been recently proposed. However, these approaches mainly focus on creating previously unseen virtual examples and can sometimes provide misleading supervisory signal to the network. To this end, we propose Puzzle Mix, a mixup method for explicitly utilizing the saliency information and the underlying statistics of the natural examples. This leads to an interesting optimization problem alternating between the multi-label objective for optimal mixing mask and saliency discounted optimal transport objective. Our experiments show Puzzle Mix achieves the state of the art generalization and the adversarial robustness results compared to other mixup methods on CIFAR-100, Tiny-ImageNet, and ImageNet datasets, and the source code is available at https://github. com/snu-mllab/PuzzleMix.",
        "year": 2020,
        "authors": "Jang-Hyun Kim and Wonho Choo and Hyun Oh Song"
      },
      {
        "title": "Deep Metric Learning via Facility Location",
        "abstract": "Learning image similarity metrics in an end-to-end fashion with deep networks has demonstrated excellent results on tasks such as clustering and retrieval. However, current methods, all focus on a very local view of the data. In this paper, we propose a new metric learning scheme, based on structured prediction, that is aware of the global structure of the embedding space, and which is designed to optimize a clustering quality metric (NMI). We show state of the art performance on standard datasets, such as CUB200-2011, Cars196, and Stanford online products on NMI and R@ K evaluation metrics.",
        "year": 2017,
        "authors": "Hyun Oh Song and Stefanie Jegelka and Vivek Rathod and Kevin Murphy"
      }
    ],
    "NpOg5soAAAAJ": [
      {
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models",
        "abstract": "DSpace at KOASAS: Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nKOASAS menu About KOASAS KAIST Library 검색 Advanced Search KOASAS About \nKOASAS Open Access Policy Browse Communities & Collections Researchers at KAIST Titles \nSubject By Date rss_1.0 rss_2.0 atom_1.0 sherpa SEARCH DSpace at KOASAS College of \nEngineering(공과대학)Kim Jaechul Graduate School of AI(김재철AI대학원)AI-Conference \nPapers(학술대회논문) Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nCited 0 time in webofscience Cited 0 time in scopus Hit : 2 Download : 0 Export DC(XML) Excel \nLim, Joseph Jaewhanresearcher Publisher IEEE Issue Date 2024-05-15 Citation IEEE \nInternational Conference on Robotics and Automation URI http://hdl.handle.net/10203/326144 \nAppears in Collection AI-Conference Papers(학술대회논문) Files in This Item There are no files …",
        "year": 2024,
        "authors": "Joseph Jaewhan Lim"
      },
      {
        "title": "Octo: An open-source generalist robot policy",
        "abstract": "Large policies pretrained on diverse robot datasets have the potential to transform robotic learning: instead of training new policies from scratch, such generalist robot policies may be finetuned with only a little in-domain data, yet generalize broadly. However, to be widely applicable across a range of robotic learning scenarios, environments, and tasks, such policies need to handle diverse sensors and action spaces, accommodate a variety of commonly used robotic platforms, and finetune readily and efficiently to new domains. In this work, we aim to lay the groundwork for developing open-source, widely applicable, generalist policies for robotic manipulation. As a first step, we introduce Octo, a large transformer-based policy trained on 800k trajectories from the Open X-Embodiment dataset, the largest robot manipulation dataset to date. It can be instructed via language commands or goal images and can be effectively finetuned to robot setups with new sensory inputs and action spaces within a few hours on standard consumer GPUs. In experiments across 9 robotic platforms, we demonstrate that Octo serves as a versatile policy initialization that can be effectively finetuned to new observation and action spaces. We also perform detailed ablations of design decisions for the Octo model, from architecture to training data, to guide future research on building generalist robot models.",
        "year": 2024,
        "authors": "Octo Model Team and Dibya Ghosh and Homer Walke and Karl Pertsch and Kevin Black and Oier Mees and Sudeep Dasari and Joey Hejna and Tobias Kreiman and Charles Xu and Jianlan Luo and You Liang Tan and Lawrence Yunliang Chen and Pannag Sanketi and Quan Vuong and Ted Xiao and Dorsa Sadigh and Chelsea Finn and Sergey Levine"
      },
      {
        "title": "Visual foresight: Model-based deep reinforcement learning for vision-based robotic control",
        "abstract": "Deep reinforcement learning (RL) algorithms can learn complex robotic skills from raw sensory inputs, but have yet to achieve the kind of broad generalization and applicability demonstrated by deep learning methods in supervised domains. We present a deep RL method that is practical for real-world robotics tasks, such as robotic manipulation, and generalizes effectively to never-before-seen tasks and objects. In these settings, ground truth reward signals are typically unavailable, and we therefore propose a self-supervised model-based approach, where a predictive model learns to directly predict the future from raw sensory readings, such as camera images. At test time, we explore three distinct goal specification methods: designated pixels, where a user specifies desired object manipulation tasks by selecting particular pixels in an image and corresponding goal positions, goal images, where the desired goal state is specified with an image, and image classifiers, which define spaces of goal states. Our deep predictive models are trained using data collected autonomously and continuously by a robot interacting with hundreds of objects, without human supervision. We demonstrate that visual MPC can generalize to never-before-seen objects---both rigid and deformable---and solve a range of user-defined object manipulation tasks using the same model.",
        "year": 2018,
        "authors": "Frederik Ebert and Chelsea Finn and Sudeep Dasari and Annie Xie and Alex Lee and Sergey Levine"
      }
    ],
    "RLvsC94AAAAJ": [
      {
        "title": "Language models are few-shot learners",
        "abstract": "We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.",
        "year": 2020,
        "authors": "Tom Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared D Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel Ziegler and Jeffrey Wu and Clemens Winter and Chris Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei"
      },
      {
        "title": "Deep reinforcement learning from human preferences",
        "abstract": "For sophisticated reinforcement learning (RL) systems to interact usefully with real-world environments, we need to communicate complex goals to these systems. In this work, we explore goals defined in terms of (non-expert) human preferences between pairs of trajectory segments. Our approach separates learning the goal from learning the behavior to achieve it. We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on about 0.1% of our agent's interactions with the environment. This reduces the cost of human oversight far enough that it can be practically applied to state-of-the-art RL systems. To demonstrate the flexibility of our approach, we show that we can successfully train complex novel behaviors with about an hour of human time. These behaviors and environments are considerably more complex than any which have been previously learned from human feedback.",
        "year": 2017,
        "authors": "Paul F Christiano and Jan Leike and Tom Brown and Miljan Martic and Shane Legg and Dario Amodei"
      },
      {
        "title": "Scaling laws for neural language models",
        "abstract": "We study empirical scaling laws for language model performance on the cross-entropy loss. The loss scales as a power-law with model size, dataset size, and the amount of compute used for training, with some trends spanning more than seven orders of magnitude. Other architectural details such as network width or depth have minimal effects within a wide range. Simple equations govern the dependence of overfitting on model/dataset size and the dependence of training speed on model size. These relationships allow us to determine the optimal allocation of a fixed compute budget. Larger models are significantly more sampleefficient, such that optimally compute-efficient training involves training very large models on a relatively modest amount of data and stopping significantly before convergence.",
        "year": 2020,
        "authors": "Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei"
      }
    ],
    "2X0cwhkAAAAJ": [
      {
        "title": "Maximum classifier discrepancy for unsupervised domain adaptation",
        "abstract": "In this work, we present a method for unsupervised domain adaptation. Many adversarial learning methods train domain classifier networks to distinguish the features as either a source or target and train a feature generator network to mimic the discriminator. Two problems exist with these methods. First, the domain classifier only tries to distinguish the features as a source or target and thus does not consider task-specific decision boundaries between classes. Therefore, a trained generator can generate ambiguous features near class boundaries. Second, these methods aim to completely match the feature distributions between different domains, which is difficult because of each domain's characteristics. To solve these problems, we introduce a new approach that attempts to align distributions of source and target by utilizing the task-specific decision boundaries. We propose to maximize the discrepancy between two classifiers' outputs to detect target samples that are far from the support of the source. A feature generator learns to generate target features near the support to minimize the discrepancy. Our method outperforms other methods on several datasets of image classification and semantic segmentation. The codes are available at url {https://github. com/mil-tokyo/MCD_DA}",
        "year": 2018,
        "authors": "Kuniaki Saito and Kohei Watanabe and Yoshitaka Ushiku and Tatsuya Harada"
      },
      {
        "title": "Strong-weak distribution alignment for adaptive object detection",
        "abstract": "We propose an approach for unsupervised adaptation of object detectors from label-rich to label-poor domains which can significantly reduce annotation costs associated with detection. Recently, approaches that align distributions of source and target images using an adversarial loss have been proven effective for adapting object classifiers. However, for object detection, fully matching the entire distributions of source and target images to each other at the global image level may fail, as domains could have distinct scene layouts and different combinations of objects. On the other hand, strong matching of local features such as texture and color makes sense, as it does not change category level semantics. This motivates us to propose a novel method for detector adaptation based on strong local alignment and weak global alignment. Our key contribution is the weak alignment model, which focuses the adversarial alignment loss on images that are globally similar and puts less emphasis on aligning images that are globally dissimilar. Additionally, we design the strong domain alignment model to only look at local receptive fields of the feature map. We empirically verify the effectiveness of our method on four datasets comprising both large and small domain shifts. Our code is available at https://github. com/VisionLearningGroup/DA_Detection.",
        "year": 2019,
        "authors": "Kuniaki Saito and Yoshitaka Ushiku and Tatsuya Harada and Kate Saenko"
      },
      {
        "title": "Semi-supervised domain adaptation via minimax entropy",
        "abstract": "Contemporary domain adaptation methods are very effective at aligning feature distributions of source and target domains without any target supervision. However, we show that these techniques perform poorly when even a few labeled examples are available in the target domain. To address this semi-supervised domain adaptation (SSDA) setting, we propose a novel Minimax Entropy (MME) approach that adversarially optimizes an adaptive few-shot model. Our base model consists of a feature encoding network, followed by a classification layer that computes the features' similarity to estimated prototypes (representatives of each class). Adaptation is achieved by alternately maximizing the conditional entropy of unlabeled target data with respect to the classifier and minimizing it with respect to the feature encoder. We empirically demonstrate the superiority of our method over many baselines, including conventional feature alignment and few-shot methods, setting a new state of the art for SSDA. Our code is available at http://cs-people. bu. edu/keisaito/research/MME. html.",
        "year": 2019,
        "authors": "Kuniaki Saito and Donghyun Kim and Stan Sclaroff and Trevor Darrell and Kate Saenko"
      }
    ],
    "pqP5_PgAAAAJ": [
      {
        "title": "Chain-of-thought prompting elicits reasoning in large language models",
        "abstract": "We explore how generating a chain of thought---a series of intermediate reasoning steps---significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.",
        "year": 2022,
        "authors": "Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Fei Xia and Ed Chi and Quoc V Le and Denny Zhou"
      },
      {
        "title": "Do as i can, not as i say: Grounding language in robotic affordances",
        "abstract": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model’s “hands and eyes,” while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project’s website, video, and open source can be …",
        "year": 2023,
        "authors": "Anthony Brohan and Yevgen Chebotar and Chelsea Finn and Karol Hausman and Alexander Herzog and Daniel Ho and Julian Ibarz and Alex Irpan and Eric Jang and Ryan Julian and Dmitry Kalashnikov and Sergey Levine and Yao Lu and Carolina Parada and Kanishka Rao and Pierre Sermanet and Alexander T Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Mengyuan Yan and Noah Brown and Michael Ahn and Omar Cortes and Nicolas Sievers and Clayton Tan and Sichun Xu and Diego Reyes and Jarek Rettinghouse and Jornell Quiambao and Peter Pastor and Linda Luu and Kuang-Huei Lee and Yuheng Kuang and Sally Jesmonth and Nikhil J Joshi and Kyle Jeffrey and Rosario Jauregui Ruano and Jasmine Hsu and Keerthana Gopalakrishnan and Byron David and Andy Zeng and Chuyuan Kelly Fu"
      },
      {
        "title": "PaLM-E: An Embodied Multimodal Language Model",
        "abstract": "Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.",
        "year": 2023,
        "authors": "Danny Driess and Fei Xia and Mehdi SM Sajjadi and Corey Lynch and Aakanksha Chowdhery and Brian Ichter and Ayzaan Wahid and Jonathan Tompson and Quan Vuong and Tianhe Yu and Wenlong Huang and Yevgen Chebotar and Pierre Sermanet and Daniel Duckworth and Sergey Levine and Vincent Vanhoucke and Karol Hausman and Marc Toussaint and Klaus Greff and Andy Zeng and Igor Mordatch and Pete Florence"
      }
    ],
    "5VaXUQsAAAAJ": [
      {
        "title": "Gemini: a family of highly capable multimodal models",
        "abstract": "This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.",
        "year": 2023,
        "authors": "Gemini Team and Rohan Anil and Sebastian Borgeaud and Yonghui Wu and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M Dai and Anja Hauth and Katie Millican and David Silver and Slav Petrov and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Anaïs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Martin Chadwick and Gaurav Singh Tomar and Xavier Garcia and Evan Senter and Emanuel Taropa and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco and Adrià Puigdomènech Badia and David Reitter and Mianna Chen and Jenny Brennan and Clara Rivera and Sergey Brin and Shariq Iqbal and Gabriela Surita and Jane Labanowski and Abhi Rao and Stephanie Winkler and Emilio Parisotto and Yiming Gu and Kate Olszewska and Yujing Zhang and Ravi Addanki and Antoine Miech and Annie Louis and Laurent El Shafey and Denis Teplyashin and Geoff Brown and Elliot Catt and Nithya Attaluri and Jan Balaguer and Jackie Xiang and Pidong Wang and Zoe Ashwood and Anton Briukhov and Albert Webson and Sanjay Ganapathy and Smit Sanghavi and Ajay Kannan and Ming-Wei Chang and Axel Stjerngren and Josip Djolonga and Yuting Sun and Ankur Bapna and Matthew Aitchison and Pedram Pejman and Henryk Michalewski and Tianhe Yu and Cindy Wang and Juliette Love and Junwhan Ahn"
      },
      {
        "title": "PaLM-E: An Embodied Multimodal Language Model",
        "abstract": "Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.",
        "year": 2023,
        "authors": "Danny Driess and Fei Xia and Mehdi SM Sajjadi and Corey Lynch and Aakanksha Chowdhery and Brian Ichter and Ayzaan Wahid and Jonathan Tompson and Quan Vuong and Tianhe Yu and Wenlong Huang and Yevgen Chebotar and Pierre Sermanet and Daniel Duckworth and Sergey Levine and Vincent Vanhoucke and Karol Hausman and Marc Toussaint and Klaus Greff and Andy Zeng and Igor Mordatch and Pete Florence"
      },
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien MR Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan"
      }
    ],
    "OFlBL2kAAAAJ": [
      {
        "title": "Bc-z: Zero-shot task generalization with robotic imitation learning",
        "abstract": "In this paper, we study the problem of enabling a vision-based robotic manipulation system to generalize to novel tasks, a long-standing challenge in robot learning. We approach the challenge from an imitation learning perspective, aiming to study how scaling and broadening the data collected can facilitate such generalization. To that end, we develop an interactive and flexible imitation learning system that can learn from both demonstrations and interventions and can be conditioned on different forms of information that convey the task, including pre-trained embeddings of natural language or videos of humans performing the task. When scaling data collection on a real robot to more than 100 distinct tasks, we find that this system can perform 24 unseen manipulation tasks with an average success rate of 44%, without any robot demonstrations for those tasks.",
        "year": 2022,
        "authors": "Eric Jang and Alex Irpan and Mohi Khansari and Daniel Kappler and Frederik Ebert and Corey Lynch and Sergey Levine and Chelsea Finn"
      },
      {
        "title": "Stochastic adversarial video prediction",
        "abstract": "Being able to predict what may happen in the future requires an in-depth understanding of the physical and causal rules that govern the world. A model that is able to do so has a number of appealing applications, from robotic planning to representation learning. However, learning to predict raw future observations, such as frames in a video, is exceedingly challenging -- the ambiguous nature of the problem can cause a naively designed model to average together possible futures into a single, blurry prediction. Recently, this has been addressed by two distinct approaches: (a) latent variational variable models that explicitly model underlying stochasticity and (b) adversarially-trained models that aim to produce naturalistic images. However, a standard latent variable model can struggle to produce realistic results, and a standard adversarially-trained model underutilizes latent variables and fails to produce diverse predictions. We show that these distinct methods are in fact complementary. Combining the two produces predictions that look more realistic to human raters and better cover the range of possible futures. Our method outperforms prior and concurrent work in these aspects.",
        "year": 2018,
        "authors": "Alex X Lee and Richard Zhang and Frederik Ebert and Pieter Abbeel and Chelsea Finn and Sergey Levine"
      },
      {
        "title": "Visual foresight: Model-based deep reinforcement learning for vision-based robotic control",
        "abstract": "Deep reinforcement learning (RL) algorithms can learn complex robotic skills from raw sensory inputs, but have yet to achieve the kind of broad generalization and applicability demonstrated by deep learning methods in supervised domains. We present a deep RL method that is practical for real-world robotics tasks, such as robotic manipulation, and generalizes effectively to never-before-seen tasks and objects. In these settings, ground truth reward signals are typically unavailable, and we therefore propose a self-supervised model-based approach, where a predictive model learns to directly predict the future from raw sensory readings, such as camera images. At test time, we explore three distinct goal specification methods: designated pixels, where a user specifies desired object manipulation tasks by selecting particular pixels in an image and corresponding goal positions, goal images, where the desired goal state is specified with an image, and image classifiers, which define spaces of goal states. Our deep predictive models are trained using data collected autonomously and continuously by a robot interacting with hundreds of objects, without human supervision. We demonstrate that visual MPC can generalize to never-before-seen objects---both rigid and deformable---and solve a range of user-defined object manipulation tasks using the same model.",
        "year": 2018,
        "authors": "Frederik Ebert and Chelsea Finn and Sudeep Dasari and Annie Xie and Alex Lee and Sergey Levine"
      }
    ],
    "XCZpOcAAAAAJ": [
      {
        "title": "Intriguing properties of neural networks",
        "abstract": "Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties. First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks. Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.",
        "year": 2013,
        "authors": "Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian Goodfellow and Rob Fergus"
      },
      {
        "title": "Gpt-4 technical report",
        "abstract": "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.",
        "year": 2023,
        "authors": "Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew"
      },
      {
        "title": "Improved techniques for training gans",
        "abstract": "We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: Our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.",
        "year": 2016,
        "authors": "Tim Salimans and Ian Goodfellow and Wojciech Zaremba and Vicki Cheung and Alec Radford and Xi Chen"
      }
    ],
    "FwxfQosAAAAJ": [
      {
        "title": "Sim-to-real transfer of robotic control with dynamics randomization",
        "abstract": "Simulations are attractive environments for training agents as they provide an abundant source of data and alleviate certain safety concerns during the training process. But the behaviours developed by agents in simulation are often specific to the characteristics of the simulator. Due to modeling error, strategies that are successful in simulation may not transfer to their real world counterparts. In this paper, we demonstrate a simple method to bridge this “reality gap”. By randomizing the dynamics of the simulator during training, we are able to develop policies that are capable of adapting to very different dynamics, including ones that differ significantly from the dynamics on which the policies were trained. This adaptivity enables the policies to generalize to the dynamics of the real world without any training on the physical system. Our approach is demonstrated on an object pushing task using a robotic arm. Despite …",
        "year": 2018,
        "authors": "Xue Bin Peng and Marcin Andrychowicz and Wojciech Zaremba and Pieter Abbeel"
      },
      {
        "title": "Deepmimic: Example-guided deep reinforcement learning of physics-based character skills",
        "abstract": "A longstanding goal in character animation is to combine data-driven specification of behavior with a system that can execute a similar behavior in a physical simulation, thus enabling realistic responses to perturbations and environmental variation. We show that well-known reinforcement learning (RL) methods can be adapted to learn robust control policies capable of imitating a broad range of example motion clips, while also learning complex recoveries, adapting to changes in morphology, and accomplishing user-specified goals. Our method handles keyframed motions, highly-dynamic actions such as motion-captured flips and spins, and retargeted motions. By combining a motion-imitation objective with a task objective, we can train characters that react intelligently in interactive settings, e.g., by walking in a desired direction or throwing a ball at a user-specified target. This approach thus combines the …",
        "year": 2018,
        "authors": "Xue Bin Peng and Pieter Abbeel and Sergey Levine and Michiel Van de Panne"
      },
      {
        "title": "Deeploco: Dynamic locomotion skills using hierarchical deep reinforcement learning",
        "abstract": "Learning physics-based locomotion skills is a difficult problem, leading to solutions that typically exploit prior knowledge of various forms. In this paper we aim to learn a variety of environment-aware locomotion skills with a limited amount of prior knowledge. We adopt a two-level hierarchical control framework. First, low-level controllers are learned that operate at a fine timescale and which achieve robust walking gaits that satisfy stepping-target and style objectives. Second, high-level controllers are then learned which plan at the timescale of steps by invoking desired step targets for the low-level controller. The high-level controller makes decisions directly based on high-dimensional inputs, including terrain maps or other suitable representations of the surroundings. Both levels of the control policy are trained using deep reinforcement learning. Results are demonstrated on a simulated 3D biped. Low-level …",
        "year": 2017,
        "authors": "Xue Bin Peng and Glen Berseth and KangKang Yin and Michiel Van De Panne"
      }
    ],
    "UpZmJI0AAAAJ": [
      {
        "title": "Curiosity-driven exploration by self-supervised prediction",
        "abstract": "In many real-world scenarios, rewards extrinsic to the agent are extremely sparse, or absent altogether. In such cases, curiosity can serve as an intrinsic reward signal to enable the agent to explore its environment and learn skills that might be useful later in its life. We formulate curiosity as the error in an agent’s ability to predict the consequence of its own actions in a visual feature space learned by a self-supervised inverse dynamics model. Our formulation scales to high-dimensional continuous state spaces like images, bypasses the difficulties of directly predicting pixels, and, critically, ignores the aspects of the environment that cannot affect the agent. The proposed approach is evaluated in two environments: VizDoom and Super Mario Bros. Three broad settings are investigated: 1) sparse extrinsic reward, where curiosity allows for far fewer interactions with the environment to reach the goal; 2) exploration with no extrinsic reward, where curiosity pushes the agent to explore more efficiently; and 3) generalization to unseen scenarios (eg new levels of the same game) where the knowledge gained from earlier experience helps the agent explore new places much faster than starting from scratch.",
        "year": 2017,
        "authors": "Deepak Pathak and Pulkit Agrawal and Alexei A Efros and Trevor Darrell"
      },
      {
        "title": "Human pose estimation with iterative error feedback",
        "abstract": "Hierarchical feature extractors such as Convolutional Networks (ConvNets) have achieved impressive performance on a variety of classification tasks using purely feedforward processing. Feedforward architectures can learn rich representations of the input space but do not explicitly model dependencies in the output spaces, that are quite structured for tasks such as articulated human pose estimation or object segmentation. Here we propose a framework that expands the expressive power of hierarchical feature extractors to encompass both input and output spaces, by introducing top-down feedback. Instead of directly predicting the outputs in one go, we use a self-correcting model that progressively changes an initial solution by feeding back error predictions, in a process we call Iterative Error Feedback (IEF). IEF shows excellent performance on the task of articulated pose estimation in the challenging MPII and LSP benchmarks, matching the state-of-the-art without requiring ground truth scale annotation.",
        "year": 2016,
        "authors": "Joao Carreira and Pulkit Agrawal and Katerina Fragkiadaki and Jitendra Malik"
      },
      {
        "title": "Fully automated echocardiogram interpretation in clinical practice: feasibility and diagnostic accuracy",
        "abstract": "Automated cardiac image interpretation has the potential to transform clinical practice in multiple ways, including enabling serial assessment of cardiac function by nonexperts in primary care and rural settings. We hypothesized that advances in computer vision could enable building a fully automated, scalable analysis pipeline for echocardiogram interpretation, including (1) view identification, (2) image segmentation, (3) quantification of structure and function, and (4) disease detection.Using 14 035 echocardiograms spanning a 10-year period, we trained and evaluated convolutional neural network models for multiple tasks, including automated identification of 23 viewpoints and segmentation of cardiac chambers across 5 common views. The segmentation output was used to quantify chamber volumes and left ventricular mass, determine ejection fraction, and facilitate automated …",
        "year": 2018,
        "authors": "Jeffrey Zhang and Sravani Gajjala and Pulkit Agrawal and Geoffrey H Tison and Laura A Hallock and Lauren Beussink-Nelson and Mats H Lassen and Eugene Fan and Mandar A Aras and ChaRandle Jordan and Kirsten E Fleischmann and Michelle Melisko and Atif Qasim and Sanjiv J Shah and Ruzena Bajcsy and Rahul C Deo"
      }
    ],
    "Ivot3fkAAAAJ": [
      {
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models",
        "abstract": "DSpace at KOASAS: Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nKOASAS menu About KOASAS KAIST Library 검색 Advanced Search KOASAS About \nKOASAS Open Access Policy Browse Communities & Collections Researchers at KAIST Titles \nSubject By Date rss_1.0 rss_2.0 atom_1.0 sherpa SEARCH DSpace at KOASAS College of \nEngineering(공과대학)Kim Jaechul Graduate School of AI(김재철AI대학원)AI-Conference \nPapers(학술대회논문) Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nCited 0 time in webofscience Cited 0 time in scopus Hit : 2 Download : 0 Export DC(XML) Excel \nLim, Joseph Jaewhanresearcher Publisher IEEE Issue Date 2024-05-15 Citation IEEE \nInternational Conference on Robotics and Automation URI http://hdl.handle.net/10203/326144 \nAppears in Collection AI-Conference Papers(학술대회논문) Files in This Item There are no files …",
        "year": 2024,
        "authors": "Joseph Jaewhan Lim"
      },
      {
        "title": "Learning modular neural network policies for multi-task and multi-robot transfer",
        "abstract": "Reinforcement learning (RL) can automate a wide variety of robotic skills, but learning each new skill requires considerable real-world data collection and manual representation engineering to design policy classes or features. Using deep reinforcement learning to train general purpose neural network policies alleviates some of the burden of manual representation engineering by using expressive policy classes, but exacerbates the challenge of data collection, since such methods tend to be less efficient than RL with low-dimensional, hand-designed representations. Transfer learning can mitigate this problem by enabling us to transfer information from one skill to another and even from one robot to another. We show that neural network policies can be decomposed into “task-specific” and “robot-specific” modules, where the task-specific modules are shared across robots, and the robot-specific modules are …",
        "year": 2017,
        "authors": "Coline Devin and Abhishek Gupta and Trevor Darrell and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Learning invariant feature spaces to transfer skills with reinforcement learning",
        "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where two agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of \"analogy making\", or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.",
        "year": 2017,
        "authors": "Abhishek Gupta and Coline Devin and YuXuan Liu and Pieter Abbeel and Sergey Levine"
      }
    ],
    "wVGqmWkAAAAJ": [
      {
        "title": "Inferring subnetworks from perturbed expression profiles",
        "abstract": "Genome-wide expression profiles of genetic mutants provide   a wide variety of measurements of cellular responses to   perturbations. Typical analysis of such data identifies genes   affected by perturbation and uses clustering to group genes of   similar function. In this paper we discover a finer structure of   interactions between genes, such as causality, mediation, activation,   and inhibition by using a Bayesian network framework. We extend this   framework to correctly handle perturbations, and to identify   significant subnetworks of interacting genes. We apply this method to   expression data of S. cerevisiae mutants and uncover a   variety of structured metabolic, signaling and regulatory   pathways.Contact: danab@cs.huji.ac.il",
        "year": 2001,
        "authors": "Dana Pe’er and Aviv Regev and Gal Elidan and Nir Friedman"
      },
      {
        "title": "Multi-class segmentation with relative location prior",
        "abstract": "Multi-class image segmentation has made significant advances in recent years through the combination of local and global features. One important type of global feature is that of inter-class spatial relationships. For example, identifying “tree” pixels indicates that pixels above and to the sides are more likely to be “sky” whereas pixels below are more likely to be “grass.” Incorporating such global information across the entire image and between all classes is a computational challenge as it is image-dependent, and hence, cannot be precomputed.In this work we propose a method for capturing global information from inter-class spatial relationships and encoding it as a local feature. We employ a two-stage classification process to label all image pixels. First, we generate predictions which are used to compute a local relative location feature from learned relative location maps. In the second stage, we …",
        "year": 2008,
        "authors": "Stephen Gould and Jim Rodgers and David Cohen and Gal Elidan and Daphne Koller"
      },
      {
        "title": "Residual belief propagation: Informed scheduling for asynchronous message passing",
        "abstract": "Inference for probabilistic graphical models is still very much a practical challenge in large domains. The commonly used and effective belief propagation (BP) algorithm and its generalizations often do not converge when applied to hard, real-life inference tasks. While it is widely recognized that the scheduling of messages in these algorithms may have significant consequences, this issue remains largely unexplored. In this work, we address the question of how to schedule messages for asynchronous propagation so that a fixed point is reached faster and more often. We first show that any reasonable asynchronous BP converges to a unique fixed point under conditions similar to those that guarantee convergence of synchronous BP. In addition, we show that the convergence rate of a simple round-robin schedule is at least as good as that of synchronous propagation. We then propose residual belief propagation (RBP), a novel, easy-to-implement, asynchronous propagation algorithm that schedules messages in an informed way, that pushes down a bound on the distance from the fixed point. Finally, we demonstrate the superiority of RBP over state-of-the-art methods for a variety of challenging synthetic and real-life problems: RBP converges significantly more often than other methods; and it significantly reduces running time until convergence, even when other methods converge.",
        "year": 2012,
        "authors": "Gal Elidan and Ian McGraw and Daphne Koller"
      }
    ],
    "1b2kKWoAAAAJ": [
      {
        "title": "G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment",
        "abstract": "The quality of texts generated by natural language generation (NLG) systems is hard to measure automatically. Conventional reference-based metrics, such as BLEU and ROUGE, have been shown to have relatively low correlation with human judgments, especially for tasks that require creativity and diversity. Recent studies suggest using large language models (LLMs) as reference-free metrics for NLG evaluation, which have the benefit of being applicable to new tasks that lack human references. However, these LLM-based evaluators still have lower human correspondence than medium-size neural evaluators. In this work, we present G-Eval, a framework of using large language models with chain-of-thoughts (CoT) and a form-filling paradigm, to assess the quality of NLG outputs. We experiment with two generation tasks, text summarization and dialogue generation. We show that G-Eval with GPT-4 as the backbone model achieves a Spearman correlation of 0.514 with human on summarization task, outperforming all previous methods by a large margin. We also propose preliminary analysis on the behavior of LLM-based evaluators, and highlight the potential issue of LLM-based evaluators having a bias towards the LLM-generated texts. The code is at https://github.com/nlpyang/geval",
        "year": 2023,
        "authors": "Yang Liu and Dan Iter and Yichong Xu and Shuohang Wang and Ruochen Xu and Chenguang Zhu"
      },
      {
        "title": "Information diffusion and external influence in networks",
        "abstract": "Social networks play a fundamental role in the diffusion of information. However, there are two different ways of how information reaches a person in a network. Information reaches us through connections in our social networks, as well as through the influence external out-of-network sources, like the mainstream media. While most present models of information adoption in networks assume information only passes from a node to node via the edges of the underlying network, the recent availability of massive online social media data allows us to study this process in more detail.We present a model in which information can reach a node via the links of the social network or through the influence of external sources. We then develop an efficient model parameter fitting technique and apply the model to the emergence of URL mentions in the Twitter network. Using a complete one month trace of Twitter we study how …",
        "year": 2012,
        "authors": "Seth A Myers and Chenguang Zhu and Jure Leskovec"
      },
      {
        "title": "An empirical study of training end-to-end vision-and-language transformers",
        "abstract": "Vision-and-language (VL) pre-training has proven to be highly effective on various VL downstream tasks. While recent work has shown that fully transformer-based VL models can be more efficient than previous region-feature-based methods, their performance on downstream tasks often degrades significantly. In this paper, we present METER, a Multimodal End-to-end TransformER framework, through which we investigate how to design and pre-train a fully transformer-based VL model in an end-to-end manner. Specifically, we dissect the model designs along multiple dimensions: vision encoders (eg, CLIP-ViT, Swin transformer), text encoders (eg, RoBERTa, DeBERTa), multimodal fusion module (eg, merged attention vs. co-attention), architectural design (eg, encoder-only vs. encoder-decoder), and pre-training objectives (eg, masked image modeling). We conduct comprehensive experiments and provide insights on how to train a performant VL transformer while maintaining fast inference speed. Notably, our best model achieves an accuracy of 77.64% on the VQAv2 test-std set using only 4M images for pre-training, surpassing the state-of-the-art region-feature-based model by 1.04%, and outperforming the previous best fully transformer-based model by 1.6%.",
        "year": 2022,
        "authors": "Zi-Yi Dou and Yichong Xu and Zhe Gan and Jianfeng Wang and Shuohang Wang and Lijuan Wang and Chenguang Zhu and Pengchuan Zhang and Lu Yuan and Nanyun Peng and Zicheng Liu and Michael Zeng"
      }
    ],
    "xBH73TYAAAAJ": [
      {
        "title": "Gemini: a family of highly capable multimodal models",
        "abstract": "This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.",
        "year": 2023,
        "authors": "Gemini Team and Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M Dai and Anja Hauth and Katie Millican and David Silver and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Jack Krawczyk and Cosmo Du and Ed Chi and Heng-Tze Cheng and Eric Ni and Purvi Shah and Patrick Kane and Betty Chan and Manaal Faruqui and Aliaksei Severyn and Hanzhao Lin and YaGuang Li and Yong Cheng and Abe Ittycheriah and Mahdis Mahdieh and Mia Chen and Pei Sun and Dustin Tran and Sumit Bagri and Balaji Lakshminarayanan and Jeremiah Liu and Andras Orban and Fabian Güra and Hao Zhou and Xinying Song and Aurelien Boffy and Harish Ganapathy and Steven Zheng and HyunJeong Choe and Ágoston Weisz and Tao Zhu and Yifeng Lu and Siddharth Gopal and Jarrod Kahn and Maciej Kula and Jeff Pitman and Rushin Shah and Emanuel Taropa and Majd Al Merey and Martin Baeuml and Zhifeng Chen and Laurent El Shafey and Yujing Zhang and Olcan Sercinoglu and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Anaïs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Gaurav Singh Tomar and Evan Senter and Martin Chadwick and Ilya Kornakov and Nithya Attaluri and Iñaki Iturrate and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Xavier Garcia and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco"
      },
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien MR Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan"
      },
      {
        "title": "Entity abstraction in visual model-based reinforcement learning",
        "abstract": "We present OP3, a framework for model-based reinforcement learning that acquires object representations from raw visual observations without supervision and uses them to predict and plan. To ground these abstract representations of entities to actual objects in the world, we formulate an interactive inference algorithm which incorporates dynamic information in the scene. Our model can handle a variable number of entities by symmetrically processing each object representation with the same locally-scoped function. On block-stacking tasks, OP3 can generalize to novel block configurations and more objects than seen during training, outperforming both a model that assumes access to object supervision and a state-of-the-art video prediction model.",
        "year": 2020,
        "authors": "Rishi Veerapaneni and John D Co-Reyes and Michael Chang and Michael Janner and Chelsea Finn and Jiajun Wu and Joshua Tenenbaum and Sergey Levine"
      }
    ],
    "0jSdqoEAAAAJ": [
      {
        "title": "Social robots for education: A review",
        "abstract": "Social robots can be used in education as tutors or peer learners. They have been shown to be effective at increasing cognitive and affective outcomes and have achieved outcomes similar to those of human tutoring on restricted tasks. This is largely because of their physical presence, which traditional learning technologies lack. We review the potential of social robots in education, discuss the technical challenges, and consider how the robot’s appearance and behavior affect learning outcomes.",
        "year": 2018,
        "authors": "Tony Belpaeme and James Kennedy and Aditi Ramachandran and Brian Scassellati and Fumihide Tanaka"
      },
      {
        "title": "The grand challenges of Science Robotics",
        "abstract": "One of the ambitions of Science Robotics is to deeply root robotics research in science while developing novel robotic platforms that will enable new scientific discoveries. Of our 10 grand challenges, the first 7 represent underpinning technologies that have a wider impact on all application areas of robotics. For the next two challenges, we have included social robotics and medical robotics as application-specific areas of development to highlight the substantial societal and health impacts that they will bring. Finally, the last challenge is related to responsible innovation and how ethics and security should be carefully considered as we develop the technology further.",
        "year": 2018,
        "authors": "Guang-Zhong Yang and Jim Bellingham and Pierre E Dupont and Peer Fischer and Luciano Floridi and Robert Full and Neil Jacobstein and Vijay Kumar and Marcia McNutt and Robert Merrifield and Bradley J Nelson and Brian Scassellati and Mariarosaria Taddeo and Russell Taylor and Manuela Veloso and Zhong Lin Wang and Robert Wood"
      },
      {
        "title": "Robots for use in autism research",
        "abstract": "Autism spectrum disorders are a group of lifelong disabilities that affect people's ability to communicate and to understand social cues. Research into applying robots as therapy tools has shown that robots seem to improve engagement and elicit novel social behaviors from people (particularly children and teenagers) with autism. Robot therapy for autism has been explored as one of the first application domains in the field of socially assistive robotics (SAR), which aims to develop robots that assist people with special needs through social interactions. In this review, we discuss the past decade's work in SAR systems designed for autism therapy by analyzing robot design decisions, human-robot interactions, and system evaluations. We conclude by discussing challenges and future trends for this young but rapidly developing research area.",
        "year": 2012,
        "authors": "Brian Scassellati and Henny Admoni and Maja Matarić"
      }
    ],
    "I1EvjZsAAAAJ": [
      {
        "title": "A view of cloud computing",
        "abstract": "Clearing the clouds away from the true potential and obstacles posed by this computing capability.",
        "year": 2010,
        "authors": "Michael Armbrust and Armando Fox and Rean Griffith and Anthony D Joseph and Randy Katz and Andy Konwinski and Gunho Lee and David Patterson and Ariel Rabkin and Ion Stoica and Matei Zaharia"
      },
      {
        "title": "Spark: Cluster computing with working sets",
        "abstract": "MapReduce and its variants have been highly successful in implementing large-scale data-intensive applications on commodity clusters. However, most of these systems are built around an acyclic data flow model that is not suitable for other popular applications. This paper focuses on one such class of applications: those that reuse a working set of data across multiple parallel operations. This includes many iterative machine learning algorithms, as well as interactive data analysis tools. We propose a new framework called Spark that supports these applications while retaining the scalability and fault tolerance of MapReduce. To achieve these goals, Spark introduces an abstraction called resilient distributed datasets (RDDs). An RDD is a read-only collection of objects partitioned across a set of machines that can be rebuilt if a partition is lost. Spark can outperform Hadoop by 10x in iterative machine learning jobs, and can be used to interactively query a 39 GB dataset with sub-second response time.",
        "year": 2010,
        "authors": "Matei Zaharia and Mosharaf Chowdhury and Michael J Franklin and Scott Shenker and Ion Stoica"
      },
      {
        "title": "Above the clouds: A berkeley view of cloud computing",
        "abstract": "Cloud Computing, the long-held dream of computing as a utility, has the potential to transform a large part of the IT industry, making software even more attractive as a service and shaping the way IT hardware is designed and purchased. Developers with innovative ideas for new Internet services no longer require the large capital outlays in hardware to deploy their service or the human expense to operate it. They need not be concerned about overprovisioning for a service whose popularity does not meet their predictions, thus wasting costly resources, or underprovisioning for one that becomes wildly popular, thus missing potential customers and revenue. Moreover, companies with large batch-oriented tasks can get results as quickly as their programs can scale, since using 1000 servers for one hour costs no more than using one server for 1000 hours. This elasticity of resources, without paying a premium for large scale, is unprecedented in the history of IT.Cloud Computing refers to both the applications delivered as services over the Internet and the hardware and systems software in the datacenters that provide those services. The services themselves have long been referred to as Software as a Service (SaaS). The datacenter hardware and software is what we will call a Cloud. When a Cloud is made available in a pay-as-you-go manner to the general public, we call it a Public Cloud; the service being sold is Utility Computing. We use the term Private Cloud to refer to internal datacenters of a business or other organization, not made available to the general public. Thus, Cloud Computing is the sum of SaaS and Utility Computing, but does not …",
        "year": 2009,
        "authors": "Michael Armbrust and Armando Fox and Rean Griffith and Anthony D Joseph and Randy H Katz and Andrew Konwinski and Gunho Lee and David A Patterson and Ariel Rabkin and Ion Stoica and Matei Zaharia"
      }
    ],
    "JwiByPoAAAAJ": [
      {
        "title": "Joint learning of named entity recognition and entity linking",
        "abstract": "Named entity recognition (NER) and entity linking (EL) are two fundamentally related tasks, since in order to perform EL, first the mentions to entities have to be detected. However, most entity linking approaches disregard the mention detection part, assuming that the correct mentions have been previously detected. In this paper, we perform joint learning of NER and EL to leverage their relatedness and obtain a more robust and generalisable system. For that, we introduce a model inspired by the Stack-LSTM approach (Dyer et al., 2015). We observe that, in fact, doing multi-task learning of NER and EL improves the performance in both tasks when comparing with models trained with individual objectives. Furthermore, we achieve results competitive with the state-of-the-art in both NER and EL.",
        "year": 2019,
        "authors": "Pedro Henrique Martins and Zita Marinho and André FT Martins"
      },
      {
        "title": "-former: Infinite Memory Transformer",
        "abstract": "Transformers are unable to model long-term memories effectively, since the amount of computation they need to perform grows with the context length. While variations of efficient transformers have been proposed, they all have a finite memory capacity and are forced to drop old information. In this paper, we propose the -former, which extends the vanilla transformer with an unbounded long-term memory. By making use of a continuous-space attention mechanism to attend over the long-term memory, the -former's attention complexity becomes independent of the context length, trading off memory length with precision. In order to control where precision is more important, -former maintains \"sticky memories\" being able to model arbitrarily long contexts while keeping the computation budget fixed. Experiments on a synthetic sorting task, language modeling, and document grounded dialogue generation demonstrate the -former's ability to retain information from long sequences.",
        "year": 2021,
        "authors": "Pedro Henrique Martins and Zita Marinho and André FT Martins"
      },
      {
        "title": "Functional gradient motion planning in reproducing kernel hilbert spaces",
        "abstract": "We introduce a functional gradient descent trajectory optimization algorithm for robot motion planning in Reproducing Kernel Hilbert Spaces (RKHSs). Functional gradient algorithms are a popular choice for motion planning in complex many-degree-of-freedom robots, since they (in theory) work by directly optimizing within a space of continuous trajectories to avoid obstacles while maintaining geometric properties such as smoothness. However, in practice, functional gradient algorithms typically commit to a fixed, finite parameterization of trajectories, often as a list of waypoints. Such a parameterization can lose much of the benefit of reasoning in a continuous trajectory space: e.g., it can require taking an inconveniently small step size and large number of iterations to maintain smoothness. Our work generalizes functional gradient trajectory optimization by formulating it as minimization of a cost functional in an RKHS. This generalization lets us represent trajectories as linear combinations of kernel functions, without any need for waypoints. As a result, we are able to take larger steps and achieve a locally optimal trajectory in just a few iterations. Depending on the selection of kernel, we can directly optimize in spaces of trajectories that are inherently smooth in velocity, jerk, curvature, etc., and that have a low-dimensional, adaptively chosen parameterization. Our experiments illustrate the effectiveness of the planner for different kernels, including Gaussian RBFs, Laplacian RBFs, and B-splines, as compared to the standard discretized waypoint representation.",
        "year": 2016,
        "authors": "Zita Marinho and Anca Dragan and Arun Byravan and Byron Boots and Siddhartha Srinivasa and Geoffrey Gordon"
      }
    ],
    "7c1B_fIAAAAJ": [
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Machel Reid and Nikolay Savinov and Denis Teplyashin and Dmitry Lepikhin and Sherry Yang and Timothy Lillicrap and Jean-baptiste Alayrac and Radu Soricut and Angeliki Lazaridou and Orhan Firat and Julian Schrittwieser and Ioannis Antonoglou and Rohan Anil and Sebastian Borgeaud and Andrew Dai and Katie Millican and Ethan Dyer and Mia Glaese and Thibault Sottiaux and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and James Molloy and Jilin Chen and Michael Isard and Paul Barham and Tom Hennigan and Ross McIlroy and Melvin Johnson and Johan Schalkwyk and Eli Collins and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Clemens Meyer and Gregory Thornton and Zhen Yang and Henryk Michalewski and Zaheer Abbas and Nathan Schucher and Ankesh Anand and Richard Ives and James Keeling and Karel Lenc and Salem Haykal and Siamak Shakeri and Pranav Shyam and Aakanksha Chowdhery and Roman Ring and Stephen Spencer and Eren Sezener and Luke Vilnis and Oscar Chang and Nobuyuki Morioka and George Tucker and Ce Zheng and Oliver Woodman and Nithya Attaluri and Tomas Kocisky"
      },
      {
        "title": "Multi-game decision transformers",
        "abstract": "A longstanding goal of the field of AI is a method for learning a highly capable, generalist agent from diverse experience. In the subfields of vision and language, this was largely achieved by scaling up transformer-based models and training them on large, diverse datasets. Motivated by this progress, we investigate whether the same strategy can be used to produce generalist reinforcement learning agents. Specifically, we show that a single transformer-based model–with a single set of weights–trained purely offline can play a suite of up to 46 Atari games simultaneously at close-to-human performance. When trained and evaluated appropriately, we find that the same trends observed in language and vision hold, including scaling of performance with model size and rapid adaptation to new games via fine-tuning. We compare several approaches in this multi-game setting, such as online and offline RL methods and behavioral cloning, and find that our Multi-Game Decision Transformer models offer the best scalability and performance. We release the pre-trained models and code to encourage further research in this direction.",
        "year": 2022,
        "authors": "Kuang-Huei Lee and Ofir Nachum and Sherry Yang and Lisa Lee and Daniel Freeman and Sergio Guadarrama and Ian Fischer and Winnie Xu and Eric Jang and Henryk Michalewski and Igor Mordatch"
      },
      {
        "title": "Learning Universal Policies via Text-Guided Video Generation",
        "abstract": "A goal of artificial intelligence is to construct an agent that can solve a wide variety of tasks. Recent progress in text-guided image synthesis has yielded models with an impressive ability to generate complex novel images, exhibiting combinatorial generalization across domains. Motivated by this success, we investigate whether such tools can be used to construct more general-purpose agents. Specifically, we cast the sequential decision making problem as a text-conditioned video generation problem, where, given a text-encoded specification of a desired goal, a planner synthesizes a set of future frames depicting its planned actions in the future, after which control actions are extracted from the generated video. By leveraging text as the underlying goal specification, we are able to naturally and combinatorially generalize to novel goals. The proposed policy-as-video formulation can further represent environments with different state and action spaces in a unified space of images, which, for example, enables learning and generalization across a variety of robot manipulation tasks. Finally, by leveraging pretrained language embeddings and widely available videos from the internet, the approach enables knowledge transfer through predicting highly realistic video plans for real robots.",
        "year": 2023,
        "authors": "Yilun Du* and Sherry Yang* and Bo Dai and Hanjun Dai and Ofir Nachum and Josh Tenenbaum and Dale Schuurmans and Pieter Abbeel"
      }
    ],
    "8jVzL_YAAAAJ": [
      {
        "title": "The landscape of genetic content in the gut and oral human microbiome",
        "abstract": "Despite substantial interest in the species diversity of the human microbiome and its role in disease, the scale of its genetic diversity, which is fundamental to deciphering human-microbe interactions, has not been quantified. Here, we conducted a cross-study meta-analysis of metagenomes from two human body niches, the mouth and gut, covering 3,655 samples from 13 studies. We found staggering genetic heterogeneity in the dataset, identifying a total of 45,666,334 non-redundant genes (23,961,508 oral and 22,254,436 gut) at the 95% identity level. Fifty percent of all genes were \"singletons,\" or unique to a single metagenomic sample. Singletons were enriched for different functions (compared with non-singletons) and arose from sub-population-specific microbial strains. Overall, these results provide potential bases for the unexplained heterogeneity observed in microbiome-derived human phenotypes. One …",
        "year": 2019,
        "authors": "Braden T Tierney and Zhen Yang and Jacob M Luber and Marc Beaudin and Marsha C Wibowo and Christina Baek and Eleanor Mehlenbacher and Chirag J Patel and Aleksandar D Kostic"
      },
      {
        "title": "Assessing generalization of SGD via disagreement",
        "abstract": "We empirically show that the test error of deep networks can be estimated by simply training the same architecture on the same training set but with a different run of Stochastic Gradient Descent (SGD), and measuring the disagreement rate between the two networks on unlabeled test data. This builds on -- and is a stronger version of -- the observation in Nakkiran & Bansal '20, which requires the second run to be on an altogether fresh training set. We further theoretically show that this peculiar phenomenon arises from the \\emph{well-calibrated} nature of \\emph{ensembles} of SGD-trained models. This finding not only provides a simple empirical measure to directly predict the test error using unlabeled test data, but also establishes a new conceptual connection between generalization and calibration.",
        "year": 2021,
        "authors": "Yiding Jiang and Vaishnavh Nagarajan and Christina Baek and J Zico Kolter"
      },
      {
        "title": "Agreement-on-the-line: Predicting the performance of neural networks under distribution shift",
        "abstract": "Recently, Miller et al. showed that a model's in-distribution (ID) accuracy has a strong linear correlation with its out-of-distribution (OOD) accuracy, on several OOD benchmarks, a phenomenon they dubbed``accuracy-on-the-line''. While a useful tool for model selection (ie, the model most likely to perform the best OOD is the one with highest ID accuracy), this fact does not help to estimate the actual OOD performance of models without access to a labeled OOD validation set. In this paper, we show a similar surprising phenomena also holds for the agreement between pairs of neural network classifiers: whenever accuracy-on-the-line holds, we observe that the OOD agreement between the predictions of any two pairs of neural networks (with potentially different architectures) also observes a strong linear correlation with their ID agreement. Furthermore, we observe that the slope and bias of OOD vs ID agreement closely matches that of OOD vs ID accuracy. This phenomenon which we call agreement-on-the-line, has important practical applications: without any labeled data, we can predict the OOD accuracy of classifiers, since OOD agreement can be estimated with just unlabeled data. Our prediction algorithm outperforms previous methods both in shifts where agreement-on-the-line holds and, surprisingly, when accuracy is not on the line. This phenomenon also provides new insights into neural networks: unlike accuracy-on-the-line, agreement-on-the-line only appears to hold for neural network classifiers.",
        "year": 2022,
        "authors": "Christina Baek and Yiding Jiang and Aditi Raghunathan and J Zico Kolter"
      }
    ],
    "vYougn0AAAAJ": [
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien MR Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan"
      },
      {
        "title": "Real-time user-guided image colorization with learned deep priors",
        "abstract": "We propose a deep learning approach for user-guided image colorization. The system directly maps a grayscale image, along with sparse, local user \"hints\" to an output colorization with a Convolutional Neural Network (CNN). Rather than using hand-defined rules, the network propagates user edits by fusing low-level cues along with high-level semantic information, learned from large-scale data. We train on a million images, with simulated user inputs. To guide the user towards efficient input selection, the system recommends likely colors based on the input image and current user inputs. The colorization is performed in a single feed-forward pass, enabling real-time use. Even with randomly simulated user inputs, we show that the proposed system helps novice users quickly create realistic colorizations, and offers large improvements in colorization quality with just a minute of use. In addition, we demonstrate that the framework can incorporate other user \"hints\" to the desired colorization, showing an application to color histogram transfer. Our code and models are available at https://richzhang.github.io/ideepcolor.",
        "year": 2017,
        "authors": "Richard Zhang and Jun-Yan Zhu and Phillip Isola and Xinyang Geng and Angela S Lin and Tianhe Yu and Alexei A Efros"
      },
      {
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models",
        "abstract": "DSpace at KOASAS: Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nKOASAS menu About KOASAS KAIST Library 검색 Advanced Search KOASAS About \nKOASAS Open Access Policy Browse Communities & Collections Researchers at KAIST Titles \nSubject By Date rss_1.0 rss_2.0 atom_1.0 sherpa SEARCH DSpace at KOASAS College of \nEngineering(공과대학)Kim Jaechul Graduate School of AI(김재철AI대학원)AI-Conference \nPapers(학술대회논문) Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nCited 0 time in webofscience Cited 0 time in scopus Hit : 2 Download : 0 Export DC(XML) Excel \nLim, Joseph Jaewhanresearcher Publisher IEEE Issue Date 2024-05-15 Citation IEEE \nInternational Conference on Robotics and Automation URI http://hdl.handle.net/10203/326144 \nAppears in Collection AI-Conference Papers(학술대회논문) Files in This Item There are no files …",
        "year": 2024,
        "authors": "Joseph Jaewhan Lim"
      }
    ],
    "CUlqK5EAAAAJ": [
      {
        "title": "Scene parsing through ade20k dataset",
        "abstract": "Scene parsing, or recognizing and segmenting objects and stuff in an image, is one of the key problems in computer vision. Despite the community's efforts in data collection, there are still few image datasets covering a wide range of scenes and object categories with dense and detailed annotations for scene parsing. In this paper, we introduce and analyze the ADE20K dataset, spanning diverse annotations of scenes, objects, parts of objects, and in some cases even parts of parts. A scene parsing benchmark is built upon the ADE20K with 150 object and stuff classes included. Several segmentation baseline models are evaluated on the benchmark. A novel network design called Cascade Segmentation Module is proposed to parse a scene into stuff, objects, and object parts in a cascade and improve over the baselines. We further show that the trained scene parsing networks can lead to applications such as image content removal and scene synthesis (Dataset and pretrained models are available at http://groups. csail. mit. edu/vision/datasets/ADE20K/).",
        "year": 2017,
        "authors": "Bolei Zhou and Hang Zhao and Xavier Puig and Sanja Fidler and Adela Barriuso and Antonio Torralba"
      },
      {
        "title": "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books",
        "abstract": "Books are a rich source of both fine-grained information, how a character, an object or a scene looks like, as well as high-level semantics, what someone is thinking, feeling and how these states evolve through a story. This paper aims to align books to their movie releases in order to provide rich descriptive explanations for visual content that go semantically far beyond the captions available in the current datasets. To align movies and books we propose a neural sentence embedding that is trained in an unsupervised way from a large corpus of books, as well as a video-text neural embedding for computing similarities between movie clips and sentences in the book. We propose a context-aware CNN to combine information from multiple sources. We demonstrate good quantitative performance for movie/book alignment and show several qualitative examples that showcase the diversity of tasks our model can be used for.",
        "year": 2015,
        "authors": "Yukun Zhu and Ryan Kiros and Rich Zemel and Ruslan Salakhutdinov and Raquel Urtasun and Antonio Torralba and Sanja Fidler"
      },
      {
        "title": "Skip-thought vectors",
        "abstract": "We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoder-decoder model that tries to reconstruct the surrounding sentences of an encoded passage. Sentences that share semantic and syntactic properties are thus mapped to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness, paraphrase detection, image-sentence ranking, question-type classification and 4 benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf encoder that can produce highly generic sentence representations that are robust and perform well in practice. We will make our encoder publicly available.",
        "year": 2015,
        "authors": "Ryan Kiros and Yukun Zhu and Russ R Salakhutdinov and Richard Zemel and Raquel Urtasun and Antonio Torralba and Sanja Fidler"
      }
    ],
    "qWak04oAAAAJ": [
      {
        "title": "Knowledge vault: A web-scale approach to probabilistic knowledge fusion",
        "abstract": "Recent years have witnessed a proliferation of large-scale knowledge bases, including Wikipedia, Freebase, YAGO, Microsoft's Satori, and Google's Knowledge Graph. To increase the scale even further, we need to explore automatic methods for constructing knowledge bases. Previous approaches have primarily focused on text-based extraction, which can be very noisy. Here we introduce Knowledge Vault, a Web-scale probabilistic knowledge base that combines extractions from Web content (obtained via analysis of text, tabular data, page structure, and human annotations) with prior knowledge derived from existing knowledge repositories. We employ supervised machine learning methods for fusing these distinct information sources. The Knowledge Vault is substantially bigger than any previously published structured knowledge repository, and features a probabilistic inference system that computes …",
        "year": 2014,
        "authors": "Xin Dong and Evgeniy Gabrilovich and Geremy Heitz and Wilko Horn and Ni Lao and Kevin Murphy and Thomas Strohmann and Shaohua Sun and Wei Zhang"
      },
      {
        "title": "Learning spatial context: Using stuff to find things",
        "abstract": "The sliding window approach of detecting rigid objects (such as cars) is predicated on the belief that the object can be identified from the appearance in a small region around the object. Other types of objects of amorphous spatial extent (e.g., trees, sky), however, are more naturally classified based on texture or color. In this paper, we seek to combine recognition of these two types of objects into a system that leverages “context” toward improving detection. In particular, we cluster image regions based on their ability to serve as context for the detection of objects. Rather than providing an explicit training set with region labels, our method automatically groups regions based on both their appearance and their relationships to the detections in the image. We show that our things and stuff (TAS) context model produces meaningful clusters that are readily interpretable, and helps improve our detection ability …",
        "year": 2008,
        "authors": "Geremy Heitz and Daphne Koller"
      },
      {
        "title": "Discriminative learning of markov random fields for segmentation of 3d scan data",
        "abstract": "We address the problem of segmenting 3D scan data into objects or object classes. Our segmentation framework is based on a subclass of Markov random fields (MRFs) which support efficient graph-cut inference. The MRF models incorporate a large set of diverse features and enforce the preference that adjacent scan points have the same classification label. We use a recently proposed maximum-margin framework to discriminatively train the model from a set of labeled scans; as a result we automatically learn the relative importance of the features for the segmentation task. Performing graph-cut inference in the trained MRF can then be used to segment new scenes very efficiently. We test our approach on three large-scale datasets produced by different kinds of 3D sensors, showing its applicability to both outdoor and indoor environments containing diverse objects.",
        "year": 2005,
        "authors": "Dragomir Anguelov and B Taskarf and Vassil Chatalbashev and Daphne Koller and Dinkar Gupta and Geremy Heitz and Andrew Ng"
      }
    ],
    "bMZFLZ_V4goC": [
      {
        "title": "Agile autonomous driving using end-to-end deep imitation learning",
        "abstract": "We present an end-to-end imitation learning system for agile, off-road autonomous driving using only low-cost sensors. By imitating a model predictive controller equipped with advanced sensors, we train a deep neural network control policy to map raw, high-dimensional observations to continuous steering and throttle commands. Compared with recent approaches to similar tasks, our method requires neither state estimation nor on-the-fly planning to navigate the vehicle. Our approach relies on, and experimentally validates, recent imitation learning theory. Empirically, we show that policies trained with online imitation learning overcome well-known challenges related to covariate shift and generalize better than policies trained with batch imitation learning. Built on these insights, our autonomous driving system demonstrates successful high-speed off-road driving, matching the state-of-the-art performance.",
        "year": 2018,
        "authors": "Yunpeng Pan and Ching-An Cheng and Kamil Saigol and Keuntak Lee and Xinyan Yan and Evangelos Theodorou and Byron Boots"
      },
      {
        "title": "Bellman-consistent pessimism for offline reinforcement learning",
        "abstract": "The use of pessimism, when reasoning about datasets lacking exhaustive exploration has recently gained prominence in offline reinforcement learning. Despite the robustness it adds to the algorithm, overly pessimistic reasoning can be equally damaging in precluding the discovery of good policies, which is an issue for the popular bonus-based pessimism. In this paper, we introduce the notion of Bellman-consistent pessimism for general function approximation: instead of calculating a point-wise lower bound for the value function, we implement pessimism at the initial state over the set of functions consistent with the Bellman equations. Our theoretical guarantees only require Bellman closedness as standard in the exploratory setting, in which case bonus-based pessimism fails to provide guarantees. Even in the special case of linear function approximation where stronger expressivity assumptions hold, our result improves upon a recent bonus-based approach by  in its sample complexity (when the action space is finite). Remarkably, our algorithms automatically adapt to the best bias-variance tradeoff in the hindsight, whereas most prior approaches require tuning extra hyperparameters a priori.",
        "year": 2021,
        "authors": "Tengyang Xie and Ching-An Cheng and Nan Jiang and Paul Mineiro and Alekh Agarwal"
      },
      {
        "title": "Truncated back-propagation for bilevel optimization",
        "abstract": "Bilevel optimization has been recently revisited for designing and analyzing algorithms in hyperparameter tuning and meta learning tasks. However, due to its nested structure, evaluating exact gradients for high-dimensional problems is computationally challenging. One heuristic to circumvent this difficulty is to use the approximate gradient given by performing truncated back-propagation through the iterative optimization procedure that solves the lower-level problem. Although promising empirical performance has been reported, its theoretical properties are still unclear. In this paper, we analyze the properties of this family of approximate gradients and establish sufficient conditions for convergence. We validate this on several hyperparameter tuning and meta learning tasks. We find that optimization with the approximate gradient computed using few-step back-propagation often performs comparably to optimization with the exact gradient, while requiring far less memory and half the computation time.",
        "year": 2019,
        "authors": "Amirreza Shaban and Ching-An Cheng and Nathan Hatch and Byron Boots"
      }
    ],
    "dD7EpwQAAAAJ": [
      {
        "title": "Scaling llm test-time compute optimally can be more effective than scaling model parameters",
        "abstract": "Enabling LLMs to improve their outputs by using more test-time computation is a critical step towards building generally self-improving agents that can operate on open-ended natural language. In this paper, we study the scaling of inference-time computation in LLMs, with a focus on answering the question: if an LLM is allowed to use a fixed but non-trivial amount of inference-time compute, how much can it improve its performance on a challenging prompt? Answering this question has implications not only on the achievable performance of LLMs, but also on the future of LLM pretraining and how one should tradeoff inference-time and pre-training compute. Despite its importance, little research attempted to understand the scaling behaviors of various test-time inference methods. Moreover, current work largely provides negative results for a number of these strategies. In this work, we analyze two primary mechanisms to scale test-time computation: (1) searching against dense, process-based verifier reward models; and (2) updating the model's distribution over a response adaptively, given the prompt at test time. We find that in both cases, the effectiveness of different approaches to scaling test-time compute critically varies depending on the difficulty of the prompt. This observation motivates applying a \"compute-optimal\" scaling strategy, which acts to most effectively allocate test-time compute adaptively per prompt. Using this compute-optimal strategy, we can improve the efficiency of test-time compute scaling by more than 4x compared to a best-of-N baseline. Additionally, in a FLOPs-matched evaluation, we find that on problems where a smaller …",
        "year": 2024,
        "authors": "Charlie Snell and Jaehoon Lee and Kelvin Xu and Aviral Kumar"
      },
      {
        "title": "The false promise of imitating proprietary llms",
        "abstract": "An emerging method to cheaply improve a weaker language model is to finetune it on outputs from a stronger model, such as a proprietary system like ChatGPT (e.g., Alpaca, Self-Instruct, and others). This approach looks to cheaply imitate the proprietary model's capabilities using a weaker open-source model. In this work, we critically analyze this approach. We first finetune a series of LMs that imitate ChatGPT using varying base model sizes (1.5B--13B), data sources, and imitation data amounts (0.3M--150M tokens). We then evaluate the models using crowd raters and canonical NLP benchmarks. Initially, we were surprised by the output quality of our imitation models -- they appear far better at following instructions, and crowd workers rate their outputs as competitive with ChatGPT. However, when conducting more targeted automatic evaluations, we find that imitation models close little to none of the gap from the base LM to ChatGPT on tasks that are not heavily supported in the imitation data. We show that these performance discrepancies may slip past human raters because imitation models are adept at mimicking ChatGPT's style but not its factuality. Overall, we conclude that model imitation is a false promise: there exists a substantial capabilities gap between open and closed LMs that, with current methods, can only be bridged using an unwieldy amount of imitation data or by using more capable base LMs. In turn, we argue that the highest leverage action for improving open-source models is to tackle the difficult challenge of developing better base LMs, rather than taking the shortcut of imitating proprietary systems.",
        "year": 2023,
        "authors": "Arnav Gudibande and Eric Wallace and Charlie Snell and Xinyang Geng and Hao Liu and Pieter Abbeel and Sergey Levine and Dawn Song"
      },
      {
        "title": "Offline rl for natural language generation with implicit language q learning",
        "abstract": "Large language models distill broad knowledge from text corpora. However, they can be inconsistent when it comes to completing user specified tasks. This issue can be addressed by finetuning such models via supervised learning on curated datasets, or via reinforcement learning. In this work, we propose a novel offline RL method, implicit language Q-learning (ILQL), designed for use on language models, that combines both the flexible utility maximization framework of RL algorithms with the ability of supervised learning to leverage previously collected data, as well as its simplicity and stability. Our method employs a combination of value conservatism alongside an implicit dataset support constraint in learning value functions, which are then used to guide language model generations towards maximizing user-specified utility functions. In addition to empirically validating ILQL, we present a detailed empirical analysis of situations where offline RL can be useful in natural language generation settings, demonstrating how it can be a more effective utility optimizer than prior approaches for end-to-end dialogue, and how it can effectively optimize high variance reward functions based on subjective judgement, such as whether to label a comment as toxic or not.",
        "year": 2022,
        "authors": "Charlie Snell and Ilya Kostrikov and Yi Su and Mengjiao Yang and Sergey Levine"
      }
    ],
    "kukA0LcAAAAJ": [
      {
        "title": "Generative adversarial nets",
        "abstract": "We propose a new framework for estimating generative models via adversarial nets, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitatively evaluation of the generated samples.",
        "year": 2014,
        "authors": "Ian J Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio"
      },
      {
        "title": "Deep learning",
        "abstract": "Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.",
        "year": 2015,
        "authors": "Yann LeCun and Yoshua Bengio and Geoffrey Hinton"
      },
      {
        "title": "Deep learning",
        "abstract": "Kwang Gi Kim https://doi. org/10.4258/hir. 2016.22. 4.351 ing those who are beginning their careers in deep learning and artificial intelligence research. The other target audience consists of software engineers who may not have a background in machine learning or statistics but who nonetheless want to acquire this knowledge rapidly and begin using deep learning in their fields. Deep learning has already proven useful in many software disciplines, including computer vision, speech and audio processing, natural language processing, robotics, bioinformatics and chemistry, video games, search engines, online advertising and finance. This book has been organized into three parts so as to best accommodate a variety of readers. In Part I, the author intro duces basic mathematical tools and machine learning concepts. Part II describes the most established deep learning …",
        "year": 2016,
        "authors": "Ian Goodfellow"
      }
    ],
    "xuLKJboAAAAJ": [
      {
        "title": "Double reinforcement learning for efficient off-policy evaluation in markov decision processes",
        "abstract": "Off-policy evaluation (OPE) in reinforcement learning allows one to evaluate novel decision policies without needing to conduct exploration, which is often costly or otherwise infeasible. We consider for the first time the semiparametric efficiency limits of OPE in Markov decision processes (MDPs), where actions, rewards, and states are memoryless. We show existing OPE estimators may fail to be efficient in this setting. We develop a new estimator based on cross-fold estimation of q-functions and marginalized density ratios, which we term double reinforcement learning (DRL). We show that DRL is efficient when both components are estimated at fourth-root rates and is also doubly robust when only one component is consistent. We investigate these properties empirically and demonstrate the performance benefits due to harnessing memorylessness.",
        "year": 2020,
        "authors": "Nathan Kallus and Masatoshi Uehara"
      },
      {
        "title": "Minimax weight and q-function learning for off-policy evaluation",
        "abstract": "We provide theoretical investigations into off-policy evaluation in reinforcement learning using function approximators for (marginalized) importance weights and value functions. Our contributions include:(1) A new estimator, MWL, that directly estimates importance ratios over the state-action distributions, removing the reliance on knowledge of the behavior policy as in prior work (Liu et. al, 2018),(2) Another new estimator, MQL, obtained by swapping the roles of importance weights and value-functions in MWL. MQL has an intuitive interpretation of minimizing average Bellman errors and can be combined with MWL in a doubly robust manner,(3) Several additional results that offer further insights, including the sample complexities of MWL and MQL, their asymptotic optimality in the tabular setting, how the learned importance weights depend the choice of the discriminator class, and how our methods provide a unified view of some old and new algorithms in RL.",
        "year": 2020,
        "authors": "Masatoshi Uehara and Jiawei Huang and Nan Jiang"
      },
      {
        "title": "Pessimistic Model-based Offline Reinforcement Learning under Partial Coverage",
        "abstract": "We study model-based offline Reinforcement Learning with general function approximation without a full coverage assumption on the offline data distribution. We present an algorithm named Constrained Pessimistic Policy Optimization (CPPO)which leverages a general function class and uses a constraint over the model class to encode pessimism. Under the assumption that the ground truth model belongs to our function class (i.e., realizability in the function class), CPPO has a PAC guarantee with offline data only providing partial coverage, i.e., it can learn a policy that competes against any policy that is covered by the offline data. We then demonstrate that this algorithmic framework can be applied to many specialized Markov Decision Processes where additional structural assumptions can further refine the concept of partial coverage. Two notable examples are: (1) low-rank MDP with representation learning where the partial coverage condition is defined using a relative condition number measured by the unknown ground truth feature representation; (2) factored MDP where the partial coverage condition is defined using density ratio based concentrability coefficients associated with individual factors.",
        "year": 2022,
        "authors": "Masatoshi Uehara and Wen Sun"
      }
    ],
    "x-n9rIMAAAAJ": [
      {
        "title": "Analysis and observations from the first amazon picking challenge",
        "abstract": "This paper presents an overview of the inaugural Amazon Picking Challenge along with a summary of a survey conducted among the 26 participating teams. The challenge goal was to design an autonomous robot to pick items from a warehouse shelf. This task is currently performed by human workers, and there is hope that robots can someday help increase efficiency and throughput while lowering cost. We report on a 28-question survey posed to the teams to learn about each team's background, mechanism design, perception apparatus, planning, and control approach. We identify trends in this data, correlate it with each team's success in the competition, and discuss observations and lessons learned based on survey results and the authors' personal experiences during the challenge.",
        "year": 2016,
        "authors": "Nikolaus Correll and Kostas E Bekris and Dmitry Berenson and Oliver Brock and Albert Causo and Kris Hauser and Kei Okada and Alberto Rodriguez and Joseph M Romano and Peter R Wurman"
      },
      {
        "title": "Task Space Regions: A Framework for Pose-Constrained Manipulation Planning",
        "abstract": "We present a manipulation planning framework that allows robots to plan in the presence of constraints on end-effector pose, as well as other common constraints. The framework has three main components: constraint representation, constraint-satisfaction strategies, and a general planning algorithm. These components come together to create an efficient and probabilistically complete manipulation planning algorithm called the Constrained BiDirectional Rapidly-exploring Random Tree (RRT) – CBiRRT2. The underpinning of our framework for pose constraints is our Task Space Regions (TSRs) representation. TSRs are intuitive to specify, can be efficiently sampled, and the distance to a TSR can be evaluated very quickly, making them ideal for sampling-based planning. Most importantly, TSRs are a general representation of pose constraints that can fully describe many practical tasks. For more complex tasks …",
        "year": 2011,
        "authors": "Dmitry Berenson and Siddhartha Srinivasa and James Kuffner"
      },
      {
        "title": "Human-robot collaborative manipulation planning using early prediction of human motion",
        "abstract": "In this paper we present a framework that allows a human and a robot to perform simultaneous manipulation tasks safely in close proximity. The proposed framework is based on early prediction of the human's motion. The prediction system, which builds on previous work in the area of gesture recognition, generates a prediction of human workspace occupancy by computing the swept volume of learned human motion trajectories. The motion planner then plans robot trajectories that minimize a penetration cost in the human workspace occupancy while interleaving planning and execution. Multiple plans are computed in parallel, one for each robot task available at the current time, and the trajectory with the least cost is selected for execution. We test our framework in simulation using recorded human motions and a simulated PR2 robot. Our results show that our framework enables the robot to avoid the human while …",
        "year": 2013,
        "authors": "Jim Mainprice and Dmitry Berenson"
      }
    ],
    "VecEj6kAAAAJ": [
      {
        "title": "Speech synthesis from neural decoding of spoken sentences",
        "abstract": "Technology that translates neural activity into speech would be transformative for people who are unable to communicate as a result of neurological impairments. Decoding speech from neural activity is challenging because speaking requires very precise and rapid multi-dimensional control of vocal tract articulators. Here we designed a neural decoder that explicitly leverages kinematic and sound representations encoded in human cortical activity to synthesize audible speech. Recurrent neural networks first decoded directly recorded cortical activity into representations of articulatory movement, and then transformed these representations into speech acoustics. In closed vocabulary tests, listeners could readily identify and transcribe speech synthesized from cortical activity. Intermediate articulatory dynamics enhanced performance even with limited data. Decoded articulatory representations were highly …",
        "year": 2019,
        "authors": "Gopala K Anumanchipalli and Josh Chartier and Edward F Chang"
      },
      {
        "title": "Neuroprosthesis for decoding speech in a paralyzed person with anarthria",
        "abstract": "Technology to restore the ability to communicate in paralyzed persons who cannot speak has the potential to improve autonomy and quality of life. An approach that decodes words and sentences directly from the cerebral cortical activity of such patients may represent an advancement over existing methods for assisted communication.We implanted a subdural, high-density, multielectrode array over the area of the sensorimotor cortex that controls speech in a person with anarthria (the loss of the ability to articulate speech) and spastic quadriparesis caused by a brain-stem stroke. Over the course of 48 sessions, we recorded 22 hours of cortical activity while the participant attempted to say individual words from a vocabulary set of 50 words. We used deep-learning algorithms to create computational models for the detection and classification of words from patterns in the recorded cortical …",
        "year": 2021,
        "authors": "David A Moses and Sean L Metzger and Jessie R Liu and Gopala K Anumanchipalli and Joseph G Makin and Pengfei F Sun and Josh Chartier and Maximilian E Dougherty and Patricia M Liu and Gary M Abrams and Adelyn Tu-Chan and Karunesh Ganguly and Edward F Chang"
      },
      {
        "title": "A high-performance neuroprosthesis for speech decoding and avatar control",
        "abstract": "Speech neuroprostheses have the potential to restore communication to people living with paralysis, but naturalistic speed and expressivity are elusive. Here we use high-density surface recordings of the speech cortex in a clinical-trial participant with severe limb and vocal paralysis to achieve high-performance real-time decoding across three complementary speech-related output modalities: text, speech audio and facial-avatar animation. We trained and evaluated deep-learning models using neural data collected as the participant attempted to silently speak sentences. For text, we demonstrate accurate and rapid large-vocabulary decoding with a median rate of 78 words per minute and median word error rate of 25%. For speech audio, we demonstrate intelligible and rapid speech synthesis and personalization to the participant’s pre-injury voice. For facial-avatar animation, we demonstrate the control of virtual …",
        "year": 2023,
        "authors": "Sean L Metzger and Kaylo T Littlejohn and Alexander B Silva and David A Moses and Margaret P Seaton and Ran Wang and Maximilian E Dougherty and Jessie R Liu and Peter Wu and Michael A Berger and Inga Zhuravleva and Adelyn Tu-Chan and Karunesh Ganguly and Gopala K Anumanchipalli and Edward F Chang"
      }
    ],
    "B7oP0bIAAAAJ": [
      {
        "title": "Training language models to follow instructions with human feedback",
        "abstract": "Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through a language model API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3 B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.",
        "year": 2022,
        "authors": "Long Ouyang and Jeffrey Wu and Xu Jiang and Diogo Almeida and Carroll Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul F Christiano and Jan Leike and Ryan Lowe"
      },
      {
        "title": "Deep reinforcement learning from human preferences",
        "abstract": "For sophisticated reinforcement learning (RL) systems to interact usefully with real-world environments, we need to communicate complex goals to these systems. In this work, we explore goals defined in terms of (non-expert) human preferences between pairs of trajectory segments. Our approach separates learning the goal from learning the behavior to achieve it. We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on about 0.1% of our agent's interactions with the environment. This reduces the cost of human oversight far enough that it can be practically applied to state-of-the-art RL systems. To demonstrate the flexibility of our approach, we show that we can successfully train complex novel behaviors with about an hour of human time. These behaviors and environments are considerably more complex than any which have been previously learned from human feedback.",
        "year": 2017,
        "authors": "Paul F Christiano and Jan Leike and Tom Brown and Miljan Martic and Shane Legg and Dario Amodei"
      },
      {
        "title": "Concrete problems in AI safety",
        "abstract": "Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function (\"avoiding side effects\" and \"avoiding reward hacking\"), an objective function that is too expensive to evaluate frequently (\"scalable supervision\"), or undesirable behavior during the learning process (\"safe exploration\" and \"distributional shift\"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.",
        "year": 2016,
        "authors": "Dario Amodei and Chris Olah and Jacob Steinhardt and Paul Christiano and John Schulman and Dan Mané"
      }
    ],
    "m8m9nD0AAAAJ": [
      {
        "title": "On layer normalization in the transformer architecture",
        "abstract": "The Transformer is widely used in natural language processing tasks. To train a Transformer however, one usually needs a carefully designed learning rate warm-up stage, which is shown to be crucial to the final performance but will slow down the optimization and bring more hyper-parameter tunings. In this paper, we first study theoretically why the learning rate warm-up stage is essential and show that the location of layer normalization matters. Specifically, we prove with mean field theory that at initialization, for the original-designed Post-LN Transformer, which places the layer normalization between the residual blocks, the expected gradients of the parameters near the output layer are large. Therefore, using a large learning rate on those gradients makes the training unstable. The warm-up stage is practically helpful for avoiding this problem. On the other hand, our theory also shows that if the layer normalization is put inside the residual blocks (recently proposed as Pre-LN Transformer), the gradients are well-behaved at initialization. This motivates us to remove the warm-up stage for the training of Pre-LN Transformers. We show in our experiments that Pre-LN Transformers without the warm-up stage can reach comparable results with baselines while requiring significantly less training time and hyper-parameter tuning on a wide range of applications.",
        "year": 2020,
        "authors": "Ruibin Xiong and Yunchang Yang and Di He and Kai Zheng and Shuxin Zheng and Chen Xing and Huishuai Zhang and Yanyan Lan and Liwei Wang and Tieyan Liu"
      },
      {
        "title": "On reinforcement learning with adversarial corruption and its application to block mdp",
        "abstract": "We study reinforcement learning (RL) in episodic tabular MDPs with adversarial corruptions, where some episodes can be adversarially corrupted. When the total number of corrupted episodes is known, we propose an algorithm, Corruption Robust Monotonic Value Propagation (\\textsf {CR-MVP}), which achieves a regret bound of $\\tilde {O}\\left (\\left (\\sqrt {SAK}+ S^ 2A+ CSA)\\right)\\polylog (H)\\right) $, where  is the number of states,  is the number of actions,  is the planning horizon,  is the number of episodes, and  is the corruption level. We also provide a corresponding lower bound, which indicates that our upper bound is tight. Finally, as an application, we study RL with rich observations in the block MDP model. We provide the first algorithm that achieves a -type regret in this setting and is computationally efficient.",
        "year": 2021,
        "authors": "Tianhao Wu and Yunchang Yang and Simon Du and Liwei Wang"
      }
    ],
    "VYiRfCwAAAAJ": [
      {
        "title": "Cloth grasp point detection based on multiple-view geometric cues with application to robotic towel folding",
        "abstract": "We present a novel vision-based grasp point detection algorithm that can reliably detect the corners of a piece of cloth, using only geometric cues that are robust to variation in texture. Furthermore, we demonstrate the effectiveness of our algorithm in the context of folding a towel using a general-purpose two-armed mobile robotic platform without the use of specialized end-effectors or tools. The robot begins by picking up a randomly dropped towel from a table, goes through a sequence of vision-based re-grasps and manipulations-partially in the air, partially on the table-and finally stacks the folded towel in a target location. The reliability and robustness of our algorithm enables for the first time a robot with general purpose manipulators to reliably and fully-autonomously fold previously unseen towels, demonstrating success on all 50 out of 50 single-towel trials as well as on a pile of 5 towels.",
        "year": 2010,
        "authors": "Jeremy Maitin-Shepard and Marco Cusumano-Towner and Jinna Lei and Pieter Abbeel"
      },
      {
        "title": "Gen: a general-purpose probabilistic programming system with programmable inference",
        "abstract": "Although probabilistic programming is widely used for some restricted classes of statistical models, existing systems lack the flexibility and efficiency needed for practical use with more challenging models arising in fields like computer vision and robotics. This paper introduces Gen, a general-purpose probabilistic programming system that achieves modeling flexibility and inference efficiency via several novel language constructs: (i) the generative function interface for encapsulating probabilistic models; (ii) interoperable modeling languages that strike different flexibility/efficiency trade-offs; (iii) combinators that exploit common patterns of conditional independence; and (iv) an inference library that empowers users to implement efficient inference algorithms at a high level of abstraction. We show that Gen outperforms state-of-the-art probabilistic programming systems, sometimes by multiple orders of magnitude, on …",
        "year": 2019,
        "authors": "Marco F Cusumano-Towner and Feras A Saad and Alexander K Lew and Vikash K Mansinghka"
      },
      {
        "title": "Bringing clothing into desired configurations with limited perception",
        "abstract": "We consider the problem of autonomously bringing an article of clothing into a desired configuration using a general-purpose two-armed robot. We propose a hidden Markov model (HMM) for estimating the identity of the article and tracking the article's configuration throughout a specific sequence of manipulations and observations. At the end of this sequence, the article's configuration is known, though not necessarily desired. The estimated identity and configuration of the article are then used to plan a second sequence of manipulations that brings the article into the desired configuration. We propose a relaxation of a strain limiting finite element model for cloth simulation that can be solved via convex optimization; this serves as the basis of the transition and observation models of the HMM. The observation model uses simple perceptual cues consisting of the height of the article when held by a single gripper and …",
        "year": 2011,
        "authors": "Marco Cusumano-Towner and Arjun Singh and Stephen Miller and James F O'Brien and Pieter Abbeel"
      }
    ],
    "j_xavDQAAAAJ": [
      {
        "title": "#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning",
        "abstract": "Count-based exploration algorithms are known to perform near-optimally when used in conjunction with tabular reinforcement learning (RL) methods for solving small discrete Markov decision processes (MDPs). It is generally thought that count-based methods cannot be applied in high-dimensional state spaces, since most states will only occur once. Recent deep RL exploration strategies are able to deal with high-dimensional continuous state spaces through complex heuristics, often relying on optimism in the face of uncertainty or intrinsic motivation. In this work, we describe a surprising finding: a simple generalization of the classic count-based approach can reach near state-of-the-art performance on various high-dimensional and/or continuous deep RL benchmarks. States are mapped to hash codes, which allows to count their occurrences with a hash table. These counts are then used to compute a reward bonus according to the classic count-based exploration theory. We find that simple hash functions can achieve surprisingly good results on many challenging tasks. Furthermore, we show that a domain-dependent learned hash code may further improve these results. Detailed analysis reveals important aspects of a good hash function: 1) having appropriate granularity and 2) encoding information relevant to solving the MDP. This exploration strategy achieves near state-of-the-art performance on both continuous control tasks and Atari 2600 games, hence providing a simple yet powerful baseline for solving MDPs that require considerable exploration.",
        "year": 2017,
        "authors": "Haoran Tang and Rein Houthooft and Davis Foote and Adam Stooke and OpenAI Xi Chen and Yan Duan and John Schulman and Filip DeTurck and Pieter Abbeel"
      },
      {
        "title": "Why Does Hierarchy (Sometimes) Work So Well in Reinforcement Learning?",
        "abstract": "Hierarchical reinforcement learning has demonstrated significant success at solving difficult reinforcement learning (RL) tasks. Previous works have motivated the use of hierarchy by appealing to a number of intuitive benefits, including learning over temporally extended transitions, exploring over temporally extended periods, and training and exploring in a more semantically meaningful action space, among others. However, in fully observed, Markovian settings, it is not immediately clear why hierarchical RL should provide benefits over standard \"shallow\" RL architectures. In this work, we isolate and evaluate the claimed benefits of hierarchical RL on a suite of tasks encompassing locomotion, navigation, and manipulation. Surprisingly, we find that most of the observed benefits of hierarchy can be attributed to improved exploration, as opposed to easier policy learning or imposed hierarchical structures. Given this insight, we present exploration techniques inspired by hierarchy that achieve performance competitive with hierarchical RL while at the same time being much simpler to use and implement.",
        "year": 2019,
        "authors": "Ofir Nachum and Haoran Tang and Xingyu Lu and Shixiang Gu and Honglak Lee and Sergey Levine"
      }
    ],
    "55TAOdgAAAAJ": [
      {
        "title": "Matrix completion from a few entries",
        "abstract": "Let M be an n¿ × n matrix of rank r, and assume that a uniformly random subset E of its entries is observed. We describe an efficient algorithm, which we call OptSpace, that reconstructs M from |E| = O(rn) observed entries with relative root mean square error 1/2 RMSE ¿ C(¿) (nr/|E|)1/2 with probability larger than 1 - 1/n3. Further, if r = O(1) and M is sufficiently unstructured, then OptSpace reconstructs it exactly from |E| = O(n log n) entries with probability larger than 1 - 1/n3. This settles (in the case of bounded rank) a question left open by Candes and Recht and improves over the guarantees for their reconstruction algorithm. The complexity of our algorithm is O(|E|r log n), which opens the way to its use for massive data sets. In the process of proving these statements, we obtain a generalization of a celebrated result by Friedman-Kahn-Szemeredi and Feige-Ofek on the spectrum of sparse random matrices.",
        "year": 2010,
        "authors": "Raghunandan H Keshavan and Andrea Montanari and Sewoong Oh"
      },
      {
        "title": "The composition theorem for differential privacy",
        "abstract": "Interactive querying of a database degrades the privacy level. In this paper we answer the fundamental question of characterizing the level of privacy degradation as a function of the number of adaptive interactions and the differential privacy levels maintained by the individual queries. Our solution is complete: the privacy degradation guarantee is true for every privacy mechanism, and further, we demonstrate a sequence of privacy mechanisms that do degrade in the characterized manner. The key innovation is the introduction of an operational interpretation (involving hypothesis testing) to differential privacy and the use of the corresponding data processing inequalities. Our result improves over the state of the art and has immediate applications to several problems studied in the literature.",
        "year": 2015,
        "authors": "Peter Kairouz and Sewoong Oh and Pramod Viswanath"
      },
      {
        "title": "Matrix completion from noisy entries",
        "abstract": "Given a matrix M of low-rank, we consider the problem of reconstructing it from noisy observations of a small, random subset of its entries. The problem arises in a variety of applications, from collaborative filtering (the ‘Netflix problem’) to structure-from-motion and positioning. We study a low complexity algorithm introduced in [1], based on a combination of spectral techniques and manifold optimization, that we call here OPTSPACE. We prove performance guarantees that are order-optimal in a number of circumstances.",
        "year": 2010,
        "authors": "Raghunandan H Keshavan and Andrea Montanari and Sewoong Oh"
      }
    ],
    "xT19Jc0AAAAJ": [
      {
        "title": "Adaptive wavelet thresholding for image denoising and compression",
        "abstract": "The first part of this paper proposes an adaptive, data-driven threshold for image denoising via wavelet soft-thresholding. The threshold is derived in a Bayesian framework, and the prior used on the wavelet coefficients is the generalized Gaussian distribution (GGD) widely used in image processing applications. The proposed threshold is simple and closed-form, and it is adaptive to each subband because it depends on data-driven estimates of the parameters. Experimental results show that the proposed method, called BayesShrink, is typically within 5% of the MSE of the best soft-thresholding benchmark with the image assumed known. It also outperforms SureShrink (Donoho and Johnstone 1994, 1995; Donoho 1995) most of the time. The second part of the paper attempts to further validate claims that lossy compression can be used for denoising. The BayesShrink threshold can aid in the parameter selection of …",
        "year": 2000,
        "authors": "S Grace Chang and Bin Yu and Martin Vetterli"
      },
      {
        "title": "On model selection consistency of Lasso",
        "abstract": "Sparsity or parsimony of statistical models is crucial for their proper interpretations, as in sciences and social sciences. Model selection is a commonly used method to find such models, but usually involves a computationally heavy combinatorial search. Lasso (Tibshirani, 1996) is now being used as a computationally feasible alternative to model selection. Therefore it is important to study Lasso for model selection purposes.",
        "year": 2006,
        "authors": "Peng Zhao and Bin Yu"
      },
      {
        "title": "Definitions, methods, and applications in interpretable machine learning",
        "abstract": "Machine-learning models have demonstrated great success in learning complex patterns that enable them to make predictions about unobserved data. In addition to using models for prediction, the ability to interpret what a model has learned is receiving an increasing amount of attention. However, this increased focus has led to considerable confusion about the notion of interpretability. In particular, it is unclear how the wide array of proposed interpretation methods are related and what common concepts can be used to evaluate them. We aim to address these concerns by defining interpretability in the context of machine learning and introducing the predictive, descriptive, relevant (PDR) framework for discussing interpretations. The PDR framework provides 3 overarching desiderata for evaluation: predictive accuracy, descriptive accuracy, and relevancy, with relevancy judged relative to a human audience …",
        "year": 2019,
        "authors": "W James Murdoch and Chandan Singh and Karl Kumbier and Reza Abbasi-Asl and Bin Yu"
      }
    ],
    "vS8b6GwAAAAJ": [
      {
        "title": "CAD2RL: Real Single-Image Flight without a Single Real Image",
        "abstract": "Deep reinforcement learning has emerged as a promising and powerful technique for automatically acquiring control policies that can process raw sensory inputs, such as images, and perform complex behaviors. However, extending deep RL to real-world robotic tasks has proven challenging, particularly in safety-critical domains such as autonomous flight, where a trial-and-error learning process is often impractical. In this paper, we explore the following question: can we train vision-based navigation policies entirely in simulation, and then transfer them into the real world to achieve real-world flight without a single real training image? We propose a learning method that we call CADRL, which can be used to perform collision-free indoor flight in the real world while being trained entirely on 3D CAD models. Our method uses single RGB images from a monocular camera, without needing to explicitly reconstruct the 3D geometry of the environment or perform explicit motion planning. Our learned collision avoidance policy is represented by a deep convolutional neural network that directly processes raw monocular images and outputs velocity commands. This policy is trained entirely on simulated images, with a Monte Carlo policy evaluation algorithm that directly optimizes the network's ability to produce collision-free flight. By highly randomizing the rendering settings for our simulated training set, we show that we can train a policy that generalizes to the real world, without requiring the simulator to be particularly realistic or high-fidelity. We evaluate our method by flying a real quadrotor through indoor environments, and further evaluate the …",
        "year": 2017,
        "authors": "Fereshteh Sadeghi and Sergey Levine"
      },
      {
        "title": "CAD2RL: Real single-image flight without a single real image",
        "abstract": "Deep reinforcement learning has emerged as a promising and powerful technique for automatically acquiring control policies that can process raw sensory inputs, such as images, and perform complex behaviors. However, extending deep RL to real-world robotic tasks has proven challenging, particularly in safety-critical domains such as autonomous flight, where a trial-and-error learning process is often impractical. In this paper, we explore the following question: can we train vision-based navigation policies entirely in simulation, and then transfer them into the real world to achieve real-world flight without a single real training image? We propose a learning method that we call CADRL, which can be used to perform collision-free indoor flight in the real world while being trained entirely on 3D CAD models. Our method uses single RGB images from a monocular camera, without needing to explicitly reconstruct the 3D geometry of the environment or perform explicit motion planning. Our learned collision avoidance policy is represented by a deep convolutional neural network that directly processes raw monocular images and outputs velocity commands. This policy is trained entirely on simulated images, with a Monte Carlo policy evaluation algorithm that directly optimizes the network's ability to produce collision-free flight. By highly randomizing the rendering settings for our simulated training set, we show that we can train a policy that generalizes to the real world, without requiring the simulator to be particularly realistic or high-fidelity. We evaluate our method by flying a real quadrotor through indoor environments, and further evaluate the …",
        "year": 2016,
        "authors": "Fereshteh Sadeghi and Sergey Levine"
      },
      {
        "title": "Learning agile soccer skills for a bipedal robot with deep reinforcement learning",
        "abstract": "We investigated whether deep reinforcement learning (deep RL) is able to synthesize sophisticated and safe movement skills for a low-cost, miniature humanoid robot that can be composed into complex behavioral strategies. We used deep RL to train a humanoid robot to play a simplified one-versus-one soccer game. The resulting agent exhibits robust and dynamic movement skills, such as rapid fall recovery, walking, turning, and kicking, and it transitions between them in a smooth and efficient manner. It also learned to anticipate ball movements and block opponent shots. The agent’s tactical behavior adapts to specific game contexts in a way that would be impractical to manually design. Our agent was trained in simulation and transferred to real robots zero-shot. A combination of sufficiently high-frequency control, targeted dynamics randomization, and perturbations during training enabled good-quality transfer …",
        "year": 2024,
        "authors": "Tuomas Haarnoja and Ben Moran and Guy Lever and Sandy H Huang and Dhruva Tirumala and Jan Humplik and Markus Wulfmeier and Saran Tunyasuvunakool and Noah Y Siegel and Roland Hafner and Michael Bloesch and Kristian Hartikainen and Arunkumar Byravan and Leonard Hasenclever and Yuval Tassa and Fereshteh Sadeghi and Nathan Batchelor and Federico Casarini and Stefano Saliceti and Charles Game and Neil Sreendra and Kushal Patel and Marlon Gwira and Andrea Huber and Nicole Hurley and Francesco Nori and Raia Hadsell and Nicolas Heess"
      }
    ],
    "_vjPh4UAAAAJ": [
      {
        "title": "When trees collide: An approximation algorithm for the generalized Steiner problem on networks",
        "abstract": "We give the first approximation algorithm for the generalized network Steiner problem, a problem in network design. An instance consists of a network with link-costs and} for each pair {i, j} of nodes, an edge-connectivity requirement Tij. The goal is to find a minimum-cost network using the available links and satisfying the requirements. Our algorithm outputs a solution whose cost is within 2 lg R of optimal, where R is the highest requirement value.In the course of proving the performance guarantee, we prove acombinatorial min-max approximate equality relating minimum-cost networks to maximum packings of certain kinds of cuts. As a consequence of the proof of this theorem, we obtain an approximation algorithm for optimally packing these cuts; we show that this algorithm has application to estimating the reliability of a probabilistic network.",
        "year": 1991,
        "authors": "Ajit Agrawal and Philip Klein and Ramamoorthi Ravi"
      },
      {
        "title": "A nearly best-possible approximation algorithm for node-weighted Steiner trees",
        "abstract": "We give the first approximation algorithm for the node-weighted Steiner tree problem. Its performance guarantee is within a constant factor of the best possible unless P̃ ⊇ NP. (P̃ stands for the complexity class deterministic quasi-polynomial time, or DTIME[npolylog n].) Our algorithm generalizes to handle other network-design problems.",
        "year": 1995,
        "authors": "Philip Klein and RJJA Ravi"
      },
      {
        "title": "A polylogarithmic approximation algorithm for the group Steiner tree problem",
        "abstract": "Given a weighted graph with some subsets of vertices called groups, the group Steiner tree problem is to find a minimum-weight subgraph which contains at least one vertex from each group. We give a randomized algorithm with a polylogarithmic approximation guarantee for the group Steiner tree problem. The previous best approximation guarantee was O(i2k1/i) in time O(nik2i) (Charikar, Chekuri, Goel, and Guha). Our algorithm also improves existing approximation results for network design problems with location-based constraints and for the symmetric generalized traveling salesman problem.",
        "year": 2000,
        "authors": "Naveen Garg and Goran Konjevod and Ramamoorthi Ravi"
      }
    ],
    "bLUllHEAAAAJ": [
      {
        "title": "Reading Digits in Natural Images with Unsupervised Feature Learning",
        "abstract": "Detecting and reading text from natural images is a hard computer vision task that is central to a variety of emerging applications. Related problems like document character recognition have been widely studied by computer vision and machine learning researchers and are virtually solved for practical applications like reading handwritten digits. Reliably recognizing characters in more complex scenes like photographs, however, is far more difficult: the best existing methods lag well behind human performance on the same tasks. In this paper we attack the problem of recognizing digits in a real application using unsupervised feature learning methods: reading house numbers from street level photos. To this end, we introduce a new benchmark dataset for research use containing over 600,000 labeled digits cropped from Street View images. We then demonstrate the difficulty of recognizing these digits when the problem is approached with hand-designed features. Finally, we employ variants of two recently proposed unsupervised feature learning methods and find that they are convincingly superior on our benchmarks.",
        "year": 2011,
        "authors": "Yuval Netzer and Tao Wang and Adam Coates and Alessandro Bissacco and Bo Wu and Andrew Y Ng"
      },
      {
        "title": "An analysis of single-layer networks in unsupervised feature learning",
        "abstract": "A great deal of research has focused on algorithms for learning features from unlabeled data. Indeed, much progress has been made on benchmark datasets like NORB and CIFAR-10 by employing increasingly complex unsupervised learning algorithms and deep models. In this paper, however, we show that several simple factors, such as the number of hidden nodes in the model, may be more important to achieving high performance than the learning algorithm or the depth of the model. Specifically, we will apply several off-the-shelf feature learning algorithms (sparse auto-encoders, sparse RBMs, K-means clustering, and Gaussian mixtures) to CIFAR-10, NORB, and STL datasets using only single-layer networks. We then present a detailed analysis of the effect of changes in the model setup: the receptive field size, number of hidden nodes (features), the step-size (“stride”) between extracted features, and the effect of whitening. Our results show that large numbers of hidden nodes and dense feature extraction are critical to achieving high performance-so critical, in fact, that when these parameters are pushed to their limits, we achieve state-of-the-art performance on both CIFAR-10 and NORB using only a single layer of features. More surprisingly, our best performance is based on K-means clustering, which is extremely fast, has no hyper-parameters to tune beyond the model structure itself, and is very easy to implement. Despite the simplicity of our system, we achieve accuracy beyond all previously published results on the CIFAR-10 and NORB datasets (79.6% and 97.2% respectively).",
        "year": 2011,
        "authors": "Adam Coates and Honglak Lee and Andrew Y Ng"
      },
      {
        "title": "Deep speech 2: End-to-end speech recognition in english and mandarin",
        "abstract": "We show that an end-to-end deep learning approach can be used to recognize either English or Mandarin Chinese speech–two vastly different languages. Because it replaces entire pipelines of hand-engineered components with neural networks, end-to-end learning allows us to handle a diverse variety of speech including noisy environments, accents and different languages. Key to our approach is our application of HPC techniques, enabling experiments that previously took weeks to now run in days. This allows us to iterate more quickly to identify superior architectures and algorithms. As a result, in several cases, our system is competitive with the transcription of human workers when benchmarked on standard datasets. Finally, using a technique called Batch Dispatch with GPUs in the data center, we show that our system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale.",
        "year": 2016,
        "authors": "Dario Amodei and Sundaram Ananthanarayanan and Rishita Anubhai and Jingliang Bai and Eric Battenberg and Carl Case and Jared Casper and Bryan Catanzaro and Qiang Cheng and Guoliang Chen and Jie Chen and Jingdong Chen and Zhijie Chen and Mike Chrzanowski and Adam Coates and Greg Diamos and Ke Ding and Niandong Du and Erich Elsen and Jesse Engel and Weiwei Fang and Linxi Fan and Christopher Fougner and Liang Gao and Caixia Gong and Awni Hannun and Tony Han and Lappi Johannes and Bing Jiang and Cai Ju and Billy Jun and Patrick LeGresley and Libby Lin and Junjie Liu and Yang Liu and Weigao Li and Xiangang Li and Dongpeng Ma and Sharan Narang and Andrew Ng and Sherjil Ozair and Yiping Peng and Ryan Prenger and Sheng Qian and Zongfeng Quan and Jonathan Raiman and Vinay Rao and Sanjeev Satheesh and David Seetapun and Shubho Sengupta and Kavya Srinet and Anuroop Sriram and Haiyuan Tang and Liliang Tang and Chong Wang and Jidong Wang and Kaifu Wang and Yi Wang and Zhijian Wang and Zhiqian Wang and Shuang Wu and Likai Wei and Bo Xiao and Wen Xie and Yan Xie and Dani Yogatama and Bin Yuan and Jun Zhan and Zhenyao Zhu"
      }
    ],
    "XP_Hxm4AAAAJ": [
      {
        "title": "nuscenes: A multimodal dataset for autonomous driving",
        "abstract": "Robust detection and tracking of objects is crucial for the deployment of autonomous vehicle technology. Image based benchmark datasets have driven development in computer vision tasks such as object detection, tracking and segmentation of agents in the environment. Most autonomous vehicles, however, carry a combination of cameras and range sensors such as lidar and radar. As machine learning based methods for detection and tracking become more prevalent, there is a need to train and evaluate such methods on datasets containing range sensor data along with images. In this work we present nuTonomy scenes (nuScenes), the first dataset to carry the full autonomous vehicle sensor suite: 6 cameras, 5 radars and 1 lidar, all with full 360 degree field of view. nuScenes comprises 1000 scenes, each 20s long and fully annotated with 3D bounding boxes for 23 classes and 8 attributes. It has 7x as many annotations and 100x as many images as the pioneering KITTI dataset. We define novel 3D detection and tracking metrics. We also provide careful dataset analysis as well as baselines for lidar and image based detection and tracking. Data, development kit and more information are available online.",
        "year": 2020,
        "authors": "Holger Caesar and Varun Bankiti and Alex H Lang and Sourabh Vora and Venice Erin Liong and Qiang Xu and Anush Krishnan and Yu Pan and Giancarlo Baldan and Oscar Beijbom"
      },
      {
        "title": "Pointpillars: Fast encoders for object detection from point clouds",
        "abstract": "Object detection in point clouds is an important aspect of many robotics applications such as autonomous driving. In this paper, we consider the problem of encoding a point cloud into a format appropriate for a downstream detection pipeline. Recent literature suggests two types of encoders; fixed encoders tend to be fast but sacrifice accuracy, while encoders that are learned from data are more accurate, but slower. In this work, we propose PointPillars, a novel encoder which utilizes PointNets to learn a representation of point clouds organized in vertical columns (pillars). While the encoded features can be used with any standard 2D convolutional detection architecture, we further propose a lean downstream network. Extensive experimentation shows that PointPillars outperforms previous encoders with respect to both speed and accuracy by a large margin. Despite only using lidar, our full detection pipeline significantly outperforms the state of the art, even among fusion methods, with respect to both the 3D and bird's eye view KITTI benchmarks. This detection performance is achieved while running at 62 Hz: a 2-4 fold runtime improvement. A faster version of our method matches the state of the art at 105 Hz. These benchmarks suggest that PointPillars is an appropriate encoding for object detection in point clouds.",
        "year": 2019,
        "authors": "Alex H Lang and Sourabh Vora and Holger Caesar and Lubing Zhou and Jiong Yang and Oscar Beijbom"
      },
      {
        "title": "Pointpainting: Sequential fusion for 3d object detection",
        "abstract": "Camera and lidar are important sensor modalities for robotics in general and self-driving cars in particular. The sensors provide complementary information offering an opportunity for tight sensor-fusion. Surprisingly, lidar-only methods outperform fusion methods on the main benchmark datasets, suggesting a gap in the literature. In this work, we propose PointPainting: a sequential fusion method to fill this gap. PointPainting works by projecting lidar points into the output of an image-only semantic segmentation network and appending the class scores to each point. The appended (painted) point cloud can then be fed to any lidar-only method. Experiments show large improvements on three different state-of-the art methods, Point-RCNN, VoxelNet and PointPillars on the KITTI and nuScenes datasets. The painted version of PointRCNN represents a new state of the art on the KITTI leaderboard for the bird's-eye view detection task. In ablation, we study how the effects of Painting depends on the quality and format of the semantic segmentation output, and demonstrate how latency can be minimized through pipelining.",
        "year": 2020,
        "authors": "Sourabh Vora and Alex H Lang and Bassam Helou and Oscar Beijbom"
      }
    ],
    "wCRav7EAAAAJ": [
      {
        "title": "ViNT: A foundation model for visual navigation",
        "abstract": "General-purpose pre-trained models (\"foundation models\") have enabled practitioners to produce generalizable solutions for individual machine learning problems with datasets that are significantly smaller than those required for learning from scratch. Such models are typically trained on large and diverse datasets with weak supervision, consuming much more training data than is available for any individual downstream application. In this paper, we describe the Visual Navigation Transformer (ViNT), a foundation model that aims to bring the success of general-purpose pre-trained models to vision-based robotic navigation. ViNT is trained with a general goal-reaching objective that can be used with any navigation dataset, and employs a flexible Transformer-based architecture to learn navigational affordances and enable efficient adaptation to a variety of downstream navigational tasks. ViNT is trained on a number of existing navigation datasets, comprising hundreds of hours of robotic navigation from a variety of different robotic platforms, and exhibits positive transfer, outperforming specialist models trained on singular datasets. ViNT can be augmented with diffusion-based subgoal proposals to explore novel environments, and can solve kilometer-scale navigation problems when equipped with long-range heuristics. ViNT can also be adapted to novel task specifications with a technique inspired by prompt-tuning, where the goal encoder is replaced by an encoding of another task modality (e.g., GPS waypoints or routing commands) embedded into the same space of goal tokens. This flexibility and ability to accommodate a variety of …",
        "year": 2023,
        "authors": "Dhruv Shah and Ajay Sridhar and Nitish Dashora and Kyle Stachowicz and Kevin Black and Noriaki Hirose and Sergey Levine"
      },
      {
        "title": "Nomad: Goal masked diffusion policies for navigation and exploration",
        "abstract": "Robotic learning for navigation in unfamiliar environments needs to provide policies for both task-oriented navigation (i.e., reaching a goal that the robot has located), and task-agnostic exploration (i.e., searching for a goal in a novel setting). Typically, these roles are handled by separate models, for example by using subgoal proposals, planning, or separate navigation strategies. In this paper, we describe how we can train a single unified diffusion policy to handle both goal-directed navigation and goal-agnostic exploration, with the latter providing the ability to search novel environments, and the former providing the ability to reach a user-specified goal once it has been located. We show that this unified policy results in better overall performance when navigating to visually indicated goals in novel environments, as compared to approaches that use subgoal proposals from generative models, or prior methods …",
        "year": 2024,
        "authors": "Ajay Sridhar and Dhruv Shah and Catherine Glossop and Sergey Levine"
      },
      {
        "title": "Gnm: A general navigation model to drive any robot",
        "abstract": "Learning provides a powerful tool for vision-based navigation, but the capabilities of learning-based policies are constrained by limited training data. If we could combine data from all available sources, including multiple kinds of robots, we could train more powerful navigation models. In this paper, we study how a general goal-conditioned model for vision-based navigation can be trained on data obtained from many distinct but structurally similar robots, and enable broad generalization across environments and embodiments. We analyze the necessary design decisions for effective data sharing across robots, including the use of temporal context and standardized action spaces, and demonstrate that an omnipolicy trained from heterogeneous datasets outperforms policies trained on any single dataset. We curate 60 hours of navigation trajectories from 6 distinct robots, and deploy the trained GNM on a range of …",
        "year": 2023,
        "authors": "Dhruv Shah and Ajay Sridhar and Arjun Bhorkar and Noriaki Hirose and Sergey Levine"
      }
    ],
    "dB6ftCcAAAAJ": [
      {
        "title": "Apache spark: a unified engine for big data processing",
        "abstract": "This open source computing framework unifies streaming, batch, and interactive big data workloads to unlock new applications.",
        "year": 2016,
        "authors": "Matei Zaharia and Reynold S Xin and Patrick Wendell and Tathagata Das and Michael Armbrust and Ankur Dave and Xiangrui Meng and Josh Rosen and Shivaram Venkataraman and Michael J Franklin and Ali Ghodsi and Joseph Gonzalez and Scott Shenker and Ion Stoica"
      },
      {
        "title": "MLlib: Machine Learning in Apache Spark",
        "abstract": "On-line portfolio selection is a practical financial engineering problem, which aims to sequentially allocate capital among a set of assets in order to maximize long-term return. In recent years, a variety of machine learning algorithms have been proposed to address this challenging problem, but no comprehensive open-source toolbox has been released for various reasons. This article presents the first open-source toolbox for \"On-Line Portfolio Selection\" (OLPS), which implements a collection of classical and state-of-the-art strategies powered by machine learning algorithms. We hope that OLPS can facilitate the development of new learning methods and enable the performance benchmarking and comparisons of different strategies. OLPS is an open-source project released under Apache License (version 2.0), which is available at https://github.com/OLPS/ or http://OLPS.stevenhoi.org/.",
        "year": 2015,
        "authors": "Xiangrui Meng and Joseph Bradley and Burak Yavuz and Evan Sparks and Shivaram Venkataraman and Davies Liu and Jeremy Freeman and DB Tsai and Manish Amde and Sean Owen and Doris Xin and Reynold Xin and Michael J Franklin and Reza Zadeh and Matei Zaharia and Ameet Talwalkar"
      },
      {
        "title": "Spark SQL: Relational data processing in Spark",
        "abstract": "Spark SQL is a new module in Apache Spark that integrates relational processing with Spark's functional programming API. Built on our experience with Shark, Spark SQL lets Spark programmers leverage the benefits of relational processing (e.g. declarative queries and optimized storage), and lets SQL users call complex analytics libraries in Spark (e.g. machine learning). Compared to previous systems, Spark SQL makes two main additions. First, it offers much tighter integration between relational and procedural processing, through a declarative DataFrame API that integrates with procedural Spark code. Second, it includes a highly extensible optimizer, Catalyst, built using features of the Scala programming language, that makes it easy to add composable rules, control code generation, and define extension points. Using Catalyst, we have built a variety of features (e.g. schema inference for JSON, machine …",
        "year": 2015,
        "authors": "Michael Armbrust and Reynold S Xin and Cheng Lian and Yin Huai and Davies Liu and Joseph K Bradley and Xiangrui Meng and Tomer Kaftan and Michael J Franklin and Ali Ghodsi and Matei Zaharia"
      }
    ],
    "GR_DsT0AAAAJ": [
      {
        "title": "Gradient descent finds global minima of deep neural networks",
        "abstract": "Gradient descent finds a global minimum in training deep neural networks despite the objective function being non-convex. The current paper proves gradient descent achieves zero training loss in polynomial time for a deep over-parameterized neural network with residual connections (ResNet). Our analysis relies on the particular structure of the Gram matrix induced by the neural network architecture. This structure allows us to show the Gram matrix is stable throughout the training process and this stability implies the global optimality of the gradient descent algorithm. We further extend our analysis to deep residual convolutional neural networks and obtain a similar convergence result.",
        "year": 2018,
        "authors": "Simon S Du and Jason D Lee and Haochuan Li and Liwei Wang and Xiyu Zhai"
      },
      {
        "title": "Exact post-selection inference, with application to the lasso",
        "abstract": " We develop a general approach to valid inference after model selection. At the core of our framework is a result that characterizes the distribution of a post-selection estimator conditioned on the selection event. We specialize the approach to model selection by the lasso to form valid confidence intervals for the selected coefficients and test whether all relevant variables have been included in the model. ",
        "year": 2016,
        "authors": "Jason D Lee and Dennis L Sun and Yuekai Sun and Jonathan E Taylor"
      },
      {
        "title": "Gradient descent only converges to minimizers",
        "abstract": "We show that gradient descent converges to a local minimizer, almost surely with random initial-ization. This is proved by applying the Stable Manifold Theorem from dynamical systems theory.",
        "year": 2016,
        "authors": "Jason D Lee and Max Simchowitz and Michael I Jordan and Benjamin Recht"
      }
    ],
    "7GSWYLQAAAAJ": [
      {
        "title": "SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards",
        "abstract": "Learning to imitate expert behavior from demonstrations can be challenging, especially in environments with high-dimensional, continuous observations and unknown dynamics. Supervised learning methods based on behavioral cloning (BC) suffer from distribution shift: because the agent greedily imitates demonstrated actions, it can drift away from demonstrated states due to error accumulation. Recent methods based on reinforcement learning (RL), such as inverse RL and generative adversarial imitation learning (GAIL), overcome this issue by training an RL agent to match the demonstrations over a long horizon. Since the true reward function for the task is unknown, these methods learn a reward function from the demonstrations, often using complex and brittle approximation techniques that involve adversarial training. We propose a simple alternative that still uses RL, but does not require learning a reward function. The key idea is to provide the agent with an incentive to match the demonstrations over a long horizon, by encouraging it to return to demonstrated states upon encountering new, out-of-distribution states. We accomplish this by giving the agent a constant reward of r=+1 for matching the demonstrated action in a demonstrated state, and a constant reward of r=0 for all other behavior. Our method, which we call soft Q imitation learning (SQIL), can be implemented with a handful of minor modifications to any standard Q-learning or off-policy actor-critic algorithm. Theoretically, we show that SQIL can be interpreted as a regularized variant of BC that uses a sparsity prior to encourage long-horizon imitation. Empirically, we show that …",
        "year": 2019,
        "authors": "Siddharth Reddy and Anca D Dragan and Sergey Levine"
      },
      {
        "title": "Shared Autonomy via Deep Reinforcement Learning",
        "abstract": "In shared autonomy, user input is combined with semi-autonomous control to achieve a common goal. The goal is often unknown ex-ante, so prior work enables agents to infer the goal from user input and assist with the task. Such methods tend to assume some combination of knowledge of the dynamics of the environment, the user's policy given their goal, and the set of possible goals the user might target, which limits their application to real-world scenarios. We propose a deep reinforcement learning framework for model-free shared autonomy that lifts these assumptions. We use human-in-the-loop reinforcement learning with neural network function approximation to learn an end-to-end mapping from environmental observation and user input to agent action values, with task reward as the only form of supervision. This approach poses the challenge of following user commands closely enough to provide the user with real-time action feedback and thereby ensure high-quality user input, but also deviating from the user's actions when they are suboptimal. We balance these two needs by discarding actions whose values fall below some threshold, then selecting the remaining action closest to the user's input. Controlled studies with users (n = 12) and synthetic pilots playing a video game, and a pilot study with users (n = 4) flying a real quadrotor, demonstrate the ability of our algorithm to assist users with real-time control tasks in which the agent cannot directly access the user's private information through observations, but receives a reward signal and user input that both depend on the user's intent. The agent learns to assist the user without …",
        "year": 2018,
        "authors": "Siddharth Reddy and Anca D. Dragan and Sergey Levine"
      },
      {
        "title": "Where Do You Think You're Going?: Inferring Beliefs about Dynamics from Behavior",
        "abstract": "Inferring intent from observed behavior has been studied extensively within the frameworks of Bayesian inverse planning and inverse reinforcement learning. These methods infer a goal or reward function that best explains the actions of the observed agent, typically a human demonstrator. Another agent can use this inferred intent to predict, imitate, or assist the human user. However, a central assumption in inverse reinforcement learning is that the demonstrator is close to optimal. While models of suboptimal behavior exist, they typically assume that suboptimal actions are the result of some type of random noise or a known cognitive bias, like temporal inconsistency. In this paper, we take an alternative approach, and model suboptimal behavior as the result of internal model misspecification: the reason that user actions might deviate from near-optimal actions is that the user has an incorrect set of beliefs about the rules--the dynamics--governing how actions affect the environment. Our insight is that while demonstrated actions may be suboptimal in the real world, they may actually be near-optimal with respect to the user's internal model of the dynamics. By estimating these internal beliefs from observed behavior, we arrive at a new method for inferring intent. We demonstrate in simulation and in a user study with 12 participants that this approach enables us to more accurately model human intent, and can be used in a variety of applications, including offering assistance in a shared autonomy framework and inferring human preferences.",
        "year": 2018,
        "authors": "Siddharth Reddy and Anca D. Dragan and Sergey Levine"
      }
    ],
    "SgST3LkAAAAJ": [
      {
        "title": "Extracting Training Data from Large Language Models",
        "abstract": "It has become common to publish large (billion parameter) language models that have been trained on private datasets. This paper demonstrates that in such settings, an adversary can perform a training data extraction attack to recover individual training examples by querying the language model.",
        "year": 2020,
        "authors": "Nicholas Carlini and Florian Tramer and Eric Wallace and Matthew Jagielski and Ariel Herbert-Voss and Katherine Lee and Adam Roberts and Tom Brown and Dawn Song and Ulfar Erlingsson and Alina Oprea and Colin Raffel"
      },
      {
        "title": "AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts",
        "abstract": "The remarkable success of pretrained language models has motivated the study of what kinds of knowledge these models learn during pretraining. Reformulating tasks as fill-in-the-blanks problems (e.g., cloze tests) is a natural approach for gauging such knowledge, however, its usage is limited by the manual effort and guesswork required to write suitable prompts. To address this, we develop AutoPrompt, an automated method to create prompts for a diverse set of tasks, based on a gradient-guided search. Using AutoPrompt, we show that masked language models (MLMs) have an inherent capability to perform sentiment analysis and natural language inference without additional parameters or finetuning, sometimes achieving performance on par with recent state-of-the-art supervised models. We also show that our prompts elicit more accurate factual knowledge from MLMs than the manually created prompts on the LAMA benchmark, and that MLMs can be used as relation extractors more effectively than supervised relation extraction models. These results demonstrate that automatically generated prompts are a viable parameter-free alternative to existing probing methods, and as pretrained LMs become more sophisticated and capable, potentially a replacement for finetuning.",
        "year": 2020,
        "authors": "Taylor Shin and Yasaman Razeghi and Robert L Logan IV and Eric Wallace and Sameer Singh"
      },
      {
        "title": "Beyond the Imitation Game: Quantifying and Extrapolating the Capabilities of Language Models",
        "abstract": "Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit \"breakthrough\" behavior at …",
        "year": 2022,
        "authors": "Aarohi Srivastava and Abhinav Rastogi and Abhishek Rao and Abu Awal Md Shoeb and Abubakar Abid and Adam Fisch and Adam R Brown and Adam Santoro and Aditya Gupta and Adrià Garriga-Alonso and Agnieszka Kluska and Aitor Lewkowycz and Akshat Agarwal and Alethea Power and Alex Ray and Alex Warstadt and Alexander W Kocurek and Ali Safaya and Ali Tazarv and Alice Xiang and Alicia Parrish and Allen Nie and Aman Hussain and Amanda Askell and Amanda Dsouza and Ameet Rahane and Anantharaman S Iyer and Anders Andreassen and Andrea Santilli and Andreas Stuhlmüller and Andrew Dai and Andrew La and Andrew Lampinen and Andy Zou and Angela Jiang and Angelica Chen and Anh Vuong and Animesh Gupta and Anna Gottardi and Antonio Norelli and Anu Venkatesh and Arash Gholamidavoodi and Arfa Tabassum and Arul Menezes and Arun Kirubarajan and Asher Mullokandov and Ashish Sabharwal and Austin Herrick and Avia Efrat and Aykut Erdem and Ayla Karakaş and B Ryan Roberts and Bao Sheng Loe and Barret Zoph and Bartłomiej Bojanowski and Batuhan Özyurt and Behnam Hedayatnia and Behnam Neyshabur and Benjamin Inden and Benno Stein"
      }
    ],
    "K3QJPdMAAAAJ": [
      {
        "title": "Fbnet: Hardware-aware efficient convnet design via differentiable neural architecture search",
        "abstract": "Designing accurate and efficient ConvNets for mobile devices is challenging because the design space is combinatorially large. Due to this, previous neural architecture search (NAS) methods are computationally expensive. ConvNet architecture optimality depends on factors such as input resolution and target devices. However, existing approaches are too resource demanding for case-by-case redesigns. Also, previous work focuses primarily on reducing FLOPs, but FLOP count does not always reflect actual latency. To address these, we propose a differentiable neural architecture search (DNAS) framework that uses gradient-based methods to optimize ConvNet architectures, avoiding enumerating and training individual architectures separately as in previous methods. FBNets (Facebook-Berkeley-Nets), a family of models discovered by DNAS surpass state-of-the-art models both designed manually and generated automatically. FBNet-B achieves 74.1% top-1 accuracy on ImageNet with 295M FLOPs and 23.1 ms latency on a Samsung S8 phone, 2.4 x smaller and 1.5 x faster than MobileNetV2-1.3 with similar accuracy. Despite higher accuracy and lower latency than MnasNet, we estimate FBNet-B's search cost is 420x smaller than MnasNet's, at only 216 GPU-hours. Searched for different resolutions and channel sizes, FBNets achieve 1.5% to 6.4% higher accuracy than MobileNetV2. The smallest FBNet achieves 50.2% accuracy and 2.9 ms latency (345 frames per second) on a Samsung S8. Over a Samsung-optimized FBNet, the iPhone-X-optimized model achieves a 1.4 x speedup on an iPhone X. FBNet models are open-sourced at …",
        "year": 2019,
        "authors": "Bichen Wu and Xiaoliang Dai and Peizhao Zhang and Yanghan Wang and Fei Sun and Yiming Wu and Yuandong Tian and Peter Vajda and Yangqing Jia and Kurt Keutzer"
      },
      {
        "title": "Squeezeseg: Convolutional neural nets with recurrent crf for real-time road-object segmentation from 3d lidar point cloud",
        "abstract": "We address semantic segmentation of road-objects from 3D LiDAR point clouds. In particular, we wish to detect and categorize instances of interest, such as cars, pedestrians and cyclists. We formulate this problem as a point-wise classification problem, and propose an end-to-end pipeline called SqueezeSeg based on convolutional neural networks (CNN): the CNN takes a transformed LiDAR point cloud as input and directly outputs a point-wise label map, which is then refined by a conditional random field (CRF) implemented as a recurrent layer. Instance-level labels are then obtained by conventional clustering algorithms. Our CNN model is trained on LiDAR point clouds from the KITTI [1] dataset, and our point-wise segmentation labels are derived from 3D bounding boxes from KITTI. To obtain extra training data, we built a LiDAR simulator into Grand Theft Auto V (GTA-V), a popular video game, to synthesize …",
        "year": 2018,
        "authors": "Bichen Wu and Alvin Wan and Xiangyu Yue and Kurt Keutzer"
      },
      {
        "title": "Squeezesegv2: Improved model structure and unsupervised domain adaptation for road-object segmentation from a lidar point cloud",
        "abstract": "Earlier work demonstrates the promise of deep-learning-based approaches for point cloud segmentation; however, these approaches need to be improved to be practically useful. To this end, we introduce a new model SqueezeSegV2. With an improved model structure, SqueezeSetV2 is more robust against dropout noises in LiDAR point cloud and therefore achieves significant accuracy improvement. Training models for point cloud segmentation requires large amounts of labeled data, which is expensive to obtain. To sidestep the cost of data collection and annotation, simulators such as GTA-V can be used to create unlimited amounts of labeled, synthetic data. However, due to domain shift, models trained on synthetic data often do not generalize well to the real world. Existing domain-adaptation methods mainly focus on images and most of them cannot be directly applied to point clouds. We address this …",
        "year": 2019,
        "authors": "Bichen Wu and Xuanyu Zhou and Sicheng Zhao and Xiangyu Yue and Kurt Keutzer"
      }
    ],
    "ZaJEZpYAAAAJ": [
      {
        "title": "On the opportunities and risks of foundation models",
        "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",
        "year": 2021,
        "authors": "Rishi Bommasani and Drew A Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher Ré and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W Thomas and Florian Tramèr and Rose E Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang"
      },
      {
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models",
        "abstract": "DSpace at KOASAS: Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nKOASAS menu About KOASAS KAIST Library 검색 Advanced Search KOASAS About \nKOASAS Open Access Policy Browse Communities & Collections Researchers at KAIST Titles \nSubject By Date rss_1.0 rss_2.0 atom_1.0 sherpa SEARCH DSpace at KOASAS College of \nEngineering(공과대학)Kim Jaechul Graduate School of AI(김재철AI대학원)AI-Conference \nPapers(학술대회논문) Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nCited 0 time in webofscience Cited 0 time in scopus Hit : 2 Download : 0 Export DC(XML) Excel \nLim, Joseph Jaewhanresearcher Publisher IEEE Issue Date 2024-05-15 Citation IEEE \nInternational Conference on Robotics and Automation URI http://hdl.handle.net/10203/326144 \nAppears in Collection AI-Conference Papers(학술대회논문) Files in This Item There are no files …",
        "year": 2024,
        "authors": "Joseph Jaewhan Lim"
      },
      {
        "title": "Planning for autonomous cars that leverage effects on human actions.",
        "abstract": "Traditionally, autonomous cars make predictions about other drivers’ future trajectories, and plan to stay out of their way. This tends to result in defensive and opaque behaviors. Our key insight is that an autonomous car’s actions will actually affect what other cars will do in response, whether the car is aware of it or not. Our thesis is that we can leverage these responses to plan more efficient and communicative behaviors. We model the interaction between an autonomous car and a human driver as a dynamical system, in which the robot’s actions have immediate consequences on the state of the car, but also on human actions. We model these consequences by approximating the human as an optimal planner, with a reward function that we acquire through Inverse Reinforcement Learning. When the robot plans with this reward function in this dynamical system, it comes up with actions that purposefully change human state: it merges in front of a human to get them to slow down or to reach its own goal faster; it blocks two lanes to get them to switch to a third lane; or it backs up slightly at an intersection to get them to proceed first. Such behaviors arise from the optimization, without relying on hand-coded signaling strategies and without ever explicitly modeling communication. Our user study results suggest that the robot is indeed capable of eliciting desired changes in human state by planning using this dynamical system.",
        "year": 2016,
        "authors": "Dorsa Sadigh and Shankar Sastry and Sanjit A Seshia and Anca D Dragan"
      }
    ],
    "on2DUKoAAAAJ": [
      {
        "title": "Video-based AI for beat-to-beat assessment of cardiac function",
        "abstract": "Accurate assessment of cardiac function is crucial for the diagnosis of cardiovascular disease 1, screening for cardiotoxicity 2 and decisions regarding the clinical management of patients with a critical illness 3. However, human assessment of cardiac function focuses on a limited sampling of cardiac cycles and has considerable inter-observer variability despite years of training 4, 5. Here, to overcome this challenge, we present a video-based deep learning algorithm—EchoNet-Dynamic—that surpasses the performance of human experts in the critical tasks of segmenting the left ventricle, estimating ejection fraction and assessing cardiomyopathy. Trained on echocardiogram videos, our model accurately segments the left ventricle with a Dice similarity coefficient of 0.92, predicts ejection fraction with a mean absolute error of 4.1% and reliably classifies heart failure with reduced ejection fraction (area under the curve …",
        "year": 2020,
        "authors": "David Ouyang and Bryan He and Amirata Ghorbani and Neal Yuan and Joseph Ebinger and Curtis P Langlotz and Paul A Heidenreich and Robert A Harrington and David H Liang and Euan A Ashley and James Y Zou"
      },
      {
        "title": "Deep learning interpretation of echocardiograms",
        "abstract": "Echocardiography uses ultrasound technology to capture high temporal and spatial resolution images of the heart and surrounding structures, and is the most common imaging modality in cardiovascular medicine. Using convolutional neural networks on a large new dataset, we show that deep learning applied to echocardiography can identify local cardiac structures, estimate cardiac function, and predict systemic phenotypes that modify cardiovascular risk but not readily identifiable to human interpretation. Our deep learning model, EchoNet, accurately identified the presence of pacemaker leads (AUC = 0.89), enlarged left atrium (AUC = 0.86), left ventricular hypertrophy (AUC = 0.75), left ventricular end systolic and diastolic volumes ( = 0.74 and  = 0.70), and ejection fraction ( = 0.50), as well as predicted systemic phenotypes of age ( = 0.46), sex (AUC = 0.88), weight ( = 0.56), and height …",
        "year": 2020,
        "authors": "Amirata Ghorbani and David Ouyang and Abubakar Abid and Bryan He and Jonathan H Chen and Robert A Harrington and David H Liang and Euan A Ashley and James Y Zou"
      },
      {
        "title": "How medical AI devices are evaluated: limitations and recommendations from an analysis of FDA approvals",
        "abstract": "A comprehensive overview of medical AI devices approved by the US Food and Drug Administration sheds new light on limitations of the evaluation process that can mask vulnerabilities of devices when they are deployed on patients.",
        "year": 2021,
        "authors": "Eric Wu and Kevin Wu and Roxana Daneshjou and David Ouyang and Daniel E Ho and James Zou"
      }
    ],
    "GdOmgYwAAAAJ": [
      {
        "title": "White-Box Transformers via Sparse Rate Reduction: Compression Is All There Is?",
        "abstract": "In this paper, we contend that a natural objective of representation learning is to compress and transform the distribution of the data, say sets of tokens, towards a low-dimensional Gaussian mixture supported on incoherent subspaces. The goodness of such a representation can be evaluated by a principled measure, called sparse rate reduction, that simultaneously maximizes the intrinsic information gain and extrinsic sparsity of the learned representation. From this perspective, popular deep network architectures, including transformers, can be viewed as realizing iterative schemes to optimize this measure. Particularly, we derive a transformer block from alternating optimization on parts of this objective: the multihead self-attention operator compresses the representation by implementing an approximate gradient descent step on the coding rate of the features, and the subsequent multi-layer perceptron sparsifies the features. This leads to a family of white-box transformer-like deep network architectures, named crate, which are mathematically fully interpretable. We show, by way of a novel connection between denoising and compression, that the inverse to the aforementioned compressive encoding can be realized by the same class of crate architectures. Thus, the so-derived white-box architectures are universal to both encoders and decoders. Experiments show that these networks, despite their simplicity, indeed learn to compress and sparsify representations of large-scale real-world image and text datasets, and achieve strong performance across different settings: ViT, MAE, DINO, BERT, and GPT2. We believe the proposed computational …",
        "year": 2024,
        "authors": "Yaodong Yu* and Sam Buchanan* and Druv Pai* and Tianzhe Chu and Ziyang Wu and Shengbang Tong and Hao Bai and Yuexiang Zhai and Benjamin D Haeffele and Yi Ma"
      },
      {
        "title": "Emergence of segmentation with minimalistic white-box transformers",
        "abstract": "Transformer-like models for vision tasks have recently proven effective for a wide range of downstream applications such as segmentation and detection. Previous works have shown that segmentation properties emerge in vision transformers (ViTs) trained using self-supervised methods such as DINO, but not in those trained on supervised classification tasks. In this study, we probe whether segmentation emerges in transformer-based models solely as a result of intricate self-supervised learning mechanisms, or if the same emergence can be achieved under much broader conditions through proper design of the model architecture. Through extensive experimental results, we demonstrate that when employing a white-box transformer-like architecture known as CRATE, whose design explicitly models and pursues low-dimensional structures in the data distribution, segmentation properties, at both the whole and parts levels, already emerge with a minimalistic supervised training recipe. Layer-wise finer-grained analysis reveals that the emergent properties strongly corroborate the designed mathematical functions of the white-box network. Our results suggest a path to design white-box foundation models that are simultaneously highly performant and mathematically fully interpretable. Code is at \\url{https://github.com/Ma-Lab-Berkeley/CRATE}.",
        "year": 2023,
        "authors": "Yaodong Yu and Tianzhe Chu and Shengbang Tong and Ziyang Wu and Druv Pai and Sam Buchanan and Yi Ma"
      },
      {
        "title": "Independent and decentralized learning in markov potential games",
        "abstract": "We study a multi-agent reinforcement learning dynamics, and analyze its asymptotic behavior in infinite-horizon discounted Markov potential games. We focus on the independent and decentralized setting, where players do not know the game parameters, and cannot communicate or coordinate. In each stage, players update their estimate of Q-function that evaluates their total contingent payoff based on the realized one-stage reward in an asynchronous manner. Then, players independently update their policies by incorporating an optimal one-stage deviation strategy based on the estimated Q-function. Inspired by the actor-critic algorithm in single-agent reinforcement learning, a key feature of our learning dynamics is that agents update their Q-function estimates at a faster timescale than the policies. Leveraging tools from two-timescale asynchronous stochastic approximation theory, we characterize the …",
        "year": 2025,
        "authors": "Chinmay Maheshwari and Manxi Wu and Druv Pai and Shankar Sastry"
      }
    ],
    "FLJ86DwAAAAJ": [
      {
        "title": "Lightsecagg: a lightweight and versatile design for secure aggregation in federated learning",
        "abstract": "Secure model aggregation is a key component of federated learning (FL) that aims at protecting the privacy of each user’s individual model while allowing for their global aggregation. It can be applied to any aggregation-based FL approach for training a global or personalized model. Model aggregation needs to also be resilient against likely user dropouts in FL systems, making its design substantially more complex. State-of-the-art secure aggregation protocols rely on secret sharing of the random-seeds used for mask generations at the users to enable the reconstruction and cancellation of those belonging to the dropped users. The complexity of such approaches, however, grows substantially with the number of dropped users. We propose a new approach, named LightSecAgg, to overcome this bottleneck by changing the design from random-seed reconstruction of the dropped users''to one-shot aggregate-mask reconstruction of the active users via mask encoding/decoding''. We show that LightSecAgg achieves the same privacy and dropout-resiliency guarantees as the state-of-the-art protocols while significantly reducing the overhead for resiliency against dropped users. We also demonstrate that, unlike existing schemes, LightSecAgg can be applied to secure aggregation in the asynchronous FL setting. Furthermore, we provide a modular system design and optimized on-device parallelization for scalable implementation, by enabling computational overlapping between model training and on-device encoding, as well as improving the speed of concurrent receiving and sending of chunked masks. We evaluate LightSecAgg via extensive …",
        "year": 2022,
        "authors": "Jinhyun So and Chaoyang He and Chien-Sheng Yang and Songze Li and Qian Yu and Ramy E Ali and Basak Guler and Salman Avestimehr"
      },
      {
        "title": "Securing secure aggregation: Mitigating multi-round privacy leakage in federated learning",
        "abstract": "Secure aggregation is a critical component in federated learning (FL), which enables the server to learn the aggregate model of the users without observing their local models. Conventionally, secure aggregation algorithms focus only on ensuring the privacy of individual users in a single training round. We contend that such designs can lead to significant privacy leakages over multiple training rounds, due to partial user selection/participation at each round of FL. In fact, we show that the conventional random user selection strategies in FL lead to leaking users' individual models within number of rounds that is linear in the number of users. To address this challenge, we introduce a secure aggregation framework, Multi-RoundSecAgg, with multi-round privacy guarantees. In particular, we introduce a new metric to quantify the privacy guarantees of FL over multiple training rounds, and develop a structured user selection strategy that guarantees the long-term privacy of each user (over any number of training rounds). Our framework also carefully accounts for the fairness and the average number of participating users at each round. Our experiments on MNIST, CIFAR-10 and CIFAR-100 datasets in the IID and the non-IID settings demonstrate the performance improvement over the baselines, both in terms of privacy protection and test accuracy.",
        "year": 2023,
        "authors": "Jinhyun So* and Ramy E Ali* and Başak Güler and Jiantao Jiao and A Salman Avestimehr"
      },
      {
        "title": "Adaptive verifiable coded computing: Towards fast, secure and private distributed machine learning",
        "abstract": "Stragglers, Byzantine workers, and data privacy are the main bottlenecks in distributed cloud computing. Some prior works proposed coded computing strategies to jointly address all three challenges. They require either a large number of workers, a significant communication cost or a significant computational complexity to tolerate Byzantine workers. Much of the overhead in prior schemes comes from the fact that they tightly couple coding for all three problems into a single framework. In this paper, we propose Adaptive Verifiable Coded Computing (AVCC) framework that decouples the Byzantine node detection challenge from the straggler tolerance. AVCC leverages coded computing just for handling stragglers and privacy, and then uses an orthogonal approach that leverages verifiable computing to mitigate Byzantine workers. Furthermore, AVCC dynamically adapts its coding scheme to trade-off straggler …",
        "year": 2022,
        "authors": "Tingting Tang and Ramy E Ali and Hanieh Hashemi and Tynan Gangwani and Salman Avestimehr and Murali Annavaram"
      }
    ],
    "jIs-Y2gAAAAJ": [
      {
        "title": "Effects of nonverbal communication on efficiency and robustness in human-robot teamwork",
        "abstract": "Nonverbal communication plays an important role in coordinating teammates' actions for collaborative activities. In this paper, we explore the impact of non-verbal social cues and behavior on task performance by a human-robot team. We report our results from an experiment where naive human subjects guide a robot to perform a physical task using speech and gesture. Both self-report via questionnaire and behavioral analysis of video offer evidence to support our hypothesis that implicit non-verbal communication positively impacts human-robot task performance with respect to understandability of the robot, efficiency of task performance, and robustness to errors that arise from miscommunication.",
        "year": 2005,
        "authors": "Cynthia Breazeal and Cory D Kidd and Andrea Lockerd Thomaz and Guy Hoffman and Matt Berlin"
      },
      {
        "title": "Policy shaping: Integrating human feedback with reinforcement learning",
        "abstract": "A long term goal of Interactive Reinforcement Learning is to incorporate non-expert human feedback to solve complex tasks. State-of-the-art methods have approached this problem by mapping human information to reward and value signals to indicate preferences and then iterating over them to compute the necessary control policy. In this paper we argue for an alternate, more effective characterization of human feedback: Policy Shaping. We introduce Advise, a Bayesian approach that attempts to maximize the information gained from human feedback by utilizing it as direct labels on the policy. We compare Advise to state-of-the-art approaches and highlight scenarios where it outperforms them and importantly is robust to infrequent and inconsistent human feedback.",
        "year": 2013,
        "authors": "Shane Griffith and Kaushik Subramanian and Jonathan Scholz and Charles L Isbell and Andrea L Thomaz"
      },
      {
        "title": "Teachable robots: Understanding human teaching behavior to build more effective robot learners",
        "abstract": "While Reinforcement Learning (RL) is not traditionally designed for interactive supervisory input from a human teacher, several works in both robot and software agents have adapted it for human input by letting a human trainer control the reward signal. In this work, we experimentally examine the assumption underlying these works, namely that the human-given reward is compatible with the traditional RL reward signal. We describe an experimental platform with a simulated RL robot and present an analysis of real-time human teaching behavior found in a study in which untrained subjects taught the robot to perform a new task. We report three main observations on how people administer feedback when teaching a Reinforcement Learning agent: (a) they use the reward channel not only for feedback, but also for future-directed guidance; (b) they have a positive bias to their feedback, possibly using the signal as a …",
        "year": 2008,
        "authors": "Andrea L Thomaz and Cynthia Breazeal"
      }
    ],
    "rTw-pq0AAAAJ": [
      {
        "title": "Convnext v2: Co-designing and scaling convnets with masked autoencoders",
        "abstract": "Driven by improved architectures and better representation learning frameworks, the field of visual recognition has enjoyed rapid modernization and performance boost in the early 2020s. For example, modern ConvNets, represented by ConvNeXt models, have demonstrated strong performance across different application scenarios. Like many other architectures, ConvNeXt models were designed under the supervised learning setting with ImageNet labels. It is natural to expect ConvNeXt can also benefit from state-of-the-art self-supervised learning frameworks such as masked autoencoders (MAE), which was originally designed with Transformers. However, we show that simply combining the two designs yields subpar performance. In this paper, we develop an efficient and fully-convolutional masked autoencoder framework. We then upgrade the ConvNeXt architecture with a new Global Response Normalization (GRN) layer. GRN enhances inter-channel feature competition and is crucial for pre-training with masked input. The new model family, dubbed ConvNeXt V2, is a complete training recipe that synergizes both the architectural improvement and the advancement in self-supervised learning. With ConvNeXt V2, we are able to significantly advance pure ConvNets' performance across different recognition benchmarks including ImageNet classification, ADE20K segmentation and COCO detection. To accommodate different use cases, we provide pre-trained ConvNeXt V2 models of a wide range of complexity: from an efficient 3.7 M-parameter Atto model that achieves 76.8% top-1 accuracy on ImageNet, to a 650M Huge model that can …",
        "year": 2023,
        "authors": "Sanghyun Woo and Shoubhik Debnath and Ronghang Hu and Xinlei Chen and Zhuang Liu and In So Kweon and Saining Xie"
      },
      {
        "title": "Sam 2: Segment anything in images and videos",
        "abstract": "We present Segment Anything Model 2 (SAM 2), a foundation model towards solving promptable visual segmentation in images and videos. We build a data engine, which improves model and data via user interaction, to collect the largest video segmentation dataset to date. Our model is a simple transformer architecture with streaming memory for real-time video processing. SAM 2 trained on our data provides strong performance across a wide range of tasks. In video segmentation, we observe better accuracy, using 3x fewer interactions than prior approaches. In image segmentation, our model is more accurate and 6x faster than the Segment Anything Model (SAM). We believe that our data, model, and insights will serve as a significant milestone for video segmentation and related perception tasks. We are releasing our main model, dataset, as well as code for model training and our demo.",
        "year": 2024,
        "authors": "Nikhila Ravi and Valentin Gabeur and Yuan-Ting Hu and Ronghang Hu and Chaitanya Ryali and Tengyu Ma and Haitham Khedr and Roman Rädle and Chloe Rolland and Laura Gustafson and Eric Mintun and Junting Pan and Kalyan Vasudev Alwala and Nicolas Carion and Chao-Yuan Wu and Ross Girshick and Piotr Dollár and Christoph Feichtenhofer"
      },
      {
        "title": "Flava: A foundational language and vision alignment model",
        "abstract": "State-of-the-art vision and vision-and-language models rely on large-scale visio-linguistic pretraining for obtaining good performance on a variety of downstream tasks. Generally, such models are often either cross-modal (contrastive) or multi-modal (with earlier fusion) but not both; and they often only target specific modalities or tasks. A promising direction would be to use a single holistic universal model, as a\" foundation\", that targets all modalities at once---a true vision and language foundation model should be good at vision tasks, language tasks, and cross-and multi-modal vision and language tasks. We introduce FLAVA as such a model and demonstrate impressive performance on a wide range of 35 tasks spanning these target modalities.",
        "year": 2022,
        "authors": "Amanpreet Singh and Ronghang Hu and Vedanuj Goswami and Guillaume Couairon and Wojciech Galuba and Marcus Rohrbach and Douwe Kiela"
      }
    ],
    "dq3yXjkAAAAJ": [
      {
        "title": "Hyperband: A novel bandit-based approach to hyperparameter optimization",
        "abstract": "Performance of machine learning algorithms depends critically on identifying a good set of hyperparameters. While recent approaches use Bayesian optimization to adaptively select configurations, we focus on speeding up random search through adaptive resource allocation and early-stopping. We formulate hyperparameter optimization as a pure-exploration nonstochastic infinite-armed bandit problem where a predefined resource like iterations, data samples, or features is allocated to randomly sampled configurations. We introduce a novel algorithm, Hyperband, for this framework and analyze its theoretical properties, providing several desirable guarantees. Furthermore, we compare Hyperband with popular Bayesian optimization methods on a suite of hyperparameter optimization problems. We observe that Hyperband can provide over an order-of-magnitude speedup over our competitor set on a variety of deep-learning and kernel-based learning problems.",
        "year": 2017,
        "authors": "Lisha Li and Kevin Jamieson and Giulia DeSalvo and Afshin Rostamizadeh and Ameet Talwalkar"
      },
      {
        "title": "Non-stochastic best arm identification and hyperparameter optimization",
        "abstract": "Motivated by the task of hyperparameter optimization, we introduce the\\em non-stochastic best-arm identification problem. We identify an attractive algorithm for this setting that makes no assumptions on the convergence behavior of the arms’ losses, has no free-parameters to adjust, provably outperforms the uniform allocation baseline in favorable conditions, and performs comparably (up to\\log factors) otherwise. Next, by leveraging the iterative nature of many learning algorithms, we cast hyperparameter optimization as an instance of non-stochastic best-arm identification. Our empirical results show that, by allocating more resources to promising hyperparameter settings, our approach achieves comparable test accuracies an order of magnitude faster than the uniform strategy. The robustness and simplicity of our approach makes it well-suited to ultimately replace the uniform strategy currently used in most machine learning software packages.",
        "year": 2016,
        "authors": "Kevin Jamieson and Ameet Talwalkar"
      },
      {
        "title": "A system for massively parallel hyperparameter tuning",
        "abstract": "Modern learning models are characterized by large hyperparameter spaces and long training times. These properties, coupled with the rise of parallel computing and the growing demand to productionize machine learning workloads, motivate the need to develop mature hyperparameter optimization functionality in distributed computing settings. We address this challenge by first introducing a simple and robust hyperparameter optimization algorithm called ASHA, which exploits parallelism and aggressive early-stopping to tackle large-scale hyperparameter optimization problems. Our extensive empirical results show that ASHA outperforms existing state-of-the-art hyperparameter optimization methods; scales linearly with the number of workers in distributed settings; and is suitable for massive parallelism, converging to a high quality configuration in half the time taken by Vizier (Google’s internal hyperparameter optimization service) in an experiment with 500 workers. We then describe several design decisions we encountered, along with our associated solutions, when integrating ASHA in SystemX, an end-to-end production-quality machine learning system that offers hyperparameter tuning as a service.",
        "year": 2020,
        "authors": "Liam Li and Kevin Jamieson and Afshin Rostamizadeh and Ekaterina Gonina and Jonathan Ben-Tzur and Moritz Hardt and Benjamin Recht and Ameet Talwalkar"
      }
    ],
    "2DBmo-wAAAAJ": [
      {
        "title": "Scalable deep reinforcement learning for vision-based robotic manipulation",
        "abstract": "In this paper, we study the problem of learning vision-based dynamic manipulation skills using a scalable reinforcement learning approach. We study this problem in the context of grasping, a longstanding challenge in robotic manipulation. In contrast to static learning behaviors that choose a grasp point and then execute the desired grasp, our method enables closed-loop vision-based control, whereby the robot continuously updates its grasp strategy based on the most recent observations to optimize long-horizon grasp success. To that end, we introduce QT-Opt, a scalable self-supervised vision-based reinforcement learning framework that can leverage over 580k real-world grasp attempts to train a deep neural network Q-function with over 1.2 M parameters to perform closed-loop, real-world grasping that generalizes to 96% grasp success on unseen objects. Aside from attaining a very high success rate, our method exhibits behaviors that are quite distinct from more standard grasping systems: using only RGB vision-based perception from an over-the-shoulder camera, our method automatically learns regrasping strategies, probes objects to find the most effective grasps, learns to reposition objects and perform other non-prehensile pre-grasp manipulations, and responds dynamically to disturbances and perturbations.",
        "year": 2018,
        "authors": "Dmitry Kalashnikov and Alex Irpan and Peter Pastor and Julian Ibarz and Alexander Herzog and Eric Jang and Deirdre Quillen and Ethan Holly and Mrinal Kalakrishnan and Vincent Vanhoucke and Sergey Levine"
      },
      {
        "title": "Do as i can, not as i say: Grounding language in robotic affordances",
        "abstract": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model's \"hands and eyes,\" while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally-extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project's website and the video can be found at https …",
        "year": 2022,
        "authors": "Michael Ahn and Anthony Brohan and Noah Brown and Yevgen Chebotar and Omar Cortes and Byron David and Chelsea Finn and Chuyuan Fu and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Daniel Ho and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Eric Jang and Rosario Jauregui Ruano and Kyle Jeffrey and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Kuang-Huei Lee and Sergey Levine and Yao Lu and Linda Luu and Carolina Parada and Peter Pastor and Jornell Quiambao and Kanishka Rao and Jarek Rettinghouse and Diego Reyes and Pierre Sermanet and Nicolas Sievers and Clayton Tan and Alexander Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Mengyuan Yan and Andy Zeng"
      },
      {
        "title": "Rt-1: Robotics transformer for real-world control at scale",
        "abstract": "By transferring knowledge from large, diverse, task-agnostic datasets, modern machine learning models can solve specific downstream tasks either zero-shot or with small task-specific datasets to a high level of performance. While this capability has been demonstrated in other fields such as computer vision, natural language processing or speech recognition, it remains to be shown in robotics, where the generalization capabilities of the models are particularly critical due to the difficulty of collecting real-world robotic data. We argue that one of the keys to the success of such general robotic models lies with open-ended task-agnostic training, combined with high-capacity architectures that can absorb all of the diverse, robotic data. In this paper, we present a model class, dubbed Robotics Transformer, that exhibits promising scalable model properties. We verify our conclusions in a study of different model classes and their ability to generalize as a function of the data size, model size, and data diversity based on a large-scale data collection on real robots performing real-world tasks. The project's website and videos can be found at robotics-transformer1.github.io",
        "year": 2022,
        "authors": "Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Joseph Dabis and Chelsea Finn and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Tomas Jackson and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Kuang-Huei Lee and Sergey Levine and Yao Lu and Utsav Malla and Deeksha Manjunath and Igor Mordatch and Ofir Nachum and Carolina Parada and Jodilyn Peralta and Emily Perez and Karl Pertsch and Jornell Quiambao and Kanishka Rao and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Kevin Sayed and Jaspiar Singh and Sumedh Sontakke and Austin Stone and Clayton Tan and Huong Tran and Vincent Vanhoucke and Steve Vega and Quan Vuong and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich"
      }
    ],
    "lsbreWwAAAAJ": [
      {
        "title": "Deep imitation learning for complex manipulation tasks from virtual reality teleoperation",
        "abstract": "Imitation learning is a powerful paradigm for robot skill acquisition. However, obtaining demonstrations suitable for learning a policy that maps from raw pixels to actions can be challenging. In this paper we describe how consumer-grade Virtual Reality headsets and hand tracking hardware can be used to naturally teleoperate robots to perform complex tasks. We also describe how imitation learning can learn deep neural network policies (mapping from pixels to actions) that can acquire the demonstrated skills. Our experiments showcase the effectiveness of our approach for learning visuomotor skills.",
        "year": 2018,
        "authors": "Tianhao Zhang and Zoe McCarthy and Owen Jow and Dennis Lee and Xi Chen and Ken Goldberg and Pieter Abbeel"
      },
      {
        "title": "Quasi-static manipulation of a Kirchhoff elastic rod based on a geometric analysis of equilibrium configurations",
        "abstract": "Consider a thin, flexible wire of fixed length that is held at each end by a robotic gripper. Any curve traced by this wire when in static equilibrium is a local solution to a geometric optimal control problem, with boundary conditions that vary with the position and orientation of each gripper. We prove that the set of all local solutions to this problem over all possible boundary conditions is a smooth manifold of finite dimension that can be parameterized by a single chart. We show that this chart makes it easy to implement a sampling-based algorithm for quasi-static manipulation planning. We characterize the performance of such an algorithm with experiments in simulation.",
        "year": 2014,
        "authors": "Timothy Bretl and Zoe McCarthy"
      },
      {
        "title": "Neuralpde: Automating physics-informed neural networks (pinns) with error approximations",
        "abstract": "Physics-informed neural networks (PINNs) are an increasingly powerful way to solve partial differential equations, generate digital twins, and create neural surrogates of physical models. In this manuscript we detail the inner workings of NeuralPDE.jl and show how a formulation structured around numerical quadrature gives rise to new loss functions which allow for adaptivity towards bounded error tolerances. We describe the various ways one can use the tool, detailing mathematical techniques like using extended loss functions for parameter estimation and operator discovery, to help potential users adopt these PINN-based techniques into their workflow. We showcase how NeuralPDE uses a purely symbolic formulation so that all of the underlying training code is generated from an abstract formulation, and show how to make use of GPUs and solve systems of PDEs. Afterwards we give a detailed performance analysis which showcases the trade-off between training techniques on a large set of PDEs. We end by focusing on a complex multiphysics example, the Doyle-Fuller-Newman (DFN) Model, and showcase how this PDE can be formulated and solved with NeuralPDE. Together this manuscript is meant to be a detailed and approachable technical report to help potential users of the technique quickly get a sense of the real-world performance trade-offs and use cases of the PINN techniques.",
        "year": 2021,
        "authors": "Kirill Zubov and Zoe McCarthy and Yingbo Ma and Francesco Calisto and Valerio Pagliarino and Simone Azeglio and Luca Bottero and Emmanuel Luján and Valentin Sulzer and Ashutosh Bharambe and Nand Vinchhi and Kaushik Balakrishnan and Devesh Upadhyay and Chris Rackauckas"
      }
    ],
    "fpVf9QkAAAAJ": [
      {
        "title": "Lipschitz-constrained unsupervised skill discovery",
        "abstract": "We study the problem of unsupervised skill discovery, whose goal is to learn a set of diverse and useful skills with no external reward. There have been a number of skill discovery methods based on maximizing the mutual information (MI) between skills and states. However, we point out that their MI objectives usually prefer static skills to dynamic ones, which may hinder the application for downstream tasks. To address this issue, we propose Lipschitz-constrained Skill Discovery (LSD), which encourages the agent to discover more diverse, dynamic, and far-reaching skills. Another benefit of LSD is that its learned representation function can be utilized for solving goal-following downstream tasks even in a zero-shot manner — i.e., without further training or complex planning. Through experiments on various MuJoCo robotic locomotion and manipulation environments, we demonstrate that LSD outperforms previous approaches in terms of skill diversity, state space coverage, and performance on seven downstream tasks including the challenging task of following multiple goals on Humanoid. Our code and videos are available at https://shpark.me/projects/lsd/.",
        "year": 2022,
        "authors": "Seohong Park and Jongwook Choi and Jaekyeom Kim and Honglak Lee and Gunhee Kim"
      },
      {
        "title": "Hiql: Offline goal-conditioned rl with latent states as actions",
        "abstract": "Unsupervised pre-training has recently become the bedrock for computer vision and natural language processing. In reinforcement learning (RL), goal-conditioned RL can potentially provide an analogous self-supervised approach for making use of large quantities of unlabeled (reward-free) data. However, building effective algorithms for goal-conditioned RL that can learn directly from diverse offline data is challenging, because it is hard to accurately estimate the exact value function for faraway goals. Nonetheless, goal-reaching problems exhibit structure, such that reaching distant goals entails first passing through closer subgoals. This structure can be very useful, as assessing the quality of actions for nearby goals is typically easier than for more distant goals. Based on this idea, we propose a hierarchical algorithm for goal-conditioned RL from offline data. Using one action-free value function, we learn two policies that allow us to exploit this structure: a high-level policy that treats states as actions and predicts (a latent representation of) a subgoal and a low-level policy that predicts the action for reaching this subgoal. Through analysis and didactic examples, we show how this hierarchical decomposition makes our method robust to noise in the estimated value function. We then apply our method to offline goal-reaching benchmarks, showing that our method can solve long-horizon tasks that stymie prior methods, can scale to high-dimensional image observations, and can readily make use of action-free data. Our code is available at https://seohong. me/projects/hiql/",
        "year": 2023,
        "authors": "Seohong Park and Dibya Ghosh and Benjamin Eysenbach and Sergey Levine"
      },
      {
        "title": "Controllability-aware unsupervised skill discovery",
        "abstract": "One of the key capabilities of intelligent agents is the ability to discover useful skills without external supervision. However, the current unsupervised skill discovery methods are often limited to acquiring simple, easy-to-learn skills due to the lack of incentives to discover more complex, challenging behaviors. We introduce a novel unsupervised skill discovery method, Controllability-aware Skill Discovery (CSD), which actively seeks complex, hard-to-control skills without supervision. The key component of CSD is a controllability-aware distance function, which assigns larger values to state transitions that are harder to achieve with the current skills. Combined with distance-maximizing skill discovery, CSD progressively learns more challenging skills over the course of training as our jointly trained distance function reduces rewards for easy-to-achieve skills. Our experimental results in six robotic manipulation and locomotion environments demonstrate that CSD can discover diverse complex skills including object manipulation and locomotion skills with no supervision, significantly outperforming prior unsupervised skill discovery methods. Videos and code are available at https://seohong.me/projects/csd/",
        "year": 2023,
        "authors": "Seohong Park and Kimin Lee and Youngwoon Lee and Pieter Abbeel"
      }
    ],
    "LjsKfKYAAAAJ": [
      {
        "title": "Pairwise proximal policy optimization: Harnessing relative feedback for llm alignment",
        "abstract": "Large Language Models (LLMs) can acquire extensive world knowledge through pre-training on large corpora. However, due to exposure to low-quality data, LLMs may exhibit harmful behavior without aligning with human values. The dominant approach for steering LLMs towards beneficial behavior involves Reinforcement Learning with Human Feedback (RLHF), with Proximal Policy Optimization (PPO) serving as the default RL optimizer. Despite its effectiveness, PPO has limitations when optimizing rewards trained from comparison-based loss. Primarily, PPO is not invariant to equivalent reward functions containing identical preference information due to the need to calibrate the reward scale. Additionally, PPO's necessity for token-wise updates introduces complexity in both function approximation and algorithm design compared to trajectory-wise optimization. This paper proposes a new framework, reinforcement learning with relative feedback, and a novel trajectory-wise policy gradient algorithm, Pairwise Proximal Policy Optimization (P3O) that operates directly on comparative rewards. We show theoretically that P3O is invariant to equivalent rewards and avoids the complexity of PPO. Empirical evaluations demonstrate that P3O outperforms PPO in the KL-Reward trade-off and can align with human preferences as well as or better than prior methods. In summary, this work introduces a simpler yet effective approach for aligning LLMs to human preferences through relative feedback.",
        "year": 2023,
        "authors": "Tianhao Wu and Banghua Zhu and Ruoyu Zhang and Zhaojin Wen and Kannan Ramchandran and Jiantao Jiao"
      },
      {
        "title": "EmbedLLM: Learning Compact Representations of Large Language Models",
        "abstract": "With hundreds of thousands of language models available on Huggingface today, efficiently evaluating and utilizing these models across various downstream, tasks has become increasingly critical. Many existing methods repeatedly learn task-specific representations of Large Language Models (LLMs), which leads to inefficiencies in both time and computational resources. To address this, we propose EmbedLLM, a framework designed to learn compact vector representations, of LLMs that facilitate downstream applications involving many models, such as model routing. We introduce an encoder-decoder approach for learning such embeddings, along with a systematic framework to evaluate their effectiveness. Empirical results show that EmbedLLM outperforms prior methods in model routing both in accuracy and latency. Additionally, we demonstrate that our method can forecast a model's performance on multiple benchmarks, without incurring additional inference cost. Extensive probing experiments validate that the learned embeddings capture key model characteristics, e.g. whether the model is specialized for coding tasks, even without being explicitly trained on them. We open source our dataset, code and embedder to facilitate further research and application.",
        "year": 2024,
        "authors": "Richard Zhuang and Tianhao Wu and Zhaojin Wen and Andrew Li and Jiantao Jiao and Kannan Ramchandran"
      }
    ],
    "wLf0Vw0AAAAJ": [
      {
        "title": "Stability and robustness analysis of a class of adaptive controllers for robotic manipulators",
        "abstract": "The stability and robustness properties of the adaptive control scheme proposed by Sadegh and Horowitz (1987) are stud ied. The properties include the global exponential stability and Lpinput/output stability of the nonadaptive (i.e., fixed- parameter) control system and the global asymptotic stability of the adaptive control scheme. Sufficient conditions for the convergence of the estimated parameters to their true values are also given. A computationally efficient adaptation scheme that is a modified version of the original scheme is proposed. The modified scheme utilizes the desired trajectory outputs, which can be calculated a priori, instead of the actual joint outputs in the parameter adaptation algorithm and the non linearity compensation controller. Sufficient conditions for guaranteeing all the stability properties of the original scheme in the modified scheme are also explicitly derived. A com puter simulation study of …",
        "year": 1990,
        "authors": "Nader Sadegh and Roberto Horowitz"
      },
      {
        "title": "Control design of an automated highway system",
        "abstract": "Describes the design of an automated highway system (AHS) developed over the past ten years in the California PATH program. The AHS is a large, complex system, in which vehicles are automatically controlled. The design and implementation of the AHS required advances in actuator and sensor technologies, as well as the design, analysis, simulation, and testing of large-scale, hierarchical hybrid control systems. The paper focuses on the multilayer AHS control architecture and some questions of implementation. It discusses in detail the design and safety verification of the on-board vehicle control system and the design of the link-layer traffic-flow controller.",
        "year": 2002,
        "authors": "Roberto Horowitz and Pravin Varaiya"
      },
      {
        "title": "Optimal freeway ramp metering using the asymmetric cell transmission model",
        "abstract": "The onramp metering control problem is posed using a cell transmission-like model called the asymmetric cell transmission model (ACTM). The problem formulation captures both freeflow and congested conditions, and includes upper bounds on the metering rates and on the onramp queue lengths. It is shown that a near-global solution to the resulting nonlinear optimization problem can be found by solving a single linear program, whenever certain conditions are met. The most restrictive of these conditions requires the congestion on the mainline not to back up onto the onramps whenever optimal metering is used. The technique is tested numerically using data from a severely congested stretch of freeway in southern California. Simulation results predict a 17.3% reduction in delay when queue constraints are enforced.",
        "year": 2006,
        "authors": "Gabriel Gomes and Roberto Horowitz"
      }
    ],
    "df-THM0AAAAJ": [
      {
        "title": "From crowdsourced data to high-quality benchmarks: Arena-hard and benchbuilder pipeline",
        "abstract": "The rapid evolution of Large Language Models (LLMs) has outpaced the development of model evaluation, highlighting the need for continuous curation of new, challenging benchmarks. However, manual curation of high-quality, human-aligned benchmarks is expensive and time-consuming. To address this, we introduce BenchBuilder, an automated pipeline that leverages LLMs to curate high-quality, open-ended prompts from large, crowd-sourced datasets, enabling continuous benchmark updates without human in the loop. We apply BenchBuilder to datasets such as Chatbot Arena and WildChat-1M, extracting challenging prompts and utilizing LLM-as-a-Judge for automatic model evaluation. To validate benchmark quality, we propose new metrics to measure a benchmark's alignment with human preferences and ability to separate models. We release Arena-Hard-Auto, a benchmark consisting 500 challenging prompts curated by BenchBuilder. Arena-Hard-Auto provides 3x higher separation of model performances compared to MT-Bench and achieves 98.6% correlation with human preference rankings, all at a cost of $20. Our work sets a new framework for the scalable curation of automated benchmarks from extensive data.",
        "year": 2024,
        "authors": "Tianle Li and Wei-Lin Chiang and Evan Frick and Lisa Dunlap and Tianhao Wu and Banghua Zhu and Joseph E Gonzalez and Ion Stoica"
      },
      {
        "title": "Starling-7b: Improving helpfulness and harmlessness with rlaif",
        "abstract": "This paper presents Starling-7B, the current best-performing 7B chat model on Chatbot Arena, along with its training dataset Nectar, a high-quality preference dataset collected by prompting GPT-4 to rank responses. We propose an internal pairwise rating technique, where the model considers all pairings before providing a ranking decision, leveraging the proven pairwise rating capability of LLMs without the cost of individual pairwise calls. The resulting Nectar dataset comprises 182,954 chat prompts, each with seven responses from various models, ranked by GPT-4, equating to 3.8 million high-quality pairwise comparisons. We introduce Starling-RM-7B and Starling-RM-34B, the reward model suites trained with a K-wise preference loss on Nectar, outperforming pairwise counterparts. We benchmark reward model training pipelines across metrics such as human preference, truthfulness, and safety. Using Nectar and our new training pipeline, we fine-tuned Openchat-3.5 to create Starling-LM-7B, achieving significant performance enhancements on MT-Bench, AlpacaEval, and human evaluation metrics. To facilitate research and understanding of RLHF mechanisms, we open-source the Nectar dataset, the reward models, and the language models.",
        "year": 2024,
        "authors": "Banghua Zhu and Evan Frick and Tianhao Wu and Hanlin Zhu and Karthik Ganesan and Wei-Lin Chiang and Jian Zhang and Jiantao Jiao"
      },
      {
        "title": "RouteLLM: Learning to Route LLMs from Preference Data",
        "abstract": "Large language models (LLMs) excel at a wide range of tasks, but choosing the right model often involves balancing performance and cost. Powerful models offer better results but are expensive, while smaller models are more cost-effective but less capable. To address this trade-off, we introduce a training framework for learning efficient router models that dynamically select between a stronger and weaker LLM during inference. Our framework leverages human preference data and employs data augmentation techniques to enhance performance. Evaluations on public benchmarks show that our approach can reduce costs by over 2 times without sacrificing response quality. Moreover, our routers exhibit strong generalization capabilities, maintaining performance even when routing between LLMs not included in training. This highlights the potential of our framework to deliver cost-effective, high-performance LLM solutions.",
        "year": 2024,
        "authors": "Isaac Ong and Amjad Almahairi and Vincent Wu and Wei-Lin Chiang and Tianhao Wu and Joseph E Gonzalez and M Waleed Kadous and Ion Stoica"
      }
    ],
    "XM97iScAAAAJ": [
      {
        "title": "Graphcut textures: Image and video synthesis using graph cuts",
        "abstract": "In this paper we introduce a new algorithm for image and video texture synthesis. In our approach, patch regions from a sample image or video are transformed and copied to the output and then stitched together along optimal seams to generate a new (and typically larger) output. In contrast to other techniques, the size of the patch is not chosen a-priori, but instead a graph cut technique is used to determine the optimal patch region for any given offset between the input and output texture. Unlike dynamic programming, our graph cut technique for seam optimization is applicable in any dimension. We specifically explore it in 2D and 3D to perform video texture synthesis in addition to regular image synthesis. We present approximative offset search techniques that work well in conjunction with the presented patch size optimization. We show results for synthesizing regular, random, and natural images and videos. We …",
        "year": 2003,
        "authors": "Vivek Kwatra and Arno Schödl and Irfan Essa and Greg Turk and Aaron Bobick"
      },
      {
        "title": "The aware home: A living laboratory for ubiquitous computing research",
        "abstract": "We are building a home, called the Aware Home, to create a living laboratory for research in ubiquitous computing for everyday activities. This paper introduces the Aware Home project and outlines some of our technology-and human-centered research objectives in creating the Aware Home.",
        "year": 1999,
        "authors": "Cory D Kidd and Robert Orr and Gregory D Abowd and Christopher G Atkeson and Irfan A Essa and Blair MacIntyre and Elizabeth Mynatt and Thad E Starner and Wendy Newstetter"
      },
      {
        "title": "Coding, analysis, interpretation, and recognition of facial expressions",
        "abstract": "We describe a computer vision system for observing facial motion by using an optimal estimation optical flow method coupled with geometric, physical and motion-based dynamic models describing the facial structure. Our method produces a reliable parametric representation of the face's independent muscle action groups, as well as an accurate estimate of facial motion. Previous efforts at analysis of facial expression have been based on the facial action coding system (FACS), a representation developed in order to allow human psychologists to code expression from static pictures. To avoid use of this heuristic coding scheme, we have used our computer vision system to probabilistically characterize facial motion and muscle activation in an experimental population, thus deriving a new, more accurate, representation of human facial expressions that we call FACS+. Finally, we show how this method can be used …",
        "year": 1997,
        "authors": "Irfan A.  Essa and Alex Paul Pentland"
      }
    ],
    "i38QlUwAAAAJ": [
      {
        "title": "On the opportunities and risks of foundation models",
        "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",
        "year": 2021,
        "authors": "Rishi Bommasani and Drew A Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher Ré and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W Thomas and Florian Tramèr and Rose E Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang"
      },
      {
        "title": "Learning imbalanced datasets with label-distribution-aware margin loss",
        "abstract": "Deep learning algorithms can fare poorly when the training dataset suffers from heavy class-imbalance but the testing criterion requires good generalization on less frequent classes. We design two novel methods to improve performance in such scenarios. First, we propose a theoretically-principled label-distribution-aware margin (LDAM) loss motivated by minimizing a margin-based generalization bound. This loss replaces the standard cross-entropy objective during training and can be applied with prior strategies for training with class-imbalance such as re-weighting or re-sampling. Second, we propose a simple, yet effective, training schedule that defers re-weighting until after the initial stage, allowing the model to learn an initial representation while avoiding some of the complications associated with re-weighting or re-sampling. We test our methods on several benchmark vision tasks including the real-world imbalanced dataset iNaturalist 2018. Our experiments show that either of these methods alone can already improve over existing techniques and their combination achieves even better performance gains.",
        "year": 2019,
        "authors": "Kaidi Cao and Colin Wei and Adrien Gaidon and Nikos Arechiga and Tengyu Ma"
      },
      {
        "title": "A simple but tough-to-beat baseline for sentence embeddings",
        "abstract": "The success of neural network methods for computing word embeddings has motivated methods for generating semantic embeddings of longer pieces of text, such as sentences and paragraphs. Surprisingly, Wieting et al (ICLR'16) showed that such complicated methods are outperformed, especially in out-of-domain (transfer learning) settings, by simpler methods involving mild retraining of word embeddings and basic linear regression. The  method of Wieting et al. requires retraining with a substantial labeled dataset such as Paraphrase Database (Ganitkevitch et al., 2013). The current paper goes further, showing that the following completely unsupervised sentence embedding is a formidable baseline: Use word embeddings computed using one of the popular methods on unlabeled corpus like Wikipedia, represent the sentence by a weighted average of the word vectors, and then modify them a bit using PCA/SVD. This weighting improves performance by about 10% to 30% in textual similarity tasks, and beats sophisticated supervised methods including RNN's and LSTM's. It even improves Wieting et al.'s embeddings. This simple method should be used as the baseline to beat in future, especially when labeled training data is scarce or nonexistent. The paper also gives a theoretical explanation of the success of the above unsupervised method using a latent variable generative model for sentences, which is a simple extension of the model in Arora et al. (TACL'16) with new \"smoothing\" terms that allow for words occurring out of context, as well as high probabilities for words like and, not in all contexts.",
        "year": 2016,
        "authors": "Sanjeev Arora and Yingyu Liang and Tengyu Ma"
      }
    ],
    "umivlPQAAAAJ": [
      {
        "title": "Sample-optimal parametric q-learning using linearly additive features",
        "abstract": "Consider a Markov decision process (MDP) that admits a set of state-action features, which can linearly express the process’s probabilistic transition model. We propose a parametric Q-learning algorithm that finds an approximate-optimal policy using a sample size proportional to the feature dimension  and invariant with respect to the size of the state space. To further improve its sample efficiency, we exploit the monotonicity property and intrinsic noise structure of the Bellman operator, provided the existence of anchor state-actions that imply implicit non-negativity in the feature space. We augment the algorithm using techniques of variance reduction, monotonicity preservation, and confidence bounds. It is proved to find a policy which is -optimal from any initial state with high probability using  sample transitions for arbitrarily large-scale MDP with a discount factor . A matching information-theoretical lower bound is proved, confirming the sample optimality of the proposed method with respect to all parameters (up to polylog factors).",
        "year": 2019,
        "authors": "Lin Yang and Mengdi Wang"
      },
      {
        "title": "Model-based reinforcement learning with value-targeted regression",
        "abstract": "This paper studies model-based reinforcement learning (RL) for regret minimization. We focus on finite-horizon episodic RL where the transition model  belongs to a known family of models , a special case of which is when models in  take the form of linear mixtures: . We propose a model based RL algorithm that is based on the optimism principle: In each episode, the set of models that are ‘consistent’with the data collected is constructed. The criterion of consistency is based on the total squared error that the model incurs on the task of predicting\\emph {state values} as determined by the last value estimate along the transitions. The next value function is then chosen by solving the optimistic planning problem with the constructed set of models. We derive a bound on the regret, which, in the special case of linear mixtures, takes the form , where ,  and  are the horizon, the total number of steps and the dimension of , respectively. In particular, this regret bound is independent of the total number of states or actions, and is close to a lower bound . For a general model family , the regret bound is derived based on the Eluder dimension.",
        "year": 2020,
        "authors": "Alex Ayoub and Zeyu Jia and Csaba Szepesvari and Mengdi Wang and Lin Yang"
      },
      {
        "title": "Reinforcement learning in feature space: Matrix bandit, kernels, and regret bound",
        "abstract": "Exploration in reinforcement learning (RL) suffers from the curse of dimensionality when the state-action space is large. A common practice is to parameterize the high-dimensional value and policy functions using given features. However existing methods either have no theoretical guarantee or suffer a regret that is exponential in the planning horizon . In this paper, we propose an online RL algorithm, namely the MatrixRL, that leverages ideas from linear bandit to learn a low-dimensional representation of the probability transition model while carefully balancing the exploitation-exploration tradeoff. We show that MatrixRL achieves a regret bound  where  is the number of features, independent with the number of state-action pairs. MatrixRL has an equivalent kernelized version, which is able to work with an arbitrary kernel Hilbert space without using explicit features. In this case, the kernelized MatrixRL satisfies a regret bound ${O}\\big (H^ 2\\wt {d}\\log T\\sqrt {T}\\big) $, where $\\wt {d} $ is the effective dimension of the kernel space.",
        "year": 2020,
        "authors": "Lin Yang and Mengdi Wang"
      }
    ],
    "3yQFuR4AAAAJ": [
      {
        "title": "Thermal expansion coefficient of diamond in a wide temperature range",
        "abstract": "Experimental data for the linear thermal expansion coefficient of diamond available in the literature were analyzed and carefully selected to produce a representative dataset, which was fit with a multi-frequency Einstein model (R. Reeber, 1975) using a limited number of effective independent oscillators. In the temperature range of 10–300 K, the fits were constrained using the high-accuracy data (S. Stoupin and Yu. Shvyd’ko, 2011). It was found that the multi-frequency model precisely describes the available data from 10 K to approximately 1000 K. Above 1000 K, discrepancies were found, which suggest presence of anharmonic effects in diamond and/or influence of defects. The obtained semi-empirical formulas can be used as convenient continuous approximations for the thermal expansion coefficient in modeling thermoelastic behavior of diamond components subjected to large temperature variations.",
        "year": 2019,
        "authors": "P Jacobson and S Stoupin"
      },
      {
        "title": "Hybrid convolutional optoelectronic reservoir computing for image recognition",
        "abstract": "Photonic delay-based reservoircomputers (RC) have emerged as an attractive high-speed, low-power alternative to traditional digital hardware for AI. We demonstrate experimentally a novel hybrid RC scheme in which input data is first preprocessed through several convolutional layers, either trained or untrained, digitally to generate novel feature maps. These random feature maps are then processed through an optoelectronic implementation of delay-based RC. Using the MNIST dataset of handwritten digits, experiments of our proposed hybrid scheme achieve classification error of 1.6% using untrained convolutions, and an error of 1.1% using trained convolutions, results comparable to that of state-of-the-art machine learning algorithms. Additionally, our experimental implementation can offer a potential 10× decrease in model training time, compared to that of common digital alternatives.",
        "year": 2021,
        "authors": "Philip Jacobson and Mizuki Shirao and Kerry Yu and Guan-Lin Su and Ming C Wu"
      },
      {
        "title": "Center Feature Fusion: Selective Multi-Sensor Fusion of Center-based Objects",
        "abstract": "Leveraging multi-modal fusion, especially between camera and LiDAR, has become essential for building accurate and robust 3D object detection systems for autonomous vehicles. Until recently, point decorating approaches, in which point clouds are augmented with camera features, have been the dominant approach in the field. However, these approaches fail to utilize the higher resolution images from cameras. Recent works projecting camera features to the bird's-eye-view (BEV) space for fusion have also been proposed, however they require projecting millions of pixels, most of which only contain background information. In this work, we propose a novel approach Center Feature Fusion (CFF), in which we leverage center-based detection networks in both the camera and LiDAR streams to identify relevant object locations. We then use the center-based detection to identify the locations of pixel features …",
        "year": 2022,
        "authors": "Philip Jacobson and Yiyang Zhou and Wei Zhan and Masayoshi Tomizuka and Ming C Wu"
      }
    ],
    "6uIhh6MAAAAJ": [
      {
        "title": "Deep reinforcement learning in a handful of trials using probabilistic dynamics models",
        "abstract": "Model-based reinforcement learning (RL) algorithms can attain excellent sample efficiency, but often lag behind the best model-free algorithms in terms of asymptotic performance. This is especially true with high-capacity parametric function approximators, such as deep networks. In this paper, we study how to bridge this gap, by employing uncertainty-aware dynamics models. We propose a new algorithm called probabilistic ensembles with trajectory sampling (PETS) that combines uncertainty-aware deep network dynamics models with sampling-based uncertainty propagation. Our comparison to state-of-the-art model-based and model-free deep RL algorithms shows that our approach matches the asymptotic performance of model-free algorithms on several challenging benchmark tasks, while requiring significantly fewer samples (eg 8 and 125 times fewer samples than Soft Actor Critic and Proximal Policy Optimization respectively on the half-cheetah task).",
        "year": 2018,
        "authors": "Kurtland Chua and Roberto Calandra and Rowan McAllister and Sergey Levine"
      },
      {
        "title": "Learning invariant representations for reinforcement learning without reconstruction",
        "abstract": "We study how representation learning can accelerate reinforcement learning from rich observations, such as images, without relying either on domain knowledge or pixel-reconstruction. Our goal is to learn representations that both provide for effective downstream control and invariance to task-irrelevant details. Bisimulation metrics quantify behavioral similarity between states in continuous MDPs, which we propose using to learn robust latent representations which encode only the task-relevant information from observations. Our method trains encoders such that distances in latent space equal bisimulation distances in state space. We demonstrate the effectiveness of our method at disregarding task-irrelevant information using modified visual MuJoCo tasks, where the background is replaced with moving distractors and natural videos, while achieving SOTA performance. We also test a first-person highway driving task where our method learns invariance to clouds, weather, and time of day. Finally, we provide generalization results drawn from properties of bisimulation metrics, and links to causal inference.",
        "year": 2020,
        "authors": "Amy Zhang and Rowan McAllister and Roberto Calandra and Yarin Gal and Sergey Levine"
      },
      {
        "title": "PRECOG: Prediction conditioned on goals in visual multi-agent settings",
        "abstract": "For autonomous vehicles (AVs) to behave appropriately on roads populated by human-driven vehicles, they must be able to reason about the uncertain intentions and decisions of other drivers from rich perceptual information. Towards these capabilities, we present a probabilistic forecasting model of future interactions between a variable number of agents. We perform both standard forecasting and the novel task of conditional forecasting, which reasons about how all agents will likely respond to the goal of a controlled agent (here, the AV). We train models on real and simulated data to forecast vehicle trajectories given past positions and LIDAR. Our evaluation shows that our model is substantially more accurate in multi-agent driving scenarios compared to existing state-of-the-art. Beyond its general ability to perform conditional forecasting queries, we show that our model's predictions of all agents improve when conditioned on knowledge of the AV's goal, further illustrating its capability to model agent interactions.",
        "year": 2019,
        "authors": "Nicholas Rhinehart and Rowan McAllister and Kris Kitani and Sergey Levine"
      }
    ],
    "zkvW8FQAAAAJ": [
      {
        "title": "Learning diverse rankings with multi-armed bandits",
        "abstract": "Algorithms for learning to rank Web documents usually assume a document's relevance is independent of other documents. This leads to learned ranking functions that produce rankings with redundant results. In contrast, user studies have shown that diversity at high ranks is often preferred. We present two online learning algorithms that directly learn a diverse ranking of documents based on users' clicking behavior. We show that these algorithms minimize abandonment, or alternatively, maximize the probability that a relevant document is found in the top k positions of a ranking. Moreover, one of our algorithms asymptotically achieves optimal worst-case performance even if users' interests change.",
        "year": 2008,
        "authors": "Filip Radlinski and Robert Kleinberg and Thorsten Joachims"
      },
      {
        "title": "Bandits with knapsacks",
        "abstract": "Multi-armed bandit problems are the predominant theoretical model of exploration-exploitation tradeoffs in learning, and they have countless applications ranging from medical trials, to communication networks, to Web search and advertising. In many of these application domains, the learner may be constrained by one or more supply (or budget) limits, in addition to the customary limitation on the time horizon. The literature lacks a general model encompassing these sorts of problems. We introduce such a model, called bandits with knapsacks, that combines bandit learning with aspects of stochastic integer programming. In particular, a bandit algorithm needs to solve a stochastic version of the well-known knapsack problem, which is concerned with packing items into a limited-size knapsack. A distinctive feature of our problem, in comparison to the existing regret-minimization literature, is that the optimal policy for a …",
        "year": 2018,
        "authors": "Ashwinkumar Badanidiyuru and Robert Kleinberg and Aleksandrs Slivkins"
      },
      {
        "title": "Multi-armed bandits in metric spaces",
        "abstract": "In a multi-armed bandit problem, an online algorithm chooses from a set of strategies in a sequence of  trials so as to maximize the total payoff of the chosen strategies. While the performance of bandit algorithms with a small finite strategy set is quite well understood, bandit problems with large strategy sets are still a topic of very active investigation, motivated by practical applications such as online auctions and web advertisement. The goal of such research is to identify broad and natural classes of strategy sets and payoff functions which enable the design of efficient solutions.In this work we study a very general setting for the multi-armed bandit problem in which the strategies form a metric space, and the payoff function satisfies a Lipschitz condition with respect to the metric. We refer to this problem as the \"Lipschitz MAB problem\". We present a complete solution for the multi-armed problem in this setting. That is, for …",
        "year": 2008,
        "authors": "Robert Kleinberg and Aleksandrs Slivkins and Eli Upfal"
      }
    ],
    "jikMhF4AAAAJ": [
      {
        "title": "To afford or not to afford: A new formalization of affordances toward affordance-based robot control",
        "abstract": "The concept of affordances was introduced by J. J. Gibson to eXplain how inherent “values” and “meanings” of things in the environment can be directly perceived and how this information can be linked to the action possibilities offered to the organism by the environment. Although introduced in psychology, the concept influenced studies in other fields ranging from human—computer interaction to autonomous robotics. In this article, we first introduce the concept of affordances as conceived by J. J. Gibson and review the use of the term in different fields, with particular emphasis on its use in autonomous robotics. Then, we summarize four of the major formalization proposals for the affordance term. We point out that there are three, not one, perspectives from which to view affordances and that much of the confusion regarding discussions on the concept has arisen from this. We propose a new formalism for …",
        "year": 2007,
        "authors": "Erol Şahin and Maya Cakmak and Mehmet R Doğar and Emre Uğur and Göktürk Üçoluk"
      },
      {
        "title": "Haptic identification of objects using a modular soft robotic gripper",
        "abstract": "This work presents a soft hand capable of robustly grasping and identifying objects based on internal state measurements. A highly compliant hand allows for intrinsic robustness to grasping uncertainty, but the specific configuration of the hand and object is not known, leaving undetermined if a grasp was successful in picking up the right object. A soft finger was adapted and combined to form a three finger gripper that can easily be attached to existing robots, for example, to the wrist of the Baxter robot. Resistive bend sensors were added within each finger to provide a configuration estimate sufficient for distinguishing between a set of objects. With one data point from each finger, the object grasped by the gripper can be identified. A clustering algorithm to find the correspondence for each grasped object is presented for both enveloping grasps and pinch grasps. This hand is a first step towards robust proprioceptive …",
        "year": 2015,
        "authors": "Bianca S Homberg and Robert K Katzschmann and Mehmet R Dogar and Daniela Rus"
      },
      {
        "title": "A framework for push-grasping in clutter",
        "abstract": "Humans use a remarkable set of strategies to manipulate objects in clutter. We pick up, push, slide, and sweep with our hands and arms to rearrange clutter surrounding our primary task. But our robots treat the world like the Tower of Hanoi—moving with pick-and-place actions and fearful to interact with it with anything but rigid grasps. This produces inefficient plans and is often inapplicable with heavy, large, or otherwise ungraspable objects. We introduce a framework for planning in clutter that uses a library of actions inspired by human strategies. the mechanics The action library is derived analytically from of pushing and is provably conservative. The framework reduces the problem to one of combinatorial search, and demonstrates planning times on the order of seconds. With the extra functionality, our planner succeeds where traditional grasp planners fail, and works under high uncertainty by utilizing the funneling effect of pushing. We demonstrate our results with experiments in simulation and on HERB, a robotic platform developed at the Personal Robotics Lab at Carnegie Mellon University.",
        "year": 2011,
        "authors": "Mehmet Dogar and Siddhartha Srinivasa"
      }
    ],
    "VjsNXysAAAAJ": [
      {
        "title": "Reciprocal n-body collision avoidance",
        "abstract": "In this paper, we present a formal approach to reciprocal n-body collision avoidance, where multiple mobile robots need to avoid collisions with each other while moving in a common workspace. In our formulation, each robot acts fully independently, and does not communicate with other robots. Based on the definition of velocity obstacles [5], we derive sufficient conditions for collision-free motion by reducing the problem to solving a low-dimensional linear program. We test our approach on several dense and complex simulation scenarios involving thousands of robots and compute collision-free actions for all of them in only a few milliseconds. To the best of our knowledge, this method is the first that can guarantee local collision-free motion for a large number of robots in a cluttered workspace.",
        "year": 2011,
        "authors": "Jur van den Berg and Stephen J Guy and Ming Lin and Dinesh Manocha"
      },
      {
        "title": "Reciprocal velocity obstacles for real-time multi-agent navigation",
        "abstract": "In this paper, we propose a new concept — the ‘Reciprocal Velocity Obstacle’— for real-time multi-agent navigation. We consider the case in which each agent navigates independently without explicit communication with other agents. Our formulation is an extension of the Velocity Obstacle concept [3], which was introduced for navigation among (passively) moving obstacles. Our approach takes into account the reactive behavior of the other agents by implicitly assuming that the other agents make a similar collision-avoidance reasoning. We show that this method guarantees safe and oscillation-free motions for each of the agents. We apply our concept to navigation of hundreds of agents in densely populated environments containing both static and moving obstacles, and we show that real-time and scalable performance is achieved in such challenging scenarios.",
        "year": 2008,
        "authors": "Jur van den Berg and Ming Lin and Dinesh Manocha"
      },
      {
        "title": "Kinodynamic RRT*: Asymptotically optimal motion planning for robots with linear dynamics",
        "abstract": "We present Kinodynamic RRT*, an incremental sampling-based approach for asymptotically optimal motion planning for robots with linear dynamics. Our approach extends RRT*, which was introduced for holonomic robots [10], by using a fixed-final-state-free-final-time controller that optimally connects any pair of states, where the cost function is expressed as a trade-off between the duration of a trajectory and the expended control effort. Our approach generalizes earlier work on RRT* for kinodynamic systems, as it guarantees asymptotic optimality for any system with controllable linear dynamics, in state spaces of any dimension. In addition, we show that for the rich subclass of systems with a nilpotent dynamics matrix, closed-form solutions for optimal trajectories can be derived, which keeps the computational overhead of our algorithm compared to traditional RRT* at a minimum. We demonstrate the potential of …",
        "year": 2013,
        "authors": "Dustin J Webb and Jur Van Den Berg"
      }
    ],
    "-XCiamcAAAAJ": [
      {
        "title": "Multi-scale context aggregation by dilated convolutions",
        "abstract": "State-of-the-art models for semantic segmentation are based on adaptations of convolutional networks that had originally been designed for image classification. However, dense prediction and image classification are structurally different. In this work, we develop a new convolutional network module that is specifically designed for dense prediction. The presented module uses dilated convolutions to systematically aggregate multi-scale contextual information without losing resolution. The architecture is based on the fact that dilated convolutions support exponential expansion of the receptive field without loss of resolution or coverage. We show that the presented context module increases the accuracy of state-of-the-art semantic segmentation systems. In addition, we examine the adaptation of image classification networks to dense prediction and show that simplifying the adapted network can increase accuracy.",
        "year": 2016,
        "authors": "Fisher Yu and Vladlen Koltun"
      },
      {
        "title": "3d shapenets: A deep representation for volumetric shapes",
        "abstract": "3D shape is a crucial but heavily underutilized cue in today's computer vision systems, mostly due to the lack of a good generic shape representation. With the recent availability of inexpensive 2.5 D depth sensors (eg Microsoft Kinect), it is becoming increasingly important to have a powerful 3D shape representation in the loop. Apart from category recognition, recovering full 3D shapes from view-based 2.5 D depth maps is also a critical part of visual understanding. To this end, we propose to represent a geometric 3D shape as a probability distribution of binary variables on a 3D voxel grid, using a Convolutional Deep Belief Network. Our model, 3D ShapeNets, learns the distribution of complex 3D shapes across different object categories and arbitrary poses from raw CAD data, and discovers hierarchical compositional part representation automatically. It naturally supports joint object recognition and shape completion from 2.5 D depth maps, and it enables active object recognition through view planning. To train our 3D deep learning model, we construct ModelNet-a large-scale 3D CAD model dataset. Extensive experiments show that our 3D deep representation enables significant performance improvement over the-state-of-the-arts in a variety of tasks.",
        "year": 2015,
        "authors": "Zhirong Wu and Shuran Song and Aditya Khosla and Fisher Yu and Linguang Zhang and Xiaoou Tang and Jianxiong Xiao"
      },
      {
        "title": "Shapenet: An information-rich 3d model repository",
        "abstract": "We present ShapeNet: a richly-annotated, large-scale repository of shapes represented by 3D CAD models of objects. ShapeNet contains 3D models from a multitude of semantic categories and organizes them under the WordNet taxonomy. It is a collection of datasets providing many semantic annotations for each 3D model such as consistent rigid alignments, parts and bilateral symmetry planes, physical sizes, keywords, as well as other planned annotations. Annotations are made available through a public web-based interface to enable data visualization of object attributes, promote data-driven geometric analysis, and provide a large-scale quantitative benchmark for research in computer graphics and vision. At the time of this technical report, ShapeNet has indexed more than 3,000,000 models, 220,000 models out of which are classified into 3,135 categories (WordNet synsets). In this report we describe the ShapeNet effort as a whole, provide details for all currently available datasets, and summarize future plans.",
        "year": 2015,
        "authors": "Angel X Chang and Thomas Funkhouser and Leonidas Guibas and Pat Hanrahan and Qixing Huang and Zimo Li and Silvio Savarese and Manolis Savva and Shuran Song and Hao Su and Jianxiong Xiao and Li Yi and Fisher Yu"
      }
    ],
    "yDVn5LEAAAAJ": [
      {
        "title": "Starling-7b: Improving helpfulness and harmlessness with rlaif",
        "abstract": "This paper presents Starling-7B, the current best-performing 7B chat model on Chatbot Arena, along with its training dataset Nectar, a high-quality preference dataset collected by prompting GPT-4 to rank responses. We propose an internal pairwise rating technique, where the model considers all pairings before providing a ranking decision, leveraging the proven pairwise rating capability of LLMs without the cost of individual pairwise calls. The resulting Nectar dataset comprises 182,954 chat prompts, each with seven responses from various models, ranked by GPT-4, equating to 3.8 million high-quality pairwise comparisons. We introduce Starling-RM-7B and Starling-RM-34B, the reward model suites trained with a K-wise preference loss on Nectar, outperforming pairwise counterparts. We benchmark reward model training pipelines across metrics such as human preference, truthfulness, and safety. Using Nectar and our new training pipeline, we fine-tuned Openchat-3.5 to create Starling-LM-7B, achieving significant performance enhancements on MT-Bench, AlpacaEval, and human evaluation metrics. To facilitate research and understanding of RLHF mechanisms, we open-source the Nectar dataset, the reward models, and the language models.",
        "year": 2024,
        "authors": "Banghua Zhu and Evan Frick and Tianhao Wu and Hanlin Zhu and Karthik Ganesan and Wei-Lin Chiang and Jian Zhang and Jiantao Jiao"
      },
      {
        "title": "Guided dialog policy learning: Reward estimation for multi-domain task-oriented dialog",
        "abstract": "Dialog policy decides what and how a task-oriented dialog system will respond, and plays a vital role in delivering effective conversations. Many studies apply Reinforcement Learning to learn a dialog policy with the reward function which requires elaborate design and pre-specified user goals. With the growing needs to handle complex goals across multiple domains, such manually designed reward functions are not affordable to deal with the complexity of real-world tasks. To this end, we propose Guided Dialog Policy Learning, a novel algorithm based on Adversarial Inverse Reinforcement Learning for joint reward estimation and policy optimization in multi-domain task-oriented dialog. The proposed approach estimates the reward signal and infers the user goal in the dialog sessions. The reward estimator evaluates the state-action pairs so that it can guide the dialog policy at each dialog turn. Extensive experiments on a multi-domain dialog dataset show that the dialog policy guided by the learned reward function achieves remarkably higher task success than state-of-the-art baselines.",
        "year": 2019,
        "authors": "Ryuichi Takanobu and Hanlin Zhu and Minlie Huang"
      },
      {
        "title": "Optimal conservative offline rl with general function approximation via augmented lagrangian",
        "abstract": "Offline reinforcement learning (RL), which refers to decision-making from a previously-collected dataset of interactions, has received significant attention over the past years. Much effort has focused on improving offline RL practicality by addressing the prevalent issue of partial data coverage through various forms of conservative policy learning. While the majority of algorithms do not have finite-sample guarantees, several provable conservative offline RL algorithms are designed and analyzed within the single-policy concentrability framework that handles partial coverage. Yet, in the nonlinear function approximation setting where confidence intervals are difficult to obtain, existing provable algorithms suffer from computational intractability, prohibitively strong assumptions, and suboptimal statistical rates. In this paper, we leverage the marginalized importance sampling (MIS) formulation of RL and present the first set of offline RL algorithms that are statistically optimal and practical under general function approximation and single-policy concentrability, bypassing the need for uncertainty quantification. We identify that the key to successfully solving the sample-based approximation of the MIS problem is ensuring that certain occupancy validity constraints are nearly satisfied. We enforce these constraints by a novel application of the augmented Lagrangian method and prove the following result: with the MIS formulation, augmented Lagrangian is enough for statistically optimal offline RL. In stark contrast to prior algorithms that induce additional conservatism through methods such as behavior regularization, our approach provably eliminates this need …",
        "year": 2022,
        "authors": "Paria Rashidinejad and Hanlin Zhu and Kunhe Yang and Stuart Russell and Jiantao Jiao"
      }
    ],
    "d5y4iKAAAAAJ": [
      {
        "title": "LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action",
        "abstract": "Goal-conditioned policies for robotic navigation can be trained on large, unannotated datasets, providing for good generalization to real-world settings. However, particularly in vision-based settings where specifying goals requires an image, this makes for an unnatural interface. Language provides a more convenient modality for communication with robots, but contemporary methods typically require expensive supervision, in the form of trajectories annotated with language descriptions. We present a system, LM-Nav, for robotic navigation that enjoys the benefits of training on unannotated large datasets of trajectories, while still providing a high-level interface to the user. Instead of utilizing a labeled instruction following dataset, we show that such a system can be constructed entirely out of pre-trained models for navigation (ViNG), image-language association (CLIP), and language modeling (GPT-3), without requiring any fine-tuning or language-annotated robot data. LM-Nav extracts landmarks names from an instruction, grounds them in the world via the image-language model, and then reaches them via the (vision-only) navigation model. We instantiate LM-Nav on a real-world mobile robot and demonstrate long-horizon navigation through complex, outdoor environments from natural language instructions.",
        "year": 2022,
        "authors": "Dhruv Shah and Blazej Osinski and Brian Ichter and Sergey Levine"
      },
      {
        "title": "The Ingredients of Real-World Robotic Reinforcement Learning",
        "abstract": "The success of reinforcement learning for real world robotics has been, in many cases limited to instrumented laboratory scenarios, often requiring arduous human effort and oversight to enable continuous learning. In this work, we discuss the elements that are needed for a robotic learning system that can continually and autonomously improve with data collected in the real world. We propose a particular instantiation of such a system, using dexterous manipulation as our case study. Subsequently, we investigate a number of challenges that come up when learning without instrumentation. In such settings, learning must be feasible without manually designed resets, using only on-board perception, and without hand-engineered reward functions. We propose simple and scalable solutions to these challenges, and then demonstrate the efficacy of our proposed system on a set of dexterous robotic manipulation tasks, providing an in-depth analysis of the challenges associated with this learning paradigm. We demonstrate that our complete system can learn without any human intervention, acquiring a variety of vision-based skills with a real-world three-fingered hand. Results and videos can be found at https://sites.google.com/view/realworld-rl/",
        "year": 2020,
        "authors": "Henry Zhu and Justin Yu and Abhishek Gupta and Dhruv Shah and Kristian Hartikainen and Avi Singh and Vikash Kumar and Sergey Levine"
      }
    ],
    "VZHxoh8AAAAJ": [
      {
        "title": "Gradient descent finds global minima of deep neural networks",
        "abstract": "Gradient descent finds a global minimum in training deep neural networks despite the objective function being non-convex. The current paper proves gradient descent achieves zero training loss in polynomial time for a deep over-parameterized neural network with residual connections (ResNet). Our analysis relies on the particular structure of the Gram matrix induced by the neural network architecture. This structure allows us to show the Gram matrix is stable throughout the training process and this stability implies the global optimality of the gradient descent algorithm. We further extend our analysis to deep residual convolutional neural networks and obtain a similar convergence result.",
        "year": 2019,
        "authors": "Simon Du and Jason Lee and Haochuan Li and Liwei Wang and Xiyu Zhai"
      },
      {
        "title": "The expressive power of neural networks: A view from the width",
        "abstract": "The expressive power of neural networks is important for understanding deep learning. Most existing works consider this problem from the view of the depth of a network. In this paper, we study how width affects the expressiveness of neural networks. Classical results state that depth-bounded (eg depth-2) networks with suitable activation functions are universal approximators. We show a universal approximation theorem for width-bounded ReLU networks: width-(n+ 4) ReLU networks, where n is the input dimension, are universal approximators. Moreover, except for a measure zero set, all functions cannot be approximated by width-n ReLU networks, which exhibits a phase transition. Several recent works demonstrate the benefits of depth by proving the depth-efficiency of neural networks. That is, there are classes of deep networks which cannot be realized by any shallow network whose size is no more than an exponential bound. Here we pose the dual question on the width-efficiency of ReLU networks: Are there wide networks that cannot be realized by narrow networks whose size is not substantially larger? We show that there exist classes of wide networks which cannot be realized by any narrow network whose depth is no more than a polynomial bound. On the other hand, we demonstrate by extensive experiments that narrow networks whose size exceed the polynomial bound by a constant factor can approximate wide and shallow network with high accuracy. Our results provide more comprehensive evidence that depth may be more effective than width for the expressiveness of ReLU networks.",
        "year": 2017,
        "authors": "Zhou Lu and Hongming Pu and Feicheng Wang and Zhiqiang Hu and Liwei Wang"
      },
      {
        "title": "On layer normalization in the transformer architecture",
        "abstract": "The Transformer is widely used in natural language processing tasks. To train a Transformer however, one usually needs a carefully designed learning rate warm-up stage, which is shown to be crucial to the final performance but will slow down the optimization and bring more hyper-parameter tunings. In this paper, we first study theoretically why the learning rate warm-up stage is essential and show that the location of layer normalization matters. Specifically, we prove with mean field theory that at initialization, for the original-designed Post-LN Transformer, which places the layer normalization between the residual blocks, the expected gradients of the parameters near the output layer are large. Therefore, using a large learning rate on those gradients makes the training unstable. The warm-up stage is practically helpful for avoiding this problem. On the other hand, our theory also shows that if the layer normalization is put inside the residual blocks (recently proposed as Pre-LN Transformer), the gradients are well-behaved at initialization. This motivates us to remove the warm-up stage for the training of Pre-LN Transformers. We show in our experiments that Pre-LN Transformers without the warm-up stage can reach comparable results with baselines while requiring significantly less training time and hyper-parameter tuning on a wide range of applications.",
        "year": 2020,
        "authors": "Ruibin Xiong and Yunchang Yang and Di He and Kai Zheng and Shuxin Zheng and Chen Xing and Huishuai Zhang and Yanyan Lan and Liwei Wang and Tieyan Liu"
      }
    ],
    "C-ZlBWMAAAAJ": [
      {
        "title": "D4rl: Datasets for deep data-driven reinforcement learning",
        "abstract": "The offline reinforcement learning (RL) setting (also known as full batch RL), where a policy is learned from a static dataset, is compelling as progress enables RL methods to take advantage of large, previously-collected datasets, much like how the rise of large datasets has fueled results in supervised learning. However, existing online RL benchmarks are not tailored towards the offline setting and existing offline RL benchmarks are restricted to data generated by partially-trained agents, making progress in offline RL difficult to measure. In this work, we introduce benchmarks specifically designed for the offline setting, guided by key properties of datasets relevant to real-world applications of offline RL. With a focus on dataset collection, examples of such properties include: datasets generated via hand-designed controllers and human demonstrators, multitask datasets where an agent performs different tasks in the same environment, and datasets collected with mixtures of policies. By moving beyond simple benchmark tasks and data collected by partially-trained RL agents, we reveal important and unappreciated deficiencies of existing algorithms. To facilitate research, we have released our benchmark tasks and datasets with a comprehensive evaluation of existing algorithms, an evaluation protocol, and open-source examples. This serves as a common starting point for the community to identify shortcomings in existing offline RL methods and a collaborative route for progress in this emerging area.",
        "year": 2020,
        "authors": "Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine"
      },
      {
        "title": "Rt-1: Robotics transformer for real-world control at scale",
        "abstract": "By transferring knowledge from large, diverse, task-agnostic datasets, modern machine learning models can solve specific downstream tasks either zero-shot or with small task-specific datasets to a high level of performance. While this capability has been demonstrated in other fields such as computer vision, natural language processing or speech recognition, it remains to be shown in robotics, where the generalization capabilities of the models are particularly critical due to the difficulty of collecting real-world robotic data. We argue that one of the keys to the success of such general robotic models lies with open-ended task-agnostic training, combined with high-capacity architectures that can absorb all of the diverse, robotic data. In this paper, we present a model class, dubbed Robotics Transformer, that exhibits promising scalable model properties. We verify our conclusions in a study of different model classes and their ability to generalize as a function of the data size, model size, and data diversity based on a large-scale data collection on real robots performing real-world tasks. The project's website and videos can be found at robotics-transformer1.github.io",
        "year": 2022,
        "authors": "Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Joseph Dabis and Chelsea Finn and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Tomas Jackson and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Kuang-Huei Lee and Sergey Levine and Yao Lu and Utsav Malla and Deeksha Manjunath and Igor Mordatch and Ofir Nachum and Carolina Parada and Jodilyn Peralta and Emily Perez and Karl Pertsch and Jornell Quiambao and Kanishka Rao and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Kevin Sayed and Jaspiar Singh and Sumedh Sontakke and Austin Stone and Clayton Tan and Huong Tran and Vincent Vanhoucke and Steve Vega and Quan Vuong and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich"
      },
      {
        "title": "Gpt-4o system card",
        "abstract": "GPT-4o is an autoregressive omni model that accepts as input any combination of text, audio, image, and video, and generates any combination of text, audio, and image outputs. It's trained end-to-end across text, vision, and audio, meaning all inputs and outputs are processed by the same neural network. GPT-4o can respond to audio inputs in as little as 232 milliseconds, with an average of 320 milliseconds, which is similar to human response time in conversation. It matches GPT-4 Turbo performance on text in English and code, with significant improvement on text in non-English languages, while also being much faster and 50\\% cheaper in the API. GPT-4o is especially better at vision and audio understanding compared to existing models. In line with our commitment to building AI safely and consistent with our voluntary commitments to the White House, we are sharing the GPT-4o System Card, which includes our Preparedness Framework evaluations. In this System Card, we provide a detailed look at GPT-4o's capabilities, limitations, and safety evaluations across multiple categories, focusing on speech-to-speech while also evaluating text and image capabilities, and measures we've implemented to ensure the model is safe and aligned. We also include third-party assessments on dangerous capabilities, as well as discussion of potential societal impacts of GPT-4o's text and vision capabilities.",
        "year": 2024,
        "authors": "Aaron Hurst and Adam Lerer and Adam P Goucher and Adam Perelman and Aditya Ramesh and Aidan Clark and AJ Ostrow and Akila Welihinda and Alan Hayes and Alec Radford and Aleksander Mądry and Alex Baker-Whitcomb and Alex Beutel and Alex Borzunov and Alex Carney and Alex Chow and Alex Kirillov and Alex Nichol and Alex Paino and Alex Renzin and Alex Tachard Passos and Alexander Kirillov and Alexi Christakis and Alexis Conneau and Ali Kamali and Allan Jabri and Allison Moyer and Allison Tam and Amadou Crookes and Amin Tootoochian and Amin Tootoonchian and Ananya Kumar and Andrea Vallone and Andrej Karpathy and Andrew Braunstein and Andrew Cann and Andrew Codispoti and Andrew Galu and Andrew Kondrich and Andrew Tulloch and Andrey Mishchenko and Angela Baek and Angela Jiang and Antoine Pelisse and Antonia Woodford and Anuj Gosalia and Arka Dhar and Ashley Pantuliano and Avi Nayak and Avital Oliver and Barret Zoph and Behrooz Ghorbani and Ben Leimberger and Ben Rossen and Ben Sokolowsky and Ben Wang and Benjamin Zweig and Beth Hoover and Blake Samic and Bob McGrew and Bobby Spero and Bogo Giertler and Bowen Cheng and Brad Lightcap and Brandon Walkin and Brendan Quinn and Brian Guarraci and Brian Hsu and Bright Kellogg and Brydon Eastman and Camillo Lugaresi and Carroll Wainwright and Cary Bassin and Cary Hudson and Casey Chu and Chad Nelson and Chak Li and Chan Jun Shern and Channing Conger and Charlotte Barette and Chelsea Voss and Chen Ding and Cheng Lu and Chong Zhang and Chris Beaumont and Chris Hallacy and Chris Koch and Christian Gibson and Christina Kim and Christine Choi and Christine McLeavey and Christopher Hesse and Claudia Fischer and Clemens Winter and Coley Czarnecki and Colin Jarvis and Colin Wei and Constantin Koumouzelis and Dane Sherburn and Daniel Kappler and Daniel Levin and Daniel Levy and David Carr and David Farhi and David Mely and David Robinson and David Sasaki and Denny Jin and Dev Valladares and Dimitris Tsipras and Doug Li and Duc Phong Nguyen and Duncan Findlay and Edede Oiwoh and Edmund Wong and Ehsan Asdar and Elizabeth Proehl and Elizabeth Yang and Eric Antonow and Eric Kramer and Eric Peterson and Eric Sigler and Eric Wallace and Eugene Brevdo and Evan Mays and Farzad Khorasani and Felipe Petroski Such and Filippo Raso and Francis Zhang and Fred von Lohmann and Freddie Sulit and Gabriel Goh and Gene Oden and Geoff Salmon and Giulio Starace and Greg Brockman and Hadi Salman and Haiming Bao and Haitang Hu and Hannah Wong and Haoyu Wang and Heather Schmidt and Heather Whitney and Heewoo Jun and Hendrik Kirchner and Henrique Ponde de Oliveira Pinto and Hongyu Ren and Huiwen Chang and Hyung Won Chung and Ian Kivlichan"
      }
    ],
    "qRAQ5BsAAAAJ": [
      {
        "title": "Adversarial learning for neural dialogue generation",
        "abstract": "In this paper, drawing intuition from the Turing test, we propose using adversarial training for open-domain dialogue generation: the system is trained to produce sequences that are indistinguishable from human-generated dialogue utterances. We cast the task as a reinforcement learning (RL) problem where we jointly train two systems, a generative model to produce response sequences, and a discriminator---analagous to the human evaluator in the Turing test--- to distinguish between the human-generated dialogues and the machine-generated ones. The outputs from the discriminator are then used as rewards for the generative model, pushing the system to generate dialogues that mostly resemble human dialogues. In addition to adversarial training we describe a model for adversarial {\\em evaluation} that uses success in fooling an adversary as a dialogue evaluation metric, while avoiding a number of potential pitfalls. Experimental results on several metrics, including adversarial evaluation, demonstrate that the adversarially-trained system generates higher-quality responses than previous baselines.",
        "year": 2017,
        "authors": "Jiwei Li and Will Monroe and Tianlin Shi and Sébastien Jean and Alan Ritter and Dan Jurafsky"
      },
      {
        "title": "World of Bits: An Open-Domain Platform for Web-Based Agents",
        "abstract": "While simulated game environments have greatly accelerated research in reinforcement learning, existing environments lack the open-domain realism of tasks in computer vision or natural language processing, which operate on artifacts created by humans in natural, organic settings. To foster reinforcement learning research in such settings, we introduce the World of Bits (WoB), a platform in which agents complete tasks on the Internet by performing low-level keyboard and mouse actions. The two main challenges are:(i) to curate a large, diverse set of interesting web-based tasks, and (ii) to ensure that these tasks have a well-defined reward structure and are reproducible despite the transience of the web. To do this, we develop a methodology in which crowdworkers create tasks defined by natural language questions and provide demonstrations of how to answer the question on real websites using keyboard and mouse; HTTP traffic is cached to create a reproducible offline approximation of the web site. Finally, we show that agents trained via behavioral cloning and reinforcement learning can successfully complete a range of our web-based tasks.",
        "year": 2017,
        "authors": "Tianlin Shi and Andrej Karpathy and Linxi Fan and Jonathan Hernandez and Percy Liang"
      },
      {
        "title": "Reinforcement Learning on Web Interfaces Using Workflow-Guided Exploration",
        "abstract": "Reinforcement learning (RL) agents improve through trial-and-error, but when reward is sparse and the agent cannot discover successful action sequences, learning stagnates. This has been a notable problem in training deep RL agents to perform web-based tasks, such as booking flights or replying to emails, where a single mistake can ruin the entire sequence of actions. A common remedy is to \"warm-start\" the agent by pre-training it to mimic expert demonstrations, but this is prone to overfitting. Instead, we propose to constrain exploration using demonstrations. From each demonstration, we induce high-level \"workflows\" which constrain the allowable actions at each time step to be similar to those in the demonstration (e.g., \"Step 1: click on a textbox; Step 2: enter some text\"). Our exploration policy then learns to identify successful workflows and samples actions that satisfy these workflows. Workflows prune out bad exploration directions and accelerate the agent's ability to discover rewards. We use our approach to train a novel neural policy designed to handle the semi-structured nature of websites, and evaluate on a suite of web tasks, including the recent World of Bits benchmark. We achieve new state-of-the-art results, and show that workflow-guided exploration improves sample efficiency over behavioral cloning by more than 100x.",
        "year": 2018,
        "authors": "Evan Zheran Liu and Kelvin Guu and Panupong Pasupat and Tianlin Shi and Percy Liang"
      }
    ],
    "LeshmV8AAAAJ": [
      {
        "title": "Conformal prediction: A gentle introduction",
        "abstract": "Black-box machine learning models are now routinely used in high-risk settings, like medical diagnostics, which demand uncertainty quantification to avoid consequential model failures. Conformal prediction (aka conformal inference) is a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models. Critically, the sets are valid in a distribution-free sense: they possess explicit, non-asymptotic guarantees even without distributional assumptions or model assumptions. One can use conformal prediction with any pre-trained model, such as a neural network, to produce sets that are guaranteed to contain the ground truth with a user-specified probability, such as 90%. It is easy-to-understand, easy-to-use, and general, applying naturally to problems arising in the fields of computer vision, natural language processing, deep reinforcement learning, and so on.",
        "year": 2023,
        "authors": "Anastasios N Angelopoulos and Stephen Bates"
      },
      {
        "title": "Uncertainty sets for image classifiers using conformal prediction",
        "abstract": "Convolutional image classifiers can achieve high predictive accuracy, but quantifying their uncertainty remains an unresolved challenge, hindering their deployment in consequential settings. Existing uncertainty quantification techniques, such as Platt scaling, attempt to calibrate the network's probability estimates, but they do not have formal guarantees. We present an algorithm that modifies any classifier to output a predictive set containing the true label with a user-specified probability, such as 90%. The algorithm is simple and fast like Platt scaling, but provides a formal finite-sample coverage guarantee for every model and dataset. Our method modifies an existing conformal prediction algorithm to give more stable predictive sets by regularizing the small scores of unlikely classes after Platt scaling. In experiments on both Imagenet and Imagenet-V2 with ResNet-152 and other classifiers, our scheme outperforms existing approaches, achieving coverage with sets that are often factors of 5 to 10 smaller than a stand-alone Platt scaling baseline.",
        "year": 2021,
        "authors": "Anastasios Angelopoulos* and Stephen Bates* and Jitendra Malik and Michael I Jordan"
      },
      {
        "title": "Cross-validation: what does it estimate and how well does it do it?",
        "abstract": "Cross-validation is a widely used technique to estimate prediction error, but its behavior is complex and not fully understood. Ideally, one would like to think that cross-validation estimates the prediction error for the model at hand, fit to the training data. We prove that this is not the case for the linear model fit by ordinary least squares; rather it estimates the average prediction error of models fit on other unseen training sets drawn from the same population. We further show that this phenomenon occurs for most popular estimates of prediction error, including data splitting, bootstrapping, and Mallow’s . Next, the standard confidence intervals for prediction error derived from cross-validation may have coverage far below the desired level. Because each data point is used for both training and testing, there are correlations among the measured accuracies for each fold, and so the usual estimate of variance is too small …",
        "year": 2023,
        "authors": "Stephen Bates and Trevor Hastie and Robert Tibshirani"
      }
    ],
    "3kDtybgAAAAJ": [
      {
        "title": "Long-term Recurrent Convolutional Networks for Visual Recognition and Description",
        "abstract": "Models comprised of deep convolutional network layers have dominated recent image interpretation tasks; we investigate whether models which are also compositional, or\" deep\", temporally are effective on tasks involving visual sequences or label sequences. We develop a novel recurrent convolutional architecture suitable for large-scale visual learning which is end-to-end trainable, and demonstrate the value of these models on benchmark video recognition tasks, image to sentence generation problems, and video narration challenges. In contrast to current models which assume a fixed spatio-temporal receptive field or simple temporal averaging for sequential processing, recurrent convolutional models are\" doubly deep\" in that they can be compositional in spatial and temporal\" layers\". Such models may have advantages when target concepts are complex and/or training data are limited. Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. Long-term RNN models are appealing in that they directly can map variable length inputs (ie video frames) to variable length outputs (ie natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent long-term models are directly connected to state-of-the-art visual convnet models and can jointly trained, updating temporal dynamics and convolutional perceptual representations simultaneously. Our results show such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined and/or optimized.",
        "year": 2017,
        "authors": "Jeff Donahue and Lisa Anne Hendricks and Marcus Rohrbach and Subhashini Venugopalan and Sergio Guadarrama and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Memory Aware Synapses: Learning what (not) to forget",
        "abstract": "Humans can learn in a continuous manner. Old rarely utilized knowledge can be overwritten by new incoming information while important, frequently used knowledge is prevented from being erased. In artificial learning systems, lifelong learning so far has focused mainly on accumulating knowledge over tasks and overcoming catastrophic forgetting. In this paper, we argue that, given the limited model capacity and the unlimited new information to be learned, knowledge has to be preserved or erased selectively. Inspired by neuroplasticity, we propose a novel approach for lifelong learning, coined Memory Aware Synapses (MAS). It computes the importance of the parameters of a neural network in an unsupervised and online manner. Given a new sample which is fed to the network, MAS accumulates an importance measure for each parameter of the network, based on how sensitive the predicted output function is to a change in this parameter. When learning a new task, changes to important parameters can then be penalized, effectively preventing important knowledge related to previous tasks from being overwritten. Further, we show an interesting connection between a local version of our method and Hebb’s rule, which is a model for the learning process in the brain. We test our method on a sequence of object recognition tasks and on the challenging problem of learning an embedding for predicting< subject, predicate, object> triplets. We show state-of-the-art performance and, for the first time, the ability to adapt the importance of the parameters based on unlabeled data towards what the network needs (not) to forget, which may vary …",
        "year": 2018,
        "authors": "Rahaf Aljundi and Francesca Babiloni and Mohamed Elhoseiny and Marcus Rohrbach and Tinne Tuytelaars"
      },
      {
        "title": "Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding",
        "abstract": "Modeling textual or visual information with vector representations trained from large language or visual datasets has been successfully explored in recent years. However, tasks such as visual question answering require combining these vector representations with each other. Approaches to multimodal pooling include element-wise product or sum, as well as concatenation of the visual and textual representations. We hypothesize that these methods are not as expressive as an outer product of the visual and textual vectors. As the outer product is typically infeasible due to its high dimensionality, we instead propose utilizing Multimodal Compact Bilinear pooling (MCB) to efficiently and expressively combine multimodal features. We extensively evaluate MCB on the visual question answering and grounding tasks. We consistently show the benefit of MCB over ablations without MCB. For visual question answering, we present an architecture which uses MCB twice, once for predicting attention over spatial features and again to combine the attended representation with the question representation. This model outperforms the state-of-the-art on the Visual7W dataset and the VQA challenge.",
        "year": 2016,
        "authors": "Akira Fukui and Dong Huk Park and Daylen Yang and Anna Rohrbach and Trevor Darrell and Marcus Rohrbach"
      }
    ],
    "aa9LMvoAAAAJ": [
      {
        "title": "Opportunities and challenges in using real-world data for health care",
        "abstract": "Real-world data (RWD) continue to emerge as a new source of clinical evidence. Although the best-known use case of RWD has been in drug regulation, RWD are being generated and used by many other parties, including biopharmaceutical companies, payors, clinical researchers, providers, and patients. In this Review, we describe 21 potential uses for RWD across the spectrum of health care. We also discuss important challenges and limitations relevant to the translation of these data into evidence.",
        "year": 2020,
        "authors": "Vivek A Rudrapatna and Atul J Butte"
      },
      {
        "title": "Drosophila cancer models",
        "abstract": "Cancer is driven by complex genetic and cellular mechanisms. Recently, the Drosophila community has become increasingly interested in exploring cancer issues. The Drosophila field has made seminal contributions to many of the mechanisms that are fundamental to the cancer process; several of these mechanisms have already been validated in vertebrates. Less well known are the Drosophila field's early direct contributions to the cancer field: some of the earliest tumor suppressors were identified in flies. In this review, we identify major contributions that Drosophila studies have made toward dissecting the pathways and mechanisms underlying tumor progression. We also highlight areas, such as drug discovery, where we expect Drosophila studies to make a major scientific impact in the future. Developmental Dynamics 241:107–118, 2012. © 2011 Wiley Periodicals, Inc",
        "year": 2012,
        "authors": "Vivek A Rudrapatna and Ross L Cagan and Tirtha K Das"
      },
      {
        "title": "Caspase signalling in the absence of apoptosis drives Jnk‐dependent invasion",
        "abstract": "Tumours evolve several mechanisms to evade apoptosis, yet many resected carcinomas show significantly elevated caspase activity. Moreover, caspase activity is positively correlated with tumour aggression and adverse patient outcome. These observations indicate that caspases might have a functional role in promoting tumour invasion and metastasis. Using a Drosophila model of invasion, we show that precise effector caspase activity drives cell invasion without initiating apoptosis. Affected cells express the matrix metalloprotinase Mmp1 and invade by activating Jnk. Our results link Jnk and effector caspase signalling during the invasive process and suggest that tumours under apoptotic stresses from treatment, immune surveillance or intrinsic signals might be induced further along the metastatic cascade.",
        "year": 2013,
        "authors": "Vivek A Rudrapatna and Erdem Bangi and Ross L Cagan"
      }
    ],
    "itSa94cAAAAJ": [
      {
        "title": "Proximal policy optimization algorithms",
        "abstract": "We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a \"surrogate\" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.",
        "year": 2017,
        "authors": "John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov"
      },
      {
        "title": "Training language models to follow instructions with human feedback",
        "abstract": "Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through a language model API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3 B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.",
        "year": 2022,
        "authors": "Long Ouyang and Jeffrey Wu and Xu Jiang and Diogo Almeida and Carroll Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul F Christiano and Jan Leike and Ryan Lowe"
      },
      {
        "title": "Gpt-4 technical report",
        "abstract": "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.",
        "year": 2023,
        "authors": "Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew"
      }
    ],
    "OP6ejqgAAAAJ": [
      {
        "title": "Minimax estimation of functionals of discrete distributions",
        "abstract": "We propose a general methodology for the construction and analysis of essentially minimax estimators for a wide class of functionals of finite dimensional parameters, and elaborate on the case of discrete distributions, where the support size S is unknown and may be comparable with or even much larger than the number of observations n. We treat the respective regions where the functional is nonsmooth and smooth separately. In the nonsmooth regime, we apply an unbiased estimator for the best polynomial approximation of the functional whereas, in the smooth regime, we apply a bias-corrected version of the maximum likelihood estimator (MLE). We illustrate the merit of this approach by thoroughly analyzing the performance of the resulting schemes for estimating two important information measures: 1) the entropy H(P) = ΣSi=1 -pi ln pi and 2) Fα(P) = ΣSi=1 pαi, α > 0. We obtain the minimax L2 rates for …",
        "year": 2015,
        "authors": "Jiantao Jiao and Kartik Venkat and Yanjun Han and Tsachy Weissman"
      },
      {
        "title": "Justification of logarithmic loss via the benefit of side information",
        "abstract": "We consider a natural measure of relevance: the reduction in optimal prediction risk in the presence of side information. For any given loss function, this relevance measure captures the benefit of side information for performing inference on a random variable under this loss function. When such a measure satisfies a natural data processing property, and the random variable of interest has alphabet size greater than two, we show that it is uniquely characterized by the mutual information, and the corresponding loss function coincides with logarithmic loss. In doing so, our work provides a new characterization of mutual information, and justifies its use as a measure of relevance. When the alphabet is binary, we characterize the only admissible forms the measure of relevance can assume while obeying the specified data processing property. Our results naturally extend to measuring the causal influence between …",
        "year": 2015,
        "authors": "Jiantao Jiao and Thomas A Courtade and Kartik Venkat and Tsachy Weissman"
      },
      {
        "title": "Reference based genome compression",
        "abstract": "DNA sequencing technology has advanced to a point where storage is becoming the central bottleneck in the acquisition and mining of more data. Large amounts of data are vital for genomics research, and generic compression tools, while viable, cannot offer the same savings as approaches tuned to inherent biological properties. We propose an algorithm to compress a target genome given a known reference genome. The proposed algorithm first generates a mapping from the reference to the target genome, and then compresses this mapping with an entropy coder. As an illustration of the performance: applying our algorithm to James Watson's genome with hg18 as a reference, we are able to reduce the 2991 megabyte (MB) genome down to 6.99 MB, while Gzip compresses it to 834.8 MB.",
        "year": 2012,
        "authors": "BG Chern and Idoia Ochoa and Alexandros Manolakos and Albert No and Kartik Venkat and Tsachy Weissman"
      }
    ],
    "Bk5q_pAAAAAJ": [
      {
        "title": "Iterative preference learning from human feedback: Bridging theory and practice for rlhf under kl-constraint",
        "abstract": "This paper studies the alignment process of generative models with Reinforcement Learning from Human Feedback (RLHF). We first identify the primary challenges of existing popular methods like offline PPO and offline DPO as lacking in strategical exploration of the environment. Then, to understand the mathematical principle of RLHF, we consider a standard mathematical formulation, the reverse-KL regularized contextual bandit for RLHF. Despite its widespread practical application, a rigorous theoretical analysis of this formulation remains open. We investigate its behavior in three distinct settings -- offline, online, and hybrid -- and propose efficient algorithms with finite-sample theoretical guarantees. Moving towards practical applications, our framework, with a robust approximation of the information-theoretical policy improvement oracle, naturally gives rise to several novel RLHF algorithms. This includes an iterative version of the Direct Preference Optimization (DPO) algorithm for online settings, and a multi-step rejection sampling strategy for offline scenarios. Our empirical evaluations on real-world alignment experiment of large language model demonstrate that these proposed methods significantly surpass existing strong baselines, such as DPO and Rejection Sampling Optimization (RSO), showcasing the connections between solid theoretical foundations and their potent practical implementations.",
        "year": 2024,
        "authors": "Wei Xiong and Hanze Dong and Chenlu Ye and Ziqi Wang and Han Zhong and Heng Ji and Nan Jiang and Tong Zhang"
      },
      {
        "title": "Human-in-the-loop: Provably Efficient Preference-based Reinforcement Learning with General Function Approximation",
        "abstract": "We study human-in-the-loop reinforcement learning (RL) with trajectory preferences, where instead of receiving a numeric reward at each step, the RL agent only receives preferences over trajectory pairs from a human overseer. The goal of the RL agent is to learn the optimal policy which is most preferred by the human overseer. Despite the empirical success in various real-world applications, the theoretical understanding of preference-based RL (PbRL) is only limited to the tabular case. In this paper, we propose the first optimistic model-based algorithm for PbRL with general function approximation, which estimates the model using value-targeted regression and calculates the exploratory policies by solving an optimistic planning problem. We prove that our algorithm achieves the regret bound of , where  is the complexity measure of the transition and preference model depending on the Eluder dimension and log-covering numbers,  is the planning horizon,  is the number of episodes, and  omits logarithmic terms. Our lower bound indicates that our algorithm is near-optimal when specialized to the linear setting. Furthermore, we extend the PbRL problem by formulating a novel problem called RL with -wise comparisons, and provide the first sample-efficient algorithm for this new setting. To the best of our knowledge, this is the first theoretical result for PbRL with (general) function approximation.",
        "year": 2022,
        "authors": "Xiaoyu Chen and Han Zhong and Zhuoran Yang and Zhaoran Wang and Liwei Wang"
      },
      {
        "title": "Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic Preference Adjustment",
        "abstract": "We consider the problem of multi-objective alignment of foundation models with human preferences, which is a critical step towards helpful and harmless AI systems. However, it is generally costly and unstable to fine-tune large foundation models using reinforcement learning (RL), and the multi-dimensionality, heterogeneity, and conflicting nature of human preferences further complicate the alignment process. In this paper, we introduce Rewards-in-Context (RiC), which conditions the response of a foundation model on multiple rewards in its prompt context and applies supervised fine-tuning for alignment. The salient features of RiC are simplicity and adaptivity, as it only requires supervised fine-tuning of a single foundation model and supports dynamic adjustment for user preferences during inference time. Inspired by the analytical solution of an abstracted convex optimization problem, our dynamic inference-time adjustment method approaches the Pareto-optimal solution for multiple objectives. Empirical evidence demonstrates the efficacy of our method in aligning both Large Language Models (LLMs) and diffusion models to accommodate diverse rewards with only around 10% GPU hours compared with multi-objective RL baseline.",
        "year": 2024,
        "authors": "Rui Yang and Xiaoman Pan and Feng Luo and Shuang Qiu and Han Zhong and Dong Yu and Jianshu Chen"
      }
    ],
    "BAAZ_ysAAAAJ": [
      {
        "title": "Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks",
        "abstract": "Many machine learning tasks such as multiple instance learning, 3D shape recognition, and few-shot image classification are defined on sets of instances. Since solutions to such problems do not depend on the order of elements of the set, models used to address them should be permutation invariant. We present an attention-based neural network module, the Set Transformer, specifically designed to model interactions among elements in the input set. The model consists of an encoder and a decoder, both of which rely on attention mechanisms. In an effort to reduce computational complexity, we introduce an attention scheme inspired by inducing point methods from sparse Gaussian process literature. It reduces the computation time of self-attention from quadratic to linear in the number of elements in the set. We show that our model is theoretically attractive and we evaluate it on a range of tasks, demonstrating the state-of-the-art performance compared to recent methods for set-structured data.",
        "year": 2019,
        "authors": "Juho Lee and Yoonho Lee and Jungtaek Kim and Adam Kosiorek and Seungjin Choi and Yee Whye Teh"
      },
      {
        "title": "Detectgpt: Zero-shot machine-generated text detection using probability curvature",
        "abstract": "The increasing fluency and widespread usage of large language models (LLMs) highlight the desirability of corresponding tools aiding detection of LLM-generated text. In this paper, we identify a property of the structure of an LLM’s probability function that is useful for such detection. Specifically, we demonstrate that text sampled from an LLM tends to occupy negative curvature regions of the model’s log probability function. Leveraging this observation, we then define a new curvature-based criterion for judging if a passage is generated from a given LLM. This approach, which we call DetectGPT, does not require training a separate classifier, collecting a dataset of real or generated passages, or explicitly watermarking generated text. It uses only log probabilities computed by the model of interest and random perturbations of the passage from another generic pre-trained language model (eg, T5). We find DetectGPT is more discriminative than existing zero-shot methods for model sample detection, notably improving detection of fake news articles generated by 20B parameter GPT-NeoX from 0.81 AUROC for the strongest zero-shot baseline to 0.95 AUROC for DetectGPT.",
        "year": 2023,
        "authors": "Eric Mitchell and Yoonho Lee and Alexander Khazatsky and Christopher D Manning and Chelsea Finn"
      },
      {
        "title": "Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace",
        "abstract": "Gradient-based meta-learning methods leverage gradient descent to learn the commonalities among various tasks. While previous such methods have been successful in meta-learning tasks, they resort to simple gradient descent during meta-testing. Our primary contribution is the MT-net, which enables the meta-learner to learn on each layer’s activation space a subspace that the task-specific learner performs gradient descent on. Additionally, a task-specific learner of an MT-net performs gradient descent with respect to a meta-learned distance metric, which warps the activation space to be more sensitive to task identity. We demonstrate that the dimension of this learned subspace reflects the complexity of the task-specific learner’s adaptation task, and also that our model is less sensitive to the choice of initial learning rates than previous gradient-based meta-learning methods. Our method achieves state-of-the-art or comparable performance on few-shot classification and regression tasks.",
        "year": 2018,
        "authors": "Yoonho Lee and Seungjin Choi"
      }
    ],
    "PGdm9MUAAAAJ": [
      {
        "title": "Adversarial Texture for Fooling Person Detectors in the Physical World",
        "abstract": "Nowadays, cameras equipped with AI systems can capture and analyze images to detect people automatically. However, the AI system can make mistakes when receiving deliberately designed patterns in the real world, ie, physical adversarial examples. Prior works have shown that it is possible to print adversarial patches on clothes to evade DNN-based person detectors. However, these adversarial examples could have catastrophic drops in the attack success rate when the viewing angle (ie, the camera's angle towards the object) changes. To perform a multi-angle attack, we propose Adversarial Texture (AdvTexture). AdvTexture can cover clothes with arbitrary shapes so that people wearing such clothes can hide from person detectors from different viewing angles. We propose a generative method, named Toroidal-Cropping-based Expandable Generative Attack (TC-EGA), to craft AdvTexture with repetitive structures. We printed several pieces of cloth with AdvTexure and then made T-shirts, skirts, and dresses in the physical world. Experiments showed that these clothes could fool person detectors in the physical world.",
        "year": 2022,
        "authors": "Zhanhao Hu and Siyuan Huang and Xiaopei Zhu and Fuchun Sun and Bo Zhang and Xiaolin Hu"
      },
      {
        "title": "Infrared Invisible Clothing: Hiding from Infrared Detectors at Multiple Angles in Real World",
        "abstract": "Thermal infrared imaging is widely used in body temperature measurement, security monitoring, and so on, but its safety research attracted attention only in recent years. We proposed the infrared adversarial clothing, which could fool infrared pedestrian detectors at different angles. We simulated the process from cloth to clothing in the digital world and then designed the adversarial\" QR code\" pattern. The core of our method is to design a basic pattern that can be expanded periodically, and make the pattern after random cropping and deformation still have an adversarial effect, then we can process the flat cloth with an adversarial pattern into any 3D clothes. The results showed that the optimized\" QR code\" pattern lowered the Average Precision (AP) of YOLOv3 by 87.7%, while the random\" QR code\" pattern and blank pattern lowered the AP of YOLOv3 by 57.9% and 30.1%, respectively, in the digital world. We then manufactured an adversarial shirt with a new material: aerogel. Physical-world experiments showed that the adversarial\" QR code\" pattern clothing lowered the AP of YOLOv3 by 64.6%, while the random\" QR code\" pattern clothing and fully heat-insulated clothing lowered the AP of YOLOv3 by 28.3% and 22.8%, respectively. We used the model ensemble technique to improve the attack transferability to unseen models.",
        "year": 2022,
        "authors": "Xiaopei Zhu and Zhanhao Hu and Siyuan Huang and Jianmin Li and Xiaolin Hu"
      },
      {
        "title": "Physically Realizable Natural-Looking Clothing Textures Evade Person Detectors via 3D Modeling",
        "abstract": "Recent works have proposed to craft adversarial clothes for evading person detectors, while they are either only effective at limited viewing angles or very conspicuous to humans. We aim to craft adversarial texture for clothes based on 3D modeling, an idea that has been used to craft rigid adversarial objects such as a 3D-printed turtle. Unlike rigid objects, humans and clothes are non-rigid, leading to difficulties in physical realization. In order to craft natural-looking adversarial clothes that can evade person detectors at multiple viewing angles, we propose adversarial camouflage textures (AdvCaT) that resemble one kind of the typical textures of daily clothes, camouflage textures. We leverage the Voronoi diagram and Gumbel-softmax trick to parameterize the camouflage textures and optimize the parameters via 3D modeling. Moreover, we propose an efficient augmentation pipeline on 3D meshes combining topologically plausible projection (TopoProj) and Thin Plate Spline (TPS) to narrow the gap between digital and real-world objects. We printed the developed 3D texture pieces on fabric materials and tailored them into T-shirts and trousers. Experiments show high attack success rates of these clothes against multiple detectors.",
        "year": 2023,
        "authors": "Zhanhao Hu and Wenda Chu and Xiaopei Zhu and Hui Zhang and Bo Zhang and Xiaolin Hu"
      }
    ],
    "0qfCL-QAAAAJ": [
      {
        "title": "A study of Gaussian mixture models of color and texture features for image classification and segmentation",
        "abstract": "The aims of this paper are two-fold: to define Gaussian mixture models (GMMs) of colored texture on several feature spaces and to compare the performance of these models in various classification tasks, both with each other and with other models popular in the literature. We construct GMMs over a variety of different color and texture feature spaces, with a view to the retrieval of textured color images from databases. We compare supervised classification results for different choices of color and texture features using the Vistex database, and explore the best set of features and the best GMM configuration for this task. In addition we introduce several methods for combining the ‘color’ and ‘structure’ information in order to improve the classification performances. We then apply the resulting models to the classification of texture databases and to the classification of man-made and natural areas in aerial images. We …",
        "year": 2006,
        "authors": "Haim Permuter and Joseph Francos and Ian Jermyn"
      },
      {
        "title": "Coordination capacity",
        "abstract": "We develop elements of a theory of cooperation and coordination in networks. Rather than considering a communication network as a means of distributing information, or of reconstructing random processes at remote nodes, we ask what dependence can be established among the nodes given the communication constraints. Specifically, in a network with communication rates  between the nodes, we ask what is the set of all achievable joint distributions  of actions at the nodes of the network. Several networks are solved, including arbitrarily large cascade networks. Distributed cooperation can be the solution to many problems such as distributed games, distributed control, and establishing mutual information bounds on the influence of one part of a physical system on another.",
        "year": 2010,
        "authors": "Paul Warner Cuff and Haim H Permuter and Thomas M Cover"
      },
      {
        "title": "Gaussian mixture models of texture and colour for image database retrieval",
        "abstract": "We introduce Gaussian mixture models of 'structure' and colour features in order to classify coloured textures in images, with a view to the retrieval of textured colour images from databases. Classifications are performed separately using structure and colour and then combined using a confidence criterion. We apply the models to the VisTex database and to the classification of man-made and natural areas in aerial images. We compare these models with others in the literature, and show an overall improvement in performance.",
        "year": 2003,
        "authors": "Haim Permuter and Joseph Francos and Ian H Jermyn"
      }
    ],
    "0bwP0i4AAAAJ": [
      {
        "title": "Immune correlates analysis of the mRNA-1273 COVID-19 vaccine efficacy clinical trial",
        "abstract": "In the coronavirus efficacy (COVE) phase 3 clinical trial, vaccine recipients were assessed for neutralizing and binding antibodies as correlates of risk for COVID-19 disease and as correlates of protection. These immune markers were measured at the time of second vaccination and 4 weeks later, with values reported in standardized World Health Organization international units. All markers were inversely associated with COVID-19 risk and directly associated with vaccine efficacy. Vaccine recipients with postvaccination 50% neutralization titers 10, 100, and 1000 had estimated vaccine efficacies of 78% (95% confidence interval, 54 to 89%), 91% (87 to 94%), and 96% (94 to 98%), respectively. These results help define immune marker correlates of protection and may guide approval decisions for messenger RNA (mRNA) COVID-19 vaccines and other COVID-19 vaccines.",
        "year": 2022,
        "authors": "Peter B Gilbert and David C Montefiori and Adrian B McDermott and Youyi Fong and David Benkeser and Weiping Deng and Honghong Zhou and Christopher R Houchens and Karen Martins and Lakshmi Jayashankar and Flora Castellino and Britta Flach and Bob C Lin and Sarah O’Connell and Charlene McDanal and Amanda Eaton and Marcella Sarzotti-Kelsoe and Yiwen Lu and Chenchen Yu and Bhavesh Borate and Lars WP van der Laan and Nima S Hejazi and Chuong Huynh and Jacqueline Miller and Hana M El Sahly and Lindsey R Baden and Mira Baron and Luis De La Cruz and Cynthia Gay and Spyros Kalams and Colleen F Kelley and Michele P Andrasik and James G Kublin and Lawrence Corey and Kathleen M Neuzil and Lindsay N Carpp and Rolando Pajon and Dean Follmann and Ruben O Donis and Richard A Koup and Immune Assays Team § and Moderna and Inc. Team § and Coronavirus Vaccine Prevention Network (CoVPN)/Coronavirus Efficacy (COVE) Team § and United States Government (USG)/CoVPN Biostatistics Team §"
      },
      {
        "title": "Immune correlates analysis of the PREVENT-19 COVID-19 vaccine efficacy clinical trial",
        "abstract": "In the PREVENT-19 phase 3 trial of the NVX-CoV2373 vaccine (NCT04611802), anti-spike binding IgG concentration (spike IgG), anti-RBD binding IgG concentration (RBD IgG), and pseudovirus 50% neutralizing antibody titer (nAb ID50) measured two weeks post-dose two are assessed as correlates of risk and as correlates of protection against COVID-19. Analyses are conducted in the U.S. cohort of baseline SARS-CoV-2 negative per-protocol participants using a case-cohort design that measures the markers from all 12 vaccine recipient breakthrough COVID-19 cases starting 7 days post antibody measurement and from 639 vaccine recipient non-cases. All markers are inversely associated with COVID-19 risk and directly associated with vaccine efficacy. In vaccine recipients with nAb ID50 titers of 50, 100, and 7230 international units (IU50)/ml, vaccine efficacy estimates are 75.7% (49.8%, 93.2%), 81.7% (66.3 …",
        "year": 2023,
        "authors": "Youyi Fong and Yunda Huang and David Benkeser and Lindsay N Carpp and Germán Áñez and Wayne Woo and Alice McGarry and Lisa M Dunkle and Iksung Cho and Christopher R Houchens and Karen Martins and Lakshmi Jayashankar and Flora Castellino and Christos J Petropoulos and Andrew Leith and Deanne Haugaard and Bill Webb and Yiwen Lu and Chenchen Yu and Bhavesh Borate and Lars WP van der Laan and Nima S Hejazi and April K Randhawa and Michele P Andrasik and James G Kublin and Julia Hutter and Maryam Keshtkar-Jahromi and Tatiana H Beresnev and Lawrence Corey and Kathleen M Neuzil and Dean Follmann and Julie A Ake and Cynthia L Gay and Karen L Kotloff and Richard A Koup and Ruben O Donis and Peter B Gilbert and Immune Assays Team and Coronavirus Vaccine Prevention Network (CoVPN)/2019nCoV-301 Principal Investigators and Study Team and United States Government (USG)/CoVPN Biostatistics Team"
      },
      {
        "title": "Immune correlates analysis of the ENSEMBLE single Ad26. COV2. S dose vaccine efficacy clinical trial",
        "abstract": "Measuring immune correlates of disease acquisition and protection in the context of a clinical trial is a prerequisite for improved vaccine design. We analysed binding and neutralizing antibody measurements 4 weeks post vaccination as correlates of risk of moderate to severe-critical COVID-19 through 83 d post vaccination in the phase 3, double-blind placebo-controlled phase of ENSEMBLE, an international randomized efficacy trial of a single dose of Ad26.COV2.S. We also evaluated correlates of protection in the trial cohort. Of the three antibody immune markers we measured, we found most support for 50% inhibitory dilution (ID50) neutralizing antibody titre as a correlate of risk and of protection. The outcome hazard ratio was 0.49 (95% confidence interval 0.29, 0.81; P = 0.006) per 10-fold increase in ID50; vaccine efficacy was 60% (43%, 72%) at non-quantifiable ID50 (<2.7 IU50 ml−1) and increased to …",
        "year": 2022,
        "authors": "Youyi Fong and Adrian B McDermott and David Benkeser and Sanne Roels and Daniel J Stieh and An Vandebosch and Mathieu Le Gars and Griet A Van Roey and Christopher R Houchens and Karen Martins and Lakshmi Jayashankar and Flora Castellino and Obrimpong Amoa-Awua and Manjula Basappa and Britta Flach and Bob C Lin and Christopher Moore and Mursal Naisan and Muhammed Naqvi and Sandeep Narpala and Sarah O’Connell and Allen Mueller and Leo Serebryannyy and Mike Castro and Jennifer Wang and Christos J Petropoulos and Alex Luedtke and Ollivier Hyrien and Yiwen Lu and Chenchen Yu and Bhavesh Borate and Lars WP van Der Laan and Nima S Hejazi and Avi Kenny and Marco Carone and Daniel N Wolfe and Jerald Sadoff and Glenda E Gray and Beatriz Grinsztejn and Paul A Goepfert and Susan J Little and Leonardo Paiva de Sousa and Rebone Maboa and April K Randhawa and Michele P Andrasik and Jenny Hendriks and Carla Truyers and Frank Struyf and Hanneke Schuitemaker and Macaya Douoguih and James G Kublin and Lawrence Corey and Kathleen M Neuzil and Lindsay N Carpp and Dean Follmann and Peter B Gilbert and Richard A Koup and Ruben O Donis and Immune Assays Team and Coronavirus Vaccine Prevention Network (CoVPN)/ENSEMBLE Team and United States Government (USG)/CoVPN Biostatistics Team"
      }
    ],
    "PS-TM94AAAAJ": [
      {
        "title": "The dynamics of message passing on dense graphs, with applications to compressed sensing",
        "abstract": "“Approximate message passing” (AMP) algorithms have proved to be effective in reconstructing sparse signals from a small number of incoherent linear measurements. Extensive numerical experiments further showed that their dynamics is accurately tracked by a simple one-dimensional iteration termed state evolution. In this paper, we provide rigorous foundation to state evolution. We prove that indeed it holds asymptotically in the large system limit for sensing matrices with independent and identically distributed Gaussian entries. While our focus is on message passing algorithms for compressed sensing, the analysis extends beyond this setting, to a general class of algorithms on dense graphs. In this context, state evolution plays the role that density evolution has for sparse graphs. The proof technique is fundamentally different from the standard approach to density evolution, in that it copes with a large number …",
        "year": 2011,
        "authors": "Mohsen Bayati and Andrea Montanari"
      },
      {
        "title": "Matrix completion methods for causal panel data models",
        "abstract": "In this article, we study methods for estimating causal effects in settings with panel data, where some units are exposed to a treatment during some periods and the goal is estimating counterfactual (untreated) outcomes for the treated unit/period combinations. We propose a class of matrix completion estimators that uses the observed elements of the matrix of control outcomes corresponding to untreated unit/periods to impute the “missing” elements of the control outcome matrix, corresponding to treated units/periods. This leads to a matrix that well-approximates the original (incomplete) matrix, but has lower complexity according to the nuclear norm for matrices. We generalize results from the matrix completion literature by allowing the patterns of missing data to have a time series dependency structure that is common in social science applications. We present novel insights concerning the connections between the …",
        "year": 2021,
        "authors": "Susan Athey and Mohsen Bayati and Nikolay Doudchenko and Guido Imbens and Khashayar Khosravi"
      },
      {
        "title": "Online decision making with high-dimensional covariates",
        "abstract": "Big data have enabled decision makers to tailor decisions at the individual level in a variety of domains, such as personalized medicine and online advertising. Doing so involves learning a model of decision rewards conditional on individual-specific covariates. In many practical settings, these covariates are high dimensional; however, typically only a small subset of the observed features are predictive of a decision’s success. We formulate this problem as a K-armed contextual bandit with high-dimensional covariates and present a new efficient bandit algorithm based on the LASSO estimator. We prove that our algorithm’s cumulative expected regret scales at most polylogarithmically in the covariate dimension d; to the best of our knowledge, this is the first such bound for a contextual bandit. The key step in our analysis is proving a new tail inequality that guarantees the convergence of the LASSO estimator despite …",
        "year": 2020,
        "authors": "Hamsa Bastani and Mohsen Bayati"
      }
    ],
    "fmSHtE8AAAAJ": [
      {
        "title": "An analysis of single-layer networks in unsupervised feature learning",
        "abstract": "A great deal of research has focused on algorithms for learning features from unlabeled data. Indeed, much progress has been made on benchmark datasets like NORB and CIFAR-10 by employing increasingly complex unsupervised learning algorithms and deep models. In this paper, however, we show that several simple factors, such as the number of hidden nodes in the model, may be more important to achieving high performance than the learning algorithm or the depth of the model. Specifically, we will apply several off-the-shelf feature learning algorithms (sparse auto-encoders, sparse RBMs, K-means clustering, and Gaussian mixtures) to CIFAR-10, NORB, and STL datasets using only single-layer networks. We then present a detailed analysis of the effect of changes in the model setup: the receptive field size, number of hidden nodes (features), the step-size (“stride”) between extracted features, and the effect of whitening. Our results show that large numbers of hidden nodes and dense feature extraction are critical to achieving high performance-so critical, in fact, that when these parameters are pushed to their limits, we achieve state-of-the-art performance on both CIFAR-10 and NORB using only a single layer of features. More surprisingly, our best performance is based on K-means clustering, which is extremely fast, has no hyper-parameters to tune beyond the model structure itself, and is very easy to implement. Despite the simplicity of our system, we achieve accuracy beyond all previously published results on the CIFAR-10 and NORB datasets (79.6% and 97.2% respectively).",
        "year": 2011,
        "authors": "Adam Coates and Honglak Lee and Andrew Y Ng"
      },
      {
        "title": "Multimodal deep learning",
        "abstract": "Deep networks have been successfully applied to unsupervised feature learning for single modalities (eg, text, images or audio). In this work, we propose a novel application of deep networks to learn features over multiple modalities. We present a series of tasks for multimodal learning and show how to train deep networks that learn features to address these tasks. In particular, we demonstrate cross modality feature learning, where better features for one modality (eg, video) can be learned if multiple modalities (eg, audio and video) are present at feature learning time. Furthermore, we show how to learn a shared representation between modalities and evaluate it on a unique task, where the classifier is trained with audio-only data but tested with video-only data and vice-versa. Our models are validated on the CUAVE and AVLetters datasets on audio-visual speech classification, demonstrating best published visual speech classification on AVLetters and effective shared representation learning.",
        "year": 2011,
        "authors": "Jiquan Ngiam and Aditya Khosla and Mingyu Kim and Juhan Nam and Honglak Lee and Andrew Y Ng"
      },
      {
        "title": "Generative Adversarial Text to Image Synthesis",
        "abstract": "Automatic synthesis of realistic images from text would be interesting and useful, but current AI systems are still far from this goal. However, in recent years generic and powerful recurrent neural network architectures have been developed to learn discriminative text feature representations. Meanwhile, deep convolutional generative adversarial networks (GANs) have begun to generate highly compelling images of specific categories such as faces, album covers, room interiors and flowers. In this work, we develop a novel deep architecture and GAN formulation to effectively bridge these advances in text and image modeling, translating visual concepts from characters to pixels. We demonstrate the capability of our model to generate plausible images of birds and flowers from detailed text descriptions.",
        "year": 2016,
        "authors": "Scott Reed and Zeynep Akata and Xinchen Yan and Lajanugen Logeswaran and Bernt Schiele and Honglak Lee"
      }
    ],
    "j8ULfMsAAAAJ": [
      {
        "title": "Attention, intentions, and the structure of discourse",
        "abstract": "In this paper we explore a new theory of discourse structure that stresses the role of purpose and processing in discourse. In this theory, discourse structure is composed of three separate but interrelated components: the structure of the sequence of utterances (called the linguistic structure), a structure of purposes (called the intentional structure), and the state of focus of attention (called the attentional state). The linguistic structure consists of segments of the discourse into which the utterances naturally aggregate. The intentional structure captures the discourse-relevant purposes, expressed in each of the linguistic segments as well as relationships among them. The attentional state is an abstraction of the focus of attention of the participants as the discourse unfolds. The attentional state, being dynamic, records the objects, properties, and relations that are salient at each point of the discourse. The distinction among these components is essential to provide an adequate explanation of such discourse phenomena as cue phrases, referring expressions, and interruptions. The theory of attention, intention, and aggregation of utterances is illustrated in the paper with a number of example discourses. Various properties of discourse are described, and explanations for the behavior of cue phrases, referring expressions, and interruptions are explored. This theory provides a framework for describing the processing of utterances in a discourse. Discourse processing requires recognizing how the utterances of the discourse aggregate into segments, recognizing the intentions expressed in the discourse and the relationships among intentions, and tracking …",
        "year": 1986,
        "authors": "Barbara J Grosz and Candace L Sidner"
      },
      {
        "title": "Email overload: exploring personal information management of email",
        "abstract": "Email is one of the most successful computer applications yet devised. Our empirical data show however, that although email was originally designed as a communications application, it is now being used for additional functions, that it was not designed for, such as task management and personal archiving. We call this email overload. We demonstrate that email overload creates problems for personal information management: users often have cluttered inboxes containing hundreds of messages, including outstanding tasks, partially read documents and conversational threads. Furthermore, user attempts to rationalise their inboxes by filing are often unsuccessful, with the consequence that important messages get overlooked, or\" lost\" in archives. We explain how email overloading arises and propose technical solutions to the problem.",
        "year": 1996,
        "authors": "Steve Whittaker and Candace Sidner"
      },
      {
        "title": "Plans for discourse",
        "abstract": "In Grosz and Sidner 1986 we proposed a theory of discourse structure comprising three components: a linguistic structure, an intentional structure, and an attentional state. These three constituents of discourse structure deal with different aspects of the utterances in a discourse. Utterancesthe actual saying or writing of particular sequences of phrases and clausesare the linguistic structure's basic elements. Intentions and the relations of domination and satisfaction precedence provide the basic elements of the intentional structure. Attentional state contains information about the objects, properties, relations, and discourse intentions that are most salient at any given point. It is an abstraction of the focus of attention of the discourse participants; it serves to summarize information from previous utterances crucial for processing subsequent ones, thus obviating the need for keeping a complete history of the discourse. In …",
        "year": 1990,
        "authors": "Barbara J Grosz and Candace L Sidner"
      }
    ],
    "tfN6V84AAAAJ": [
      {
        "title": "Open X-Embodiment: Robotic Learning Datasets and RT-X Models : Open X-Embodiment Collaboration0",
        "abstract": "Large, high-capacity models trained on diverse datasets have shown remarkable successes on efficiently tackling downstream applications. In domains from NLP to Computer Vision, this has led to a consolidation of pretrained models, with general pretrained backbones serving as a starting point for many applications. Can such a consolidation happen in robotics? Conventionally, robotic learning methods train a separate model for every application, every robot, and even every environment. Can we instead train \"generalist\" X-robot policy that can be adapted efficiently to new robots, tasks, and environments? In this paper, we provide datasets in standardized data formats and models to make it possible to explore this possibility in the context of robotic manipulation, alongside experimental results that provide an example of effective X-robot policies. We assemble a dataset from 22 different robots collected through …",
        "year": 2024,
        "authors": "Abby O’Neill and Abdul Rehman and Abhiram Maddukuri and Abhishek Gupta and Abhishek Padalkar and Abraham Lee and Acorn Pooley and Agrim Gupta and Ajay Mandlekar and Ajinkya Jain and Albert Tung and Alex Bewley and Alex Herzog and Alex Irpan and Alexander Khazatsky and Anant Rai and Anchit Gupta and Andrew Wang and Anikait Singh and Animesh Garg and Aniruddha Kembhavi and Annie Xie and Anthony Brohan and Antonin Raffin and Archit Sharma and Arefeh Yavary and Arhan Jain and Ashwin Balakrishna and Ayzaan Wahid and Ben Burgess-Limerick and Beomjoon Kim and Bernhard Schölkopf and Blake Wulfe and Brian Ichter and Cewu Lu and Charles Xu and Charlotte Le and Chelsea Finn and Chen Wang and Chenfeng Xu and Cheng Chi and Chenguang Huang and Christine Chan and Christopher Agia and Chuer Pan and Chuyuan Fu and Coline Devin and Danfei Xu and Daniel Morton and Danny Driess and Daphne Chen and Deepak Pathak and Dhruv Shah and Dieter Büchler and Dinesh Jayaraman and Dmitry Kalashnikov and Dorsa Sadigh and Edward Johns and Ethan Foster and Fangchen Liu and Federico Ceola and Fei Xia and Feiyu Zhao and Freek Stulp and Gaoyue Zhou and Gaurav S Sukhatme and Gautam Salhotra and Ge Yan and Gilbert Feng and Giulio Schiavi and Glen Berseth and Gregory Kahn and Guanzhi Wang and Hao Su and Hao-Shu Fang and Haochen Shi and Henghui Bao and Heni Ben Amor and Henrik I Christensen and Hiroki Furuta and Homer Walke and Hongjie Fang and Huy Ha and Igor Mordatch and Ilija Radosavovic and Isabel Leal and Jacky Liang and Jad Abou-Chakra and Jaehyung Kim and Jaimyn Drake and Jan Peters and Jan Schneider and Jasmine Hsu and Jeannette Bohg and Jeffrey Bingham and Jeffrey Wu and Jensen Gao and Jiaheng Hu and Jiajun Wu and Jialin Wu and Jiankai Sun and Jianlan Luo and Jiayuan Gu and Jie Tan and Jihoon Oh and Jimmy Wu and Jingpei Lu and Jingyun Yang and Jitendra Malik and Joao Silverio and Joey Hejna and Jonathan Booher and Jonathan Tompson and Jonathan Yang and Jordi Salvador and Joseph J Lim and Junhyek Han and Kaiyuan Wang and Kanishka Rao and Karl Pertsch and Karol Hausman and Keegan Go and Keerthana Gopalakrishnan and Ken Goldberg and Kendra Byrne and Kenneth Oslund and Kento Kawaharazuka and Kevin Black and Kevin Lin and Kevin Zhang and Kiana Ehsani and Kiran Lekkala and Kirsty Ellis and Krishan Rana and Krishnan Srinivasan and Kuan Fang and Kunal Pratap Singh and Kuo-Hao Zeng and Kyle Hatch and Kyle Hsu and Laurent Itti and Lawrence Yunliang Chen and Lerrel Pinto and Li Fei-Fei and Liam Tan and Linxi Jim Fan and Lionel Ott and Lisa Lee and Luca Weihs and Magnum Chen"
      },
      {
        "title": "Openvla: An open-source vision-language-action model",
        "abstract": "Large policies pretrained on a combination of Internet-scale vision-language data and diverse robot demonstrations have the potential to change how we teach robots new skills: rather than training new behaviors from scratch, we can fine-tune such vision-language-action (VLA) models to obtain robust, generalizable policies for visuomotor control. Yet, widespread adoption of VLAs for robotics has been challenging as 1) existing VLAs are largely closed and inaccessible to the public, and 2) prior work fails to explore methods for efficiently fine-tuning VLAs for new tasks, a key component for adoption. Addressing these challenges, we introduce OpenVLA, a 7B-parameter open-source VLA trained on a diverse collection of 970k real-world robot demonstrations. OpenVLA builds on a Llama 2 language model combined with a visual encoder that fuses pretrained features from DINOv2 and SigLIP. As a product of the added data diversity and new model components, OpenVLA demonstrates strong results for generalist manipulation, outperforming closed models such as RT-2-X (55B) by 16.5% in absolute task success rate across 29 tasks and multiple robot embodiments, with 7x fewer parameters. We further show that we can effectively fine-tune OpenVLA for new settings, with especially strong generalization results in multi-task environments involving multiple objects and strong language grounding abilities, and outperform expressive from-scratch imitation learning methods such as Diffusion Policy by 20.4%. We also explore compute efficiency; as a separate contribution, we show that OpenVLA can be fine-tuned on consumer GPUs via modern …",
        "year": 2024,
        "authors": "Moo Jin Kim and Karl Pertsch and Siddharth Karamcheti and Ted Xiao and Ashwin Balakrishna and Suraj Nair and Rafael Rafailov and Ethan Foster and Grace Lam and Pannag Sanketi and Quan Vuong and Thomas Kollar and Benjamin Burchfiel and Russ Tedrake and Dorsa Sadigh and Sergey Levine and Percy Liang and Chelsea Finn"
      },
      {
        "title": "Recovery rl: Safe reinforcement learning with learned recovery zones",
        "abstract": "Safety remains a central obstacle preventing widespread use of RL in the real world: learning new tasks in uncertain environments requires extensive exploration, but safety requires limiting exploration. We propose Recovery RL, an algorithm which navigates this tradeoff by (1) leveraging offline data to learn about constraint violating zones before policy learning and (2) separating the goals of improving task performance and constraint satisfaction across two policies: a task policy that only optimizes the task reward and a recovery policy that guides the agent to safety when constraint violation is likely. We evaluate Recovery RL on 6 simulation domains, including two contact-rich manipulation tasks and an image-based navigation task, and an image-based obstacle avoidance task on a physical robot. We compare Recovery RL to 5 prior safe RL methods which jointly optimize for task performance and safety via …",
        "year": 2021,
        "authors": "Brijen Thananjeyan and Ashwin Balakrishna and Suraj Nair and Michael Luo and Krishnan Srinivasan and Minho Hwang and Joseph E Gonzalez and Julian Ibarz and Chelsea Finn and Ken Goldberg"
      }
    ],
    "ri1sE34AAAAJ": [
      {
        "title": "End-To-End Memory Networks",
        "abstract": "We introduce a neural network with a recurrent attention model over a possibly large external memory. The architecture is a form of Memory Network (Weston et al., 2015) but unlike the model in that work, it is trained end-to-end, and hence requires significantly less supervision during training, making it more generally applicable in realistic settings. It can also be seen as an extension of RNNsearch to the case where multiple computational steps (hops) are performed per output symbol. The flexibility of the model allows us to apply it to tasks as diverse as (synthetic) question answering and to language modeling. For the former our approach is competitive with Memory Networks, but with less supervision. For the latter, on the Penn TreeBank and Text8 datasets our approach demonstrates comparable performance to RNNs and LSTMs. In both cases we show that the key concept of multiple computational hops yields improved results.",
        "year": 2015,
        "authors": "Sainbayar Sukhbaatar and Arthur Szlam and Jason Weston and Rob Fergus"
      },
      {
        "title": "Learning multiagent communication with backpropagation",
        "abstract": "Many tasks in AI require the collaboration of multiple agents. Typically, the communication protocol between agents is manually specified and not altered during training. In this paper we explore a simple neural model, called CommNet, that uses continuous communication for fully cooperative tasks. The model consists of multiple agents and the communication between them is learned alongside their policy. We apply this model to a diverse set of tasks, demonstrating the ability of the agents to learn to communicate amongst themselves, yielding improved performance over non-communicative agents and baselines. In some cases, it is possible to interpret the language devised by the agents, revealing simple but effective strategies for solving the task at hand.",
        "year": 2016,
        "authors": "Sainbayar Sukhbaatar and Arthur Szlam and Rob Fergus"
      },
      {
        "title": "Training Convolutional Networks with Noisy Labels",
        "abstract": "The availability of large labeled datasets has allowed Convolutional Network models to achieve impressive recognition results. However, in many settings manual annotation of the data is impractical; instead our data has noisy labels, i.e. there is some freely available label for each image which may or may not be accurate. In this paper, we explore the performance of discriminatively-trained Convnets when trained on such noisy data. We introduce an extra noise layer into the network which adapts the network outputs to match the noisy label distribution. The parameters of this noise layer can be estimated as part of the training process and involve simple modifications to current training infrastructures for deep networks. We demonstrate the approaches on several datasets, including large scale experiments on the ImageNet classification benchmark.",
        "year": 2014,
        "authors": "Sainbayar Sukhbaatar and Joan Bruna and Manohar Paluri and Lubomir Bourdev and Rob Fergus"
      }
    ],
    "MzKvJhAAAAAJ": [
      {
        "title": "Measuring massive multitask language understanding",
        "abstract": "We propose a new test to measure a text model's multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have near-random accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model's academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings.",
        "year": 2020,
        "authors": "Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt"
      },
      {
        "title": "Measuring mathematical problem solving with the math dataset",
        "abstract": "Many intellectual endeavors require mathematical problem solving, but this skill remains beyond the capabilities of computers. To measure this ability in machine learning models, we introduce MATH, a new dataset of 12,500 challenging competition mathematics problems. Each problem in MATH has a full step-by-step solution which can be used to teach models to generate answer derivations and explanations. To facilitate future research and increase accuracy on MATH, we also contribute a large auxiliary pretraining dataset which helps teach models the fundamentals of mathematics. Even though we are able to increase accuracy on MATH, our results show that accuracy remains relatively low, even with enormous Transformer models. Moreover, we find that simply increasing budgets and model parameter counts will be impractical for achieving strong mathematical reasoning if scaling trends continue. While scaling Transformers is automatically solving most other text-based tasks, scaling is not currently solving MATH. To have more traction on mathematical problem solving we will likely need new algorithmic advancements from the broader research community.",
        "year": 2021,
        "authors": "Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt"
      },
      {
        "title": "The many faces of robustness: A critical analysis of out-of-distribution generalization",
        "abstract": "We introduce four new real-world distribution shift datasets consisting of changes in image style, image blurriness, geographic location, camera operation, and more. With our new datasets, we take stock of previously proposed methods for improving out-of-distribution robustness and put them to the test. We find that using larger models and artificial data augmentations can improve robustness on real-world distribution shifts, contrary to claims in prior work. We find improvements in artificial robustness benchmarks can transfer to real-world distribution shifts, contrary to claims in prior work. Motivated by our observation that data augmentations can help with real-world distribution shifts, we also introduce a new data augmentation method which advances the state-of-the-art and outperforms models pretrained with 1000x more labeled data. Overall we find that some methods consistently help with distribution shifts in texture and local image statistics, but these methods do not help with some other distribution shifts like geographic changes. Our results show that future research must study multiple distribution shifts simultaneously, as we demonstrate that no evaluated method consistently improves robustness.",
        "year": 2021,
        "authors": "Dan Hendrycks and Steven Basart and Norman Mu and Saurav Kadavath and Frank Wang and Evan Dorundo and Rahul Desai and Tyler Zhu and Samyak Parajuli and Mike Guo and Dawn Song and Jacob Steinhardt and Justin Gilmer"
      }
    ],
    "rNcmwggAAAAJ": [
      {
        "title": "Combined task and motion planning through an extensible planner-independent interface layer",
        "abstract": "The need for combined task and motion planning in robotics is well understood. Solutions to this problem have typically relied on special purpose, integrated implementations of task planning and motion planning algorithms. We propose a new approach that uses off-the-shelf task planners and motion planners and makes no assumptions about their implementation. Doing so enables our approach to directly build on, and benefit from, the vast literature and latest advances in task planning and motion planning. It uses a novel representational abstraction and requires only that failures in computing a motion plan for a high-level action be identifiable and expressible in the form of logical predicates at the task level. We evaluate the approach and illustrate its robustness through a number of experiments using a state-of-the-art robotics simulator and a PR2 robot. These experiments show the system accomplishing a …",
        "year": 2014,
        "authors": "Siddharth Srivastava and Eugene Fang and Lorenzo Riano and Rohan Chitnis and Stuart Russell and Pieter Abbeel"
      },
      {
        "title": "Integrated task and motion planning",
        "abstract": "The problem of planning for a robot that operates in environments containing a large number of objects, taking actions to move itself through the world as well as to change the state of the objects, is known as task and motion planning (TAMP). TAMP problems contain elements of discrete task planning, discrete–continuous mathematical programming, and continuous motion planning and thus cannot be effectively addressed by any of these fields directly. In this article, we define a class of TAMP problems and survey algorithms for solving them, characterizing the solution methods in terms of their strategies for solving the continuous-space subproblems and their techniques for integrating the discrete and continuous components of the search.",
        "year": 2021,
        "authors": "Caelan Reed Garrett and Rohan Chitnis and Rachel Holladay and Beomjoon Kim and Tom Silver and Leslie Pack Kaelbling and Tomás Lozano-Pérez"
      },
      {
        "title": "Learning symbolic operators for task and motion planning",
        "abstract": "Robotic planning problems in hybrid state and action spaces can be solved by integrated task and motion planners (TAMP) that handle the complex interaction between motion-level decisions and task-level plan feasibility. TAMP approaches rely on domain-specific symbolic operators to guide the task-level search, making planning efficient. In this work, we formalize and study the problem of operator learning for TAMP. Central to this study is the view that operators define a lossy abstraction of the transition model of a domain. We then propose a bottom-up relational learning method for operator learning and show how the learned operators can be used for planning in a TAMP system. Experimentally, we provide results in three domains, including long-horizon robotic planning tasks. We find our approach to substantially outperform several baselines, including three graph neural network-based model-free …",
        "year": 2021,
        "authors": "Tom Silver and Rohan Chitnis and Joshua Tenenbaum and Leslie Pack Kaelbling and Tomás Lozano-Pérez"
      }
    ],
    "WXbhp_4AAAAJ": [
      {
        "title": "Automatic dimensionality selection from the scree plot via the use of profile likelihood",
        "abstract": "Most dimension reduction techniques produce ordered coordinates so that only the first few coordinates need be considered in subsequent analyses. The choice of how many coordinates to use is often made with a visual heuristic, i.e., by making a scree plot and looking for a “big gap” or an “elbow.” In this article, we present a simple and automatic procedure to accomplish this goal by maximizing a simple profile likelihood function. We give a wide variety of both simulated and real examples.",
        "year": 2006,
        "authors": "Mu Zhu and Ali Ghodsi"
      },
      {
        "title": "Supervised principal component analysis: Visualization, classification and regression on subspaces and submanifolds",
        "abstract": "We propose “supervised principal component analysis (supervised PCA)”, a generalization of PCA that is uniquely effective for regression and classification problems with high-dimensional input data. It works by estimating a sequence of principal components that have maximal dependence on the response variable. The proposed supervised PCA is solvable in closed-form, and has a dual formulation that significantly reduces the computational complexity of problems in which the number of predictors greatly exceeds the number of observations (such as DNA microarray experiments). Furthermore, we show how the algorithm can be kernelized, which makes it applicable to non-linear dimensionality reduction tasks. Experimental results on various visualization, classification and regression problems show significant improvement over other supervised approaches both in accuracy and computational efficiency.",
        "year": 2011,
        "authors": "Elnaz Barshan and Ali Ghodsi and Zohreh Azimifar and Mansoor Zolghadri Jahromi"
      },
      {
        "title": "Sentiment analysis based on improved pre-trained word embeddings",
        "abstract": "Sentiment analysis is a fast growing area of research in natural language processing (NLP) and text classifications. This technique has become an essential part of a wide range of applications including politics, business, advertising and marketing. There are various techniques for sentiment analysis, but recently word embeddings methods have been widely used in sentiment classification tasks. Word2Vec and GloVe are currently among the most accurate and usable word embedding methods which can convert words into meaningful vectors. However, these methods ignore sentiment information of texts and need a large corpus of texts for training and generating exact vectors. As a result, because of the small size of some corpora, researcher often have to use pre-trained word embeddings which were trained on other large text corpora such as Google News with about 100 billion words. The increasing accuracy …",
        "year": 2019,
        "authors": "Seyed Mahdi Rezaeinia and Rouhollah Rahmani and Ali Ghodsi and Hadi Veisi"
      }
    ],
    "y2pH4jcAAAAJ": [
      {
        "title": "Settling the complexity of computing two-player Nash equilibria",
        "abstract": "We prove that Bimatrix, the problem of finding a Nash equilibrium in a two-player game, is complete for the complexity class PPAD (Polynomial Parity Argument, Directed version) introduced by Papadimitriou in 1991.Our result, building upon the work of Daskalakis et al. [2006a] on the complexity of four-player Nash equilibria, settles a long standing open problem in algorithmic game theory. It also serves as a starting point for a series of results concerning the complexity of two-player Nash equilibria. In particular, we prove the following theorems:—Bimatrix does not have a fully polynomial-time approximation scheme unless every problem in PPAD is solvable in polynomial time.—The smoothed complexity of the classic Lemke-Howson algorithm and, in fact, of any algorithm for Bimatrix is not polynomial unless every problem in PPAD is solvable in randomized polynomial time.Our results also have a complexity …",
        "year": 2009,
        "authors": "Xi Chen and Xiaotie Deng and Shang-Hua Teng"
      },
      {
        "title": "Settling the complexity of two-player Nash equilibrium",
        "abstract": "We prove that the problem of finding a Nash equilibrium in a two-player game is PPAD-complete.",
        "year": 2006,
        "authors": "Xi Chen and Xiaotie Deng"
      },
      {
        "title": "How to compress interactive communication",
        "abstract": "We describe new ways to simulate 2-party communication protocols to get protocols with potentially smaller communication. We show that every communication protocol that communicates C bits and reveals I bits of information about the inputs to the participating parties can be simulated by a new protocol involving at most ~O(√CI) bits of communication. If the protocol reveals I bits of information about the inputs to an observer that watches the communication in the protocol, we show how to carry out the simulation with ~O(I) bits of communication.These results lead to a direct sum theorem for randomized communication complexity. Ignoring polylogarithmic factors, we show that for worst case computation, computing n copies of a function requires √n times the communication required for computing one copy of the function. For average case complexity, given any distribution μ on inputs, computing n copies of the …",
        "year": 2013,
        "authors": "Boaz Barak and Mark Braverman and Xi Chen and Anup Rao"
      }
    ],
    "-CeUxegAAAAJ": [
      {
        "title": "Exact sampling with coupled Markov chains and applications to statistical mechanics",
        "abstract": "For many applications it is useful to sample from a finite set of objects in accordance with some particular distribution. One approach is to run an ergodic (ie, irreducible aperiodic) Markov chain whose stationary distribution is the desired distribution on this set; after the Markov chain has run for M steps, with M sufficiently large, the distribution governing the state of the chain approximates the desired distribution. Unfortunately, it can be difficult to determine how large M needs to be. We describe a simple variant of this method that determines on its own when to stop and that outputs samples in exact accordance with the desired distribution. The method uses couplings which have also played a role in other sampling schemes; however, rather than running the coupled chains from the present into the future, one runs from a distant point in the past up until the present, where the distance into the past that one needs to go …",
        "year": 1996,
        "authors": "James Gary Propp and David Bruce Wilson"
      },
      {
        "title": "Generating random spanning trees more quickly than the cover time",
        "abstract": "It is widely known how to generate random spanning trees of an undirected graph. Broder showed how at FOCS[6], and Aldous too found the algorithm [2]. Start at any vertex and do a simple random walk on the graph. Each time a vertex is first encountered, mark the edge from which it was discovered. When all the vertices are discovered, the marked edges form a random spanning tree. This algorithm is easy to code up, has small running time constants, and has a nice proof that it generates trees with the right probabilities. This paper gives a new algorithm for generating random spanning trees. It too is simple, easy to code up, and has nice proofs. The new algorithm also has the following advantages: q q q",
        "year": 1996,
        "authors": "David Bruce Wilson"
      },
      {
        "title": "Tug-of-war and the infinity Laplacian",
        "abstract": "We prove that every bounded Lipschitz function  on a subset  of a length space  admits a tautest extension to , ie, a unique Lipschitz extension  for which  for all open . This was previously known only for bounded domains in , in which case  is infinity harmonic; that is, a viscosity solution to , where We also prove the first general uniqueness results for  on bounded subsets of (when  is uniformly continuous and bounded away from ) and analogous results for bounded length spaces. The proofs rely on a new game-theoretic description of . Let  be the value of the following two-player zero-sum game, called tug-of-war: fix . At the  turn, the players toss a coin and the winner chooses an  with . The game ends when , and player I’s payoff is . We show that . Even for bounded …",
        "year": 2009,
        "authors": "Yuval Peres and Oded Schramm and Scott Sheffield and David Wilson"
      }
    ],
    "wxnzyjwAAAAJ": [
      {
        "title": "Palm-e: An embodied multimodal language model",
        "abstract": "Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.",
        "year": 2023,
        "authors": "Danny Driess and Fei Xia and Mehdi SM Sajjadi and Corey Lynch and Aakanksha Chowdhery and Ayzaan Wahid and Jonathan Tompson and Quan Vuong and Tianhe Yu and Wenlong Huang and Yevgen Chebotar and Pierre Sermanet and Daniel Duckworth and Sergey Levine and Vincent Vanhoucke and Karol Hausman and Marc Toussaint and Klaus Greff and Andy Zeng and Igor Mordatch and Pete Florence"
      },
      {
        "title": "Rt-2: Vision-language-action models transfer web knowledge to robotic control",
        "abstract": "We study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robotic trajectory data and Internet-scale vision-language tasks, such as visual question answering. In contrast to other approaches, we propose a simple, general recipe to achieve this goal: in order to fit both natural language responses and robotic actions into the same format, we express the actions as text tokens and incorporate them directly into the training set of the model in the same way as natural language tokens. We refer to such category of models as vision-language-action models (VLA) and instantiate an example of such a model, which we call RT-2. Our extensive evaluation (6k evaluation trials) shows that our approach leads to performant robotic policies and enables RT-2 to obtain a range of emergent capabilities from Internet-scale training. This includes significantly improved generalization to novel objects, the ability to interpret commands not present in the robot training data (such as placing an object onto a particular number or icon), and the ability to perform rudimentary reasoning in response to user commands (such as picking up the smallest or largest object, or the one closest to another object). We further show that incorporating chain of …",
        "year": 2023,
        "authors": "Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Xi Chen and Krzysztof Choromanski and Tianli Ding and Danny Driess and Avinava Dubey and Chelsea Finn and Pete Florence and Chuyuan Fu and Montse Gonzalez Arenas and Keerthana Gopalakrishnan and Kehang Han and Karol Hausman and Alexander Herzog and Jasmine Hsu and Brian Ichter and Alex Irpan and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Lisa Lee and Tsang-Wei Edward Lee and Sergey Levine and Yao Lu and Henryk Michalewski and Igor Mordatch and Karl Pertsch and Kanishka Rao and Krista Reymann and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Pierre Sermanet and Jaspiar Singh and Anikait Singh and Radu Soricut and Huong Tran and Vincent Vanhoucke and Quan Vuong and Ayzaan Wahid and Stefan Welker and Paul Wohlhart and Jialin Wu and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich"
      },
      {
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models",
        "abstract": "DSpace at KOASAS: Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nKOASAS menu About KOASAS KAIST Library 검색 Advanced Search KOASAS About \nKOASAS Open Access Policy Browse Communities & Collections Researchers at KAIST Titles \nSubject By Date rss_1.0 rss_2.0 atom_1.0 sherpa SEARCH DSpace at KOASAS College of \nEngineering(공과대학)Kim Jaechul Graduate School of AI(김재철AI대학원)AI-Conference \nPapers(학술대회논문) Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nCited 0 time in webofscience Cited 0 time in scopus Hit : 2 Download : 0 Export DC(XML) Excel \nLim, Joseph Jaewhanresearcher Publisher IEEE Issue Date 2024-05-15 Citation IEEE \nInternational Conference on Robotics and Automation URI http://hdl.handle.net/10203/326144 \nAppears in Collection AI-Conference Papers(학술대회논문) Files in This Item There are no files …",
        "year": 2024,
        "authors": "Joseph Jaewhan Lim"
      }
    ],
    "gTWUZlsAAAAJ": [
      {
        "title": "How powerful are graph neural networks?",
        "abstract": "Graph Neural Networks (GNNs) are an effective framework for representation learning of graphs. GNNs follow a neighborhood aggregation scheme, where the representation vector of a node is computed by recursively aggregating and transforming representation vectors of its neighboring nodes. Many GNN variants have been proposed and have achieved state-of-the-art results on both node and graph classification tasks. However, despite GNNs revolutionizing graph representation learning, there is limited understanding of their representational properties and limitations. Here, we present a theoretical framework for analyzing the expressive power of GNNs to capture different graph structures. Our results characterize the discriminative power of popular GNN variants, such as Graph Convolutional Networks and GraphSAGE, and show that they cannot learn to distinguish certain simple graph structures. We then develop a simple architecture that is provably the most expressive among the class of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism test. We empirically validate our theoretical findings on a number of graph classification benchmarks, and demonstrate that our model achieves state-of-the-art performance.",
        "year": 2018,
        "authors": "Keyulu Xu and Weihua Hu and Jure Leskovec and Stefanie Jegelka"
      },
      {
        "title": "Representation learning on graphs with jumping knowledge networks",
        "abstract": "Recent deep learning approaches for representation learning on graphs follow a neighborhood aggregation procedure. We analyze some important properties of these models, and propose a strategy to overcome those. In particular, the range of\" neighboring\" nodes that a node’s representation draws from strongly depends on the graph structure, analogous to the spread of a random walk. To adapt to local neighborhood properties and tasks, we explore an architecture–jumping knowledge (JK) networks–that flexibly leverages, for each node, different neighborhood ranges to enable better structure-aware representation. In a number of experiments on social, bioinformatics and citation networks, we demonstrate that our model achieves state-of-the-art performance. Furthermore, combining the JK framework with models like Graph Convolutional Networks, GraphSAGE and Graph Attention Networks consistently improves those models’ performance.",
        "year": 2018,
        "authors": "Keyulu Xu and Chengtao Li and Yonglong Tian and Tomohiro Sonobe and Ken-ichi Kawarabayashi and Stefanie Jegelka"
      },
      {
        "title": "Deep metric learning via lifted structured feature embedding",
        "abstract": "Learning the distance metric between pairs of examples is of great importance for learning and visual recognition. With the remarkable success from the state of the art convolutional neural networks, recent works have shown promising results on discriminatively training the networks to learn semantic feature embeddings where similar examples are mapped close to each other and dissimilar examples are mapped farther apart. In this paper, we describe an algorithm for taking full advantage of the training batches in the neural network training by lifting the vector of pairwise distances within the batch to the matrix of pairwise distances. This step enables the algorithm to learn the state of the art feature embedding by optimizing a novel structured prediction objective for active hard negative mining on the lifted problem. Additionally, we collected Online Products dataset: 120k images of 23k classes of online products for metric learning. Our experiments on the CUB-200-2011, CARS196, and Online Products datasets demonstrate significant improvement over existing deep feature embedding methods on all experimented embedding sizes with the GoogLeNet network. The source code and the dataset are available at: https://github. com/rksltnl/Deep-Metric-Learning-CVPR16",
        "year": 2016,
        "authors": "Hyun Oh Song and Yu Xiang and Stefanie Jegelka and Silvio Savarese"
      }
    ],
    "O43_7KUAAAAJ": [
      {
        "title": "Modern baselines for SPARQL semantic parsing",
        "abstract": "In this work, we focus on the task of generating SPARQL queries from natural language questions, which can then be executed on Knowledge Graphs (KGs). We assume that gold entity and relations have been provided, and the remaining task is to arrange them in the right order along with SPARQL vocabulary, and input tokens to produce the correct SPARQL query. Pre-trained Language Models (PLMs) have not been explored in depth on this task so far, so we experiment with BART, T5 and PGNs (Pointer Generator Networks) with BERT embeddings, looking for new baselines in the PLM era for this task, on DBpedia and Wikidata KGs. We show that T5 requires special input tokenisation, but produces state of the art performance on LC-QuAD 1.0 and LC-QuAD 2.0 datasets, and outperforms task-specific models from previous works. Moreover, the methods enable semantic parsing for questions where a part of the …",
        "year": 2022,
        "authors": "Debayan Banerjee and Pranav Ajit Nair* and Jivat Neet Kaur* and Ricardo Usbeck and Chris Biemann"
      },
      {
        "title": "Modeling the data-generating process is necessary for out-of-distribution generalization",
        "abstract": "Recent empirical studies on domain generalization (DG) have shown that DG algorithms that perform well on some distribution shifts fail on others, and no state-of-the-art DG algorithm performs consistently well on all shifts. Moreover, real-world data often has multiple distribution shifts over different attributes; hence we introduce multi-attribute distribution shift datasets and find that the accuracy of existing DG algorithms falls even further. To explain these results, we provide a formal characterization of generalization under multi-attribute shifts using a canonical causal graph. Based on the relationship between spurious attributes and the classification label, we obtain realizations of the canonical causal graph that characterize common distribution shifts and show that each shift entails different independence constraints over observed variables. As a result, we prove that any algorithm based on a single, fixed constraint cannot work well across all shifts, providing theoretical evidence for mixed empirical results on DG algorithms. Based on this insight, we develop Causally Adaptive Constraint Minimization (CACM), an algorithm that uses knowledge about the data-generating process to adaptively identify and apply the correct independence constraints for regularization. Results on fully synthetic, MNIST, small NORB, and Waterbirds datasets, covering binary and multi-valued attributes and labels, show that adaptive dataset-dependent constraints lead to the highest accuracy on unseen domains whereas incorrect constraints fail to do so. Our results demonstrate the importance of modeling the causal relationships inherent in the data-generating process.",
        "year": 2023,
        "authors": "Jivat Neet Kaur and Emre Kiciman and Amit Sharma"
      },
      {
        "title": "LM-CORE: Language models with contextually relevant external knowledge",
        "abstract": "Large transformer-based pre-trained language models have achieved impressive performance on a variety of knowledge-intensive tasks and can capture factual knowledge in their parameters. We argue that storing large amounts of knowledge in the model parameters is sub-optimal given the ever-growing amounts of knowledge and resource requirements. We posit that a more efficient alternative is to provide explicit access to contextually relevant structured knowledge to the model and train it to use that knowledge. We present LM-CORE -- a general framework to achieve this -- that allows \\textit{decoupling} of the language model training from the external knowledge source and allows the latter to be updated without affecting the already trained model. Experimental results show that LM-CORE, having access to external knowledge, achieves significant and robust outperformance over state-of-the-art knowledge-enhanced language models on knowledge probing tasks; can effectively handle knowledge updates; and performs well on two downstream tasks. We also present a thorough error analysis highlighting the successes and failures of LM-CORE.",
        "year": 2022,
        "authors": "Jivat Neet Kaur and Sumit Bhatia and Milan Aggarwal and Rachit Bansal and Balaji Krishnamurthy"
      }
    ],
    "NkzyCvUAAAAJ": [
      {
        "title": "Highly accurate protein structure prediction with AlphaFold",
        "abstract": "Proteins are essential to life, and understanding their structure can facilitate a mechanistic understanding of their function. Through an enormous experimental effort 1, 2, 3, 4, the structures of around 100,000 unique proteins have been determined 5, but this represents a small fraction of the billions of known protein sequences 6, 7. Structural coverage is bottlenecked by the months to years of painstaking effort required to determine a single protein structure. Accurate computational approaches are needed to address this gap and to enable large-scale structural bioinformatics. Predicting the three-dimensional structure that a protein will adopt based solely on its amino acid sequence—the structure prediction component of the ‘protein folding problem’8—has been an important open research problem for more than 50 years 9. Despite recent progress 10, 11, 12, 13, 14, existing methods fall far short of atomic accuracy …",
        "year": 2021,
        "authors": "John Jumper and Richard Evans and Alexander Pritzel and Tim Green and Michael Figurnov and Olaf Ronneberger and Kathryn Tunyasuvunakool and Russ Bates and Augustin Žídek and Anna Potapenko and Alex Bridgland and Clemens Meyer and Simon AA Kohl and Andrew J Ballard and Andrew Cowie and Bernardino Romera-Paredes and Stanislav Nikolov and Rishub Jain and Jonas Adler and Trevor Back and Stig Petersen and David Reiman and Ellen Clancy and Michal Zielinski and Martin Steinegger and Michalina Pacholska and Tamas Berghammer and Sebastian Bodenstein and David Silver and Oriol Vinyals and Andrew W Senior and Koray Kavukcuoglu and Pushmeet Kohli and Demis Hassabis"
      },
      {
        "title": "Sequence to sequence learning with neural networks",
        "abstract": "Deep Neural Networks (DNNs) are powerful models that have achieved excellent performance on difficult learning tasks. Although DNNs work well whenever large labeled training sets are available, they cannot be used to map sequences to sequences. In this paper, we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure. Our method uses a multilayered Long Short-Term Memory (LSTM) to map the input sequence to a vector of a fixed dimensionality, and then another deep LSTM to decode the target sequence from the vector. Our main result is that on an English to French translation task from the WMT-14 dataset, the translations produced by the LSTM achieve a BLEU score of 34.8 on the entire test set, where the LSTM's BLEU score was penalized on out-of-vocabulary words. Additionally, the LSTM did not have difficulty on long sentences. For comparison, a phrase-based SMT system achieves a BLEU score of 33.3 on the same dataset. When we used the LSTM to rerank the 1000 hypotheses produced by the aforementioned SMT system, its BLEU score increases to 36.5, which is close to the previous state of the art. The LSTM also learned sensible phrase and sentence representations that are sensitive to word order and are relatively invariant to the active and the passive voice. Finally, we found that reversing the order of the words in all source sentences (but not target sentences) improved the LSTM's performance markedly, because doing so introduced many short term dependencies between the source and the target sentence which made the optimization problem …",
        "year": 2014,
        "authors": "Ilya Sutskever and Oriol Vinyals and Quoc V Le"
      }
    ],
    "lyadgWkAAAAJ": [
      {
        "title": "Joint channel estimation and coding over channels with memory using polar codes",
        "abstract": "A joint channel estimation and channel coding scheme is presented for channels with memory using polar codes. Unlike the conventional approach of first estimating all channel parameters and then performing channel decoding separately, the proposed scheme incorporates a subset of reliable estimates of channel parameters into the decoding procedure and computes decoding metrics averaged over the statistical behavior of the channel. Specifically, decoding algorithms for finite-state Markov channels of any order, for the Gauss-Markov channel and for flat-fading channels are presented. Further, by adapting list decoding to identify reliably-decoded bits within a codeword, channel estimation and decoding steps are performed iteratively to boost the reliability of channel estimation as well as error correction. In order to improve the performance even further, a new pilot arrangement scheme is developed that …",
        "year": 2021,
        "authors": "Nadim Ghaddar and Young-Han Kim and Laurence B Milstein and Liangping Ma and Byung K Yi"
      },
      {
        "title": "Noisy sorting capacity",
        "abstract": "Sorting is the task of ordering n elements using pairwise comparisons. It is well known that   comparisons are both necessary and sufficient when the outcomes of the comparisons are observed with no noise. In this paper, we study the sorting problem when each comparison is incorrect with some fixed yet unknown probability p. Unlike the common approach in the literature which aims to minimize the number of pairwise comparisons m to achieve a given desired error probability, we consider randomized algorithms with expected number of queries   and aim at characterizing the maximal sorting rate   such that the ordering of the elements can be estimated with a vanishing error probability asymptotically. The maximal rate is referred to as the noisy sorting capacity. In this work, we derive upper and lower bounds on the noisy sorting capacity. The two lower bounds — one for fixed-length …",
        "year": 2024,
        "authors": "Ziao Wang and Nadim Ghaddar and Banghua Zhu and Lele Wang"
      },
      {
        "title": "A Lego-brick approach to coding for asymmetric channels and channels with state",
        "abstract": "Coding schemes for asymmetric channels and channels with state are developed starting from a pair of linear codes designed for symmetric channels. Guarantees on the block error rate performance of the coding schemes are derived in terms of the parameters of the constituent codes. Assuming the constituent codes satisfy some properties on the rate, the error probability, and the distribution of the Hamming distance to decoded sequences, the performance guarantees hold irrespective of other properties of the codes. This would allow one to leverage commercial off-the-shelf codes for point-to-point symmetric channels to design codes for asymmetric channels and channels with state known noncausally at the encoder.",
        "year": 2021,
        "authors": "Nadim Ghaddar and Shouvik Ganguly and Lele Wang and Young-Han Kim"
      }
    ],
    "B8wslVsAAAAJ": [
      {
        "title": "Gpt-4 technical report",
        "abstract": "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.",
        "year": 2023,
        "authors": "Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew"
      },
      {
        "title": "Categorical reparameterization with gumbel-softmax",
        "abstract": "Categorical variables are a natural choice for representing discrete structure in the world. However, stochastic neural networks rarely use categorical latent variables due to the inability to backpropagate through samples. In this work, we present an efficient gradient estimator that replaces the non-differentiable sample from a categorical distribution with a differentiable sample from a novel Gumbel-Softmax distribution. This distribution has the essential property that it can be smoothly annealed into a categorical distribution. We show that our Gumbel-Softmax estimator outperforms state-of-the-art gradient estimators on structured output prediction and unsupervised generative modeling tasks with categorical latent variables, and enables large speedups on semi-supervised classification.",
        "year": 2016,
        "authors": "Eric Jang and Shixiang Gu and Ben Poole"
      },
      {
        "title": "Large language models are zero-shot reasoners",
        "abstract": "Pretrained large language models (LLMs) are widely used in many sub-fields of natural language processing (NLP) and generally known as excellent few-shot learners with task-specific exemplars. Notably, chain of thought (CoT) prompting, a recent technique for eliciting complex multi-step reasoning through step-by-step answer examples, achieved the state-of-the-art performances in arithmetics and symbolic reasoning, difficult system-2 tasks that do not follow the standard scaling laws for LLMs. While these successes are often attributed to LLMs' ability for few-shot learning, we show that LLMs are decent zero-shot reasoners by simply adding``Let's think step by step''before each answer. Experimental results demonstrate that our Zero-shot-CoT, using the same single prompt template, significantly outperforms zero-shot LLM performances on diverse benchmark reasoning tasks including arithmetics (MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin Flip), and other logical reasoning tasks (Date Understanding, Tracking Shuffled Objects), without any hand-crafted few-shot examples, eg increasing the accuracy on MultiArith from 17.7% to 78.7% and GSM8K from 10.4% to 40.7% with large-scale InstructGPT model (text-davinci-002), as well as similar magnitudes of improvements with another off-the-shelf large model, 540B parameter PaLM. The versatility of this single prompt across very diverse reasoning tasks hints at untapped and understudied fundamental zero-shot capabilities of LLMs, suggesting high-level, multi-task broad cognitive capabilities may be extracted by simple prompting. We hope our work not only …",
        "year": 2022,
        "authors": "Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa"
      }
    ],
    "b4PmtFkAAAAJ": [
      {
        "title": "Accelerated Information Gradient flow",
        "abstract": "We present a framework for Nesterov’s accelerated gradient flows in probability space to design efficient mean-field Markov chain Monte Carlo algorithms for Bayesian inverse problems. Here four examples of information metrics are considered, including Fisher-Rao metric, Wasserstein-2 metric, Kalman-Wasserstein metric and Stein metric. For both Fisher-Rao and Wasserstein-2 metrics, we prove convergence properties of accelerated gradient flows. In implementations, we propose a sampling-efficient discrete-time algorithm for Wasserstein-2, Kalman-Wasserstein and Stein accelerated gradient flows with a restart technique. We also formulate a kernel bandwidth selection method, which learns the gradient of logarithm of density from Brownian-motion samples. Numerical experiments, including Bayesian logistic regression and Bayesian neural network, show the strength of the proposed methods …",
        "year": 2019,
        "authors": "Yifei Wang and Wuchen Li"
      },
      {
        "title": "Information Newton's flow: second-order optimization method in probability space",
        "abstract": "We introduce a framework for Newton's flows in probability space with information metrics, named information Newton's flows. Here two information metrics are considered, including both the Fisher-Rao metric and the Wasserstein-2 metric. A known fact is that overdamped Langevin dynamics correspond to Wasserstein gradient flows of Kullback-Leibler (KL) divergence. Extending this fact to Wasserstein Newton's flows, we derive Newton's Langevin dynamics. We provide examples of Newton's Langevin dynamics in both one-dimensional space and Gaussian families. For the numerical implementation, we design sampling efficient variational methods in affine models and reproducing kernel Hilbert space (RKHS) to approximate Wasserstein Newton's directions. We also establish convergence results of the proposed information Newton's method with approximated directions. Several numerical examples from Bayesian sampling problems are shown to demonstrate the effectiveness of the proposed method.",
        "year": 2020,
        "authors": "Yifei Wang and Wuchen Li"
      },
      {
        "title": "Projected wasserstein gradient descent for high-dimensional bayesian inference",
        "abstract": "We propose a projected Wasserstein gradient descent method (pWGD) for high-dimensional Bayesian inference problems. The underlying density function of a particle system of Wasserstein gradient descent (WGD) is approximated by kernel density estimation (KDE), which faces the long-standing curse of dimensionality. We overcome this challenge by exploiting the intrinsic low-rank structure in the difference between the posterior and prior distributions. The parameters are projected into a low-dimensional subspace to alleviate the approximation error of KDE in high dimensions. We formulate a projected Wasserstein gradient flow and analyze its convergence property under mild assumptions. Several numerical experiments illustrate the accuracy, convergence, and complexity scalability of pWGD with respect to parameter dimension, sample size, and processor cores.",
        "year": 2022,
        "authors": "Yifei Wang and Peng Chen and Wuchen Li"
      }
    ],
    "0ei9XEUAAAAJ": [
      {
        "title": "Communication algorithms via deep learning",
        "abstract": "Coding theory is a central discipline underpinning wireline and wireless modems that are the workhorses of the information age. Progress in coding theory is largely driven by individual human ingenuity with sporadic breakthroughs over the past century. In this paper we study whether it is possible to automate the discovery of decoding algorithms via deep learning. We study a family of sequential codes parameterized by recurrent neural network (RNN) architectures. We show that creatively designed and trained RNN architectures can decode well known sequential codes such as the convolutional and turbo codes with close to optimal performance on the additive white Gaussian noise (AWGN) channel, which itself is achieved by breakthrough algorithms of our times (Viterbi and BCJR decoders, representing dynamic programing and forward-backward algorithms). We show strong generalizations, i.e., we train at a specific signal to noise ratio and block length but test at a wide range of these quantities, as well as robustness and adaptivity to deviations from the AWGN setting.",
        "year": 2018,
        "authors": "Hyeji Kim and Yihan Jiang and Ranvir Rana and Sreeram Kannan and Sewoong Oh and Pramod Viswanath"
      },
      {
        "title": "Free2shard: Adversary-resistant distributed resource allocation for blockchains",
        "abstract": "In this paper, we study a canonical distributed resource allocation problem arising in blockchains. While distributed resource allocation is a well-studied problem in networking, the blockchain setting additionally requires the solution to be resilient to adversarial behavior from a fraction of nodes. Scaling blockchain performance is a basic research topic; a plethora of solutions (under the umbrella of sharding ) have been proposed in recent years. Although the various sharding solutions share a common thread (they cryptographically stitch together multiple parallel chains), architectural differences lead to differing resource allocation problems. In this paper we make three main contributions: (a) we categorize the different sharding proposals under a common architectural framework, allowing for the emergence of a new, uniformly improved, uni-consensus sharding architecture. (b) We formulate and exactly solve a core …",
        "year": 2022,
        "authors": "Ranvir Rana and Sreeram Kannan and David Tse and Pramod Viswanath"
      },
      {
        "title": "Barracuda: the power of ℓ-polling in proof-of-stake blockchains",
        "abstract": "A blockchain is a database of sequential events that is maintained by a distributed group of nodes. A key consensus problem in blockchains is that of determining the next block (data element) in the sequence. Many blockchains address this by electing a new node to propose each new block. The new block is (typically) appended to the tip of the proposer's local blockchain, and subsequently broadcast to the rest of the network. Without network delay (or adversarial behavior), this procedure would give a perfect chain, since each proposer would have the same view of the blockchain. A major challenge in practice is forking. Due to network delays, a proposer may not yet have the most recent block, and may therefore create a side chain that branches from the middle of the main chain. Forking reduces throughput, since only one a single main chain can survive, and all other blocks are discarded. We propose a new …",
        "year": 2019,
        "authors": "Giulia Fanti and Jiantao Jiao and Ashok Makkuva and Sewoong Oh and Ranvir Rana and Pramod Viswanath"
      }
    ],
    "n-B0jr4AAAAJ": [
      {
        "title": "Context-aware crowd counting",
        "abstract": "State-of-the-art methods for counting people in crowded scenes rely on deep networks to estimate crowd density. They typically use the same filters over the whole image or over large image patches. Only then do they estimate local scale to compensate for perspective distortion. This is typically achieved by training an auxiliary classifier to select, for predefined image patches, the best kernel size among a limited set of choices. As such, these methods are not end-to-end trainable and restricted in the scope of context they can leverage. In this paper, we introduce an end-to-end trainable deep architecture that combines features obtained using multiple receptive field sizes and learns the importance of each such feature at each image location. In other words, our approach adaptively encodes the scale of the contextual information required to accurately predict crowd density. This yields an algorithm that outperforms state-of-the-art crowd counting methods, especially when perspective effects are strong.",
        "year": 2019,
        "authors": "Weizhe Liu and Mathieu Salzmann and Pascal Fua"
      },
      {
        "title": "Deep subspace clustering networks",
        "abstract": "We present a novel deep neural network architecture for unsupervised subspace clustering. This architecture is built upon deep auto-encoders, which non-linearly map the input data into a latent space. Our key idea is to introduce a novel self-expressive layer between the encoder and the decoder to mimic the\" self-expressiveness\" property that has proven effective in traditional subspace clustering. Being differentiable, our new self-expressive layer provides a simple but effective way to learn pairwise affinities between all data points through a standard back-propagation procedure. Being nonlinear, our neural-network based method is able to cluster data points having complex (often nonlinear) structures. We further propose pre-training and fine-tuning strategies that let us effectively learn the parameters of our subspace clustering networks. Our experiments show that the proposed method significantly outperforms the state-of-the-art unsupervised subspace clustering methods.",
        "year": 2017,
        "authors": "Pan Ji and Tong Zhang and Hongdong Li and Mathieu Salzmann and Ian Reid"
      },
      {
        "title": "Learning to find good correspondences",
        "abstract": "We develop a deep architecture to learn to find good correspondences for wide-baseline stereo. Given a set of putative sparse matches and the camera intrinsics, we train our network in an end-to-end fashion to label the correspondences as inliers or outliers, while simultaneously using them to recover the relative pose, as encoded by the essential matrix. Our architecture is based on a multi-layer perceptron operating on pixel coordinates rather than directly on the image, and is thus simple and small. We introduce a novel normalization technique, called Context Normalization, which allows us to process each data point separately while embedding global information in it, and also makes the network invariant to the order of the correspondences. Our experiments on multiple challenging datasets demonstrate that our method is able to drastically improve the state of the art with little training data.",
        "year": 2018,
        "authors": "Kwang Moo Yi and Eduard Trulls and Yuki Ono and Vincent Lepetit and Mathieu Salzmann and Pascal Fua"
      }
    ],
    "Qhe5ua0AAAAJ": [
      {
        "title": "Wireless network information flow: A deterministic approach",
        "abstract": "In a wireless network with a single source and a single destination and an arbitrary number of relay nodes, what is the maximum rate of information flow achievable? We make progress on this long standing problem through a two-step approach. First, we propose a deterministic channel model which captures the key wireless properties of signal strength, broadcast and superposition. We obtain an exact characterization of the capacity of a network with nodes connected by such deterministic channels. This result is a natural generalization of the celebrated max-flow min-cut theorem for wired networks. Second, we use the insights obtained from the deterministic analysis to design a new quantize-map-and-forward scheme for Gaussian networks. In this scheme, each relay quantizes the received signal at the noise level and maps it to a random Gaussian codeword for forwarding, and the final destination decodes the …",
        "year": 2011,
        "authors": "A Salman Avestimehr and Suhas N Diggavi and David NC Tse"
      },
      {
        "title": "Fedml: A research library and benchmark for federated machine learning",
        "abstract": "Federated learning (FL) is a rapidly growing research field in machine learning. However, existing FL libraries cannot adequately support diverse algorithmic development; inconsistent dataset and model usage make fair algorithm comparison challenging. In this work, we introduce FedML, an open research library and benchmark to facilitate FL algorithm development and fair performance comparison. FedML supports three computing paradigms: on-device training for edge devices, distributed computing, and single-machine simulation. FedML also promotes diverse algorithmic research with flexible and generic API design and comprehensive reference baseline implementations (optimizer, models, and datasets). We hope FedML could provide an efficient and reproducible means for developing and evaluating FL algorithms that would benefit the FL research community. We maintain the source code, documents, and user community at https://fedml.ai.",
        "year": 2020,
        "authors": "Chaoyang He and Songze Li and Jinhyun So and Xiao Zeng and Mi Zhang and Hongyi Wang and Xiaoyang Wang and Praneeth Vepakomma and Abhishek Singh and Hang Qiu and Xinghua Zhu and Jianzong Wang and Li Shen and Peilin Zhao and Yan Kang and Yang Liu and Ramesh Raskar and Qiang Yang and Murali Annavaram and Salman Avestimehr"
      },
      {
        "title": "Group knowledge transfer: Federated learning of large cnns at the edge",
        "abstract": "Scaling up the convolutional neural network (CNN) size (eg, width, depth, etc.) is known to effectively improve model accuracy. However, the large model size impedes training on resource-constrained edge devices. For instance, federated learning (FL) may place undue burden on the compute capability of edge nodes, even though there is a strong practical need for FL due to its privacy and confidentiality properties. To address the resource-constrained reality of edge devices, we reformulate FL as a group knowledge transfer training algorithm, called FedGKT. FedGKT designs a variant of the alternating minimization approach to train small CNNs on edge nodes and periodically transfer their knowledge by knowledge distillation to a large server-side CNN. FedGKT consolidates several advantages into a single framework: reduced demand for edge computation, lower communication bandwidth for large CNNs, and asynchronous training, all while maintaining model accuracy comparable to FedAvg. We train CNNs designed based on ResNet-56 and ResNet-110 using three distinct datasets (CIFAR-10, CIFAR-100, and CINIC-10) and their non-IID variants. Our results show that FedGKT can obtain comparable or even slightly higher accuracy than FedAvg. More importantly, FedGKT makes edge training affordable. Compared to the edge training using FedAvg, FedGKT demands 9 to 17 times less computational power (FLOPs) on edge devices and requires 54 to 105 times fewer parameters in the edge CNN. Our source code is released at FedML (https://fedml. ai).",
        "year": 2020,
        "authors": "Chaoyang He and Murali Annavaram and Salman Avestimehr"
      }
    ],
    "V42yp08AAAAJ": [
      {
        "title": "Multixnet: Multiclass multistage multimodal motion prediction",
        "abstract": "One of the critical pieces of the self-driving puzzle is understanding the surroundings of a self-driving vehicle (SDV) and predicting how these surroundings will change in the near future. To address this task we propose MultiXNet, an end-to-end approach for detection and motion prediction based directly on lidar sensor data. This approach builds on prior work by handling multiple classes of traffic actors, adding a jointly trained second-stage trajectory refinement step, and producing a multimodal probability distribution over future actor motion that includes both multiple discrete traffic behaviors and calibrated continuous position uncertainties. The method was evaluated on large-scale, real-world data collected by a fleet of SDV s in several cities, with the results indicating that it outperforms existing state-of-the-art approaches.",
        "year": 2021,
        "authors": "Nemanja Djuric and Henggang Cui and Zhaoen Su and Shangxuan Wu and Huahua Wang and Fang-Chieh Chou and Luisa San Martin and Song Feng and Rui Hu and Yang Xu and Alyssa Dayan and Sidney Zhang and Brian C Becker and Gregory P Meyer and Carlos Vallespi-Gonzalez and Carl K Wellington"
      },
      {
        "title": "A neural circuit for flexible control of persistent behavioral states",
        "abstract": "To adapt to their environments, animals must generate behaviors that are closely aligned to a rapidly changing sensory world. However, behavioral states such as foraging or courtship typically persist over long time scales to ensure proper execution. It remains unclear how neural circuits generate persistent behavioral states while maintaining the flexibility to select among alternative states when the sensory context changes. Here, we elucidate the functional architecture of a neural circuit controlling the choice between roaming and dwelling states, which underlie exploration and exploitation during foraging in C. elegans. By imaging ensemble-level neural activity in freely moving animals, we identify stereotyped changes in circuit activity corresponding to each behavioral state. Combining circuit-wide imaging with genetic analysis, we find that mutual inhibition between two antagonistic neuromodulatory systems underlies the persistence and mutual exclusivity of the neural activity patterns observed in each state. Through machine learning analysis and circuit perturbations, we identify a sensory processing neuron that can transmit information about food odors to both the roaming and dwelling circuits and bias the animal towards different states in different sensory contexts, giving rise to context-appropriate state transitions. Our findings reveal a potentially general circuit architecture that enables flexible, sensory-driven control of persistent behavioral states.",
        "year": 2021,
        "authors": "Ni Ji and Gurrein K Madan and Guadalupe I Fabre and Alyssa Dayan and Casey M Baker and Talya S Kramer and Ijeoma Nwabudike and Steven W Flavell"
      },
      {
        "title": "Intrinsically-Motivated Humans and Agents in Open-World Exploration",
        "abstract": "What drives exploration? Understanding intrinsic motivation is a long-standing challenge in both cognitive science and artificial intelligence; numerous objectives have been proposed and used to train agents, yet there remains a gap between human and agent exploration. We directly compare adults, children, and AI agents in a complex open-ended environment, Crafter, and study how common intrinsic objectives: Entropy, Information Gain, and Empowerment, relate to their behavior. We find that only Entropy and Empowerment are consistently positively correlated with human exploration progress, indicating that these objectives may better inform intrinsic reward design for agents. Furthermore, across agents and humans we observe that Entropy initially increases rapidly, then plateaus, while Empowerment increases continuously, suggesting that state diversity may provide more signal in early exploration, while advanced exploration should prioritize control. Finally, we find preliminary evidence that private speech utterances, and particularly goal verbalizations, may aid exploration in children.",
        "year": 2025,
        "authors": "Aly Lidayan and Yuqing Du and Eliza Kosoy and Maria Rufova and Pieter Abbeel and Alison Gopnik"
      }
    ],
    "Jp6Mz1sAAAAJ": [
      {
        "title": "Geodesic flow kernel for unsupervised domain adaptation",
        "abstract": "In real-world applications of visual recognition, many factors - such as pose, illumination, or image quality - can cause a significant mismatch between the source domain on which classifiers are trained and the target domain to which those classifiers are applied. As such, the classifiers often perform poorly on the target domain. Domain adaptation techniques aim to correct the mismatch. Existing approaches have concentrated on learning feature representations that are invariant across domains, and they often do not directly exploit low-dimensional structures that are intrinsic to many vision datasets. In this paper, we propose a new kernel-based method that takes advantage of such structures. Our geodesic flow kernel models domain shift by integrating an infinite number of subspaces that characterize changes in geometric and statistical properties from the source to the target domain. Our approach is …",
        "year": 2012,
        "authors": "Boqing Gong and Yuan Shi and Fei Sha and Kristen Grauman"
      },
      {
        "title": "The pyramid match kernel: Discriminative classification with sets of image features",
        "abstract": "Discriminative learning is challenging when examples are sets of features, and the sets vary in cardinality and lack any sort of meaningful ordering. Kernel-based classification methods can learn complex decision boundaries, but a kernel over unordered set inputs must somehow solve for correspondences epsivnerally a computationally expensive task that becomes impractical for large set sizes. We present a new fast kernel function which maps unordered feature sets to multi-resolution histograms and computes a weighted histogram intersection in this space. This \"pyramid match\" computation is linear in the number of features, and it implicitly finds correspondences based on the finest resolution histogram cell where a matched pair first appears. Since the kernel does not penalize the presence of extra features, it is robust to clutter. We show the kernel function is positive-definite, making it valid for use in learning …",
        "year": 2005,
        "authors": "Kristen Grauman and Trevor Darrell"
      },
      {
        "title": "Ego4d: Around the world in 3,000 hours of egocentric video",
        "abstract": "We introduce Ego4D, a massive-scale egocentric video dataset and benchmark suite. It offers 3,670 hours of daily-life activity video spanning hundreds of scenarios (household, outdoor, workplace, leisure, etc.) captured by 931 unique camera wearers from 74 worldwide locations and 9 different countries. The approach to collection is designed to uphold rigorous privacy and ethics standards, with consenting participants and robust de-identification procedures where relevant. Ego4D dramatically expands the volume of diverse egocentric video footage publicly available to the research community. Portions of the video are accompanied by audio, 3D meshes of the environment, eye gaze, stereo, and/or synchronized videos from multiple egocentric cameras at the same event. Furthermore, we present a host of new benchmark challenges centered around understanding the first-person visual experience in the past (querying an episodic memory), present (analyzing hand-object manipulation, audio-visual conversation, and social interactions), and future (forecasting activities). By publicly sharing this massive annotated dataset and benchmark suite, we aim to push the frontier of first-person perception. Project page: https://ego4d-data. org/",
        "year": 2022,
        "authors": "Kristen Grauman and Andrew Westbury and Eugene Byrne and Zachary Chavis and Antonino Furnari and Rohit Girdhar and Jackson Hamburger and Hao Jiang and Miao Liu and Xingyu Liu and Miguel Martin and Tushar Nagarajan and Ilija Radosavovic and Santhosh Kumar Ramakrishnan and Fiona Ryan and Jayant Sharma and Michael Wray and Mengmeng Xu and Eric Zhongcong Xu and Chen Zhao and Siddhant Bansal and Dhruv Batra and Vincent Cartillier and Sean Crane and Tien Do and Morrie Doulaty and Akshay Erapalli and Christoph Feichtenhofer and Adriano Fragomeni and Qichen Fu and Abrham Gebreselasie and Cristina González and James Hillis and Xuhua Huang and Yifei Huang and Wenqi Jia and Weslie Khoo and Jáchym Kolář and Satwik Kottur and Anurag Kumar and Federico Landini and Chao Li and Yanghao Li and Zhenqiang Li and Karttikeya Mangalam and Raghava Modhugu and Jonathan Munro and Tullie Murrell and Takumi Nishiyasu and Will Price and Paola Ruiz and Merey Ramazanova and Leda Sari and Kiran Somasundaram and Audrey Southerland and Yusuke Sugano and Ruijie Tao and Minh Vo and Yuchen Wang and Xindi Wu and Takuma Yagi and Ziwei Zhao and Yunyi Zhu and Pablo Arbeláez and David Crandall and Dima Damen and Giovanni Maria Farinella and Christian Fuegen and Bernard Ghanem and Vamsi Krishna Ithapu and CV Jawahar and Hanbyul Joo and Kris Kitani and Haizhou Li and Richard Newcombe and Aude Oliva and Hyun Soo Park and James M Rehg and Yoichi Sato and Jianbo Shi and Mike Zheng Shou and Antonio Torralba and Lorenzo Torresani and Mingfei Yan and Jitendra Malik"
      }
    ],
    "t4dSV4YAAAAJ": [
      {
        "title": "Predicting with confidence on unseen distributions",
        "abstract": "Recent work has shown that the accuracy of machine learning models can vary substantially when evaluated on a distribution that even slightly differs from that of the training data. As a result, predicting model performance on previously unseen distributions without access to labeled data is an important challenge with implications for increasing the reliability of machine learning models. In the context of distribution shift, distance measures are often used to adapt models and improve their performance on new domains, however accuracy estimation is seldom explored in these investigations. Our investigation determines that common distributional distances such as Frechet distance or Maximum Mean Discrepancy, fail to induce reliable estimates of performance under distribution shift. On the other hand, we find that our proposed difference of confidences (DoC) approach yields successful estimates of a classifier's performance over a variety of shifts and model architectures. Despite its simplicity, we observe that DoC outperforms other methods across synthetic, natural, and adversarial distribution shifts, reducing error by (> 46%) on several realistic and challenging datasets such as ImageNet-Vid-Robust and ImageNet-Rendition.",
        "year": 2021,
        "authors": "Devin Guillory and Vaishaal Shankar and Sayna Ebrahimi and Trevor Darrell and Ludwig Schmidt"
      },
      {
        "title": "Weakly-supervised action localization with expectation-maximization multi-instance learning",
        "abstract": "Weakly-supervised action localization requires training a model to localize the action segments in the video given only video level action label. It can be solved under the Multiple Instance Learning (MIL) framework, where a bag (video) contains multiple instances (action segments). Since only the bag’s label is known, the main challenge is assigning which key instances within the bag to trigger the bag’s label. Most previous models use attention-based approaches applying attentions to generate the bag’s representation from instances, and then train it via the bag’s classification. These models, however, implicitly violate the MIL assumption that instances in negative bags should be uniformly negative. In this work, we explicitly model the key instances assignment as a hidden variable and adopt an Expectation-Maximization (EM) framework. We derive two pseudo-label generation schemes to model the E …",
        "year": 2020,
        "authors": "Zhekun Luo and Devin Guillory and Baifeng Shi and Wei Ke and Fang Wan and Trevor Darrell and Huijuan Xu"
      },
      {
        "title": "Self-supervised pretraining improves self-supervised pretraining",
        "abstract": "While self-supervised pretraining has proven beneficial for many computer vision tasks, it requires expensive and lengthy computation, large amounts of data, and is sensitive to data augmentation. Prior work demonstrates that models pretrained on datasets dissimilar to their target data, such as chest X-ray models trained on ImageNet, underperform models trained from scratch. Users that lack the resources to pretrain must use existing models with lower performance. This paper explores Hierarchical PreTraining (HPT), which decreases convergence time and improves accuracy by initializing the pretraining process with an existing pretrained model. Through experimentation on 16 diverse vision datasets, we show HPT converges up to 80x faster, improves accuracy across tasks, and improves the robustness of the self-supervised pretraining process to changes in the image augmentation policy or amount of pretraining data. Taken together, HPT provides a simple framework for obtaining better pretrained representations with less computational resources.",
        "year": 2022,
        "authors": "Colorado J Reed and Xiangyu Yue and Ani Nrusimha and Sayna Ebrahimi and Vivek Vijaykumar and Richard Mao and Bo Li and Shanghang Zhang and Devin Guillory and Sean Metzger and Kurt Keutzer and Trevor Darrell"
      }
    ],
    "Q8kbUQEAAAAJ": [
      {
        "title": "Serverless computing: One step forward, two steps back",
        "abstract": "Serverless computing offers the potential to program the cloud in an autoscaling, pay-as-you go manner. In this paper we address critical gaps in first-generation serverless computing, which place its autoscaling potential at odds with dominant trends in modern computing: notably data-centric and distributed computing, but also open source and custom hardware. Put together, these gaps make current serverless offerings a bad fit for cloud innovation and particularly bad for data systems innovation. In addition to pinpointing some of the main shortfalls of current serverless architectures, we raise a set of challenges we believe must be met to unlock the radical potential that the cloud---with its exabytes of storage and millions of cores---should offer to innovative developers.",
        "year": 2019,
        "authors": "Joseph M Hellerstein and Jose Faleiro and Joseph E Gonzalez and Johann Schleier-Smith and Vikram Sreekanti and Alexey Tumanov and Chenggang Wu"
      },
      {
        "title": "Cloudburst: Stateful functions-as-a-service",
        "abstract": "Function-as-a-Service (FaaS) platforms and \"serverless\" cloud computing are becoming increasingly popular. Current FaaS offerings are targeted at stateless functions that do minimal I/O and communication. We argue that the benefits of serverless computing can be extended to a broader range of applications and algorithms. We present the design and implementation of Cloudburst, a stateful FaaS platform that provides familiar Python programming with low-latency mutable state and communication, while maintaining the autoscaling benefits of serverless computing. Cloudburst accomplishes this by leveraging Anna, an autoscaling key-value store, for state sharing and overlay routing combined with mutable caches co-located with function executors for data locality. Performant cache consistency emerges as a key challenge in this architecture. To this end, Cloudburst provides a combination of lattice-encapsulated state and new definitions and protocols for distributed session consistency. Empirical results on benchmarks and diverse applications show that Cloudburst makes stateful functions practical, reducing the state-management overheads of current FaaS platforms by orders of magnitude while also improving the state of the art in serverless consistency.",
        "year": 2020,
        "authors": "Vikram Sreekanti and Chenggang Wu and Xiayue C Lin and Jose M Faleiro and Joseph E Gonzalez and Joseph M Hellerstein and Alexey Tumanov"
      },
      {
        "title": "Deep unsupervised cardinality estimation",
        "abstract": "Cardinality estimation has long been grounded in statistical tools for density estimation. To capture the rich multivariate distributions of relational tables, we propose the use of a new type of high-capacity statistical model: deep autoregressive models. However, direct application of these models leads to a limited estimator that is prohibitively expensive to evaluate for range or wildcard predicates. To produce a truly usable estimator, we develop a Monte Carlo integration scheme on top of autoregressive models that can efficiently handle range queries with dozens of dimensions or more. Like classical synopses, our estimator summarizes the data without supervision. Unlike previous solutions, we approximate the joint data distribution without any independence assumptions. Evaluated on real-world datasets and compared against real systems and dominant families of techniques, our estimator achieves single-digit multiplicative error at tail, an up to 90 accuracy improvement over the second best method, and is space- and runtime-efficient.",
        "year": 2019,
        "authors": "Zongheng Yang and Eric Liang and Amog Kamsetty and Chenggang Wu and Yan Duan and Xi Chen and Pieter Abbeel and Joseph M Hellerstein and Sanjay Krishnan and Ion Stoica"
      }
    ],
    "zX3ba1kAAAAJ": [
      {
        "title": "Similarity estimation techniques from rounding algorithms",
        "abstract": "(MATH) A locality sensitive hashing scheme is a distribution on a family $\\F$ of hash functions operating on a collection of objects, such that for two objects x,y, PrhεF[h(x) = h(y)] = sim(x,y), where sim(x,y) ε [0,1] is some similarity function defined on the collection of objects. Such a scheme leads to a compact representation of objects so that similarity of objects can be estimated from their compact sketches, and also leads to efficient algorithms for approximate nearest neighbor search and clustering. Min-wise independent permutations provide an elegant construction of such a locality sensitive hashing scheme for a collection of subsets with the set similarity measure sim(A,B) = \\frac{|A ∩ B|}{|A ∪ B|}.(MATH) We show that rounding algorithms for LPs and SDPs used in the context of approximation algorithms can be viewed as locality sensitive hashing schemes for several interesting collections of objects. Based on …",
        "year": 2002,
        "authors": "Moses S Charikar"
      },
      {
        "title": "Finding frequent items in data streams",
        "abstract": "We present a 1-pass algorithm for estimating the most frequent items in a data stream using very limited storage space. Our method relies on a novel data structure called a count sketch, which allows us to estimate the frequencies of all the items in the stream. Our algorithm achieves better space bounds than the previous best known algorithms for this problem for many natural distributions on the item frequencies. In addition, our algorithm leads directly to a 2-pass algorithm for the problem of estimating the items with the largest (absolute) change in frequency between two data streams. To our knowledge, this problem has not been previously studied in the literature.",
        "year": 2004,
        "authors": "Moses Charikar and Kevin Chen and Martin Farach-Colton"
      },
      {
        "title": "Min-wise independent permutations",
        "abstract": "We define and study the notion of min-wise independent families of permutations. We say that F⊆ Sn is min-wise independent if for any set X⊆[n] and any x∈ X, when π is chosen at random in F we have",
        "year": 1998,
        "authors": "Andrei Z Broder and Moses Charikar and Alan M Frieze and Michael Mitzenmacher"
      }
    ],
    "mVkGg80AAAAJ": [
      {
        "title": "Reward-free exploration for reinforcement learning",
        "abstract": "Exploration is widely regarded as one of the most challenging aspects of reinforcement learning (RL), with many naive approaches succumbing to exponential sample complexity. To isolate the challenges of exploration, we propose the following “reward-free RL” framework. In the exploration phase, the agent first collects trajectories from an MDP  without a pre-specified reward function. After exploration, it is tasked with computing a near-policies under the transitions of  for a collection of given reward functions. This framework is particularly suitable where there are many reward functions of interest, or where the reward function is shaped by an external agent to elicit desired behavior. We give an efficient algorithm that conducts  episodes of exploration, and returns -suboptimal policies for an arbitrary number of reward functions. We achieve this by finding exploratory policies that jointly visit each “significant” state with probability proportional to its maximum visitation probability under any possible policy. Moreover, our planning procedure can be instantiated by any black-box approximate planner, such as value iteration or natural policy gradient. Finally, we give a nearly-matching  lower bound, demonstrating the near-optimality of our algorithm in this setting.",
        "year": 2020,
        "authors": "Chi Jin and Akshay Krishnamurthy and Max Simchowitz and Tiancheng Yu"
      },
      {
        "title": "Learning adversarial markov decision processes with bandit feedback and unknown transition",
        "abstract": "We consider the task of learning in episodic finite-horizon Markov decision processes with an unknown transition function, bandit feedback, and adversarial losses. We propose an efficient algorithm that achieves  regret with high probability, where  is the horizon,  the number of states,  the number of actions, and T the number of episodes. To our knowledge, our algorithm is the first to ensure  regret in this challenging setting; in fact, it achieves the same regret as (Rosenberg & Mansour, 2019a) who consider the easier setting with full-information. Our key contributions are two-fold: a tighter confidence set for the transition function; and an optimistic loss estimator that is inversely weighted by an\" upper occupancy bound\".",
        "year": 2020,
        "authors": "Chi Jin and Tiancheng Jin and Haipeng Luo and Suvrit Sra and Tiancheng Yu"
      },
      {
        "title": "Near-optimal reinforcement learning with self-play",
        "abstract": "This paper considers the problem of designing optimal algorithms for reinforcement learning in two-player zero-sum games. We focus on self-play algorithms which learn the optimal policy by playing against itself without any direct supervision. In a tabular episodic Markov game with S states, A max-player actions and B min-player actions, the best existing algorithm for finding an approximate Nash equilibrium requires\\tlO (S^ 2AB) steps of game playing, when only highlighting the dependency on (S, A, B). In contrast, the best existing lower bound scales as\\Omega (S (A+ B)) and has a significant gap from the upper bound. This paper closes this gap for the first time: we propose an optimistic variant of the Nash Q-learning algorithm with sample complexity\\tlO (SAB), and a new Nash V-learning algorithm with sample complexity\\tlO (S (A+ B)). The latter result matches the information-theoretic lower bound in all problem-dependent parameters except for a polynomial factor of the length of each episode. In addition, we present a computational hardness result for learning the best responses against a fixed opponent in Markov games---a learning objective different from finding the Nash equilibrium.",
        "year": 2020,
        "authors": "Yu Bai and Chi Jin and Tiancheng Yu"
      }
    ],
    "q-buMEoAAAAJ": [
      {
        "title": "Dermatologist-level classification of skin cancer with deep neural networks",
        "abstract": "Skin cancer, the most common human malignancy,,, is primarily diagnosed visually, beginning with an initial clinical screening and followed potentially by dermoscopic analysis, a biopsy and histopathological examination. Automated classification of skin lesions using images is a challenging task owing to the fine-grained variability in the appearance of skin lesions. Deep convolutional neural networks (CNNs), show potential for general and highly variable tasks across many fine-grained object categories,,,,,. Here we demonstrate classification of skin lesions using a single CNN, trained end-to-end from images directly, using only pixels and disease labels as inputs. We train a CNN using a dataset of 129,450 clinical images—two orders of magnitude larger than previous datasets—consisting of 2,032 different diseases. We test its performance against 21 board-certified dermatologists on biopsy-proven clinical …",
        "year": 2017,
        "authors": "Andre Esteva and Brett Kuprel and Roberto A Novoa and Justin Ko and Susan M Swetter and Helen M Blau and Sebastian Thrun"
      },
      {
        "title": "Probabilistic robotics",
        "abstract": "Planning and navigation algorithms exploit statistics gleaned from uncertain, imperfect real-world environments to guide robots toward their goals and around obstacles.",
        "year": 2002,
        "authors": "Sebastian Thrun"
      },
      {
        "title": "The dynamic window approach to collision avoidance",
        "abstract": "This approach, designed for mobile robots equipped with synchro-drives, is derived directly from the motion dynamics of the robot. In experiments, the dynamic window approach safely controlled the mobile robot RHINO at speeds of up to 95 cm/sec, in populated and dynamic environments.",
        "year": 2002,
        "authors": "Dieter Fox and Wolfram Burgard and Sebastian Thrun"
      }
    ],
    "ESCWolcAAAAJ": [
      {
        "title": "Noisy sorting capacity",
        "abstract": "Sorting is the task of ordering n elements using pairwise comparisons. It is well known that   comparisons are both necessary and sufficient when the outcomes of the comparisons are observed with no noise. In this paper, we study the sorting problem when each comparison is incorrect with some fixed yet unknown probability p. Unlike the common approach in the literature which aims to minimize the number of pairwise comparisons m to achieve a given desired error probability, we consider randomized algorithms with expected number of queries   and aim at characterizing the maximal sorting rate   such that the ordering of the elements can be estimated with a vanishing error probability asymptotically. The maximal rate is referred to as the noisy sorting capacity. In this work, we derive upper and lower bounds on the noisy sorting capacity. The two lower bounds — one for fixed-length …",
        "year": 2024,
        "authors": "Ziao Wang and Nadim Ghaddar and Banghua Zhu and Lele Wang"
      },
      {
        "title": "Attributed graph alignment",
        "abstract": "Motivated by various data science applications including de-anonymizing user identities in social networks, we consider the graph alignment problem, where the goal is to identify the vertex/user correspondence between two correlated graphs. Existing work mostly recovers the correspondence by exploiting the user-user connections. However, in many real-world applications, additional information about the users, such as user profiles, might be publicly available. In this paper, we introduce the attributed graph alignment problem, where additional user information, referred to as attributes, is incorporated to assist graph alignment. We establish both the achievability and converse results on recovering vertex correspondence exactly, where the conditions match for certain parameter regimes. Our results span the full spectrum between models that only consider user-user connections and models where only attribute …",
        "year": 2024,
        "authors": "Ning Zhang and Ziao Wang and Weina Wang and Lele Wang"
      },
      {
        "title": "On the feasible region of efficient algorithms for attributed graph alignment",
        "abstract": "Graph alignment aims at finding the vertex correspondence between two correlated graphs, a task that frequently occurs in graph mining applications such as social network analysis. Attributed graph alignment is a variant of graph alignment, in which publicly available side information or attributes are exploited to assist graph alignment. Existing studies on attributed graph alignment focus on either theoretical performance without computational constraints or empirical performance of efficient algorithms. This motivates us to investigate efficient algorithms with theoretical performance guarantee. In this paper, we propose two polynomial-time algorithms that exactly recover the vertex correspondence with high probability. The feasible region of the proposed algorithms is near optimal compared to the information-theoretic limits. When specialized to the seeded graph alignment problem under the seeded Erdős-Rényi …",
        "year": 2024,
        "authors": "Ziao Wang and Ning Zhang and Weina Wang and Lele Wang"
      }
    ],
    "MhDyxdYAAAAJ": [
      {
        "title": "A mean field view of the landscape of two-layers neural networks",
        "abstract": "Multilayer neural networks are among the most powerful models in machine learning, yet the fundamental reasons for this success defy mathematical understanding. Learning a neural network requires optimizing a nonconvex high-dimensional objective (risk function), a problem that is usually attacked using stochastic gradient descent (SGD). Does SGD converge to a global optimum of the risk or only to a local optimum? In the former case, does this happen because local minima are absent or because SGD somehow avoids them? In the latter, why do local minima reached by SGD have good generalization properties? In this paper, we consider a simple case, namely two-layer neural networks, and prove that—in a suitable scaling limit—SGD dynamics is captured by a certain nonlinear partial differential equation (PDE) that we call distributional dynamics (DD). We then consider several specific examples and …",
        "year": 2018,
        "authors": "S Mei and A Montanari and P Nguyen"
      },
      {
        "title": "The generalization error of random features regression: Precise asymptotics and the double descent curve",
        "abstract": "Deep learning methods operate in regimes that defy the traditional statistical mindset. Neural network architectures often contain more parameters than training samples, and are so rich that they can interpolate the observed labels, even if the latter are replaced by pure noise. Despite their huge complexity, the same architectures achieve small generalization error on real data.This phenomenon has been rationalized in terms of a so‐called ‘double descent’ curve. As the model complexity increases, the test error follows the usual U‐shaped curve at the beginning, first decreasing and then peaking around the interpolation threshold (when the model achieves vanishing training error). However, it descends again as model complexity exceeds this threshold. The global minimum of the test error is found above the interpolation threshold, often in the extreme overparametrization regime in which the number of …",
        "year": 2022,
        "authors": "Song Mei and Andrea Montanari"
      },
      {
        "title": "The landscape of empirical risk for non-convex losses",
        "abstract": "Most high-dimensional estimation methods propose to minimize a cost function (empirical risk) that is a sum of losses associated to each data point (each example). In this paper, we focus on the case of nonconvex losses. Classical empirical process theory implies uniform convergence of the empirical (or sample) risk to the population risk. While under additional assumptions, uniform convergence implies consistency of the resultingM-estimator, it does not ensure that the latter can be computed efficiently.In order to capture the complexity of computing M-estimators, we study the landscape of the empirical risk, namely its stationary points and their properties. We establish uniform convergence of the gradient and Hessian of the empirical risk to their population counterparts, as soon as the number of samples becomes larger than the number of unknown parameters (modulo logarithmic factors). Consequently, good …",
        "year": 2018,
        "authors": "Song Mei and Yu Bai and Andrea Montanari"
      }
    ],
    "7HCKL10AAAAJ": [
      {
        "title": "Global and regional mortality from 235 causes of death for 20 age groups in 1990 and 2010: a systematic analysis for the Global Burden of Disease Study 2010",
        "abstract": "Reliable and timely information on the leading causes of death in populations, and how these are changing, is a crucial input into health policy debates. In the Global Burden of Diseases, Injuries, and Risk Factors Study 2010 (GBD 2010), we aimed to estimate annual deaths for the world and 21 regions between 1980 and 2010 for 235 causes, with uncertainty intervals (UIs), separately by age and sex.We attempted to identify all available data on causes of death for 187 countries from 1980 to 2010 from vital registration, verbal autopsy, mortality surveillance, censuses, surveys, hospitals, police records, and mortuaries. We assessed data quality for completeness, diagnostic accuracy, missing data, stochastic variations, and probable causes of death. We applied six different modelling strategies to estimate cause-specific mortality trends depending on the strength of the data. For 133 causes and …",
        "year": 2012,
        "authors": "Rafael Lozano and Mohsen Naghavi and Kyle Foreman and Stephen Lim and Kenji Shibuya and Victor Aboyans and Jerry Abraham and Timothy Adair and Rakesh Aggarwal and Stephanie Y Ahn and Mohammad A AlMazroa and Miriam Alvarado and H Ross Anderson and Laurie M Anderson and Kathryn G Andrews and Charles Atkinson and Larry M Baddour and Suzanne Barker-Collo and David H Bartels and Michelle L Bell and Emelia J Benjamin and Derrick Bennett and Kavi Bhalla and Boris Bikbov and Aref Bin Abdulhak and Gretchen Birbeck and Fiona Blyth and Ian Bolliger and Soufiane Boufous and Chiara Bucello and Michael Burch and Peter Burney and Jonathan Carapetis and Honglei Chen and David Chou and Sumeet S Chugh and Luc E Coffeng and Steven D Colan and Samantha Colquhoun and K Ellicott Colson and John Condon and Myles D Connor and Leslie T Cooper and Matthew Corriere and Monica Cortinovis and Karen Courville De Vaccaro and William Couser and Benjamin C Cowie and Michael H Criqui and Marita Cross and Kaustubh C Dabhadkar and Nabila Dahodwala and Diego De Leo and Louisa Degenhardt and Allyne Delossantos and Julie Denenberg and Don C Des Jarlais and Samath D Dharmaratne and E Ray Dorsey and Tim Driscoll and Herbert Duber and Beth Ebel and Patricia J Erwin and Patricia Espindola and Majid Ezzati and Valery Feigin and Abraham D Flaxman and Mohammad H Forouzanfar and Francis Gerry R Fowkes and Richard Franklin and Marlene Fransen and Michael K Freeman and Sherine E Gabriel and Emmanuela Gakidou and Flavio Gaspari and Richard F Gillum and Diego Gonzalez-Medina and Yara A Halasa and Diana Haring and James E Harrison and Rasmus Havmoeller and Roderick J Hay and Bruno Hoen and Peter J Hotez and Damian Hoy and Kathryn H Jacobsen and Spencer L James and Rashmi Jasrasaria and Sudha Jayaraman and Nicole Johns and Ganesan Karthikeyan and Nicholas Kassebaum and Andre Keren and Jon-Paul Khoo and Lisa Marie Knowlton and Olive Kobusingye and Adofo Koranteng and Rita Krishnamurthi and Michael Lipnick and Steven E Lipshultz and Summer Lockett Ohno and Jacqueline Mabweijano and Michael F MacIntyre and Leslie Mallinger and Lyn March and Guy B Marks and Robin Marks and Akira Matsumori and Richard Matzopoulos and Bongani M Mayosi and John H McAnulty and Mary M McDermott and John McGrath and Ziad A Memish and George A Mensah and Tony R Merriman and Catherine Michaud and Matthew Miller and Ted R Miller and Charles Mock and Ana Olga Mocumbi and Ali A Mokdad and Andrew Moran and Kim Mulholland and M Nathan Nair and Luigi Naldi and KM Venkat Narayan and Kiumarss Nasseri and Paul Norman and Martin O'Donnell and Saad B Omer and Katrina Ortblad and Richard Osborne and Doruk Ozgediz and Bishnu Pahari and Jeyaraj Durai Pandian and Andrea Panozo Rivero and Rogelio Perez Padilla and Fernando Perez-Ruiz and Norberto Perico and David Phillips and Kelsey Pierce and C Arden Pope and Esteban Porrini and Farshad Pourmalek and Murugesan Raju and Dharani Ranganathan and Jürgen T Rehm and David B Rein and Guiseppe Remuzzi"
      },
      {
        "title": "Global, regional, and national prevalence of overweight and obesity in children and adults during 1980–2013: a systematic analysis for the Global Burden of Disease Study 2013",
        "abstract": "In 2010, overweight and obesity were estimated to cause 3·4 million deaths, 3·9% of years of life lost, and 3·8% of disability-adjusted life-years (DALYs) worldwide. The rise in obesity has led to widespread calls for regular monitoring of changes in overweight and obesity prevalence in all populations. Comparable, up-to-date information about levels and trends is essential to quantify population health effects and to prompt decision makers to prioritise action. We estimate the global, regional, and national prevalence of overweight and obesity in children and adults during 1980–2013.We systematically identified surveys, reports, and published studies (n=1769) that included data for height and weight, both through physical measurements and self-reports. We used mixed effects linear regression to correct for bias in self-reports. We obtained data for prevalence of obesity and overweight by age …",
        "year": 2014,
        "authors": "Marie Ng and Tom Fleming and Margaret Robinson and Blake Thomson and Nicholas Graetz and Christopher Margono and Erin C Mullany and Stan Biryukov and Cristiana Abbafati and Semaw Ferede Abera and Jerry P Abraham and Niveen ME Abu-Rmeileh and Tom Achoki and Fadia S AlBuhairan and Zewdie A Alemu and Rafael Alfonso and Mohammed K Ali and Raghib Ali and Nelson Alvis Guzman and Walid Ammar and Palwasha Anwari and Amitava Banerjee and Simon Barquera and Sanjay Basu and Derrick A Bennett and Zulfiqar Bhutta and Jed Blore and Norberto Cabral and Ismael Campos Nonato and Jung-Chen Chang and Rajiv Chowdhury and Karen J Courville and Michael H Criqui and David K Cundiff and Kaustubh C Dabhadkar and Lalit Dandona and Adrian Davis and Anand Dayama and Samath D Dharmaratne and Eric L Ding and Adnan M Durrani and Alireza Esteghamati and Farshad Farzadfar and Derek FJ Fay and Valery L Feigin and Abraham Flaxman and Mohammad H Forouzanfar and Atsushi Goto and Mark A Green and Rajeev Gupta and Nima Hafezi-Nejad and Graeme J Hankey and Heather C Harewood and Rasmus Havmoeller and Simon Hay and Lucia Hernandez and Abdullatif Husseini and Bulat T Idrisov and Nayu Ikeda and Farhad Islami and Eiman Jahangir and Simerjot K Jassal and Sun Ha Jee and Mona Jeffreys and Jost B Jonas and Edmond K Kabagambe and Shams Eldin Ali Hassan Khalifa and Andre Pascal Kengne and Yousef Saleh Khader and Young-Ho Khang and Daniel Kim and Ruth W Kimokoti and Jonas M Kinge and Yoshihiro Kokubo and Soewarta Kosen and Gene Kwan and Taavi Lai and Mall Leinsalu and Yichong Li and Xiaofeng Liang and Shiwei Liu and Giancarlo Logroscino and Paulo A Lotufo and Yuan Lu and Jixiang Ma and Nana Kwaku Mainoo and George A Mensah and Tony R Merriman and Ali H Mokdad and Joanna Moschandreas and Mohsen Naghavi and Aliya Naheed and Devina Nand and KM Venkat Narayan and Erica Leigh Nelson and Marian L Neuhouser and Muhammad Imran Nisar and Takayoshi Ohkubo and Samuel O Oti and Andrea Pedroza and Dorairaj Prabhakaran and Nobhojit Roy and Uchechukwu Sampson and Hyeyoung Seo and Sadaf G Sepanlou and Kenji Shibuya and Rahman Shiri and Ivy Shiue and Gitanjali M Singh and Jasvinder A Singh and Vegard Skirbekk and Nicolas JC Stapelberg and Lela Sturua and Bryan L Sykes and Martin Tobias and Bach X Tran and Leonardo Trasande and Hideaki Toyoshima and Steven Van De Vijver and Tommi J Vasankari and J Lennert Veerman and Gustavo Velasquez-Melendez and Vasiliy Victorovich Vlassov and Stein Emil Vollset and Theo Vos and Claire Wang and XiaoRong Wang and Elisabete Weiderpass and Andrea Werdecker and Jonathan L Wright and Y Claire Yang and Hiroshi Yatsuya and Jihyun Yoon and Seok-Jun Yoon and Yong Zhao and Maigeng Zhou and Shankuan Zhu and Alan D Lopez and Christopher JL Murray and Emmanuela Gakidou"
      },
      {
        "title": "A comparative risk assessment of burden of disease and injury attributable to 67 risk factors and risk factor clusters in 21 regions, 1990–2010: a systematic analysis for the Global Burden of Disease Study 2010",
        "abstract": "Quantification of the disease burden caused by different risks informs prevention by providing an account of health loss different to that provided by a disease-by-disease analysis. No complete revision of global disease burden caused by risk factors has been done since a comparative risk assessment in 2000, and no previous analysis has assessed changes in burden attributable to risk factors over time.We estimated deaths and disability-adjusted life years (DALYs; sum of years lived with disability [YLD] and years of life lost [YLL]) attributable to the independent effects of 67 risk factors and clusters of risk factors for 21 regions in 1990 and 2010. We estimated exposure distributions for each year, region, sex, and age group, and relative risks per unit of exposure by systematically reviewing and synthesising published and unpublished data. We used these estimates, together with estimates of …",
        "year": 2012,
        "authors": "Stephen S Lim and Theo Vos and Abraham D Flaxman and Goodarz Danaei and Kenji Shibuya and Heather Adair-Rohani and Mohammad A AlMazroa and Markus Amann and H Ross Anderson and Kathryn G Andrews and Martin Aryee and Charles Atkinson and Loraine J Bacchus and Adil N Bahalim and Kalpana Balakrishnan and John Balmes and Suzanne Barker-Collo and Amanda Baxter and Michelle L Bell and Jed D Blore and Fiona Blyth and Carissa Bonner and Guilherme Borges and Rupert Bourne and Michel Boussinesq and Michael Brauer and Peter Brooks and Nigel G Bruce and Bert Brunekreef and Claire Bryan-Hancock and Chiara Bucello and Rachelle Buchbinder and Fiona Bull and Richard T Burnett and Tim E Byers and Bianca Calabria and Jonathan Carapetis and Emily Carnahan and Zoe Chafe and Fiona Charlson and Honglei Chen and Jian Shen Chen and Andrew Tai-Ann Cheng and Jennifer Christine Child and Aaron Cohen and K Ellicott Colson and Benjamin C Cowie and Sarah Darby and Susan Darling and Adrian Davis and Louisa Degenhardt and Frank Dentener and Don C Des Jarlais and Karen Devries and Mukesh Dherani and Eric L Ding and E Ray Dorsey and Tim Driscoll and Karen Edmond and Suad Eltahir Ali and Rebecca E Engell and Patricia J Erwin and Saman Fahimi and Gail Falder and Farshad Farzadfar and Alize Ferrari and Mariel M Finucane and Seth Flaxman and Francis Gerry R Fowkes and Greg Freedman and Michael K Freeman and Emmanuela Gakidou and Santu Ghosh and Edward Giovannucci and Gerhard Gmel and Kathryn Graham and Rebecca Grainger and Bridget Grant and David Gunnell and Hialy R Gutierrez and Wayne Hall and Hans W Hoek and Anthony Hogan and H Dean Hosgood and Damian Hoy and Howard Hu and Bryan J Hubbell and Sally J Hutchings and Sydney E Ibeanusi and Gemma L Jacklyn and Rashmi Jasrasaria and Jost B Jonas and Haidong Kan and John A Kanis and Nicholas Kassebaum and Norito Kawakami and Young-Ho Khang and Shahab Khatibzadeh and Jon-Paul Khoo and Cindy Kok and Francine Laden and Ratilal Lalloo and Qing Lan and Tim Lathlean and Janet L Leasher and James Leigh and Yang Li and John Kent Lin and Steven E Lipshultz and Stephanie London and Rafael Lozano and Yuan Lu and Joelle Mak and Reza Malekzadeh and Leslie Mallinger and Wagner Marcenes and Lyn March and Robin Marks and Randall Martin and Paul McGale and John McGrath and Sumi Mehta and Ziad A Memish and George A Mensah and Tony R Merriman and Renata Micha and Catherine Michaud and Vinod Mishra and Khayriyyah Mohd Hanafiah and Ali A Mokdad and Lidia Morawska and Dariush Mozaffarian and Tasha Murphy and Mohsen Naghavi and Bruce Neal and Paul K Nelson and Joan Miquel Nolla and Rosana Norman and Casey Olives and Saad B Omer and Jessica Orchard and Richard Osborne and Bart Ostro and Andrew Page and Kiran D Pandey and Charles DH Parry and Erin Passmore and Jayadeep Patra and Neil Pearce and Pamela M Pelizzari"
      }
    ],
    "wRyjJfMAAAAJ": [
      {
        "title": "Generalized Zero-and Few-Shot Learning via Aligned Variational Autoencoders",
        "abstract": "Many approaches in generalized zero-shot learning rely on cross-modal mapping between the image feature space and the class embedding space. As labeled images are expensive, one direction is to augment the dataset by generating either images or image features. However, the former misses fine-grained details and the latter requires learning a mapping associated with class embeddings. In this work, we take feature generation one step further and propose a model where a shared latent space of image features and class embeddings is learned by modality-specific aligned variational autoencoders. This leaves us with the required discriminative information about the image and classes in the latent features, on which we train a softmax classifier. The key to our approach is that we align the distributions learned from images and from side-information to construct latent features that contain the essential multi-modal information associated with unseen classes. We evaluate our learned latent features on several benchmark datasets, ie CUB, SUN, AWA1 and AWA2, and establish a new state of the art on generalized zero-shot as well as on few-shot learning. Moreover, our results on ImageNet with various zero-shot splits show that our latent features generalize well in large-scale settings.",
        "year": 2018,
        "authors": "Edgar Schönfeld and Sayna Ebrahimi and Samarth Sinha and Trevor Darrell and Zeynep Akata"
      },
      {
        "title": "Variational adversarial active learning",
        "abstract": "Active learning aims to develop label-efficient algorithms by sampling the most representative queries to be labeled by an oracle. We describe a pool-based semi-supervised active learning algorithm that implicitly learns this sampling mechanism in an adversarial manner. Our method learns a latent space using a variational autoencoder (VAE) and an adversarial network trained to discriminate between unlabeled and labeled data. The mini-max game between the VAE and the adversarial network is played such that while the VAE tries to trick the adversarial network into predicting that all data points are from the labeled pool, the adversarial network learns how to discriminate between dissimilarities in the latent space. We extensively evaluate our method on various image classification and semantic segmentation benchmark datasets and establish a new state of the art on CIFAR10/100, Caltech-256, ImageNet, Cityscapes, and BDD100K. Our results demonstrate that our adversarial approach learns an effective low dimensional latent space in large-scale settings and provides for a computationally efficient sampling method. Our code is available at https://github. com/sinhasam/vaal.",
        "year": 2019,
        "authors": "Samarth Sinha and Sayna Ebrahimi and Trevor Darrell"
      },
      {
        "title": "DualPrompt: Complementary Prompting for Rehearsal-free Continual Learning",
        "abstract": " Continual learning aims to enable a single model to learn a sequence of tasks without catastrophic forgetting. Top-performing methods usually require a rehearsal buffer to store past pristine examples for experience replay, which, however, limits their practical value due to privacy and memory constraints. In this work, we present a simple yet effective framework, DualPrompt, which learns a tiny set of parameters, called prompts, to properly instruct a pre-trained model to learn tasks arriving sequentially without buffering past examples. DualPrompt presents a novel approach to attach complementary prompts to the pre-trained backbone, and then formulates the objective as learning task-invariant and task-specific “instructions”. With extensive experimental validation, DualPrompt consistently sets state-of-the-art performance under the challenging class-incremental setting. In particular, DualPrompt outperforms recent …",
        "year": 2022,
        "authors": "Zifeng Wang and Zizhao Zhang and Sayna Ebrahimi and Ruoxi Sun and Han Zhang and Chen-Yu Lee and Xiaoqi Ren and Guolong Su and Vincent Perot and Jennifer Dy and Tomas Pfister"
      }
    ],
    "FH9nKOAAAAAJ": [
      {
        "title": "RLlib: Abstractions for Distributed Reinforcement Learning",
        "abstract": "Reinforcement learning (RL) algorithms involve the deep nesting of highly irregular computation patterns, each of which typically exhibits opportunities for distributed computation. We argue for distributing RL components in a composable way by adapting algorithms for top-down hierarchical control, thereby encapsulating parallelism and resource requirements within short-running compute tasks. We demonstrate the benefits of this principle through RLlib: a library that provides scalable software primitives for RL. These primitives enable a broad range of algorithms to be implemented with high performance, scalability, and substantial code reuse. RLlib is available as part of the open source Ray project at http://rllib. io/.",
        "year": 2018,
        "authors": "Eric Liang* and Richard Liaw* and Robert Nishihara and Philipp Moritz and Roy Fox and Ken Goldberg and Joseph Gonzalez and Michael Jordan and Ion Stoica"
      },
      {
        "title": "Taming the Noise in Reinforcement Learning via Soft Updates",
        "abstract": "Model-free reinforcement learning algorithms, such as Q-learning, perform poorly in the early stages of learning in noisy environments, because much effort is spent unlearning biased estimates of the state-action value function. The bias results from selecting, among several noisy estimates, the apparent optimum, which may actually be suboptimal. We propose G-learning, a new off-policy learning algorithm that regularizes the value estimates by penalizing deterministic policies in the beginning of the learning process. We show that this method reduces the bias of the value-function estimation, leading to faster convergence to the optimal value and the optimal policy. Moreover, G-learning enables the natural incorporation of prior domain knowledge, when available. The stochastic nature of G-learning also makes it avoid some exploration costs, a property usually attributed only to on-policy algorithms. We illustrate these ideas in several examples, where G-learning results in significant improvements of the convergence rate and the cost of the learning process.",
        "year": 2016,
        "authors": "Roy Fox* and Ari Pakman* and Naftali Tishby"
      },
      {
        "title": "DART: Noise Injection for Robust Imitation Learning",
        "abstract": "One approach to Imitation Learning is Behavior Cloning, in which a robot observes a supervisor and infers a control policy. A known problem with this “off-policy\" approach is that the robot’s errors compound when drifting away from the supervisor’s demonstrations. On-policy, techniques alleviate this by iteratively collecting corrective actions for the current robot policy. However, these techniques can be difficult for human supervisors, add significant computation burden, and require the robot to visit potentially dangerous states during training. We propose an off-policy approach that\\emphinjects noise into the supervisor’s policy while demonstrating. This forces the supervisor and robot to explore and recover from errors without letting them compound. We propose a new algorithm, DART, that collects demonstrations with injected noise, and optimizes the noise level to approximate the error of the robot’s trained policy during data collection. We provide a theoretical analysis to illustrate that DART reduces covariate shift more than Behavior Cloning for a robot with non-zero error. We evaluate DART in two domains: in simulation with an algorithmic supervisor on the MuJoCo locomotive tasks and in physical experiments with human supervisors training a Toyota HSR robot to perform grasping in clutter. For challenging tasks like Humanoid, DART can be up to $280% $ faster in computation time and only decreases the supervisor’s cumulative reward by $5% $ during training, whereas DAgger executes policies that have $80% $ less cumulative reward than the supervisor. On the grasping in clutter task, DART obtains on average $62% $ performance …",
        "year": 2017,
        "authors": "Michael Laskey and Jonathan Lee and Roy Fox and Anca Dragan and Ken Goldberg"
      }
    ],
    "ED5iKYYAAAAJ": [
      {
        "title": "Vibrotactile display: Perception, technology, and applications",
        "abstract": "This paper reviews the technology and applications of vibrotactile display, an effective information transfer modality for the emerging area of haptic media. Our emphasis is on summarizing foundational knowledge in this area and providing implementation guidelines for application designers who do not yet have a background in haptics. Specifically, we explain the relevant human vibrotactile perceptual capabilities, detail the main types of commercial vibrotactile actuators, and describe how to build both monolithic and localized vibrotactile displays. We then identify exemplary vibrotactile display systems in application areas ranging from the presentation of physical object properties to broadcasting vibrotactile media content.",
        "year": 2012,
        "authors": "Seungmoon Choi and Katherine J Kuchenbecker"
      },
      {
        "title": "Human-inspired robotic grasp control with tactile sensing",
        "abstract": "We present a novel robotic grasp controller that allows a sensorized parallel jaw gripper to gently pick up and set down unknown objects once a grasp location has been selected. Our approach is inspired by the control scheme that humans employ for such actions, which is known to centrally depend on tactile sensation rather than vision or proprioception. Our controller processes measurements from the gripper's fingertip pressure arrays and hand-mounted accelerometer in real time to generate robotic tactile signals that are designed to mimic human SA-I, FA-I, and FA-II channels. These signals are combined into tactile event cues that drive the transitions between six discrete states in the grasp controller: Close, Load, Lift and Hold, Replace, Unload, and Open. The controller selects an appropriate initial grasping force, detects when an object is slipping from the grasp, increases the grasp force as needed, and …",
        "year": 2011,
        "authors": "Joseph M Romano and Kaijen Hsiao and Günter Niemeyer and Sachin Chitta and Katherine J Kuchenbecker"
      },
      {
        "title": "Improving contact realism through event-based haptic feedback",
        "abstract": "Tapping on surfaces in a typical virtual environment feels like contact with soft foam rather than a hard object. The realism of such interactions can be dramatically improved by superimposing event-based, high-frequency transient forces over traditional position-based feedback. When scaled by impact velocity, hand-tuned pulses and decaying sinusoids produce haptic cues that resemble those experienced during real impacts. Our new method for generating appropriate transients inverts a dynamic model of the haptic device to determine the motor forces required to create prerecorded acceleration profiles at the user's fingertips. After development, the event-based haptic paradigm and the method of acceleration matching were evaluated in a carefully controlled user study. Sixteen individuals blindly tapped on nine virtual and three real samples, rating the degree to which each felt like real wood. Event-based …",
        "year": 2006,
        "authors": "Katherine J Kuchenbecker and Jonathan Fiene and Günter Niemeyer"
      }
    ],
    "i28fU0MAAAAJ": [
      {
        "title": "Learning physics-based motion style with nonlinear inverse optimization",
        "abstract": "This paper presents a novel physics-based representation of realistic character motion. The dynamical model incorporates several factors of locomotion derived from the biomechanical literature, including relative preferences for using some muscles more than others. elastic mechanisms at joints due to the mechanical properties of tendons, ligaments, and muscles, and variable stiffness at joints depending on the task. When used in a spacetime optimization framework, the parameters of this model define a wide range of styles of natural human movement.Due to the complexity of biological motion, these style parameters are too difficult to design by hand. To address this, we introduce Nonlinear Inverse Optimization, a novel algorithm for estimating optimization parameters from motion capture data. Our method can extract the physical parameters from a single short motion sequence. Once captured, this …",
        "year": 2005,
        "authors": "C Karen Liu and Aaron Hertzmann and Zoran Popović"
      },
      {
        "title": "Preparing for the unknown: Learning a universal policy with online system identification",
        "abstract": "We present a new method of learning control policies that successfully operate under unknown dynamic models. We create such policies by leveraging a large number of training examples that are generated using a physical simulator. Our system is made of two components: a Universal Policy (UP) and a function for Online System Identification (OSI). We describe our control policy as universal because it is trained over a wide array of dynamic models. These variations in the dynamic model may include differences in mass and inertia of the robots' components, variable friction coefficients, or unknown mass of an object to be manipulated. By training the Universal Policy with this variation, the control policy is prepared for a wider array of possible conditions when executed in an unknown environment. The second part of our system uses the recent state and action history of the system to predict the dynamics model parameters mu. The value of mu from the Online System Identification is then provided as input to the control policy (along with the system state). Together, UP-OSI is a robust control policy that can be used across a wide range of dynamic models, and that is also responsive to sudden changes in the environment. We have evaluated the performance of this system on a variety of tasks, including the problem of cart-pole swing-up, the double inverted pendulum, locomotion of a hopper, and block-throwing of a manipulator. UP-OSI is effective at these tasks across a wide range of dynamic models. Moreover, when tested with dynamic models outside of the training range, UP-OSI outperforms the Universal Policy alone, even when UP is …",
        "year": 2017,
        "authors": "Wenhao Yu and Jie Tan and C Karen Liu and Greg Turk"
      },
      {
        "title": "Synthesis of complex dynamic character motion from simple animations",
        "abstract": "In this paper we present a general method for rapid prototyping of realistic character motion. We solve for the natural motion from a simple animation provided by the animator. Our framework can be used to produce relatively complex realistic motion with little user effort.We describe a novel constraint detection method that automatically determines different constraints on the character by analyzing the input motion. We show that realistic motion can be achieved by enforcing a small set of linear and angular momentum constraints. This simplified approach helps us avoid the complexities of computing muscle forces. Simpler dynamic constraints also allow us to generate animations of models with greater complexity, performing more intricate motions. Finally, we show that by learning a small set of key parameters that describe a character pose we can help a non-skilled animator rapidly create realistic character motion.",
        "year": 2002,
        "authors": "C Karen Liu and Zoran Popović"
      }
    ],
    "t9HPFawAAAAJ": [
      {
        "title": "End-to-end learning of driving models from large-scale video datasets",
        "abstract": "Robust perception-action models should be learned from training data with diverse visual appearances and realistic behaviors, yet current approaches to deep visuomotor policy learning have been generally limited to in-situ models learned from a single vehicle or simulation environment. We advocate learning a generic vehicle motion model from large scale crowd-sourced video data, and develop an end-to-end trainable architecture for learning to predict a distribution over future vehicle egomotion from instantaneous monocular camera observations and previous vehicle state. Our model incorporates a novel FCN-LSTM architecture, which can be learned from large-scale crowd-sourced vehicle action data, and leverages available scene segmentation side tasks to improve performance under a privileged learning paradigm. We provide a novel large-scale dataset of crowd-sourced driving behavior suitable for training our model, and report results predicting the driver action on held out sequences across diverse conditions.",
        "year": 2017,
        "authors": "Huazhe Xu and Yang Gao and Fisher Yu and Trevor Darrell"
      },
      {
        "title": "Natural language object retrieval",
        "abstract": "In this paper, we address the task of natural language object retrieval, to localize a target object within a given image based on a natural language query of the object. Natural language object retrieval differs from text-based image retrieval task as it involves spatial information about objects within the scene and global scene context. To address this issue, we propose a novel Spatial Context Recurrent ConvNet (SCRC) model as scoring function on candidate boxes for object retrieval, integrating spatial configurations and global scene-level contextual information into the network. Our model processes query text, local image descriptors, spatial configurations and global context features through a recurrent network, outputs the probability of the query text conditioned on each candidate box as a score for the box, and can transfer visual-linguistic knowledge from image captioning domain to our task. Experimental results demonstrate that our method effectively utilizes both local and global information, outperforming previous baseline methods significantly on different datasets and scenarios, and can exploit large scale vision and language datasets for knowledge transfer.",
        "year": 2016,
        "authors": "Ronghang Hu and Huazhe Xu and Marcus Rohrbach and Jiashi Feng and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Algorithmic Framework for Model-based Deep Reinforcement Learning with Theoretical Guarantees",
        "abstract": "Model-based reinforcement learning (RL) is considered to be a promising approach to reduce the sample complexity that hinders model-free RL. However, the theoretical understanding of such methods has been rather limited. This paper introduces a novel algorithmic framework for designing and analyzing model-based RL algorithms with theoretical guarantees. We design a meta-algorithm with a theoretical guarantee of monotone improvement to a local maximum of the expected reward. The meta-algorithm iteratively builds a lower bound of the expected reward based on the estimated dynamical model and sample trajectories, and then maximizes the lower bound jointly over the policy and the model. The framework extends the optimism-in-face-of-uncertainty principle to non-linear dynamical models in a way that requires \\textit{no explicit} uncertainty quantification. Instantiating our framework with simplification gives a variant of model-based RL algorithms Stochastic Lower Bounds Optimization (SLBO). Experiments demonstrate that SLBO achieves state-of-the-art performance when only one million or fewer samples are permitted on a range of continuous control benchmark tasks.",
        "year": 2019,
        "authors": "Yuping Luo and Huazhe Xu and Yuanzhi Li and Yuandong Tian and Trevor Darrell and Tengyu Ma"
      }
    ],
    "hiOfejkAAAAJ": [
      {
        "title": "Minimax estimation of a functional on a structured high-dimensional model",
        "abstract": "Supplement to “Minimax estimation of a functional on a structured high-dimensional model”. The remainder of the paper is given in the supplement.",
        "year": 2017,
        "authors": "James M Robins and Lingling Li and Rajarshi Mukherjee and Eric Tchetgen Tchetgen and Aad van der Vaart"
      },
      {
        "title": "The generalized higher criticism for testing SNP-set effects in genetic association studies",
        "abstract": "It is of substantial interest to study the effects of genes, genetic pathways, and networks on the risk of complex diseases. These genetic constructs each contain multiple SNPs, which are often correlated and function jointly, and might be large in number. However, only a sparse subset of SNPs in a genetic construct is generally associated with the disease of interest. In this article, we propose the generalized higher criticism (GHC) to test for the association between an SNP set and a disease outcome. The higher criticism is a test traditionally used in high-dimensional signal detection settings when marginal test statistics are independent and the number of parameters is very large. However, these assumptions do not always hold in genetic association studies, due to linkage disequilibrium among SNPs and the finite number of SNPs in an SNP set in each genetic construct. The proposed GHC overcomes the …",
        "year": 2017,
        "authors": "Ian Barnett and Rajarshi Mukherjee and Xihong Lin"
      },
      {
        "title": "Hypothesis testing for high-dimensional sparse binary regression",
        "abstract": "In this paper, we study the detection boundary for minimax hypothesis testing in the context of high-dimensional, sparse binary regression models. Motivated by genetic sequencing association studies for rare variant effects, we investigate the complexity of the hypothesis testing problem when the design matrix is sparse. We observe a new phenomenon in the behavior of detection boundary which does not occur in the case of Gaussian linear regression. We derive the detection boundary as a function of two components: a design matrix sparsity index and signal strength, each of which is a function of the sparsity of the alternative. For any alternative, if the design matrix sparsity index is too high, any test is asymptotically powerless irrespective of the magnitude of signal strength. For binary design matrices with the sparsity index that is not too high, our results are parallel to those in the Gaussian case. In this context …",
        "year": 2015,
        "authors": "Rajarshi Mukherjee and Natesh S Pillai and Xihong Lin"
      }
    ],
    "SOt7sr4AAAAJ": [
      {
        "title": "Effects of Vibrotactile Feedback on Human Learning of Arm Motions",
        "abstract": "Tactile cues generated from lightweight, wearable actuators can help users learn new motions by providing immediate feedback on when and how to correct their movements. We present a vibrotactile motion guidance system that measures arm motions and provides vibration feedback when the user deviates from a desired trajectory. A study was conducted to test the effects of vibrotactile guidance on a subject's ability to learn arm motions. Twenty-six subjects learned motions of varying difficulty with both visual (V), and visual and vibrotactile (VVT) feedback over the course of four days of training. After four days of rest, subjects returned to perform the motions from memory with no feedback. We found that augmenting visual feedback with vibrotactile feedback helped subjects reduce the root mean square (rms) angle error of their limb significantly while they were learning the motions, particularly for 1DOF motions …",
        "year": 2014,
        "authors": "Karlin Bark and Emily Hyman and Frank Tan and Elizabeth Cha and Steven A Jax and Laurel J Buxbaum and Katherine J Kuchenbecker"
      },
      {
        "title": "A survey of nonverbal signaling methods for non-humanoid robots",
        "abstract": "The goal of this survey is to inform the design and usage of nonverbal signals for human-robot interaction. With robots being increasingly utilized for tasks that require them to not only operate in close proximity to humans but to interact with them as well, there has been great interest in the communication challenges associated with the varying degrees of interaction in these environments. The success of such interactions depends on robots’ ability to convey information about their knowledge, intent, and actions to co-located humans. In this work, we present a comprehensive review of literature related to the generation and usage of nonverbal signals that facilitate legibility of non-humanoid robot state and behavior. To motivate the need for these signaling behaviors, we survey literature in human communication and psychology and outline target use cases of non-humanoid robots. Specifically, we focus on works that provide insight into the cognitive processes that enable humans to recognize, interpret, and exploit nonverbal signals. From these use cases, we identify information that is potentially important for non-humanoid robots to signal and organize it into three categories of robot state. We then present a review of signal design techniques to illustrate how signals conveying this information can be generated and utilized. Finally, we discuss issues that must be considered during nonverbal signaling and open research areas, with a focus on informing the design and usage of generalizable nonverbal signaling behaviors for task-oriented non-humanoid robots.",
        "year": 2018,
        "authors": "Elizabeth Cha and Yunkyung Kim and Terrence Fong and Maja J Mataric"
      },
      {
        "title": "Perceived robot capability",
        "abstract": "Robotics research often focuses on increasing robot capability. If end users do not perceive these increases, however, user acceptance may not improve. In this work, we explore the idea of perceived capability and how it relates to true capability, differentiating between physical and social capabilities. We present a framework that outlines their potential relationships, along with two user studies, on robot speed and speech, exploring these relationships. Our studies identify two possible consequences of the disconnect between the true and perceived capability: (1) under-perception: true improvements in capability may not lead to perceived improvements and (2) over-perception: true improvements in capability may lead to additional perceived improvements that do not actually exist.",
        "year": 2015,
        "authors": "Elizabeth Cha and Anca D Dragan and Siddhartha S Srinivasa"
      }
    ],
    "_TkfqdgAAAAJ": [
      {
        "title": "Towards inspecting and eliminating trojan backdoors in deep neural networks",
        "abstract": "A trojan backdoor is a hidden pattern typically implanted in a deep neural network (DNN). It could be activated and thus forces that infected model to behave abnormally when an input sample with a particular trigger is fed to that model. As such, given a DNN and clean input samples, it is challenging to inspect and determine the existence of a trojan backdoor. Recently, researchers design and develop several pioneering solutions to address this problem. They demonstrate that the proposed techniques have great potential in trojan detection. However, we show that none of these existing techniques completely address the problem. On the one hand, they mostly work under an unrealistic assumption of assuming the availability of the contaminated training database. On the other hand, these techniques can neither accurately detect the existence of trojan backdoors, nor restore high-fidelity triggers, especially when …",
        "year": 2020,
        "authors": "Wenbo Guo* and Lun Wang* and Yan Xu and Xinyu Xing and Min Du and Dawn Song"
      },
      {
        "title": "CHURP: dynamic-committee proactive secret sharing",
        "abstract": "We introduce CHURP (CHUrn-Robust Proactive secret sharing). CHURP enables secure secret-sharing in dynamic settings, where the committee of nodes storing a secret changes over time. Designed for blockchains, CHURP has lower communication complexity than previous schemes:  on-chain and  off-chain in the optimistic case of no node failures. CHURP includes several technical innovations: An efficient new proactivization scheme of independent interest, a technique (using asymmetric bivariate polynomials) for efficiently changing secret-sharing thresholds, and a hedge against setup failures in an efficient polynomial commitment scheme. We also introduce a general new technique for inexpensive off-chain communication across the peer-to-peer networks of permissionless blockchains. We formally prove the security of CHURP, report on an implementation, and present performance …",
        "year": 2019,
        "authors": "Sai Krishna Deepak Maram* and Fan Zhang* and Lun Wang and Andrew Low and Yupeng Zhang and Ari Juels and Dawn Song"
      }
    ],
    "8m8taGEAAAAJ": [
      {
        "title": "Zero phase error tracking algorithm for digital control",
        "abstract": "A digital feedforward control algorithm for tracking desired time varying signals is presented. The feedforward controller cancels all the closed-loop poles and cancellable closed-loop zeros. For uncancellable zeros, which include zeros outside the unit circle, the feedforward controller cancels the phase shift induced by them. The phase cancellation assures that the frequency response between the desired output and actual output exhibits zero phase shift for all the frequencies. The algorithm is particularly suited to the general motion control problems including robotic arms and positioning tables. A typical motion control problem is used to show the effectiveness of the proposed feedforward controller.",
        "year": 1987,
        "authors": "Masayoshi Tomizuka"
      },
      {
        "title": "Sparse r-cnn: End-to-end object detection with learnable proposals",
        "abstract": "We present Sparse R-CNN, a purely sparse method for object detection in images. Existing works on object detection heavily rely on dense object candidates, such as k anchor boxes pre-defined on all grids of image feature map of size HxW. In our method, however, a fixed sparse set of learned object proposals, total length of N, are provided to object recognition head to perform classification and location. By eliminating HWk (up to hundreds of thousands) hand-designed object candidates to N (eg 100) learnable proposals, Sparse R-CNN completely avoids all efforts related to object candidates design and many-to-one label assignment. More importantly, final predictions are directly output without non-maximum suppression post-procedure. Sparse R-CNN demonstrates accuracy, run-time and training convergence performance on par with the well-established detector baselines on the challenging COCO dataset, eg, achieving 45.0 AP in standard 3x training schedule and running at 22 fps using ResNet-50 FPN model. We hope our work could inspire re-thinking the convention of dense prior in object detectors. The code is available at: https://github. com/PeizeSun/SparseR-CNN.",
        "year": 2021,
        "authors": "Peize Sun and Rufeng Zhang and Yi Jiang and Tao Kong and Chenfeng Xu and Wei Zhan and Masayoshi Tomizuka and Lei Li and Zehuan Yuan and Changhu Wang and Ping Luo"
      },
      {
        "title": "Fuzzy gain scheduling of PID controllers",
        "abstract": "This paper describes the development of a fuzzy gain scheduling scheme of PID controllers for process control. Fuzzy rules and reasoning are utilized online to determine the controller parameters based on the error signal and its first difference. Simulation results demonstrate that better control performance can be achieved in comparison with Ziegler-Nichols controllers and Kitamori's PID controllers.<>",
        "year": 1993,
        "authors": "Zhen-Yu Zhao and Masayoshi Tomizuka and Satoru Isaka"
      }
    ],
    "9xDADY4AAAAJ": [
      {
        "title": "Long-term recurrent convolutional networks for visual recognition and description",
        "abstract": "Models comprised of deep convolutional network layers have dominated recent image interpretation tasks; we investigate whether models which are also compositional, or\" deep\", temporally are effective on tasks involving visual sequences or label sequences. We develop a novel recurrent convolutional architecture suitable for large-scale visual learning which is end-to-end trainable, and demonstrate the value of these models on benchmark video recognition tasks, image to sentence generation problems, and video narration challenges. In contrast to current models which assume a fixed spatio-temporal receptive field or simple temporal averaging for sequential processing, recurrent convolutional models are\" doubly deep\" in that they can be compositional in spatial and temporal\" layers\". Such models may have advantages when target concepts are complex and/or training data are limited. Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. Long-term RNN models are appealing in that they directly can map variable length inputs (ie video frames) to variable length outputs (ie natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent long-term models are directly connected to state-of-the-art visual convnet models and can jointly trained, updating temporal dynamics and convolutional perceptual representations simultaneously. Our results show such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined and/or optimized.",
        "year": 2015,
        "authors": "Jeffrey Donahue and Lisa Anne Hendricks and Sergio Guadarrama and Marcus Rohrbach and Subhashini Venugopalan and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Adversarial discriminative domain adaptation",
        "abstract": "Adversarial learning methods are a promising approach to training robust deep networks, and can generate complex samples across diverse domains. They can also improve recognition despite the presence of domain shift or dataset bias: recent adversarial approaches to unsupervised domain adaptation reduce the difference between the training and test domain distributions and thus improve generalization performance. However, while generative adversarial networks (GANs) show compelling visualizations, they are not optimal on discriminative tasks and can be limited to smaller shifts. On the other hand, discriminative approaches can handle larger domain shifts, but impose tied weights on the model and do not exploit a GAN-based loss. In this work, we first outline a novel generalized framework for adversarial adaptation, which subsumes recent state-of-the-art approaches as special cases, and use this generalized view to better relate prior approaches. We then propose a previously unexplored instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss, which we call Adversarial Discriminative Domain Adaptation (ADDA). We show that ADDA is more effective yet considerably simpler than competing domain-adversarial methods, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results on standard domain adaptation tasks as well as a difficult cross-modality object classification task.",
        "year": 2017,
        "authors": "Eric Tzeng and Judy Hoffman and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Deep coral: Correlation alignment for deep domain adaptation",
        "abstract": "Deep neural networks are able to learn powerful representations from large quantities of labeled input data, however they cannot always generalize well across changes in input distributions. Domain adaptation algorithms have been proposed to compensate for the degradation in performance due to domain shift. In this paper, we address the case when the target domain is unlabeled, requiring unsupervised adaptation. CORAL [18] is a simple unsupervised domain adaptation method that aligns the second-order statistics of the source and target distributions with a linear transformation. Here, we extend CORAL to learn a nonlinear transformation that aligns correlations of layer activations in deep neural networks (Deep CORAL). Experiments on standard benchmark datasets show state-of-the-art performance. Our code is available at:                      https://github.com/VisionLearningGroup/CORAL …",
        "year": 2016,
        "authors": "Baochen Sun and Kate Saenko"
      }
    ],
    "HaN8b2YAAAAJ": [
      {
        "title": "On the opportunities and risks of foundation models",
        "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",
        "year": 2021,
        "authors": "Rishi Bommasani and Drew A Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher Ré and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W Thomas and Florian Tramèr and Rose E Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang"
      },
      {
        "title": "Global and regional hearing impairment prevalence: an analysis of 42 studies in 29 countries",
        "abstract": " Background: Hearing impairment is a leading cause of disease burden, yet population-based studies that measure hearing impairment are rare. We estimate regional and global hearing impairment prevalence from sparse data and calculate corresponding uncertainty intervals. Methods: We accessed papers from a published literature review and obtained additional detailed data tabulations from investigators. We estimated the prevalence of hearing impairment by region, sex, age and hearing level using a Bayesian hierarchical model, a method that is effective for sparse data. As the primary objective of modelling was to produce regional and global prevalence estimates, including for those regions with scarce to no data, models were evaluated using cross-validation. Results: We used data from 42 studies, carried out between 1973 and 2010 in 29 countries. Hearing impairment was positively related to …",
        "year": 2013,
        "authors": "Gretchen Stevens and Seth Flaxman and Emma Brunskill and Maya Mascarenhas and Colin D Mathers and Mariel Finucane"
      },
      {
        "title": "Data-efficient off-policy policy evaluation for reinforcement learning",
        "abstract": "In this paper we present a new way of predicting the performance of a reinforcement learning policy given historical data that may have been generated by a different policy. The ability to evaluate a policy from historical data is important for applications where the deployment of a bad policy can be dangerous or costly. We show empirically that our algorithm produces estimates that often have orders of magnitude lower mean squared error than existing methods—it makes more efficient use of the available data. Our new estimator is based on two advances: an extension of the doubly robust estimator (Jiang & Li, 2015), and a new way to mix between model based and importance sampling based estimates.",
        "year": 2016,
        "authors": "Philip Thomas and Emma Brunskill"
      }
    ],
    "ZWH5jCwAAAAJ": [
      {
        "title": "Open X-Embodiment: Robotic Learning Datasets and RT-X Models : Open X-Embodiment Collaboration0",
        "abstract": "Large, high-capacity models trained on diverse datasets have shown remarkable successes on efficiently tackling downstream applications. In domains from NLP to Computer Vision, this has led to a consolidation of pretrained models, with general pretrained backbones serving as a starting point for many applications. Can such a consolidation happen in robotics? Conventionally, robotic learning methods train a separate model for every application, every robot, and even every environment. Can we instead train \"generalist\" X-robot policy that can be adapted efficiently to new robots, tasks, and environments? In this paper, we provide datasets in standardized data formats and models to make it possible to explore this possibility in the context of robotic manipulation, alongside experimental results that provide an example of effective X-robot policies. We assemble a dataset from 22 different robots collected through …",
        "year": 2024,
        "authors": "Abby O’Neill and Abdul Rehman and Abhiram Maddukuri and Abhishek Gupta and Abhishek Padalkar and Abraham Lee and Acorn Pooley and Agrim Gupta and Ajay Mandlekar and Ajinkya Jain and Albert Tung and Alex Bewley and Alex Herzog and Alex Irpan and Alexander Khazatsky and Anant Rai and Anchit Gupta and Andrew Wang and Anikait Singh and Animesh Garg and Aniruddha Kembhavi and Annie Xie and Anthony Brohan and Antonin Raffin and Archit Sharma and Arefeh Yavary and Arhan Jain and Ashwin Balakrishna and Ayzaan Wahid and Ben Burgess-Limerick and Beomjoon Kim and Bernhard Schölkopf and Blake Wulfe and Brian Ichter and Cewu Lu and Charles Xu and Charlotte Le and Chelsea Finn and Chen Wang and Chenfeng Xu and Cheng Chi and Chenguang Huang and Christine Chan and Christopher Agia and Chuer Pan and Chuyuan Fu and Coline Devin and Danfei Xu and Daniel Morton and Danny Driess and Daphne Chen and Deepak Pathak and Dhruv Shah and Dieter Büchler and Dinesh Jayaraman and Dmitry Kalashnikov and Dorsa Sadigh and Edward Johns and Ethan Foster and Fangchen Liu and Federico Ceola and Fei Xia and Feiyu Zhao and Freek Stulp and Gaoyue Zhou and Gaurav S Sukhatme and Gautam Salhotra and Ge Yan and Gilbert Feng and Giulio Schiavi and Glen Berseth and Gregory Kahn and Guanzhi Wang and Hao Su and Hao-Shu Fang and Haochen Shi and Henghui Bao and Heni Ben Amor and Henrik I Christensen and Hiroki Furuta and Homer Walke and Hongjie Fang and Huy Ha and Igor Mordatch and Ilija Radosavovic and Isabel Leal and Jacky Liang and Jad Abou-Chakra and Jaehyung Kim and Jaimyn Drake and Jan Peters and Jan Schneider and Jasmine Hsu and Jeannette Bohg and Jeffrey Bingham and Jeffrey Wu and Jensen Gao and Jiaheng Hu and Jiajun Wu and Jialin Wu and Jiankai Sun and Jianlan Luo and Jiayuan Gu and Jie Tan and Jihoon Oh and Jimmy Wu and Jingpei Lu and Jingyun Yang and Jitendra Malik and Joao Silverio and Joey Hejna and Jonathan Booher and Jonathan Tompson and Jonathan Yang and Jordi Salvador and Joseph J Lim and Junhyek Han and Kaiyuan Wang and Kanishka Rao and Karl Pertsch and Karol Hausman and Keegan Go and Keerthana Gopalakrishnan and Ken Goldberg and Kendra Byrne and Kenneth Oslund and Kento Kawaharazuka and Kevin Black and Kevin Lin and Kevin Zhang and Kiana Ehsani and Kiran Lekkala and Kirsty Ellis and Krishan Rana and Krishnan Srinivasan and Kuan Fang and Kunal Pratap Singh and Kuo-Hao Zeng and Kyle Hatch and Kyle Hsu and Laurent Itti and Lawrence Yunliang Chen and Lerrel Pinto and Li Fei-Fei and Liam Tan and Linxi Jim Fan and Lionel Ott and Lisa Lee and Luca Weihs and Magnum Chen"
      },
      {
        "title": "Octo: An open-source generalist robot policy",
        "abstract": "Octo: An Open-Source Generalist Robot Policy | OpenReview OpenReview.net Login back arrow \nGo to DBLP homepage Octo: An Open-Source Generalist Robot Policy Open Webpage Dibya \nGhosh, Homer Rich Walke, Karl Pertsch, Kevin Black, Oier Mees, Sudeep Dasari, Joey Hejna, \nTobias Kreiman, Charles Xu, Jianlan Luo, You Liang Tan, Lawrence Yunliang Chen, Quan \nVuong, Ted Xiao, Pannag R. Sanketi, Dorsa Sadigh, Chelsea Finn, Sergey Levine Published: \n01 Jan 2024, Last Modified: 23 Mar 2025Robotics: Science and Systems 2024Everyone\nRevisionsBibTeXCC BY-SA 4.0 Loading About OpenReview Hosting a Venue All Venues \nContact Feedback Sponsors Join the Team Frequently Asked Questions Terms of Use Privacy \nPolicy About OpenReview Hosting a Venue All Venues Sponsors Join the Team Frequently \nAsked Questions Contact Feedback Terms of Use Privacy Policy OpenReview is a long-…",
        "year": 2024,
        "authors": "Dibya Ghosh and Homer Rich Walke and Karl Pertsch and Kevin Black and Oier Mees and Sudeep Dasari and Joey Hejna and Tobias Kreiman and Charles Xu and Jianlan Luo and You Liang Tan and Lawrence Yunliang Chen and Quan Vuong and Ted Xiao and Pannag R Sanketi and Dorsa Sadigh and Chelsea Finn and Sergey Levine"
      },
      {
        "title": "Bridgedata v2: A dataset for robot learning at scale",
        "abstract": "We introduce BridgeData V2, a large and diverse dataset of robotic manipulation behaviors designed to facilitate research in scalable robot learning. BridgeData V2 contains 53,896 trajectories collected across 24 environments on a publicly available low-cost robot. Unlike many existing robotic manipulation datasets, BridgeData V2 provides enough task and environment variability that skills learned from the data generalize across institutions, making the dataset a useful resource for a broad range of researchers. Additionally, the dataset is compatible with a wide variety of open-vocabulary, multi-task learning methods conditioned on goal images or natural language instructions. In our experiments, we apply 6 state-of-the-art imitation learning and offline reinforcement learning methods to the data and find that they succeed on a suite of tasks requiring varying amounts of generalization. We also demonstrate that the performance of these methods improves with more data and higher capacity models. By publicly sharing BridgeData V2 and our pre-trained models, we aim to accelerate research in scalable robot learning methods.",
        "year": 2023,
        "authors": "Homer Rich Walke and Kevin Black and Tony Z Zhao and Quan Vuong and Chongyi Zheng and Philippe Hansen-Estruch and Andre Wang He and Vivek Myers and Moo Jin Kim and Max Du and Abraham Lee and Kuan Fang and Chelsea Finn and Sergey Levine"
      }
    ],
    "ADkiClQAAAAJ": [
      {
        "title": "Do as i can, not as i say: Grounding language in robotic affordances",
        "abstract": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model’s “hands and eyes,” while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project’s website, video, and open source can be …",
        "year": 2023,
        "authors": "Anthony Brohan and Yevgen Chebotar and Chelsea Finn and Karol Hausman and Alexander Herzog and Daniel Ho and Julian Ibarz and Alex Irpan and Eric Jang and Ryan Julian and Dmitry Kalashnikov and Sergey Levine and Yao Lu and Carolina Parada and Kanishka Rao and Pierre Sermanet and Alexander T Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Mengyuan Yan and Noah Brown and Michael Ahn and Omar Cortes and Nicolas Sievers and Clayton Tan and Sichun Xu and Diego Reyes and Jarek Rettinghouse and Jornell Quiambao and Peter Pastor and Linda Luu and Kuang-Huei Lee and Yuheng Kuang and Sally Jesmonth and Nikhil J Joshi and Kyle Jeffrey and Rosario Jauregui Ruano and Jasmine Hsu and Keerthana Gopalakrishnan and Byron David and Andy Zeng and Chuyuan Kelly Fu"
      },
      {
        "title": "Palm-e: An embodied multimodal language model",
        "abstract": "Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.",
        "year": 2023,
        "authors": "Danny Driess and Fei Xia and Mehdi SM Sajjadi and Corey Lynch and Aakanksha Chowdhery and Ayzaan Wahid and Jonathan Tompson and Quan Vuong and Tianhe Yu and Wenlong Huang and Yevgen Chebotar and Pierre Sermanet and Daniel Duckworth and Sergey Levine and Vincent Vanhoucke and Karol Hausman and Marc Toussaint and Klaus Greff and Andy Zeng and Igor Mordatch and Pete Florence"
      },
      {
        "title": "Rt-2: Vision-language-action models transfer web knowledge to robotic control",
        "abstract": "We study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robotic trajectory data and Internet-scale vision-language tasks, such as visual question answering. In contrast to other approaches, we propose a simple, general recipe to achieve this goal: in order to fit both natural language responses and robotic actions into the same format, we express the actions as text tokens and incorporate them directly into the training set of the model in the same way as natural language tokens. We refer to such category of models as vision-language-action models (VLA) and instantiate an example of such a model, which we call RT-2. Our extensive evaluation (6k evaluation trials) shows that our approach leads to performant robotic policies and enables RT-2 to obtain a range of emergent capabilities from Internet-scale training. This includes significantly improved generalization to novel objects, the ability to interpret commands not present in the robot training data (such as placing an object onto a particular number or icon), and the ability to perform rudimentary reasoning in response to user commands (such as picking up the smallest or largest object, or the one closest to another object). We further show that incorporating chain of …",
        "year": 2023,
        "authors": "Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Xi Chen and Krzysztof Choromanski and Tianli Ding and Danny Driess and Avinava Dubey and Chelsea Finn and Pete Florence and Chuyuan Fu and Montse Gonzalez Arenas and Keerthana Gopalakrishnan and Kehang Han and Karol Hausman and Alexander Herzog and Jasmine Hsu and Brian Ichter and Alex Irpan and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Lisa Lee and Tsang-Wei Edward Lee and Sergey Levine and Yao Lu and Henryk Michalewski and Igor Mordatch and Karl Pertsch and Kanishka Rao and Krista Reymann and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Pierre Sermanet and Jaspiar Singh and Anikait Singh and Radu Soricut and Huong Tran and Vincent Vanhoucke and Quan Vuong and Ayzaan Wahid and Stefan Welker and Paul Wohlhart and Jialin Wu and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich"
      }
    ],
    "BgQkdsYAAAAJ": [
      {
        "title": "Bridging offline reinforcement learning and imitation learning: A tale of pessimism",
        "abstract": "Offline (or batch) reinforcement learning (RL) algorithms seek to learn an optimal policy from a fixed dataset without active data collection. Based on the composition of the offline dataset, two main methods are used: imitation learning which is suitable for expert datasets, and vanilla offline RL which often requires uniform coverage datasets. From a practical standpoint, datasets often deviate from these two extremes and the exact data composition is usually unknown. To bridge this gap, we present a new offline RL framework that smoothly interpolates between the two extremes of data composition, hence unifying imitation learning and vanilla offline RL. The new framework is centered around a weak version of the concentrability coefficient that measures the deviation of the behavior policy from the expert policy alone. Under this new framework, we ask: can one develop an algorithm that achieves a minimax optimal rate adaptive to unknown data composition? To address this question, we consider a lower confidence bound (LCB) algorithm developed based on pessimism in the face of uncertainty in offline RL. We study finite-sample properties of LCB as well as information-theoretic limits in multi-armed bandits, contextual bandits, and Markov decision processes (MDPs). Our analysis reveals surprising facts about optimality rates. In particular, in both contextual bandits and RL, LCB achieves a faster rate of  for nearly-expert datasets compared to the usual rate of  in offline RL, where  is the batch dataset sample size. In contextual bandits with at least two contexts, we prove that LCB is adaptively optimal for the entire data composition …",
        "year": 2021,
        "authors": "Paria Rashidinejad and Banghua Zhu and Cong Ma and Jiantao Jiao and Stuart Russell"
      },
      {
        "title": "MADE: Exploration via maximizing deviation from explored regions",
        "abstract": "In online reinforcement learning (RL), efficient exploration remains particularly challenging in high-dimensional environments with sparse rewards. In low-dimensional environments, where tabular parameterization is possible, count-based upper confidence bound (UCB) exploration methods achieve minimax near-optimal rates. However, it remains unclear how to efficiently implement UCB in realistic RL tasks that involve non-linear function approximation. To address this, we propose a new exploration approach via maximizing the deviation of the occupancy of the next policy from the explored regions. We add this term as an adaptive regularizer to the standard RL objective to balance exploration vs. exploitation. We pair the new objective with a provably convergent algorithm, giving rise to a new intrinsic reward that adjusts existing bonuses. The proposed intrinsic reward is easy to implement and combine with other existing RL algorithms to conduct exploration. As a proof of concept, we evaluate the new intrinsic reward on tabular examples across a variety of model-based and model-free algorithms, showing improvements over count-only exploration strategies. When tested on navigation and locomotion tasks from MiniGrid and DeepMind Control Suite benchmarks, our approach significantly improves sample efficiency over state-of-the-art methods.",
        "year": 2021,
        "authors": "Tianjun Zhang* and Paria Rashidinejad* and Jiantao Jiao and Yuandong Tian and Joseph Gonzalez and Stuart Russell"
      },
      {
        "title": "Optimal conservative offline RL with general function approximation via augmented Lagrangian",
        "abstract": "Offline reinforcement learning (RL), which refers to decision-making from a previously-collected dataset of interactions, has received significant attention over the past years. Much effort has focused on improving offline RL practicality by addressing the prevalent issue of partial data coverage through various forms of conservative policy learning. While the majority of algorithms do not have finite-sample guarantees, several provable conservative offline RL algorithms are designed and analyzed within the single-policy concentrability framework that handles partial coverage. Yet, in the nonlinear function approximation setting where confidence intervals are difficult to obtain, existing provable algorithms suffer from computational intractability, prohibitively strong assumptions, and suboptimal statistical rates. In this paper, we leverage the marginalized importance sampling (MIS) formulation of RL and present the first set of offline RL algorithms that are statistically optimal and practical under general function approximation and single-policy concentrability, bypassing the need for uncertainty quantification. We identify that the key to successfully solving the sample-based approximation of the MIS problem is ensuring that certain occupancy validity constraints are nearly satisfied. We enforce these constraints by a novel application of the augmented Lagrangian method and prove the following result: with the MIS formulation, augmented Lagrangian is enough for statistically optimal offline RL. In stark contrast to prior algorithms that induce additional conservatism through methods such as behavior regularization, our approach provably eliminates this need …",
        "year": 2023,
        "authors": "Paria Rashidinejad and Hanlin Zhu and Kunhe Yang and Stuart Russell and Jiantao Jiao"
      }
    ],
    "IzUjvBYAAAAJ": [
      {
        "title": "Efficient sampling and compressive sensing for urban monitoring vehicular sensor networks",
        "abstract": "Vehicular sensor network (VSN) using vehicle-based sensors is an emerging technology that can provide an inexpensive solution for surveillance and urban monitoring applications. For the constantly moving vehicles, resulting in unpredictable network topology, data transmission in VSN is vulnerable to packet losses, thus deteriorating the surveillance quality. To resolve this problem, a cooperative data sampling and compression approach is proposed. Based on compressive sensing, this approach does not require inter-sensor communication and adopts sparse random projections to remove redundancy in spatially neighbouring measurements. It is experimentally shown that the proposed algorithm provides fairly accurate reconstruction of the field under surveillance, and incurs much less communication traffic load compared to conventional sampling strategies. Practical data sets, including the temperature …",
        "year": 2012,
        "authors": "X Yu and Y Liu and Y Zhu and W Feng and L Zhang and Habib F Rashvand and Victor OK Li"
      },
      {
        "title": "Optimal scheduling for multi-flow update in software-defined networks",
        "abstract": "Aiming to adapt various traffic dynamics, deal with network errors, perform planned maintenance, etc., flow update is carried out frequently in Software-Defined Networks (SDNs) to adjust network configurations, and how to update the flows successfully is an important and challenging problem. Due to the resource constraints of network links and switches, the update of multiple flows can cause transient congestion which degrades network performance if they are not scheduled carefully. In this work, we address the multi-flow update sequence scheduling problem by formulating it as an optimization problem. Considering the limitations of link bandwidth and flow table size, we find the optimal flow update sequence with efficient resource utilization. By extensive simulations under real network settings, we demonstrate the effectiveness of our algorithm, which achieves smaller flow table usage, and increases the update …",
        "year": 2015,
        "authors": "Yujie Liu and Yong Li and Yue Wang and Jian Yuan"
      },
      {
        "title": "Scheduling multi-flow network updates in Software-Defined NFV systems",
        "abstract": "Combining Network Functions Virtualization (NFV) with Software-Defined Networking (SDN) is an emerging solution to provide fine-grained control over scalable and elastic packet processing functions. Due to changes in network policy, traffic characteristics, or physical topology in Software-Defined NFV (SDNFV) systems, the controller needs to carry out network updates frequently, i.e., change the data plane configuration from one state to another. In order to adapt to a newly desired network state quickly, the network update process is expected to be completed in the shortest time possible. However, the update scheduling schemes need to address resource constraints including flow table sizes, CPU capacities of Virtualized Network Functions (VNFs) and link bandwidths, which are closely coupled. Thus, the problem is difficult to solve, especially when multiple flows are involved in the network update. In this work …",
        "year": 2016,
        "authors": "Yujie Liu and Yong Li and Marco Canini and Yue Wang and Jian Yuan"
      }
    ],
    "U_Jw8DUAAAAJ": [
      {
        "title": "Joint training of a convolutional network and a graphical model for human pose estimation",
        "abstract": "This paper proposes a new hybrid architecture that consists of a deep Convolutional Network and a Markov Random Field. We show how this architecture is successfully applied to the challenging problem of articulated human pose estimation in monocular images. The architecture can exploit structural domain constraints such as geometric relationships between body joint locations. We show that joint training of these two model paradigms improves performance and allows us to significantly outperform existing state-of-the-art techniques.",
        "year": 2014,
        "authors": "Jonathan J Tompson and Arjun Jain and Yann LeCun and Christoph Bregler"
      },
      {
        "title": "Palm-e: An embodied multimodal language model",
        "abstract": "Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.",
        "year": 2023,
        "authors": "Danny Driess and Fei Xia and Mehdi SM Sajjadi and Corey Lynch and Aakanksha Chowdhery and Ayzaan Wahid and Jonathan Tompson and Quan Vuong and Tianhe Yu and Wenlong Huang and Yevgen Chebotar and Pierre Sermanet and Daniel Duckworth and Sergey Levine and Vincent Vanhoucke and Karol Hausman and Marc Toussaint and Klaus Greff and Andy Zeng and Igor Mordatch and Pete Florence"
      },
      {
        "title": "Efficient object localization using convolutional networks",
        "abstract": "Recent state-of-the-art performance on human-body pose estimation has been achieved with Deep Convolutional Networks (ConvNets). Traditional ConvNet architectures include pooling and sub-sampling layers which reduce computational requirements, introduce invariance and prevent over-training. These benefits of pooling come at the cost of reduced localization accuracy. We introduce a novel architecture which includes an efficientposition refinement'model that is trained to estimate the joint offset location within a small region of the image. This refinement model is jointly trained in cascade with a state-of-the-art ConvNet model to achieve improved accuracy in human joint location estimation. We show that the variance of our detector approaches the variance of human annotations on the FLIC dataset and outperforms all existing approaches on the MPII-human-pose dataset.",
        "year": 2015,
        "authors": "Jonathan Tompson and Ross Goroshin and Arjun Jain and Yann LeCun and Christoph Bregler"
      }
    ],
    "UnEHCNkAAAAJ": [
      {
        "title": "Maximizing Social Influence in Nearly Optimal Time.",
        "abstract": "Diffusion is a fundamental graph process, underpinning such phenomena as epidemic disease contagion and the spread of innovation by word-of-mouth. We address the algorithmic problem of finding a set of k initial seed nodes in a network so that the expected size of the resulting cascade is maximized, under the standard independent cascade model of network diffusion. Runtime is a primary consideration for this problem due to the massive size of the relevant input networks.We provide a fast algorithm for the influence maximization problem, obtaining the near-optimal approximation factor of , for any ∊ > 0, in time O((m + n)∊−3 log n). Our algorithm is runtime-optimal (up to a logarithmic factor) and substantially improves upon the previously best-known algorithms which run in time Ω(mnk · POLY(∊−1)). Furthermore, our algorithm can be modified to allow early termination: if it is terminated after O(β(m + n) logn …",
        "year": 2014,
        "authors": "Christian Borgs and Michael Brautbar and Jennifer T Chayes and Brendan Lucier"
      },
      {
        "title": "The power of local information in social networks",
        "abstract": "We study the power of local information algorithms for optimization problems on social and technological networks. We focus on sequential algorithms where the network topology is initially unknown and is revealed only within a local neighborhood of vertices that have been irrevocably added to the output set. This framework models the behavior of an external agent that does not have direct access to the network data, such as a user interacting with an online social network.We study a range of problems under this model of algorithms with local information. When the underlying graph is a preferential attachment network, we show that one can find the root (i.e. initial node) in a polylogarithmic number of steps, using a local algorithm that repeatedly queries the visible node of maximum degree. This addresses an open question of Bollobás and Riordan. This result is motivated by its implications: we …",
        "year": 2012,
        "authors": "Christian Borgs and Michael Brautbar and Jennifer Chayes and Sanjeev Khanna and Brendan Lucier"
      },
      {
        "title": "Local algorithms for finding interesting individuals in large networks",
        "abstract": "We initiate the study of local, sublinear time algorithms for finding vertices with extreme topological properties—such as high degree or clustering coefficient—in large social or other networks. We introduce a new model, called the Jump and Crawl model, in which algorithms are permitted only two graph operations. The Jump operation returns a randomly chosen vertex, and is meant to model the ability to discover “new” vertices via keyword search in the Web, shared hobbies or interests in social networks such as Facebook, and other mechanisms that may return vertices that are distant from all those currently known. The Crawl operation permits an algorithm to explore the neighbors of any currently known vertex, and has clear analogous in many modern networks. We give both upper and lower bounds in the Jump and Crawl model for the problems of finding vertices of high degree and high clustering coefficient. We consider both arbitrary graphs, and specializations in which some common assumptions are made on the global topology (such as power law degree distributions or generation via preferential attachment). We also examine local algorithms for some related vertex or graph properties, and discuss areas for future investigation.",
        "year": 2010,
        "authors": "Michael Brautbar and Michael J Kearns"
      }
    ],
    "KgZxzjsAAAAJ": [
      {
        "title": "Robust face recognition via sparse representation",
        "abstract": "We consider the problem of automatically recognizing human faces from frontal views with varying expression and illumination, as well as occlusion and disguise. We cast the recognition problem as one of classifying among multiple linear regression models and argue that new theory from sparse signal representation offers the key to addressing this problem. Based on a sparse representation computed by \\ell^{1}-minimization, we propose a general classification algorithm for (image-based) object recognition. This new framework provides new insights into two crucial issues in face recognition: feature extraction and robustness to occlusion. For feature extraction, we show that if sparsity in the recognition problem is properly harnessed, the choice of features is no longer critical. What is critical, however, is whether the number of features is sufficiently large and whether the sparse representation is correctly …",
        "year": 2008,
        "authors": "John Wright and Allen Y Yang and Arvind Ganesh and S Shankar Sastry and Yi Ma"
      },
      {
        "title": "A mathematical introduction to robotic manipulation",
        "abstract": "A Mathematical Introduction to Robotic Manipulation presents a mathematical formulation of the kinematics, dynamics, and control of robot manipulators. It uses an elegant set of mathematical tools that emphasizes the geometry of robot motion and allows a large class of robotic manipulation problems to be analyzed within a unified framework. The foundation of the book is a derivation of robot kinematics using the product of the exponentials formula. The authors explore the kinematics of open-chain manipulators and multifingered robot hands, present an analysis of the dynamics and control of robot systems, discuss the specification and control of internal forces and internal motions, and address the implications of the nonholonomic nature of rolling contact are addressed, as well. The wealth of information, numerous examples, and exercises make A Mathematical Introduction to Robotic Manipulation valuable as …",
        "year": 2017,
        "authors": "Richard M Murray and Zexiang Li and S Shankar Sastry"
      },
      {
        "title": "Adaptive control: stability, convergence and robustness",
        "abstract": "With a focus on linear, continuous time, single-input, single-output systems, this volume surveys the major results and techniques of analysis in the field of adaptive control. The authors offer a clear, conceptual presentation of adaptive methods, enabling a critical evaluation of these techniques and suggesting avenues of further development. A brief historical overview of adaptive control is followed by a review of mathematical preliminaries and the development of several adaptive identification algorithms. Succeeding chapters examine averaging techniques, the robustness of adaptive schemes, and advanced topics—including the use of prior information and multivariable adaptive control—followed by a concise introduction to the control of a class of nonlinear systems. The treatment is largely self-contained, assuming only some graduate-level background in basic control systems and in linear systems theory.",
        "year": 2011,
        "authors": "Shankar Sastry and Marc Bodson"
      }
    ],
    "5Iqe53IAAAAJ": [
      {
        "title": "Probabilistic graphical models: principles and techniques",
        "abstract": "A general framework for constructing and using probabilistic models of complex systems that would enable a computer to use available information for making decisions. Most tasks require a person or an automated system to reason—to reach conclusions based on available information. The framework of probabilistic graphical models, presented in this book, provides a general approach for this task. The approach is model-based, allowing interpretable models to be constructed and then manipulated by reasoning algorithms. These models can also be learned automatically from data, allowing the approach to be used in cases where manually constructing a model is difficult or even impossible. Because uncertainty is an inescapable aspect of most real-world applications, the book focuses on probabilistic models, which make the uncertainty explicit and provide models that are more faithful to reality. Probabilistic Graphical Models discusses a variety of models, spanning Bayesian networks, undirected Markov networks, discrete and continuous models, and extensions to deal with dynamical systems and relational data. For each class of models, the text describes the three fundamental cornerstones: representation, inference, and learning, presenting both basic concepts and advanced techniques. Finally, the book considers the use of the proposed framework for causal reasoning and decision making under uncertainty. The main text in each chapter provides the detailed technical development of the key ideas. Most chapters also include boxes with additional material: skill boxes, which describe techniques; case study boxes, which discuss …",
        "year": 2009,
        "authors": "Daphne Koller and Nir Friedman"
      },
      {
        "title": "The genotype-tissue expression (GTEx) project",
        "abstract": "Genome-wide association studies have identified thousands of loci for common diseases, but, for the majority of these, the mechanisms underlying disease susceptibility remain unknown. Most associated variants are not correlated with protein-coding changes, suggesting that polymorphisms in regulatory regions probably contribute to many disease phenotypes. Here we describe the Genotype-Tissue Expression (GTEx) project, which will establish a resource database and associated tissue bank for the scientific community to study the relationship between genetic variation and gene expression in human tissues.",
        "year": 2013,
        "authors": "John Lonsdale and Jeffrey Thomas and Mike Salvatore and Rebecca Phillips and Edmund Lo and Saboor Shad and Richard Hasz and Gary Walters and Fernando Garcia and Nancy Young and Barbara Foster and Mike Moser and Ellen Karasik and Bryan Gillard and Kimberley Ramsey and Susan Sullivan and Jason Bridge and Harold Magazine and John Syron and Johnelle Fleming and Laura Siminoff and Heather Traino and Maghboeba Mosavel and Laura Barker and Scott Jewell and Dan Rohrer and Dan Maxim and Dana Filkins and Philip Harbach and Eddie Cortadillo and Bree Berghuis and Lisa Turner and Eric Hudson and Kristin Feenstra and Leslie Sobin and James Robb and Phillip Branton and Greg Korzeniewski and Charles Shive and David Tabor and Liqun Qi and Kevin Groch and Sreenath Nampally and Steve Buia and Angela Zimmerman and Anna Smith and Robin Burges and Karna Robinson and Kim Valentino and Deborah Bradbury and Mark Cosentino and Norma Diaz-Mayoral and Mary Kennedy and Theresa Engel and Penelope Williams and Kenyon Erickson and Kristin Ardlie and Wendy Winckler and Gad Getz and David DeLuca and Daniel MacArthur and Manolis Kellis and Alexander Thomson and Taylor Young and Ellen Gelfand and Molly Donovan and Yan Meng and George Grant and Deborah Mash and Yvonne Marcus and Margaret Basile and Jun Liu and Jun Zhu and Zhidong Tu and Nancy J Cox and Dan L Nicolae and Eric R Gamazon and Hae Kyung Im and Anuar Konkashbaev and Jonathan Pritchard and Matthew Stevens and Timothèe Flutre and Xiaoquan Wen and Emmanouil T Dermitzakis and Tuuli Lappalainen and Roderic Guigo and Jean Monlong and Michael Sammeth and Daphne Koller and Alexis Battle and Sara Mostafavi and Mark McCarthy and Manual Rivas and Julian Maller and Ivan Rusyn and Andrew Nobel and Fred Wright and Andrey Shabalin and Mike Feolo and Nataliya Sharopova and Anne Sturcke and Justin Paschal and James M Anderson and Elizabeth L Wilder and Leslie K Derr and Eric D Green and Jeffery P Struewing and Gary Temple and Simona Volpi and Joy T Boyer and Elizabeth J Thomson and Mark S Guyer and Cathy Ng and Assya Abdallah and Deborah Colantuoni and Thomas R Insel and Susan E Koester and A Roger Little and Patrick K Bender and Thomas Lehner and Yin Yao and Carolyn C Compton and Jimmie B Vaught and Sherilyn Sawyer and Nicole C Lockhart and Joanne Demchok and Helen F Moore"
      },
      {
        "title": "The Genotype-Tissue Expression (GTEx) pilot analysis: multitissue gene regulation in humans",
        "abstract": "Understanding the functional consequences of genetic variation, and how it affects complex human disease and quantitative traits, remains a critical challenge for biomedicine. We present an analysis of RNA sequencing data from 1641 samples across 43 tissues from 175 individuals, generated as part of the pilot phase of the Genotype-Tissue Expression (GTEx) project. We describe the landscape of gene expression across tissues, catalog thousands of tissue-specific and shared regulatory expression quantitative trait loci (eQTL) variants, describe complex network relationships, and identify signals from genome-wide association studies explained by eQTLs. These findings provide a systematic understanding of the cellular and biological consequences of human genetic variation and of the heterogeneity of such effects among a diverse set of human tissues.",
        "year": 2015,
        "authors": "GTEx Consortium and Kristin G Ardlie and David S Deluca and Ayellet V Segrè and Timothy J Sullivan and Taylor R Young and Ellen T Gelfand and Casandra A Trowbridge and Julian B Maller and Taru Tukiainen and Monkol Lek and Lucas D Ward and Pouya Kheradpour and Benjamin Iriarte and Yan Meng and Cameron D Palmer and Tõnu Esko and Wendy Winckler and Joel N Hirschhorn and Manolis Kellis and Daniel G MacArthur and Gad Getz and Andrey A Shabalin and Gen Li and Yi-Hui Zhou and Andrew B Nobel and Ivan Rusyn and Fred A Wright and Tuuli Lappalainen and Pedro G Ferreira and Halit Ongen and Manuel A Rivas and Alexis Battle and Sara Mostafavi and Jean Monlong and Michael Sammeth and Marta Mele and Ferran Reverter and Jakob M Goldmann and Daphne Koller and Roderic Guigó and Mark I McCarthy and Emmanouil T Dermitzakis and Eric R Gamazon and Hae Kyung Im and Anuar Konkashbaev and Dan L Nicolae and Nancy J Cox and Timothée Flutre and Xiaoquan Wen and Matthew Stephens and Jonathan K Pritchard and Zhidong Tu and Bin Zhang and Tao Huang and Quan Long and Luan Lin and Jialiang Yang and Jun Zhu and Jun Liu and Amanda Brown and Bernadette Mestichelli and Denee Tidwell and Edmund Lo and Mike Salvatore and Saboor Shad and Jeffrey A Thomas and John T Lonsdale and Michael T Moser and Bryan M Gillard and Ellen Karasik and Kimberly Ramsey and Christopher Choi and Barbara A Foster and John Syron and Johnell Fleming and Harold Magazine and Rick Hasz and Gary D Walters and Jason P Bridge and Mark Miklos and Susan Sullivan and Laura K Barker and Heather M Traino and Maghboeba Mosavel and Laura A Siminoff and Dana R Valley and Daniel C Rohrer and Scott D Jewell and Philip A Branton and Leslie H Sobin and Mary Barcus and Liqun Qi and Jeffrey McLean and Pushpa Hariharan and Ki Sung Um and Shenpei Wu and David Tabor and Charles Shive and Anna M Smith and Stephen A Buia and Anita H Undale and Karna L Robinson and Nancy Roche and Kimberly M Valentino and Angela Britton and Robin Burges and Debra Bradbury and Kenneth W Hambright and John Seleski and Greg E Korzeniewski and Kenyon Erickson and Yvonne Marcus and Jorge Tejada and Mehran Taherian and Chunrong Lu and Margaret Basile and Deborah C Mash and Simona Volpi and Jeffery P Struewing and Gary F Temple and Joy Boyer and Deborah Colantuoni and Roger Little and Susan Koester and Latarsha J Carithers and Helen M Moore and Ping Guan and Carolyn Compton and Sherilyn J Sawyer and Joanne P Demchok and Jimmie B Vaught and Chana A Rabiner and Nicole C Lockhart and Kristin G Ardlie and Gad Getz and Fred A Wright and Manolis Kellis and Simona Volpi and Emmanouil T Dermitzakis"
      }
    ],
    "wb-DKCIAAAAJ": [
      {
        "title": "Gaussian process optimization in the bandit setting: No regret and experimental design",
        "abstract": "Many applications require optimizing an unknown, noisy function that is expensive to evaluate. We formalize this task as a multi-armed bandit problem, where the payoff function is either sampled from a Gaussian process (GP) or has low RKHS norm. We resolve the important open problem of deriving regret bounds for this setting, which imply novel convergence rates for GP optimization. We analyze GP-UCB, an intuitive upper-confidence based algorithm, and bound its cumulative regret in terms of maximal information gain, establishing a novel connection between GP optimization and experimental design. Moreover, by bounding the latter in terms of operator spectra, we obtain explicit sublinear regret bounds for many commonly used covariance functions. In some important cases, our bounds have surprisingly weak dependence on the dimensionality. In our experiments on real sensor data, GP-UCB compares favorably with other heuristical GP optimization approaches.",
        "year": 2009,
        "authors": "Niranjan Srinivas and Andreas Krause and Sham M Kakade and Matthias Seeger"
      },
      {
        "title": "A natural policy gradient",
        "abstract": "We provide a natural gradient method that represents the steepest descent direction based on the underlying structure of the param (cid: 173) eter space. Although gradient methods cannot make large changes in the values of the parameters, we show that the natural gradi (cid: 173) ent is moving toward choosing a greedy optimal action rather than just a better action. These greedy optimal actions are those that would be chosen under one improvement step of policy iteration with approximate, compatible value functions, as defined by Sut (cid: 173) ton et al.[9]. We then show drastic performance improvements in simple MDPs and in the more challenging MDP of Tetris.",
        "year": 2001,
        "authors": "Sham Kakade"
      },
      {
        "title": "Approximately optimal approximate reinforcement learning",
        "abstract": "Approximately Optimal Approximate Reinforcement Learning | Proceedings of the Nineteenth \nInternational Conference on Machine Learning skip to main content ACM Digital Library home \nACM Association for Computing Machinery corporate logo Google, Inc. (search) Advanced \nSearch Browse About Sign in Register Advanced Search Journals Magazines Proceedings \nBooks SIGs Conferences People More Search ACM Digital Library SearchSearch Advanced \nSearch Browse Browse Digital Library Collections More Home Browse by Title Proceedings \nICML '02 Approximately Optimal Approximate Reinforcement Learning Article Share on \nApproximately Optimal Approximate Reinforcement Learning Authors: Sham Kakade, John \nLangfordAuthors Info & Claims ICML '02: Proceedings of the Nineteenth International Conference \non Machine Learning Pages 267 - 274 Published: 08 July 2002 Publication History 102…",
        "year": 2002,
        "authors": "Sham Kakade and John Langford"
      }
    ],
    "tcfl2hUAAAAJ": [
      {
        "title": "The False Promise of Imitating Proprietary LLMs",
        "abstract": "An emerging method to cheaply improve a weaker language model is to finetune it on outputs from a stronger model, such as a proprietary system like ChatGPT (e.g., Alpaca, Self-Instruct, and others). This approach looks to cheaply imitate the proprietary model's capabilities using a weaker open-source model. In this work, we critically analyze this approach. We first finetune a series of LMs that imitate ChatGPT using varying base model sizes (1.5B--13B), data sources, and imitation data amounts (0.3M--150M tokens). We then evaluate the models using crowd raters and canonical NLP benchmarks. Initially, we were surprised by the output quality of our imitation models -- they appear far better at following instructions, and crowd workers rate their outputs as competitive with ChatGPT. However, when conducting more targeted automatic evaluations, we find that imitation models close little to none of the gap from the base LM to ChatGPT on tasks that are not heavily supported in the imitation data. We show that these performance discrepancies may slip past human raters because imitation models are adept at mimicking ChatGPT's style but not its factuality. Overall, we conclude that model imitation is a false promise: there exists a substantial capabilities gap between open and closed LMs that, with current methods, can only be bridged using an unwieldy amount of imitation data or by using more capable base LMs. In turn, we argue that the highest leverage action for improving open-source models is to tackle the difficult challenge of developing better base LMs, rather than taking the shortcut of imitating proprietary systems.",
        "year": 2023,
        "authors": "Arnav Gudibande and Eric Wallace and Charlie Snell and Xinyang Geng and Hao Liu and Pieter Abbeel and Sergey Levine and Dawn Song"
      },
      {
        "title": "Test-time Adaptation of Residual Blocks against Poisoning and Backdoor Attacks",
        "abstract": "Data poisoning has become a major security threat for deep neural networks, where the attacker injects maliciously crafted poisoning samples into the training set to mislead the model prediction. Numerous poisoning attack strategies have been proposed recently, which are mostly able to alter the model behavior or embed backdoors with a small number of poisoning samples. Current defenses for these attacks either do not generalize to diverse threat models or suffer from a huge computational cost. In this work, we propose ReScaler, a parameter-efficient defense that adapts the residual blocks at the test time. Specifically, ReScaler learns a scalar for each residual connection to downweight potentially redundant non-linear transformations, in favor of the features propagated through the skip connections. Our evaluation on several state-of-theart poisoning attacks and different residual networks shows that ReScaler effectively defends against different attack algorithms, without introducing significant computational overhead. Our test-time adaptation scheme introduces a novel way of approaching defenses for poisoning and backdoor attacks, and also brings up broader questions about the connection between the architectural design and the vulnerability against attacks. 1",
        "year": 2022,
        "authors": "Arnav Gudibande and Xinyun Chen and Yang Bai and Jason Xiong and Dawn Song"
      }
    ],
    "_koixUEAAAAJ": [
      {
        "title": "Estimation and inference of heterogeneous treatment effects using random forests",
        "abstract": "Many scientific and engineering challenges—ranging from personalized medicine to customized marketing recommendations—require an understanding of treatment effect heterogeneity. In this article, we develop a nonparametric causal forest for estimating heterogeneous treatment effects that extends Breiman’s widely used random forest algorithm. In the potential outcomes framework with unconfoundedness, we show that causal forests are pointwise consistent for the true treatment effect and have an asymptotically Gaussian and centered sampling distribution. We also discuss a practical method for constructing asymptotic confidence intervals for the true treatment effect that are centered at the causal forest estimates. Our theoretical results rely on a generic Gaussian theory for a large family of random forest algorithms. To our knowledge, this is the first set of results that allows any type of random forest …",
        "year": 2018,
        "authors": "Stefan Wager and Susan Athey"
      },
      {
        "title": "Generalized random forests",
        "abstract": "Supplement to “Generalized random forests”. The supplement ontains proofs of technical results, as well as a simulation study for instrumental variables regression with forests.",
        "year": 2019,
        "authors": "Susan Athey and Julie Tibshirani and Stefan Wager"
      },
      {
        "title": "Synthetic difference-in-differences",
        "abstract": "We present a new estimator for causal effects with panel data that builds on insights behind the widely used difference-in-differences and synthetic control methods. Relative to these methods we find, both theoretically and empirically, that this “synthetic difference-in-differences” estimator has desirable robustness properties, and that it performs well in settings where the conventional estimators are commonly used in practice. We study the asymptotic behavior of the estimator when the systematic part of the outcome model includes latent unit factors interacted with latent time factors, and we present conditions for consistency and asymptotic normality. (JEL C23, H25, H71, I18, L66)",
        "year": 2021,
        "authors": "Dmitry Arkhangelsky and Susan Athey and David A Hirshberg and Guido W Imbens and Stefan Wager"
      }
    ],
    "CgItEbQAAAAJ": [
      {
        "title": "Making ai forget you: Data deletion in machine learning",
        "abstract": "Intense recent discussions have focused on how to provide individuals with control over when their data can and cannot be used---the EU’s Right To Be Forgotten regulation is an example of this effort. In this paper we initiate a framework studying what to do when it is no longer permissible to deploy models derivative from specific user data. In particular, we formulate the problem of efficiently deleting individual data points from trained machine learning models. For many standard ML models, the only way to completely remove an individual's data is to retrain the whole model from scratch on the remaining data, which is often not computationally practical. We investigate algorithmic principles that enable efficient data deletion in ML. For the specific setting of -means clustering, we propose two provably deletion efficient algorithms which achieve an average of over  improvement in deletion efficiency across 6 datasets, while producing clusters of comparable statistical quality to a canonical -means++ baseline.",
        "year": 2019,
        "authors": "Antonio Ginart and Melody Guan and Gregory Valiant and James Y Zou"
      },
      {
        "title": "What can transformers learn in-context? a case study of simple function classes",
        "abstract": "In-context learning is the ability of a model to condition on a prompt sequence consisting of in-context examples (input-output pairs corresponding to some task) along with a new query input, and generate the corresponding output. Crucially, in-context learning happens only at inference time without any parameter updates to the model. While large language models such as GPT-3 exhibit some ability to perform in-context learning, it is unclear what the relationship is between tasks on which this succeeds and what is present in the training data. To investigate this, we consider the problem of training a model to in-context learn a function class (eg, linear functions): given data derived from some functions in the class, can we train a model (eg, a Transformer) to in-context learn most functions from that class? We show empirically that standard Transformers can be trained from scratch to perform in-context learning of linear functions---that is, the trained model is able to learn unseen linear functions from in-context examples with performance comparable to the optimal least squares estimator. In fact, in-context learning is possible even under two forms of distribution shift:(i) between the training data of the Transformer and inference-time prompts, and (ii) between the in-context examples and the query input during inference. We also show that we can train Transformers to in-context learn more complex function classes: sparse linear functions where the model outperforms least squares and nearly matches the performance of Lasso, and two-layer neural networks where the model performs comparably to neural networks trained on in-context examples …",
        "year": 2022,
        "authors": "Shivam Garg and Dimitris Tsipras and Percy S Liang and Gregory Valiant"
      },
      {
        "title": "Settling the polynomial learnability of mixtures of gaussians",
        "abstract": "Given data drawn from a mixture of multivariate Gaussians, a basic problem is to accurately estimate the mixture parameters. We give an algorithm for this problem that has running time and data requirements polynomial in the dimension and the inverse of the desired accuracy, with provably minimal assumptions on the Gaussians. As a simple consequence of our learning algorithm, we we give the first polynomial time algorithm for proper density estimation for mixtures of k Gaussians that needs no assumptions on the mixture. It was open whether proper density estimation was even statistically possible (with no assumptions) given only polynomially many samples, let alone whether it could be computationally efficient. The building blocks of our algorithm are based on the work (Kalai et al, STOC 2010) that gives an efficient algorithm for learning mixtures of two Gaussians by considering a series of projections down …",
        "year": 2010,
        "authors": "Ankur Moitra and Gregory Valiant"
      }
    ],
    "zFNvU34AAAAJ": [
      {
        "title": "Personality traits in large language models",
        "abstract": "The advent of large language models (LLMs) has revolutionized natural language processing, enabling the generation of coherent and contextually relevant text. As LLMs increasingly power conversational agents, the synthetic personality embedded in these models, by virtue of training on large amounts of human data, is becoming increasingly important. Since personality is a key factor determining the effectiveness of communication, we present a comprehensive method for administering and validating personality tests on widely-used LLMs, as well as for shaping personality in the generated text of such LLMs. Applying this method, we found: 1) personality measurements in the outputs of some LLMs under specific prompting configurations are reliable and valid; 2) evidence of reliability and validity of synthetic LLM personality is stronger for larger and instruction fine-tuned models; and 3) personality in LLM outputs can be shaped along desired dimensions to mimic specific personality profiles. We discuss application and ethical implications of the measurement and shaping method, in particular regarding responsible use of LLMs.",
        "year": 2023,
        "authors": "Gregory Serapio-García and Mustafa Safdari and Clément Crepy and Luning Sun and Stephen Fitz and Marwa Abdulhai and Aleksandra Faust and Maja Matarić"
      },
      {
        "title": "Moral Foundations of Large Language Models",
        "abstract": "Moral foundations theory (MFT) is a psychological assessment tool that decomposes human moral reasoning into five factors, including care/harm, liberty/oppression, and sanctity/degradation (Graham et al., 2009). People vary in the weight they place on these dimensions when making moral decisions, in part due to their cultural upbringing and political ideology. As large language models (LLMs) are trained on datasets collected from the internet, they may reflect the biases that are present in such corpora. This paper uses MFT as a lens to analyze whether popular LLMs have acquired a bias towards a particular set of moral values. We analyze known LLMs and find they exhibit particular moral foundations, and show how these relate to human moral foundations and political affiliations. We also measure the consistency of these biases, or whether they vary strongly depending on the context of how the model is prompted. Finally, we show that we can adversarially select prompts that encourage the moral to exhibit a particular set of moral foundations, and that this can affect the model's behavior on downstream tasks. These findings help illustrate the potential risks and unintended consequences of LLMs assuming a particular moral stance.",
        "year": 2022,
        "authors": "Marwa Abdulhai and Clément Crepy and Daria Valter and John Canny and Natasha Jaques"
      },
      {
        "title": "A policy gradient algorithm for learning to learn in multiagent reinforcement learning",
        "abstract": "A fundamental challenge in multiagent reinforcement learning is to learn beneficial behaviors in a shared environment with other simultaneously learning agents. In particular, each agent perceives the environment as effectively non-stationary due to the changing policies of other agents. Moreover, each agent is itself constantly learning, leading to natural non-stationarity in the distribution of experiences encountered. In this paper, we propose a novel meta-multiagent policy gradient theorem that directly accounts for the non-stationary policy dynamics inherent to multiagent learning settings. This is achieved by modeling our gradient updates to consider both an agent’s own non-stationary policy dynamics and the non-stationary policy dynamics of other agents in the environment. We show that our theoretically grounded approach provides a general solution to the multiagent learning problem, which inherently comprises all key aspects of previous state of the art approaches on this topic. We test our method on a diverse suite of multiagent benchmarks and demonstrate a more efficient ability to adapt to new agents as they learn than baseline methods across the full spectrum of mixed incentive, competitive, and cooperative domains.",
        "year": 2021,
        "authors": "Dong Ki Kim and Miao Liu and Matthew D Riemer and Chuangchuang Sun and Marwa Abdulhai and Golnaz Habibi and Sebastian Lopez-Cot and Gerald Tesauro and Jonathan How"
      }
    ],
    "Wd8_fOcAAAAJ": [
      {
        "title": "Gansynth: Adversarial neural audio synthesis",
        "abstract": "Efficient audio synthesis is an inherently difficult machine learning task, as human perception is sensitive to both global structure and fine-scale waveform coherence. Autoregressive models, such as WaveNet, model local structure at the expense of global latent structure and slow iterative sampling, while Generative Adversarial Networks (GANs), have global latent conditioning and efficient parallel sampling, but struggle to generate locally-coherent audio waveforms. Herein, we demonstrate that GANs can in fact generate high-fidelity and locally-coherent audio by modeling log magnitudes and instantaneous frequencies with sufficient frequency resolution in the spectral domain. Through extensive empirical investigations on the NSynth dataset, we demonstrate that GANs are able to outperform strong WaveNet baselines on automated and human evaluation metrics, and efficiently generate audio several orders of magnitude faster than their autoregressive counterparts.",
        "year": 2019,
        "authors": "Jesse Engel and Kumar Krishna Agrawal and Shuo Chen and Ishaan Gulrajani and Chris Donahue and Adam Roberts"
      },
      {
        "title": "Discriminator-actor-critic: Addressing sample inefficiency and reward bias in adversarial imitation learning",
        "abstract": "We identify two issues with the family of algorithms based on the Adversarial Imitation Learning framework. The first problem is implicit bias present in the reward functions used in these algorithms. While these biases might work well for some environments, they can also lead to sub-optimal behavior in others. Secondly, even though these algorithms can learn from few expert demonstrations, they require a prohibitively large number of interactions with the environment in order to imitate the expert for many real-world applications. In order to address these issues, we propose a new algorithm called Discriminator-Actor-Critic that uses off-policy Reinforcement Learning to reduce policy-environment interaction sample complexity by an average factor of 10. Furthermore, since our reward function is designed to be unbiased, we can apply our algorithm to many problems without making any task-specific adjustments.",
        "year": 2018,
        "authors": "Ilya Kostrikov and Kumar Krishna Agrawal and Debidatta Dwibedi and Sergey Levine and Jonathan Tompson"
      },
      {
        "title": "Discrete flows: Invertible generative models of discrete data",
        "abstract": "While normalizing flows have led to significant advances in modeling high-dimensional continuous distributions, their applicability to discrete distributions remains unknown. In this paper, we show that flows can in fact be extended to discrete events---and under a simple change-of-variables formula not requiring log-determinant-Jacobian computations. Discrete flows have numerous applications. We consider two flow architectures: discrete autoregressive flows that enable bidirectionality, allowing, for example, tokens in text to depend on both left-to-right and right-to-left contexts in an exact language model; and discrete bipartite flows that enable efficient non-autoregressive generation as in RealNVP. Empirically, we find that discrete autoregressive flows outperform autoregressive baselines on synthetic discrete distributions, an addition task, and Potts models; and bipartite flows can obtain competitive performance with autoregressive baselines on character-level language modeling for Penn Tree Bank and text8.",
        "year": 2019,
        "authors": "Dustin Tran and Keyon Vafa and Kumar Agrawal and Laurent Dinh and Ben Poole"
      }
    ],
    "Q6F3O0sAAAAJ": [
      {
        "title": "Soft actor-critic algorithms and applications",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Learning to walk via deep reinforcement learning",
        "abstract": "Deep reinforcement learning (deep RL) holds the promise of automating the acquisition of complex controllers that can map sensory inputs directly to low-level actions. In the domain of robotic locomotion, deep RL could enable learning locomotion skills with minimal engineering and without an explicit model of the robot dynamics. Unfortunately, applying deep RL to real-world robotic tasks is exceptionally difficult, primarily due to poor sample complexity and sensitivity to hyperparameters. While hyperparameters can be easily tuned in simulated domains, tuning may be prohibitively expensive on physical systems, such as legged robots, that can be damaged through extensive trial-and-error learning. In this paper, we propose a sample-efficient deep RL algorithm based on maximum entropy RL that requires minimal per-task tuning and only a modest number of trials to learn neural network policies. We apply this method to learning walking gaits on a real-world Minitaur robot. Our method can acquire a stable gait from scratch directly in the real world in about two hours, without relying on any model or simulation, and the resulting policy is robust to moderate variations in the environment. We further show that our algorithm achieves state-of-the-art performance on simulated benchmarks with a single set of hyperparameters. Videos of training and the learned policy can be found on the project website.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Sehoon Ha and Aurick Zhou and Jie Tan and George Tucker and Sergey Levine"
      },
      {
        "title": "Dart: Dynamic animation and robotics toolkit",
        "abstract": "DART (Dynamic Animation and Robotics Toolkit) is a collaborative, cross-platform, open source library created by the Graphics Lab and Humanoid Robotics Lab at Georgia Institute of Technology with ongoing contributions from the Personal Robotics Lab at University of Washington and Open Source Robotics Foundation. The library provides data structures and algorithms for kinematic and dynamic applications in robotics and computer animation. DART is distinguished by its accuracy and stability due to its use of generalized coordinates to represent articulated rigid body systems in the geometric notations (Park, Bobrow, and Ploen 1995) and Featherstone’s Articulated Body Algorithm (Featherstone 2008) using a Lie group formulation to compute forward dynamics (Ploen and Park 1999) and hybrid dynamics (Sohl and Bobrow 2001). For developers, in contrast to many popular physics engines which view the simulator as a black box, DART gives full access to internal kinematic and dynamic quantities, such as the mass matrix, Coriolis and centrifugal forces, transformation matrices and their derivatives. DART also provides an efficient computation of Jacobian matrices for arbitrary body points and coordinate frames. The frame semantics of DART allows users to define arbitrary reference frames (both inertial and non-inertial) and use those frames to specify or request data. For air-tight code safety, forward kinematics and dynamics values are updated automatically through lazy evaluation, making DART suitable for real-time controllers. In addition, DART provides flexibility to extend the API for embedding user-provided classes into DART data …",
        "year": 2018,
        "authors": "Jeongseok Lee and Michael X. Grey and Sehoon Ha and Tobias Kunz and Sumit Jain and Yuting Ye and Siddhartha S. Srinivasa and Mike Stilman and C Karen Liu"
      }
    ],
    "f2NAF7QAAAAJ": [
      {
        "title": "Yell at your robot: Improving on-the-fly from language corrections",
        "abstract": "Hierarchical policies that combine language and low-level control have been shown to perform impressively long-horizon robotic tasks, by leveraging either zero-shot high-level planners like pretrained language and vision-language models (LLMs/VLMs) or models trained on annotated robotic demonstrations. However, for complex and dexterous skills, attaining high success rates on long-horizon tasks still represents a major challenge -- the longer the task is, the more likely it is that some stage will fail. Can humans help the robot to continuously improve its long-horizon task performance through intuitive and natural feedback? In this paper, we make the following observation: high-level policies that index into sufficiently rich and expressive low-level language-conditioned skills can be readily supervised with human feedback in the form of language corrections. We show that even fine-grained corrections, such as small movements (\"move a bit to the left\"), can be effectively incorporated into high-level policies, and that such corrections can be readily obtained from humans observing the robot and making occasional suggestions. This framework enables robots not only to rapidly adapt to real-time language feedback, but also incorporate this feedback into an iterative training scheme that improves the high-level policy's ability to correct errors in both low-level execution and high-level decision-making purely from verbal feedback. Our evaluation on real hardware shows that this leads to significant performance improvement in long-horizon, dexterous manipulation tasks without the need for any additional teleoperation. Videos and code are …",
        "year": 2024,
        "authors": "Lucy Xiaoyang Shi and Zheyuan Hu and Tony Z Zhao and Archit Sharma and Karl Pertsch and Jianlan Luo and Sergey Levine and Chelsea Finn"
      },
      {
        "title": "Serl: A software suite for sample-efficient robotic reinforcement learning",
        "abstract": "In recent years, significant progress has been made in the field of robotic reinforcement learning (RL), enabling methods that handle complex image observations, train in the real world, and incorporate auxiliary data, such as demonstrations and prior experience. However, despite these advances, robotic RL remains hard to use. It is acknowledged among practitioners that the particular implementation details of these algorithms are often just as important (if not more so) for performance as the choice of algorithm. We posit that a significant challenge to the widespread adoption of robotic RL, as well as the further development of robotic RL methods, is the comparative inaccessibility of such methods. To address this challenge, we developed a carefully implemented library containing a sample efficient off-policy deep RL method, together with methods for computing rewards and resetting the environment, a high …",
        "year": 2024,
        "authors": "Jianlan Luo and Zheyuan Hu and Charles Xu and You Liang Tan and Jacob Berg and Archit Sharma and Stefan Schaal and Chelsea Finn and Abhishek Gupta and Sergey Levine"
      },
      {
        "title": "Dexterous manipulation from images: Autonomous real-world rl via substep guidance",
        "abstract": "Complex and contact-rich robotic manipulation tasks, particularly those that involve multi-fingered hands and underactuated object manipulation, present a significant challenge to any control method. Methods based on reinforcement learning offer an appealing choice for such settings, as they can enable robots to learn to delicately balance contact forces and dexterously reposition objects without strong modeling assumptions. However, running reinforcement learning on real-world dexterous manipulation systems often requires significant manual engineering. This negates the benefits of autonomous data collection and ease of use that reinforcement learning should in principle provide. In this paper, we describe a system for vision-based dexterous manipulation that provides a “programming-free” approach for users to define new tasks and enable robots with complex multi-fingered hands to learn to perform them …",
        "year": 2023,
        "authors": "Kelvin Xu and Zheyuan Hu and Ria Doshi and Aaron Rovinsky and Vikash Kumar and Abhishek Gupta and Sergey Levine"
      }
    ],
    "rRJ9wTJMUB8C": [
      {
        "title": "A global geometric framework for nonlinear dimensionality reduction",
        "abstract": "Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs—30,000 auditory nerve fibers or 106 optic nerve fibers—a manageably small number of perceptually relevant features. Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex …",
        "year": 2000,
        "authors": "Joshua B Tenenbaum and Vin de Silva and John C Langford"
      },
      {
        "title": "Human-level concept learning through probabilistic program induction",
        "abstract": "People learning new concepts can often generalize successfully from just a single example, yet machine learning algorithms typically require tens or hundreds of examples to perform with similar accuracy. People can also use learned concepts in richer ways than conventional algorithms—for action, imagination, and explanation. We present a computational model that captures these human learning abilities for a large class of simple visual concepts: handwritten characters from the world’s alphabets. The model represents concepts as simple programs that best explain observed examples under a Bayesian criterion. On a challenging one-shot classification task, the model achieves human-level performance while outperforming recent deep learning approaches. We also present several “visual Turing tests” probing the model’s creative generalization abilities, which in many cases are indistinguishable from human …",
        "year": 2015,
        "authors": "Brenden M Lake and Ruslan Salakhutdinov and Joshua B Tenenbaum"
      },
      {
        "title": "Building machines that learn and think like people",
        "abstract": "Recent progress in artificial intelligence has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats that of humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn and how they learn it. Specifically, we argue that these machines should (1) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (2) ground learning in intuitive theories of physics and …",
        "year": 2017,
        "authors": "Brenden M Lake and Tomer D Ullman and Joshua B Tenenbaum and Samuel J Gershman"
      }
    ],
    "9yRwkr4AAAAJ": [
      {
        "title": "Challenges with quality of race and ethnicity data in observational databases",
        "abstract": "We sought to assess the quality of race and ethnicity information in observational health databases, including electronic health records (EHRs), and to propose patient self-recording as an improvement strategy.We assessed completeness of race and ethnicity information in large observational health databases in the United States (Healthcare Cost and Utilization Project and Optum Labs), and at a single healthcare system in New York City serving a racially and ethnically diverse population. We compared race and ethnicity data collected via administrative processes with data recorded directly by respondents via paper surveys (National Health and Nutrition Examination Survey and Hospital Consumer Assessment of Healthcare Providers and Systems). Respondent-recorded data were considered the gold standard for the collection of race and …",
        "year": 2019,
        "authors": "Fernanda CG Polubriaginof and Patrick Ryan and Hojjat Salmasian and Andrea Wells Shapiro and Adler Perotte and Monika M Safford and George Hripcsak and Shaun Smith and Nicholas P Tatonetti and David K Vawdrey"
      },
      {
        "title": "The role of chemoprevention in modifying the risk of breast cancer in women with atypical breast lesions",
        "abstract": "Women with atypical ductal hyperplasia (ADH), atypical lobular hyperplasia (ALH), lobular carcinoma in situ (LCIS), and severe ADH are at increased risk of breast cancer, but a systematic quantification of this risk and the efficacy of chemoprevention in the clinical setting is still lacking. The objective of this study is to evaluate a woman’s risk of breast cancer based on atypia type and to determine the effect of chemoprevention in decreasing this risk. Review of 76,333 breast pathology reports from three institutions within Partners Healthcare System, Boston, from 1987 to 2010 using natural language processing was carried out. This approach identified 2,938 women diagnosed with atypical breast lesions. The main outcome of this study is breast cancer occurrence. Of the 2,938 patients with atypical breast lesions, 1,658 were documented to have received no chemoprevention, and 184/1,658 (11.1 …",
        "year": 2012,
        "authors": "Suzanne B Coopey and Emanuele Mazzola and Julliette M Buckley and John Sharko and Ahmet K Belli and Elizabeth MH Kim and Fernanda Polubriaginof and Giovanni Parmigiani and Judy E Garber and Barbara L Smith and Michele A Gadd and Michelle C Specht and Anthony J Guidi and Constance A Roche and Kevin S Hughes"
      },
      {
        "title": "Using machine learning to parse breast pathology reports",
        "abstract": " Extracting information from electronic medical record is a time-consuming and expensive process when done manually. Rule-based and machine learning techniques are two approaches to solving this problem. In this study, we trained a machine learning model on pathology reports to extract pertinent tumor characteristics, which enabled us to create a large database of attribute searchable pathology reports. This database can be used to identify cohorts of patients with characteristics of interest. We collected a total of 91,505 breast pathology reports from three Partners hospitals: Massachusetts General Hospital, Brigham and Women’s Hospital, and Newton-Wellesley Hospital, covering the period from 1978 to 2016. We trained our system with annotations from two datasets, consisting of 6295 and 10,841 manually annotated reports …",
        "year": 2017,
        "authors": "Adam Yala and Regina Barzilay and Laura Salama and Molly Griffin and Grace Sollender and Aditya Bardia and Constance Lehman and Julliette M Buckley and Suzanne B Coopey and Fernanda Polubriaginof and Judy E Garber and Barbara L Smith and Michele A Gadd and Michelle C Specht and Thomas M Gudewicz and Anthony J Guidi and Alphonse Taghian and Kevin S Hughes"
      }
    ],
    "RU0ZAp4AAAAJ": [
      {
        "title": "Neural joint source-channel coding",
        "abstract": "For reliable transmission across a noisy communication channel, classical results from information theory show that it is asymptotically optimal to separate out the source and channel coding processes. However, this decomposition can fall short in the finite bit-length regime, as it requires non-trivial tuning of hand-crafted codes and assumes infinite computational power for decoding. In this work, we propose to jointly learn the encoding and decoding processes using a new discrete variational autoencoder model. By adding noise into the latent codes to simulate the channel during training, we learn to both compress and error-correct given a fixed bit-length and computational budget. We obtain codes that are not only competitive against several separation schemes, but also learn useful robust representations of the data for downstream tasks such as classification. Finally, inference amortization yields an extremely fast neural decoder, almost an order of magnitude faster compared to standard decoding methods based on iterative belief propagation.",
        "year": 2019,
        "authors": "Kristy Choi and Kedar Tatwawadi and Aditya Grover and Tsachy Weissman and Stefano Ermon"
      },
      {
        "title": "Elf-vc: Efficient learned flexible-rate video coding",
        "abstract": "While learned video codecs have demonstrated great promise, they have yet to achieve sufficient efficiency for practical deployment. In this work, we propose several ideas for learned video compression which allow for improved performance for the low-latency mode (I-and P-frames only) along with a considerable increase in computational efficiency. In this setting, for natural videos our approach compares favorably across the entire RD curve under metrics PSNR, MS-SSIM and VMAF against all mainstream video standards (H. 264, H. 265, AV1) and all ML codecs. At the same time, our approach runs at least 5x faster and has fewer parameters than all ML codecs which report these figures. Our contributions include a flexible-rate framework allowing a single model to cover a large and dense range of bitrates, at a negligible increase in computation and parameter count; an efficient backbone optimized for ML-based codecs; and a novel in-loop flow prediction scheme which leverages prior information towards more efficient compression. We benchmark our method, which we call ELF-VC (Efficient, Learned and Flexible Video Coding) on popular video test sets UVG and MCL-JCV under metrics PSNR, MS-SSIM and VMAF. For example, on UVG under PSNR, it reduces the BD-rate by 44% against H. 264, 26% against H. 265, 15% against AV1, 35% against the current best ML codec. At the same time, on an NVIDIA Titan V GPU our approach encodes/decodes VGA at 49/91 FPS, HD 720 at 19/35 FPS, and HD 1080 at 10/18 FPS.",
        "year": 2021,
        "authors": "Oren Rippel and Alexander G Anderson and Kedar Tatwawadi and Sanjay Nair and Craig Lytle and Lubomir Bourdev"
      },
      {
        "title": "Deepzip: Lossless data compression using recurrent neural networks",
        "abstract": "Sequential data is being generated at an unprecedented pace in various forms, including text and genomic data. This creates the need for efficient compression mechanisms to enable better storage, transmission and processing of such data. To solve this problem, many of the existing compressors attempt to learn models for the data and perform prediction-based compression. Since neural networks are known as universal function approximators with the capability to learn arbitrarily complex mappings, and in practice show excellent performance in prediction tasks, we explore and devise methods to compress sequential data using neural network predictors. We combine recurrent neural network predictors with an arithmetic coder and losslessly compress a variety of synthetic, text and genomic datasets. The proposed compressor outperforms Gzip on the real datasets and achieves near-optimal compression for the synthetic datasets. The results also help understand why and where neural networks are good alternatives for traditional finite context models",
        "year": 2018,
        "authors": "Mohit Goyal and Kedar Tatwawadi and Shubham Chandak and Idoia Ochoa"
      }
    ],
    "czyretsAAAAJ": [
      {
        "title": "Gaussian Error Linear Units (GELUs)",
        "abstract": "We propose the Gaussian Error Linear Unit (GELU), a high-performing neural network activation function. The GELU activation function is , where  the standard Gaussian cumulative distribution function. The GELU nonlinearity weights inputs by their value, rather than gates inputs by their sign as in ReLUs (). We perform an empirical evaluation of the GELU nonlinearity against the ReLU and ELU activations and find performance improvements across all considered computer vision, natural language processing, and speech tasks.",
        "year": 2016,
        "authors": "Dan Hendrycks and Kevin Gimpel"
      },
      {
        "title": "Measuring Massive Multitask Language Understanding",
        "abstract": "We propose a new test to measure a text model's multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have near-random accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model's academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings.",
        "year": 2020,
        "authors": "Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt"
      },
      {
        "title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations",
        "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.",
        "year": 2019,
        "authors": "Dan Hendrycks and Thomas Dietterich"
      }
    ],
    "r44N6h8AAAAJ": [
      {
        "title": "Maximizing social influence in nearly optimal time",
        "abstract": "Diffusion is a fundamental graph process, underpinning such phenomena as epidemic disease contagion and the spread of innovation by word-of-mouth. We address the algorithmic problem of finding a set of k initial seed nodes in a network so that the expected size of the resulting cascade is maximized, under the standard independent cascade model of network diffusion. Runtime is a primary consideration for this problem due to the massive size of the relevant input networks.We provide a fast algorithm for the influence maximization problem, obtaining the near-optimal approximation factor of , for any ∊ > 0, in time O((m + n)∊−3 log n). Our algorithm is runtime-optimal (up to a logarithmic factor) and substantially improves upon the previously best-known algorithms which run in time Ω(mnk · POLY(∊−1)). Furthermore, our algorithm can be modified to allow early termination: if it is terminated after O(β(m + n) logn …",
        "year": 2014,
        "authors": "Christian Borgs and Michael Brautbar and Jennifer Chayes and Brendan Lucier"
      },
      {
        "title": "Combinatorial auctions via posted prices",
        "abstract": "We study anonymous posted price mechanisms for combinatorial auctions in a Bayesian framework. In a posted price mechanism, item prices are posted, then the consumers approach the seller sequentially in an arbitrary order, each purchasing her favorite bundle from among the unsold items at the posted prices. These mechanisms are simple, transparent and trivially dominant strategy incentive compatible (DSIC).We show that when agent preferences are fractionally subadditive (which includes all submodular functions), there always exist prices that, in expectation, obtain at least half of the optimal welfare. Our result is constructive: given black-box access to a combinatorial auction algorithm A, sample access to the prior distribution, and appropriate query access to the sampled valuations, one can compute, in polytime, prices that guarantee at least half of the expected welfare of A. As a corollary, we obtain the …",
        "year": 2014,
        "authors": "Michal Feldman and Nick Gravin and Brendan Lucier"
      },
      {
        "title": "A simple and approximately optimal mechanism for an additive buyer",
        "abstract": "We consider a monopolist seller with n heterogeneous items, facing a single buyer. The buyer has a value for each item drawn independently according to (non-identical) distributions, and her value for a set of items is additive. The seller aims to maximize his revenue.We suggest using the a priori better of two simple pricing methods: selling the items separately, each at its optimal price, and bundling together, in which the entire set of items is sold as one bundle at its optimal price. We show that for any distribution, this mechanism achieves a constant-factor approximation to the optimal revenue. Beyond its simplicity, this is the first computationally tractable mechanism to obtain a constant-factor approximation for this multi-parameter problem. We additionally discuss extensions to multiple buyers and to valuations that are correlated across items.",
        "year": 2020,
        "authors": "Moshe Babaioff and Nicole Immorlica and Brendan Lucier and S Matthew Weinberg"
      }
    ],
    "N_rVVG8AAAAJ": [
      {
        "title": "Object Hallucination in Image Captioning",
        "abstract": "Despite continuously improving performance, contemporary image captioning models are prone to \"hallucinating\" objects that are not actually in a scene. One problem is that standard metrics only measure similarity to ground truth captions and may not fully capture image relevance. In this work, we propose a new image relevance metric to evaluate current models with veridical visual labels and assess their rate of object hallucination. We analyze how captioning model architectures and learning objectives contribute to object hallucination, explore when hallucination is likely due to image misclassification or language priors, and assess how well current sentence metrics capture object hallucination. We investigate these questions on the standard image captioning benchmark, MSCOCO, using a diverse set of models. Our analysis yields several interesting findings, including that models which score best on standard sentence metrics do not always have lower hallucination and that models which hallucinate more tend to make errors driven by language priors.",
        "year": 2018,
        "authors": "Anna Rohrbach and Lisa Anne Hendricks and Kaylee Burns and Trevor Darrell and Kate Saenko"
      },
      {
        "title": "Women also Snowboard: Overcoming Bias in Captioning Models",
        "abstract": "Most machine learning methods are known to capture and exploit biases of the training data. While some biases are beneficial for learning, others are harmful. Specifically, image captioning models tend to exaggerate biases present in training data (e.g., if a word is present in 60% of training sentences, it might be predicted in 70% of sentences at test time). This can lead to incorrect captions in domains where unbiased captions are desired, or required, due to over-reliance on the learned prior and image context. In this work we investigate generation of gender-specific caption words (e.g. man, woman) based on the person's appearance or the image context. We introduce a new Equalizer model that ensures equal gender probability when gender evidence is occluded in a scene and confident predictions when gender evidence is present. The resulting model is forced to look at a person rather than use contextual cues to make a gender-specific predictions. The losses that comprise our model, the Appearance Confusion Loss and the Confident Loss, are general, and can be added to any description model in order to mitigate impacts of unwanted bias in a description dataset. Our proposed model has lower error than prior work when describing images with people and mentioning their gender and more closely matches the ground truth ratio of sentences including women to sentences including men. We also show that unlike other approaches, our model is indeed more often looking at people when predicting their gender.",
        "year": 2018,
        "authors": "Kaylee Burns and Lisa Anne Hendricks and Trevor Darrell and Anna Rohrbach"
      },
      {
        "title": "Evaluating Theory of Mind in Question Answering",
        "abstract": "We propose a new dataset for evaluating question answering models with respect to their capacity to reason about beliefs. Our tasks are inspired by theory-of-mind experiments that examine whether children are able to reason about the beliefs of others, in particular when those beliefs differ from reality. We evaluate a number of recent neural models with memory augmentation. We find that all fail on our tasks, which require keeping track of inconsistent states of the world; moreover, the models' accuracy decreases notably when random sentences are introduced to the tasks at test.",
        "year": 2018,
        "authors": "Aida Nematzadeh and Kaylee Burns and Erin Grant and Alison Gopnik and Thomas L Griffiths"
      }
    ],
    "yyIoQu4AAAAJ": [
      {
        "title": "Adam: A method for stochastic optimization",
        "abstract": "We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.",
        "year": 2014,
        "authors": "Diederik P Kingma and Jimmy Ba"
      },
      {
        "title": "Auto-Encoding Variational Bayes",
        "abstract": "How can we perform efficient inference and learning in directed probabilistic models, in the presence of continuous latent variables with intractable posterior distributions, and large datasets? We introduce a stochastic variational inference and learning algorithm that scales to large datasets and, under some mild differentiability conditions, even works in the intractable case. Our contributions is two-fold. First, we show that a reparameterization of the variational lower bound yields a lower bound estimator that can be straightforwardly optimized using standard stochastic gradient methods. Second, we show that for iid datasets with continuous latent variables per datapoint, posterior inference can be made especially efficient by fitting an approximate inference model (also called a recognition model) to the intractable posterior using the proposed lower bound estimator. Theoretical advantages are reflected in experimental results.",
        "year": 2013,
        "authors": "Diederik P Kingma and Max Welling"
      },
      {
        "title": "Score-based generative modeling through stochastic differential equations",
        "abstract": "Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reverse-time SDE depends only on the time-dependent gradient field (\\aka, score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in score-based generative modeling and diffusion probabilistic modeling, allowing for new sampling procedures and new modeling capabilities. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, but additionally enables exact likelihood computation, and improved sampling efficiency. In addition, we provide a new way to solve inverse problems with score-based models, as demonstrated with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 2.99 bits/dim, and demonstrate high fidelity …",
        "year": 2020,
        "authors": "Yang Song and Jascha Sohl-Dickstein and Diederik P Kingma and Abhishek Kumar and Stefano Ermon and Ben Poole"
      }
    ],
    "slQp6UYAAAAJ": [
      {
        "title": "Personalized kinematics for human-robot collaborative manipulation",
        "abstract": "We present a framework for parameter and state estimation of personalized human kinematic models from motion capture data. These models can be used to optimize a variety of human-robot collaboration scenarios for the comfort or ergonomics of an individual human collaborator. Our approach offers two main advantages over prior approaches from the literature and commercial software: the kinematic models are estimated for a specific individual without a priori assumptions on limb dimensions or range of motion, and our kinematic formalism explicitly encodes the natural kinematic constraints of the human body. The personalized models are tested in a human-robot collaborative manipulation experiment. We find that human subjects with a restricted range of motion rotate their torso significantly less during bimanual object handoffs if the robot uses a personalized kinematic model to plan the handoff …",
        "year": 2015,
        "authors": "Aaron M Bestick and Samuel A Burden and Giorgia Willits and Nikhil Naikal and S Shankar Sastry and Ruzena Bajcsy"
      },
      {
        "title": "Implicitly assisting humans to choose good grasps in robot to human handovers",
        "abstract": "We focus on selecting handover configurations that result in low human ergonomic cost not only at the time of handover, but also when the human is achieving a goal with the object after that handover. People take objects using whatever grasping configuration is most comfortable to them. When the human has a goal pose they’d like to place the object at, however, the most comfortable grasping configuration at the handover might be cumbersome overall, requiring regrasping or the use of an uncomfortable configuration to reach the goal. We enable robots to purposefully influence the choices available to the person when taking the object, implicitly helping the person avoid suboptimal solutions and account for the goal. We introduce a probabilistic model of how humans select grasping configurations, and use this model to optimize expected cost. We present results in simulation, as well as from a user …",
        "year": 2017,
        "authors": "Aaron Bestick and Ruzena Bajcsy and Anca D Dragan"
      },
      {
        "title": "Learning human ergonomic preferences for handovers",
        "abstract": "Our goal is for people to be physically comfortable when taking objects from robots. This puts a burden on the robot to hand over the object in such a way that a person can easily reach it, without needing to strain or twist their arm - a way that is conducive to ergonomic human grasping configurations. To achieve this, the robot needs to understand what makes a configuration more or less ergonomic to the person, i.e. their ergonomic cost function. In this work, we formulate learning a person's ergonomic cost as an online estimation problem. The robot can implicitly make queries to the person by handing them objects in different configurations, and gets observations in response about the way they choose to take the object. We compare the performance of both passive and active approaches for solving this problem in simulation, as well as in an in-person user study.",
        "year": 2018,
        "authors": "Aaron Bestick and Ravi Pandya and Ruzena Bajcsy and Anca D Dragan"
      }
    ],
    "zXhuhtwAAAAJ": [
      {
        "title": "Pfinder: Real-time tracking of the human body",
        "abstract": "Pfinder is a real-time system for tracking people and interpreting their behavior. It runs at 10 Hz on a standard SGI Indy computer, and has performed reliably on thousands of people in many different physical locations. The system uses a multiclass statistical model of color and shape to obtain a 2D representation of head and hands in a wide range of viewing conditions. Pfinder has been successfully used in a wide range of applications including wireless interfaces, video databases, and low-bandwidth coding.",
        "year": 1997,
        "authors": "Christopher Richard  Wren and Ali Azarbayejani and Trevor Darrell and Alex Paul Pentland"
      },
      {
        "title": "Method for processing queries for surveillance tasks",
        "abstract": "A method for querying a Surveillance database stores videos and events acquired by cameras and detectors in an envi ronment. Each event includes a time at which the event was detected. The videos are indexed according to the events. A query specifies a spatial and temporal context. The database is searched for events that match the spatial and temporal context of the query, and only segment of the videos that correlate with the matching events are displayed.",
        "year": 2007,
        "authors": "Yuri Ivanov and Christopher Wren"
      },
      {
        "title": "Surveillance System and Method for Tracking and Identifying Objects in Environments",
        "abstract": "In a conventional surveillance system, tracking of objects, such as people, animals and vehicles, is usually per formed by means of image and video processing. The disad vantage of such a surveillance system is that When a speci? c object needs to be tracked and identi? ed, the object needs to be observed by a camera. HoWever, many surveillance envi ronments require a large number of video cameras to provide the complete coverage necessary for accurate operation. A large number of video streams increase the computational burden on the surveillance system in order to operate accu rately.[0006] The embodiments of the invention provide a mixed modality surveillance system. The system includes a large number of relatively simple sensors and a relatively small number of moveable cameras. This reduces cost, complexity, netWork bandWidth, storage, and processing time When com pared With …",
        "year": 2008,
        "authors": "Yuri A Ivanov and Alexander Sorokin and Christopher R Wren"
      }
    ],
    "GHpxNQIAAAAJ": [
      {
        "title": "Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding",
        "abstract": "Modeling textual or visual information with vector representations trained from large language or visual datasets has been successfully explored in recent years. However, tasks such as visual question answering require combining these vector representations with each other. Approaches to multimodal pooling include element-wise product or sum, as well as concatenation of the visual and textual representations. We hypothesize that these methods are not as expressive as an outer product of the visual and textual vectors. As the outer product is typically infeasible due to its high dimensionality, we instead propose utilizing Multimodal Compact Bilinear pooling (MCB) to efficiently and expressively combine multimodal features. We extensively evaluate MCB on the visual question answering and grounding tasks. We consistently show the benefit of MCB over ablations without MCB. For visual question answering, we present an architecture which uses MCB twice, once for predicting attention over spatial features and again to combine the attended representation with the question representation. This model outperforms the state-of-the-art on the Visual7W dataset and the VQA challenge.",
        "year": 2016,
        "authors": "Akira Fukui and Dong Huk Park and Daylen Yang and Anna Rohrbach and Trevor Darrell and Marcus Rohrbach"
      },
      {
        "title": "A Dataset for Movie Description",
        "abstract": "Audio Description (AD) provides linguistic descriptions of movies and allows visually impaired people to follow a movie along with their peers. Such descriptions are by design mainly visual and thus naturally form an interesting data source for computer vision and computational linguistics. In this work we propose a novel dataset which contains transcribed ADs, which are temporally aligned to full length HD movies. In addition we also collected the aligned movie scripts which have been used in prior work and compare the two different sources of descriptions. In total the MPII Movie Description dataset (MPII-MD) contains a parallel corpus of over 68K sentences and video snippets from 94 HD movies. We characterize the dataset by benchmarking different approaches for generating video descriptions. Comparing ADs to scripts, we find that ADs are far more visual and describe precisely what is shown rather than what should happen according to the scripts created prior to movie production.",
        "year": 2015,
        "authors": "Anna Rohrbach and Marcus Rohrbach and Niket Tandon and Bernt Schiele"
      },
      {
        "title": "Object Hallucination in Image Captioning",
        "abstract": "Despite continuously improving performance, contemporary image captioning models are prone to \"hallucinating\" objects that are not actually in a scene. One problem is that standard metrics only measure similarity to ground truth captions and may not fully capture image relevance. In this work, we propose a new image relevance metric to evaluate current models with veridical visual labels and assess their rate of object hallucination. We analyze how captioning model architectures and learning objectives contribute to object hallucination, explore when hallucination is likely due to image misclassification or language priors, and assess how well current sentence metrics capture object hallucination. We investigate these questions on the standard image captioning benchmark, MSCOCO, using a diverse set of models. Our analysis yields several interesting findings, including that models which score best on standard sentence metrics do not always have lower hallucination and that models which hallucinate more tend to make errors driven by language priors.",
        "year": 2018,
        "authors": "Anna Rohrbach and Lisa Anne Hendricks and Kaylee Burns and Trevor Darrell and Kate Saenko"
      }
    ],
    "BOAOkNQAAAAJ": [
      {
        "title": "Pebble: Feedback-efficient interactive reinforcement learning via relabeling experience and unsupervised pre-training",
        "abstract": "Conveying complex objectives to reinforcement learning (RL) agents can often be difficult, involving meticulous design of reward functions that are sufficiently informative yet easy enough to provide. Human-in-the-loop RL methods allow practitioners to instead interactively teach agents through tailored feedback; however, such approaches have been challenging to scale since human feedback is very expensive. In this work, we aim to make this process more sample- and feedback-efficient. We present an off-policy, interactive RL algorithm that capitalizes on the strengths of both feedback and off-policy learning. Specifically, we learn a reward model by actively querying a teacher's preferences between two clips of behavior and use it to train an agent. To enable off-policy learning, we relabel all the agent's past experience when its reward model changes. We additionally show that pre-training our agents with unsupervised exploration substantially increases the mileage of its queries. We demonstrate that our approach is capable of learning tasks of higher complexity than previously considered by human-in-the-loop methods, including a variety of locomotion and robotic manipulation skills. We also show that our method is able to utilize real-time human feedback to effectively prevent reward exploitation and learn new behaviors that are difficult to specify with standard reward functions.",
        "year": 2021,
        "authors": "Kimin Lee and Laura Smith and Pieter Abbeel"
      },
      {
        "title": "Solar: Deep structured representations for model-based reinforcement learning",
        "abstract": "Model-based reinforcement learning (RL) has proven to be a data efficient approach for learning control tasks but is difficult to utilize in domains with complex observations such as images. In this paper, we present a method for learning representations that are suitable for iterative model-based policy improvement, even when the underlying dynamical system has complex dynamics and image observations, in that these representations are optimized for inferring simple dynamics and cost models given data from the current policy. This enables a model-based RL method based on the linear-quadratic regulator (LQR) to be used for systems with image observations. We evaluate our approach on a range of robotics tasks, including manipulation with a real-world robotic arm directly from images. We find that our method produces substantially better final performance than other model-based RL methods while being significantly more efficient than model-free RL.",
        "year": 2019,
        "authors": "Marvin Zhang and Sharad Vikram and Laura Smith and Pieter Abbeel and Matthew Johnson and Sergey Levine"
      },
      {
        "title": "Efficient online reinforcement learning with offline data",
        "abstract": "Sample efficiency and exploration remain major challenges in online reinforcement learning (RL). A powerful approach that can be applied to address these issues is the inclusion of offline data, such as prior trajectories from a human expert or a sub-optimal exploration policy. Previous methods have relied on extensive modifications and additional complexity to ensure the effective use of this data. Instead, we ask: can we simply apply existing off-policy methods to leverage offline data when learning online? In this work, we demonstrate that the answer is yes; however, a set of minimal but important changes to existing off-policy RL algorithms are required to achieve reliable performance. We extensively ablate these design choices, demonstrating the key factors that most affect performance, and arrive at a set of recommendations that practitioners can readily apply, whether their data comprise a small number of expert demonstrations or large volumes of sub-optimal trajectories. We see that correct application of these simple recommendations can provide a  improvement over existing approaches across a diverse set of competitive benchmarks, with no additional computational overhead.",
        "year": 2023,
        "authors": "Philip J Ball and Laura Smith and Ilya Kostrikov and Sergey Levine"
      }
    ],
    "e9gUdKwAAAAJ": [
      {
        "title": "BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning",
        "abstract": "Datasets drive vision progress, yet existing driving datasets are impoverished in terms of visual content and supported tasks to study multitask learning for autonomous driving. Researchers are usually constrained to study a small set of problems on one dataset, while real-world computer vision applications require performing tasks of various complexities. We construct BDD100K, the largest driving video dataset with 100K videos and 10 tasks to evaluate the exciting progress of image recognition algorithms on autonomous driving. The dataset possesses geographic, environmental, and weather diversity, which is useful for training models that are less likely to be surprised by new conditions. Based on this diverse dataset, we build a benchmark for heterogeneous multitask learning and study how to solve the tasks together. Our experiments show that special training strategies are needed for existing models to perform such heterogeneous tasks. BDD100K opens the door for future studies in this important venue.",
        "year": 2020,
        "authors": "Fisher Yu and Haofeng Chen and Xin Wang and Wenqi Xian and Yingying Chen and Fangchen Liu and Vashisht Madhavan and Trevor Darrell"
      },
      {
        "title": "Phi-3 technical report: A highly capable language model locally on your phone",
        "abstract": "We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and GPT-3.5 (e.g., phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench), despite being small enough to be deployed on a phone. Our training dataset is a scaled-up version of the one used for phi-2, composed of heavily filtered publicly available web data and synthetic data. The model is also further aligned for robustness, safety, and chat format. We also provide parameter-scaling results with a 7B, 14B models trained for 4.8T tokens, called phi-3-small, phi-3-medium, both significantly more capable than phi-3-mini (e.g., respectively 75%, 78% on MMLU, and 8.7, 8.9 on MT-bench). To enhance multilingual, multimodal, and long-context capabilities, we introduce three models in the phi-3.5 series: phi-3.5-mini, phi-3.5-MoE, and phi-3.5-Vision. The phi-3.5-MoE, a 16 x 3.8B MoE model with 6.6 billion active parameters, achieves superior performance in language reasoning, math, and code tasks compared to other open-source models of similar scale, such as Llama 3.1 and the Mixtral series, and on par with Gemini-1.5-Flash and GPT-4o-mini. Meanwhile, phi-3.5-Vision, a 4.2 billion parameter model derived from phi-3.5-mini, excels in reasoning tasks and is adept at handling both single-image and text prompts, as well as multi-image and text prompts.",
        "year": 2024,
        "authors": "Marah Abdin and Jyoti Aneja and Hany Awadalla and Ahmed Awadallah and Ammar Ahmad Awan and Nguyen Bach and Amit Bahree and Arash Bakhtiari and Jianmin Bao and Harkirat Behl and Alon Benhaim and Misha Bilenko and Johan Bjorck and Sébastien Bubeck and Martin Cai and Qin Cai and Vishrav Chaudhary and Dong Chen and Dongdong Chen and Weizhu Chen and Yen-Chun Chen and Yi-Ling Chen and Hao Cheng and Parul Chopra and Xiyang Dai and Matthew Dixon and Ronen Eldan and Victor Fragoso and Jianfeng Gao and Mei Gao and Min Gao and Amit Garg and Allie Del Giorno and Abhishek Goswami and Suriya Gunasekar and Emman Haider and Junheng Hao and Russell J Hewett and Wenxiang Hu and Jamie Huynh and Dan Iter and Sam Ade Jacobs and Mojan Javaheripi and Xin Jin and Nikos Karampatziakis and Piero Kauffmann and Mahoud Khademi and Dongwoo Kim and Young Jin Kim and Lev Kurilenko and James R Lee and Yin Tat Lee and Yuanzhi Li and Yunsheng Li and Chen Liang and Lars Liden and Xihui Lin and Zeqi Lin and Ce Liu and Liyuan Liu and Mengchen Liu and Weishung Liu and Xiaodong Liu and Chong Luo and Piyush Madan and Ali Mahmoudzadeh and David Majercak and Matt Mazzola and Caio César Teodoro Mendes and Arindam Mitra and Hardik Modi and Anh Nguyen and Brandon Norick and Barun Patra and Daniel Perez-Becker and Thomas Portet and Reid Pryzant and Heyang Qin and Marko Radmilac and Liliang Ren and Gustavo de Rosa and Corby Rosset and Sambudha Roy and Olatunji Ruwase and Olli Saarikivi and Amin Saied and Adil Salim and Michael Santacroce and Shital Shah and Ning Shang and Hiteshi Sharma and Yelong Shen and Swadheen Shukla and Xia Song and Masahiro Tanaka and Andrea Tupini and Praneetha Vaddamanu and Chunyu Wang and Guanhua Wang and Lijuan Wang and Shuohang Wang and Xin Wang and Yu Wang and Rachel Ward and Wen Wen and Philipp Witte and Haiping Wu and Xiaoxia Wu and Michael Wyatt and Bin Xiao and Can Xu and Jiahang Xu and Weijian Xu and Jilong Xue and Sonali Yadav and Fan Yang and Jianwei Yang and Yifan Yang and Ziyi Yang and Donghan Yu and Lu Yuan and Chenruidong Zhang and Cyril Zhang and Jianwen Zhang and Li Lyna Zhang and Yi Zhang and Yue Zhang and Yunan Zhang and Xiren Zhou"
      },
      {
        "title": "Few-shot Object Detection via Feature Reweighting",
        "abstract": "Conventional training of a deep CNN based object detector demands a large number of bounding box annotations, which may be unavailable for rare categories. In this work we develop a few-shot object detector that can learn to detect novel objects from only a few annotated examples. Our proposed model leverages fully labeled base classes and quickly adapts to novel classes, using a meta feature learner and a reweighting module within a one-stage detection architecture. The feature learner extracts meta features that are generalizable to detect novel object classes, using training data from base classes with sufficient samples. The reweighting module transforms a few support examples from the novel classes to a global vector that indicates the importance or relevance of meta features for detecting the corresponding objects. These two modules, together with a detection prediction module, are trained end-to-end based on an episodic few-shot learning scheme and a carefully designed loss function. Through extensive experiments we demonstrate that our model outperforms well-established baselines by a large margin for few-shot object detection, on multiple datasets and settings. We also present analysis on various aspects of our proposed model, aiming to provide some inspiration for future few-shot detection works.",
        "year": 2019,
        "authors": "Bingyi Kang and Zhuang Liu and Xin Wang and Fisher Yu and Jiashi Feng and Trevor Darrell"
      }
    ],
    "DkUUhXEAAAAJ": [
      {
        "title": "Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning",
        "abstract": "Model-free deep reinforcement learning algorithms have been shown to be capable of learning a wide range of robotic skills, but typically require a very large number of samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that neural network dynamics models can in fact be combined with model predictive control (MPC) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits that accomplish various complex locomotion tasks. We further propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free …",
        "year": 2018,
        "authors": "Anusha Nagabandi and Gregory Kahn and Ronald S Fearing and Sergey Levine"
      },
      {
        "title": "Learning to adapt in dynamic, real-world environments through meta-reinforcement learning",
        "abstract": "Although reinforcement learning methods can achieve impressive results in simulation, the real world presents two major challenges: generating samples is exceedingly expensive, and unexpected perturbations or unseen situations cause proficient but specialized policies to fail at test time. Given that it is impractical to train separate policies to accommodate all situations the agent may see in the real world, this work proposes to learn how to quickly and effectively adapt online to new tasks. To enable sample-efficient learning, we consider learning online adaptation in the context of model-based reinforcement learning. Our approach uses meta-learning to train a dynamics model prior such that, when combined with recent data, this prior can be rapidly adapted to the local context. Our experiments demonstrate online adaptation for continuous control tasks on both simulated and real-world agents. We first show simulated agents adapting their behavior online to novel terrains, crippled body parts, and highly-dynamic environments. We also illustrate the importance of incorporating online adaptation into autonomous agents that operate in the real world by applying our method to a real dynamic legged millirobot. We demonstrate the agent's learned ability to quickly adapt online to a missing leg, adjust to novel terrains and slopes, account for miscalibration or errors in pose estimation, and compensate for pulling payloads.",
        "year": 2018,
        "authors": "Anusha Nagabandi and Ignasi Clavera and Simin Liu and Ronald S Fearing and Pieter Abbeel and Sergey Levine and Chelsea Finn"
      },
      {
        "title": "Deep Dynamics Models for Learning Dexterous Manipulation",
        "abstract": "Dexterous multi-fingered hands can provide robots with the ability to flexibly perform a wide range of manipulation skills. However, many of the more complex behaviors are also notoriously difficult to control: Performing in-hand object manipulation, executing finger gaits to move objects, and exhibiting precise fine motor skills such as writing, all require finely balancing contact forces, breaking and reestablishing contacts repeatedly, and maintaining control of unactuated objects. Learning-based techniques provide the appealing possibility of acquiring these skills directly from data, but current learning approaches either require large amounts of data and produce task-specific policies, or they have not yet been shown to scale up to more complex and realistic tasks requiring fine motor skills. In this work, we demonstrate that our method of online planning with deep dynamics models (PDDM) addresses both of these limitations; we show that improvements in learned dynamics models, together with improvements in on-line model-predictive control, can indeed enable efficient and effective learning of flexible contact-rich dexterous manipulation skills–and that too, on a 24-DoF anthropomorphic hand in the real world, using just 4 hours of purely real-world data to learn to simultaneously coordinate multiple free-floating objects. Videos can be found at https://sites. google. com/view/pddm/.",
        "year": 2019,
        "authors": "Anusha Nagabandi and Kurt Konoglie and Sergey Levine and Vikash Kumar"
      }
    ],
    "xEWgxBsAAAAJ": [
      {
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models",
        "abstract": "DSpace at KOASAS: Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nKOASAS menu About KOASAS KAIST Library 검색 Advanced Search KOASAS About \nKOASAS Open Access Policy Browse Communities & Collections Researchers at KAIST Titles \nSubject By Date rss_1.0 rss_2.0 atom_1.0 sherpa SEARCH DSpace at KOASAS College of \nEngineering(공과대학)Kim Jaechul Graduate School of AI(김재철AI대학원)AI-Conference \nPapers(학술대회논문) Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nCited 0 time in webofscience Cited 0 time in scopus Hit : 2 Download : 0 Export DC(XML) Excel \nLim, Joseph Jaewhanresearcher Publisher IEEE Issue Date 2024-05-15 Citation IEEE \nInternational Conference on Robotics and Automation URI http://hdl.handle.net/10203/326144 \nAppears in Collection AI-Conference Papers(학술대회논문) Files in This Item There are no files …",
        "year": 2024,
        "authors": "Joseph Jaewhan Lim"
      },
      {
        "title": "BLOG: Probabilistic Models with Unknown Objects",
        "abstract": "Many AI problems, ranging from sensor data association to linguistic coreference resolution, involve making inferences about real-world objects that underlie some data. In many cases, we do not know the number of underlying objects or the mapping between observations and objects. This chapter presents a probabilistic modeling language, called Bayesian logic (BLOG), which allows such scenarios to be represented in a natural way. A well-formed BLOG model fully deﬁnes a distribution over model structures of a ﬁrst-order logical language; these “possible worlds” can contain varying numbers of objects with varying relations among them. We show how to use a probabilistic form of Skolemization to express evidence about objects that were not initially known to exist. We also present a sampling-based approximate inference algorithm that does inference in ﬁnite time per sampling step on a large class of BLOG models, even those involving inﬁnitely many random variables.",
        "year": 2007,
        "authors": "Brian Milch and Bhaskara Marthi and Stuart Russell and David Sontag and Daniel L Ong and Andrey Kolobov"
      },
      {
        "title": "Parallel task routing for crowdsourcing",
        "abstract": "An ideal crowdsourcing or citizen-science system would route tasks to the most appropriate workers, but the best assignment is unclear because workers have varying skill, tasks have varying difficulty, and assigning several workers to a single task may significantly improve output quality. This paper defines a space of task routing problems, proves that even the simplest is NP-hard, and develops several approximation algorithms for parallel routing problems. We show that an intuitive class of requesters' utility functions is submodular, which lets us provide iterative methods for dynamically allocating batches of tasks that make near-optimal use of available workers in each round. Experiments with live oDesk workers show that our task routing algorithm uses only 48% of the human labor compared to the commonly used round-robin strategy. Further, we provide versions of our task routing algorithm which enable it to scale to large numbers of workers and questions and to handle workers with variable response times while still providing significant benefit over common baselines.",
        "year": 2014,
        "authors": "Jonathan Bragg and Andrey Kolobov and Mausam Mausam and Daniel Weld"
      }
    ],
    "4V1nNm4AAAAJ": [
      {
        "title": "Adapting visual category models to new domains",
        "abstract": "Domain adaptation is an important emerging topic in computer vision. In this paper, we present one of the first studies of domain shift in the context of object recognition. We introduce a method that adapts object models acquired in a particular visual domain to new imaging conditions by learning a transformation that minimizes the effect of domain-induced changes in the feature distribution. The transformation is learned in a supervised manner and can be applied to categories for which there are no labeled examples in the new domain. While we focus our evaluation on object recognition tasks, the transform-based adaptation technique we develop is general and could be applied to non-image data. Another contribution is a new multi-domain object database, freely available for download. We experimentally demonstrate the ability of our method to improve recognition on categories with few or no target …",
        "year": 2010,
        "authors": "Kate Saenko and Brian Kulis and Mario Fritz and Trevor Darrell"
      },
      {
        "title": "Ml-leaks: Model and data independent membership inference attacks and defenses on machine learning models",
        "abstract": "Machine learning (ML) has become a core component of many real-world applications and training data is a key factor that drives current progress. This huge success has led Internet companies to deploy machine learning as a service (MLaaS). Recently, the first membership inference attack has shown that extraction of information on the training set is possible in such MLaaS settings, which has severe security and privacy implications. However, the early demonstrations of the feasibility of such attacks have many assumptions on the adversary, such as using multiple so-called shadow models, knowledge of the target model structure, and having a dataset from the same distribution as the target model's training data. We relax all these key assumptions, thereby showing that such attacks are very broadly applicable at low cost and thereby pose a more severe risk than previously thought. We present the most comprehensive study so far on this emerging and developing threat using eight diverse datasets which show the viability of the proposed attacks across domains. In addition, we propose the first effective defense mechanisms against such broader class of membership inference attacks that maintain a high level of utility of the ML model.",
        "year": 2018,
        "authors": "Ahmed Salem and Yang Zhang and Mathias Humbert and Pascal Berrang and Mario Fritz and Michael Backes"
      },
      {
        "title": "Appearance-based gaze estimation in the wild",
        "abstract": "Appearance-based gaze estimation is believed to work well in real-world settings, but existing datasets have been collected under controlled laboratory conditions and methods have been not evaluated across multiple datasets. In this work we study appearance-based gaze estimation in the wild. We present the MPIIGaze dataset that contains 213,659 images we collected from 15 participants during natural everyday laptop use over more than three months. Our dataset is significantly more variable than existing ones with respect to appearance and illumination. We also present a method for in-the-wild appearance-based gaze estimation using multimodal convolutional neural networks that significantly outperforms state-of-the art methods in the most challenging cross-dataset evaluation. We present an extensive evaluation of several state-of-the-art image-based gaze estimation algorithms on three current datasets, including our own. This evaluation provides clear insights and allows us to identify key research challenges of gaze estimation in the wild.",
        "year": 2015,
        "authors": "Xucong Zhang and Yusuke Sugano and Mario Fritz and Andreas Bulling"
      }
    ],
    "xdGKgtcAAAAJ": [
      {
        "title": "A view of cloud computing",
        "abstract": "Clearing the clouds away from the true potential and obstacles posed by this computing capability.",
        "year": 2010,
        "authors": "Michael Armbrust and Armando Fox and Rean Griffith and Anthony D Joseph and Randy Katz and Andy Konwinski and Gunho Lee and David Patterson and Ariel Rabkin and Ion Stoica and Matei Zaharia"
      },
      {
        "title": "Above the clouds: A berkeley view of cloud computing",
        "abstract": "Cloud Computing, the long-held dream of computing as a utility, has the potential to transform a large part of the IT industry, making software even more attractive as a service and shaping the way IT hardware is designed and purchased. Developers with innovative ideas for new Internet services no longer require the large capital outlays in hardware to deploy their service or the human expense to operate it. They need not be concerned about overprovisioning for a service whose popularity does not meet their predictions, thus wasting costly resources, or underprovisioning for one that becomes wildly popular, thus missing potential customers and revenue. Moreover, companies with large batch-oriented tasks can get results as quickly as their programs can scale, since using 1000 servers for one hour costs no more than using one server for 1000 hours. This elasticity of resources, without paying a premium for large scale, is unprecedented in the history of IT.Cloud Computing refers to both the applications delivered as services over the Internet and the hardware and systems software in the datacenters that provide those services. The services themselves have long been referred to as Software as a Service (SaaS). The datacenter hardware and software is what we will call a Cloud. When a Cloud is made available in a pay-as-you-go manner to the general public, we call it a Public Cloud; the service being sold is Utility Computing. We use the term Private Cloud to refer to internal datacenters of a business or other organization, not made available to the general public. Thus, Cloud Computing is the sum of SaaS and Utility Computing, but does not …",
        "year": 2009,
        "authors": "Michael Armbrust and Armando Fox and Rean Griffith and Anthony D Joseph and Randy H Katz and Andrew Konwinski and Gunho Lee and David A Patterson and Ariel Rabkin and Ion Stoica and Matei Zaharia"
      },
      {
        "title": "Tapestry: An infrastructure for fault-tolerant wide-area location and routing",
        "abstract": "In today’s chaotic network, data and services are mobile and replicated widely for availability, durability, and locality. Components within this infrastructure interact in rich and complex ways, greatly stressing traditional approaches to name service and routing. This paper explores an alternative to traditional approaches called Tapestry. Tapestry is an overlay location and routing infrastructure that provides location-independent routing of messages directly to the closest copy of an object or service using only point-to-point links and without centralized resources. The routing and directory information within this infrastructure is purely soft state and easily repaired. Tapestry is self-administering, faulttolerant, and resilient under load. This paper presents the architecture and algorithms of Tapestry and explores their advantages through a number of experiments.",
        "year": 2001,
        "authors": "Ben Yanbin Zhao and John Kubiatowicz and Anthony D Joseph"
      }
    ],
    "gQpYbRsAAAAJ": [
      {
        "title": "Hurtful words: quantifying biases in clinical contextual word embeddings",
        "abstract": "In this work, we examine the extent to which embeddings may encode marginalized populations differently, and how this may lead to a perpetuation of biases and worsened performance on clinical tasks. We pretrain deep embedding models (BERT) on medical notes from the MIMIC-III hospital dataset, and quantify potential disparities using two approaches. First, we identify dangerous latent relationships that are captured by the contextual word embeddings using a fill-in-the-blank method with text from real clinical notes and a log probability bias score quantification. Second, we evaluate performance gaps across different definitions of fairness on over 50 downstream clinical prediction tasks that include detection of acute and chronic conditions. We find that classifiers trained from BERT representations exhibit statistically significant differences in performance, often favoring the majority group with regards to gender …",
        "year": 2020,
        "authors": "Haoran Zhang and Amy X Lu and Mohamed Abdalla and Matthew McDermott and Marzyeh Ghassemi"
      },
      {
        "title": "Self-supervised contrastive learning of protein representations by mutual information maximization",
        "abstract": "Pretrained embedding representations of biological sequences which capture meaningful properties can alleviate many problems associated with supervised learning in biology. We apply the principle of mutual information maximization between local and global information as a self-supervised pretraining signal for protein embeddings. To do so, we divide protein sequences into fixed size fragments, and train an autoregressive model to distinguish between subsequent fragments from the same protein and fragments from random proteins. Our model, CPCProt, achieves comparable performance to state-of-the-art self-supervised models for protein sequence embeddings on various downstream tasks, but reduces the number of parameters down to 0.9% to 8.9% of benchmarked models. Further, we explore how downstream assessment protocols affect embedding evaluation, and the effect of contrastive learning hyperparameters on empirical performance. We hope that these results will inform the development of contrastive learning methods in protein biology and other modalities.",
        "year": 2020,
        "authors": "Amy X Lu and Haoran Zhang and Marzyeh Ghassemi and Alan Moses"
      },
      {
        "title": "Learned embeddings from deep learning to visualize and predict protein sets",
        "abstract": "Models from machine learning (ML) or artificial intelligence (AI) increasingly assist in guiding experimental design and decision making in molecular biology and medicine. Recently, Language Models (LMs) have been adapted from Natural Language Processing (NLP) to encode the implicit language written in protein sequences. Protein LMs show enormous potential in generating descriptive representations (embeddings) for proteins from just their sequences, in a fraction of the time with respect to previous approaches, yet with comparable or improved predictive ability. Researchers have trained a variety of protein LMs that are likely to illuminate different angles of the protein language. By leveraging the bio_embeddings pipeline and modules, simple and reproducible workflows can be laid out to generate protein embeddings and rich visualizations. Embeddings can then be leveraged as input features through …",
        "year": 2021,
        "authors": "Christian Dallago and Konstantin Schütze and Michael Heinzinger and Tobias Olenyi and Maria Littmann and Amy X Lu and Kevin K Yang and Seonwoo Min and Sungroh Yoon and James T Morton and Burkhard Rost"
      }
    ],
    "hHkuxSUAAAAJ": [
      {
        "title": "Unpaired image-to-image translation using cycle-consistent adversarial networks",
        "abstract": "Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G: X-> Y such that the distribution of images from G (X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F: Y-> X and introduce a cycle consistency loss to push F (G (X))~ X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.",
        "year": 2017,
        "authors": "Jun-Yan Zhu and Taesung Park and Phillip Isola and Alexei A Efros"
      },
      {
        "title": "Cycada: Cycle-consistent adversarial domain adaptation",
        "abstract": "Domain adaptation is critical for success in new, unseen environments. Adversarial adaptation models have shown tremendous progress towards adapting to new environments by focusing either on discovering domain invariant representations or by mapping between unpaired image domains. While feature space methods are difficult to interpret and sometimes fail to capture pixel-level and low-level domain shifts, image space methods sometimes fail to incorporate high level semantic knowledge relevant for the end task. We propose a model which adapts between domains using both generative image space alignment and latent representation space alignment. Our approach, Cycle-Consistent Adversarial Domain Adaptation (CyCADA), guides transfer between domains according to a specific discriminatively trained task and avoids divergence by enforcing consistency of the relevant semantics before and after adaptation. We evaluate our method on a variety of visual recognition and prediction settings, including digit classification and semantic segmentation of road scenes, advancing state-of-the-art performance for unsupervised adaptation from synthetic to real world driving domains.",
        "year": 2018,
        "authors": "Judy Hoffman and Eric Tzeng and Taesung Park and Jun-Yan Zhu and Phillip Isola and Kate Saenko and Alexei Efros and Trevor Darrell"
      },
      {
        "title": "Semantic image synthesis with spatially-adaptive normalization",
        "abstract": "We propose spatially-adaptive normalization, a simple but effective layer for synthesizing photorealistic images given an input semantic layout. Previous methods directly feed the semantic layout as input to the network, forcing the network to memorize the information throughout all the layers. Instead, we propose using the input layout for modulating the activations in normalization layers through a spatially-adaptive, learned affine transformation. Experiments on several challenging datasets demonstrate the superiority of our method compared to existing approaches, regarding both visual fidelity and alignment with input layouts. Finally, our model allows users to easily control the style and content of image synthesis results as well as create multi-modal results. Code is available upon publication.",
        "year": 2019,
        "authors": "Taesung Park and Ming-Yu Liu and Ting-Chun Wang and Jun-Yan Zhu"
      }
    ],
    "szDNg-0AAAAJ": [
      {
        "title": "Junior: The stanford entry in the urban challenge",
        "abstract": "This article presents the architecture of Junior, a robotic vehicle capable of navigating urban environments autonomously. In doing so, the vehicle is able to select its own routes, perceive and interact with other traffic, and execute various urban driving skills including lane changes, U‐turns, parking, and merging into moving traffic. The vehicle successfully finished and won second place in the DARPA Urban Challenge, a robot competition organized by the U.S. Government. © 2008 Wiley Periodicals, Inc.",
        "year": 2008,
        "authors": "Michael Montemerlo and Jan Becker and Suhrid Bhat and Hendrik Dahlkamp and Dmitri Dolgov and Scott Ettinger and Dirk Haehnel and Tim Hilden and Gabe Hoffmann and Burkhard Huhnke and Doug Johnston and Stefan Klumpp and Dirk Langer and Anthony Levandowski and Jesse Levinson and Julien Marcil and David Orenstein and Johannes Paefgen and Isaac Penny and Anna Petrovskaya and Mike Pflueger and Ganymed Stanek and David Stavens and Antone Vogt and Sebastian Thrun"
      },
      {
        "title": "Path planning for autonomous vehicles in unknown semi-structured environments",
        "abstract": "We describe a practical path-planning algorithm for an autonomous vehicle operating in an unknown semi-structured (or unstructured) environment, where obstacles are detected online by the robot’s sensors. This work was motivated by and experimentally validated in the 2007 DARPA Urban Challenge, where robotic vehicles had to autonomously navigate parking lots. The core of our approach to path planning consists of two phases. The first phase uses a variant of A* search (applied to the 3D kinematic state space of the vehicle) to obtain a kinematically feasible trajectory. The second phase then improves the quality of the solution via numeric non-linear optimization, leading to a local (and frequently global) optimum. Further, we extend our algorithm to use prior topological knowledge of the environment to guide path planning, leading to faster search and final trajectories better suited to the structure of the …",
        "year": 2010,
        "authors": "Dmitri Dolgov and Sebastian Thrun and Michael Montemerlo and James Diebel"
      },
      {
        "title": "System and method for predicting behaviors of detected objects",
        "abstract": "6,321,147 6,332,354 6,343,247 6,438,472 6,438,491 6,470,874 6,504,259 6,516,262 6,591,172 6,643,576 6,832,156 6,847,869 6,862,524 6,876,908 6,934,613 7,011, 186 7, 031829 7,102,496 7,194,347 7,207,304 7,233,861 7,327,242 7,346,439 7,394,046 7,486,802 7,499,774 7,499,776 7,499,804 7,515, 101 7,579,942 7,656,280 7,694,555 7,865,277 7,908,040 7.956, 730 8,050,863 8,078,349 8, 190,322 8, 195,341 8, 244408 8,260,515 8,280,601 2001/0037927 2003, OO16804 2003/0055554 2003/0093.209 2004/0243292 2005, OO12589 2005/0273251 2006, OO37573 2006/0O82437 2006/0O89764 2006/0178240 2006/0276942 2007/0225909 2007/0239331 2007/0247281 2008, 0021628 2008/0059.048 2008/0084.283 2008/O120025 2008/O147253 2008/O161987 2008/O183512 2008. O188246 2008/02771.83 2008/0303696 2008/0306969 2009, 0005959 2009, OO82879 2009/O115594 2009 …",
        "year": 2014,
        "authors": "Jiajun Zhu and David I Ferguson and Dmitri A Dolgov"
      }
    ],
    "p1DZVX8AAAAJ": [
      {
        "title": "Graphical models, exponential families, and variational inference",
        "abstract": "The formalism of probabilistic graphical models provides a unifying framework for capturing complex dependencies among random variables, and building large-scale multivariate statistical models. Graphical models have become a focus of research in many statistical, computational and mathematical fields, including bioinformatics, communication theory, statistical physics, combinatorial optimization, signal and image processing, information retrieval and statistical machine learning. Many problems that arise in specific instances—including the key problems of computing marginals and modes of probability distributions—are best studied in the general setting. Working with exponential family representations, and exploiting the conjugate duality between the cumulant function and the entropy for exponential families, we develop general variational representations of the problems of computing likelihoods, marginal probabilities and most probable configurations. We describe how a wide variety of algorithms—among them sum-product, cluster variational methods, expectation-propagation, mean field methods, max-product and linear programming relaxation, as well as conic programming relaxations—can all be understood in terms of exact or approximate forms of these variational representations. The variational approach provides a complementary alternative to Markov chain Monte Carlo as a general source of approximation methods for inference in large-scale statistical models.",
        "year": 2008,
        "authors": "Martin J Wainwright and Michael I Jordan"
      },
      {
        "title": "Statistical learning with sparsity",
        "abstract": "In this monograph, we have attempted to summarize the actively developing field of statistical learning with sparsity. A sparse statistical model is one having only a small number of nonzero parameters or weights. It represents a classic case of “less is more”: a sparse model can be much easier to estimate and interpret than a dense model. In this age of big data, the number of features measured on a person or object can be large, and might be larger than the number of observations. The sparsity assumption allows us to tackle such problems and extract useful and reproducible patterns from big datasets. The ideas described here represent the work of an entire community of researchers in statistics and machine learning, and we thank everyone for their continuing contributions to this exciting area. We particularly thank our colleagues at Stanford, Berkeley and elsewhere; our collaborators, and our past and current …",
        "year": 2015,
        "authors": "Trevor Hastie and Robert Tibshirani and Martin Wainwright"
      },
      {
        "title": "High-dimensional statistics: A non-asymptotic viewpoint",
        "abstract": "Recent years have witnessed an explosion in the volume and variety of data collected in all scientific disciplines and industrial settings. Such massive data sets present a number of challenges to researchers in statistics and machine learning. This book provides a self-contained introduction to the area of high-dimensional statistics, aimed at the first-year graduate level. It includes chapters that are focused on core methodology and theory-including tail bounds, concentration inequalities, uniform laws and empirical process, and random matrices-as well as chapters devoted to in-depth exploration of particular model classes-including sparse linear models, matrix models with rank constraints, graphical models, and various types of non-parametric models. With hundreds of worked examples and exercises, this text is intended both for courses and for self-study by graduate students and researchers in statistics, machine learning, and related fields who must understand, apply, and adapt modern statistical methods suited to large-scale data.",
        "year": 2019,
        "authors": "Martin J Wainwright"
      }
    ],
    "wORhZLMAAAAJ": [
      {
        "title": "Do you want your autonomous car to drive like you?",
        "abstract": "With progress in enabling autonomous cars to drive safely on the road, it is time to start asking how they should be driving. A common answer is that they should be adopting their users' driving style. This makes the assumption that users want their autonomous cars to drive like they drive - aggressive drivers want aggressive cars, defensive drivers want defensive cars. In this paper, we put that assumption to the test. We find that users tend to prefer a significantly more defensive driving style than their own. Interestingly, they prefer the style they think is their own, even though their actual driving style tends to be more aggressive. We also find that preferences do depend on the specific driving scenario, opening the door for new ways of learning driving style preference.",
        "year": 2017,
        "authors": "Chandrayee Basu and Qian Yang and David Hungerman and Mukesh Singhal and Anca D Dragan"
      },
      {
        "title": "Trust Dynamics in Human Autonomous Vehicle Interaction: A Review of Trust Models.",
        "abstract": "Several ongoing research projects in Human autonomous car interactions are addressing the problem of safe co-existence for human and robot drivers on road. Automation in cars can vary across a continuum of levels at which it can replace manual tasks. Social relationships like anthropomorphic behavior of owners towards their cars is also expected to vary according to this spectrum of autonomous decision making capacity. Some researchers have proposed a joint cognitive model of a human-car collaboration that can make the best of the respective strengths of humans and machines. For a successful collaboration, it is important that the members of this humancar team develop, maintain and update each others behavioral models. We consider mutual trust as an integral part of these models. In this paper, we present a review of the quantitative models of trust in automation. We found that only a few models of humans’ trust on automation exist in literature that account for the dynamic nature of trust and may be leveraged in human car interaction. However, these models do not support mutual trust. Our review suggests that there is significant scope for future research in the domain of mutual trust modeling for human car interaction, especially, when considered over the lifetime of the vehicle. Hardware and computational framework (for sensing, data aggregation, processing and modeling) must be developed to support these adaptive models over the operational phase of autonomous vehicles. In order to further research in mutual human-automation trust, we propose a framework for integrating Mutual Trust computation into standard Human …",
        "year": 2016,
        "authors": "Chandrayee Basu and Mukesh Singhal"
      },
      {
        "title": "Learning from richer human guidance: Augmenting comparison-based learning with feature queries",
        "abstract": "We focus on learning the desired objective function for a robot. Although trajectory demonstrations can be very informative of the desired objective, they can also be difficult for users to provide. Answers to comparison queries, asking which of two trajectories is preferable, are much easier for users, and have emerged as an effective alternative. Unfortunately, comparisons are far less informative. We propose that there is much richer information that users can easily provide and that robots ought to leverage. We focus on augmenting comparisons with feature queries, and introduce a unified formalism for treating all answers as observations about the true desired reward. We derive an active query selection algorithm, and test these queries in simulation and on real users. We find that richer, feature-augmented queries can extract more information faster, leading to robots that better match user preferences in their …",
        "year": 2018,
        "authors": "Chandrayee Basu and Mukesh Singhal and Anca D Dragan"
      }
    ],
    "yxUduqMAAAAJ": [
      {
        "title": "Latent Dirichlet Allocation",
        "abstract": "We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.",
        "year": 2003,
        "authors": "DM Blei and AY Ng and MI Jordan"
      },
      {
        "title": "On spectral clustering: Analysis and an algorithm",
        "abstract": "Despite many empirical successes of spectral clustering methods (cid: 173) algorithms that cluster points using eigenvectors of matrices de (cid: 173) rived from the data-there are several unresolved issues. First, there are a wide variety of algorithms that use the eigenvectors in slightly different ways. Second, many of these algorithms have no proof that they will actually compute a reasonable clustering. In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab. Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well. We also show surprisingly good experimental results on a number of challenging clustering problems.",
        "year": 2001,
        "authors": "Andrew Ng and Michael Jordan and Yair Weiss"
      },
      {
        "title": "Machine learning: Trends, perspectives, and prospects",
        "abstract": "Machine learning addresses the question of how to build computers that improve automatically through experience. It is one of today’s most rapidly growing technical fields, lying at the intersection of computer science and statistics, and at the core of artificial intelligence and data science. Recent progress in machine learning has been driven both by the development of new learning algorithms and theory and by the ongoing explosion in the availability of online data and low-cost computation. The adoption of data-intensive machine-learning methods can be found throughout science, technology and commerce, leading to more evidence-based decision-making across many walks of life, including health care, manufacturing, education, financial modeling, policing, and marketing.",
        "year": 2015,
        "authors": "Michael I Jordan and Tom M Mitchell"
      }
    ],
    "cl7CnNYAAAAJ": [
      {
        "title": "A supernodal approach to sparse partial pivoting",
        "abstract": "We investigate several ways to improve the performance of sparse LU factorization with partial pivoting, as used to solve unsymmetric linear systems. We introduce the notion of unsymmetric supernodes to perform most of the numerical computation in dense matrix kernels. We introduce unsymmetric supernode-panel updates and two-dimensional data partitioning to better exploit the memory hierarchy. We use Gilbert and Peierls's depth-first search with Eisenstat and Liu's symmetric structural reductions to speed up symbolic factorization. We have developed a sparse LU code using all these ideas. We present experiments demonstrating that it is significantly faster than earlier partial pivoting codes. We also compare its performance with UMFPACK, which uses a multifrontal approach; our code is very competitive in time and storage requirements, especially for large problems.",
        "year": 1999,
        "authors": "James W Demmel and Stanley C Eisenstat and John R Gilbert and Xiaoye S Li and Joseph WH Liu"
      },
      {
        "title": "Sparse matrices in MATLAB: Design and implementation",
        "abstract": "The matrix computation language and environment MATLAB is extended to include sparse matrix storage and operations. The only change to the outward appearance of the MATLAB language is a pair of commands to create full or sparse matrices. Nearly all the operations of MATLAB now apply equally to full or sparse matrices, without any explicit action by the user. The sparse data structure represents a matrix in space proportional to the number of nonzero entries, and most of the operations compute sparse results in time proportional to the number of arithmetic operations on nonzeros.",
        "year": 1992,
        "authors": "John R Gilbert and Cleve Moler and Robert Schreiber"
      },
      {
        "title": "Parallel sparse matrix-vector and matrix-transpose-vector multiplication using compressed sparse blocks",
        "abstract": "This paper introduces a storage format for sparse matrices, called compressed sparse blocks (CSB), which allows both Ax and A,x to be computed efficiently in parallel, where A is an n×n sparse matrix with nnzen nonzeros and x is a dense n-vector. Our algorithms use Θ(nnz) work (serial running time) and Θ(√nlgn) span (critical-path length), yielding a parallelism of Θ(nnz/√nlgn), which is amply high for virtually any large matrix. The storage requirement for CSB is the same as that for the more-standard compressed-sparse-rows (CSR) format, for which computing Ax in parallel is easy but A,x is difficult. Benchmark results indicate that on one processor, the CSB algorithms for Ax and A,x run just as fast as the CSR algorithm for Ax, but the CSB algorithms also scale up linearly with processors until limited by off-chip memory bandwidth.",
        "year": 2009,
        "authors": "Aydin Buluç and Jeremy T Fineman and Matteo Frigo and John R Gilbert and Charles E Leiserson"
      }
    ],
    "EMDboA4AAAAJ": [
      {
        "title": "InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets",
        "abstract": "This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods.",
        "year": 2016,
        "authors": "Xi Chen and Yan Duan and Rein Houthooft and John Schulman and Ilya Sutskever and Pieter Abbeel"
      },
      {
        "title": "Benchmarking deep reinforcement learning for continuous control",
        "abstract": "Recently, researchers have made significant progress combining the advances in deep learning for learning feature representations with reinforcement learning. Some notable examples include training agents to play Atari games based on raw pixel data and to acquire advanced manipulation skills using raw sensory inputs. However, it has been difficult to quantify progress in the domain of continuous control due to the lack of a commonly adopted benchmark. In this work, we present a benchmark suite of continuous control tasks, including classic tasks like cart-pole swing-up, tasks with very high state and action dimensionality such as 3D humanoid locomotion, tasks with partial observations, and tasks with hierarchical structure. We report novel findings based on the systematic evaluation of a range of implemented reinforcement learning algorithms. Both the benchmark and reference implementations are released at https://github. com/rllab/rllab in order to facilitate experimental reproducibility and to encourage adoption by other researchers.",
        "year": 2016,
        "authors": "Yan Duan and Xi Chen and Rein Houthooft and John Schulman and Pieter Abbeel"
      },
      {
        "title": "RL^2: Fast Reinforcement Learning via Slow Reinforcement Learning",
        "abstract": "Deep reinforcement learning (deep RL) has been successful in learning sophisticated behaviors automatically; however, the learning process requires a huge number of trials. In contrast, animals can learn new tasks in just a few trials, benefiting from their prior knowledge about the world. This paper seeks to bridge this gap. Rather than designing a \"fast\" reinforcement learning algorithm, we propose to represent it as a recurrent neural network (RNN) and learn it from data. In our proposed method, RL, the algorithm is encoded in the weights of the RNN, which are learned slowly through a general-purpose (\"slow\") RL algorithm. The RNN receives all information a typical RL algorithm would receive, including observations, actions, rewards, and termination flags; and it retains its state across episodes in a given Markov Decision Process (MDP). The activations of the RNN store the state of the \"fast\" RL algorithm on the current (previously unseen) MDP. We evaluate RL experimentally on both small-scale and large-scale problems. On the small-scale side, we train it to solve randomly generated multi-arm bandit problems and finite MDPs. After RL is trained, its performance on new MDPs is close to human-designed algorithms with optimality guarantees. On the large-scale side, we test RL on a vision-based navigation task and show that it scales up to high-dimensional problems.",
        "year": 2016,
        "authors": "Yan Duan and John Schulman and Xi Chen and Peter L Bartlett and Ilya Sutskever and Pieter Abbeel"
      }
    ],
    "0mgEF28AAAAJ": [
      {
        "title": "FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search",
        "abstract": "Designing accurate and efficient ConvNets for mobile devices is challenging because the design space is combinatorially large. Due to this, previous neural architecture search (NAS) methods are computationally expensive. ConvNet architecture optimality depends on factors such as input resolution and target devices. However, existing approaches are too resource demanding for case-by-case redesigns. Also, previous work focuses primarily on reducing FLOPs, but FLOP count does not always reflect actual latency. To address these, we propose a differentiable neural architecture search (DNAS) framework that uses gradient-based methods to optimize ConvNet architectures, avoiding enumerating and training individual architectures separately as in previous methods. FBNets (Facebook-Berkeley-Nets), a family of models discovered by DNAS surpass state-of-the-art models both designed manually and generated automatically. FBNet-B achieves 74.1% top-1 accuracy on ImageNet with 295M FLOPs and 23.1 ms latency on a Samsung S8 phone, 2.4 x smaller and 1.5 x faster than MobileNetV2-1.3 with similar accuracy. Despite higher accuracy and lower latency than MnasNet, we estimate FBNet-B's search cost is 420x smaller than MnasNet's, at only 216 GPU-hours. Searched for different resolutions and channel sizes, FBNets achieve 1.5% to 6.4% higher accuracy than MobileNetV2. The smallest FBNet achieves 50.2% accuracy and 2.9 ms latency (345 frames per second) on a Samsung S8. Over a Samsung-optimized FBNet, the iPhone-X-optimized model achieves a 1.4 x speedup on an iPhone X. FBNet models are open-sourced at …",
        "year": 2018,
        "authors": "Bichen Wu and Xiaoliang Dai and Peizhao Zhang and Yanghan Wang and Fei Sun and Yiming Wu and Yuandong Tian and Peter Vajda and Yangqing Jia and Kurt Keutzer"
      },
      {
        "title": "Efficient streaming language models with attention sinks",
        "abstract": "Deploying Large Language Models (LLMs) in streaming applications such as multi-round dialogue, where long interactions are expected, is urgently needed but poses two major challenges. Firstly, during the decoding stage, caching previous tokens' Key and Value states (KV) consumes extensive memory. Secondly, popular LLMs cannot generalize to longer texts than the training sequence length. Window attention, where only the most recent KVs are cached, is a natural approach -- but we show that it fails when the text length surpasses the cache size. We observe an interesting phenomenon, namely attention sink, that keeping the KV of initial tokens will largely recover the performance of window attention. In this paper, we first demonstrate that the emergence of attention sink is due to the strong attention scores towards initial tokens as a \"sink\" even if they are not semantically important. Based on the above analysis, we introduce StreamingLLM, an efficient framework that enables LLMs trained with a finite length attention window to generalize to infinite sequence lengths without any fine-tuning. We show that StreamingLLM can enable Llama-2, MPT, Falcon, and Pythia to perform stable and efficient language modeling with up to 4 million tokens and more. In addition, we discover that adding a placeholder token as a dedicated attention sink during pre-training can further improve streaming deployment. In streaming settings, StreamingLLM outperforms the sliding window recomputation baseline by up to 22.2x speedup. Code and datasets are provided at https://github.com/mit-han-lab/streaming-llm.",
        "year": 2023,
        "authors": "Guangxuan Xiao and Yuandong Tian and Beidi Chen and Song Han and Mike Lewis"
      },
      {
        "title": "H  O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models",
        "abstract": "Large Language Models (LLMs), despite their recent impressive accomplishments, are notably cost-prohibitive to deploy, particularly for applications involving long-content generation, such as dialogue systems and story writing. Often, a large amount of transient state information, referred to as the , is stored in GPU memory in addition to model parameters, scaling linearly with the sequence length and batch size. In this paper, we introduce a novel approach for implementing the  which significantly reduces its memory footprint. Our approach is based on the noteworthy observation that a small portion of tokens contributes most of the value when computing attention scores. We call these tokens Heavy Hitters (). Through a comprehensive investigation, we find that () the emergence of  is natural and strongly correlates with the frequent co-occurrence of tokens in the text, and () removing them results in significant performance degradation. Based on these insights, we propose Heavy Hitter Oracle (), a  eviction policy that dynamically retains a balance of recent and  tokens. We formulate the  eviction as a dynamic submodular problem and prove (under mild assumptions) a theoretical guarantee for our novel eviction algorithm which could help guide future work. We validate the accuracy of our algorithm with OPT, LLaMA, and GPT-NeoX across a wide range of tasks. Our implementation of  with 20\\% heavy hitters improves the throughput over three leading inference systems DeepSpeed Zero-Inference, Hugging Face Accelerate, and FlexGen by up to , , and  on OPT-6.7 B and OPT-30B. With the same …",
        "year": 2023,
        "authors": "Zhenyu Zhang and Ying Sheng and Tianyi Zhou and Tianlong Chen and Lianmin Zheng and Ruisi Cai and Zhao Song and Yuandong Tian and Christopher Ré and Clark Barrett and Zhangyang Wang and Beidi Chen"
      }
    ],
    "Wj4ZBFIAAAAJ": [
      {
        "title": "Computer architecture: a quantitative approach",
        "abstract": "Computer Architecture: A Quantitative Approach, Fifth Edition, explores the ways that software and technology in the cloud are accessed by digital media, such as cell phones, computers, tablets, and other mobile devices. The book, which became a part of Intel's 2012 recommended reading list for developers, covers the revolution of mobile computing. It also highlights the two most important factors in architecture today: parallelism and memory hierarchy. This fully updated edition is comprised of six chapters that follow a consistent framework: explanation of the ideas in each chapter; a crosscutting issues section, which presents how the concepts covered in one chapter connect with those given in other chapters; a putting it all together section that links these concepts by discussing how they are applied in real machine; and detailed examples of misunderstandings and architectural traps commonly encountered by developers and architects. Formulas for energy, static and dynamic power, integrated circuit costs, reliability, and availability are included. The book also covers virtual machines, SRAM and DRAM technologies, and new material on Flash memory. Other topics include the exploitation of instruction-level parallelism in high-performance processors, superscalar execution, dynamic scheduling and multithreading, vector architectures, multicore processors, and warehouse-scale computers (WSCs). There are updated case studies and completely new exercises. Additional reference appendices are available online. This book will be a valuable reference for computer architects, programmers, application developers, compiler and system …",
        "year": 2011,
        "authors": "John L Hennessy and David A Patterson"
      },
      {
        "title": "A view of cloud computing",
        "abstract": "Clearing the clouds away from the true potential and obstacles posed by this computing capability.",
        "year": 2010,
        "authors": "Michael Armbrust and Armando Fox and Rean Griffith and Anthony D Joseph and Randy Katz and Andy Konwinski and Gunho Lee and David Patterson and Ariel Rabkin and Ion Stoica and Matei Zaharia"
      },
      {
        "title": "Above the clouds: A berkeley view of cloud computing",
        "abstract": "Cloud Computing, the long-held dream of computing as a utility, has the potential to transform a large part of the IT industry, making software even more attractive as a service and shaping the way IT hardware is designed and purchased. Developers with innovative ideas for new Internet services no longer require the large capital outlays in hardware to deploy their service or the human expense to operate it. They need not be concerned about overprovisioning for a service whose popularity does not meet their predictions, thus wasting costly resources, or underprovisioning for one that becomes wildly popular, thus missing potential customers and revenue. Moreover, companies with large batch-oriented tasks can get results as quickly as their programs can scale, since using 1000 servers for one hour costs no more than using one server for 1000 hours. This elasticity of resources, without paying a premium for large scale, is unprecedented in the history of IT.Cloud Computing refers to both the applications delivered as services over the Internet and the hardware and systems software in the datacenters that provide those services. The services themselves have long been referred to as Software as a Service (SaaS). The datacenter hardware and software is what we will call a Cloud. When a Cloud is made available in a pay-as-you-go manner to the general public, we call it a Public Cloud; the service being sold is Utility Computing. We use the term Private Cloud to refer to internal datacenters of a business or other organization, not made available to the general public. Thus, Cloud Computing is the sum of SaaS and Utility Computing, but does not …",
        "year": 2009,
        "authors": "Michael Armbrust and Armando Fox and Rean Griffith and Anthony D Joseph and Randy H Katz and Andrew Konwinski and Gunho Lee and David A Patterson and Ariel Rabkin and Ion Stoica and Matei Zaharia"
      }
    ],
    "m0WCd-4AAAAJ": [
      {
        "title": "Cloud programming simplified: A berkeley view on serverless computing",
        "abstract": "Serverless cloud computing handles virtually all the system administration operations needed to make it easier for programmers to use the cloud. It provides an interface that greatly simplifies cloud programming, and represents an evolution that parallels the transition from assembly language to high-level programming languages. This paper gives a quick history of cloud computing, including an accounting of the predictions of the 2009 Berkeley View of Cloud Computing paper, explains the motivation for serverless computing, describes applications that stretch the current limits of serverless, and then lists obstacles and research opportunities required for serverless computing to fulfill its full potential. Just as the 2009 paper identified challenges for the cloud and predicted they would be addressed and that cloud use would accelerate, we predict these issues are solvable and that serverless computing will grow to dominate the future of cloud computing.",
        "year": 2019,
        "authors": "Eric Jonas and Johann Schleier-Smith and Vikram Sreekanti and Chia-Che Tsai and Anurag Khandelwal and Qifan Pu and Vaishaal Shankar and Joao Carreira and Karl Krauth and Neeraja Yadwadkar and Joseph E Gonzalez and Raluca Ada Popa and Ion Stoica and David A Patterson"
      },
      {
        "title": "Serverless computing: One step forward, two steps back",
        "abstract": "Serverless computing offers the potential to program the cloud in an autoscaling, pay-as-you go manner. In this paper we address critical gaps in first-generation serverless computing, which place its autoscaling potential at odds with dominant trends in modern computing: notably data-centric and distributed computing, but also open source and custom hardware. Put together, these gaps make current serverless offerings a bad fit for cloud innovation and particularly bad for data systems innovation. In addition to pinpointing some of the main shortfalls of current serverless architectures, we raise a set of challenges we believe must be met to unlock the radical potential that the cloud---with its exabytes of storage and millions of cores---should offer to innovative developers.",
        "year": 2018,
        "authors": "Joseph M Hellerstein and Jose Faleiro and Joseph E Gonzalez and Johann Schleier-Smith and Vikram Sreekanti and Alexey Tumanov and Chenggang Wu"
      },
      {
        "title": "Cloudburst: Stateful functions-as-a-service",
        "abstract": "Function-as-a-Service (FaaS) platforms and \"serverless\" cloud computing are becoming increasingly popular. Current FaaS offerings are targeted at stateless functions that do minimal I/O and communication. We argue that the benefits of serverless computing can be extended to a broader range of applications and algorithms. We present the design and implementation of Cloudburst, a stateful FaaS platform that provides familiar Python programming with low-latency mutable state and communication, while maintaining the autoscaling benefits of serverless computing. Cloudburst accomplishes this by leveraging Anna, an autoscaling key-value store, for state sharing and overlay routing combined with mutable caches co-located with function executors for data locality. Performant cache consistency emerges as a key challenge in this architecture. To this end, Cloudburst provides a combination of lattice-encapsulated state and new definitions and protocols for distributed session consistency. Empirical results on benchmarks and diverse applications show that Cloudburst makes stateful functions practical, reducing the state-management overheads of current FaaS platforms by orders of magnitude while also improving the state of the art in serverless consistency.",
        "year": 2020,
        "authors": "Vikram Sreekanti and Chenggang Wu and Xiayue Charles Lin and Johann Schleier-Smith and Jose M Faleiro and Joseph E Gonzalez and Joseph M Hellerstein and Alexey Tumanov"
      }
    ],
    "Ctp3igcAAAAJ": [
      {
        "title": "Random path selection for continual learning",
        "abstract": "Incremental life-long learning is a main challenge towards the long-standing goal of Artificial General Intelligence. In real-life settings, learning tasks arrive in a sequence and machine learning models must continually learn to increment already acquired knowledge. The existing incremental learning approaches fall well below the state-of-the-art cumulative models that use all training classes at once. In this paper, we propose a random path selection algorithm, called RPS-Net, that progressively chooses optimal paths for the new tasks while encouraging parameter sharing and reuse. Our approach avoids the overhead introduced by computationally expensive evolutionary and reinforcement learning based path selection strategies while achieving considerable performance gains. As an added novelty, the proposed model integrates knowledge distillation and retrospection along with the path selection strategy to overcome catastrophic forgetting. In order to maintain an equilibrium between previous and newly acquired knowledge, we propose a simple controller to dynamically balance the model plasticity. Through extensive experiments, we demonstrate that the proposed method surpasses the state-of-the-art performance on incremental learning and by utilizing parallel computation this method can run in constant time with nearly the same efficiency as a conventional deep convolutional neural network.",
        "year": 2019,
        "authors": "Jathushan Rajasegaran and Munawar Hayat and Salman H Khan and Fahad Shahbaz Khan and Ling Shao"
      },
      {
        "title": "Deepcaps: Going deeper with capsule networks",
        "abstract": "Capsule Network is a promising concept in deep learning, yet its true potential is not fully realized thus far, providing sub-par performance on several key benchmark datasets with complex data. Drawing intuition from the success achieved by Convolutional Neural Networks (CNNs) by going deeper, we introduce DeepCaps, a deep capsule network architecture which uses a novel 3D convolution based dynamic routing algorithm. With DeepCaps, we surpass the state-of-the-art capsule domain networks results on CIFAR10, SVHN and Fashion MNIST, while achieving a 68% reduction in the number of parameters. Further, we propose a class independent decoder network, which strengthens the use of reconstruction loss as a regularization term. This leads to an interesting property of the decoder, which allows us to identify and control the physical attributes of the images represented by the instantiation parameters.",
        "year": 2019,
        "authors": "Jathushan Rajasegaran and Vinoj Jayasundara and Sandaru Jayasekara and Hirunima Jayasekara and Suranga Seneviratne and Ranga Rodrigo"
      },
      {
        "title": "Humans in 4D: Reconstructing and tracking humans with transformers",
        "abstract": "We present an approach to reconstruct humans and track them over time. At the core of our approach, we propose a fully\" transformerized\" version of a network for human mesh recovery. This network, HMR 2.0, advances the state of the art and shows the capability to analyze unusual poses that have in the past been difficult to reconstruct from single images. To analyze video, we use 3D reconstructions from HMR 2.0 as input to a tracking system that operates in 3D. This enables us to deal with multiple people and maintain identities through occlusion events. Our complete approach, 4DHumans, achieves state-of-the-art results for tracking people from monocular video. Furthermore, we demonstrate the effectiveness of HMR 2.0 on the downstream task of action recognition, achieving significant improvements over previous pose-based action recognition approaches. Our code and models are available on the project website: https://shubham-goel. github. io/4dhumans/.",
        "year": 2023,
        "authors": "Shubham Goel and Georgios Pavlakos and Jathushan Rajasegaran and Angjoo Kanazawa and Jitendra Malik"
      }
    ],
    "07qshUgAAAAJ": [
      {
        "title": "A randomized scheduler with probabilistic guarantees of finding bugs",
        "abstract": "This paper presents a randomized scheduler for finding concurrency bugs. Like current stress-testing methods, it repeatedly runs a given test program with supplied inputs. However, it improves on stress-testing by finding buggy schedules more effectively and by quantifying the probability of missing concurrency bugs. Key to its design is the characterization of the depth of a concurrency bug as the minimum number of scheduling constraints required to find it. In a single run of a program with n threads and k steps, our scheduler detects a concurrency bug of depth d with probability at least 1/nkd-1. We hypothesize that in practice, many concurrency bugs (including well-known types such as ordering errors, atomicity violations, and deadlocks) have small bug-depths, and we confirm the efficiency of our schedule randomization by detecting previously unknown and known concurrency bugs in several production-scale …",
        "year": 2010,
        "authors": "Sebastian Burckhardt and Pravesh Kothari and Madanlal Musuvathi and Santosh Nagarakatte"
      },
      {
        "title": "A nearly tight sum-of-squares lower bound for the planted clique problem",
        "abstract": "We prove that with high probability over the choice of a random graph  from the Erdös--Rényi distribution , the -time degree  sum-of-squares (SOS) semidefinite programming relaxation for the clique problem will give a value of at least  for some constant .  This yields a nearly tight  bound on the value of this program for any degree . Moreover, we introduce a new framework that we call pseudocalibration to construct SOS lower bounds. This framework is  inspired by taking a computational analogue of Bayesian probability theory. It yields a general recipe for constructing  good pseudodistributions (i.e., dual certificates for the SOS semidefinite program)  and sheds further light on the ways in which this hierarchy differs from others.",
        "year": 2019,
        "authors": "Boaz Barak and Samuel Hopkins and Jonathan Kelner and Pravesh K Kothari and Ankur Moitra and Aaron Potechin"
      },
      {
        "title": "Differentially private online learning",
        "abstract": "In this paper, we consider the problem of preserving privacy in the context of online learning. Online learning involves learning from data in real-time, due to which the learned model as well as its predictions are continuously changing. This makes preserving privacy of each data point significantly more challenging as its effect on the learned model can be easily tracked by observing changes in the subsequent predictions. Furthermore, with more and more online systems (eg search engines like Bing, Google etc.) trying to learn their customers’ behavior by leveraging their access to sensitive customer data (through cookies etc.), the problem of privacy preserving online learning has become critical. We study the problem in the framework of online convex programming (OCP)–a popular online learning setting with several theoretical and practical implications–while using differential privacy as the formal measure of privacy. For this problem, we provide a generic framework that can be used to convert any given OCP algorithm into a private OCP algorithm with provable privacy as well as regret guarantees (utility), provided that the given OCP algorithm satisfies the following two criteria: 1) linearly decreasing sensitivity, ie, the effect of the new data points on the learned model decreases linearly, 2) sub-linear regret. We then illustrate our approach by converting two popular OCP algorithms into corresponding differentially private algorithms while guaranteeing\\emphÕ (√ T) regret for strongly convex functions. Next, we consider the practically important class of online linear regression problems, for which we generalize the approach by Dwork et al …",
        "year": 2012,
        "authors": "Prateek Jain and Pravesh Kothari and Abhradeep Thakurta"
      }
    ],
    "H3LMjtoAAAAJ": [
      {
        "title": "{PowerGraph}: Distributed {Graph-Parallel} computation on natural graphs",
        "abstract": "Large-scale graph-structured computation is central to tasks ranging from targeted advertising to natural language processing and has led to the development of several graph-parallel abstractions including Pregel and GraphLab. However, the natural graphs commonly found in the real-world have highly skewed power-law degree distributions, which challenge the assumptions made by these abstractions, limiting performance and scalability.",
        "year": 2012,
        "authors": "Joseph E Gonzalez and Yucheng Low and Haijie Gu and Danny Bickson and Carlos Guestrin"
      },
      {
        "title": "Distributed graphlab: A framework for machine learning in the cloud",
        "abstract": "While high-level data parallel frameworks, like MapReduce, simplify the design and implementation of large-scale data processing systems, they do not naturally or efficiently support many important data mining and machine learning algorithms and can lead to inefficient learning systems. To help fill this critical void, we introduced the GraphLab abstraction which naturally expresses asynchronous, dynamic, graph-parallel computation while ensuring data consistency and achieving a high degree of parallel performance in the shared-memory setting. In this paper, we extend the GraphLab framework to the substantially more challenging distributed setting while preserving strong data consistency guarantees. We develop graph based extensions to pipelined locking and data versioning to reduce network congestion and mitigate the effect of network latency. We also introduce fault tolerance to the GraphLab abstraction using the classic Chandy-Lamport snapshot algorithm and demonstrate how it can be easily implemented by exploiting the GraphLab abstraction itself. Finally, we evaluate our distributed implementation of the GraphLab abstraction on a large Amazon EC2 deployment and show 1-2 orders of magnitude performance gains over Hadoop-based implementations.",
        "year": 2012,
        "authors": "Yucheng Low and Joseph Gonzalez and Aapo Kyrola and Danny Bickson and Carlos Guestrin and Joseph M Hellerstein"
      },
      {
        "title": "Graphlab: A new framework for parallel machine learning",
        "abstract": "Designing and implementing efficient, provably correct parallel machine learning (ML) algorithms is challenging. Existing high-level parallel abstractions like MapReduce are insufficiently expressive while low-level tools like MPI and Pthreads leave ML experts repeatedly solving the same design challenges. By targeting common patterns in ML, we developed GraphLab, which improves upon abstractions like MapReduce by compactly expressing asynchronous iterative algorithms with sparse computational dependencies while ensuring data consistency and achieving a high degree of parallel performance. We demonstrate the expressiveness of the GraphLab framework by designing and implementing parallel versions of belief propagation, Gibbs sampling, Co-EM, Lasso and Compressed Sensing. We show that using GraphLab we can achieve excellent parallel performance on large scale real-world problems.",
        "year": 2014,
        "authors": "Yucheng Low and Joseph E Gonzalez and Aapo Kyrola and Danny Bickson and Carlos E Guestrin and Joseph Hellerstein"
      }
    ],
    "ITZ1e7MAAAAJ": [
      {
        "title": "Dropout: a simple way to prevent neural networks from overfitting",
        "abstract": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves …",
        "year": 2014,
        "authors": "Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov"
      },
      {
        "title": "Reducing the dimensionality of data with neural networks",
        "abstract": "High-dimensional data can be converted to low-dimensional codes by training a multilayer neural network with a small central layer to reconstruct high-dimensional input vectors. Gradient descent can be used for fine-tuning the weights in such “autoencoder” networks, but this works well only if the initial weights are close to a good solution. We describe an effective way of initializing the weights that allows deep autoencoder networks to learn low-dimensional codes that work much better than principal components analysis as a tool to reduce the dimensionality of data.",
        "year": 2006,
        "authors": "Geoffrey E Hinton and Ruslan R Salakhutdinov"
      },
      {
        "title": "Show, attend and tell: Neural image caption generation with visual attention",
        "abstract": "Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO.",
        "year": 2015,
        "authors": "Kelvin Xu and Jimmy Ba and Ryan Kiros and Kyunghyun Cho and Aaron Courville and Ruslan Salakhutdinov and Richard S Zemel and Yoshua Bengio"
      }
    ],
    "3ifikJ0AAAAJ": [
      {
        "title": "A unified approach to interpreting model predictions",
        "abstract": "Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include:(1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.",
        "year": 2017,
        "authors": "Scott Lundberg and Su-In Lee"
      },
      {
        "title": "From local explanations to global understanding with explainable AI for trees",
        "abstract": "Tree-based machine learning models such as random forests, decision trees and gradient boosted trees are popular nonlinear predictive models, yet comparatively little attention has been paid to explaining their predictions. Here we improve the interpretability of tree-based models through three main contributions.(1) A polynomial time algorithm to compute optimal explanations based on game theory.(2) A new type of explanation that directly measures local feature interaction effects.(3) A new set of tools for understanding global model structure based on combining many local explanations of each prediction. We apply these tools to three medical machine learning problems and show how combining many high-quality local explanations allows us to represent global structure while retaining local faithfulness to the original model. These tools enable us to (1) identify high-magnitude but low-frequency nonlinear …",
        "year": 2020,
        "authors": "Scott M Lundberg and Gabriel Erion and Hugh Chen and Alex DeGrave and Jordan M Prutkin and Bala Nair and Ronit Katz and Jonathan Himmelfarb and Nisha Bansal and Su-In Lee"
      },
      {
        "title": "Consistent individualized feature attribution for tree ensembles",
        "abstract": "Interpreting predictions from tree ensemble methods such as gradient boosting machines and random forests is important, yet feature attribution for trees is often heuristic and not individualized for each prediction. Here we show that popular feature attribution methods are inconsistent, meaning they can lower a feature's assigned importance when the true impact of that feature actually increases. This is a fundamental problem that casts doubt on any comparison between features. To address it we turn to recent applications of game theory and develop fast exact tree solutions for SHAP (SHapley Additive exPlanation) values, which are the unique consistent and locally accurate attribution values. We then extend SHAP values to interaction effects and define SHAP interaction values. We propose a rich visualization of individualized feature attributions that improves over classic attribution summaries and partial dependence plots, and a unique \"supervised\" clustering (clustering based on feature attributions). We demonstrate better agreement with human intuition through a user study, exponential improvements in run time, improved clustering performance, and better identification of influential features. An implementation of our algorithm has also been merged into XGBoost and LightGBM, see http://github.com/slundberg/shap for details.",
        "year": 2018,
        "authors": "Scott M Lundberg and Gabriel G Erion and Su-In Lee"
      }
    ],
    "bZ9oyW8AAAAJ": [
      {
        "title": "Theoretically Principled Trade-off between Robustness and Accuracy",
        "abstract": "We identify a trade-off between robustness and accuracy that serves as a guiding principle in the design of defenses against adversarial examples. Although this problem has been widely studied empirically, much remains unknown concerning the theory underlying this trade-off. In this work, we decompose the prediction error for adversarial examples (robust error) as the sum of the natural (classification) error and boundary error, and provide a differentiable upper bound using the theory of classification-calibrated loss, which is shown to be the tightest possible upper bound uniform over all probability distributions and measurable predictors. Inspired by our theoretical analysis, we also design a new defense method, TRADES, to trade adversarial robustness off against accuracy. Our proposed algorithm performs well experimentally in real-world datasets. The methodology is the foundation of our entry to the NeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of 2,000 submissions, surpassing the runner-up approach by 11.41% in terms of mean L_2 perturbation distance.",
        "year": 2019,
        "authors": "Hongyang Zhang and Yaodong Yu and Jiantao Jiao and Eric P Xing and Laurent El Ghaoui and Michael I Jordan"
      },
      {
        "title": "Rethinking Bias-Variance Trade-off for Generalization of Neural Networks",
        "abstract": "The classical bias-variance trade-off predicts that bias decreases and variance increase with model complexity, leading to a U-shaped risk curve. Recent work calls this into question for neural networks and other over-parameterized models, for which it is often observed that larger models generalize better. We provide a simple explanation of this by measuring the bias and variance of neural networks: while the bias is\\emph {monotonically decreasing} as in the classical theory, the variance is\\emph {unimodal} or bell-shaped: it increases then decreases with the width of the network. We vary the network architecture, loss function, and choice of dataset and confirm that variance unimodality occurs robustly for all models we considered. The risk curve is the sum of the bias and variance curves and displays different qualitative shapes depending on the relative scale of bias and variance, with the double descent in the recent literature as a special case. We corroborate these empirical results with a theoretical analysis of two-layer linear networks with random first layer. Finally, evaluation on out-of-distribution data shows that most of the drop in accuracy comes from increased bias while variance increases by a relatively small amount. Moreover, we find that deeper models decrease bias and increase variance for both in-distribution and out-of-distribution data.",
        "year": 2020,
        "authors": "Zitong Yang and Yaodong Yu and Chong You and Jacob Steinhardt and Yi Ma"
      },
      {
        "title": "Learning Diverse and Discriminative Representations via the Principle of Maximal Coding Rate Reduction",
        "abstract": "To learn intrinsic low-dimensional structures from high-dimensional data that most discriminate between classes, we propose the principle of {\\em Maximal Coding Rate Reduction}(), an information-theoretic measure that maximizes the coding rate difference between the whole dataset and the sum of each individual class. We clarify its relationships with most existing frameworks such as cross-entropy, information bottleneck, information gain, contractive and contrastive learning, and provide theoretical guarantees for learning diverse and discriminative features. The coding rate can be accurately computed from finite samples of degenerate subspace-like distributions and can learn intrinsic representations in supervised, self-supervised, and unsupervised settings in a unified manner. Empirically, the representations learned using this principle alone are significantly more robust to label corruptions in classification than those using cross-entropy, and can lead to state-of-the-art results in clustering mixed data from self-learned invariant features.",
        "year": 2020,
        "authors": "Yaodong Yu and Kwan Ho Ryan Chan and Chong You and Chaobing Song and Yi Ma"
      }
    ],
    "NSWI3OwAAAAJ": [
      {
        "title": "Palm-e: An embodied multimodal language model",
        "abstract": "Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.",
        "year": 2023,
        "authors": "Danny Driess and Fei Xia and Mehdi SM Sajjadi and Corey Lynch and Aakanksha Chowdhery and Ayzaan Wahid and Jonathan Tompson and Quan Vuong and Tianhe Yu and Wenlong Huang and Yevgen Chebotar and Pierre Sermanet and Daniel Duckworth and Sergey Levine and Vincent Vanhoucke and Karol Hausman and Marc Toussaint and Klaus Greff and Andy Zeng and Igor Mordatch and Pete Florence"
      },
      {
        "title": "Rt-1: Robotics transformer for real-world control at scale",
        "abstract": "By transferring knowledge from large, diverse, task-agnostic datasets, modern machine learning models can solve specific downstream tasks either zero-shot or with small task-specific datasets to a high level of performance. While this capability has been demonstrated in other fields such as computer vision, natural language processing or speech recognition, it remains to be shown in robotics, where the generalization capabilities of the models are particularly critical due to the difficulty of collecting real-world robotic data. We argue that one of the keys to the success of such general robotic models lies with open-ended task-agnostic training, combined with high-capacity architectures that can absorb all of the diverse, robotic data. In this paper, we present a model class, dubbed Robotics Transformer, that exhibits promising scalable model properties. We verify our conclusions in a study of different model classes and their ability to generalize as a function of the data size, model size, and data diversity based on a large-scale data collection on real robots performing real-world tasks. The project's website and videos can be found at robotics-transformer1.github.io",
        "year": 2022,
        "authors": "Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Joseph Dabis and Chelsea Finn and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Tomas Jackson and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Kuang-Huei Lee and Sergey Levine and Yao Lu and Utsav Malla and Deeksha Manjunath and Igor Mordatch and Ofir Nachum and Carolina Parada and Jodilyn Peralta and Emily Perez and Karl Pertsch and Jornell Quiambao and Kanishka Rao and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Kevin Sayed and Jaspiar Singh and Sumedh Sontakke and Austin Stone and Clayton Tan and Huong Tran and Vincent Vanhoucke and Steve Vega and Quan Vuong and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich"
      },
      {
        "title": "Rt-2: Vision-language-action models transfer web knowledge to robotic control",
        "abstract": "We study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robotic trajectory data and Internet-scale vision-language tasks, such as visual question answering. In contrast to other approaches, we propose a simple, general recipe to achieve this goal: in order to fit both natural language responses and robotic actions into the same format, we express the actions as text tokens and incorporate them directly into the training set of the model in the same way as natural language tokens. We refer to such category of models as vision-language-action models (VLA) and instantiate an example of such a model, which we call RT-2. Our extensive evaluation (6k evaluation trials) shows that our approach leads to performant robotic policies and enables RT-2 to obtain a range of emergent capabilities from Internet-scale training. This includes significantly improved generalization to novel objects, the ability to interpret commands not present in the robot training data (such as placing an object onto a particular number or icon), and the ability to perform rudimentary reasoning in response to user commands (such as picking up the smallest or largest object, or the one closest to another object). We further show that incorporating chain of …",
        "year": 2023,
        "authors": "Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Xi Chen and Krzysztof Choromanski and Tianli Ding and Danny Driess and Avinava Dubey and Chelsea Finn and Pete Florence and Chuyuan Fu and Montse Gonzalez Arenas and Keerthana Gopalakrishnan and Kehang Han and Karol Hausman and Alexander Herzog and Jasmine Hsu and Brian Ichter and Alex Irpan and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Lisa Lee and Tsang-Wei Edward Lee and Sergey Levine and Yao Lu and Henryk Michalewski and Igor Mordatch and Karl Pertsch and Kanishka Rao and Krista Reymann and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Pierre Sermanet and Jaspiar Singh and Anikait Singh and Radu Soricut and Huong Tran and Vincent Vanhoucke and Quan Vuong and Ayzaan Wahid and Stefan Welker and Paul Wohlhart and Jialin Wu and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich"
      }
    ],
    "FdNHp8QAAAAJ": [
      {
        "title": "Testing Robustness Against Unforeseen Adversaries",
        "abstract": "Most existing defenses against adversarial attacks only consider robustness to L_p-bounded distortions. In reality, the specific attack is rarely known in advance and adversaries are free to modify images in ways which lie outside any fixed distortion model; for example, adversarial rotations lie outside the set of L_p-bounded distortions. In this work, we advocate measuring robustness against a much broader range of unforeseen attacks, attacks whose precise form is unknown during defense design.  We propose several new attacks and a methodology for evaluating a defense against a diverse range of unforeseen distortions. First, we construct novel adversarial JPEG, Fog, Gabor, and Snow distortions to simulate more diverse adversaries. We then introduce UAR, a summary metric that measures the robustness of a defense against a given distortion.  Using UAR to assess robustness against existing and novel attacks, we perform an extensive study of adversarial robustness. We find that evaluation against existing L_p attacks yields redundant information which does not generalize to other attacks; we instead recommend evaluating against our significantly more diverse set of attacks. We further find that adversarial training against either one or multiple distortions fails to confer robustness to attacks with other distortion types.  These results underscore the need to evaluate and study robustness against unforeseen distortions.",
        "year": 2019,
        "authors": "Daniel* Kang and Yi* Sun and Dan Hendrycks and Tom Brown and Jacob Steinhardt"
      },
      {
        "title": "Evolving the olfactory system with machine learning",
        "abstract": "The convergent evolution of the fly and mouse olfactory system led us to ask whether the anatomic connectivity and functional logic of olfactory circuits would evolve in artificial neural networks trained to perform olfactory tasks. Artificial networks trained to classify odor identity recapitulate the connectivity inherent in the olfactory system. Input units are driven by a single receptor type, and units driven by the same receptor converge to form a glomerulus. Glomeruli exhibit sparse, unstructured connectivity onto a larger expansion layer of Kenyon cells. When trained to both classify odor identity and to impart innate valence onto odors, the network develops independent pathways for identity and valence classification. Thus, the defining features of fly and mouse olfactory systems also evolved in artificial neural networks trained to perform olfactory tasks. This implies that convergent evolution reflects an underlying logic …",
        "year": 2021,
        "authors": "Peter Y Wang and Yi Sun and Richard Axel and LF Abbott and Guangyu Robert Yang"
      },
      {
        "title": "Scaling up Trustless DNN Inference with Zero-Knowledge Proofs",
        "abstract": "As ML models have increased in capabilities and accuracy, so has the complexity of their deployments. Increasingly, ML model consumers are turning to service providers to serve the ML models in the ML-as-a-service (MLaaS) paradigm. As MLaaS proliferates, a critical requirement emerges: how can model consumers verify that the correct predictions were served, in the face of malicious, lazy, or buggy service providers? In this work, we present the first practical ImageNet-scale method to verify ML model inference non-interactively, i.e., after the inference has been done. To do so, we leverage recent developments in ZK-SNARKs (zero-knowledge succinct non-interactive argument of knowledge), a form of zero-knowledge proofs. ZK-SNARKs allows us to verify ML model execution non-interactively and with only standard cryptographic hardness assumptions. In particular, we provide the first ZK-SNARK proof of valid inference for a full resolution ImageNet model, achieving 79\\% top-5 accuracy. We further use these ZK-SNARKs to design protocols to verify ML model execution in a variety of scenarios, including for verifying MLaaS predictions, verifying MLaaS model accuracy, and using ML models for trustless retrieval. Together, our results show that ZK-SNARKs have the promise to make verified ML model inference practical.",
        "year": 2022,
        "authors": "Daniel Kang and Tatsunori Hashimoto and Ion Stoica and Yi Sun"
      }
    ],
    "D1okUccAAAAJ": [
      {
        "title": "Recognizing indoor scenes",
        "abstract": "Indoor scene recognition is a challenging open problem in high level vision. Most scene recognition models that work well for outdoor scenes perform poorly in the indoor domain. The main difficulty is that while some indoor scenes (e.g. corridors) can be well characterized by global spatial properties, others (e.g, bookstores) are better characterized by the objects they contain. More generally, to address the indoor scenes recognition problem we need a model that can exploit local and global discriminative information. In this paper we propose a prototype based model that can successfully combine both sources of information. To test our approach we created a dataset of 67 indoor scenes categories (the largest available) covering a wide range of domains. The results show that our approach can significantly outperform a state of the art classifier for the task.",
        "year": 2009,
        "authors": "Ariadna Quattoni and Antonio Torralba"
      },
      {
        "title": "Conditional random fields for object recognition",
        "abstract": "We present a discriminative part-based approach for the recognition of object classes from unsegmented cluttered scenes. Objects are modeled as flexible constellations of parts conditioned on local observations found by an interest operator. For each object class the probability of a given assignment of parts to local features is modeled by a Conditional Ran-dom Field (CRF). We propose an extension of the CRF framework that incorporates hidden variables and combines class conditional CRFs into a unified framework for part-based object recognition. The parameters of the CRF are estimated in a maximum likelihood framework and recogni-tion proceeds by finding the most likely class under our model. The main advantage of the proposed CRF framework is that it allows us to relax the assumption of conditional independence of the observed data (ie local features) often used in generative approaches, an assumption that might be too restrictive for a considerable number of object classes.",
        "year": 2004,
        "authors": "Ariadna Quattoni and Michael Collins and Trevor Darrell"
      },
      {
        "title": "Hidden conditional random fields for gesture recognition",
        "abstract": "We introduce a discriminative hidden-state approach for the recognition of human gestures. Gesture sequences often have a complex underlying structure, and models that can incorporate hidden structures have proven to be advantageous for recognition tasks. Most existing approaches to gesture recognition with hidden states employ a Hidden Markov Model or suitable variant (e.g., a factored or coupled state model) to model gesture streams; a significant limitation of these models is the requirement of conditional independence of observations. In addition, hidden states in a generative model are selected to maximize the likelihood of generating all the examples of a given gesture class, which is not necessarily optimal for discriminating the gesture class against other gestures. Previous discriminative approaches to gesture sequence recognition have shown promising results, but have not incorporated hidden …",
        "year": 2006,
        "authors": "Sy Bor Wang and Ariadna Quattoni and L-P Morency and David Demirdjian and Trevor Darrell"
      }
    ],
    "_kJ-zUYAAAAJ": [
      {
        "title": "Multimodal compact bilinear pooling for visual question answering and visual grounding",
        "abstract": "Modeling textual or visual information with vector representations trained from large language or visual datasets has been successfully explored in recent years. However, tasks such as visual question answering require combining these vector representations with each other. Approaches to multimodal pooling include element-wise product or sum, as well as concatenation of the visual and textual representations. We hypothesize that these methods are not as expressive as an outer product of the visual and textual vectors. As the outer product is typically infeasible due to its high dimensionality, we instead propose utilizing Multimodal Compact Bilinear pooling (MCB) to efficiently and expressively combine multimodal features. We extensively evaluate MCB on the visual question answering and grounding tasks. We consistently show the benefit of MCB over ablations without MCB. For visual question answering, we present an architecture which uses MCB twice, once for predicting attention over spatial features and again to combine the attended representation with the question representation. This model outperforms the state-of-the-art on the Visual7W dataset and the VQA challenge.",
        "year": 2016,
        "authors": "Akira Fukui and Dong Huk Park and Daylen Yang and Anna Rohrbach and Trevor Darrell and Marcus Rohrbach"
      },
      {
        "title": "Multimodal explanations: Justifying decisions and pointing to the evidence",
        "abstract": "Deep models that are both effective and explainable are desirable in many settings; prior explainable models have been unimodal, offering either image-based visualization of attention weights or text-based generation of post-hoc justifications. We propose a multimodal approach to explanation, and argue that the two modalities provide complementary explanatory strengths. We collect two new datasets to define and evaluate this task, and propose a novel model which can provide joint textual rationale generation and attention visualization. Our datasets define visual and textual justifications of a classification decision for activity recognition tasks (ACT-X) and for visual question answering tasks (VQA-X). We quantitatively show that training with the textual explanations not only yields better textual justification models, but also better localizes the evidence that supports the decision. We also qualitatively show cases where visual explanation is more insightful than textual explanation, and vice versa, supporting our thesis that multimodal explanation models offer significant benefits over unimodal approaches.",
        "year": 2018,
        "authors": "Dong Huk Park and Lisa Anne Hendricks and Zeynep Akata and Anna Rohrbach and Bernt Schiele and Trevor Darrell and Marcus Rohrbach"
      },
      {
        "title": "Toward transformer-based object detection",
        "abstract": "Transformers have become the dominant model in natural language processing, owing to their ability to pretrain on massive amounts of data, then transfer to smaller, more specific tasks via fine-tuning. The Vision Transformer was the first major attempt to apply a pure transformer model directly to images as input, demonstrating that as compared to convolutional networks, transformer-based architectures can achieve competitive results on benchmark classification tasks. However, the computational complexity of the attention operator means that we are limited to low-resolution inputs. For more complex tasks such as detection or segmentation, maintaining a high input resolution is crucial to ensure that models can properly identify and reflect fine details in their output. This naturally raises the question of whether or not transformer-based architectures such as the Vision Transformer are capable of performing tasks other than classification. In this paper, we determine that Vision Transformers can be used as a backbone by a common detection task head to produce competitive COCO results. The model that we propose, ViT-FRCNN, demonstrates several known properties associated with transformers, including large pretraining capacity and fast fine-tuning performance. We also investigate improvements over a standard detection backbone, including superior performance on out-of-domain images, better performance on large objects, and a lessened reliance on non-maximum suppression. We view ViT-FRCNN as an important stepping stone toward a pure-transformer solution of complex vision tasks such as object detection.",
        "year": 2020,
        "authors": "Josh Beal and Eric Kim and Eric Tzeng and Dong Huk Park and Andrew Zhai and Dmitry Kislyuk"
      }
    ],
    "evUv2MAAAAAJ": [
      {
        "title": "Cloud Programming Simplified: A Berkeley View on Serverless Computing",
        "abstract": "Serverless cloud computing handles virtually all the system administration operations needed to make it easier for programmers to use the cloud. It provides an interface that greatly simplifies cloud programming, and represents an evolution that parallels the transition from assembly language to high-level programming languages. This paper gives a quick history of cloud computing, including an accounting of the predictions of the 2009 Berkeley View of Cloud Computing paper, explains the motivation for serverless computing, describes applications that stretch the current limits of serverless, and then lists obstacles and research opportunities required for serverless computing to fulfill its full potential. Just as the 2009 paper identified challenges for the cloud and predicted they would be addressed and that cloud use would accelerate, we predict these issues are solvable and that serverless computing will grow to dominate the future of cloud computing.",
        "year": 2019,
        "authors": "Eric Jonas and Johann Schleier-Smith and Vikram Sreekanti and Chia-Che Tsai and Anurag Khandelwal and Qifan Pu and Vaishaal Shankar and Joao Carreira and Karl Krauth and Neeraja Yadwadkar and Joseph E Gonzalez and Raluca Ada Popa and Ion Stoica and David A Patterson"
      },
      {
        "title": "What serverless computing is and should become: The next phase of cloud computing",
        "abstract": "The evolution that serverless computing represents, the economic forces that shape it, why it could fail, and how it might fulfill its potential.",
        "year": 2021,
        "authors": "Johann Schleier-Smith and Vikram Sreekanti and Anurag Khandelwal and Joao Carreira and Neeraja J Yadwadkar and Raluca Ada Popa and Joseph E Gonzalez and Ion Stoica and David A Patterson"
      },
      {
        "title": "INFaaS: Automated Model-less Inference Serving",
        "abstract": "Despite existing work in machine learning inference serving, ease-of-use and cost efficiency remain challenges at large scales. Developers must manually search through thousands of model-variants—versions of already-trained models that differ in hardware, resource footprints, latencies, costs, and accuracies—to meet the diverse application requirements. Since requirements, query load, and applications themselves evolve over time, these decisions need to be made dynamically for each inference query to avoid excessive costs through naive autoscaling. To avoid navigating through the large and complex trade-off space of model-variants, developers often fix a variant across queries, and replicate it when load increases. However, given the diversity across variants and hardware platforms in the cloud, a lack of understanding of the trade-off space can incur significant costs to developers.",
        "year": 2021,
        "authors": "Francisco Romero and Qian Li and Neeraja J Yadwadkar and Christos Kozyrakis"
      }
    ],
    "fftO_HsAAAAJ": [
      {
        "title": "Recovery rl: Safe reinforcement learning with learned recovery zones",
        "abstract": "Safety remains a central obstacle preventing widespread use of RL in the real world: learning new tasks in uncertain environments requires extensive exploration, but safety requires limiting exploration. We propose Recovery RL, an algorithm which navigates this tradeoff by (1) leveraging offline data to learn about constraint violating zones before policy learning and (2) separating the goals of improving task performance and constraint satisfaction across two policies: a task policy that only optimizes the task reward and a recovery policy that guides the agent to safety when constraint violation is likely. We evaluate Recovery RL on 6 simulation domains, including two contact-rich manipulation tasks and an image-based navigation task, and an image-based obstacle avoidance task on a physical robot. We compare Recovery RL to 5 prior safe RL methods which jointly optimize for task performance and safety via …",
        "year": 2021,
        "authors": "Brijen Thananjeyan and Ashwin Balakrishna and Suraj Nair and Michael Luo and Krishnan Srinivasan and Minho Hwang and Joseph E Gonzalez and Julian Ibarz and Chelsea Finn and Ken Goldberg"
      },
      {
        "title": "Multilateral surgical pattern cutting in 2D orthotropic gauze with deep reinforcement learning policies for tensioning",
        "abstract": "In the Fundamentals of Laparoscopic Surgery (FLS) standard medical training regimen, the Pattern Cutting task requires residents to demonstrate proficiency by maneuvering two tools, surgical scissors and tissue gripper, to accurately cut a circular pattern on surgical gauze suspended at the corners. Accuracy of cutting depends on tensioning, wherein the gripper pinches a point on the gauze in R3 and pulls to induce and maintain tension in the material as cutting proceeds. An automated tensioning policy maps the current state of the gauze to output a direction of pulling as an action. The optimal tensioning policy depends on both the choice of pinch point and cutting trajectory. We explore the problem of learning a tensioning policy conditioned on specific cutting trajectories. Every timestep, we allow the gripper to react to the deformation of the gauze and progress of the cutting trajectory with a translation unit vector …",
        "year": 2017,
        "authors": "Brijen Thananjeyan and Animesh Garg and Sanjay Krishnan and Carolyn Chen and Lauren Miller and Ken Goldberg"
      },
      {
        "title": "Deep imitation learning of sequential fabric smoothing from an algorithmic supervisor",
        "abstract": "Sequential pulling policies to flatten and smooth fabrics have applications from surgery to manufacturing to home tasks such as bed making and folding clothes. Due to the complexity of fabric states and dynamics, we apply deep imitation learning to learn policies that, given color (RGB), depth (D), or combined color-depth (RGBD) images of a rectangular fabric sample, estimate pick points and pull vectors to spread the fabric to maximize coverage. To generate data, we develop a fabric simulator and an algorithmic supervisor that has access to complete state information. We train policies in simulation using domain randomization and dataset aggregation (DAgger) on three tiers of difficulty in the initial randomized configuration. We present results comparing five baseline policies to learned policies and report systematic comparisons of RGB vs D vs RGBD images as inputs. In simulation, learned policies achieve …",
        "year": 2020,
        "authors": "Daniel Seita and Aditya Ganapathi and Ryan Hoque and Minho Hwang and Edward Cen and Ajay Kumar Tanwani and Ashwin Balakrishna and Brijen Thananjeyan and Jeffrey Ichnowski and Nawid Jamali and Katsu Yamane and Soshi Iba and John Canny and Ken Goldberg"
      }
    ],
    "k7NgVSUAAAAJ": [
      {
        "title": "Multi-agent reinforcement learning: A selective overview of theories and algorithms",
        "abstract": "Recent years have witnessed significant advances in reinforcement learning (RL), which has registered tremendous success in solving various sequential decision-making problems in machine learning. Most of the successful RL applications, e.g., the games of Go and Poker, robotics, and autonomous driving, involve the participation of more than one single agent, which naturally fall into the realm of multi-agent RL (MARL), a domain with a relatively long history, and has recently re-emerged due to advances in single-agent RL techniques. Though empirically successful, theoretical foundations for MARL are relatively lacking in the literature. In this chapter, we provide a selective overview of MARL, with focus on algorithms backed by theoretical analysis. More specifically, we review the theoretical results of MARL algorithms mainly within two representative frameworks, Markov/stochastic games and extensive-form …",
        "year": 2021,
        "authors": "Kaiqing Zhang and Zhuoran Yang and Tamer Başar"
      },
      {
        "title": "Provably efficient reinforcement learning with linear function approximation",
        "abstract": "Modern Reinforcement Learning (RL) is commonly applied to practical problems with an enormous number of states, where\\emph {function approximation} must be deployed to approximate either the value function or the policy. The introduction of function approximation raises a fundamental set of challenges involving computational and statistical efficiency, especially given the need to manage the exploration/exploitation tradeoff. As a result, a core RL question remains open: how can we design provably efficient RL algorithms that incorporate function approximation? This question persists even in a basic setting with linear dynamics and linear rewards, for which only linear function approximation is needed. This paper presents the first provable RL algorithm with both polynomial runtime and polynomial sample complexity in this linear setting, without requiring a “simulator” or additional assumptions. Concretely, we prove that an optimistic modification of Least-Squares Value Iteration (LSVI)—a classical algorithm frequently studied in the linear setting—achieves  regret, where  is the ambient dimension of feature space,  is the length of each episode, and  is the total number of steps. Importantly, such regret is independent of the number of states and actions.",
        "year": 2023,
        "authors": "Chi Jin and Zhuoran Yang and Zhaoran Wang and Michael I Jordan"
      }
    ],
    "b8OxVWUAAAAJ": [
      {
        "title": "Cloud programming simplified: A berkeley view on serverless computing",
        "abstract": "Serverless cloud computing handles virtually all the system administration operations needed to make it easier for programmers to use the cloud. It provides an interface that greatly simplifies cloud programming, and represents an evolution that parallels the transition from assembly language to high-level programming languages. This paper gives a quick history of cloud computing, including an accounting of the predictions of the 2009 Berkeley View of Cloud Computing paper, explains the motivation for serverless computing, describes applications that stretch the current limits of serverless, and then lists obstacles and research opportunities required for serverless computing to fulfill its full potential. Just as the 2009 paper identified challenges for the cloud and predicted they would be addressed and that cloud use would accelerate, we predict these issues are solvable and that serverless computing will grow to dominate the future of cloud computing.",
        "year": 2019,
        "authors": "Eric Jonas and Johann Schleier-Smith and Vikram Sreekanti and Chia-Che Tsai and Anurag Khandelwal and Qifan Pu and Vaishaal Shankar and Joao Carreira and Karl Krauth and Neeraja Yadwadkar and Joseph E Gonzalez and Raluca Ada Popa and Ion Stoica and David A Patterson"
      },
      {
        "title": "Serverless computing: One step forward, two steps back",
        "abstract": "Serverless computing offers the potential to program the cloud in an autoscaling, pay-as-you go manner. In this paper we address critical gaps in first-generation serverless computing, which place its autoscaling potential at odds with dominant trends in modern computing: notably data-centric and distributed computing, but also open source and custom hardware. Put together, these gaps make current serverless offerings a bad fit for cloud innovation and particularly bad for data systems innovation. In addition to pinpointing some of the main shortfalls of current serverless architectures, we raise a set of challenges we believe must be met to unlock the radical potential that the cloud---with its exabytes of storage and millions of cores---should offer to innovative developers.",
        "year": 2018,
        "authors": "Joseph M Hellerstein and Jose Faleiro and Joseph E Gonzalez and Johann Schleier-Smith and Vikram Sreekanti and Alexey Tumanov and Chenggang Wu"
      },
      {
        "title": "Cloudburst: Stateful functions-as-a-service",
        "abstract": "Function-as-a-Service (FaaS) platforms and \"serverless\" cloud computing are becoming increasingly popular. Current FaaS offerings are targeted at stateless functions that do minimal I/O and communication. We argue that the benefits of serverless computing can be extended to a broader range of applications and algorithms. We present the design and implementation of Cloudburst, a stateful FaaS platform that provides familiar Python programming with low-latency mutable state and communication, while maintaining the autoscaling benefits of serverless computing. Cloudburst accomplishes this by leveraging Anna, an autoscaling key-value store, for state sharing and overlay routing combined with mutable caches co-located with function executors for data locality. Performant cache consistency emerges as a key challenge in this architecture. To this end, Cloudburst provides a combination of lattice-encapsulated state and new definitions and protocols for distributed session consistency. Empirical results on benchmarks and diverse applications show that Cloudburst makes stateful functions practical, reducing the state-management overheads of current FaaS platforms by orders of magnitude while also improving the state of the art in serverless consistency.",
        "year": 2020,
        "authors": "Vikram Sreekanti and Chenggang Wu and Xiayue Charles Lin and Johann Schleier-Smith and Jose M Faleiro and Joseph E Gonzalez and Joseph M Hellerstein and Alexey Tumanov"
      }
    ],
    "xegzhJcAAAAJ": [
      {
        "title": "Imagenet classification with deep convolutional neural networks",
        "abstract": "We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7\\% and 18.9\\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.",
        "year": 2012,
        "authors": "Alex Krizhevsky and Ilya Sutskever and Geoffrey E Hinton"
      },
      {
        "title": "Dropout: a simple way to prevent neural networks from overfitting",
        "abstract": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves …",
        "year": 2014,
        "authors": "Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov"
      },
      {
        "title": "Learning multiple layers of features from tiny images",
        "abstract": "In this work we describe how to train a multi-layer generative model of natural images. We use a dataset of millions of tiny colour images, described in the next section. This has been attempted by several groups but without success [3, 7]. The models on which we focus are RBMs (Restricted Boltzmann Machines) and DBNs (Deep Belief Networks). These models learn interesting-looking filters, which we show are more useful to a classifier than the raw pixels. We train the classifier on a labeled subset that we have collected and call the CIFAR-10 dataset.",
        "year": 2009,
        "authors": "Alex Krizhevsky and Geoffrey Hinton"
      }
    ],
    "bRWa8q8AAAAJ": [
      {
        "title": "Struq: Defending against prompt injection with structured queries",
        "abstract": "Recent advances in Large Language Models (LLMs) enable exciting LLM-integrated applications, which perform text-based tasks by utilizing their advanced language understanding capabilities. However, as LLMs have improved, so have the attacks against them. Prompt injection attacks are an important threat: they trick the model into deviating from the original application's instructions and instead follow user directives. These attacks rely on the LLM's ability to follow instructions and inability to separate prompts and user data. We introduce structured queries, a general approach to tackle this problem. Structured queries separate prompts and data into two channels. We implement a system that supports structured queries. This system is made of (1) a secure front-end that formats a prompt and user data into a special format, and (2) a specially trained LLM that can produce high-quality outputs from these inputs. The LLM is trained using a novel fine-tuning strategy: we convert a base (non-instruction-tuned) LLM to a structured instruction-tuned model that will only follow instructions in the prompt portion of a query. To do so, we augment standard instruction tuning datasets with examples that also include instructions in the data portion of the query, and fine-tune the model to ignore these. Our system significantly improves resistance to prompt injection attacks, with little or no impact on utility. Our code is released at https://github.com/Sizhe-Chen/StruQ.",
        "year": 2024,
        "authors": "Sizhe Chen and Julien Piet and Chawin Sitawarin and David Wagner"
      },
      {
        "title": "Jatmo: Prompt injection defense by task-specific finetuning",
        "abstract": "Large Language Models (LLMs) are attracting significant research attention due to their instruction-following abilities, allowing users and developers to leverage LLMs for a variety of tasks. However, LLMs are vulnerable to prompt-injection attacks: a class of attacks that hijack the model’s instruction-following abilities, changing responses to prompts to undesired, possibly malicious ones. In this work, we introduce Jatmo , a method for generating task-specific models resilient to prompt-injection attacks. Jatmo leverages the fact that LLMs can only follow instructions once they have undergone instruction tuning. It harnesses a teacher instruction-tuned model to generate a task-specific dataset, which is then used to fine-tune a base model (i.e., a non-instruction-tuned model). Jatmo only needs a task prompt and a dataset of inputs for the task: it uses the teacher model to generate outputs. For situations with no pre …",
        "year": 2023,
        "authors": "Julien Piet and Maha Alrashed and Chawin Sitawarin and Sizhe Chen and Zeming Wei and Elizabeth Sun and Basel Alomair and David Wagner"
      },
      {
        "title": "Extracting godl [sic] from the salt mines: Ethereum miners extracting value",
        "abstract": "Cryptocurrency miners have great latitude in deciding which transactions they accept, including their own, and the order in which they accept them. Ethereum miners in particular use this flexibility to collect MEV-Miner Extractable Value-by structuring transactions to extract additional revenue. Ethereum also contains numerous bots that attempt to obtain MEV based on public-but-not-yet-confirmed transactions. Private relays shelter operations from these selfsame bots by directly submitting transactions to mining pools. In this work, we develop an algorithm to detect MEV exploitation present in previously mined blocks. We use our implementation of the detector to analyze MEV usage and profit redistribution, finding that miners make the lion's share of the profits, rather than independent users of the private relays. More specifically, (i) 73% of private transactions hide trading activity or re-distribute miner rewards, and 87.6% of MEV collection is accomplished with privately submitted transactions, (ii) our algorithm finds more than $6M worth of MEV profit in a period of 12 days, two thirds of which go directly to miners, and (iii) MEV represents 9.2% of miners' profit from transaction fees. Furthermore, in those 12 days, we also identify four blocks that contain enough MEV profits to make time-bandit forking attacks economically viable for large miners, undermining the security and stability of Ethereum as a whole.",
        "year": 2022,
        "authors": "Julien Piet and Jaiden Fairoze and Nicholas Weaver"
      }
    ],
    "DpLFv4gAAAAJ": [
      {
        "title": "Xgboost: A scalable tree boosting system",
        "abstract": "Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.",
        "year": 2016,
        "authors": "Tianqi Chen and Carlos Guestrin"
      },
      {
        "title": "\" Why should i trust you?\" Explaining the predictions of any classifier",
        "abstract": "Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by …",
        "year": 2016,
        "authors": "Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin"
      },
      {
        "title": "Cost-effective outbreak detection in networks",
        "abstract": "Given a water distribution network, where should we place sensors toquickly detect contaminants? Or, which blogs should we read to avoid missing important stories?.These seemingly different problems share common structure: Outbreak detection can be modeled as selecting nodes (sensor locations, blogs) in a network, in order to detect the spreading of a virus or information asquickly as possible. We present a general methodology for near optimal sensor placement in these and related problems. We demonstrate that many realistic outbreak detection objectives (e.g., detection likelihood, population affected) exhibit the property of \"submodularity\". We exploit submodularity to develop an efficient algorithm that scales to large problems, achieving near optimal placements, while being 700 times faster than a simple greedy algorithm. We also derive online bounds on the quality of the placements obtained by any …",
        "year": 2007,
        "authors": "Jure Leskovec and Andreas Krause and Carlos Guestrin and Christos Faloutsos and Jeanne VanBriesen and Natalie Glance"
      }
    ],
    "FUOEBDUAAAAJ": [
      {
        "title": "Minimum snap trajectory generation and control for quadrotors",
        "abstract": "We address the controller design and the trajectory generation for a quadrotor maneuvering in three dimensions in a tightly constrained setting typical of indoor environments. In such settings, it is necessary to allow for significant excursions of the attitude from the hover state and small angle approximations cannot be justified for the roll and pitch. We develop an algorithm that enables the real-time generation of optimal trajectories through a sequence of 3-D positions and yaw angles, while ensuring safe passage through specified corridors and satisfying constraints on velocities, accelerations and inputs. A nonlinear controller ensures the faithful tracking of these trajectories. Experimental results illustrate the application of the method to fast motion (5–10 body lengths/second) in three-dimensional slalom courses.",
        "year": 2011,
        "authors": "Daniel Mellinger and Vijay Kumar"
      },
      {
        "title": "Multirotor aerial vehicles: Modeling, estimation, and control of quadrotor",
        "abstract": "This article provides a tutorial introduction to modeling, estimation, and control formultirotor aerial vehicles that includes the common four-rotor or quadrotor case.",
        "year": 2012,
        "authors": "Robert Mahony and Vijay Kumar and Peter Corke"
      },
      {
        "title": "Robotic grasping and contact: A review",
        "abstract": "In this paper, we survey the field of robotic grasping and the work that has been done in this area over the last two decades, with a slight bias toward the development of the theoretical framework and analytical results in this area.",
        "year": 2000,
        "authors": "Antonio Bicchi and Vijay Kumar"
      }
    ],
    "9GMg6q8AAAAJ": [
      {
        "title": "Deep imitation learning for complex manipulation tasks from virtual reality teleoperation",
        "abstract": "Imitation learning is a powerful paradigm for robot skill acquisition. However, obtaining demonstrations suitable for learning a policy that maps from raw pixels to actions can be challenging. In this paper we describe how consumer-grade Virtual Reality headsets and hand tracking hardware can be used to naturally teleoperate robots to perform complex tasks. We also describe how imitation learning can learn deep neural network policies (mapping from pixels to actions) that can acquire the demonstrated skills. Our experiments showcase the effectiveness of our approach for learning visuomotor skills.",
        "year": 2018,
        "authors": "Tianhao Zhang and Zoe McCarthy and Owen Jowl and Dennis Lee and Xi Chen and Ken Goldberg and Pieter Abbeel"
      },
      {
        "title": "One-shot visual imitation learning via meta-learning",
        "abstract": "In order for a robot to be a generalist that can perform a wide range of jobs, it must be able to acquire a wide variety of skills quickly and efficiently in complex unstructured environments. High-capacity models such as deep neural networks can enable a robot to represent complex skills, but learning each skill from scratch then becomes infeasible. In this work, we present a meta-imitation learning method that enables a robot to learn how to learn more efficiently, allowing it to acquire new skills from just a single demonstration. Unlike prior methods for one-shot imitation, our method can scale to raw pixel inputs and requires data from significantly fewer prior tasks for effective learning of new skills. Our experiments on both simulated and real robot platforms demonstrate the ability to learn new tasks, end-to-end, from a single visual demonstration.",
        "year": 2017,
        "authors": "Chelsea Finn and Tianhe Yu and Tianhao Zhang and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Learning Deep Control Policies for Autonomous Aerial Vehicles with MPC-Guided Policy Search",
        "abstract": "Model predictive control (MPC) is an effective method for controlling robotic systems, particularly autonomous aerial vehicles such as quadcopters. However, application of MPC can be computationally demanding, and typically requires estimating the state of the system, which can be challenging in complex, unstructured environments. Reinforcement learning can in principle forego the need for explicit state estimation and acquire a policy that directly maps sensor readings to actions, but is difficult to apply to unstable systems that are liable to fail catastrophically during training before an effective policy has been found. We propose to combine MPC with reinforcement learning in the framework of guided policy search, where MPC is used to generate data at training time, under full state observations provided by an instrumented training environment. This data is used to train a deep neural network policy, which is …",
        "year": 2016,
        "authors": "Tianhao Zhang and Gregory Kahn and Sergey Levine and Pieter Abbeel"
      }
    ],
    "5JserkUAAAAJ": [
      {
        "title": "Gemini: a family of highly capable multimodal models",
        "abstract": "This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.",
        "year": 2023,
        "authors": "Gemini Team and Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M Dai and Anja Hauth and Katie Millican and David Silver and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Jack Krawczyk and Cosmo Du and Ed Chi and Heng-Tze Cheng and Eric Ni and Purvi Shah and Patrick Kane and Betty Chan and Manaal Faruqui and Aliaksei Severyn and Hanzhao Lin and YaGuang Li and Yong Cheng and Abe Ittycheriah and Mahdis Mahdieh and Mia Chen and Pei Sun and Dustin Tran and Sumit Bagri and Balaji Lakshminarayanan and Jeremiah Liu and Andras Orban and Fabian Güra and Hao Zhou and Xinying Song and Aurelien Boffy and Harish Ganapathy and Steven Zheng and HyunJeong Choe and Ágoston Weisz and Tao Zhu and Yifeng Lu and Siddharth Gopal and Jarrod Kahn and Maciej Kula and Jeff Pitman and Rushin Shah and Emanuel Taropa and Majd Al Merey and Martin Baeuml and Zhifeng Chen and Laurent El Shafey and Yujing Zhang and Olcan Sercinoglu and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Anaïs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Gaurav Singh Tomar and Evan Senter and Martin Chadwick and Ilya Kornakov and Nithya Attaluri and Iñaki Iturrate and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Xavier Garcia and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco"
      },
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien MR Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan"
      },
      {
        "title": "Metric learning by collapsing classes",
        "abstract": "We present an algorithm for learning a quadratic Gaussian metric (Mahalanobis distance) for use in classification tasks. Our method relies on the simple geometric intuition that a good metric is one under which points in the same class are simultaneously near each other and far from points in the other classes. We construct a convex optimization problem whose solution generates such a metric by trying to collapse all examples in the same class to a single point and push examples in other classes infinitely far away. We show that when the metric we learn is used in simple classifiers, it yields substantial improvements over standard alternatives on a variety of problems. We also discuss how the learned metric may be used to obtain a compact low dimensional feature representation of the original input space, allowing more efficient classification with very little reduction in performance.",
        "year": 2005,
        "authors": "Amir Globerson and Sam Roweis"
      }
    ],
    "owqhKD8AAAAJ": [
      {
        "title": "Openai o1 system card",
        "abstract": "The o1 model series is trained with large-scale reinforcement learning to reason using chain of thought. These advanced reasoning capabilities provide new avenues for improving the safety and robustness of our models. In particular, our models can reason about our safety policies in context when responding to potentially unsafe prompts, through deliberative alignment. This leads to state-of-the-art performance on certain benchmarks for risks such as generating illicit advice, choosing stereotyped responses, and succumbing to known jailbreaks. Training models to incorporate a chain of thought before answering has the potential to unlock substantial benefits, while also increasing potential risks that stem from heightened intelligence. Our results underscore the need for building robust alignment methods, extensively stress-testing their efficacy, and maintaining meticulous risk management protocols. This report outlines the safety work carried out for the OpenAI o1 and OpenAI o1-mini models, including safety evaluations, external red teaming, and Preparedness Framework evaluations.",
        "year": 2024,
        "authors": "Aaron Jaech and Adam Kalai and Adam Lerer and Adam Richardson and Ahmed El-Kishky and Aiden Low and Alec Helyar and Aleksander Madry and Alex Beutel and Alex Carney and Alex Iftimie and Alex Karpenko and Alex Tachard Passos and Alexander Neitz and Alexander Prokofiev and Alexander Wei and Allison Tam and Ally Bennett and Ananya Kumar and Andre Saraiva and Andrea Vallone and Andrew Duberstein and Andrew Kondrich and Andrey Mishchenko and Andy Applebaum and Angela Jiang and Ashvin Nair and Barret Zoph and Behrooz Ghorbani and Ben Rossen and Benjamin Sokolowsky and Boaz Barak and Bob McGrew and Borys Minaiev and Botao Hao and Bowen Baker and Brandon Houghton and Brandon McKinzie and Brydon Eastman and Camillo Lugaresi and Cary Bassin and Cary Hudson and Chak Ming Li and Charles de Bourcy and Chelsea Voss and Chen Shen and Chong Zhang and Chris Koch and Chris Orsinger and Christopher Hesse and Claudia Fischer and Clive Chan and Dan Roberts and Daniel Kappler and Daniel Levy and Daniel Selsam and David Dohan and David Farhi and David Mely and David Robinson and Dimitris Tsipras and Doug Li and Dragos Oprica and Eben Freeman and Eddie Zhang and Edmund Wong and Elizabeth Proehl and Enoch Cheung and Eric Mitchell and Eric Wallace and Erik Ritter and Evan Mays and Fan Wang and Felipe Petroski Such and Filippo Raso and Florencia Leoni and Foivos Tsimpourlas and Francis Song and Fred von Lohmann and Freddie Sulit and Geoff Salmon and Giambattista Parascandolo and Gildas Chabot and Grace Zhao and Greg Brockman and Guillaume Leclerc and Hadi Salman and Haiming Bao and Hao Sheng and Hart Andrin and Hessam Bagherinezhad and Hongyu Ren and Hunter Lightman and Hyung Won Chung and Ian Kivlichan and Ian O'Connell and Ian Osband and Ignasi Clavera Gilaberte and Ilge Akkaya and Ilya Kostrikov and Ilya Sutskever and Irina Kofman and Jakub Pachocki and James Lennon and Jason Wei and Jean Harb and Jerry Twore and Jiacheng Feng and Jiahui Yu and Jiayi Weng and Jie Tang and Jieqi Yu and Joaquin Quiñonero Candela and Joe Palermo and Joel Parish and Johannes Heidecke and John Hallman and John Rizzo and Jonathan Gordon and Jonathan Uesato and Jonathan Ward and Joost Huizinga and Julie Wang and Kai Chen and Kai Xiao and Karan Singhal and Karina Nguyen and Karl Cobbe and Katy Shi and Kayla Wood and Kendra Rimbach and Keren Gu-Lemberg and Kevin Liu and Kevin Lu and Kevin Stone and Kevin Yu and Lama Ahmad and Lauren Yang and Leo Liu and Leon Maksin and Leyton Ho and Liam Fedus and Lilian Weng and Linden Li and Lindsay McCallum and Lindsey Held and Lorenz Kuhn and Lukas Kondraciuk and Lukasz Kaiser and Luke Metz"
      },
      {
        "title": "The landscape of empirical risk for nonconvex losses",
        "abstract": "Most high-dimensional estimation methods propose to minimize a cost function (empirical risk) that is a sum of losses associated to each data point (each example). In this paper, we focus on the case of nonconvex losses. Classical empirical process theory implies uniform convergence of the empirical (or sample) risk to the population risk. While under additional assumptions, uniform convergence implies consistency of the resultingM-estimator, it does not ensure that the latter can be computed efficiently.In order to capture the complexity of computing M-estimators, we study the landscape of the empirical risk, namely its stationary points and their properties. We establish uniform convergence of the gradient and Hessian of the empirical risk to their population counterparts, as soon as the number of samples becomes larger than the number of unknown parameters (modulo logarithmic factors). Consequently, good …",
        "year": 2018,
        "authors": "Song Mei and Yu Bai and Andrea Montanari"
      },
      {
        "title": "Transformers as statisticians: Provable in-context learning with in-context algorithm selection",
        "abstract": "Neural sequence models based on the transformer architecture have demonstrated remarkable\\emph {in-context learning}(ICL) abilities, where they can perform new tasks when prompted with training and test examples, without any parameter update to the model. This work first provides a comprehensive statistical theory for transformers to perform ICL. Concretely, we show that transformers can implement a broad class of standard machine learning algorithms in context, such as least squares, ridge regression, Lasso, learning generalized linear models, and gradient descent on two-layer neural networks, with near-optimal predictive power on various in-context data distributions. Using an efficient implementation of in-context gradient descent as the underlying mechanism, our transformer constructions admit mild size bounds, and can be learned with polynomially many pretraining sequences. Building on these``base''ICL algorithms, intriguingly, we show that transformers can implement more complex ICL procedures involving\\emph {in-context algorithm selection}, akin to what a statistician can do in real life---A\\emph {single} transformer can adaptively select different base ICL algorithms---or even perform qualitatively different tasks---on different input sequences, without any explicit prompting of the right algorithm or task. We both establish this in theory by explicit constructions, and also observe this phenomenon experimentally. In theory, we construct two general mechanisms for algorithm selection with concrete examples: pre-ICL testing, and post-ICL validation. As an example, we use the post-ICL validation mechanism to construct a …",
        "year": 2023,
        "authors": "Yu Bai and Fan Chen and Huan Wang and Caiming Xiong and Song Mei"
      }
    ],
    "DplAah0AAAAJ": [
      {
        "title": "Decaf: A deep convolutional activation feature for generic visual recognition",
        "abstract": "We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.",
        "year": 2014,
        "authors": "Jeff Donahue and Yangqing Jia and Oriol Vinyals and Judy Hoffman and Ning Zhang and Eric Tzeng and Trevor Darrell"
      },
      {
        "title": "Deep domain confusion: Maximizing for domain invariance",
        "abstract": "Recent reports suggest that a generic supervised deep CNN model trained on a large-scale dataset reduces, but does not remove, dataset bias on a standard benchmark. Fine-tuning deep models in a new domain can require a significant amount of data, which for many applications is simply not available. We propose a new CNN architecture which introduces an adaptation layer and an additional domain confusion loss, to learn a representation that is both semantically meaningful and domain invariant. We additionally show that a domain confusion metric can be used for model selection to determine the dimension of an adaptation layer and the best position for the layer in the CNN architecture. Our proposed adaptation method offers empirical performance which exceeds previously published results on a standard benchmark visual domain adaptation task.",
        "year": 2014,
        "authors": "Eric Tzeng and Judy Hoffman and Ning Zhang and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Part-based R-CNNs for fine-grained category detection",
        "abstract": "Semantic part localization can facilitate fine-grained categorization by explicitly isolating subtle appearance differences associated with specific object parts. Methods for pose-normalized representations have been proposed, but generally presume bounding box annotations at test time due to the difficulty of object detection. We propose a model for fine-grained categorization that overcomes these limitations by leveraging deep convolutional features computed on bottom-up region proposals. Our method learns whole-object and part detectors, enforces learned geometric constraints between them, and predicts a fine-grained category from a pose-normalized representation. Experiments on the Caltech-UCSD bird dataset confirm that our method outperforms state-of-the-art fine-grained categorization methods in an end-to-end evaluation without requiring a bounding box at test time.",
        "year": 2014,
        "authors": "Ning Zhang and Jeff Donahue and Ross Girshick and Trevor Darrell"
      }
    ],
    "YTO4ex4AAAAJ": [
      {
        "title": "Bridgedata v2: A dataset for robot learning at scale",
        "abstract": "We introduce BridgeData V2, a large and diverse dataset of robotic manipulation behaviors designed to facilitate research in scalable robot learning. BridgeData V2 contains 53,896 trajectories collected across 24 environments on a publicly available low-cost robot. Unlike many existing robotic manipulation datasets, BridgeData V2 provides enough task and environment variability that skills learned from the data generalize across institutions, making the dataset a useful resource for a broad range of researchers. Additionally, the dataset is compatible with a wide variety of open-vocabulary, multi-task learning methods conditioned on goal images or natural language instructions. In our experiments, we apply 6 state-of-the-art imitation learning and offline reinforcement learning methods to the data and find that they succeed on a suite of tasks requiring varying amounts of generalization. We also demonstrate that the performance of these methods improves with more data and higher capacity models. By publicly sharing BridgeData V2 and our pre-trained models, we aim to accelerate research in scalable robot learning methods.",
        "year": 2023,
        "authors": "Homer Rich Walke and Kevin Black and Tony Z Zhao and Quan Vuong and Chongyi Zheng and Philippe Hansen-Estruch and Andre Wang He and Vivek Myers and Moo Jin Kim and Max Du and Abraham Lee and Kuan Fang and Chelsea Finn and Sergey Levine"
      },
      {
        "title": "Goal representations for instruction following: A semi-supervised language interface to control",
        "abstract": "Our goal is for robots to follow natural language instructions like “put the towel next to the microwave.” But getting large amounts of labeled data, ie data that contains demonstrations of tasks labeled with the language instruction, is prohibitive. In contrast, obtaining policies that respond to image goals is much easier, because any autonomous trial or demonstration can be labeled in hindsight with its final state as the goal. In this work, we contribute a method that taps into joint image-and goal-conditioned policies with language using only a small amount of language data. Prior work has made progress on this using vision-language models or by jointly training language-goal-conditioned policies, but so far neither method has scaled effectively to real-world robot tasks without significant human annotation. Our method achieves robust performance in the real world by learning an embedding from the labeled data that aligns language not to the goal image, but rather to the desired change between the start and goal images that the instruction corresponds to. We then train a policy on this embedding: the policy benefits from all the unlabeled data, but the aligned embedding provides an* interface* for language to steer the policy. We show instruction following across a variety of manipulation tasks in different scenes, with generalization to language instructions outside of the labeled data.",
        "year": 2023,
        "authors": "Vivek Myers and Andre Wang He and Kuan Fang and Homer Rich Walke and Philippe Hansen-Estruch and Ching-An Cheng and Mihai Jalobeanu and Andrey Kolobov and Anca Dragan and Sergey Levine"
      }
    ],
    "m_HQ-WQAAAAJ": [
      {
        "title": "Survey propagation: An algorithm for satisfiability",
        "abstract": "We study the satisfiability of randomly generated formulas formed by M clauses of exactly K literals over N Boolean variables. For a given value of N the problem is known to be most difficult when α = M/N is close to the experimental threshold αc separating the region where almost all formulas are SAT from the region where all formulas are UNSAT. Recent results from a statistical physics analysis suggest that the difficulty is related to the existence of a clustering phenomenon of the solutions when α is close to (but smaller than) αc. We introduce a new type of message passing algorithm which allows to find efficiently a satisfying assignment of the variables in this difficult region. This algorithm is iterative and composed of two main parts. The first is a message‐passing procedure which generalizes the usual methods like Sum‐Product or Belief Propagation: It passes messages that may be thought of as surveys over …",
        "year": 2005,
        "authors": "Alfredo Braunstein and Marc Mézard and Riccardo Zecchina"
      },
      {
        "title": "Network dismantling",
        "abstract": "We study the network dismantling problem, which consists of determining a minimal set of vertices in which removal leaves the network broken into connected components of subextensive size. For a large class of random graphs, this problem is tightly connected to the decycling problem (the removal of vertices, leaving the graph acyclic). Exploiting this connection and recent works on epidemic spreading, we present precise predictions for the minimal size of a dismantling set in a large random graph with a prescribed (light-tailed) degree distribution. Building on the statistical mechanics perspective, we propose a three-stage Min-Sum algorithm for efficiently dismantling networks, including heavy-tailed ones for which the dismantling and decycling problems are not equivalent. We also provide additional insights into the dismantling problem, concluding that it is an intrinsically collective problem and that optimal …",
        "year": 2016,
        "authors": "Alfredo Braunstein and Luca Dall’Asta and Guilhem Semerjian and Lenka Zdeborová"
      },
      {
        "title": "Bayesian inference of epidemics on networks via belief propagation",
        "abstract": "We study several Bayesian inference problems for irreversible stochastic epidemic models on networks from a statistical physics viewpoint. We derive equations which allow us to accurately compute the posterior distribution of the time evolution of the state of each node given some observations. At difference with most existing methods, we allow very general observation models, including unobserved nodes, state observations made at different or unknown times, and observations of infection times, possibly mixed together. Our method, which is based on the belief propagation algorithm, is efficient, naturally distributed, and exact on trees. As a particular case, we consider the problem of finding the “zero patient” of a susceptible-infected-recovered or susceptible-infected epidemic given a snapshot of the state of the network at a later unknown time. Numerical simulations show that our method outperforms previous …",
        "year": 2014,
        "authors": "Fabrizio Altarelli and Alfredo Braunstein and Luca Dall’Asta and Alejandro Lage-Castellanos and Riccardo Zecchina"
      }
    ],
    "eQujqDgAAAAJ": [
      {
        "title": "Competitive poaching in sponsored search advertising and its strategic impact on traditional advertising",
        "abstract": "Traditional advertising, such as TV and print advertising, primarily builds awareness of a firm's product among consumers, whereas sponsored search advertising on a search engine can target consumers closer to making a purchase because they reveal their interest by searching for a relevant keyword. Increased consumer targetability in sponsored search advertising induces a firm to “poach” a competing firm's consumers by directly advertising on the competing firm's keywords; in other words, the poaching firm tries to obtain more than its “fair share” of sales through sponsored search advertising by free riding on the market created by the firm being poached. Using a game theory model with firms of different advertising budgets, we study the phenomenon of poaching, its impact on how firms allocate their advertising budgets to traditional and sponsored search advertising, and the search engine's policy on …",
        "year": 2014,
        "authors": "Amin Sayedi and Kinshuk Jerath and Kannan Srinivasan"
      },
      {
        "title": "Minimizing movement",
        "abstract": "We give approximation algorithms and inapproximability results for a class of movement problems. In general, these problems involve planning the coordinated motion of a large collection of objects (representing anything from a robot swarm or firefighter team to map labels or network messages) to achieve a global property of the network while minimizing the maximum or average movement. In particular, we consider the goals of achieving connectivity (undirected and directed), achieving connectivity between a given pair of vertices, achieving independence (a dispersion problem), and achieving a perfect matching (with applications to multicasting). This general family of movement problems encompasses an intriguing range of graph and geometric algorithms, with several real-world applications and a surprising range of approximability. In some cases, we obtain tight approximation and inapproximability results …",
        "year": 2009,
        "authors": "Erik D Demaine and MohammadTaghi Hajiaghayi and Hamid Mahini and Amin S Sayedi-Roshkhar and Shayan Oveisgharan and Morteza Zadimoghaddam"
      },
      {
        "title": "Real-time bidding in online display advertising",
        "abstract": "Display advertising is a major source of revenue for many online publishers and content providers. Historically, display advertising impressions have been sold through prenegotiated contracts, known as reservation contracts, between publishers and advertisers. In recent years, a growing number of impressions are being sold in real-time bidding (RTB), where advertisers bid for impressions in real time, as consumers visit publishers’ websites. RTB allows advertisers to target consumers at an individual level using browser cookie information, and enables them to customize their ads for each individual. The rapid growth of RTB has created new challenges for advertisers and publishers on how much budget and ad inventory to allocate to RTB. In this paper, we use a game theory model with two advertisers and a publisher to study the effects of RTB on advertisers’ and publishers’ strategies and their profits. We show …",
        "year": 2018,
        "authors": "Amin Sayedi"
      }
    ],
    "1O83J5MAAAAJ": [
      {
        "title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Soft actor-critic algorithms and applications",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Conservative q-learning for offline reinforcement learning",
        "abstract": "Effectively leveraging large, previously collected datasets in reinforcement learn-ing (RL) is a key challenge for large-scale real-world applications. Offline RL algorithms promise to learn effective policies from previously-collected, static datasets without further interaction. However, in practice, offline RL presents a major challenge, and standard off-policy RL methods can fail due to overestimation of values induced by the distributional shift between the dataset and the learned policy, especially when training on complex and multi-modal data distributions. In this paper, we propose conservative Q-learning (CQL), which aims to address these limitations by learning a conservative Q-function such that the expected value of a policy under this Q-function lower-bounds its true value. We theoretically show that CQL produces a lower bound on the value of the current policy and that it can be incorporated into a policy learning procedure with theoretical improvement guarantees. In practice, CQL augments the standard Bellman error objective with a simple Q-value regularizer which is straightforward to implement on top of existing deep Q-learning and actor-critic implementations. On both discrete and continuous control domains, we show that CQL substantially outperforms existing offline RL methods, often learning policies that attain 2-5 times higher final return, especially when learning from complex and multi-modal data distributions.",
        "year": 2020,
        "authors": "Aviral Kumar and Aurick Zhou and George Tucker and Sergey Levine"
      }
    ],
    "OZ7PjVoAAAAJ": [
      {
        "title": "Objects as points",
        "abstract": "Detection identifies objects as axis-aligned boxes in an image. Most successful object detectors enumerate a nearly exhaustive list of potential object locations and classify each. This is wasteful, inefficient, and requires additional post-processing. In this paper, we take a different approach. We model an object as a single point --- the center point of its bounding box. Our detector uses keypoint estimation to find center points and regresses to all other object properties, such as size, 3D location, orientation, and even pose. Our center point based approach, CenterNet, is end-to-end differentiable, simpler, faster, and more accurate than corresponding bounding box based detectors. CenterNet achieves the best speed-accuracy trade-off on the MS COCO dataset, with 28.1% AP at 142 FPS, 37.4% AP at 52 FPS, and 45.1% AP with multi-scale testing at 1.4 FPS. We use the same approach to estimate 3D bounding box in the KITTI benchmark and human pose on the COCO keypoint dataset. Our method performs competitively with sophisticated multi-stage methods and runs in real-time.",
        "year": 2019,
        "authors": "Xingyi Zhou and Dequan Wang and Philipp Krähenbühl"
      },
      {
        "title": "Deep layer aggregation",
        "abstract": "Visual recognition requires rich representations that span levels from low to high, scales from small to large, and resolutions from fine to coarse. Even with the depth of features in a convolutional network, a layer in isolation is not enough: compounding and aggregating these representations improves inference of what and where. Architectural efforts are exploring many dimensions for network backbones, designing deeper or wider architectures, but how to best aggregate layers and blocks across a network deserves further attention. Although skip connections have been incorporated to combine layers, these connections have been``shallow''themselves, and only fuse by simple, one-step operations. We augment standard architectures with deeper aggregation to better fuse information across layers. Our deep layer aggregation structures iteratively and hierarchically merge the feature hierarchy to make networks with better accuracy and fewer parameters. Experiments across architectures and tasks show that deep layer aggregation improves recognition and resolution compared to existing branching and merging schemes.",
        "year": 2018,
        "authors": "Fisher Yu and Dequan Wang and Evan Shelhamer and Trevor Darrell"
      },
      {
        "title": "Tent: Fully test-time adaptation by entropy minimization",
        "abstract": "A model must adapt itself to generalize to new and different data during testing. In this setting of fully test-time adaptation the model has only the test data and its own parameters. We propose to adapt by test entropy minimization (tent): we optimize the model for confidence as measured by the entropy of its predictions. Our method estimates normalization statistics and optimizes channel-wise affine transformations to update online on each batch. Tent reduces generalization error for image classification on corrupted ImageNet and CIFAR-10/100 and reaches a new state-of-the-art error on ImageNet-C. Tent handles source-free domain adaptation on digit recognition from SVHN to MNIST/MNIST-M/USPS, on semantic segmentation from GTA to Cityscapes, and on the VisDA-C benchmark. These results are achieved in one epoch of test-time optimization without altering training.",
        "year": 2020,
        "authors": "Dequan Wang and Evan Shelhamer and Shaoteng Liu and Bruno Olshausen and Trevor Darrell"
      }
    ],
    "6dskOSUAAAAJ": [
      {
        "title": "Conditional image synthesis with auxiliary classifier gans",
        "abstract": "In this paper we introduce new methods for the improved training of generative adversarial networks (GANs) for image synthesis. We construct a variant of GANs employing label conditioning that results in  resolution image samples exhibiting global coherence. We expand on previous work for image quality assessment to provide two new analyses for assessing the discriminability and diversity of samples from class-conditional image synthesis models. These analyses demonstrate that high resolution samples provide class information not present in low resolution samples. Across 1000 ImageNet classes,  samples are more than twice as discriminable as artificially resized  samples. In addition, 84.7\\% of the classes have samples exhibiting diversity comparable to real ImageNet data.",
        "year": 2017,
        "authors": "Augustus Odena and Christopher Olah and Jonathon Shlens"
      },
      {
        "title": "Concrete problems in AI safety",
        "abstract": "Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function (\"avoiding side effects\" and \"avoiding reward hacking\"), an objective function that is too expensive to evaluate frequently (\"scalable supervision\"), or undesirable behavior during the learning process (\"safe exploration\" and \"distributional shift\"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.",
        "year": 2016,
        "authors": "Dario Amodei and Chris Olah and Jacob Steinhardt and Paul Christiano and John Schulman and Dan Mané"
      }
    ],
    "7OTD-LEAAAAJ": [
      {
        "title": "A ConvNet for the 2020s",
        "abstract": "The\" Roaring 20s\" of visual recognition began with the introduction of Vision Transformers (ViTs), which quickly superseded ConvNets as the state-of-the-art image classification model. A vanilla ViT, on the other hand, faces difficulties when applied to general computer vision tasks such as object detection and semantic segmentation. It is the hierarchical Transformers (eg, Swin Transformers) that reintroduced several ConvNet priors, making Transformers practically viable as a generic vision backbone and demonstrating remarkable performance on a wide variety of vision tasks. However, the effectiveness of such hybrid approaches is still largely credited to the intrinsic superiority of Transformers, rather than the inherent inductive biases of convolutions. In this work, we reexamine the design spaces and test the limits of what a pure ConvNet can achieve. We gradually\" modernize\" a standard ResNet toward the design of a vision Transformer, and discover several key components that contribute to the performance difference along the way. The outcome of this exploration is a family of pure ConvNet models dubbed ConvNeXt. Constructed entirely from standard ConvNet modules, ConvNeXts compete favorably with Transformers in terms of accuracy and scalability, achieving 87.8% ImageNet top-1 accuracy and outperforming Swin Transformers on COCO detection and ADE20K segmentation, while maintaining the simplicity and efficiency of standard ConvNets.",
        "year": 2022,
        "authors": "Zhuang Liu and Hanzi Mao and Chao-Yuan Wu and Christoph Feichtenhofer and Trevor Darrell and Saining Xie"
      },
      {
        "title": "Learning Efficient Convolutional Networks through Network Slimming",
        "abstract": "The deployment of deep convolutional neural networks (CNNs) in many real world applications is largely hindered by their high computational cost. In this paper, we propose a novel learning scheme for CNNs to simultaneously 1) reduce the model size; 2) decrease the run-time memory footprint; and 3) lower the number of computing operations, without compromising accuracy. This is achieved by enforcing channel-level sparsity in the network in a simple but effective way. Different from many existing approaches, the proposed method directly applies to modern CNN architectures, introduces minimum overhead to the training process, and requires no special software/hardware accelerators for the resulting models. We call our approach network slimming, which takes wide and large networks as input models, but during training insignificant channels are automatically identified and pruned afterwards, yielding thin and compact models with comparable accuracy. We empirically demonstrate the effectiveness of our approach with several state-of-the-art CNN models, including VGGNet, ResNet and DenseNet, on various image classification datasets. For VGGNet, a multi-pass version of network slimming gives a 20x reduction in model size and a 5x reduction in computing operations.",
        "year": 2017,
        "authors": "Zhuang Liu and Jianguo Li and Zhiqiang Shen and Gao Huang and Shoumeng Yan and Changshui Zhang"
      }
    ],
    "vN-is70AAAAJ": [
      {
        "title": "Chord: A scalable peer-to-peer lookup service for internet applications",
        "abstract": "A fundamental problem that confronts peer-to-peer applications is to efficiently locate the node that stores a particular data item. This paper presents Chord, a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data item pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis, simulations, and experiments show that Chord is scalable, with communication cost and the state maintained by each node scaling logarithmically with the number of Chord nodes.",
        "year": 2001,
        "authors": "Ion Stoica and Robert Morris and David Karger and M Frans Kaashoek and Hari Balakrishnan"
      },
      {
        "title": "A view of cloud computing",
        "abstract": "Clearing the clouds away from the true potential and obstacles posed by this computing capability.",
        "year": 2010,
        "authors": "Michael Armbrust and Armando Fox and Rean Griffith and Anthony D Joseph and Randy Katz and Andy Konwinski and Gunho Lee and David Patterson and Ariel Rabkin and Ion Stoica and Matei Zaharia"
      },
      {
        "title": "Spark: Cluster computing with working sets",
        "abstract": "MapReduce and its variants have been highly successful in implementing large-scale data-intensive applications on commodity clusters. However, most of these systems are built around an acyclic data flow model that is not suitable for other popular applications. This paper focuses on one such class of applications: those that reuse a working set of data across multiple parallel operations. This includes many iterative machine learning algorithms, as well as interactive data analysis tools. We propose a new framework called Spark that supports these applications while retaining the scalability and fault tolerance of MapReduce. To achieve these goals, Spark introduces an abstraction called resilient distributed datasets (RDDs). An RDD is a read-only collection of objects partitioned across a set of machines that can be rebuilt if a partition is lost. Spark can outperform Hadoop by 10x in iterative machine learning jobs, and can be used to interactively query a 39 GB dataset with sub-second response time.",
        "year": 2010,
        "authors": "Matei Zaharia and Mosharaf Chowdhury and Michael J Franklin and Scott Shenker and Ion Stoica"
      }
    ],
    "x1mbRloAAAAJ": [
      {
        "title": "Coresets for scalable Bayesian logistic regression",
        "abstract": "The use of Bayesian methods in large-scale data settings is attractive because of the rich hierarchical models, uncertainty quantification, and prior specification they provide. Standard Bayesian inference algorithms are computationally expensive, however, making their direct application to large datasets difficult or infeasible. Recent work on scaling Bayesian inference has focused on modifying the underlying algorithms to, for example, use only a random data subsample at each iteration. We leverage the insight that data is often redundant to instead obtain a weighted subset of the data (called a coreset) that is much smaller than the original dataset. We can then use this small coreset in any number of existing posterior inference algorithms without modification. In this paper, we develop an efficient coreset construction algorithm for Bayesian logistic regression models. We provide theoretical guarantees on the size and approximation quality of the coreset--both for fixed, known datasets, and in expectation for a wide class of data generative models. Crucially, the proposed approach also permits efficient construction of the coreset in both streaming and parallel settings, with minimal additional effort. We demonstrate the efficacy of our approach on a number of synthetic and real-world datasets, and find that, in practice, the size of the coreset is independent of the original dataset size. Furthermore, constructing the coreset takes a negligible amount of time compared to that required to run MCMC on it.",
        "year": 2016,
        "authors": "Jonathan H Huggins and Trevor Campbell and Tamara Broderick"
      },
      {
        "title": "Bidirectional contact tracing could dramatically improve COVID-19 control",
        "abstract": "Contact tracing is critical to controlling COVID-19, but most protocols only “forward-trace” to notify people who were recently exposed. Using a stochastic branching-process model, we find that “bidirectional” tracing to identify infector individuals and their other infectees robustly improves outbreak control. In our model, bidirectional tracing more than doubles the reduction in effective reproduction number (Reff) achieved by forward-tracing alone, while dramatically increasing resilience to low case ascertainment and test sensitivity. The greatest gains are realised by expanding the manual tracing window from 2 to 6 days pre-symptom-onset or, alternatively, by implementing high-uptake smartphone-based exposure notification; however, to achieve the performance of the former approach, the latter requires nearly all smartphones to detect exposure events. With or without exposure notification, our results suggest that …",
        "year": 2021,
        "authors": "William J Bradshaw and Ethan C Alley and Jonathan H Huggins and Alun L Lloyd and Kevin M Esvelt"
      },
      {
        "title": "Validated variational inference via practical posterior error bounds",
        "abstract": "Variational inference has become an increasingly attractive fast alternative to Markov chain Monte Carlo methods for approximate Bayesian inference. However, a major obstacle to the widespread use of variational methods is the lack of post-hoc accuracy measures that are both theoretically justified and computationally efficient. In this paper, we provide rigorous bounds on the error of posterior mean and uncertainty estimates that arise from full-distribution approximations, as in variational inference. Our bounds are widely applicable, as they require only that the approximating and exact posteriors have polynomial moments. Our bounds are also computationally efficient for variational inference because they require only standard values from variational objectives, straightforward analytic calculations, and simple Monte Carlo estimates. We show that our analysis naturally leads to a new and improved workflow for validated variational inference. Finally, we demonstrate the utility of our proposed workflow and error bounds on a robust regression problem and on a real-data example with a widely used multilevel hierarchical model.",
        "year": 2020,
        "authors": "Jonathan Huggins and Mikolaj Kasprzak and Trevor Campbell and Tamara Broderick"
      }
    ],
    "IB_jPZ0AAAAJ": [
      {
        "title": "Implicit regularization in nonconvex statistical estimation: Gradient descent converges linearly for phase retrieval, matrix completion, and blind deconvolution",
        "abstract": "Recent years have seen a flurry of activities in designing provably efficient nonconvex optimization procedures for solving statistical estimation problems. For various problems like phase retrieval or low-rank matrix completion, state-of-the-art nonconvex procedures require proper regularization (eg trimming, regularized cost, projection) in order to guarantee fast convergence. When it comes to vanilla procedures such as gradient descent, however, prior theory either recommends highly conservative learning rates to avoid overshooting, or completely lacks performance guarantees. This paper uncovers a striking phenomenon in several nonconvex problems: even in the absence of explicit regularization, gradient descent follows a trajectory staying within a basin that enjoys nice geometry, consisting of points incoherent with the sampling mechanism. This “implicit regularization” feature allows gradient descent to proceed in a far more aggressive fashion without overshooting, which in turn results in substantial computational savings. Focusing on two statistical estimation problems, ie solving random quadratic systems of equations and low-rank matrix completion, we establish that gradient descent achieves near-optimal statistical and computational guarantees without explicit regularization. As a byproduct, for noisy matrix completion, we demonstrate that gradient descent enables optimal control of both entrywise and spectral-norm errors.",
        "year": 2020,
        "authors": "Cong Ma and Kaizheng Wang and Yuejie Chi and Yuxin Chen"
      },
      {
        "title": "Bridging offline reinforcement learning and imitation learning: A tale of pessimism",
        "abstract": "Offline (or batch) reinforcement learning (RL) algorithms seek to learn an optimal policy from a fixed dataset without active data collection. Based on the composition of the offline dataset, two main methods are used: imitation learning which is suitable for expert datasets, and vanilla offline RL which often requires uniform coverage datasets. From a practical standpoint, datasets often deviate from these two extremes and the exact data composition is usually unknown. To bridge this gap, we present a new offline RL framework that smoothly interpolates between the two extremes of data composition, hence unifying imitation learning and vanilla offline RL. The new framework is centered around a weak version of the concentrability coefficient that measures the deviation of the behavior policy from the expert policy alone. Under this new framework, we ask: can one develop an algorithm that achieves a minimax optimal rate adaptive to unknown data composition? To address this question, we consider a lower confidence bound (LCB) algorithm developed based on pessimism in the face of uncertainty in offline RL. We study finite-sample properties of LCB as well as information-theoretic limits in multi-armed bandits, contextual bandits, and Markov decision processes (MDPs). Our analysis reveals surprising facts about optimality rates. In particular, in both contextual bandits and RL, LCB achieves a faster rate of  for nearly-expert datasets compared to the usual rate of  in offline RL, where  is the batch dataset sample size. In contextual bandits with at least two contexts, we prove that LCB is adaptively optimal for the entire data composition …",
        "year": 2021,
        "authors": "Paria Rashidinejad and Banghua Zhu and Cong Ma and Jiantao Jiao and Stuart Russell"
      },
      {
        "title": "Gradient descent with random initialization: Fast global convergence for nonconvex phase retrieval",
        "abstract": "This paper considers the problem of solving systems of quadratic equations, namely, recovering an object of interest $$\\varvec{x}^{\\natural }\\in {\\mathbb {R}}^{n}$$ from m quadratic equations/samples $$y_{i}=(\\varvec{a}_{i}^{\\top }\\varvec{x}^{\\natural })^{2}, 1\\le i\\le m$$. This problem, also dubbed as phase retrieval, spans multiple domains including physical sciences and machine learning. We investigate the efficacy of gradient descent (or Wirtinger flow) designed for the nonconvex least squares problem. We prove that under Gaussian designs, gradient descent—when randomly initialized—yields an -accurate solution in  iterations given nearly minimal samples, thus achieving near-optimal computational and sample complexities at once. This provides the first global convergence guarantee concerning vanilla gradient descent for phase retrieval, without the need of (i) carefully-designed …",
        "year": 2019,
        "authors": "Yuxin Chen and Yuejie Chi and Jianqing Fan and Cong Ma"
      }
    ],
    "DZ-fHPgAAAAJ": [
      {
        "title": "Learning with kernels: support vector machines, regularization, optimization, and beyond",
        "abstract": "A comprehensive introduction to Support Vector Machines and related kernel methods. In the 1990s, a new type of learning algorithm was developed, based on results from statistical learning theory: the Support Vector Machine (SVM). This gave rise to a new class of theoretically elegant learning machines that use a central concept of SVMs---kernels--for a number of learning tasks. Kernel machines provide a modular framework that can be adapted to different tasks and domains by the choice of the kernel function and the base algorithm. They are replacing neural networks in a variety of fields, including engineering, information retrieval, and bioinformatics. Learning with Kernels provides an introduction to SVMs and related kernel methods. Although the book begins with the basics, it also includes the latest research. It provides all of the concepts necessary to enable a reader equipped with some basic mathematical knowledge to enter the world of machine learning using theoretically well-founded yet easy-to-use kernel algorithms and to understand and apply the powerful algorithms that have been developed over the last few years.",
        "year": 2002,
        "authors": "Bernhard Schölkopf and Alexander J. Smola"
      },
      {
        "title": "A tutorial on support vector regression",
        "abstract": "In this tutorial we give an overview of the basic ideas underlying Support Vector (SV) machines for function estimation. Furthermore, we include a summary of currently used algorithms for training SV machines, covering both the quadratic (or convex) programming part and advanced methods for dealing with large datasets. Finally, we mention some modifications and extensions that have been applied to the standard SV algorithm, and discuss the aspect of regularization from a SV perspective.",
        "year": 2004,
        "authors": "Alex J Smola and Bernhard Schölkopf"
      },
      {
        "title": "Nonlinear component analysis as a kernel eigenvalue problem",
        "abstract": "A new method for performing a nonlinear form of principal component analysis is proposed. By the use of integral operator kernel functions, one can efficiently compute principal components in high-dimensional feature spaces, related to input space by some nonlinear map—for instance, the space of all possible five-pixel products in 16 × 16 images. We give the derivation of the method and present experimental results on polynomial feature extraction for pattern recognition.",
        "year": 1998,
        "authors": "Bernhard Schölkopf and Alexander Smola and Klaus-Robert Müller"
      }
    ],
    "9I7kD8sAAAAJ": [
      {
        "title": "Nexusraven: a commercially-permissive language model for function calling",
        "abstract": "The rise of open-source, commercially permissive large language models (LLMs) is revolutionizing generative AI, presenting organizations with enhanced control, minimized data risks, and cost benefits compared to proprietary models. However, in the field of tool use and function-calling LLMs, many open-source models, such as Gorilla and ToolLLAMA, are dependent on proprietary LLMs like GPT-4 for high-quality training data, which often faces legal restrictions for competitive commercial applications. In this paper, we introduce NexusRaven-13B, an open-source LLM designed for function calls. Originating from the CodeLLAMA-13B lineage, NexusRaven-13B employs a unique data curation via multi-step refinement, ensuring high-quality training data without relying on GPT-4 distillation.  NexusRaven-13B matches GPT-3.5 in zero-shot function-calling accuracy. When combined with our second core technique, demonstration retrieval augmentation, its performance significantly surpasses GPT-4. The code, model, and demo will be available after the review process.",
        "year": 2023,
        "authors": "Venkat Krishna Srinivasan and Zhen Dong and Banghua Zhu and Brian Yu and Damon Mosk-Aoyama and Kurt Keutzer and Jiantao Jiao and Jian Zhang"
      },
      {
        "title": "Simple and Effective Input Reformulations for Translation",
        "abstract": "Foundation language models learn from their finetuning input context in different ways. In this paper, we reformulate inputs during finetuning for challenging translation tasks, leveraging model strengths from pretraining in novel ways to improve downstream performance. These reformulations are simple data level modifications, require no additional collection of training data or modification of data at inference time. They can be applied either on single language pair translation tasks or massively multilingual translation tasks. Experiments with these techniques demonstrate significant performance improvements up to $\\textbf{3.5 chrF++ on the Flores200 translation benchmark}$. We hope our research accessibly improves finetuning data efficiency, enabling more effective training to scalably improve state-of-the-art performance. Our code is released $\\href{https://github.com/bri25yu/LanguageModelExperimentation}{here}.$",
        "year": 2023,
        "authors": "Brian Yu and Hansen Lillemark and Kurt Keutzer"
      },
      {
        "title": "Treating Models Better for Language-agnostic Understanding",
        "abstract": "State-of-the-art foundation language models have many strengths that are under-valued. Simultaneously, multilingual NLP lacks a clear goal. In this paper, we propose language-agnostic understanding as the goal of multilingual NLP and demonstrate that leveraging foundation language model strengths directly improves on this goal. We reformulate inputs during supervised finetuning to better leverage foundation language model strengths. We obtain significant improvements on challenging translation tasks compared to a baseline mT5 setup. On a Classical Tibetan to English translation task, these reformulations improve performance up to 2.8 BLEU. On the Flores200 translation benchmark, these reformulations improve performance up to 3.1 chrF++. Our research reveals insights into how models learn from different inputs, enabling more effective training to scalably improve state-of-the-art performance. We hope our research inspires further work that leverages foundation language model strengths and further work on language-agnostic understanding. Our experiments are released here.",
        "year": 2023,
        "authors": "Brian Yu and Kurt Keutzer and John DeNero"
      }
    ],
    "DcV-5RAAAAAJ": [
      {
        "title": "Network coding for distributed storage systems",
        "abstract": "Distributed storage systems provide reliable access to data through redundancy spread over individually unreliable nodes. Application scenarios include data centers, peer-to-peer storage systems, and storage in wireless networks. Storing data using an erasure code, in fragments spread across nodes, requires less redundancy than simple replication for the same level of reliability. However, since fragments must be periodically replaced as nodes fail, a key question is how to generate encoded fragments in a distributed way while transferring as little data as possible across the network. For an erasure coded system, a common practice to repair from a single node failure is for a new node to reconstruct the whole encoded data object to generate just one encoded block. We show that this procedure is sub-optimal. We introduce the notion of regenerating codes, which allow a new node to communicate  functions  of …",
        "year": 2010,
        "authors": "Alexandros G Dimakis and P Brighten Godfrey and Yunnan Wu and Martin J Wainwright and Kannan Ramchandran"
      },
      {
        "title": "Byzantine-robust distributed learning: Towards optimal statistical rates",
        "abstract": "In this paper, we develop distributed optimization algorithms that are provably robust against Byzantine failures—arbitrary and potentially adversarial behavior, in distributed computing systems, with a focus on achieving optimal statistical performance. A main result of this work is a sharp analysis of two robust distributed gradient descent algorithms based on median and trimmed mean operations, respectively. We prove statistical error rates for all of strongly convex, non-strongly convex, and smooth non-convex population loss functions. In particular, these algorithms are shown to achieve order-optimal statistical error rates for strongly convex losses. To achieve better communication efficiency, we further propose a median-based distributed algorithm that is provably robust, and uses only one communication round. For strongly convex quadratic loss, we show that this algorithm achieves the same optimal error rate as the robust distributed gradient descent algorithms.",
        "year": 2018,
        "authors": "Dong Yin and Yudong Chen and Ramchandran Kannan and Peter Bartlett"
      },
      {
        "title": "Distributed source coding using syndromes (DISCUS): Design and construction",
        "abstract": "We address the problem of compressing correlated distributed sources, i.e., correlated sources which are not co-located or which cannot cooperate to directly exploit their correlation. We consider the related problem of compressing a source which is correlated with another source that is available only at the decoder. This problem has been studied in the information theory literature under the name of the Slepian-Wolf (1973) source coding problem for the lossless coding case, and as \"rate-distortion with side information\" for the lossy coding case. We provide a constructive practical framework based on algebraic trellis codes dubbed as DIstributed Source Coding Using Syndromes (DISCUS), that can be applicable in a variety of settings. Simulation results are presented for source coding of independent and identically distributed (i.i.d.) Gaussian sources with side information available at the decoder in the form of a …",
        "year": 2003,
        "authors": "S Sandeep Pradhan and Kannan Ramchandran"
      }
    ],
    "pouyVyUAAAAJ": [
      {
        "title": "Squad: 100,000+ questions for machine comprehension of text",
        "abstract": "We present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at https://stanford-qa.com",
        "year": 2016,
        "authors": "Pranav Rajpurkar and Jian Zhang and Konstantin Lopyrev and Percy Liang"
      },
      {
        "title": "On the opportunities and risks of foundation models",
        "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",
        "year": 2021,
        "authors": "Rishi Bommasani and Drew A Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher Ré and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W Thomas and Florian Tramèr and Rose E Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang"
      },
      {
        "title": "Prefix-tuning: Optimizing continuous prompts for generation",
        "abstract": "Fine-tuning is the de facto way to leverage large pretrained language models to perform downstream tasks. However, it modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning for natural language generation tasks, which keeps language model parameters frozen, but optimizes a small continuous task-specific vector (called the prefix). Prefix-tuning draws inspiration from prompting, allowing subsequent tokens to attend to this prefix as if it were \"virtual tokens\". We apply prefix-tuning to GPT-2 for table-to-text generation and to BART for summarization. We find that by learning only 0.1\\% of the parameters, prefix-tuning obtains comparable performance in the full data setting, outperforms fine-tuning in low-data settings, and extrapolates better to examples with topics unseen during training.",
        "year": 2021,
        "authors": "Xiang Lisa Li and Percy Liang"
      }
    ],
    "X0EXfT8AAAAJ": [
      {
        "title": "Multi-content gan for few-shot font style transfer",
        "abstract": "In this work, we focus on the challenge of taking partial observations of highly-stylized text and generalizing the observations to generate unobserved glyphs in the ornamented typeface. To generate a set of multi-content images following a consistent style from very few examples, we propose an end-to-end stacked conditional GAN model considering content along channels and style along network layers. Our proposed network transfers the style of given glyphs to the contents of unseen ones, capturing highly stylized fonts found in the real-world such as those on movie posters or infographics. We seek to transfer both the typographic stylization (ex. serifs and ears) as well as the textual stylization (ex. color gradients and effects.) We base our experiments on our collected data set including 10,000 fonts with different styles and demonstrate effective generalization from a very small number of observed glyphs.",
        "year": 2018,
        "authors": "Samaneh Azadi and Matthew Fisher and Vladimir G Kim and Zhaowen Wang and Eli Shechtman and Trevor Darrell"
      },
      {
        "title": "Compositional gan: Learning image-conditional binary composition",
        "abstract": "Generative Adversarial Networks can produce images of remarkable complexity and realism but are generally structured to sample from a single latent source ignoring the explicit spatial interaction between multiple entities that could be present in a scene. Capturing such complex interactions between different objects in the world, including their relative scaling, spatial layout, occlusion, or viewpoint transformation is a challenging problem. In this work, we propose a novel self-consistent Composition-by-Decomposition network to compose a pair of objects. Given object images from two distinct distributions, our model can generate a realistic composite image from their joint distribution following the texture and shape of the input objects. We evaluate our approach through qualitative experiments and user evaluations. Our results indicate that the learned model captures potential interactions between the two object …",
        "year": 2020,
        "authors": "Samaneh Azadi and Deepak Pathak and Sayna Ebrahimi and Trevor Darrell"
      },
      {
        "title": "More Control for Free! Image Synthesis with Semantic Diffusion Guidance",
        "abstract": "Controllable image synthesis models allow creation of diverse images based on text instructions or guidance from a reference image. Recently, denoising diffusion probabilistic models have been shown to generate more realistic imagery than prior methods, and have been successfully demonstrated in unconditional and class-conditional settings. We investigate fine-grained, continuous control of this model class, and introduce a novel unified framework for semantic diffusion guidance, which allows either language or image guidance, or both. Guidance is injected into a pretrained unconditional diffusion model using the gradient of image-text or image matching scores, without re-training the diffusion model. We explore CLIP-based language guidance as well as both content and style-based image guidance in a unified framework. Our text-guided synthesis approach can be applied to datasets without associated text annotations. We conduct experiments on FFHQ and LSUN datasets, and show results on fine-grained text-guided image synthesis, synthesis of images related to a style or content reference image, and examples with both textual and image guidance.",
        "year": 2023,
        "authors": "Xihui Liu and Dong Huk Park and Samaneh Azadi and Gong Zhang and Arman Chopikyan and Yuxiao Hu and Humphrey Shi and Anna Rohrbach and Trevor Darrell"
      }
    ],
    "P4nfoKYAAAAJ": [
      {
        "title": "Eigenfaces for recognition",
        "abstract": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal …",
        "year": 1991,
        "authors": "Matthew Turk and Alex Pentland"
      },
      {
        "title": "Face recognition using eigenfaces.",
        "abstract": "We present an approach to thc dctcction and identification of human faces and describe a work-ig, near-real-time face recognition systen whiclı tracks a subject's head and then recognizes the person by comparing characteristics of the face to those of known individuals. Our approach treats face recognition as a two-dimensional recognition problem, taking advantage of the fact that faces are are normally upright and thus may be described by a small set of 2-D characteristic views. Face images are projected onto a feature space (“face space”) that bcst cncodcs the variation among known face images. The face space is defined by the “eigenfaces”, which are the eigenvectors of the set of faces; they do not necessarily correspond to isolated fea-tures such as eyes, ears, and noses. The framework provides the ability to learn to recognize new faces in an unsupervised manner.",
        "year": 1991,
        "authors": "Matthew A Turk and Alex Pentland"
      },
      {
        "title": "Pfinder: Real-time tracking of the human body",
        "abstract": "Pfinder is a real-time system for tracking people and interpreting their behavior. It runs at 10 Hz on a standard SGI Indy computer, and has performed reliably on thousands of people in many different physical locations. The system uses a multiclass statistical model of color and shape to obtain a 2D representation of head and hands in a wide range of viewing conditions. Pfinder has been successfully used in a wide range of applications including wireless interfaces, video databases, and low-bandwidth coding.",
        "year": 1997,
        "authors": "Christopher Richard  Wren and Ali Azarbayejani and Trevor Darrell and Alex Paul Pentland"
      }
    ],
    "L5jDQS8AAAAJ": [
      {
        "title": "Plug and play language models: A simple approach to controlled text generation",
        "abstract": "Large transformer-based language models (LMs) trained on huge text corpora have shown unparalleled generation capabilities. However, controlling attributes of the generated language (e.g. switching topic or sentiment) is difficult without modifying the model architecture or fine-tuning on attribute-specific data and entailing the significant cost of retraining. We propose a simple alternative: the Plug and Play Language Model (PPLM) for controllable language generation, which combines a pretrained LM with one or more simple attribute classifiers that guide text generation without any further training of the LM. In the canonical scenario we present, the attribute models are simple classifiers consisting of a user-specified bag of words or a single learned layer with 100,000 times fewer parameters than the LM. Sampling entails a forward and backward pass in which gradients from the attribute model push the LM's hidden activations and thus guide the generation. Model samples demonstrate control over a range of topics and sentiment styles, and extensive automated and human annotated evaluations show attribute alignment and fluency. PPLMs are flexible in that any combination of differentiable attribute models may be used to steer text generation, which will allow for diverse and creative applications beyond the examples given in this paper.",
        "year": 2019,
        "authors": "Sumanth Dathathri and Andrea Madotto and Janice Lan and Jane Hung and Eric Frank and Piero Molino and Jason Yosinski and Rosanne Liu"
      },
      {
        "title": "Deconstructing lottery tickets: Zeros, signs, and the supermask",
        "abstract": "The recent\" Lottery Ticket Hypothesis\" paper by Frankle & Carbin showed that a simple approach to creating sparse networks (keep the large weights) results in models that are trainable from scratch, but only when starting from the same initial weights. The performance of these networks often exceeds the performance of the non-sparse base model, but for reasons that were not well understood. In this paper we study the three critical components of the Lottery Ticket (LT) algorithm, showing that each may be varied significantly without impacting the overall results. Ablating these factors leads to new insights for why LT networks perform as well as they do. We show why setting weights to zero is important, how signs are all you need to make the re-initialized network train, and why masking behaves like training. Finally, we discover the existence of Supermasks, or masks that can be applied to an untrained, randomly initialized network to produce a model with performance far better than chance (86% on MNIST, 41% on CIFAR-10).",
        "year": 2019,
        "authors": "Hattie Zhou and Janice Lan and Rosanne Liu and Jason Yosinski"
      },
      {
        "title": "The Open Catalyst 2022 (OC22) dataset and challenges for oxide electrocatalysts",
        "abstract": "The development of machine learning models for electrocatalysts requires a broad set of training data to enable their use across a wide variety of materials. One class of materials that currently lacks sufficient training data is oxides, which are critical for the development of Oxygen Evolution Reaction (OER) catalysts. To address this, we developed the Open Catalyst 2022 (OC22) dataset, consisting of 62,331 Density Functional Theory (DFT) relaxations (∼9,854,504 single point calculations) across a range of oxide materials, coverages, and adsorbates. We define generalized total energy tasks that enable property prediction beyond adsorption energies; we test baseline performance of several graph neural networks; and we provide predefined dataset splits to establish clear benchmarks for future efforts. In the most general task, GemNet-OC sees a ∼36% improvement in energy predictions when combining the …",
        "year": 2023,
        "authors": "Richard Tran and Janice Lan and Muhammed Shuaibi and Brandon M Wood and Siddharth Goyal and Abhishek Das and Javier Heras-Domingo and Adeesh Kolluru and Ammar Rizvi and Nima Shoghi and Anuroop Sriram and Félix Therrien and Jehad Abed and Oleksandr Voznyy and Edward H Sargent and Zachary Ulissi and C Lawrence Zitnick"
      }
    ],
    "HQRnt54AAAAJ": [
      {
        "title": "Sparse PCA: Optimal rates and adaptive estimation",
        "abstract": "Supplement to “Sparse PCA: Optimal rates and adaptive estimation”. We provide proofs for all the remaining theoretical results in the paper. The proofs rely on results in [17, 19, 20, 25, 31, 33] and [51].",
        "year": 2013,
        "authors": "T Tony Cai and Zongming Ma and Yihong Wu"
      },
      {
        "title": "LECTURE NOTES ON INFORMATION THEORY",
        "abstract": "“There is a whole book of readymade, long and convincing, lavishly composed telegrams for all occasions. Sending such a telegram costs only twenty-five cents. You see, what gets transmitted over the telegraph is not the text of the telegram, but simply the number under which it is listed in the book, and the signature of the sender. This is quite a funny thing, reminiscent of Drugstore Breakfast# 2. Everything is served up in a ready form, and the customer is totally freed from the unpleasant necessity to think, and to spend money on top of it.”",
        "year": 2014,
        "authors": "Y Polyanskiy and Y Wu"
      },
      {
        "title": "Information Theory: From Coding to Learning",
        "abstract": "This enthusiastic introduction to the fundamentals of information theory builds from classical Shannon theory through to modern applications in statistical learning, equipping students with a uniquely well-rounded and rigorous foundation for further study. Introduces core topics such as data compression, channel coding, and rate-distortion theory using a unique finite block-length approach. With over 210 end-of-part exercises and numerous examples, students are introduced to contemporary applications in statistics, machine learning and modern communication theory. This textbook presents information-theoretic methods with applications in statistical learning and computer science, such as f-divergences, PAC Bayes and variational principle, Kolmogorov's metric entropy, strong data processing inequalities, and entropic upper bounds for statistical estimation. Accompanied by a solutions manual for instructors, and …",
        "year": 2023,
        "authors": "Yury Polyanskiy and Yihong Wu"
      }
    ],
    "hISpTpQAAAAJ": [
      {
        "title": "Upstream reciprocity and the evolution of gratitude",
        "abstract": "If someone is nice to you, you feel good and may be inclined to be nice to somebody else. This every day experience is borne out by experimental games: the recipients of an act of kindness are more likely to help in turn, even if the person who benefits from their generosity is somebody else. This behaviour, which has been called ‘upstream reciprocity’, appears to be a misdirected act of gratitude: you help somebody because somebody else has helped you. Does this make any sense from an evolutionary or a game theoretic perspective? In this paper, we show that upstream reciprocity alone does not lead to the evolution of cooperation, but it can evolve and increase the level of cooperation if it is linked to either direct or spatial reciprocity. We calculate the random walks of altruistic acts that are induced by upstream reciprocity. Our analysis shows that gratitude and other positive emotions, which increase the …",
        "year": 2007,
        "authors": "Martin A Nowak and Sébastien Roch"
      },
      {
        "title": "Submodularity of influence in social networks: From local to global",
        "abstract": "Social networks are often represented as directed graphs, where the nodes are individuals and the edges indicate a form of social relationship. A simple way to model the diffusion of ideas, innovative behavior, or “word-of-mouth” effects on such a graph is to consider an increasing process of “infected” (or active) nodes: each node becomes infected once an activation function of the set of its infected neighbors crosses a certain threshold value. Such a model was introduced by Kempe, Kleinberg, and Tardos (KKT) in [Maximizing the spread of influence through a social network, in Proceedings of the 9th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2003, pp. 137–146] and [Influential nodes in a diffusion model for social networks, in Proceedings of the 32nd International Colloquium on Automata, Languages and Programming (ICALP), 2005], where the authors also impose several natural …",
        "year": 2010,
        "authors": "Elchanan Mossel and Sebastien Roch"
      },
      {
        "title": "Likelihood-based tree reconstruction on a concatenation of aligned sequence data sets can be statistically inconsistent",
        "abstract": "The reconstruction of a species tree from genomic data faces a double hurdle. First, the (gene) tree describing the evolution of each gene may differ from the species tree, for instance, due to incomplete lineage sorting. Second, the aligned genetic sequences at the leaves of each gene tree provide merely an imperfect estimate of the topology of the gene tree. In this note, we demonstrate formally that a basic statistical problem arises if one tries to avoid accounting for these two processes and analyses the genetic data directly via a concatenation approach. More precisely, we show that, under the multispecies coalescent with a standard site substitution model, maximum likelihood estimation on sequence data that has been concatenated across genes and performed under the incorrect assumption that all sites have evolved independently and identically on a fixed tree is a statistically inconsistent estimator of the …",
        "year": 2015,
        "authors": "Sebastien Roch and Mike Steel"
      }
    ],
    "lS96SqoAAAAJ": [
      {
        "title": "Soft actor-critic algorithms and applications",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Learning complex dexterous manipulation with deep reinforcement learning and demonstrations",
        "abstract": "Dexterous multi-fingered hands are extremely versatile and provide a generic way to perform a multitude of tasks in human-centric environments. However, effectively controlling them remains challenging due to their high dimensionality and large number of potential contacts. Deep reinforcement learning (DRL) provides a model-agnostic approach to control complex dynamical systems, but has not been shown to scale to high-dimensional dexterous manipulation. Furthermore, deployment of DRL on physical systems remains challenging due to sample inefficiency. Consequently, the success of DRL in robotics has thus far been limited to simpler manipulators and tasks. In this work, we show that model-free DRL can effectively scale up to complex manipulation tasks with a high-dimensional 24-DoF hand, and solve them from scratch in simulated experiments. Furthermore, with the use of a small number of human demonstrations, the sample complexity can be significantly reduced, which enables learning with sample sizes equivalent to a few hours of robot experience. The use of demonstrations result in policies that exhibit very natural movements and, surprisingly, are also substantially more robust.",
        "year": 2017,
        "authors": "Aravind Rajeswaran* and Vikash Kumar* and Abhishek Gupta and Giulia Vezzani and John Schulman and Emanuel Todorov and Sergey Levine"
      },
      {
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models",
        "abstract": "DSpace at KOASAS: Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nKOASAS menu About KOASAS KAIST Library 검색 Advanced Search KOASAS About \nKOASAS Open Access Policy Browse Communities & Collections Researchers at KAIST Titles \nSubject By Date rss_1.0 rss_2.0 atom_1.0 sherpa SEARCH DSpace at KOASAS College of \nEngineering(공과대학)Kim Jaechul Graduate School of AI(김재철AI대학원)AI-Conference \nPapers(학술대회논문) Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nCited 0 time in webofscience Cited 0 time in scopus Hit : 2 Download : 0 Export DC(XML) Excel \nLim, Joseph Jaewhanresearcher Publisher IEEE Issue Date 2024-05-15 Citation IEEE \nInternational Conference on Robotics and Automation URI http://hdl.handle.net/10203/326144 \nAppears in Collection AI-Conference Papers(학술대회논문) Files in This Item There are no files …",
        "year": 2024,
        "authors": "Joseph Jaewhan Lim"
      }
    ],
    "a8Y2OJMAAAAJ": [
      {
        "title": "Microsoft coco: Common objects in context",
        "abstract": "We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and …",
        "year": 2014,
        "authors": "Tsung-Yi Lin and Michael Maire and Serge Belongie and James Hays and Pietro Perona and Deva Ramanan and Piotr Dollár and C Lawrence Zitnick"
      },
      {
        "title": "Mask r-cnn",
        "abstract": "We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, eg, allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without tricks, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code will be made available.",
        "year": 2017,
        "authors": "Kaiming He and Georgia Gkioxari and Piotr Dollár and Ross Girshick"
      },
      {
        "title": "Focal loss for dense object detection",
        "abstract": "The highest accuracy object detectors to date are based on a two-stage approach popularized by R-CNN, where a classifier is applied to a sparse set of candidate object locations. In contrast, one-stage detectors that are applied over a regular, dense sampling of possible object locations have the potential to be faster and simpler, but have trailed the accuracy of two-stage detectors thus far. In this paper, we investigate why this is the case. We discover that the extreme foreground-background class imbalance encountered during training of dense detectors is the central cause. We propose to address this class imbalance by reshaping the standard cross entropy loss such that it down-weights the loss assigned to well-classified examples. Our novel Focal Loss focuses training on a sparse set of hard examples and prevents the vast number of easy negatives from overwhelming the detector during training. To evaluate the effectiveness of our loss, we design and train a simple dense detector we call RetinaNet. Our results show that when trained with the focal loss, RetinaNet is able to match the speed of previous one-stage detectors while surpassing the accuracy of all existing state-of-the-art two-stage detectors.",
        "year": 2017,
        "authors": "TY Lin and P Goyal and R Girshick and K He and P Dollár"
      }
    ],
    "1p3dDesAAAAJ": [
      {
        "title": "Bolt: Privacy-preserving, accurate and efficient inference for transformers",
        "abstract": "The advent of transformers has brought about significant advancements in traditional machine learning tasks. However, their pervasive deployment has raised concerns about the potential leakage of sensitive information during inference. Existing approaches using secure multiparty computation (MPC) face limitations when applied to transformers due to the extensive model size and resource-intensive matrix-matrix multiplications. In this paper, we present BOLT, a privacy-preserving inference framework for transformer models that supports efficient matrix multiplications and nonlinear computations. Combined with our novel machine learning optimizations, BOLT reduces the communication cost by 10.91×. Our evaluation on diverse datasets demonstrates that BOLT maintains comparable accuracy to floating-point models and achieves 4.8-9.5× faster inference across various network settings compared to the state …",
        "year": 2024,
        "authors": "Qi Pang and Jinhao Zhu and Helen Möllering and Wenting Zheng and Thomas Schneider"
      },
      {
        "title": "Metamorphic testing of deep learning compilers",
        "abstract": "The prosperous trend of deploying deep neural network (DNN) models to diverse hardware platforms has boosted the development of deep learning (DL) compilers. DL compilers take the high-level DNN model specifications as input and generate optimized DNN executables for diverse hardware architectures like CPUs, GPUs, and various hardware accelerators. Compiling DNN models into high-efficiency executables is not easy: the compilation procedure often involves converting high-level model specifications into several different intermediate representations (IR), e.g., graph IR and operator IR, and performing rule-based or learning-based optimizations from both platform-independent and platform-dependent perspectives. Despite the prosperous adoption of DL compilers in real-world scenarios, principled and systematic understanding toward the correctness of DL compilers does not yet exist. To fill this …",
        "year": 2022,
        "authors": "Dongwei Xiao and Zhibo Liu and Yuanyuan Yuan and Qi Pang and Shuai Wang"
      },
      {
        "title": "Byzantine-robust federated learning with optimal statistical rates",
        "abstract": "We propose Byzantine-robust federated learning protocols with nearly optimal statistical rates based on recent progress in high dimensional robust statistics. In contrast to prior work, our proposed protocols improve the dimension dependence and achieve a near-optimal statistical rate for strongly convex losses. We also provide statistical lower bound for the problem. For experiments, we benchmark against competing protocols and show the empirical superiority of the proposed protocols.",
        "year": 2023,
        "authors": "Banghua Zhu and Lun Wang and Qi Pang and Shuai Wang and Jiantao Jiao and Dawn Song and Michael I Jordan"
      }
    ],
    "opbZfw0AAAAJ": [
      {
        "title": "Locality-sensitive hashing scheme based on p-stable distributions",
        "abstract": "We present a novel Locality-Sensitive Hashing scheme for the Approximate Nearest Neighbor Problem under lp norm, based on p-stable distributions.Our scheme improves the running time of the earlier algorithm for the case of the lp norm. It also yields the first known provably efficient approximate NN algorithm for the case p<1. We also show that the algorithm finds the exact near neigbhor in O(log n) time for data satisfying certain \"bounded growth\" condition.Unlike earlier schemes, our LSH scheme works directly on points in the Euclidean space without embeddings. Consequently, the resulting query time bound is free of large factors and is simple and easy to implement. Our experiments (on synthetic data sets) show that the our data structure is up to 40 times faster than kd-tree.",
        "year": 2004,
        "authors": "Mayur Datar and Nicole Immorlica and Piotr Indyk and Vahab S Mirrokni"
      },
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien MR Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan"
      },
      {
        "title": "Maximizing non-monotone submodular functions",
        "abstract": "Submodular maximization generalizes many important problems including Max Cut in directed and undirected graphs and hypergraphs, certain constraint satisfaction problems, and maximum facility location problems. Unlike the problem of minimizing submodular functions, the problem of maximizing submodular functions is NP-hard. In this paper, we design the first constant-factor approximation algorithms for maximizing nonnegative (non-monotone) submodular functions. In particular, we give a deterministic local-search -approximation and a randomized -approximation algorithm for maximizing nonnegative submodular functions. We also show that a uniformly random set gives a -approximation. For symmetric submodular functions, we show that a random set gives a -approximation, which can also be achieved by deterministic local search. These algorithms work in the value oracle model, where the submodular function is …",
        "year": 2011,
        "authors": "Uriel Feige and Vahab S Mirrokni and Jan Vondrák"
      }
    ],
    "_QlCijoAAAAJ": [
      {
        "title": "Gpt-4o system card",
        "abstract": "GPT-4o is an autoregressive omni model that accepts as input any combination of text, audio, image, and video, and generates any combination of text, audio, and image outputs. It's trained end-to-end across text, vision, and audio, meaning all inputs and outputs are processed by the same neural network. GPT-4o can respond to audio inputs in as little as 232 milliseconds, with an average of 320 milliseconds, which is similar to human response time in conversation. It matches GPT-4 Turbo performance on text in English and code, with significant improvement on text in non-English languages, while also being much faster and 50\\% cheaper in the API. GPT-4o is especially better at vision and audio understanding compared to existing models. In line with our commitment to building AI safely and consistent with our voluntary commitments to the White House, we are sharing the GPT-4o System Card, which includes our Preparedness Framework evaluations. In this System Card, we provide a detailed look at GPT-4o's capabilities, limitations, and safety evaluations across multiple categories, focusing on speech-to-speech while also evaluating text and image capabilities, and measures we've implemented to ensure the model is safe and aligned. We also include third-party assessments on dangerous capabilities, as well as discussion of potential societal impacts of GPT-4o's text and vision capabilities.",
        "year": 2024,
        "authors": "Aaron Hurst and Adam Lerer and Adam P Goucher and Adam Perelman and Aditya Ramesh and Aidan Clark and AJ Ostrow and Akila Welihinda and Alan Hayes and Alec Radford and Aleksander Mądry and Alex Baker-Whitcomb and Alex Beutel and Alex Borzunov and Alex Carney and Alex Chow and Alex Kirillov and Alex Nichol and Alex Paino and Alex Renzin and Alex Tachard Passos and Alexander Kirillov and Alexi Christakis and Alexis Conneau and Ali Kamali and Allan Jabri and Allison Moyer and Allison Tam and Amadou Crookes and Amin Tootoochian and Amin Tootoonchian and Ananya Kumar and Andrea Vallone and Andrej Karpathy and Andrew Braunstein and Andrew Cann and Andrew Codispoti and Andrew Galu and Andrew Kondrich and Andrew Tulloch and Andrey Mishchenko and Angela Baek and Angela Jiang and Antoine Pelisse and Antonia Woodford and Anuj Gosalia and Arka Dhar and Ashley Pantuliano and Avi Nayak and Avital Oliver and Barret Zoph and Behrooz Ghorbani and Ben Leimberger and Ben Rossen and Ben Sokolowsky and Ben Wang and Benjamin Zweig and Beth Hoover and Blake Samic and Bob McGrew and Bobby Spero and Bogo Giertler and Bowen Cheng and Brad Lightcap and Brandon Walkin and Brendan Quinn and Brian Guarraci and Brian Hsu and Bright Kellogg and Brydon Eastman and Camillo Lugaresi and Carroll Wainwright and Cary Bassin and Cary Hudson and Casey Chu and Chad Nelson and Chak Li and Chan Jun Shern and Channing Conger and Charlotte Barette and Chelsea Voss and Chen Ding and Cheng Lu and Chong Zhang and Chris Beaumont and Chris Hallacy and Chris Koch and Christian Gibson and Christina Kim and Christine Choi and Christine McLeavey and Christopher Hesse and Claudia Fischer and Clemens Winter and Coley Czarnecki and Colin Jarvis and Colin Wei and Constantin Koumouzelis and Dane Sherburn and Daniel Kappler and Daniel Levin and Daniel Levy and David Carr and David Farhi and David Mely and David Robinson and David Sasaki and Denny Jin and Dev Valladares and Dimitris Tsipras and Doug Li and Duc Phong Nguyen and Duncan Findlay and Edede Oiwoh and Edmund Wong and Ehsan Asdar and Elizabeth Proehl and Elizabeth Yang and Eric Antonow and Eric Kramer and Eric Peterson and Eric Sigler and Eric Wallace and Eugene Brevdo and Evan Mays and Farzad Khorasani and Felipe Petroski Such and Filippo Raso and Francis Zhang and Fred von Lohmann and Freddie Sulit and Gabriel Goh and Gene Oden and Geoff Salmon and Giulio Starace and Greg Brockman and Hadi Salman and Haiming Bao and Haitang Hu and Hannah Wong and Haoyu Wang and Heather Schmidt and Heather Whitney and Heewoo Jun and Hendrik Kirchner and Henrique Ponde de Oliveira Pinto and Hongyu Ren and Huiwen Chang and Hyung Won Chung and Ian Kivlichan"
      },
      {
        "title": "Learning correspondence from the cycle-consistency of time",
        "abstract": "We introduce a self-supervised method for learning visual correspondence from unlabeled video. The main idea is to use cycle-consistency in time as free supervisory signal for learning visual representations from scratch. At training time, our model learns a feature map representation to be useful for performing cycle-consistent tracking. At test time, we use the acquired representation to find nearest neighbors across space and time. We demonstrate the generalizability of the representation--without finetuning--across a range of visual correspondence tasks, including video object segmentation, keypoint tracking, and optical flow. Our approach outperforms previous self-supervised methods and performs competitively with strongly supervised methods.",
        "year": 2019,
        "authors": "Xiaolong Wang* and Allan Jabri* and Alexei A Efros"
      },
      {
        "title": "Learning visual features from large weakly supervised data",
        "abstract": "Convolutional networks trained on large supervised datasets produce visual features which form the basis for the state-of-the-art in many computer-vision problems. Further improvements of these visual features will likely require even larger manually labeled data sets, which severely limits the pace at which progress can be made. In this paper, we explore the potential of leveraging massive, weakly-labeled image collections for learning good visual features. We train convolutional networks on a dataset of 100 million Flickr photos and comments, and show that these networks produce features that perform well in a range of vision problems. We also show that the networks appropriately capture word similarity and learn correspondences between different languages.",
        "year": 2016,
        "authors": "Armand Joulin and Laurens Van Der Maaten and Allan Jabri and Nicolas Vasilache"
      }
    ],
    "NvKHgzkAAAAJ": [
      {
        "title": "CryptDB: Protecting confidentiality with encrypted query processing",
        "abstract": "Online applications are vulnerable to theft of sensitive information because adversaries can exploit software bugs to gain access to private data, and because curious or malicious administrators may capture and leak data. CryptDB is a system that provides practical and provable confidentiality in the face of these attacks for applications backed by SQL databases. It works by executing SQL queries over encrypted data using a collection of efficient SQL-aware encryption schemes. CryptDB can also chain encryption keys to user passwords, so that a data item can be decrypted only by using the password of one of the users with access to that data. As a result, a database administrator never gets access to decrypted data, and even if all servers are compromised, an adversary cannot decrypt the data of any user who is not logged in. An analysis of a trace of 126 million SQL queries from a production MySQL server …",
        "year": 2011,
        "authors": "Raluca Ada Popa and Catherine MS Redfield and Nickolai Zeldovich and Hari Balakrishnan"
      },
      {
        "title": "Machine learning classification over encrypted data",
        "abstract": "Machine learning classification is used in numerous settings nowadays, such as medical or genomics predictions, spam detection, face recognition, and financial predictions. Due to privacy concerns in some of these applications, it is important that the data and the classifier remain confidential. In this work, we construct three major classification protocols that satisfy this privacy constraint: hyperplane decision, Naïve Bayes, and decision trees. These protocols may also be combined with AdaBoost. They rely on a library of building blocks for constructing classifiers securely, and we demonstrate the versatility of this library by constructing a face detection classifier. Our protocols are efficient, taking milliseconds to a few seconds to perform a classification when running on real medical datasets.",
        "year": 2014,
        "authors": "Raphael Bost and Raluca Ada Popa and Stephen Tu and Shafi Goldwasser"
      },
      {
        "title": "Cloud programming simplified: A berkeley view on serverless computing",
        "abstract": "Serverless cloud computing handles virtually all the system administration operations needed to make it easier for programmers to use the cloud. It provides an interface that greatly simplifies cloud programming, and represents an evolution that parallels the transition from assembly language to high-level programming languages. This paper gives a quick history of cloud computing, including an accounting of the predictions of the 2009 Berkeley View of Cloud Computing paper, explains the motivation for serverless computing, describes applications that stretch the current limits of serverless, and then lists obstacles and research opportunities required for serverless computing to fulfill its full potential. Just as the 2009 paper identified challenges for the cloud and predicted they would be addressed and that cloud use would accelerate, we predict these issues are solvable and that serverless computing will grow to dominate the future of cloud computing.",
        "year": 2019,
        "authors": "Eric Jonas and Johann Schleier-Smith and Vikram Sreekanti and Chia-Che Tsai and Anurag Khandelwal and Qifan Pu and Vaishaal Shankar and Joao Carreira and Karl Krauth and Neeraja Yadwadkar and Joseph E Gonzalez and Raluca Ada Popa and Ion Stoica and David A Patterson"
      }
    ],
    "NmHgX-wAAAAJ": [
      {
        "title": "Decoupling representation and classifier for long-tailed recognition",
        "abstract": "The long-tail distribution of the visual world poses great challenges for deep learning based classification models on how to handle the class imbalance problem. Existing solutions usually involve class-balancing strategies, e.g., by loss re-weighting, data re-sampling, or transfer learning from head- to tail-classes, but most of them adhere to the scheme of jointly learning representations and classifiers. In this work, we decouple the learning procedure into representation learning and classification, and systematically explore how different balancing strategies affect them for long-tailed recognition. The findings are surprising: (1) data imbalance might not be an issue in learning high-quality representations; (2) with representations learned with the simplest instance-balanced (natural) sampling, it is also possible to achieve strong long-tailed recognition ability by adjusting only the classifier. We conduct extensive experiments and set new state-of-the-art performance on common long-tailed benchmarks like ImageNet-LT, Places-LT and iNaturalist, showing that it is possible to outperform carefully designed losses, sampling strategies, even complex modules with memory, by using a straightforward approach that decouples representation and classification. Our code is available at https://github.com/facebookresearch/classifier-balancing.",
        "year": 2020,
        "authors": "Bingyi Kang and Saining Xie and Marcus Rohrbach and Zhicheng Yan and Albert Gordo and Jiashi Feng and Yannis Kalantidis"
      },
      {
        "title": "Depth anything: Unleashing the power of large-scale unlabeled data",
        "abstract": "This work presents Depth Anything a highly practical solution for robust monocular depth estimation. Without pursuing novel technical modules we aim to build a simple yet powerful foundation model dealing with any images under any circumstances. To this end we scale up the dataset by designing a data engine to collect and automatically annotate large-scale unlabeled data (62M) which significantly enlarges the data coverage and thus is able to reduce the generalization error. We investigate two simple yet effective strategies that make data scaling-up promising. First a more challenging optimization target is created by leveraging data augmentation tools. It compels the model to actively seek extra visual knowledge and acquire robust representations. Second an auxiliary supervision is developed to enforce the model to inherit rich semantic priors from pre-trained encoders. We evaluate its zero-shot capabilities extensively including six public datasets and randomly captured photos. It demonstrates impressive generalization ability. Further through fine-tuning it with metric depth information from NYUv2 and KITTI new SOTAs are set. Our better depth model also results in a better depth-conditioned ControlNet. Our models are released at https://github. com/LiheYoung/Depth-Anything.",
        "year": 2024,
        "authors": "Lihe Yang and Bingyi Kang†(Proj Lead) and Zilong Huang and Xiaogang Xu and Jiashi Feng and Hengshuang Zhao"
      },
      {
        "title": "Few-shot object detection via feature reweighting",
        "abstract": "Conventional training of a deep CNN based object detector demands a large number of bounding box annotations, which may be unavailable for rare categories. In this work we develop a few-shot object detector that can learn to detect novel objects from only a few annotated examples. Our proposed model leverages fully labeled base classes and quickly adapts to novel classes, using a meta feature learner and a reweighting module within a one-stage detection architecture. The feature learner extracts meta features that are generalizable to detect novel object classes, using training data from base classes with sufficient samples. The reweighting module transforms a few support examples from the novel classes to a global vector that indicates the importance or relevance of meta features for detecting the corresponding objects. These two modules, together with a detection prediction module, are trained end-to-end based on an episodic few-shot learning scheme and a carefully designed loss function. Through extensive experiments we demonstrate that our model outperforms well-established baselines by a large margin for few-shot object detection, on multiple datasets and settings. We also present analysis on various aspects of our proposed model, aiming to provide some inspiration for future few-shot detection works.",
        "year": 2019,
        "authors": "Bingyi Kang* and Zhuang Liu* and Xin Wang and Fisher Yu and Jiashi Feng and Trevor Darrell"
      }
    ],
    "dzOd2hgAAAAJ": [
      {
        "title": "Context encoders: Feature learning by inpainting",
        "abstract": "We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction. By analogy with auto-encoders, we propose Context Encoders--a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part (s). When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss. The latter produces much sharper results because it can better handle multiple modes in the output. We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures. We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classification, detection, and segmentation tasks. Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods.",
        "year": 2016,
        "authors": "Deepak Pathak and Philipp Krahenbuhl and Jeff Donahue and Trevor Darrell and Alexei A Efros"
      },
      {
        "title": "Objects as points",
        "abstract": "Detection identifies objects as axis-aligned boxes in an image. Most successful object detectors enumerate a nearly exhaustive list of potential object locations and classify each. This is wasteful, inefficient, and requires additional post-processing. In this paper, we take a different approach. We model an object as a single point --- the center point of its bounding box. Our detector uses keypoint estimation to find center points and regresses to all other object properties, such as size, 3D location, orientation, and even pose. Our center point based approach, CenterNet, is end-to-end differentiable, simpler, faster, and more accurate than corresponding bounding box based detectors. CenterNet achieves the best speed-accuracy trade-off on the MS COCO dataset, with 28.1% AP at 142 FPS, 37.4% AP at 52 FPS, and 45.1% AP with multi-scale testing at 1.4 FPS. We use the same approach to estimate 3D bounding box in the KITTI benchmark and human pose on the COCO keypoint dataset. Our method performs competitively with sophisticated multi-stage methods and runs in real-time.",
        "year": 2019,
        "authors": "Xingyi Zhou and Dequan Wang and Philipp Krähenbühl"
      },
      {
        "title": "Efficient Inference in Fully Connected CRFs with Gaussian Edge Potentials",
        "abstract": "Most state-of-the-art techniques for multi-class image segmentation and labeling use conditional random fields defined over pixels or image regions. While regionlevel models often feature dense pairwise connectivity, pixel-level models are considerably larger and have only permitted sparse graph structures. In this paper, we consider fully connected CRF models defined on the complete set of pixels in an image. The resulting graphs have billions of edges, making traditional inference algorithms impractical. Our main contribution is a highly efficient approximate inference algorithm for fully connected CRF models in which the pairwise edge potentials are defined by a linear combination of Gaussian kernels. Our experiments demonstrate that dense connectivity at the pixel level substantially improves segmentation and labeling accuracy.",
        "year": 2011,
        "authors": "Philipp Krähenbühl and Vladlen Koltun"
      }
    ],
    "MzD8rjoAAAAJ": [
      {
        "title": "Fundamentals of wireless communication",
        "abstract": "The past decade has seen many advances in physical layer wireless communication theory and their implementation in wireless systems. This textbook takes a unified view of the fundamentals of wireless communication and explains the web of concepts underpinning these advances at a level accessible to an audience with a basic background in probability and digital communication. Topics covered include MIMO (multi-input, multi-output) communication, space-time coding, opportunistic communication, OFDM and CDMA. The concepts are illustrated using many examples from real wireless systems such as GSM, IS-95 (CDMA), IS-856 (1 x EV-DO), Flash OFDM and UWB (ultra-wideband). Particular emphasis is placed on the interplay between concepts and their implementation in real systems. An abundant supply of exercises and figures reinforce the material in the text. This book is intended for use on graduate courses in electrical and computer engineering and will also be of great interest to practising engineers.",
        "year": 2005,
        "authors": "David Tse and Pramod Viswanath"
      },
      {
        "title": "Cooperative diversity in wireless networks: Efficient protocols and outage behavior",
        "abstract": "We develop and analyze low-complexity cooperative diversity protocols that combat fading induced by multipath propagation in wireless networks. The underlying techniques exploit space diversity available through cooperating terminals' relaying signals for one another. We outline several strategies employed by the cooperating radios, including fixed relaying schemes such as amplify-and-forward and decode-and-forward, selection relaying schemes that adapt based upon channel measurements between the cooperating terminals, and incremental relaying schemes that adapt based upon limited feedback from the destination terminal. We develop performance characterizations in terms of outage events and associated outage probabilities, which measure robustness of the transmissions to fading, focusing on the high signal-to-noise ratio (SNR) regime. Except for fixed decode-and-forward, all of our cooperative …",
        "year": 2004,
        "authors": "J Nicholas Laneman and David NC Tse and Gregory W Wornell"
      },
      {
        "title": "Diversity and multiplexing: A fundamental tradeoff in multiple-antenna channels",
        "abstract": "Multiple antennas can be used for increasing the amount of diversity or the number of degrees of freedom in wireless communication systems. We propose the point of view that both types of gains can be simultaneously obtained for a given multiple-antenna channel, but there is a fundamental tradeoff between how much of each any coding scheme can get. For the richly scattered Rayleigh-fading channel, we give a simple characterization of the optimal tradeoff curve and use it to evaluate the performance of existing multiple antenna schemes.",
        "year": 2003,
        "authors": "Lizhong Zheng and David N. C.  Tse"
      }
    ],
    "4pWLoJEAAAAJ": [
      {
        "title": "Objective comparison of particle tracking methods",
        "abstract": "Particle tracking is of key importance for quantitative analysis of intracellular dynamic processes from time-lapse microscopy image data. Because manually detecting and following large numbers of individual particles is not feasible, automated computational methods have been developed for these tasks by many groups. Aiming to perform an objective comparison of methods, we gathered the community and organized an open competition in which participating teams applied their own methods independently to a commonly defined data set including diverse scenarios. Performance was assessed using commonly defined measures. Although no single method performed best across all scenarios, the results revealed clear differences between the various approaches, leading to notable practical conclusions for users and developers.",
        "year": 2014,
        "authors": "Nicolas Chenouard and Ihor Smal and Fabrice De Chaumont and Martin Maška and Ivo F Sbalzarini and Yuanhao Gong and Janick Cardinale and Craig Carthel and Stefano Coraluppi and Mark Winter and Andrew R Cohen and William J Godinez and Karl Rohr and Yannis Kalaidzidis and Liang Liang and James Duncan and Hongying Shen and Yingke Xu and Klas EG Magnusson and Joakim Jaldén and Helen M Blau and Perrine Paul-Gilloteaux and Philippe Roudot and Charles Kervrann and François Waharte and Jean-Yves Tinevez and Spencer L Shorte and Joost Willemse and Katherine Celler and Gilles P Van Wezel and Han-Wei Dan and Yuh-Show Tsai and Carlos Ortiz De Solórzano and Jean-Christophe Olivo-Marin and Erik Meijering"
      },
      {
        "title": "Applying systems-level spectral imaging and analysis to reveal the organelle interactome",
        "abstract": "The organization of the eukaryotic cell into discrete membrane-bound organelles allows for the separation of incompatible biochemical processes, but the activities of these organelles must be coordinated. For example, lipid metabolism is distributed between the endoplasmic reticulum for lipid synthesis, lipid droplets for storage and transport, mitochondria and peroxisomes for β-oxidation, and lysosomes for lipid hydrolysis and recycling,,,,. It is increasingly recognized that organelle contacts have a vital role in diverse cellular functions,,,. However, the spatial and temporal organization of organelles within the cell remains poorly characterized, as fluorescence imaging approaches are limited in the number of different labels that can be distinguished in a single image. Here we present a systems-level analysis of the organelle interactome using a multispectral image acquisition method that overcomes the challenge of …",
        "year": 2017,
        "authors": "Alex M Valm and Sarah Cohen and Wesley R Legant and Justin Melunis and Uri Hershberg and Eric Wait and Andrew R Cohen and Michael W Davidson and Eric Betzig and Jennifer Lippincott-Schwartz"
      },
      {
        "title": "System and method for the distribution and synchronization of data and state information between clients in a distributed processing system",
        "abstract": "75 Inventors: Kipley J. Olson, Seattle, Wash.; 57 Andrew R. Cohen, Steamboat Springs, The present invention is directed to a novel System and Colo. method for Sharing common data and State information between network connected application clients participating 73 Assignee: Microsoft Corporation, Redmond, in an application Session. The application Session is invoked Wash. by a host client. The host client is responsible for selectively admitting other network connected clients into the applica 21 Appl. No.: 08/893,960 tion Session, and is also the application client that is respon Sible for distributing a common Set of application data for 22 Filed: Jul. 16, 1997 Storage at each admitted application client. The application",
        "year": 1999,
        "authors": "Kipley J Olson and Andrew R Cohen"
      }
    ],
    "tsXh_hwAAAAJ": [
      {
        "title": "Inverse reward design",
        "abstract": "Autonomous agents optimize the reward function we give them. What they don't know is how hard it is for us to design a reward function that actually captures what we want. When designing the reward, we might think of some specific training scenarios, and make sure that the reward will lead to the right behavior in those scenarios. Inevitably, agents encounter new scenarios (eg, new types of terrain) where optimizing that same reward may lead to undesired behavior. Our insight is that reward functions are merely observations about what the designer actually wants, and that they should be interpreted in the context in which they were designed. We introduce inverse reward design (IRD) as the problem of inferring the true objective based on the designed reward and the training MDP. We introduce approximate methods for solving IRD problems, and use their solution to plan risk-averse behavior in test MDPs. Empirical results suggest that this approach can help alleviate negative side effects of misspecified reward functions and mitigate reward hacking.",
        "year": 2016,
        "authors": "Dylan Hadfield-Menell and Smitha Milli and Pieter Abbeel and Stuart Russell and Anca Dragan"
      },
      {
        "title": "The Social Cost of Strategic Classification",
        "abstract": "Consequential decision-making typically incentivizes individuals to behave strategically, tailoring their behavior to the specifics of the decision rule. A long line of work has therefore sought to counteract strategic behavior by designing more conservative decision boundaries in an effort to increase robustness to the effects of strategic covariate shift.We show that these efforts benefit the institutional decision maker at the expense of the individuals being classified. Introducing a notion of social burden, we prove that any increase in institutional utility necessarily leads to a corresponding increase in social burden. Moreover, we show that the negative externalities of strategic classification can disproportionately harm disadvantaged groups in the population.Our results highlight that strategy-robustness must be weighed against considerations of social welfare and fairness.",
        "year": 2019,
        "authors": "Smitha Milli and John Miller and Anca D Dragan and Moritz Hardt"
      },
      {
        "title": "Reward-rational (implicit) choice: A unifying formalism for reward learning",
        "abstract": "It is often difficult to hand-specify what the correct reward function is for a task, so researchers have instead aimed to learn reward functions from human behavior or feedback. The types of behavior interpreted as evidence of the reward function have expanded greatly in recent years. We've gone from demonstrations, to comparisons, to reading into the information leaked when the human is pushing the robot away or turning it off. And surely, there is more to come. How will a robot make sense of all these diverse types of behavior? Our key observation is that different types of behavior can be interpreted in a single unifying formalism-as a reward-rational choice that the human is making, often implicitly. We use this formalism to survey prior work through a unifying lens, and discuss its potential use as a recipe for interpreting new sources of information that are yet to be uncovered.",
        "year": 2020,
        "authors": "Hong Jun Jeon and Smitha Milli and Anca D Dragan"
      }
    ],
    "Y8O9N_0AAAAJ": [
      {
        "title": "Non-local Neural Networks",
        "abstract": "Both convolutional and recurrent operations are building blocks that process one local neighborhood at a time. In this paper, we present non-local operations as a generic family of building blocks for capturing long-range dependencies. Inspired by the classical non-local means method in computer vision, our non-local operation computes the response at a position as a weighted sum of the features at all positions. This building block can be plugged into many computer vision architectures. On the task of video classification, even without any bells and whistles, our non-local models can compete or outperform current competition winners on both Kinetics and Charades datasets. In static image recognition, our non-local models improve object detection/segmentation and pose estimation on the COCO suite of tasks. Code will be made available.",
        "year": 2018,
        "authors": "Xiaolong Wang and Ross Girshick and Abhinav Gupta and Kaiming He"
      },
      {
        "title": "Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding",
        "abstract": "Computer vision has a great potential to help our daily lives by searching for lost keys, watering flowers or reminding us to take a pill. To succeed with such tasks, computer vision methods need to be trained from real and diverse examples of our daily dynamic scenes. While most of such scenes are not particularly exciting, they typically do not appear on YouTube, in movies or TV broadcasts. So how do we collect sufficiently many diverse but boring samples representing our lives? We propose a novel Hollywood in Homes approach to collect such data. Instead of shooting videos in the lab, we ensure diversity by distributing and crowdsourcing the whole process of video creation from script writing to video recording and annotation. Following this procedure we collect a new dataset, Charades, with hundreds of people recording videos in their own homes, acting out casual everyday activities. The dataset is …",
        "year": 2016,
        "authors": "Gunnar A Sigurdsson and Gül Varol and Xiaolong Wang and Ali Farhadi and Ivan Laptev and Abhinav Gupta"
      },
      {
        "title": "Unsupervised Learning of Visual Representations using Videos",
        "abstract": "Is strong supervision necessary for learning a good visual representation? Do we really need millions of semantically-labeled images to train a Convolutional Neural Network (CNN)? In this paper, we present a simple yet surprisingly powerful approach for unsupervised learning of CNN. Specifically, we use hundreds of thousands of unlabeled videos from the web to learn visual representations. Our key idea is that visual tracking provides the supervision. That is, two patches connected by a track should have similar visual representation in deep feature space since they probably belong to same object or object part. We design a Siamese-triplet network with a ranking loss function to train this CNN representation. Without using a single image from ImageNet, just using 100K unlabeled videos and the VOC 2012 dataset, we train an ensemble of unsupervised networks that achieves 52% mAP (no bounding box regression). This performance comes tantalizingly close to its ImageNet-supervised counterpart, an ensemble which achieves a mAP of 54.4%. We also show that our unsupervised network can perform competitively in other tasks such as surface-normal estimation.",
        "year": 2015,
        "authors": "Xiaolong Wang and Abhinav Gupta"
      }
    ],
    "kiFd6A8AAAAJ": [
      {
        "title": "Gain: Missing data imputation using generative adversarial nets",
        "abstract": "We propose a novel method for imputing missing data by adapting the well-known Generative Adversarial Nets (GAN) framework. Accordingly, we call our method Generative Adversarial Imputation Nets (GAIN). The generator (G) observes some components of a real data vector, imputes the missing components conditioned on what is actually observed, and outputs a completed vector. The discriminator (D) then takes a completed vector and attempts to determine which components were actually observed and which were imputed. To ensure that D forces G to learn the desired distribution, we provide D with some additional information in the form of a hint vector. The hint reveals to D partial information about the missingness of the original sample, which is used by D to focus its attention on the imputation quality of particular components. This hint ensures that G does in fact learn to generate according to the true data distribution. We tested our method on various datasets and found that GAIN significantly outperforms state-of-the-art imputation methods.",
        "year": 2018,
        "authors": "Jinsung Yoon and James Jordon and Mihaela Van Der Schaar"
      },
      {
        "title": "Time-series generative adversarial networks",
        "abstract": "A good generative model for time-series data should preserve temporal dynamics, in the sense that new sequences respect the original relationships between variables across time. Existing methods that bring generative adversarial networks (GANs) into the sequential setting do not adequately attend to the temporal correlations unique to time-series data. At the same time, supervised models for sequence prediction-which allow finer control over network dynamics-are inherently deterministic. We propose a novel framework for generating realistic time-series data that combines the flexibility of the unsupervised paradigm with the control afforded by supervised training. Through a learned embedding space jointly optimized with both supervised and adversarial objectives, we encourage the network to adhere to the dynamics of the training data during sampling. Empirically, we evaluate the ability of our method to generate realistic samples using a variety of real and synthetic time-series datasets. Qualitatively and quantitatively, we find that the proposed framework consistently and significantly outperforms state-of-the-art benchmarks with respect to measures of similarity and predictive ability.",
        "year": 2019,
        "authors": "Jinsung Yoon and Daniel Jarrett and Mihaela Van der Schaar"
      },
      {
        "title": "Cutpaste: Self-supervised learning for anomaly detection and localization",
        "abstract": "We aim at constructing a high performance model for defect detection that detects unknown anomalous patterns of an image without anomalous data. To this end, we propose a two-stage framework for building anomaly detectors using normal training data only. We first learn self-supervised deep representations and then build a generative one-class classifier on learned representations. We learn representations by classifying normal data from the CutPaste, a simple data augmentation strategy that cuts an image patch and pastes at a random location of a large image. Our empirical study on MVTec anomaly detection dataset demonstrates the proposed algorithm is general to be able to detect various types of real-world defects. We bring the improvement upon previous arts by 3.1 AUCs when learning representations from scratch. By transfer learning on pretrained representations on ImageNet, we achieve a new state-of-the-art 96.6 AUC. Lastly, we extend the framework to learn and extract representations from patches to allow localizing defective areas without annotations during training.",
        "year": 2021,
        "authors": "Chun-Liang Li and Kihyuk Sohn and Jinsung Yoon and Tomas Pfister"
      }
    ],
    "6-e-ZBEAAAAJ": [
      {
        "title": "Language models are few-shot learners",
        "abstract": "We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.",
        "year": 2020,
        "authors": "Tom Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared D Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel Ziegler and Jeffrey Wu and Clemens Winter and Chris Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei"
      },
      {
        "title": "Language models are unsupervised multitask learners",
        "abstract": "Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset-matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5 B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.",
        "year": 2019,
        "authors": "Alec Radford and Jeffrey Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever"
      },
      {
        "title": "Evaluating large language models trained on code",
        "abstract": "We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8% of the problems, while GPT-3 solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics.",
        "year": 2021,
        "authors": "Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde De Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba"
      }
    ],
    "QWzsNMDsvlIC": [
      {
        "title": "The self-avoiding walk",
        "abstract": "A self-avoiding walk is a path on a lattice that does not visit the same site more than once. In spite of this simple definition, many of the most basic questions about this model are difficult to resolve in a mathematically rigorous fashion. In particular, we do not know much about how far an n step self-avoiding walk typically travels from its starting point, or even how many such walks there are. These and other important questions about the self-avoiding walk remain unsolved in the rigorous mathematical sense, although the physics and chemistry communities have reached consensus on the answers by a variety of nonrigorous methods, including computer simulations. But there has been progress among mathematicians as well, much of it in the last decade, and the primary goal of this book is to give an account of the current state of the art as far as rigorous results are concerned. A second goal of this book is to discuss some of the applications of the self-avoiding walk in physics and chemistry, and to describe some of the nonrigorous methods used in those fields. The model originated in chem istry several decades ago as a model for long-chain polymer molecules. Since then it has become an important model in statistical physics, as it exhibits critical behaviour analogous to that occurring in the Ising model and related systems such as percolation.",
        "year": 2013,
        "authors": "Neal Madras and Gordon Slade"
      },
      {
        "title": "Mean-field critical behaviour for percolation in high dimensions",
        "abstract": "The triangle condition for percolation states that   is finite at the critical point, where τ(x, y) is the probability that the sitesx andy are connected. We use an expansion related to the lace expansion for a self-avoiding walk to prove that the triangle condition is satisfied in two situations: (i) for nearest-neighbour independent bond percolation on thed-dimensional hypercubic lattice, ifd is sufficiently large, and (ii) in more than six dimensions for a class of “spread-out” models of independent bond percolation which are believed to be in the same universality class as the nearest-neighbour model. The class of models in (ii) includes the case where the bond occupation probability is constant for bonds of length less than some large number, and is zero otherwise. In the course of the proof an infrared bound is obtained. The triangle condition is known to imply that various critical exponents take their …",
        "year": 1990,
        "authors": "Takashi Hara and Gordon Slade"
      },
      {
        "title": "Self-avoiding walk in five or more dimensions I. The critical behaviour",
        "abstract": "We use the lace expansion to study the standard self-avoiding walk in thed-dimensional hypercubic lattice, ford≧5. We prove that the numberc n ofn-step self-avoiding walks satisfiesc  n ~Aμ  n , where μ is the connective constant (i.e. γ=1), and that the mean square displacement is asymptotically linear in the number of steps (i.e.v=1/2). A bound is obtained forc n(x), the number ofn-step self-avoiding walks ending atx. The correlation length is shown to diverge asymptotically like (μ−−Z)1/2. The critical two-point function is shown to decay at least as fast as ⋎x⋎−2, and its Fourier transform is shown to be asymptotic to a multiple ofk −2 ask→0 (i.e. η=0). We also prove that the scaling limit is Gaussian, in the sense of convergence in distribution to Brownian motion. The infinite self-avoiding walk is constructed. In this paper we prove these results assuming convergence of the …",
        "year": 1992,
        "authors": "Takashi Hara and Gordon Slade"
      }
    ],
    "EWJYRncAAAAJ": [
      {
        "title": "Direct-coupling analysis of residue coevolution captures native contacts across many protein families",
        "abstract": "The similarity in the three-dimensional structures of homologous proteins imposes strong constraints on their sequence variability. It has long been suggested that the resulting correlations among amino acid compositions at different sequence positions can be exploited to infer spatial contacts within the tertiary protein structure. Crucial to this inference is the ability to disentangle direct and indirect correlations, as accomplished by the recently introduced direct-coupling analysis (DCA). Here we develop a computationally efficient implementation of DCA, which allows us to evaluate the accuracy of contact prediction by DCA for a large number of protein domains, based purely on sequence information. DCA is shown to yield a large number of correctly predicted contacts, recapitulating the global structure of the contact map for the majority of the protein domains examined. Furthermore, our analysis captures clear …",
        "year": 2011,
        "authors": "Faruck Morcos and Andrea Pagnani and Bryan Lunt and Arianna Bertolino and Debora S Marks and Chris Sander and Riccardo Zecchina and José N Onuchic and Terence Hwa and Martin Weigt"
      },
      {
        "title": "Protein 3D structure computed from evolutionary sequence variation",
        "abstract": "The evolutionary trajectory of a protein through sequence space is constrained by its function. Collections of sequence homologs record the outcomes of millions of evolutionary experiments in which the protein evolves according to these constraints. Deciphering the evolutionary record held in these sequences and exploiting it for predictive and engineering purposes presents a formidable challenge. The potential benefit of solving this challenge is amplified by the advent of inexpensive high-throughput genomic sequencing.In this paper we ask whether we can infer evolutionary constraints from a set of sequence homologs of a protein. The challenge is to distinguish true co-evolution couplings from the noisy set of observed correlations. We address this challenge using a maximum entropy model of the protein sequence, constrained by the statistics of the multiple sequence alignment, to infer residue pair couplings. Surprisingly, we find that the strength of these inferred couplings is an excellent predictor of residue-residue proximity in folded structures. Indeed, the top-scoring residue couplings are sufficiently accurate and well-distributed to define the 3D protein fold with remarkable accuracy.We quantify this observation by computing, from sequence alone, all-atom 3D structures of fifteen test proteins from different fold classes, ranging in size from 50 to 260 residues., including a G-protein coupled receptor. These blinded inferences are de novo, i.e., they do not use homology modeling or sequence-similar fragments from known structures. The co-evolution signals provide sufficient information to determine accurate 3D protein structure to …",
        "year": 2011,
        "authors": "Debora S Marks and Lucy J Colwell and Robert Sheridan and Thomas A Hopf and Andrea Pagnani and Riccardo Zecchina and Chris Sander"
      },
      {
        "title": "Integrated transcriptional and competitive endogenous RNA networks are cross-regulated in permissive molecular environments",
        "abstract": "Competitive endogenous (ce)RNAs cross-regulate each other through sequestration of shared microRNAs and form complex regulatory networks based on their microRNA signature. However, the molecular requirements for ceRNA cross-regulation and the extent of ceRNA networks remain unknown. Here, we present a mathematical mass-action model to determine the optimal conditions for ceRNA activity in silico. This model was validated using phosphatase and tensin homolog (PTEN) and its ceRNA VAMP (vesicle-associated membrane protein)-associated protein A (VAPA) as paradigmatic examples. A computational assessment of the complexity of ceRNA networks revealed that transcription factor and ceRNA networks are intimately intertwined. Notably, we found that ceRNA networks are responsive to transcription factor up-regulation or their aberrant expression in cancer. Thus, given optimal molecular …",
        "year": 2013,
        "authors": "Ugo Ala and Florian A Karreth and Carla Bosia and Andrea Pagnani and Riccardo Taulli and Valentine Léopold and Yvonne Tay and Paolo Provero and Riccardo Zecchina and Pier Paolo Pandolfi"
      }
    ],
    "POlWWAsAAAAJ": [
      {
        "title": "Libd: Scalable and precise third-party library detection in android markets",
        "abstract": "With the thriving of the mobile app markets, third-party libraries are pervasively integrated in the Android applications. Third-party libraries provide functionality such as advertisements, location services, and social networking services, making multi-functional app development much more productive. However, the spread of vulnerable or harmful third-party libraries may also hurt the entire mobile ecosystem, leading to various security problems. The Android platform suffers severely from such problems due to the way its ecosystem is constructed and maintained. Therefore, third-party Android library identification has emerged as an important problem which is the basis of many security applications such as repackaging detection and malware analysis. According to our investigation, existing work on Android library detection still requires improvement in many aspects, including accuracy and obfuscation resilience. In …",
        "year": 2017,
        "authors": "Menghao Li and Wei Wang and Pei Wang and Shuai Wang and Dinghao Wu and Jian Liu and Rui Xue and Wei Huo"
      },
      {
        "title": "Reassembleable disassembling",
        "abstract": "Reverse engineering has many important applications in computer security, one of which is retrofitting software for safety and security hardening when source code is not available. By surveying available commercial and academic reverse engineering tools, we surprisingly found that no existing tool is able to disassemble executable binaries into assembly code that can be correctly assembled back in a fully automated manner, even for simple programs. Actually in many cases, the resulted disassembled code is far from a state that an assembler accepts, which is hard to fix even by manual effort. This has become a severe obstacle. People have tried to overcome it by patching or duplicating new code sections for retrofitting of executables, which is not only inefficient but also cumbersome and restrictive on what retrofitting techniques can be applied to.",
        "year": 2015,
        "authors": "Shuai Wang and Pei Wang and Dinghao Wu"
      },
      {
        "title": "CacheD: Identifying Cache-Based Timing Channels in Production Software",
        "abstract": "Side-channel attacks recover secret information by analyzing the physical implementation of cryptosystems based on non-functional computational characteristics, eg time, power, and memory usage. Among all well-known side channels, cache-based timing channels are notoriously severe, leading to practical attacks against certain implementations of theoretically secure crypto algorithms, such as RSA, ElGamal and AES. Such attacks target the hierarchical design of the modern computer memory system, where different memory access patterns of a program can bring observable timing difference.",
        "year": 2017,
        "authors": "Shuai Wang and Pei Wang and Xiao Liu and Danfeng Zhang and Dinghao Wu"
      }
    ],
    "n1zDCkQAAAAJ": [
      {
        "title": "Arnetminer: extraction and mining of academic social networks",
        "abstract": "This paper addresses several key issues in the ArnetMiner system, which aims at extracting and mining academic social networks. Specifically, the system focuses on: 1) Extracting researcher profiles automatically from the Web; 2) Integrating the publication data into the network from existing digital libraries; 3) Modeling the entire academic network; and 4) Providing search services for the academic network. So far, 448,470 researcher profiles have been extracted using a unified tagging approach. We integrate publications from online Web databases and propose a probabilistic framework to deal with the name ambiguity problem. Furthermore, we propose a unified modeling approach to simultaneously model topical aspects of papers, authors, and publication venues. Search services such as expertise search and people association search have been provided based on the modeling results. In this paper, we …",
        "year": 2008,
        "authors": "Jie Tang and Jing Zhang and Limin Yao and Juanzi Li and Li Zhang and Zhong Su"
      },
      {
        "title": "Self-supervised Learning: Generative or Contrastive",
        "abstract": "Deep supervised learning has achieved great success in the last decade. However, its defects of heavy dependence on manual labels and vulnerability to attacks have driven people to find other paradigms. As an alternative, self-supervised learning (SSL) attracts many researchers for its soaring performance on representation learning in the last several years. Self-supervised representation learning leverages input data itself as supervision and benefits almost all types of downstream tasks. In this survey, we take a look into new self-supervised learning methods for representation in computer vision, natural language processing, and graph learning. We comprehensively review the existing empirical methods and summarize them into three main categories according to their objectives: generative, contrastive, and generative-contrastive (adversarial). We further collect related theoretical analysis on self-supervised …",
        "year": 2021,
        "authors": "Xiao Liu and Fanjin Zhang and Zhenyu Hou and Zhaoyu Wang and Li Mian and Jing Zhang and Jie Tang"
      },
      {
        "title": "GPT understands, too",
        "abstract": "Prompting a pretrained language model with natural language patterns has been proved effective for natural language understanding (NLU). However, our preliminary study reveals that manual discrete prompts often lead to unstable performance—e.g., changing a single word in the prompt might result in substantial performance drop. We propose a novel method P-Tuning that employs trainable continuous prompt embeddings in concatenation with discrete prompts. Empirically, P-Tuning not only stabilizes training by minimizing the gap between various discrete prompts, but also improves performance by a sizeable margin on a wide range of NLU tasks including LAMA and SuperGLUE. P-Tuning is generally effective for both frozen and tuned language models, under both the fully-supervised and few-shot settings.",
        "year": 2023,
        "authors": "Xiao Liu and Yanan Zheng and Zhengxiao Du and Ming Ding and Yujie Qian and Zhilin Yang and Jie Tang"
      }
    ],
    "SqFoZNUAAAAJ": [
      {
        "title": "On the spread of viruses on the internet",
        "abstract": "We analyze the contact process on random graphs generated according to the preferential attachment scheme as a model for the spread of viruses in the Internet. We show that any virus with a positive rate of spread from a node to its neighbors has a non-vanishing chance of becoming epidemic. Quantitatively, we discover an interesting dichotomy: for a virus with effective spread rate λ, if the infection starts at a typical vertex, then it develops into an epidemic with probability λΘ (log (1/λ) log log (1/λ)), but on average the epidemic probability is λΘ (1).",
        "year": 2005,
        "authors": "Noam Berger and Christian Borgs and Jennifer Chayes and Amin Saberi"
      },
      {
        "title": "Quenched invariance principle for simple random walk on percolation clusters",
        "abstract": "We consider the simple random walk on the (unique) infinite cluster of super-critical bond percolation in ℤ d  with d≥2. We prove that, for almost every percolation configuration, the path distribution of the walk converges weakly to that of non-degenerate, isotropic Brownian motion. Our analysis is based on the consideration of a harmonic deformation of the infinite cluster on which the random walk becomes a square-integrable martingale. The size of the deformation, expressed by the so called corrector, is estimated by means of ergodicity arguments.",
        "year": 2007,
        "authors": "Noam Berger and Marek Biskup"
      },
      {
        "title": "Glauber dynamics on trees and hyperbolic graphs",
        "abstract": "We study continuous time Glauber dynamics for random configurations with local constraints (e.g. proper coloring, Ising and Potts models) on finite graphs with n vertices and of bounded degree. We show that the relaxation time (defined as the reciprocal of the spectral gap |λ1−λ2|) for the dynamics on trees and on planar hyperbolic graphs, is polynomial in n. For these hyperbolic graphs, this yields a general polynomial sampling algorithm for random configurations. We then show that for general graphs, if the relaxation time τ2 satisfies τ2=O(1), then the correlation coefficient, and the mutual information, between any local function (which depends only on the configuration in a fixed window) and the boundary conditions, decays exponentially in the distance between the window and the boundary. For the Ising model on a regular tree, this condition is sharp.",
        "year": 2005,
        "authors": "Noam Berger and Claire Kenyon and Elchanan Mossel and Yuval Peres"
      }
    ],
    "3yT6IX4AAAAJ": [
      {
        "title": "Guidelines for the use and interpretation of assays for monitoring autophagy (4th edition)1",
        "abstract": "In 2008, we published the first set of guidelines for standardizing research in autophagy. Since then, this topic has received increasing attention, and many scientists have entered the field. Our knowledge base and relevant new technologies have also been expanding. Thus, it is important to formulate on a regular basis updated guidelines for monitoring autophagy in different organisms. Despite numerous reviews, there continues to be confusion regarding acceptable methods to evaluate autophagy, especially in multicellular eukaryotes. Here, we present a set of guidelines for investigators to select and interpret methods to examine autophagy and related processes, and for reviewers to provide realistic and reasonable critiques of reports that are focused on these processes. These guidelines are not meant to be a dogmatic set of rules, because the appropriateness of any assay largely depends on the question …",
        "year": 2021,
        "authors": "Daniel J Klionsky and Amal Kamal Abdel-Aziz and Sara Abdelfatah and Mahmoud Abdellatif and Asghar Abdoli and Steffen Abel and Hagai Abeliovich and Marie H Abildgaard and Yakubu Princely Abudu and Abraham Acevedo-Arozena and Iannis E Adamopoulos and Khosrow Adeli and Timon E Adolph and Annagrazia Adornetto and Elma Aflaki and Galila Agam and Anupam Agarwal and Bharat B Aggarwal and Maria Agnello and Patrizia Agostinis and Javed N Agrewala and Alexander Agrotis and Patricia V Aguilar and S Tariq Ahmad and Zubair M Ahmed and Ulises Ahumada-Castro and Sonja Aits and Shu Aizawa and Yunus Akkoc and Tonia Akoumianaki and Hafize Aysin Akpinar and Ahmed M Al-Abd and Lina Al-Akra and Abeer Al-Gharaibeh and Moulay A Alaoui-Jamali and Simon Alberti and Elísabet Alcocer-Gómez and Cristiano Alessandri and Muhammad Ali and M Abdul Alim Al-Bari and Saeb Aliwaini and Javad Alizadeh and Eugènia Almacellas and Alexandru Almasan and Alicia Alonso and Guillermo D Alonso and Nihal Altan-Bonnet and Dario C Altieri and Élida MC Álvarez and Sara Alves and Cristine Alves da Costa and Mazen M Alzaharna and Marialaura Amadio and Consuelo Amantini and Cristina Amaral and Susanna Ambrosio and Amal O Amer and Veena Ammanathan and Zhenyi An and Stig U Andersen and Shaida A Andrabi and Magaiver Andrade-Silva and Allen M Andres and Sabrina Angelini and David Ann and Uche C Anozie and Mohammad Y Ansari and Pedro Antas and Adam Antebi and Zuriñe Antón and Tahira Anwar and Lionel Apetoh and Nadezda Apostolova and Toshiyuki Araki and Yasuhiro Araki and Kohei Arasaki and Wagner L Araújo and Jun Araya and Catherine Arden and Maria-Angeles Arévalo and Sandro Arguelles and Esperanza Arias and Jyothi Arikkath and Hirokazu Arimoto and Aileen R Ariosa and Darius Armstrong-James and Laetitia Arnauné-Pelloquin and Angeles Aroca and Daniela S Arroyo and Ivica Arsov and Rubén Artero and Dalia Maria Lucia Asaro and Michael Aschner and Milad Ashrafizadeh and Osnat Ashur-Fabian and Atanas G Atanasov and Alicia K Au and Patrick Auberger and Holger W Auner and Laure Aurelian and Riccardo Autelli and Laura Avagliano and Yenniffer Ávalos and Sanja Aveic and Célia Alexandra Aveleira and Tamar Avin-Wittenberg and Yucel Aydin and Scott Ayton and Srinivas Ayyadevara and Maria Azzopardi and Misuzu Baba and Jonathan M Backer and Steven K Backues and Dong-Hun Bae and Ok-Nam Bae and Soo Han Bae and Eric H Baehrecke and Ahruem Baek and Seung-Hoon Baek and Sung Hee Baek and Giacinto Bagetta and Agnieszka Bagniewska-Zadworna and Hua Bai and Jie Bai and Xiyuan Bai and Yidong Bai and Nandadulal Bairagi and Shounak Baksi and Teresa Balbi and Cosima T Baldari and Walter Balduini and Andrea Ballabio and Maria Ballester and Salma Balazadeh and Rena Balzan and Rina Bandopadhyay and Sreeparna Banerjee and Sulagna Banerjee and Ágnes Bánréti and Yan Bao and Mauricio S Baptista and Alessandra Baracca and Cristiana Barbati and Ariadna Bargiela and Daniela Barilà and Peter G Barlow and Sami J Barmada and Esther Barreiro and George E Barreto and Jiri Bartek"
      },
      {
        "title": "Hypoxia—a key regulatory factor in tumour growth",
        "abstract": "Cells undergo a variety of biological responses when placed in hypoxic conditions, including activation of signalling pathways that regulate proliferation, angiogenesis and death. Cancer cells have adapted these pathways, allowing tumours to survive and even grow under hypoxic conditions, and tumour hypoxia is associated with poor prognosis and resistance to radiation therapy. Many elements of the hypoxia-response pathway are therefore good candidates for therapeutic targeting.",
        "year": 2002,
        "authors": "Adrian L Harris"
      }
    ],
    "_1hCq3UAAAAJ": [
      {
        "title": "Locality-sensitive hashing scheme based on p-stable distributions",
        "abstract": "We present a novel Locality-Sensitive Hashing scheme for the Approximate Nearest Neighbor Problem under lp norm, based on p-stable distributions.Our scheme improves the running time of the earlier algorithm for the case of the lp norm. It also yields the first known provably efficient approximate NN algorithm for the case p<1. We also show that the algorithm finds the exact near neigbhor in O(log n) time for data satisfying certain \"bounded growth\" condition.Unlike earlier schemes, our LSH scheme works directly on points in the Euclidean space without embeddings. Consequently, the resulting query time bound is free of large factors and is simple and easy to implement. Our experiments (on synthetic data sets) show that the our data structure is up to 40 times faster than kd-tree.",
        "year": 2004,
        "authors": "Mayur Datar and Nicole Immorlica and Piotr Indyk and Vahab S Mirrokni"
      },
      {
        "title": "Correlation clustering in general weighted graphs",
        "abstract": "We consider the following general correlation-clustering problem [N. Bansal, A. Blum, S. Chawla, Correlation clustering, in: Proc. 43rd Annu. IEEE Symp. on Foundations of Computer Science, Vancouver, Canada, November 2002, pp. 238–250]: given a graph with real nonnegative edge weights and a 〈+〉/〈-〉 edge labelling, partition the vertices into clusters to minimize the total weight of cut 〈+〉 edges and uncut 〈-〉 edges. Thus, 〈+〉 edges with large weights (representing strong correlations between endpoints) encourage those endpoints to belong to a common cluster while 〈-〉 edges with large weights encourage the endpoints to belong to different clusters. In contrast to most clustering problems, correlation clustering specifies neither the desired number of clusters nor a distance threshold for clustering; both of these parameters are effectively chosen to be the best possible by the problem definition …",
        "year": 2006,
        "authors": "Erik D Demaine and Dotan Emanuel and Amos Fiat and Nicole Immorlica"
      },
      {
        "title": "Decoupled classifiers for group-fair and efficient machine learning",
        "abstract": "When it is ethical and legal to use a sensitive attribute (such as gender or race) in machine learning systems, the question remains how to do so. We show that the naive application of machine learning algorithms using sensitive attributes leads to an inherent tradeoff in accuracy between groups. We provide a simple and efficient decoupling technique, that can be added on top of any black-box machine learning algorithm, to learn different classifiers for different groups. Transfer learning is used to mitigate the problem of having too little data on any one group.",
        "year": 2018,
        "authors": "Cynthia Dwork and Nicole Immorlica and Adam Tauman Kalai and Max Leiserson"
      }
    ],
    "78WTKm4AAAAJ": [
      {
        "title": "Eyes wide shut? exploring the visual shortcomings of multimodal llms",
        "abstract": "Is vision good enough for language? Recent advancements in multimodal models primarily stem from the powerful reasoning abilities of large language models (LLMs). However the visual component typically depends only on the instance-level contrastive language-image pre-training (CLIP). Our research reveals that the visual capabilities in recent MultiModal LLMs (MLLMs) still exhibit systematic shortcomings. To understand the roots of these errors we explore the gap between the visual embedding space of CLIP and vision-only self-supervised learning. We identify\" CLIP-blind pairs\"-images that CLIP perceives as similar despite their clear visual differences. With these pairs we construct the Multimodal Visual Patterns (MMVP) benchmark. MMVP exposes areas where state-of-the-art systems including GPT-4V struggle with straightforward questions across nine basic visual patterns often providing incorrect answers and hallucinated explanations. We further evaluate various CLIP-based vision-and-language models and found a notable correlation between visual patterns that challenge CLIP models and those problematic for multimodal LLMs. As an initial effort to address these issues we propose a Mixture of Features (MoF) approach demonstrating that integrating vision self-supervised learning features with MLLMs can significantly enhance their visual grounding capabilities. Together our research suggests visual representation learning remains an open challenge and accurate visual grounding is crucial for future successful multimodal systems.",
        "year": 2024,
        "authors": "Shengbang Tong and Zhuang Liu and Yuexiang Zhai and Yi Ma and Yann LeCun and Saining Xie"
      },
      {
        "title": "Investigating the catastrophic forgetting in multimodal large language model fine-tuning",
        "abstract": "Following the success of GPT4, there has been a surge in interest in multimodal large language model (MLLM) research. This line of research focuses on developing general-purpose LLMs through fine-tuning pre-trained LLMs and vision models. However, catastrophic forgetting, a notorious phenomenon where the fine-tuned model fails to retain similar performance compared to the pre-trained model, still remains an inherited problem in multimodal LLMs (MLLM). In this paper, we introduce EMT: Evaluating MulTimodality for evaluating the catastrophic forgetting in MLLMs, by treating each MLLM as an image classifier. We first apply EMT to evaluate several open-source fine-tuned MLLMs and we discover that almost all evaluated MLLMs fail to retain the same performance levels as their vision encoders on standard image classification tasks. Moreover, we continue fine-tuning LLaVA, an MLLM and utilize EMT to assess performance throughout the fine-tuning. Interestingly, our results suggest that early-stage fine-tuning on an image dataset improves performance across other image datasets, by enhancing the alignment of text and language features. However, as fine-tuning proceeds, the MLLMs begin to hallucinate, resulting in a significant loss of generalizability, even when the image encoder remains frozen. Our results suggest that MLLMs have yet to demonstrate performance on par with their vision models on standard image classification tasks and the current MLLM fine-tuning procedure still has room for improvement.",
        "year": 2024,
        "authors": "Yuexiang Zhai and Shengbang Tong and Xiao Li and Mu Cai and Qing Qu and Yong Jae Lee and Yi Ma"
      },
      {
        "title": "Cal-ql: Calibrated offline rl pre-training for efficient online fine-tuning",
        "abstract": "A compelling use case of offline reinforcement learning (RL) is to obtain a policy initialization from existing datasets followed by fast online fine-tuning with limited interaction. However, existing offline RL methods tend to behave poorly during fine-tuning. In this paper, we devise an approach for learning an effective initialization from offline data that also enables fast online fine-tuning capabilities. Our approach, calibrated Q-learning (Cal-QL), accomplishes this by learning a conservative value function initialization that underestimates the value of the learned policy from offline data, while also being calibrated, in the sense that the learned Q-values are at a reasonable scale. We refer to this property as calibration, and define it formally as providing a lower bound on the true value function of the learned policy and an upper bound on the value of some other (suboptimal) reference policy, which may simply be the behavior policy. We show that offline RL algorithms that learn such calibrated value functions lead to effective online fine-tuning, enabling us to take the benefits of offline initializations in online fine-tuning. In practice, Cal-QL can be implemented on top of the conservative Q learning (CQL) for offline RL within a one-line code change. Empirically, Cal-QL outperforms state-of-the-art methods on 9/11 fine-tuning benchmark tasks that we study in this paper. Code and video are available at https://nakamotoo. github. io/Cal-QL",
        "year": 2023,
        "authors": "Mitsuhiko Nakamoto and Simon Zhai and Anikait Singh and Max Sobol Mark and Yi Ma and Chelsea Finn and Aviral Kumar and Sergey Levine"
      }
    ],
    "znnl0kwAAAAJ": [
      {
        "title": "Octo: An open-source generalist robot policy",
        "abstract": "Octo: An Open-Source Generalist Robot Policy | OpenReview OpenReview.net Login back arrow \nGo to DBLP homepage Octo: An Open-Source Generalist Robot Policy Open Webpage Dibya \nGhosh, Homer Rich Walke, Karl Pertsch, Kevin Black, Oier Mees, Sudeep Dasari, Joey Hejna, \nTobias Kreiman, Charles Xu, Jianlan Luo, You Liang Tan, Lawrence Yunliang Chen, Quan \nVuong, Ted Xiao, Pannag R. Sanketi, Dorsa Sadigh, Chelsea Finn, Sergey Levine Published: \n01 Jan 2024, Last Modified: 23 Mar 2025Robotics: Science and Systems 2024Everyone\nRevisionsBibTeXCC BY-SA 4.0 Loading About OpenReview Hosting a Venue All Venues \nContact Feedback Sponsors Join the Team Frequently Asked Questions Terms of Use Privacy \nPolicy About OpenReview Hosting a Venue All Venues Sponsors Join the Team Frequently \nAsked Questions Contact Feedback Terms of Use Privacy Policy OpenReview is a long-…",
        "year": 2024,
        "authors": "Dibya Ghosh and Homer Rich Walke and Karl Pertsch and Kevin Black and Oier Mees and Sudeep Dasari and Joey Hejna and Tobias Kreiman and Charles Xu and Jianlan Luo and You Liang Tan and Lawrence Yunliang Chen and Quan Vuong and Ted Xiao and Pannag R Sanketi and Dorsa Sadigh and Chelsea Finn and Sergey Levine"
      },
      {
        "title": "Learning to reach goals via iterated supervised learning",
        "abstract": "Current reinforcement learning (RL) algorithms can be brittle and difficult to use, especially when learning goal-reaching behaviors from sparse rewards. Although supervised imitation learning provides a simple and stable alternative, it requires access to demonstrations from a human supervisor. In this paper, we study RL algorithms that use imitation learning to acquire goal reaching policies from scratch, without the need for expert demonstrations or a value function. In lieu of demonstrations, we leverage the property that any trajectory is a successful demonstration for reaching the final state in that same trajectory. We propose a simple algorithm in which an agent continually relabels and imitates the trajectories it generates to progressively learn goal-reaching behaviors from scratch. Each iteration, the agent collects new trajectories using the latest policy, and maximizes the likelihood of the actions along these trajectories under the goal that was actually reached, so as to improve the policy. We formally show that this iterated supervised learning procedure optimizes a bound on the RL objective, derive performance bounds of the learned policy, and empirically demonstrate improved goal-reaching performance and robustness over current RL algorithms in several benchmark tasks.",
        "year": 2021,
        "authors": "Dibya Ghosh and Abhishek Gupta and Ashwin Reddy and Justin Fu and Coline Devin and Benjamin Eysenbach and Sergey Levine"
      },
      {
        "title": "Why generalization in rl is difficult: Epistemic pomdps and implicit partial observability",
        "abstract": "Generalization is a central challenge for the deployment of reinforcement learning (RL) systems in the real world. In this paper, we show that the sequential structure of the RL problem necessitates new approaches to generalization beyond the well-studied techniques used in supervised learning. While supervised learning methods can generalize effectively without explicitly accounting for epistemic uncertainty, we describe why appropriate uncertainty handling can actually be essential in RL. We show that generalization to unseen test conditions from a limited number of training conditions induces a kind of implicit partial observability, effectively turning even fully-observed MDPs into POMDPs. Informed by this observation, we recast the problem of generalization in RL as solving the induced partially observed Markov decision process, which we call the epistemic POMDP. We demonstrate the failure modes of algorithms that do not appropriately handle this partial observability, and suggest a simple ensemble-based technique for approximately solving the partially observed problem. Empirically, we demonstrate that our simple algorithm derived from the epistemic POMDP achieves significant gains in generalization over current methods on the Procgen benchmark suite.",
        "year": 2021,
        "authors": "Dibya Ghosh and Jad Rahme and Aviral Kumar and Amy Zhang and Ryan P Adams and Sergey Levine"
      }
    ],
    "nCFeUqYAAAAJ": [
      {
        "title": "How do transformers learn in-context beyond simple functions? a case study on learning with representations",
        "abstract": "While large language models based on the transformer architecture have demonstrated remarkable in-context learning (ICL) capabilities, understandings of such capabilities are still in an early stage, where existing theory and mechanistic understanding focus mostly on simple scenarios such as learning simple function classes. This paper takes initial steps on understanding ICL in more complex scenarios, by studying learning with representations. Concretely, we construct synthetic in-context learning problems with a compositional structure, where the label depends on the input through a possibly complex but fixed representation function, composed with a linear function that differs in each instance. By construction, the optimal ICL algorithm first transforms the inputs by the representation function, and then performs linear ICL on top of the transformed dataset. We show theoretically the existence of transformers that approximately implement such algorithms with mild depth and size. Empirically, we find trained transformers consistently achieve near-optimal ICL performance in this setting, and exhibit the desired dissection where lower layers transforms the dataset and upper layers perform linear ICL. Through extensive probing and a new pasting experiment, we further reveal several mechanisms within the trained transformers, such as concrete copying behaviors on both the inputs and the representations, linear ICL capability of the upper layers alone, and a post-ICL representation selection mechanism in a harder mixture setting. These observed mechanisms align well with our theory and may shed light on how transformers perform ICL in …",
        "year": 2023,
        "authors": "Tianyu Guo and Wei Hu and Song Mei and Huan Wang and Caiming Xiong and Silvio Savarese and Yu Bai"
      },
      {
        "title": "What can a single attention layer learn? a study through the random features lens",
        "abstract": "Attention layers---which map a sequence of inputs to a sequence of outputs---are core building blocks of the Transformer architecture which has achieved significant breakthroughs in modern artificial intelligence. This paper presents a rigorous theoretical study on the learning and generalization of a single multi-head attention layer, with a sequence of key vectors and a separate query vector as input. We consider the random feature setting where the attention layer has a large number of heads, with randomly sampled frozen query and key matrices, and trainable value matrices. We show that such a random-feature attention layer can express a broad class of target functions that are permutation invariant to the key vectors. We further provide quantitative excess risk bounds for learning these target functions from finite samples, using random feature attention with finitely many heads. Our results feature several implications unique to the attention structure compared with existing random features theory for neural networks, such as (1) Advantages in the sample complexity over standard two-layer random-feature networks;(2) Concrete and natural classes of functions that can be learned efficiently by a random-feature attention layer; and (3) The effect of the sampling distribution of the query-key weight matrix (the product of the query and key matrix), where Gaussian random weights with a non-zero mean result in better sample complexities over the zero-mean counterpart for learning certain natural target functions. Experiments on simulated data corroborate our theoretical findings and further illustrate the interplay between the sample size and the …",
        "year": 2023,
        "authors": "Hengyu Fu and Tianyu Guo and Yu Bai and Song Mei"
      },
      {
        "title": "Collaborative heterogeneous causal inference beyond meta-analysis",
        "abstract": "Collaboration between different data centers is often challenged by heterogeneity across sites. To account for the heterogeneity, the state-of-the-art method is to re-weight the covariate distributions in each site to match the distribution of the target population. Nevertheless, this method could easily fail when a certain site couldn't cover the entire population. Moreover, it still relies on the concept of traditional meta-analysis after adjusting for the distribution shift. In this work, we propose a collaborative inverse propensity score weighting estimator for causal inference with heterogeneous data. Instead of adjusting the distribution shift separately, we use weighted propensity score models to collaboratively adjust for the distribution shift. Our method shows significant improvements over the methods based on meta-analysis when heterogeneity increases. To account for the vulnerable density estimation, we further discuss the double machine method and show the possibility of using nonparametric density estimation with d<8 and a flexible machine learning method to guarantee asymptotic normality. We propose a federated learning algorithm to collaboratively train the outcome model while preserving privacy. Using synthetic and real datasets, we demonstrate the advantages of our method.",
        "year": 2024,
        "authors": "Tianyu Guo and Sai Praneeth Karimireddy and Michael I Jordan"
      }
    ],
    "LWlN_BUAAAAJ": [
      {
        "title": "Agnostic active learning",
        "abstract": "We state and analyze the first active learning algorithm which works in the presence of arbitrary forms of noise. The algorithm, A2 (for Agnostic Active), relies only upon the assumption that the samples are drawn i.i.d. from a fixed distribution. We show that A2 achieves an exponential improvement (i.e., requires only O (ln 1/ε) samples to find an ε-optimal classifier) over the usual sample complexity of supervised learning, for several settings considered before in the realizable case. These include learning threshold classifiers and learning homogeneous linear separators with respect to an input distribution which is uniform over the unit sphere.",
        "year": 2006,
        "authors": "Maria-Florina Balcan and Alina Beygelzimer and John Langford"
      },
      {
        "title": "Margin based active learning",
        "abstract": "We present a framework for margin based active learning of linear separators. We instantiate it for a few important cases, some of which have been previously considered in the literature. We analyze the effectiveness of our framework both in the realizable case and in a specific noisy setting related to the Tsybakov small noise condition.",
        "year": 2007,
        "authors": "Maria-Florina Balcan and Andrei Broder and Tong Zhang"
      },
      {
        "title": "Adaptive gradient-based meta-learning methods",
        "abstract": "We build a theoretical framework for designing and understanding practical meta-learning methods that integrates sophisticated formalizations of task-similarity with the extensive literature on online convex optimization and sequential prediction algorithms. Our approach enables the task-similarity to be learned adaptively, provides sharper transfer-risk bounds in the setting of statistical learning-to-learn, and leads to straightforward derivations of average-case regret bounds for efficient algorithms in settings where the task-environment changes dynamically or the tasks share a certain geometric structure. We use our theory to modify several popular meta-learning algorithms and improve their training and meta-test-time performance on standard problems in few-shot and federated learning.",
        "year": 2019,
        "authors": "Mikhail Khodak and Maria-Florina F Balcan and Ameet S Talwalkar"
      }
    ],
    "C2_ZXdcAAAAJ": [
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Machel Reid and Nikolay Savinov and Denis Teplyashin and Dmitry Lepikhin and Timothy Lillicrap and Jean-baptiste Alayrac and Radu Soricut and Angeliki Lazaridou and Orhan Firat and Julian Schrittwieser and Ioannis Antonoglou and Rohan Anil and Sebastian Borgeaud and Andrew Dai and Katie Millican and Ethan Dyer and Mia Glaese and Thibault Sottiaux and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and James Molloy and Jilin Chen and Michael Isard and Paul Barham and Tom Hennigan and Ross McIlroy and Melvin Johnson and Johan Schalkwyk and Eli Collins and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Clemens Meyer and Gregory Thornton and Zhen Yang and Henryk Michalewski and Zaheer Abbas and Nathan Schucher and Ankesh Anand and Richard Ives and James Keeling and Karel Lenc and Salem Haykal and Siamak Shakeri and Pranav Shyam and Aakanksha Chowdhery and Roman Ring and Stephen Spencer and Eren Sezener and Luke Vilnis and Oscar Chang and Nobuyuki Morioka and George Tucker and Ce Zheng and Oliver Woodman and Nithya Attaluri and Tomas Kocisky and Evgenii Eltyshev and Xi Chen and Timothy Chung and Vittorio Selo and Siddhartha Brahma and Petko Georgiev and Ambrose Slone and Zhenkai Zhu and James Lottes and Siyuan Qiao and Ben Caine and Sebastian Riedel and Alex Tomala and Martin Chadwick and Juliette Love and Peter Choy and Sid Mittal and Neil Houlsby and Yunhao Tang and Matthew Lamm and Libin Bai and Qiao Zhang and Luheng He and Yong Cheng and Peter Humphreys and Yujia Li and Sergey Brin and Albin Cassirer and Yingjie Miao and Lukas Zilka and Taylor Tobin and Kelvin Xu and Lev Proleev and Daniel Sohn and Alberto Magni and Lisa Anne Hendricks and Isabel Gao and Santiago Ontañón and Oskar Bunyan and Nathan Byrd and Abhanshu Sharma and Biao Zhang and Mario Pinto and Rishika Sinha and Harsh Mehta and Dawei Jia and Sergi Caelles and Albert Webson and Alex Morris and Becca Roelofs and Yifan Ding and Robin Strudel and Xuehan Xiong and Marvin Ritter and Mostafa Dehghani and Rahma Chaabouni and Abhijit Karmarkar and Guangda Lai and Fabian Mentzer and Bibo Xu and YaGuang Li and Yujing Zhang and Tom Le Paine and Alex Goldin and Behnam Neyshabur and Kate Baumli and Anselm Levskaya and Michael Laskin and Wenhao Jia and Jack W Rae and Kefan Xiao and Antoine He and Skye Giordano and Lakshman Yagati and Jean-Baptiste Lespiau and Paul Natsev and Sanjay Ganapathy and Fangyu Liu and Danilo Martins and Nanxin Chen and Yunhan Xu and Megan Barnes and Rhys May and Arpi Vezer and Junhyuk Oh and Ken Franko and Sophie Bridgers and Ruizhe Zhao and Boxi Wu and Basil Mustafa"
      },
      {
        "title": "Visual dialog",
        "abstract": "We introduce the task of Visual Dialog, which requires an AI agent to hold a meaningful dialog with humans in natural, conversational language about visual content. Specifically, given an image, a dialog history, and a question about the image, the agent has to ground the question in image, infer context from history, and answer the question accurately. Visual Dialog is disentangled enough from a specific downstream task so as to serve as a general test of machine intelligence, while being grounded in vision enough to allow objective evaluation of individual responses and benchmark progress. We develop a novel two-person chat data-collection protocol to curate a large-scale Visual Dialog dataset (VisDial). VisDial contains 1 dialog (10 question-answer pairs) on 140k images from the COCO dataset, with a total of 1.4 M dialog question-answer pairs. We introduce a family of neural encoder-decoder models for Visual Dialog with 3 encoders (Late Fusion, Hierarchical Recurrent Encoder and Memory Network) and 2 decoders (generative and discriminative), which outperform a number of sophisticated baselines. We propose a retrieval-based evaluation protocol for Visual Dialog where the AI agent is asked to sort a set of candidate answers and evaluated on metrics such as mean-reciprocal-rank of human response. We quantify gap between machine and human performance on the Visual Dialog task via human studies. Our dataset, code, and trained models will be released publicly at https://visualdialog. org. Putting it all together, we demonstrate the first'visual chatbot'!",
        "year": 2017,
        "authors": "Abhishek Das and Satwik Kottur and Khushi Gupta and Avi Singh and Deshraj Yadav and José MF Moura and Devi Parikh and Dhruv Batra"
      },
      {
        "title": "Recurrent neural networks for driver activity anticipation via sensory-fusion architecture",
        "abstract": "Anticipating the future actions of a human is a widely studied problem in robotics that requires spatio-temporal reasoning. In this work we propose a deep learning approach for anticipation in sensory-rich robotics applications. We introduce a sensory-fusion architecture which jointly learns to anticipate and fuse information from multiple sensory streams. Our architecture consists of Recurrent Neural Networks (RNNs) that use Long Short-Term Memory (LSTM) units to capture long temporal dependencies. We train our architecture in a sequence-to-sequence prediction manner, and it explicitly learns to predict the future given only a partial temporal context. We further introduce a novel loss layer for anticipation which prevents over-fitting and encourages early anticipation. We use our architecture to anticipate driving maneuvers several seconds before they happen on a natural driving data set of 1180 miles. The …",
        "year": 2016,
        "authors": "Ashesh Jain and Avi Singh and Hema S Koppula and Shane Soh and Ashutosh Saxena"
      }
    ],
    "ijmuZ0wAAAAJ": [
      {
        "title": "Caffe: Convolutional architecture for fast feature embedding",
        "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community …",
        "year": 2014,
        "authors": "Yangqing Jia and Evan Shelhamer and Jeff Donahue and Sergey Karayev and Jonathan Long and Ross Girshick and Sergio Guadarrama and Trevor Darrell"
      },
      {
        "title": "Densenet: Implementing efficient convnet descriptor pyramids",
        "abstract": "Convolutional Neural Networks (CNNs) can provide accurate object classification. They can be extended to perform object detection by iterating over dense or selected proposed object regions. However, the runtime of such detectors scales as the total number and/or area of regions to examine per image, and training such detectors may be prohibitively slow. However, for some CNN classifier topologies, it is possible to share significant work among overlapping regions to be classified. This paper presents DenseNet, an open source system that computes dense, multiscale features from the convolutional layers of a CNN based object classifier. Future work will involve training efficient object detectors with DenseNet feature descriptors.",
        "year": 2014,
        "authors": "Forrest Iandola and Matt Moskewicz and Sergey Karayev and Ross Girshick and Trevor Darrell and Kurt Keutzer"
      },
      {
        "title": "Recognizing image style",
        "abstract": "The style of an image plays a significant role in how it is viewed, but style has received little attention in computer vision research. We describe an approach to predicting style of images, and perform a thorough evaluation of different image features for these tasks. We find that features learned in a multi-layer network generally perform best -- even when trained with object class (not style) labels. Our large-scale learning methods results in the best published performance on an existing dataset of aesthetic ratings and photographic style annotations. We present two novel datasets: 80K Flickr photographs annotated with 20 curated style labels, and 85K paintings annotated with 25 style/genre labels. Our approach shows excellent classification performance on both datasets. We use the learned classifiers to extend traditional tag-based image search to consider stylistic constraints, and demonstrate cross-dataset understanding of style.",
        "year": 2013,
        "authors": "Sergey Karayev and Matthew Trentacoste and Helen Han and Aseem Agarwala and Trevor Darrell and Aaron Hertzmann and Holger Winnemoeller"
      }
    ],
    "LajpoI8AAAAJ": [
      {
        "title": "How to Evaluate Reward Models for RLHF",
        "abstract": "We introduce a new benchmark for reward models that quantifies their ability to produce strong language models through RLHF (Reinforcement Learning from Human Feedback). The gold-standard approach is to run a full RLHF training pipeline and directly probe downstream LLM performance. However, this process is prohibitively expensive. To address this, we build a predictive model of downstream LLM performance by evaluating the reward model on proxy tasks. These proxy tasks consist of a large-scale human preference and a verifiable correctness preference dataset, in which we measure 12 metrics across 12 domains. To investigate which reward model metrics are most correlated to gold-standard RLHF outcomes, we launch an end-to-end RLHF experiment on a large-scale crowdsourced human preference platform to view real reward model downstream performance as ground truth. Ultimately, we compile our data and findings into Preference Proxy Evaluations (PPE), the first reward model benchmark explicitly linked to post-RLHF real-world human preference performance, which we open-source for public use and further development. Our code and evaluations can be found at https://github.com/lmarena/PPE .",
        "year": 2024,
        "authors": "Evan Frick and Tianle Li and Connor Chen and Wei-Lin Chiang and Anastasios N Angelopoulos and Jiantao Jiao and Banghua Zhu and Joseph E Gonzalez and Ion Stoica"
      },
      {
        "title": "Prompt-to-leaderboard",
        "abstract": "Large language model (LLM) evaluations typically rely on aggregated metrics like accuracy or human preference, averaging across users and prompts. This averaging obscures user- and prompt-specific variations in model performance. To address this, we propose Prompt-to-Leaderboard (P2L), a method that produces leaderboards specific to a prompt. The core idea is to train an LLM taking natural language prompts as input to output a vector of Bradley-Terry coefficients which are then used to predict the human preference vote. The resulting prompt-dependent leaderboards allow for unsupervised task-specific evaluation, optimal routing of queries to models, personalization, and automated evaluation of model strengths and weaknesses. Data from Chatbot Arena suggest that P2L better captures the nuanced landscape of language model performance than the averaged leaderboard. Furthermore, our findings suggest that P2L's ability to produce prompt-specific evaluations follows a power law scaling similar to that observed in LLMs themselves. In January 2025, the router we trained based on this methodology achieved the #1 spot on the Chatbot Arena leaderboard. Our code is available on GitHub at https://github.com/lmarena/p2l.",
        "year": 2025,
        "authors": "Evan Frick and Connor Chen and Joseph Tennyson and Tianle Li and Wei-Lin Chiang and Anastasios N Angelopoulos and Ion Stoica"
      }
    ],
    "jrfFYAIAAAAJ": [
      {
        "title": "Do as i can, not as i say: Grounding language in robotic affordances",
        "abstract": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model’s “hands and eyes,” while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project’s website, video, and open source can be …",
        "year": 2023,
        "authors": "Anthony Brohan and Yevgen Chebotar and Chelsea Finn and Karol Hausman and Alexander Herzog and Daniel Ho and Julian Ibarz and Alex Irpan and Eric Jang and Ryan Julian and Dmitry Kalashnikov and Sergey Levine and Yao Lu and Carolina Parada and Kanishka Rao and Pierre Sermanet and Alexander T Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Mengyuan Yan and Noah Brown and Michael Ahn and Omar Cortes and Nicolas Sievers and Clayton Tan and Sichun Xu and Diego Reyes and Jarek Rettinghouse and Jornell Quiambao and Peter Pastor and Linda Luu and Kuang-Huei Lee and Yuheng Kuang and Sally Jesmonth and Nikhil J Joshi and Kyle Jeffrey and Rosario Jauregui Ruano and Jasmine Hsu and Keerthana Gopalakrishnan and Byron David and Andy Zeng and Chuyuan Kelly Fu"
      },
      {
        "title": "Scalable deep reinforcement learning for vision-based robotic manipulation",
        "abstract": "In this paper, we study the problem of learning vision-based dynamic manipulation skills using a scalable reinforcement learning approach. We study this problem in the context of grasping, a longstanding challenge in robotic manipulation. In contrast to static learning behaviors that choose a grasp point and then execute the desired grasp, our method enables closed-loop vision-based control, whereby the robot continuously updates its grasp strategy based on the most recent observations to optimize long-horizon grasp success. To that end, we introduce QT-Opt, a scalable self-supervised vision-based reinforcement learning framework that can leverage over 580k real-world grasp attempts to train a deep neural network Q-function with over 1.2 M parameters to perform closed-loop, real-world grasping that generalizes to 96% grasp success on unseen objects. Aside from attaining a very high success rate, our method exhibits behaviors that are quite distinct from more standard grasping systems: using only RGB vision-based perception from an over-the-shoulder camera, our method automatically learns regrasping strategies, probes objects to find the most effective grasps, learns to reposition objects and perform other non-prehensile pre-grasp manipulations, and responds dynamically to disturbances and perturbations.",
        "year": 2018,
        "authors": "Dmitry Kalashnikov and Alex Irpan and Peter Pastor and Julian Ibarz and Alexander Herzog and Eric Jang and Deirdre Quillen and Ethan Holly and Mrinal Kalakrishnan and Vincent Vanhoucke and Sergey Levine"
      },
      {
        "title": "Rt-2: Vision-language-action models transfer web knowledge to robotic control",
        "abstract": "We study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robotic trajectory data and Internet-scale vision-language tasks, such as visual question answering. In contrast to other approaches, we propose a simple, general recipe to achieve this goal: in order to fit both natural language responses and robotic actions into the same format, we express the actions as text tokens and incorporate them directly into the training set of the model in the same way as natural language tokens. We refer to such category of models as vision-language-action models (VLA) and instantiate an example of such a model, which we call RT-2. Our extensive evaluation (6k evaluation trials) shows that our approach leads to performant robotic policies and enables RT-2 to obtain a range of emergent capabilities from Internet-scale training. This includes significantly improved generalization to novel objects, the ability to interpret commands not present in the robot training data (such as placing an object onto a particular number or icon), and the ability to perform rudimentary reasoning in response to user commands (such as picking up the smallest or largest object, or the one closest to another object). We further show that incorporating chain of …",
        "year": 2023,
        "authors": "Brianna Zitkovich and Tianhe Yu and Sichun Xu and Peng Xu and Ted Xiao and Fei Xia and Jialin Wu and Paul Wohlhart and Stefan Welker and Ayzaan Wahid and Quan Vuong and Vincent Vanhoucke and Huong Tran and Radu Soricut and Anikait Singh and Jaspiar Singh and Pierre Sermanet and Pannag R Sanketi and Grecia Salazar and Michael S Ryoo and Krista Reymann and Kanishka Rao and Karl Pertsch and Igor Mordatch and Henryk Michalewski and Yao Lu and Sergey Levine and Lisa Lee and Tsang-Wei Edward Lee and Isabel Leal and Yuheng Kuang and Dmitry Kalashnikov and Ryan Julian and Nikhil J Joshi and Alex Irpan and Brian Ichter and Jasmine Hsu and Alexander Herzog and Karol Hausman and Keerthana Gopalakrishnan and Chuyuan Fu and Pete Florence and Chelsea Finn and Kumar Avinava Dubey and Danny Driess and Tianli Ding and Krzysztof Marcin Choromanski and Xi Chen and Yevgen Chebotar and Justice Carbajal and Noah Brown and Anthony Brohan and Montserrat Gonzalez Arenas and Kehang Han"
      }
    ],
    "62e5CygAAAAJ": [
      {
        "title": "Getting aligned on representational alignment",
        "abstract": "Biological and artificial information processing systems form representations that they can use to categorize, reason, plan, navigate, and make decisions. How can we measure the extent to which the representations formed by these diverse systems agree? Do similarities in representations then translate into similar behavior? How can a system's representations be modified to better match those of another system? These questions pertaining to the study of representational alignment are at the heart of some of the most active research areas in cognitive science, neuroscience, and machine learning. For example, cognitive scientists measure the representational alignment of multiple individuals to identify shared cognitive priors, neuroscientists align fMRI responses from multiple individuals into a shared representational space for group-level analyses, and ML researchers distill knowledge from teacher models into student models by increasing their alignment. Unfortunately, there is limited knowledge transfer between research communities interested in representational alignment, so progress in one field often ends up being rediscovered independently in another. Thus, greater cross-field communication would be advantageous. To improve communication between these fields, we propose a unifying framework that can serve as a common language between researchers studying representational alignment. We survey the literature from all three fields and demonstrate how prior work fits into this framework. Finally, we lay out open problems in representational alignment where progress can benefit all three of these fields. We hope that our work …",
        "year": 2023,
        "authors": "Ilia Sucholutsky and Lukas Muttenthaler and Adrian Weller and Andi Peng and Andreea Bobu and Been Kim and Bradley C Love and Erin Grant and Iris Groen and Jascha Achterberg and Joshua B Tenenbaum and Katherine M Collins and Katherine L Hermann and Kerem Oktar and Klaus Greff and Martin N Hebart and Nori Jacoby and Qiuyi Zhang and Raja Marjieh and Robert Geirhos and Sherol Chen and Simon Kornblith and Sunayana Rane and Talia Konkle and Thomas P O'Connell and Thomas Unterthiner and Andrew K Lampinen and Klaus-Robert Müller and Mariya Toneva and Thomas L Griffiths"
      },
      {
        "title": "Adapting to continuously shifting domains",
        "abstract": "Domain adaptation typically focuses on adapting a model from a single source domain to a target domain. However, in practice, this paradigm of adapting from one source to one target is limiting, as different aspects of the real world such as illumination and weather conditions vary continuously and cannot be effectively captured by two static domains. Approaches that attempt to tackle this problem by adapting from a single source to many different target domains simultaneously are consistently unable to learn across all domain shifts. Instead, we propose an adaptation method that exploits the continuity between gradually varying domains by adapting in sequence from the source to the most similar target domain. By incrementally adapting while simultaneously efficiently regularizing against prior examples, we obtain a single strong model capable of recognition within all observed domains.",
        "year": 2018,
        "authors": "Andreea Bobu and Eric Tzeng and Judy Hoffman and Trevor Darrell"
      },
      {
        "title": "Less is more: Rethinking probabilistic models of human behavior",
        "abstract": "Robots need models of human behavior for both inferring human goals and preferences, and predicting what people will do. A common model is the Boltzmann noisily-rational decision model, which assumes people approximately optimize a reward function and choose trajectories in proportion to their exponentiated reward. While this model has been successful in a variety of robotics domains, its roots lie in econometrics, and in modeling decisions among different discrete options, each with its own utility or reward. In contrast, human trajectories lie in a continuous space, with continuous-valued features that influence the reward function. We propose that it is time to rethink the Boltzmann model, and design it from the ground up to operate over such trajectory spaces. We introduce a model that explicitly accounts for distances between trajectories, rather than only their rewards. Rather than each trajectory affecting …",
        "year": 2020,
        "authors": "Andreea Bobu and Dexter RR Scobee and Jaime F Fisac and S Shankar Sastry and Anca D Dragan"
      }
    ],
    "NOoKltoAAAAJ": [
      {
        "title": "CHOMP: Gradient optimization techniques for efficient motion planning",
        "abstract": "Existing high-dimensional motion planning algorithms are simultaneously overpowered and underpowered. In domains sparsely populated by obstacles, the heuristics used by sampling-based planners to navigate “narrow passages” can be needlessly complex; furthermore, additional post-processing is required to remove the jerky or extraneous motions from the paths that such planners generate. In this paper, we present CHOMP, a novel method for continuous path refinement that uses covariant gradient techniques to improve the quality of sampled trajectories. Our optimization technique both optimizes higher-order dynamics and is able to converge over a wider range of input paths relative to previous path optimization strategies. In particular, we relax the collision-free feasibility prerequisite on input paths required by those strategies. As a result, CHOMP can be used as a standalone motion planner in many …",
        "year": 2009,
        "authors": "Nathan Ratliff and Matt Zucker and J Andrew Bagnell and Siddhartha Srinivasa"
      },
      {
        "title": "CHOMP: Covariant hamiltonian optimization for motion planning",
        "abstract": "In this paper, we present CHOMP (covariant Hamiltonian optimization for motion planning), a method for trajectory optimization invariant to reparametrization. CHOMP uses functional gradient techniques to iteratively improve the quality of an initial trajectory, optimizing a functional that trades off between a smoothness and an obstacle avoidance component. CHOMP can be used to locally optimize feasible trajectories, as well as to solve motion planning queries, converging to low-cost trajectories even when initialized with infeasible ones. It uses Hamiltonian Monte Carlo to alleviate the problem of convergence to high-cost local minima (and for probabilistic completeness), and is capable of respecting hard constraints along the trajectory. We present extensive experiments with CHOMP on manipulation and locomotion tasks, using seven-degree-of-freedom manipulators and a rough-terrain quadruped robot.",
        "year": 2013,
        "authors": "Matt Zucker and Nathan Ratliff and Anca D Dragan and Mihail Pivtoraiko and Matthew Klingensmith and Christopher M Dellin and J Andrew Bagnell and Siddhartha S Srinivasa"
      }
    ],
    "L-diWvQAAAAJ": [
      {
        "title": "Discovery and refinement of loci associated with lipid levels",
        "abstract": "Levels of low-density lipoprotein (LDL) cholesterol, high-density lipoprotein (HDL) cholesterol, triglycerides and total cholesterol are heritable, modifiable risk factors for coronary artery disease. To identify new loci and refine known loci influencing these lipids, we examined 188,577 individuals using genome-wide and custom genotyping arrays. We identify and annotate 157 loci associated with lipid levels at P < 5 × 10−8, including 62 loci not previously associated with lipid levels in humans. Using dense genotyping in individuals of European, East Asian, South Asian and African ancestry, we narrow association signals in 12 loci. We find that loci associated with blood lipid levels are often associated with cardiovascular and metabolic traits, including coronary artery disease, type 2 diabetes, blood pressure, waist-hip ratio and body mass index. Our results demonstrate the value of using genetic data from individuals …",
        "year": 2013,
        "authors": []
      },
      {
        "title": "Common variants associated with plasma triglycerides and risk for coronary artery disease",
        "abstract": "Triglycerides are transported in plasma by specific triglyceride-rich lipoproteins; in epidemiological studies, increased triglyceride levels correlate with higher risk for coronary artery disease (CAD). However, it is unclear whether this association reflects causal processes. We used 185 common variants recently mapped for plasma lipids (P < 5 × 10−8 for each) to examine the role of triglycerides in risk for CAD. First, we highlight loci associated with both low-density lipoprotein cholesterol (LDL-C) and triglyceride levels, and we show that the direction and magnitude of the associations with both traits are factors in determining CAD risk. Second, we consider loci with only a strong association with triglycerides and show that these loci are also associated with CAD. Finally, in a model accounting for effects on LDL-C and/or high-density lipoprotein cholesterol (HDL-C) levels, the strength of a polymorphism's effect on …",
        "year": 2013,
        "authors": "Ron Do and Cristen J Willer and Ellen M Schmidt and Sebanti Sengupta and Chi Gao and Gina M Peloso and Stefan Gustafsson and Stavroula Kanoni and Andrea Ganna and Jin Chen and Martin L Buchkovich and Samia Mora and Jacques S Beckmann and Jennifer L Bragg-Gresham and Hsing-Yi Chang and Ayşe Demirkan and Heleen M Den Hertog and Louise A Donnelly and Georg B Ehret and Tõnu Esko and Mary F Feitosa and Teresa Ferreira and Krista Fischer and Pierre Fontanillas and Ross M Fraser and Daniel F Freitag and Deepti Gurdasani and Kauko Heikkilä and Elina Hyppönen and Aaron Isaacs and Anne U Jackson and Åsa Johansson and Toby Johnson and Marika Kaakinen and Johannes Kettunen and Marcus E Kleber and Xiaohui Li and Jian'an Luan and Leo-Pekka Lyytikäinen and Patrik KE Magnusson and Massimo Mangino and Evelin Mihailov and May E Montasser and Martina Müller-Nurasyid and Ilja M Nolte and Jeffrey R O'Connell and Cameron D Palmer and Markus Perola and Ann-Kristin Petersen and Serena Sanna and Richa Saxena and Susan K Service and Sonia Shah and Dmitry Shungin and Carlo Sidore and Ci Song and Rona J Strawbridge and Ida Surakka and Toshiko Tanaka and Tanya M Teslovich and Gudmar Thorleifsson and Evita G Van den Herik and Benjamin F Voight and Kelly A Volcik and Lindsay L Waite and Andrew Wong and Ying Wu and Weihua Zhang and Devin Absher and Gershim Asiki and Inês Barroso and Latonya F Been and Jennifer L Bolton and Lori L Bonnycastle and Paolo Brambilla and Mary S Burnett and Giancarlo Cesana and Maria Dimitriou and Alex SF Doney and Angela Doering and Paul Elliott and Stephen E Epstein and Gudmundur Ingi Eyjolfsson and Bruna Gigante and Mark O Goodarzi and Harald Grallert and Martha L Gravito and Christopher J Groves and Göran Hallmans and Anna-Liisa Hartikainen and Caroline Hayward and Dena Hernandez and Andrew A Hicks and Hilma Holm and Yi-Jen Hung and Thomas Illig and Michelle R Jones and Pontiano Kaleebu and John JP Kastelein and Kay-Tee Khaw and Eric Kim and Norman Klopp and Pirjo Komulainen and Meena Kumari and Claudia Langenberg and Terho Lehtimäki and Shih-Yi Lin and Jaana Lindström and Ruth JF Loos and François Mach and Wendy L McArdle and Christa Meisinger and Braxton D Mitchell and Gabrielle Müller and Ramaiah Nagaraja and Narisu Narisu and Tuomo VM Nieminen and Rebecca N Nsubuga and Isleifur Olafsson and Ken K Ong and Aarno Palotie and Theodore Papamarkou and Cristina Pomilla and Anneli Pouta and Daniel J Rader and Muredach P Reilly and Paul M Ridker and Fernando Rivadeneira and Igor Rudan and Aimo Ruokonen and Nilesh Samani and Hubert Scharnagl and Janet Seeley and Kaisa Silander and Alena Stančáková and Kathleen Stirrups and Amy J Swift and Laurence Tiret and Andre G Uitterlinden and L Joost van Pelt and Sailaja Vedantam and Nicholas Wainwright and Cisca Wijmenga and Sarah H Wild and Gonneke Willemsen and Tom Wilsgaard and James F Wilson and Elizabeth H Young and Jing Hua Zhao and Linda S Adair"
      },
      {
        "title": "The African genome variation project shapes medical genetics in Africa",
        "abstract": "Given the importance of Africa to studies of human origins and disease susceptibility, detailed characterization of African genetic diversity is needed. The African Genome Variation Project provides a resource with which to design, implement and interpret genomic studies in sub-Saharan Africa and worldwide. The African Genome Variation Project represents dense genotypes from 1,481 individuals and whole-genome sequences from 320 individuals across sub-Saharan Africa. Using this resource, we find novel evidence of complex, regionally distinct hunter-gatherer and Eurasian admixture across sub-Saharan Africa. We identify new loci under selection, including loci related to malaria susceptibility and hypertension. We show that modern imputation panels (sets of reference genotypes from which unobserved or missing genotypes in study sets can be inferred) can identify association signals at highly …",
        "year": 2015,
        "authors": "Deepti Gurdasani and Tommy Carstensen and Fasil Tekola-Ayele and Luca Pagani and Ioanna Tachmazidou and Konstantinos Hatzikotoulas and Savita Karthikeyan and Louise Iles and Martin O Pollard and Ananyo Choudhury and Graham RS Ritchie and Yali Xue and Jennifer Asimit and Rebecca N Nsubuga and Elizabeth H Young and Cristina Pomilla and Katja Kivinen and Kirk Rockett and Anatoli Kamali and Ayo P Doumatey and Gershim Asiki and Janet Seeley and Fatoumatta Sisay-Joof and Muminatou Jallow and Stephen Tollman and Ephrem Mekonnen and Rosemary Ekong and Tamiru Oljira and Neil Bradman and Kalifa Bojang and Michele Ramsay and Adebowale Adeyemo and Endashaw Bekele and Ayesha Motala and Shane A Norris and Fraser Pirie and Pontiano Kaleebu and Dominic Kwiatkowski and Chris Tyler-Smith and Charles Rotimi and Eleftheria Zeggini and Manjinder S Sandhu"
      }
    ],
    "YNoe5GAAAAAJ": [
      {
        "title": "Germline mutations affecting the proofreading domains of POLE and POLD1 predispose to colorectal adenomas and carcinomas",
        "abstract": "Many individuals with multiple or large colorectal adenomas or early-onset colorectal cancer (CRC) have no detectable germline mutations in the known cancer predisposition genes. Using whole-genome sequencing, supplemented by linkage and association analysis, we identified specific heterozygous POLE or POLD1 germline variants in several multiple-adenoma and/or CRC cases but in no controls. The variants associated with susceptibility, POLE p.Leu424Val and POLD1 p.Ser478Asn, have high penetrance, and POLD1 mutation was also associated with endometrial cancer predisposition. The mutations map to equivalent sites in the proofreading (exonuclease) domain of DNA polymerases ɛ and δ and are predicted to cause a defect in the correction of mispaired bases inserted during DNA replication. In agreement with this prediction, the tumors from mutation carriers were microsatellite stable but tended …",
        "year": 2013,
        "authors": "Claire Palles and Jean-Baptiste Cazier and Kimberley M Howarth and Enric Domingo and Angela M Jones and Peter Broderick and Zoe Kemp and Sarah L Spain and Estrella Guarino and Israel Salguero and Amy Sherborne and Daniel Chubb and Luis G Carvajal-Carmona and Yusanne Ma and Kulvinder Kaur and Sara Dobbins and Ella Barclay and Maggie Gorman and Lynn Martin and Michal B Kovac and Sean Humphray and WGS500 Consortium Steering Committee: Donnelly Peter (Chair) 2 10 Bell John 38 Bentley David 7 McVean Gilean 2 Ratcliffe Peter 39 Taylor Jenny 5 Wilkie Andrew 5 40 and Operations Committee: Donnelly Peter (Chair) 2 10 Broxholme John 2 Buck David 2 Cazier Jean-Baptiste 2 Cornall Richard 39 Gregory Lorna 2 Knight Julian 41 Lunter Gerton 2 McVean Gilean 2 Taylor Jenny 5 Tomlinson Ian 1 5 Wilkie Andrew 5 40 and Sequencing & Experimental Follow-up: Buck David (Lead) 2 Gregory Lorna 2 Humphray Sean 7 Kingsbury Zoya 7 and Data Analysis: McVean Gilean (Lead) 2 Donnelly Peter 2 10 Cazier Jean-Baptiste 2 Broxholme John 2 Grocock Russell 7 Hatton Edouard 2 Holmes Christopher C 2 10 Hughes Linda 2 Humburg Peter 2 Kanapin Alexander 2 Lunter Gerton 2 Murray Lisa 7 Rimmer Andy 2"
      },
      {
        "title": "Meta-analysis identifies 13 new loci associated with waist-hip ratio and reveals sexual dimorphism in the genetic basis of fat distribution",
        "abstract": "Waist-hip ratio (WHR) is a measure of body fat distribution and a predictor of metabolic consequences independent of overall adiposity. WHR is heritable, but few genetic variants influencing this trait have been identified. We conducted a meta-analysis of 32 genome-wide association studies for WHR adjusted for body mass index (comprising up to 77,167 participants), following up 16 loci in an additional 29 studies (comprising up to 113,636 subjects). We identified 13 new loci in or near RSPO3, VEGFA, TBX15-WARS2, NFE2L3, GRB14, DNM3-PIGC, ITPR2-SSPN, LY86, HOXC13, ADAMTS9, ZNRF3-KREMEN1, NISCH-STAB1 and CPEB4 (P = 1.9 × 10−9 to P = 1.8 × 10−40) and the known signal at LYPLAL1. Seven of these loci exhibited marked sexual dimorphism, all with a stronger effect on WHR in women than men (P for sex difference = 1.9 × 10−3 to P = 1.2 × 10−13). These findings provide evidence for …",
        "year": 2010,
        "authors": "Iris M Heid and Anne U Jackson and Joshua C Randall and Thomas W Winkler and Lu Qi and Valgerdur Steinthorsdottir and Gudmar Thorleifsson and M Carola Zillikens and Elizabeth K Speliotes and Reedik Mägi and Tsegaselassie Workalemahu and Charles C White and Nabila Bouatia-Naji and Tamara B Harris and Sonja I Berndt and Erik Ingelsson and Cristen J Willer and Michael N Weedon and Jian'an Luan and Sailaja Vedantam and Tonu Esko and Tuomas O Kilpelaeinen and Zoltan Kutalik and Shengxu Li and Keri L Monda and Anna L Dixon and Christopher C Holmes and Lee M Kaplan and Liming Liang and Josine L Min and Miriam F Moffatt and Cliona Molony and George Nicholson and Eric E Schadt and Krina T Zondervan and Mary F Feitosa and Teresa Ferreira and Hana Lango Allen and Robert J Weyant and Eleanor Wheeler and Andrew R Wood and Magic and Karol Estrada and Michael E Goddard and Guillaume Lettre and Massimo Mangino and Dale R Nyholt and Shaun Purcell and Albert Vernon Smith and Peter M Visscher and Jian Yang and Steven A McCarroll and James Nemesh and Benjamin F Voight and Devin Absher and Najaf Amin and Thor Aspelund and Lachlan Coin and Nicole L Glazer and Caroline Hayward and Nancy L Heard-Costa and Jouke-Jan Hottenga and Åsa Johansson and Toby Johnson and Marika Kaakinen and Karen Kapur and Shamika Ketkar and Joshua W Knowles and Peter Kraft and Aldi T Kraja and Claudia Lamina and Michael F Leitzmann and Barbara McKnight and Andrew P Morris and Ken K Ong and John RB Perry and Marjolein J Peters and Ozren Polasek and Inga Prokopenko and Nigel W Rayner and Samuli Ripatti and Fernando Rivadeneira and Neil R Robertson and Serena Sanna and Ulla Sovio and Ida Surakka and Alexander Teumer and Sophie van Wingerden and Veronique Vitart and Jing Hua Zhao and Christine Cavalcanti-Proença and Peter S Chines and Eva Fisher and Jennifer R Kulzer and Cecile Lecoeur and Narisu Narisu and Camilla Sandholt and Laura J Scott and Kaisa Silander and Klaus Stark and Mari-Liis Tammesoo and Tanya M Teslovich and Nicholas John Timpson and Richard M Watanabe and Ryan Welch and Daniel I Chasman and Matthew N Cooper and John-Olov Jansson and Johannes Kettunen and Robert W Lawrence and Niina Pellikka and Markus Perola and Liesbeth Vandenput and Helene Alavere and Peter Almgren and Larry D Atwood and Amanda J Bennett and Reiner Biffar and Lori L Bonnycastle and Stefan R Bornstein and Thomas A Buchanan and Harry Campbell and Ian NM Day and Mariano Dei and Marcus Dörr and Paul Elliott and Michael R Erdos and Johan G Eriksson and Nelson B Freimer and Mao Fu and Stefan Gaget and Eco JC Geus and Anette P Gjesing and Harald Grallert and Jürgen Gräßler and Christopher J Groves and Candace Guiducci and Anna-Liisa Hartikainen and Neelam Hassanali and Aki S Havulinna and Karl-Heinz Herzig and Andrew A Hicks and Jennie Hui and Wilmar Igl and Pekka Jousilahti and Antti Jula and Eero Kajantie and Leena Kinnunen and Ivana Kolcic and Seppo Koskinen"
      },
      {
        "title": "Reporting guidelines for clinical trial reports for interventions involving artificial intelligence: the CONSORT-AI extension",
        "abstract": "The CONSORT 2010 statement provides minimum guidelines for reporting randomised trials. Its widespread use has been instrumental in ensuring transparency in the evaluation of new interventions. More recently, there has been a growing recognition that interventions involving artificial intelligence (AI) need to undergo rigorous, prospective evaluation to demonstrate impact on health outcomes. The CONSORT-AI (Consolidated Standards of Reporting Trials-Artificial Intelligence) extension is a new reporting guideline for clinical trials evaluating interventions with an AI component. It was developed in parallel with its companion statement for clinical trial protocols: SPIRIT-AI (Standard Protocol Items: Recommendations for Interventional Trials-Artificial Intelligence). Both guidelines were developed through a staged consensus process involving literature review and expert consultation to generate 29 candidate …",
        "year": 2020,
        "authors": "Xiaoxuan Liu and Samantha Cruz Rivera and David Moher and Melanie J Calvert and Alastair K Denniston and Hutan Ashrafian and Andrew L Beam and An-Wen Chan and Gary S Collins and Ara DarziJonathan J Deeks and M Khair ElZarrad and Cyrus Espinoza and Andre Esteva and Livia Faes and Lavinia Ferrante di Ruffano and John Fletcher and Robert Golub and Hugh Harvey and Charlotte Haug and Christopher Holmes and Adrian Jonas and Pearse A Keane and Christopher J Kelly and Aaron Y Lee and Cecilia S Lee and Elaine Manna and James Matcham and Melissa McCradden and Joao Monteiro and Cynthia Mulrow and Luke Oakden-Rayner and Dina Paltoo and Maria Beatrice Panico and Gary Price and Samuel Rowley and Richard Savage and Rupa Sarkar and Sebastian J Vollmer and Christopher Yau"
      }
    ],
    "ajIYB6wAAAAJ": [
      {
        "title": "Adversarial learning",
        "abstract": "Many classification tasks, such as spam filtering, intrusion detection, and terrorism detection, are complicated by an adversary who wishes to avoid detection. Previous work on adversarial classification has made the unrealistic assumption that the attacker has perfect knowledge of the classifier [2]. In this paper, we introduce the adversarial classifier reverse engineering (ACRE) learning problem, the task of learning sufficient information about a classifier to construct adversarial attacks. We present efficient algorithms for reverse engineering linear classifiers with either continuous or Boolean features and demonstrate their effectiveness using real data from the domain of spam filtering.",
        "year": 2005,
        "authors": "Daniel Lowd and Christopher Meek"
      },
      {
        "title": "Wikiqa: A challenge dataset for open-domain question answering",
        "abstract": "We describe the WIKIQA dataset, a new publicly available set of question and sentence pairs, collected and annotated for research on open-domain question answering. Most previous work on answer sentence selection focuses on a dataset created using the TREC-QA data, which includes editor-generated questions and candidate answer sentences selected by matching content words in the question. WIKIQA is constructed using a more natural process and is more than an order of magnitude larger than the previous dataset. In addition, the WIKIQA dataset also includes questions for which there are no correct sentences, enabling researchers to work on answer triggering, a critical component in any QA system. We compare several systems on the task of answer sentence selection on both datasets and also describe the performance of a system on the problem of answer triggering using the WIKIQA dataset.",
        "year": 2015,
        "authors": "Yi Yang and Wen-tau Yih and Christopher Meek"
      },
      {
        "title": "Large-sample learning of Bayesian networks is NP-hard",
        "abstract": "In this paper, we provide new complexity results for algorithms that learn discrete-variable Bayesian networks from data. Our results apply whenever the learning algorithm uses a scoring criterion that favors the simplest structure for which the model is able to represent the generative distribution exactly. Our results therefore hold whenever the learning algorithm uses a consistent scoring criterion and is applied to a sufficiently large dataset. We show that identifying high-scoring structures is NP-hard, even when any combination of one or more of the following hold: the generative distribution is perfect with respect to some DAG containing hidden variables; we are given an independence oracle; we are given an inference oracle; we are given an information oracle; we restrict potential solutions to structures in which each node has at most k parents, for all k>= 3.",
        "year": 2004,
        "authors": "David Maxwell Chickering and David Heckerman and Christopher Meek"
      }
    ],
    "QxbpIMUAAAAJ": [
      {
        "title": "Spatial pricing in ride-sharing networks",
        "abstract": "We explore spatial price discrimination in the context of a ride-sharing platform that serves a network of locations. Riders are heterogeneous in terms of their destination preferences and their willingness to pay for receiving service. Drivers decide whether and where to provide service so as to maximize their expected earnings given the platform’s pricing and compensation policy. Our findings highlight the impact of the demand pattern on the platform’s prices, profits, and the induced consumer surplus. In particular, we establish that profits and consumer surplus at the equilibrium corresponding to the platform’s optimal pricing and compensation policy are maximized when the demand pattern is “balanced” across the network’s locations. In addition, we show that they both increase monotonically with the balancedness of the demand pattern (as formalized by its structural properties). Furthermore, if the demand pattern …",
        "year": 2019,
        "authors": "Kostas Bimpikis and Ozan Candogan and Daniela Saban"
      },
      {
        "title": "Optimal pricing in networks with externalities",
        "abstract": " We study the optimal pricing strategies of a monopolist selling a divisible good (service) to consumers who are embedded in a social network. A key feature of our model is that consumers experience a (positive) local network effect. In particular, each consumer's usage level depends directly on the usage of her neighbors in the social network structure. Thus, the monopolist's optimal pricing strategy may involve offering discounts to certain agents who have a central position in the underlying network. Our results can be summarized as follows. First, we consider a setting where the monopolist can offer individualized prices and derive a characterization of the optimal price for each consumer as a function of her network position. In particular, we show that it is optimal for the monopolist to charge each agent a price that consists of three components: (i) a nominal term that is independent of the network structure, (ii) a …",
        "year": 2012,
        "authors": "Ozan Candogan and Kostas Bimpikis and Asuman Ozdaglar"
      },
      {
        "title": "Flows and decompositions of games: Harmonic and potential games",
        "abstract": "In this paper we introduce a novel flow representation for finite games in strategic form. This representation allows us to develop a canonical direct sum decomposition of an arbitrary game into three components, which we refer to as the potential, harmonic, and nonstrategic components. We analyze natural classes of games that are induced by this decomposition, and in particular, focus on games with no harmonic component and games with no potential component. We show that the first class corresponds to the well-known potential games. We refer to the second class of games as harmonic games, and demonstrate that this new class has interesting properties which contrast with properties of potential games. Exploiting the decomposition framework, we obtain explicit expressions for the projections of games onto the subspaces of potential and harmonic games. This enables an extension of the equilibrium …",
        "year": 2011,
        "authors": "Ozan Candogan and Ishai Menache and Asuman Ozdaglar and Pablo A Parrilo"
      }
    ],
    "DZ3S--MAAAAJ": [
      {
        "title": "Gain: Missing data imputation using generative adversarial nets",
        "abstract": "We propose a novel method for imputing missing data by adapting the well-known Generative Adversarial Nets (GAN) framework. Accordingly, we call our method Generative Adversarial Imputation Nets (GAIN). The generator (G) observes some components of a real data vector, imputes the missing components conditioned on what is actually observed, and outputs a completed vector. The discriminator (D) then takes a completed vector and attempts to determine which components were actually observed and which were imputed. To ensure that D forces G to learn the desired distribution, we provide D with some additional information in the form of a hint vector. The hint reveals to D partial information about the missingness of the original sample, which is used by D to focus its attention on the imputation quality of particular components. This hint ensures that G does in fact learn to generate according to the true data distribution. We tested our method on various datasets and found that GAIN significantly outperforms state-of-the-art imputation methods.",
        "year": 2018,
        "authors": "Jinsung Yoon and James Jordon and Mihaela Schaar"
      },
      {
        "title": "Time-series generative adversarial networks",
        "abstract": "A good generative model for time-series data should preserve temporal dynamics, in the sense that new sequences respect the original relationships between variables across time. Existing methods that bring generative adversarial networks (GANs) into the sequential setting do not adequately attend to the temporal correlations unique to time-series data. At the same time, supervised models for sequence prediction-which allow finer control over network dynamics-are inherently deterministic. We propose a novel framework for generating realistic time-series data that combines the flexibility of the unsupervised paradigm with the control afforded by supervised training. Through a learned embedding space jointly optimized with both supervised and adversarial objectives, we encourage the network to adhere to the dynamics of the training data during sampling. Empirically, we evaluate the ability of our method to generate realistic samples using a variety of real and synthetic time-series datasets. Qualitatively and quantitatively, we find that the proposed framework consistently and significantly outperforms state-of-the-art benchmarks with respect to measures of similarity and predictive ability.",
        "year": 2019,
        "authors": "Jinsung Yoon and Daniel Jarrett and Mihaela Van der Schaar"
      },
      {
        "title": "PATE-GAN: Generating synthetic data with differential privacy guarantees",
        "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.",
        "year": 2018,
        "authors": "James Jordon and Jinsung Yoon and Mihaela Van Der Schaar"
      }
    ],
    "FyQAwaEAAAAJ": [
      {
        "title": "Zero-Shot Visual Imitation",
        "abstract": "The current dominant paradigm for imitation learning relies on strong supervision of expert actions to learn both'what'and'how'to imitate. We pursue an alternative paradigm wherein an agent first explores the world without any expert supervision and then distills its experience into a goal-conditioned skill policy with a novel forward consistency loss. In our framework, the role of the expert is only to communicate the goals (ie, what to imitate) during inference. The learned policy is then employed to mimic the expert (ie, how to imitate) after seeing just a sequence of images demonstrating the desired task. Our method is' zero-shot'in the sense that the agent never has access to expert actions during training or for the task demonstration at inference. We evaluate our zero-shot imitator in two real-world settings: complex rope manipulation with a Baxter robot and navigation in previously unseen office environments with a TurtleBot. Through further experiments in VizDoom simulation, we provide evidence that better mechanisms for exploration lead to learning a more capable policy which in turn improves end task performance. Videos, models, and more details are available at https://pathak22. github. io/zeroshot-imitation/",
        "year": 2018,
        "authors": "Deepak Pathak* and Parsa Mahmoudieh* and Guanghao Luo* and Pulkit Agrawal* and Dian Chen and Yide Shentu and Evan Shelhamer and Jitendra Malik and Alexei Efros"
      },
      {
        "title": "Loss is its own reward: Self-supervision for reinforcement learning",
        "abstract": "Reinforcement learning optimizes policies for expected cumulative reward. Need the supervision be so narrow? Reward is delayed and sparse for many tasks, making it a difficult and impoverished signal for end-to-end optimization. To augment reward, we consider a range of self-supervised tasks that incorporate states, actions, and successors to provide auxiliary losses. These losses offer ubiquitous and instantaneous supervision for representation learning even in the absence of reward. While current results show that learning from reward alone is feasible, pure reinforcement learning methods are constrained by computational and data efficiency issues that can be remedied by auxiliary losses. Self-supervised pre-training and joint optimization improve the data efficiency and policy returns of end-to-end reinforcement learning.",
        "year": 2016,
        "authors": "Evan Shelhamer and Parsa Mahmoudieh and Max Argus and Trevor Darrell"
      },
      {
        "title": "Zero-shot reward specification via grounded natural language",
        "abstract": "Reward signals in reinforcement learning are expensive to design and often require access to the true state which is not available in the real world. Common alternatives are usually demonstrations or goal images which can be labor-intensive to collect. On the other hand, text descriptions provide a general, natural, and low-effort way of communicating the desired task. However, prior works in learning text-conditioned policies still rely on rewards that are defined using either true state or labeled expert demonstrations. We use recent developments in building large-scale visuolanguage models like CLIP to devise a framework that generates the task reward signal just from goal text description and raw pixel observations which is then used to learn the task policy. We evaluate the proposed framework on control and robotic manipulation tasks. Finally, we distill the individual task policies into a single goal text conditioned policy that can generalize in a zero-shot manner to new tasks with unseen objects and unseen goal text descriptions.",
        "year": 2022,
        "authors": "Parsa Mahmoudieh and Deepak Pathak and Trevor Darrell"
      }
    ],
    "-QopmQoAAAAJ": [
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien MR Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan"
      },
      {
        "title": "Training language models to self-correct via reinforcement learning",
        "abstract": "Self-correction is a highly desirable capability of large language models (LLMs), yet it has consistently been found to be largely ineffective in modern LLMs. Current methods for training self-correction typically depend on either multiple models, a more advanced model, or additional forms of supervision. To address these shortcomings, we develop a multi-turn online reinforcement learning (RL) approach, SCoRe, that significantly improves an LLM's self-correction ability using entirely self-generated data. To build SCoRe, we first show that variants of supervised fine-tuning (SFT) on offline model-generated correction traces are often insufficient for instilling self-correction behavior. In particular, we observe that training via SFT falls prey to either a distribution mismatch between mistakes made by the data-collection policy and the model's own responses, or to behavior collapse, where learning implicitly prefers only a certain mode of correction behavior that is often not effective at self-correction on test problems. SCoRe addresses these challenges by training under the model's own distribution of self-generated correction traces and using appropriate regularization to steer the learning process into learning a self-correction behavior that is effective at test time as opposed to fitting high-reward responses for a given prompt. This regularization process includes an initial phase of multi-turn RL on a base model to generate a policy initialization that is less susceptible to collapse, followed by using a reward bonus to amplify self-correction. With Gemini 1.0 Pro and 1.5 Flash models, we find that SCoRe achieves state-of-the-art self-correction performance …",
        "year": 2024,
        "authors": "Aviral Kumar and Vincent Zhuang and Rishabh Agarwal and Yi Su and John D Co-Reyes and Avi Singh and Kate Baumli and Shariq Iqbal and Colton Bishop and Rebecca Roelofs and Lei M Zhang and Kay McKinney and Disha Shrivastava and Cosmin Paduraru and George Tucker and Doina Precup and Feryal Behbahani and Aleksandra Faust"
      },
      {
        "title": "Offline rl for natural language generation with implicit language q learning",
        "abstract": "Large language models distill broad knowledge from text corpora. However, they can be inconsistent when it comes to completing user specified tasks. This issue can be addressed by finetuning such models via supervised learning on curated datasets, or via reinforcement learning. In this work, we propose a novel offline RL method, implicit language Q-learning (ILQL), designed for use on language models, that combines both the flexible utility maximization framework of RL algorithms with the ability of supervised learning to leverage previously collected data, as well as its simplicity and stability. Our method employs a combination of value conservatism alongside an implicit dataset support constraint in learning value functions, which are then used to guide language model generations towards maximizing user-specified utility functions. In addition to empirically validating ILQL, we present a detailed empirical analysis of situations where offline RL can be useful in natural language generation settings, demonstrating how it can be a more effective utility optimizer than prior approaches for end-to-end dialogue, and how it can effectively optimize high variance reward functions based on subjective judgement, such as whether to label a comment as toxic or not.",
        "year": 2022,
        "authors": "Charlie Snell and Ilya Kostrikov and Yi Su and Mengjiao Yang and Sergey Levine"
      }
    ],
    "MSCQE-YAAAAJ": [
      {
        "title": "iLOCuS: Incentivizing vehicle mobility to optimize sensing distribution in crowd sensing",
        "abstract": "Vehicular crowd sensing systems are designed to achieve large spatio-temporal sensing coverage with low-cost in deployment and maintenance. For example, taxi platforms can be utilized for sensing city-wide air quality. However, the goals of vehicle agents are often inconsistent with the goal of the crowdsourcer. Vehicle agents like taxis prioritize searching for passenger ride requests (defined as task requests), which leads them to gather in busy regions. In contrast, sensing systems often need to sample data over the entire city with a desired distribution (e.g., Uniform distribution, Gaussian Mixture distribution, etc.) to ensure sufficient spatio-temporal information for further analysis. This inconsistency decreases the sensing coverage quality and thus impairs the quality of the collected information. A simple approach to reduce the inconsistency is to greedily incentivize the vehicle agents to different regions …",
        "year": 2019,
        "authors": "Susu Xu and Xinlei Chen and Xidong Pi and Carlee Joe-Wong and Pei Zhang and Hae Young Noh"
      },
      {
        "title": "PAS: Prediction-based actuation system for city-scale ridesharing vehicular mobile crowdsensing",
        "abstract": "Vehicular mobile crowdsensing (MCS) enables many smart city applications. Ridesharing vehicle fleets provide promising solutions to MCS due to the advantages of low cost, easy maintenance, high mobility, and long operational time. However, as nondedicated mobile sensing platforms, the first priorities of these vehicles are delivering passengers, which may lead to poor sensing coverage quality. Therefore, to help MCS derive good (large and balanced) sensing coverage quality, an actuation system is required to dispatch vehicles with a limited amount of monetary budget. This article presents PAS, a prediction-based actuation system for city-wide ridesharing vehicular MCS to achieve optimal sensing coverage quality with a limited budget. In PAS, two prediction models forecast probabilities of potential near-future vehicle routes and ride requests across the city. Based on prediction results, a prediction-based …",
        "year": 2020,
        "authors": "Xinlei Chen and Susu Xu and Jun Han and Haohao Fu and Xidong Pi and Carlee Joe-Wong and Yong Li and Lin Zhang and Hae Young Noh and Pei Zhang"
      },
      {
        "title": "ASC: Actuation system for city-wide crowdsensing with ride-sharing vehicular platform",
        "abstract": "Vehicular mobile crowdsensing (MCS) enables a lot of smart city applications, such as smart transportation, environmental monitoring etc. Taxis provide a good platform for MCS due to their long operational time and city-scale coverage. However, taxis, as a non-dedicated sensing platform, does not guarantee high sensing coverage quality (large and balanced). This paper presents ASC, a system that actuates vehicular taxis fleets for optimal sensing coverage quality while matching ride requests with taxis. We propose a near-optimal algorithm that integrates 1) a mobility prediction model that guides the selection of taxis to actuate and 2) a ride request prediction model to help match ride request with taxis, lower incentive cost and improve taxi drivers' motivation. Extensive simulation and real-world experiments in a testbed with 230 actuated taxis show that our ASC can achieve up to 40% improvement in sensing …",
        "year": 2019,
        "authors": "Xinlei Chen and Susu Xu and Haohao Fu and Carlee Joe-Wong and Lin Zhang and Hae Young Noh and Pei Zhang"
      }
    ],
    "vfPE6hgAAAAJ": [
      {
        "title": "Model-agnostic meta-learning for fast adaptation of deep networks",
        "abstract": "We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.",
        "year": 2017,
        "authors": "Chelsea Finn and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "On the opportunities and risks of foundation models",
        "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",
        "year": 2021,
        "authors": "Rishi Bommasani and Drew A Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher Ré and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W Thomas and Florian Tramèr and Rose E Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang"
      },
      {
        "title": "End-to-end training of deep visuomotor policies",
        "abstract": "For spline regressions, it is well known that the choice of knots is crucial for the performance of the estimator. As a general learning framework covering the smoothing splines, learning in a Reproducing Kernel Hilbert Space (RKHS) has a similar issue. However, the selection of training data points for kernel functions in the RKHS representation has not been carefully studied in the literature. In this paper we study quantile regression as an example of learning in a RKHS. In this case, the regular squared norm penalty does not perform training data selection. We propose a data sparsity constraint that imposes thresholding on the kernel function coefficients to achieve a sparse kernel function representation. We demonstrate that the proposed data sparsity method can have competitive prediction performance for certain situations, and have comparable performance in other cases compared to that of the traditional squared norm penalty. Therefore, the data sparsity method can serve as a competitive alternative to the squared norm penalty method. Some theoretical properties of our proposed method using the data sparsity constraint are obtained. Both simulated and real data sets are used to demonstrate the usefulness of our data sparsity constraint.",
        "year": 2016,
        "authors": "Sergey Levine and Chelsea Finn and Trevor Darrell and Pieter Abbeel"
      }
    ],
    "nfX25MMAAAAJ": [
      {
        "title": "Conformal Prediction: A Gentle Introduction",
        "abstract": "Black-box machine learning models are now routinely used in high-risk settings, like medical diagnostics, which demand uncertainty quantification to avoid consequential model failures. Conformal prediction (aka conformal inference) is a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models. Critically, the sets are valid in a distribution-free sense: they possess explicit, non-asymptotic guarantees even without distributional assumptions or model assumptions. One can use conformal prediction with any pre-trained model, such as a neural network, to produce sets that are guaranteed to contain the ground truth with a user-specified probability, such as 90%. It is easy-to-understand, easy-to-use, and general, applying naturally to problems arising in the fields of computer vision, natural language processing, deep reinforcement learning, and so on.",
        "year": 2023,
        "authors": "Anastasios N Angelopoulos and Stephen Bates"
      },
      {
        "title": "Chatbot arena: An open platform for evaluating LLMs by human preference",
        "abstract": "Large Language Models (LLMs) have unlocked new capabilities and applications; however, evaluating the alignment with human preferences still poses significant challenges. To address this issue, we introduce Chatbot Arena, an open platform for evaluating LLMs based on human preferences. Our methodology employs a pairwise comparison approach and leverages input from a diverse user base through crowdsourcing. The platform has been operational for several months, amassing over 240K votes. This paper describes the platform, analyzes the data we have collected so far, and explains the tried-and-true statistical methods we are using for efficient and accurate evaluation and ranking of models. We confirm that the crowdsourced questions are sufficiently diverse and discriminating and that the crowd-sourced human votes are in good agreement with those of expert raters. These analyses collectively establish a robust foundation for the credibility of Chatbot Arena. Because of its unique value and openness, Chatbot Arena has emerged as one of the most referenced LLM leaderboards, widely cited by leading LLM developers and companies. The platform is publicly available at https://chat.lmsys.org.",
        "year": 2024,
        "authors": "Wei-Lin Chiang and Lianmin Zheng and Ying Sheng and Anastasios Nikolas Angelopoulos and Tianle Li and Dacheng Li and Hao Zhang and Banghua Zhu and Michael Jordan and Joseph E Gonzalez and Ion Stoica"
      },
      {
        "title": "Uncertainty sets for image classifiers using conformal prediction",
        "abstract": "Convolutional image classifiers can achieve high predictive accuracy, but quantifying their uncertainty remains an unresolved challenge, hindering their deployment in consequential settings. Existing uncertainty quantification techniques, such as Platt scaling, attempt to calibrate the network's probability estimates, but they do not have formal guarantees. We present an algorithm that modifies any classifier to output a predictive set containing the true label with a user-specified probability, such as 90%. The algorithm is simple and fast like Platt scaling, but provides a formal finite-sample coverage guarantee for every model and dataset. Our method modifies an existing conformal prediction algorithm to give more stable predictive sets by regularizing the small scores of unlikely classes after Platt scaling. In experiments on both Imagenet and Imagenet-V2 with ResNet-152 and other classifiers, our scheme outperforms existing approaches, achieving coverage with sets that are often factors of 5 to 10 smaller than a stand-alone Platt scaling baseline.",
        "year": 2020,
        "authors": "Anastasios Angelopoulos* and Stephen Bates* and Jitendra Malik and Michael I Jordan"
      }
    ],
    "2ItLnFgAAAAJ": [
      {
        "title": "Neural activation constellations: Unsupervised part model discovery with convolutional networks",
        "abstract": "Part models of object categories are essential for challenging recognition tasks, where differences in categories are subtle and only reflected in appearances of small parts of the object. We present an approach that is able to learn part models in a completely unsupervised manner, without part annotations and even without given bounding boxes during learning. The key idea is to find constellations of neural activation patterns computed using convolutional neural networks. In our experiments, we outperform existing approaches for fine-grained recognition on the CUB200-2011, Oxford PETS, and Oxford Flowers dataset in case no part or bounding box annotations are available and achieve state-of-the-art performance for the Stanford Dog dataset. We also show the benefits of neural constellation models as a data augmentation technique for fine-tuning. Furthermore, our paper unites the areas of generic and fine-grained classification, since our approach is suitable for both scenarios.",
        "year": 2015,
        "authors": "Marcel Simon and Erik Rodner"
      },
      {
        "title": "Efficient Learning of Domain-invariant Image Representations",
        "abstract": "We present an algorithm that learns representations which explicitly compensate for domain mismatch and which can be efficiently realized as linear classifiers. Specifically, we form a linear transformation that maps features from the target (test) domain to the source (training) domain as part of training the classifier. We optimize both the transformation and classifier parameters jointly, and introduce an efficient cost function based on misclassification loss. Our method combines several features previously unavailable in a single algorithm: multi-class adaptation through representation learning, ability to map across heterogeneous feature spaces, and scalability to large datasets. We present experiments on several image datasets that demonstrate improved accuracy and computational advantages compared to previous approaches.",
        "year": 2013,
        "authors": "Judy Hoffman and Erik Rodner and Jeff Donahue and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Automatic classification of cancerous tissue in laserendomicroscopy images of the oral cavity using deep learning",
        "abstract": "Oral Squamous Cell Carcinoma (OSCC) is a common type of cancer of the oral epithelium. Despite their high impact on mortality, sufficient screening methods for early diagnosis of OSCC often lack accuracy and thus OSCCs are mostly diagnosed at a late stage. Early detection and accurate outline estimation of OSCCs would lead to a better curative outcome and a reduction in recurrence rates after surgical treatment. Confocal Laser Endomicroscopy (CLE) records sub-surface micro-anatomical images for in vivo cell structure analysis. Recent CLE studies showed great prospects for a reliable, real-time ultrastructural imaging of OSCC in situ. We present and evaluate a novel automatic approach for OSCC diagnosis using deep learning technologies on CLE images. The method is compared against textural feature-based machine learning approaches that represent the current state of the art. For this work, CLE …",
        "year": 2017,
        "authors": "Marc Aubreville and Christian Knipfer and Nicolai Oetter and Christian Jaremenko and Erik Rodner and Joachim Denzler and Christopher Bohr and Helmut Neumann and Florian Stelzle and Andreas Maier"
      }
    ],
    "aC55XVgAAAAJ": [
      {
        "title": "Breast reconstruction following nipple-sparing mastectomy: predictors of complications, reconstruction outcomes, and 5-year trends",
        "abstract": "Background:Nipple-sparing mastectomy is increasingly used for treatment and prevention of breast cancer. Few data exist on risk factors for complications and reconstruction outcomes.Methods:A single-institution retrospective review was performed between 2007 and 2012.Results:Two hundred eighty-five patients underwent 500 nipple-sparing mastectomy procedures for breast cancer (46 percent) or risk reduction (54 percent). The average body mass index was 24, and 6 percent were smokers. The mean follow-up was 2.17 years. Immediate breast reconstruction (reconstruction rate, 98.8 percent) was performed with direct-to-implant (59 percent), tissue expander/implant (38 percent), or autologous (2 percent) reconstruction. Acellular dermal matrix was used in 71 percent and mesh was used in 11 percent. Seventy-seven reconstructions had radiotherapy. Complications included infection (3.3 percent), skin …",
        "year": 2014,
        "authors": "Amy S Colwell and Oren Tessler and Alex M Lin and Eric Liao and Jonathan Winograd and Curtis L Cetrulo and Rong Tang and Barbara L Smith and William G Austen Jr"
      },
      {
        "title": "Increasing eligibility for nipple-sparing mastectomy",
        "abstract": " Eligibility for nipple-sparing mastectomy (NSM) varies widely on the basis of patient and tumor factors.Review of patients undergoing NSM from June 2007 to December 2012 at our institution was performed. Patient and tumor characteristics, complications, and recurrences were collected. NSM from 2007 to 2010 and 2011 to 2012 were compared to assess trends in eligibility and outcomes over time.NSM was performed on 645 breasts in 370 patients. Indications were risk reduction in 330 (51.2 %), invasive cancer in 226 (35.0 %), and ductal carcinoma-in situ in 89 (13.8 %) breasts. Fifty-one (13.8 %) patients had positive lymph nodes. Twenty-seven (7.3 %) patients received neoadjuvant chemotherapy. Forty-eight (7.4 %) breasts had prior radiotherapy. Total nipple necrosis occurred in 11 …",
        "year": 2013,
        "authors": "Suzanne B Coopey and Rong Tang and Lan Lei and Phoebe E Freer and Kari Kansal and Amy S Colwell and Michele A Gadd and Michelle C Specht and William G Austen and Barbara L Smith"
      },
      {
        "title": "Nipple-Sparing Mastectomy in BRCA1/2 Mutation Carriers: An Interim Analysis and Review of the Literature",
        "abstract": " There are few large-scale studies that have examined outcomes for BRCA1/2 carriers who have undergone nipple-sparing mastectomy (NSM). The objective of our study was to examine incidental cancers, operative complications, and locoregional recurrences in BRCA1/2 mutation carriers who underwent NSM for both risk reduction and cancer treatment.This was a retrospective review of pathology results and outcomes of 201 BRCA1/2 carriers from two different institutions who underwent NSM from 2007 to 2014.NSM was performed in 397 breasts of 201 BRCA1/2 carriers. One hundred and twenty-five (62.2 %) patients had a BRCA1 mutation and 76 (37.8 %) had a BRCA2 mutation; 150 (74.6 %) patients underwent NSM for risk reduction and 51 (25.4 %) for cancer. Incidental cancers …",
        "year": 2015,
        "authors": "Katharine Yao and Erik Liederbach and Rong Tang and Lan Lei and Tomasz Czechura and Mark Sisco and Michael Howard and Peter J Hulick and David J Winchester and Suzanne B Coopey and Barbara L Smith"
      }
    ],
    "sRpY9TIAAAAJ": [
      {
        "title": "A deep learning approach to antibiotic discovery",
        "abstract": "Due to the rapid emergence of antibiotic-resistant bacteria, there is a growing need to discover new antibiotics. To address this challenge, we trained a deep neural network capable of predicting molecules with antibacterial activity. We performed predictions on multiple chemical libraries and discovered a molecule from the Drug Repurposing Hub—halicin—that is structurally divergent from conventional antibiotics and displays bactericidal activity against a wide phylogenetic spectrum of pathogens including Mycobacterium tuberculosis and carbapenem-resistant Enterobacteriaceae. Halicin also effectively treated Clostridioides difficile and pan-resistant Acinetobacter baumannii infections in murine models. Additionally, from a discrete set of 23 empirically tested predictions from >107 million molecules curated from the ZINC15 database, our model identified eight antibacterial compounds that are structurally distant …",
        "year": 2020,
        "authors": "Jonathan M Stokes and Kevin Yang and Kyle Swanson and Wengong Jin and Andres Cubillos-Ruiz and Nina M Donghia and Craig R MacNair and Shawn French and Lindsey A Carfrae and Zohar Bloom-Ackermann and Victoria M Tran and Anush Chiappino-Pepe and Ahmed H Badran and Ian W Andrews and Emma J Chory and George M Church and Eric D Brown and Tommi S Jaakkola and Regina Barzilay and James J Collins"
      },
      {
        "title": "Analyzing learned molecular representations for property prediction",
        "abstract": "Advancements in neural machinery have led to a wide range of algorithmic solutions for molecular property prediction. Two classes of models in particular have yielded promising results: neural networks applied to computed molecular fingerprints or expert-crafted descriptors and graph convolutional neural networks that construct a learned molecular representation by operating on the graph structure of the molecule. However, recent literature has yet to clearly determine which of these two methods is superior when generalizing to new chemical space. Furthermore, prior research has rarely examined these new models in industry research settings in comparison to existing employed models. In this paper, we benchmark models extensively on 19 public and 16 proprietary industrial data sets spanning a wide variety of chemical end points. In addition, we introduce a graph convolutional model that consistently …",
        "year": 2019,
        "authors": "Kevin Yang and Kyle Swanson and Wengong Jin and Connor Coley and Philipp Eiden and Hua Gao and Angel Guzman-Perez and Timothy Hopper and Brian Kelley and Miriam Mathea and Andrew Palmer and Volker Settels and Tommi Jaakkola and Klavs Jensen and Regina Barzilay"
      },
      {
        "title": "FUDGE: Controlled Text Generation With Future Discriminators",
        "abstract": "We propose Future Discriminators for Generation (FUDGE), a flexible and modular method for controlled text generation. Given a pre-existing model G for generating text from a distribution of interest, FUDGE enables conditioning on a desired attribute a (for example, formality) while requiring access only to G's output logits. FUDGE learns an attribute predictor operating on a partial sequence, and uses this predictor's outputs to adjust G's original probabilities. We show that FUDGE models terms corresponding to a Bayesian decomposition of the conditional distribution of G given attribute a. Moreover, FUDGE can easily compose predictors for multiple desired attributes. We evaluate FUDGE on three tasks -- couplet completion in poetry, topic control in language generation, and formality change in machine translation -- and observe gains in all three tasks.",
        "year": 2021,
        "authors": "Kevin Yang and Dan Klein"
      }
    ],
    "w-xdg4sAAAAJ": [
      {
        "title": "Learning the dynamics of arterial traffic from probe data using a dynamic Bayesian network",
        "abstract": "Estimating and predicting traffic conditions in arterial networks using probe data has proven to be a substantial challenge. Sparse probe data represent the vast majority of the data available on arterial roads. This paper proposes a probabilistic modeling framework for estimating and predicting arterial travel-time distributions using sparsely observed probe vehicles. We introduce a model based on hydrodynamic traffic theory to learn the density of vehicles on arterial road segments, illustrating the distribution of delay within a road segment. The characterization of this distribution is essentially to use probe vehicles for traffic estimation: Probe vehicles report their location at random locations, and the travel times between location reports must be properly scaled to match the map discretization. A dynamic Bayesian network represents the spatiotemporal dependence on the network and provides a flexible framework to …",
        "year": 2012,
        "authors": "Aude Hofleitner and Ryan Herring and Pieter Abbeel and Alexandre Bayen"
      },
      {
        "title": "Estimating arterial traffic conditions using sparse probe data",
        "abstract": "Estimating and predicting traffic conditions in arterial networks using probe data has proven to be a substantial challenge. In the United States, sparse probe data represents the vast majority of the data available on arterial roads in most major urban environments. This article proposes a probabilistic modeling framework for estimating and predicting arterial travel time distributions using sparsely observed probe vehicles. We evaluate our model using data from a fleet of 500 taxis in San Francisco, CA, which send GPS data to our server every minute. The sampling rate does not provide detailed information about where vehicles encountered delay or the reason for any delay (i.e. signal delay, congestion delay, etc.). Our model provides an increase in estimation accuracy of 35% when compared to a baseline approach for processing probe vehicle data.",
        "year": 2010,
        "authors": "Ryan Herring and Aude Hofleitner and Pieter Abbeel and Alexandre Bayen"
      },
      {
        "title": "Arterial travel time forecast with streaming data: A hybrid approach of flow modeling and machine learning",
        "abstract": "This article presents a hybrid modeling framework for estimating and predicting arterial traffic conditions using streaming GPS probe data. The model is based on a well-established theory of traffic flow through signalized intersections and is combined with a machine learning framework to both learn static parameters of the roadways (such as free flow velocity or traffic signal parameters) as well as to estimate and predict travel times through the arterial network. The machine learning component of the approach uses the significant amount of historical data collected by the Mobile Millennium system since March 2009 with over 500 probe vehicles reporting their position once per minute in San Francisco, CA. The hybrid model provides a distinct advantage over pure statistical or pure traffic theory models in that it is robust to noisy data (due to the large volumes of historical data) and it produces forecasts using traffic …",
        "year": 2012,
        "authors": "Aude Hofleitner and Ryan Herring and Alexandre Bayen"
      }
    ],
    "DRnOvU8AAAAJ": [
      {
        "title": "Diversity Is All You Need: Learning Skills without a Reward Function",
        "abstract": "Intelligent creatures can explore their environments and learn useful skills without supervision. In this paper, we propose DIAYN ('Diversity is All You Need'), a method for learning useful skills without a reward function. Our proposed method learns skills by maximizing an information theoretic objective using a maximum entropy policy. On a variety of simulated robotic tasks, we show that this simple objective results in the unsupervised emergence of diverse skills, such as walking and jumping. In a number of reinforcement learning benchmark environments, our method is able to learn a skill that solves the benchmark task despite never receiving the true task reward. We show how pretrained skills can provide a good parameter initialization for downstream tasks, and can be composed hierarchically to solve complex, sparse reward tasks. Our results suggest that unsupervised discovery of skills can serve as an effective pretraining mechanism for overcoming challenges of exploration and data efficiency in reinforcement learning.",
        "year": 2019,
        "authors": "Benjamin Eysenbach and Abhishek Gupta and Julian Ibarz and Sergey Levine"
      },
      {
        "title": "Search on the Replay Buffer: Bridging Planning and Reinforcement Learning",
        "abstract": "The history of learning for control has been an exciting back and forth between two broad classes of algorithms: planning and reinforcement learning. Planning algorithms effectively reason over long horizons, but assume access to a local policy and distance metric over collision-free paths. Reinforcement learning excels at learning policies and relative values of states, but fails to plan over long horizons. Despite the successes of each method on various tasks, long horizon, sparse reward tasks with high-dimensional observations remain exceedingly challenging for both planning and reinforcement learning algorithms. Frustratingly, these sorts of tasks are potentially the most useful, as they are simple to design (a human only need to provide an example goal state) and avoid injecting bias through reward shaping. We introduce a general-purpose control algorithm that combines the strengths of planning and reinforcement learning to effectively solve these tasks. Our main idea is to decompose the task of reaching a distant goal state into a sequence of easier tasks, each of which corresponds to reaching a particular subgoal. We use goal-conditioned RL to learn a policy to reach each waypoint and to learn a distance metric for search. Using graph search over our replay buffer, we can automatically generate this sequence of subgoals, even in image-based environments. Our algorithm, search on the replay buffer (SoRB), enables agents to solve sparse reward tasks over hundreds of steps, and generalizes substantially better than standard RL algorithms.",
        "year": 2019,
        "authors": "Benjamin Eysenbach and Ruslan Salakhutdinov and Sergey Levine"
      },
      {
        "title": "Efficient Exploration via State Marginal Matching",
        "abstract": "Exploration is critical to a reinforcement learning agent's performance in its given environment. Prior exploration methods are often based on using heuristic auxiliary predictions to guide policy behavior, lacking a mathematically-grounded objective with clear properties. In contrast, we recast exploration as a problem of State Marginal Matching (SMM), where we aim to learn a policy for which the state marginal distribution matches a given target state distribution. The target distribution is a uniform distribution in most cases, but can incorporate prior knowledge if available. In effect, SMM amortizes the cost of learning to explore in a given environment. The SMM objective can be viewed as a two-player, zero-sum game between a state density model and a parametric policy, an idea that we use to build an algorithm for optimizing the SMM objective. Using this formalism, we further demonstrate that prior work approximately maximizes the SMM objective, offering an explanation for the success of these methods. On both simulated and real-world tasks, we demonstrate that agents that directly optimize the SMM objective explore faster and adapt more quickly to new tasks as compared to prior exploration methods.",
        "year": 2019,
        "authors": "Lisa Lee and Benjamin Eysenbach and Emilio Parisotto and Eric Xing and Sergey Levine and Ruslan Salakhutdinov"
      }
    ],
    "BIwrJuQAAAAJ": [
      {
        "title": "Gpt-4 technical report",
        "abstract": "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.",
        "year": 2023,
        "authors": "Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew"
      },
      {
        "title": "Visual reinforcement learning with imagined goals",
        "abstract": "For an autonomous agent to fulfill a wide range of user-specified goals at test time, it must be able to learn broadly applicable and general-purpose skill repertoires. Furthermore, to provide the requisite level of generality, these skills must handle raw sensory input such as images. In this paper, we propose an algorithm that acquires such general-purpose skills by combining unsupervised representation learning and reinforcement learning of goal-conditioned policies. Since the particular goals that might be required at test-time are not known in advance, the agent performs a self-supervised\" practice\" phase where it imagines goals and attempts to achieve them. We learn a visual representation with three distinct purposes: sampling goals for self-supervised practice, providing a structured transformation of raw sensory inputs, and computing a reward signal for goal reaching. We also propose a retroactive goal relabeling scheme to further improve the sample-efficiency of our method. Our off-policy algorithm is efficient enough to learn policies that operate on raw image observations and goals in a real-world physical system, and substantially outperforms prior techniques.",
        "year": 2018,
        "authors": "Ashvin V Nair and Vitchyr Pong and Murtaza Dalal and Shikhar Bahl and Steven Lin and Sergey Levine"
      },
      {
        "title": "Openai o1 system card",
        "abstract": "The o1 model series is trained with large-scale reinforcement learning to reason using chain of thought. These advanced reasoning capabilities provide new avenues for improving the safety and robustness of our models. In particular, our models can reason about our safety policies in context when responding to potentially unsafe prompts, through deliberative alignment. This leads to state-of-the-art performance on certain benchmarks for risks such as generating illicit advice, choosing stereotyped responses, and succumbing to known jailbreaks. Training models to incorporate a chain of thought before answering has the potential to unlock substantial benefits, while also increasing potential risks that stem from heightened intelligence. Our results underscore the need for building robust alignment methods, extensively stress-testing their efficacy, and maintaining meticulous risk management protocols. This report outlines the safety work carried out for the OpenAI o1 and OpenAI o1-mini models, including safety evaluations, external red teaming, and Preparedness Framework evaluations.",
        "year": 2024,
        "authors": "Aaron Jaech and Adam Kalai and Adam Lerer and Adam Richardson and Ahmed El-Kishky and Aiden Low and Alec Helyar and Aleksander Madry and Alex Beutel and Alex Carney and Alex Iftimie and Alex Karpenko and Alex Tachard Passos and Alexander Neitz and Alexander Prokofiev and Alexander Wei and Allison Tam and Ally Bennett and Ananya Kumar and Andre Saraiva and Andrea Vallone and Andrew Duberstein and Andrew Kondrich and Andrey Mishchenko and Andy Applebaum and Angela Jiang and Ashvin Nair and Barret Zoph and Behrooz Ghorbani and Ben Rossen and Benjamin Sokolowsky and Boaz Barak and Bob McGrew and Borys Minaiev and Botao Hao and Bowen Baker and Brandon Houghton and Brandon McKinzie and Brydon Eastman and Camillo Lugaresi and Cary Bassin and Cary Hudson and Chak Ming Li and Charles de Bourcy and Chelsea Voss and Chen Shen and Chong Zhang and Chris Koch and Chris Orsinger and Christopher Hesse and Claudia Fischer and Clive Chan and Dan Roberts and Daniel Kappler and Daniel Levy and Daniel Selsam and David Dohan and David Farhi and David Mely and David Robinson and Dimitris Tsipras and Doug Li and Dragos Oprica and Eben Freeman and Eddie Zhang and Edmund Wong and Elizabeth Proehl and Enoch Cheung and Eric Mitchell and Eric Wallace and Erik Ritter and Evan Mays and Fan Wang and Felipe Petroski Such and Filippo Raso and Florencia Leoni and Foivos Tsimpourlas and Francis Song and Fred von Lohmann and Freddie Sulit and Geoff Salmon and Giambattista Parascandolo and Gildas Chabot and Grace Zhao and Greg Brockman and Guillaume Leclerc and Hadi Salman and Haiming Bao and Hao Sheng and Hart Andrin and Hessam Bagherinezhad and Hongyu Ren and Hunter Lightman and Hyung Won Chung and Ian Kivlichan and Ian O'Connell and Ian Osband and Ignasi Clavera Gilaberte and Ilge Akkaya and Ilya Kostrikov and Ilya Sutskever and Irina Kofman and Jakub Pachocki and James Lennon and Jason Wei and Jean Harb and Jerry Twore and Jiacheng Feng and Jiahui Yu and Jiayi Weng and Jie Tang and Jieqi Yu and Joaquin Quiñonero Candela and Joe Palermo and Joel Parish and Johannes Heidecke and John Hallman and John Rizzo and Jonathan Gordon and Jonathan Uesato and Jonathan Ward and Joost Huizinga and Julie Wang and Kai Chen and Kai Xiao and Karan Singhal and Karina Nguyen and Karl Cobbe and Katy Shi and Kayla Wood and Kendra Rimbach and Keren Gu-Lemberg and Kevin Liu and Kevin Lu and Kevin Stone and Kevin Yu and Lama Ahmad and Lauren Yang and Leo Liu and Leon Maksin and Leyton Ho and Liam Fedus and Lilian Weng and Linden Li and Lindsay McCallum and Lindsey Held and Lorenz Kuhn and Lukas Kondraciuk and Lukasz Kaiser and Luke Metz"
      }
    ],
    "T6PbwPIAAAAJ": [
      {
        "title": "Show and tell: A neural image caption generator",
        "abstract": "Automatically describing the content of an image is a fundamental problem in artificial intelligence that connects computer vision and natural language processing. In this paper, we present a generative model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation and that can be used to generate natural sentences describing an image. The model is trained to maximize the likelihood of the target description sentence given the training image. Experiments on several datasets show the accuracy of the model and the fluency of the language it learns solely from image descriptions. Our model is often quite accurate, which we verify both qualitatively and quantitatively. For instance, while the current state-of-the-art BLEU score (the higher the better) on the Pascal dataset is 25, our approach yields 59, to be compared to human performance around 69. We also show BLEU score improvements on Flickr30k, from 56 to 66, and on SBU, from 19 to 28. Lastly, on the newly released COCO dataset, we achieve a BLEU-4 of 27.7, which is the current state-of-the-art.",
        "year": 2015,
        "authors": "Oriol Vinyals and Alexander Toshev and Samy Bengio and Dumitru Erhan"
      },
      {
        "title": "Deeppose: Human pose estimation via deep neural networks",
        "abstract": "We propose a method for human pose estimation based on Deep Neural Networks (DNNs). The pose estimation is formulated as a DNN-based regression problem towards body joints. We present a cascade of such DNN regressors which results in high precision pose estimates. The approach has the advantage of reasoning about pose in a holistic fashion and has a simple but yet powerful formulation which capitalizes on recent advances in Deep Learning. We present a detailed empirical analysis with state-of-art or better performance on four academic benchmarks of diverse real-world images.",
        "year": 2014,
        "authors": "Alexander Toshev and Christian Szegedy"
      },
      {
        "title": "Deep neural networks for object detection",
        "abstract": "Deep Neural Networks (DNNs) have recently shown outstanding performance on the task of whole image classification. In this paper we go one step further and address the problem of object detection--not only classifying but also precisely localizing objects of various classes using DNNs. We present a simple and yet powerful formulation of object detection as a regression to object masks. We define a multi-scale inference procedure which is able to produce a high-resolution object detection at a low cost by a few network applications. The approach achieves state-of-the-art performance on Pascal 2007 VOC.",
        "year": 2013,
        "authors": "Christian Szegedy and Alexander Toshev and Dumitru Erhan"
      }
    ],
    "MK6zHkYAAAAJ": [
      {
        "title": "Robust Estimators in High-Dimensions Without the Computational Intractability",
        "abstract": "We study high-dimensional distribution learning in an agnostic setting where an adversary is allowed to arbitrarily corrupt an -fraction of the samples. Such questions have a rich history spanning statistics, machine learning, and theoretical computer science. Even in the most basic settings, the only known approaches are either computationally inefficient or lose dimension-dependent factors in their error guarantees. This raises the following question: Is high-dimensional agnostic distribution learning even possible, algorithmically? In this work, we obtain the first computationally efficient algorithms with dimension-independent error guarantees for agnostically learning several fundamental classes of high-dimensional distributions: (1) a single Gaussian, (2) a product distribution on the hypercube, (3) mixtures of two product distributions (under a natural balancedness condition), and (4) mixtures of spherical …",
        "year": 2019,
        "authors": "Ilias Diakonikolas and Gautam Kamath and Daniel Kane and Jerry Li and Ankur Moitra and Alistair Stewart"
      },
      {
        "title": "Differentially Private Fine-tuning of Language Models",
        "abstract": "We give simpler, sparser, and faster algorithms for differentially private fine-tuning of large-scale pre-trained language models, which achieve the state-of-the-art privacy versus utility tradeoffs on many standard NLP tasks. We propose a meta-framework for this problem, inspired by the recent success of highly parameter-efficient methods for fine-tuning. Our experiments show that differentially private adaptations of these approaches outperform previous private algorithms in three important dimensions: utility, privacy, and the computational and memory cost of private training. On many commonly studied datasets, the utility of private models approaches that of non-private models. For example, on the MNLI dataset we achieve an accuracy of  using RoBERTa-Large and  using RoBERTa-Base with a privacy budget of . In comparison, absent privacy constraints, RoBERTa-Large achieves an accuracy of . Our findings are similar for natural language generation tasks. Privately fine-tuning with DART, GPT-2-Small, GPT-2-Medium, GPT-2-Large, and GPT-2-XL achieve BLEU scores of 38.5, 42.0, 43.1, and 43.8 respectively (privacy budget of  1e-5) whereas the non-private baseline is . All our experiments suggest that larger models are better suited for private fine-tuning: while they are well known to achieve superior accuracy non-privately, we find that they also better maintain their accuracy when privacy is introduced.",
        "year": 2022,
        "authors": "Da Yu and Saurabh Naik and Arturs Backurs and Sivakanth Gopi and Huseyin A Inan and Gautam Kamath and Janardhan Kulkarni and Yin Tat Lee and Andre Manoel and Lukas Wutschitz and Sergey Yekhanin and Huishuai Zhang"
      },
      {
        "title": "Remember what you want to forget: Algorithms for machine unlearning",
        "abstract": "We study the problem of unlearning datapoints from a learnt model. The learner first receives a dataset  drawn iid from an unknown distribution, and outputs a model  that performs well on unseen samples from the same distribution. However, at some point in the future, any training datapoint  can request to be unlearned, thus prompting the learner to modify its output model while still ensuring the same accuracy guarantees. We initiate a rigorous study of generalization in machine unlearning, where the goal is to perform well on previously unseen datapoints. Our focus is on both computational and storage complexity. For the setting of convex losses, we provide an unlearning algorithm that can unlearn up to  samples, where  is the problem dimension. In comparison, in general, differentially private learning (which implies unlearning) only guarantees deletion of  samples. This demonstrates a novel separation between differential privacy and machine unlearning.",
        "year": 2021,
        "authors": "Ayush Sekhari and Jayadev Acharya and Gautam Kamath and Ananda Theertha Suresh"
      }
    ],
    "NTb14PgAAAAJ": [
      {
        "title": "Climate change 2014: synthesis report. Contribution of Working Groups I, II and III to the fifth assessment report of the Intergovernmental Panel on Climate Change",
        "abstract": "The Synthesis Report (SYR), constituting the final product of the Fifth Assessment Report (AR5) of the Intergovernmental Panel on Climate Change (IPCC), is published under the title Climate Change 2014. This report distils, synthesizes and integrates the key findings of the three",
        "year": 2014,
        "authors": "Rajendra K Pachauri and Myles R Allen and Vicente R Barros and John Broome and Wolfgang Cramer and Renate Christ and John A Church and Leon Clarke and Qin Dahe and Purnamita Dasgupta and Navroz K Dubash and Ottmar Edenhofer and Ismail Elgizouli and Christopher B Field and Piers Forster and Pierre Friedlingstein and Jan Fuglestvedt and Luis Gomez-Echeverri and Stephane Hallegatte and Gabriele Hegerl and Mark Howden and Kejun Jiang and B Jimenez Cisneroz and Vladimir Kattsov and Hoesung Lee and Katharine J Mach and Jochem Marotzke and Michael D Mastrandrea and Leo Meyer and Jan Minx and Yacob Mulugetta and Karen O'Brien and Michael Oppenheimer and Joy J Pereira and Ramón Pichs-Madruga and G-K Plattner and Hans-Otto Pörtner and Scott B Power and Benjamin Preston and NH Ravindranath and Andy Reisinger and Keywan Riahi and Matilde Rusticucci and Robert Scholes and Kristin Seyboth and Youba Sokona and Robert Stavins and Thomas F Stocker and Petra Tschakert and Detlef van Vuuren and J-P van Ypserle"
      },
      {
        "title": "Systematic measurements of identified particle spectra in , , and  collisions at the STAR detector",
        "abstract": "Identified charged-particle spectra of , , , and  at midrapidity () measured by the  method in the STAR (solenoidal tracker at the BNL Relativistic Heavy Ion Collider) time projection chamber are reported for  and  collisions at  GeV and for  collisions at 62.4, 130, and 200 GeV. Average transverse momenta, total particle production, particle yield ratios, strangeness, and baryon production rates are investigated as a function of the collision system and centrality. The transverse momentum spectra are found to be flatter for heavy particles than for light particles in all collision systems; the effect is more prominent for more central collisions. The extracted average transverse momentum of each particle species follows a trend determined by the total charged-particle multiplicity density. The Bjorken energy density estimate is at least several GeV/ for a formation time less than 1 fm/. A significantly larger net-baryon …",
        "year": 2009,
        "authors": "BI Abelev and MM Aggarwal and Z Ahammed and BD Anderson and D Arkhipkin and GS Averichev and Y Bai and J Balewski and O Barannikova and LS Barnby and J Baudot and S Baumgart and DR Beavis and R Bellwied and F Benedosso and RR Betts and S Bhardwaj and A Bhasin and AK Bhati and H Bichsel and J Bielcik and J Bielcikova and B Biritz and LC Bland and M Bombara and BE Bonner and M Botje and J Bouchet and E Braidot and AV Brandin and E Bruna and S Bueltmann and TP Burton and M Bystersky and XZ Cai and H Caines and M Calderón De La Barca Sánchez and J Callner and O Catu and D Cebra and R Cendejas and MC Cervantes and Z Chajecki and P Chaloupka and S Chattopadhyay and HF Chen and JH Chen and JY Chen and J Cheng and M Cherney and A Chikanian and KE Choi and W Christie and SU Chung and RF Clarke and MJM Codrington and JP Coffin and TM Cormier and MR Cosentino and JG Cramer and HJ Crawford and D Das and S Dash and M Daugherity and C De Silva and TG Dedovich and M DePhillips and AA Derevschikov and R Derradi De Souza and L Didenko and P Djawotho and SM Dogra and X Dong and JL Drachenberg and JE Draper and F Du and JC Dunlop and MR Dutta Mazumdar and WR Edwards and LG Efimov and E Elhalhuli and M Elnimr and V Emelianov and J Engelage and G Eppley and B Erazmus and M Estienne and L Eun and P Fachini and R Fatemi and J Fedorisin and A Feng and P Filip and E Finch and V Fine and Y Fisyak and Carl A Gagliardi and L Gaillard and DR Gangadharan and MS Ganti and E Garcia-Solis and V Ghazikhanian and P Ghosh and YN Gorbunov and A Gordon and O Grebenyuk and D Grosnick and B Grube and SM Guertin and KSFF Guimaraes and A Gupta and N Gupta and W Guryn and B Haag and TJ Hallman and A Hamed and JW Harris and W He and M Heinz and S Heppelmann and B Hippolyte and A Hirsch and E Hjort and AM Hoffman and GW Hoffmann and DJ Hofman and RS Hollis and HZ Huang and TJ Humanic and G Igo and A Iordanova and P Jacobs and WW Jacobs and P Jakl and F Jin and PG Jones and J Joseph and EG Judd and S Kabana and K Kajimoto and K Kang and J Kapitan and M Kaplan and D Keane and A Kechechyan and D Kettler and V Yu Khodyrev and J Kiryluk and A Kisiel and SR Klein"
      },
      {
        "title": "Prevalence of diabetes and its risk factors in China, 1994",
        "abstract": "To determine the prevalence of diabetes and impaired glucose tolerance (IGT) and its risk factors in the Chinese population.This study was a population-based cross-sectional study of 224,251 residents aged 25–64 years in 19 provinces and areas, including cities and rural areas of the north, south, east, and middle part of China.Using the 1985 World Health Organization criteria, the prevalence of diabetes and IGT was 2.5 and 3.2%, respectively, in 213,515 subjects aged 25–64 years. Two thirds (70.3%) of the cases had newly recognized diabetes. The prevalence of diabetes in China is about three times higher than it was 10 years ago. On average, subjects with diabetes are older, have higher personal annual incomes, and more often have a family history of diabetes. They also have higher mean BMI, waist-to-hip ratio (WHR), systolic blood pressure …",
        "year": 1997,
        "authors": "Xiao-Ren Pan and Wen-Ying Yang and Guan-Wei Li and Juan Liu and National Diabetes Prevention and Control Cooperative Group"
      }
    ],
    "5MTY7-wAAAAJ": [
      {
        "title": "Photo-based mobile deixis system and related techniques",
        "abstract": "(51) Int. Cl. A mobile deixis device includes a camera to capture an image H04N 5/225(2006.01) and a wireless handheld device, coupled to the camera and to (52) US Cl.................................................... 348/2O7. 1 a wireless network, to communicate the image with existing (58) Field of Classification Search.............. 348/207.1; databases to find similar images. The mobile deixis device 382/305, 190, 165; 455/456.1, 457 further includes a processor, coupled to the device, to process See application file for complete search history. found database records related to similarimages and a display (56) Ref Cited to view found database records that include webpages includ eerees e",
        "year": 2011,
        "authors": "Trevor J Darrell and Tom Yeh and Konrad Tollmar"
      },
      {
        "title": "Searching the web with mobile images for location recognition",
        "abstract": "We describe an approach to recognizing location from mobile devices using image-based Web search. We demonstrate the usefulness of common image search metrics applied on images captured with a camera-equipped mobile device to find matching images on the World Wide Web or other general-purpose databases. Searching the entire Web can be computationally overwhelming, so we devise a hybrid image-and-keyword searching technique. First, image-search is performed over images and links to their source Web pages in a database that indexes only a small fraction of the Web. Then, relevant keywords on these Web pages are automatically identified and submitted to an existing text-based search engine (e.g. Google) that indexes a much larger portion of the Web. Finally, the resulting image set is filtered to retain images close to the original query. It is thus possible to efficiently search hundreds of …",
        "year": 2004,
        "authors": "Tom Yeh and Konrad Tollmar and Trevor Darrell"
      },
      {
        "title": "Supporting social awareness@ work design and experience",
        "abstract": "During the last year we have been designing and studying a computer based tool intended to strengthen social group awareness within aresearch laboratory. While awareness has been a subject of previous research it is still unclear how it should be conceptualized and how it can be provided for a CSCW system. In order to investigate this, and hence to attempt to create a system that would gain acceptance in the user community, we have been using a mixture of user-centered and participatory design methods. This paper presents the design process, the resulting system as well as users’ comments on it. Based on all this, issues related to awareness are discussed and ideas for further studies are suggested.",
        "year": 1996,
        "authors": "Konrad Tollmar and Ovidiu Sandor and Anna Schömer"
      }
    ],
    "85XK-uAAAAAJ": [
      {
        "title": "An autonomous strawberry‐harvesting robot: Design, development, integration, and field evaluation",
        "abstract": "This paper presents an autonomous robot capable of picking strawberries continuously in polytunnels. Robotic harvesting in cluttered and unstructured environment remains a challenge. A novel obstacle‐separation algorithm was proposed to enable the harvesting system to pick strawberries that are located in clusters. The algorithm uses the gripper to push aside surrounding leaves, strawberries, and other obstacles. We present the theoretical method to generate pushing paths based on the surrounding obstacles. In addition to manipulation, an improved vision system is more resilient to lighting variations, which was developed based on the modeling of color against light intensity. Further, a low‐cost dual‐arm system was developed with an optimized harvesting sequence that increases its efficiency and minimizes the risk of collision. Improvements were also made to the existing gripper to enable the robot to …",
        "year": 2020,
        "authors": "Ya Xiong and Yuanyue Ge and Lars Grimstad and Pål J From"
      },
      {
        "title": "Agricultural robotics: the future of robotic agriculture",
        "abstract": "Agri-Food is the largest manufacturing sector in the UK. It supports a food chain that generates over {\\pounds}108bn p.a., with 3.9m employees in a truly international industry and exports {\\pounds}20bn of UK manufactured goods. However, the global food chain is under pressure from population growth, climate change, political pressures affecting migration, population drift from rural to urban regions and the demographics of an aging global population. These challenges are recognised in the UK Industrial Strategy white paper and backed by significant investment via a Wave 2 Industrial Challenge Fund Investment (\"Transforming Food Production: from Farm to Fork\"). Robotics and Autonomous Systems (RAS) and associated digital technologies are now seen as enablers of this critical food chain transformation. To meet these challenges, this white paper reviews the state of the art in the application of RAS in Agri-Food production and explores research and innovation needs to ensure these technologies reach their full potential and deliver the necessary impacts in the Agri-Food sector.",
        "year": 2018,
        "authors": "Tom Duckett and Simon Pearson and Simon Blackmore and Bruce Grieve and Wen-Hua Chen and Grzegorz Cielniak and Jason Cleaversmith and Jian Dai and Steve Davis and Charles Fox and Pål From and Ioannis Georgilas and Richie Gill and Iain Gould and Marc Hanheide and Alan Hunter and Fumiya Iida and Lyudmila Mihalyova and Samia Nefti-Meziani and Gerhard Neumann and Paolo Paoletti and Tony Pridmore and Dave Ross and Melvyn Smith and Martin Stoelen and Mark Swainson and Sam Wane and Peter Wilson and Isobel Wright and Guang-Zhong Yang"
      },
      {
        "title": "Development and field evaluation of a strawberry harvesting robot with a cable-driven gripper",
        "abstract": "This paper presents the development and evaluation of a robot for harvesting strawberries (Fragaria × ananassa) grown on table-tops in polytunnels. The robot is comprised of a newly-designed gripper mounted on an industrial arm which in turn is mounted on a mobile base along with an RGB-D camera. The novel cable-driven gripper can open fingers to “swallow” a target. Since it is designed to target the fruit not the stem, it just requires the fruit location for picking. Moreover, equipped with internal sensors, the gripper can sense and correct for positional errors, and is robust to the localisation errors introduced by the vision module. Another important feature of the gripper is the internal container that is used to collect berries during picking. Since the manipulator does not need to go back and forth between each berry and a separate punnet, picking time is reduced significantly. The vision system uses colour …",
        "year": 2019,
        "authors": "Ya Xiong and Cheng Peng and Lars Grimstad and Pål Johan From and Volkan Isler"
      }
    ],
    "DwdjBUUAAAAJ": [
      {
        "title": "Squeezeseg: Convolutional Neural Nets with Recurrent CRF for Real-time Road-Object Segmentation from 3D LiDAR Point Cloud",
        "abstract": "We address semantic segmentation of road-objects from 3D LiDAR point clouds. In particular, we wish to detect and categorize instances of interest, such as cars, pedestrians and cyclists. We formulate this problem as a point-wise classification problem, and propose an end-to-end pipeline called SqueezeSeg based on convolutional neural networks (CNN): the CNN takes a transformed LiDAR point cloud as input and directly outputs a point-wise label map, which is then refined by a conditional random field (CRF) implemented as a recurrent layer. Instance-level labels are then obtained by conventional clustering algorithms. Our CNN model is trained on LiDAR point clouds from the KITTI [1] dataset, and our point-wise segmentation labels are derived from 3D bounding boxes from KITTI. To obtain extra training data, we built a LiDAR simulator into Grand Theft Auto V (GTA-V), a popular video game, to synthesize …",
        "year": 2018,
        "authors": "Bichen Wu and Alvin Wan and Xiangyu Yue and Kurt Keutzer"
      },
      {
        "title": "Visual transformers: Where do transformers really belong in vision models?",
        "abstract": "A recent trend in computer vision is to replace convolutions with transformers. However, the performance gain of transformers is attained at a steep cost, requiring GPU years and hundreds of millions of samples for training. This excessive resource usage compensates for a misuse of transformers: Transformers densely model relationships between its inputs--ideal for late stages of a neural network, when concepts are sparse and spatially-distant, but extremely inefficient for early stages of a network, when patterns are redundant and localized. To address these issues, we leverage the respective strengths of both operations, building convolution-transformer hybrids. Critically, in sharp contrast to pixel-space transformers, our Visual Transformer (VT) operates in a semantic token space, judiciously attending to different image parts based on context. Our VTs significantly outperforms baselines: On ImageNet, our VT-ResNets outperform convolution-only ResNet by 4.6 to 7 points and transformer-only ViT-B by 2.6 points with 2.5 times fewer FLOPs, 2.1 times fewer parameters. For semantic segmentation on LIP and COCO-stuff, VT-based feature pyramid networks (FPN) achieve 0.35 points higher mIoU while reducing the FPN module's FLOPs by 6.5 x.",
        "year": 2021,
        "authors": "Bichen Wu and Chenfeng Xu and Xiaoliang Dai and Alvin Wan and Peizhao Zhang and Zhicheng Yan and Masayoshi Tomizuka and Joseph E Gonzalez and Kurt Keutzer and Peter Vajda"
      },
      {
        "title": "Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions",
        "abstract": "Neural networks rely on convolutions to aggregate spatial information. However, spatial convolutions are expensive in terms of model size and computation, both of which grow quadratically with respect to kernel size. In this paper, we present a parameter-free, FLOP-free\" shift\" operation as an alternative to spatial convolutions. We fuse shifts and point-wise convolutions to construct end-to-end trainable shift-based modules, with a hyperparameter characterizing the tradeoff between accuracy and efficiency. To demonstrate the operation's efficacy, we replace ResNet's 3x3 convolutions with shift-based modules for improved CIFAR-10 and CIFAR-100 accuracy using 60% fewer parameters; we additionally demonstrate the operation's resilience to parameter reduction on ImageNet, outperforming ResNet family members despite having millions fewer parameters. We further design a family of neural networks called ShiftNet, which achieve strong performance on classification, face verification and style transfer while demanding many fewer parameters.",
        "year": 2017,
        "authors": "Bichen Wu and Alvin Wan and Xiangyu Yue and Peter Jin and Sicheng Zhao and Noah Golmant and Amir Gholaminejad and Joseph Gonzalez and Kurt Keutzer"
      }
    ],
    "X-Sd3-8AAAAJ": [
      {
        "title": "Sparse local embeddings for extreme multi-label classification",
        "abstract": "The objective in extreme multi-label learning is to train a classifier that can automatically tag a novel data point with the most relevant subset of labels from an extremely large label set. Embedding based approaches make training and prediction tractable by assuming that the training label matrix is low-rank and hence the effective number of labels can be reduced by projecting the high dimensional label vectors onto a low dimensional linear subspace. Still, leading embedding approaches have been unable to deliver high prediction accuracies or scale to large problems as the low rank assumption is violated in most real world applications. This paper develops the SLEEC classifier to address both limitations. The main technical contribution in SLEEC is a formulation for learning a small ensemble of local distance preserving embeddings which can accurately predict infrequently occurring (tail) labels. This allows SLEEC to break free of the traditional low-rank assumption and boost classification accuracy by learning embeddings which preserve pairwise distances between only the nearest label vectors. We conducted extensive experiments on several real-world as well as benchmark data sets and compare our method against state-of-the-art methods for extreme multi-label classification. Experiments reveal that SLEEC can make significantly more accurate predictions then the state-of-the-art methods including both embeddings (by as much as 35%) as well as trees (by as much as 6%). SLEEC can also scale efficiently to data sets with a million labels which are beyond the pale of leading embedding methods.",
        "year": 2015,
        "authors": "Kush Bhatia and Himanshu Jain and Purushottam Kar and Manik Varma and Prateek Jain"
      },
      {
        "title": "Ask me anything: A simple strategy for prompting language models",
        "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply given a natural language prompt that demonstrates how to perform the task and no additional training. Prompting is a brittle process wherein small modifications to the prompt can cause large variations in the model predictions, and therefore significant effort is dedicated towards designing a painstakingly \"perfect prompt\" for a task. To mitigate the high degree of effort involved in prompt-design, we instead ask whether producing multiple effective, yet imperfect, prompts and aggregating them can lead to a high quality prompting strategy. Our observations motivate our proposed prompting method, ASK ME ANYTHING (AMA). We first develop an understanding of the effective prompt formats, finding that question-answering (QA) prompts, which encourage open-ended generation (\"Who went to the park?\") tend to outperform those that restrict the model outputs (\"John went to the park. Output True or False.\"). Our approach recursively uses the LLM itself to transform task inputs to the effective QA format. We apply the collected prompts to obtain several noisy votes for the input's true label. We find that the prompts can have very different accuracies and complex dependencies and thus propose to use weak supervision, a procedure for combining the noisy predictions, to produce the final predictions for the inputs. We evaluate AMA across open-source model families (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B parameters), demonstrating an average performance lift of 10.2% over the few-shot baseline. This simple strategy enables the open-source …",
        "year": 2023,
        "authors": "Simran Arora and Avanika Narayan and Mayee F Chen and Laurel Orr and Neel Guha and Kush Bhatia and Ines Chami and Frederic Sala and Christopher Ré"
      },
      {
        "title": "Fastgrnn: A fast, accurate, stable and tiny kilobyte sized gated recurrent neural network",
        "abstract": "This paper develops the FastRNN and FastGRNN algorithms to address the twin RNN limitations of inaccurate training and inefficient prediction. Previous approaches have improved accuracy at the expense of prediction costs making them infeasible for resource-constrained and real-time applications. Unitary RNNs have increased accuracy somewhat by restricting the range of the state transition matrix's singular values but have also increased the model size as they require a larger number of hidden units to make up for the loss in expressive power. Gated RNNs have obtained state-of-the-art accuracies by adding extra parameters thereby resulting in even larger models. FastRNN addresses these limitations by adding a residual connection that does not constrain the range of the singular values explicitly and has only two extra scalar parameters. FastGRNN then extends the residual connection to a gate by reusing the RNN matrices to match state-of-the-art gated RNN accuracies but with a 2-4x smaller model. Enforcing FastGRNN's matrices to be low-rank, sparse and quantized resulted in accurate models that could be up to 35x smaller than leading gated and unitary RNNs. This allowed FastGRNN to accurately recognize the\" Hey Cortana\" wakeword with a 1 KB model and to be deployed on severely resource-constrained IoT microcontrollers too tiny to store other RNN models. FastGRNN's code is available at (https://github. com/Microsoft/EdgeML/).",
        "year": 2018,
        "authors": "Aditya Kusupati and Manish Singh and Kush Bhatia and Ashish Kumar and Prateek Jain and Manik Varma"
      }
    ],
    "eurA6WgAAAAJ": [
      {
        "title": "Adversarial attacks on neural network policies",
        "abstract": "Machine learning classifiers are known to be vulnerable to inputs maliciously constructed by adversaries to force misclassification. Such adversarial examples have been extensively studied in the context of computer vision applications. In this work, we show adversarial attacks are also effective when targeting neural network policies in reinforcement learning. Specifically, we show existing adversarial example crafting techniques can be used to significantly degrade test-time performance of trained policies. Our threat model considers adversaries capable of introducing small perturbations to the raw input of the policy. We characterize the degree of vulnerability across tasks and training algorithms, for a subclass of adversarial-example attacks in white-box and black-box settings. Regardless of the learned task or training algorithm, we observe a significant drop in performance, even with small adversarial perturbations that do not interfere with human perception. Videos are available at http://rll.berkeley.edu/adversarial.",
        "year": 2017,
        "authors": "Sandy Huang and Nicolas Papernot and Ian Goodfellow and Yan Duan and Pieter Abbeel"
      },
      {
        "title": "Enabling robots to communicate their objectives",
        "abstract": "The overarching goal of this work is to efficiently enable end-users to correctly anticipate a robot’s behavior in novel situations. And since a robot’s behavior is often a direct result of its underlying objective function, our insight is that end-users need to have an accurate mental model of this objective function in order to understand and predict what the robot will do. While people naturally develop such a mental model over time through observing the robot act, this familiarization process may be lengthy. Our approach reduces this time by having the robot model how people infer objectives from observed behavior, in order to then show those behaviors that are maximally informative. We introduce two factors to define candidate models of human inference, and show that certain models indeed produce example robot behaviors that better enable users to anticipate what it will do in novel situations. Our results …",
        "year": 2017,
        "authors": "Sandy H Huang and David Held and Pieter Abbeel and Anca D. Dragan"
      },
      {
        "title": "Learning agile soccer skills for a bipedal robot with deep reinforcement learning",
        "abstract": "We investigated whether deep reinforcement learning (deep RL) is able to synthesize sophisticated and safe movement skills for a low-cost, miniature humanoid robot that can be composed into complex behavioral strategies. We used deep RL to train a humanoid robot to play a simplified one-versus-one soccer game. The resulting agent exhibits robust and dynamic movement skills, such as rapid fall recovery, walking, turning, and kicking, and it transitions between them in a smooth and efficient manner. It also learned to anticipate ball movements and block opponent shots. The agent’s tactical behavior adapts to specific game contexts in a way that would be impractical to manually design. Our agent was trained in simulation and transferred to real robots zero-shot. A combination of sufficiently high-frequency control, targeted dynamics randomization, and perturbations during training enabled good-quality transfer …",
        "year": 2024,
        "authors": "Tuomas Haarnoja and Ben Moran and Guy Lever and Sandy H Huang and Dhruva Tirumala and Jan Humplik and Markus Wulfmeier and Saran Tunyasuvunakool and Noah Y Siegel and Roland Hafner and Michael Bloesch and Kristian Hartikainen and Arunkumar Byravan and Leonard Hasenclever and Yuval Tassa and Fereshteh Sadeghi and Nathan Batchelor and Federico Casarini and Stefano Saliceti and Charles Game and Neil Sreendra and Kushal Patel and Marlon Gwira and Andrea Huber and Nicole Hurley and Francesco Nori and Raia Hadsell and Nicolas Heess"
      }
    ],
    "FFWXLHUAAAAJ": [
      {
        "title": "Trust Region Policy Optimization",
        "abstract": "In this article, we describe a method for optimizing control policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified scheme, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters.",
        "year": 2015,
        "authors": "John Schulman and Sergey Levine and Philipp Moritz and Michael I. Jordan and Peter Abbeel"
      },
      {
        "title": "High-dimensional continuous control using generalized advantage estimation",
        "abstract": "Policy gradient methods are an appealing approach in reinforcement learning because they directly optimize the cumulative reward and can straightforwardly be used with nonlinear function approximators such as neural networks. The two main challenges are the large number of samples typically required, and the difficulty of obtaining stable and steady improvement despite the nonstationarity of the incoming data. We address the first challenge by using value functions to substantially reduce the variance of policy gradient estimates at the cost of some bias, with an exponentially-weighted estimator of the advantage function that is analogous to TD(lambda). We address the second challenge by using trust region optimization procedure for both the policy and the value function, which are represented by neural networks. Our approach yields strong empirical results on highly challenging 3D locomotion tasks, learning running gaits for bipedal and quadrupedal simulated robots, and learning a policy for getting the biped to stand up from starting out lying on the ground. In contrast to a body of prior work that uses hand-crafted policy representations, our neural network policies map directly from raw kinematics to joint torques. Our algorithm is fully model-free, and the amount of simulated experience required for the learning tasks on 3D bipeds corresponds to 1-2 weeks of real time.",
        "year": 2015,
        "authors": "John Schulman and Philipp Moritz and Sergey Levine and Michael Jordan and Pieter Abbeel"
      },
      {
        "title": "Ray: A distributed framework for emerging {AI} applications",
        "abstract": "The next generation of AI applications will continuously interact with the environment and learn from these interactions. These applications impose new and demanding systems requirements, both in terms of performance and flexibility. In this paper, we consider these requirements and present Ray—a distributed system to address them. Ray implements a unified interface that can express both task-parallel and actor-based computations, supported by a single dynamic execution engine. To meet the performance requirements, Ray employs a distributed scheduler and a distributed and fault-tolerant store to manage the system’s control state. In our experiments, we demonstrate scaling beyond 1.8 million tasks per second and better performance than existing specialized systems for several challenging reinforcement learning applications.",
        "year": 2018,
        "authors": "Philipp Moritz and Robert Nishihara and Stephanie Wang and Alexey Tumanov and Richard Liaw and Eric Liang and Melih Elibol and Zongheng Yang and William Paul and Michael I Jordan and Ion Stoica"
      }
    ],
    "t8v3JXsAAAAJ": [
      {
        "title": "Nocturne: a scalable driving benchmark for bringing multi-agent learning one step closer to the real world",
        "abstract": "We introduce\\textit {Nocturne}, a new 2D driving simulator for investigating multi-agent coordination under partial observability. The focus of Nocturne is to enable research into inference and theory of mind in real-world multi-agent settings without the computational overhead of computer vision and feature extraction from images. Agents in this simulator only observe an obstructed view of the scene, mimicking human visual sensing constraints. Unlike existing benchmarks that are bottlenecked by rendering human-like observations directly using a camera input, Nocturne uses efficient intersection methods to compute a vectorized set of visible features in a C++ back-end, allowing the simulator to run at  steps-per-second. Using open-source trajectory and map data, we construct a simulator to load and replay arbitrary trajectories and scenes from real-world driving data. Using this environment, we benchmark reinforcement-learning and imitation-learning agents and demonstrate that the agents are quite far from human-level coordination ability and deviate significantly from the expert trajectories.",
        "year": 2022,
        "authors": "Eugene Vinitsky and Nathan Lichtlé and Xiaomeng Yang and Brandon Amos and Jakob Foerster"
      },
      {
        "title": "Torchrl: A data-driven decision-making library for pytorch",
        "abstract": "PyTorch has ascended as a premier machine learning framework, yet it lacks a native and comprehensive library for decision and control tasks suitable for large development teams dealing with complex real-world data and environments. To address this issue, we propose TorchRL, a generalistic control library for PyTorch that provides well-integrated, yet standalone components. We introduce a new and flexible PyTorch primitive, the TensorDict, which facilitates streamlined algorithm development across the many branches of Reinforcement Learning (RL) and control. We provide a detailed description of the building blocks and an extensive overview of the library across domains and tasks. Finally, we experimentally demonstrate its reliability and flexibility and show comparative benchmarks to demonstrate its computational efficiency. TorchRL fosters long-term support and is publicly available on GitHub for greater reproducibility and collaboration within the research community. The code is open-sourced on GitHub.",
        "year": 2023,
        "authors": "Albert Bou and Matteo Bettini and Sebastian Dittert and Vikash Kumar and Shagun Sodhani and Xiaomeng Yang and Gianni De Fabritiis and Vincent Moens"
      },
      {
        "title": "Megalodon: Efficient llm pretraining and inference with unlimited context length",
        "abstract": "The quadratic complexity and weak length extrapolation of Transformers limits their ability to scale to long sequences, and while sub-quadratic solutions like linear attention and state space models exist, they empirically underperform Transformers in pretraining efficiency and downstream task accuracy. We introduce MEGALODON, an neural architecture for efficient sequence modeling with unlimited context length. MEGALODON inherits the architecture of MEGA (exponential moving average with gated attention), and further introduces multiple technical components to improve its capability and stability, including complex exponential moving average (CEMA), timestep normalization layer, normalized attention mechanism and pre-norm with two-hop residual configuration. In a controlled head-to-head comparison with LLAMA2, MEGALODON achieves better efficiency than Transformer in the scale of 7 billion parameters and 2 trillion training tokens. MEGALODON reaches a training loss of 1.70, landing mid-way between LLAMA2-7B (1.75) and LLAMA2-13B (1.67). This result is robust throughout a wide range of benchmarks, where MEGALODON consistently outperforms Transformers across different tasks, domains, and modalities.",
        "year": 2024,
        "authors": "Xuezhe Ma and Xiaomeng Yang and Wenhan Xiong and Beidi Chen and Lili Yu and Hao Zhang and Jonathan May and Luke Zettlemoyer and Omer Levy and Chunting Zhou"
      }
    ],
    "Fsz9BAUAAAAJ": [
      {
        "title": "Network information theory",
        "abstract": "This comprehensive treatment of network information theory and its applications provides the first unified coverage of both classical and recent results. With an approach that balances the introduction of new models and new coding techniques, readers are guided through Shannon's point-to-point information theory, single-hop networks, multihop networks, and extensions to distributed computing, secrecy, wireless communication, and networking. Elementary mathematical tools and techniques are used throughout, requiring only basic knowledge of probability, whilst unified proofs of coding theorems are based on a few simple lemmas, making the text accessible to newcomers. Key topics covered include successive cancellation and superposition coding, MIMO wireless communication, network coding, and cooperative relaying. Also covered are feedback and interactive communication, capacity approximations and scaling laws, and asynchronous and random access channels. This book is ideal for use in the classroom, for self-study, and as a reference for researchers and engineers in industry and academia.",
        "year": 2011,
        "authors": "Abbas El Gamal and Young-Han Kim"
      },
      {
        "title": "Noisy network coding",
        "abstract": "A noisy network coding scheme for communicating messages between multiple sources and destinations over a general noisy network is presented. For multi-message multicast networks, the scheme naturally generalizes network coding over noiseless networks by Ahlswede, Cai, Li, and Yeung, and compress-forward coding for the relay channel by Cover and El Gamal to discrete memoryless and Gaussian networks. The scheme also extends the results on coding for wireless relay networks and deterministic networks by Avestimehr, Diggavi, and Tse, and coding for wireless erasure networks by Dana, Gowaikar, Palanki, Hassibi, and Effros. The scheme involves lossy compression by the relay as in the compress-forward coding scheme for the relay channel. However, unlike previous compress-forward schemes in which independent messages are sent over multiple blocks, the same message is sent multiple …",
        "year": 2011,
        "authors": "Sung Hoon Lim and Young-Han Kim and Abbas El Gamal and Sae-Young Chung"
      },
      {
        "title": "Lecture notes on network information theory",
        "abstract": "This set of lecture notes is a much expanded version of lecture notes developed and used by the first author in courses at Stanford University from 1981 to 1984 and more recently beginning in 2002. The joint development of this set of lecture notes began in 2006 when the second author started teaching a course on network information theory at UCSD. Earlier versions of the lecture notes have also been used in courses at EPFL and UC Berkeley by the first author, at Seoul National University by the second author, and at the Chinese University of Hong Kong by Chandra Nair.",
        "year": 2010,
        "authors": "Abbas El Gamal and Young-Han Kim"
      }
    ],
    "a5nY-pYAAAAJ": [
      {
        "title": "Viability Theory: New Directions",
        "abstract": "Viability theory designs and develops mathematical and algorithmic methods for investigating the adaptation to viability constraints of evolutions governed by complex systems under uncertainty that are found in many domains involving living beings, from biological evolution to economics, from environmental sciences to financial markets, from control theory and robotics to cognitive sciences. It involves interdisciplinary investigations spanning fields that have traditionally developed in isolation. The purpose of this book is to present an initiation to applications of viability theory, explaining and motivating the main concepts and illustrating them with numerous numerical examples taken from various fields.",
        "year": 2011,
        "authors": "Jean-Pierre Aubin and Alexandre Bayen and Patrick Saint-Pierre"
      },
      {
        "title": "The surprising effectiveness of ppo in cooperative multi-agent games",
        "abstract": "Proximal Policy Optimization (PPO) is a ubiquitous on-policy reinforcement learning algorithm but is significantly less utilized than off-policy learning algorithms in multi-agent settings. This is often due to the belief that PPO is significantly less sample efficient than off-policy methods in multi-agent systems. In this work, we carefully study the performance of PPO in cooperative multi-agent settings. We show that PPO-based multi-agent algorithms achieve surprisingly strong performance in four popular multi-agent testbeds: the particle-world environments, the StarCraft multi-agent challenge, the Hanabi challenge, and Google Research Football, with minimal hyperparameter tuning and without any domain-specific algorithmic modifications or architectures. Importantly, compared to competitive off-policy methods, PPO often achieves competitive or superior results in both final returns and sample efficiency. Finally, through ablation studies, we analyze implementation and hyperparameter factors that are critical to PPO's empirical performance, and give concrete practical suggestions regarding these factors. Our results show that when using these practices, simple PPO-based methods are a strong baseline in cooperative multi-agent reinforcement learning. Source code is released at https://github. com/marlbenchmark/on-policy.",
        "year": 2022,
        "authors": "Chao Yu and Akash Velu and Eugene Vinitsky and Jiaxuan Gao and Yu Wang and Alexandre Bayen and Yi Wu"
      },
      {
        "title": "A time-dependent Hamilton-Jacobi formulation of reachable sets for continuous dynamic games",
        "abstract": "We describe and implement an algorithm for computing the set of reachable states of a continuous dynamic game. The algorithm is based on a proof that the reachable set is the zero sublevel set of the viscosity solution of a particular time-dependent Hamilton-Jacobi-Isaacs partial differential equation. While alternative techniques for computing the reachable set have been proposed, the differential game formulation allows treatment of nonlinear systems with inputs and uncertain parameters. Because the time-dependent equation's solution is continuous and defined throughout the state space, methods from the level set literature can be used to generate more accurate approximations than are possible for formulations with potentially discontinuous solutions. A numerical implementation of our formulation is described and has been released on the web. Its correctness is verified through a two vehicle, three …",
        "year": 2005,
        "authors": "Ian M Mitchell and Alexandre M Bayen and Claire J Tomlin"
      }
    ],
    "gYiCq88AAAAJ": [
      {
        "title": "Caffe: Convolutional architecture for fast feature embedding",
        "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community …",
        "year": 2014,
        "authors": "Yangqing Jia and Evan Shelhamer and Jeff Donahue and Sergey Karayev and Jonathan Long and Ross Girshick and Sergio Guadarrama and Trevor Darrell"
      },
      {
        "title": "Long-term recurrent convolutional networks for visual recognition and description",
        "abstract": "Models comprised of deep convolutional network layers have dominated recent image interpretation tasks; we investigate whether models which are also compositional, or\" deep\", temporally are effective on tasks involving visual sequences or label sequences. We develop a novel recurrent convolutional architecture suitable for large-scale visual learning which is end-to-end trainable, and demonstrate the value of these models on benchmark video recognition tasks, image to sentence generation problems, and video narration challenges. In contrast to current models which assume a fixed spatio-temporal receptive field or simple temporal averaging for sequential processing, recurrent convolutional models are\" doubly deep\" in that they can be compositional in spatial and temporal\" layers\". Such models may have advantages when target concepts are complex and/or training data are limited. Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. Long-term RNN models are appealing in that they directly can map variable length inputs (ie video frames) to variable length outputs (ie natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent long-term models are directly connected to state-of-the-art visual convnet models and can jointly trained, updating temporal dynamics and convolutional perceptual representations simultaneously. Our results show such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined and/or optimized.",
        "year": 2015,
        "authors": "Jeffrey Donahue and Lisa Anne Hendricks and Sergio Guadarrama and Marcus Rohrbach and Subhashini Venugopalan and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Speed/accuracy trade-offs for modern convolutional object detectors",
        "abstract": "The goal of this paper is to serve as a guide for selecting a detection architecture that achieves the right speed/memory/accuracy balance for a given application and platform. To this end, we investigate various ways to trade accuracy for speed and memory usage in modern convolutional object detection systems. A number of successful systems have been proposed in recent years, but apples-to-apples comparisons are difficult due to different base feature extractors (eg, VGG, Residual Networks), different default image resolutions, as well as different hardware and software platforms. We present a unified implementation of the Faster R-CNN (Ren et al., 2015), R-FCN (Dai et al., 2016) and SSD (Liu et al., 2016) systems, which we view as\" meta-architectures\" and trace out the speed/accuracy trade-off curve created by using alternative feature extractors and varying other critical parameters such as image size within each of these meta-architectures. On one extreme end of this spectrum where speed and memory are critical, we present a detector that achieves real time speeds and can be deployed on a mobile device. On the opposite end in which accuracy is critical, we present a detector that achieves state-of-the-art performance measured on the COCO detection task.",
        "year": 2017,
        "authors": "Jonathan Huang and Vivek Rathod and Chen Sun and Menglong Zhu and Anoop Korattikara and Alireza Fathi and Ian Fischer and Zbigniew Wojna and Yang Song and Sergio Guadarrama and Kevin Murphy"
      }
    ],
    "lRUi-A8AAAAJ": [
      {
        "title": "Mobile sensor network deployment using potential fields: A distributed, scalable solution to the area coverage problem",
        "abstract": "This paper considers the problem of deploying a mobile sensor network in an unknown environment. A mobile sensor network is composed of a distributed collection of nodes, each of which has sensing, computation, communication and locomotion capabilities. Such networks are capable of self-deployment; i.e., starting from some compact initial configuration, the nodes in the network can spread out such that the area ‘covered’ by the network is maximized. In this paper, we present a potential-field-based approach to deployment. The fields are constructed such that each node is repelled by both obstacles and by other nodes, thereby forcing the network to spread itself throughout the environment. The approach is both distributed and scalable.",
        "year": 2002,
        "authors": "Andrew Howard and Maja J Matarić and Gaurav S Sukhatme"
      },
      {
        "title": "Connecting the physical world with pervasive networks",
        "abstract": "This article addresses the challenges and opportunities of instrumenting the physical world with pervasive networks of sensor-rich, embedded computation. The authors present a taxonomy of emerging systems and outline the enabling technological developments.",
        "year": 2002,
        "authors": "Deborah Estrin and David Culler and Kristofer Pister and Gaurav Sukhatme"
      },
      {
        "title": "An incremental self-deployment algorithm for mobile sensor networks",
        "abstract": "This paper describes an incremental deployment algorithm for mobile sensor networks. A mobile sensor network is a distributed collection of nodes, each of which has sensing, computation, communication and locomotion capabilities. The algorithm described in this paper will deploy such nodes one-at-a-time into an unknown environment, with each node making use of information gathered by previously deployed nodes to determine its deployment location. The algorithm is designed to maximize network ‘coverage’ while simultaneously ensuring that nodes retain line-of-sight relationships with one another. This latter constraint arises from the need to localize the nodes in an unknown environment: in our previous work on team localization (A. Howard, M.J. Matarić, and G.S. Sukhatme, in Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems, EPFL, Switzerland, 2002 …",
        "year": 2002,
        "authors": "Andrew Howard and Maja J Matarić and Gaurav S Sukhatme"
      }
    ],
    "W8VIEZgAAAAJ": [
      {
        "title": "Faster R-CNN: Towards real-time object detection with region proposal networks",
        "abstract": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully-convolutional network that simultaneously predicts object bounds and objectness scores at each position. RPNs are trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. With a simple alternating optimization, RPN and Fast R-CNN can be trained to share convolutional features. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007 (73.2% mAP) and 2012 (70.4% mAP) using 300 proposals per image. Code is available at https://github. com/ShaoqingRen/faster_rcnn.",
        "year": 2015,
        "authors": "Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun"
      },
      {
        "title": "You only look once: Unified, real-time object detection",
        "abstract": "We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.",
        "year": 2016,
        "authors": "Joseph Redmon and Santosh Divvala and Ross Girshick and Ali Farhadi"
      },
      {
        "title": "Microsoft coco: Common objects in context",
        "abstract": "We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and …",
        "year": 2014,
        "authors": "Tsung-Yi Lin and Michael Maire and Serge Belongie and James Hays and Pietro Perona and Deva Ramanan and Piotr Dollár and C Lawrence Zitnick"
      }
    ],
    "YsXNU78AAAAJ": [
      {
        "title": "Apache spark: a unified engine for big data processing",
        "abstract": "This open source computing framework unifies streaming, batch, and interactive big data workloads to unlock new applications.",
        "year": 2016,
        "authors": "Matei Zaharia and Reynold S Xin and Patrick Wendell and Tathagata Das and Michael Armbrust and Ankur Dave and Xiangrui Meng and Josh Rosen and Shivaram Venkataraman and Michael J Franklin and Ali Ghodsi and Joseph Gonzalez and Scott Shenker and Ion Stoica"
      },
      {
        "title": "Mesos: A platform for {Fine-Grained} resource sharing in the data center",
        "abstract": "We present Mesos, a platform for sharing commodity clusters between multiple diverse cluster computing frameworks, such as Hadoop and MPI. Sharing improves cluster utilization and avoids per-framework data replication. Mesos shares resources in a fine-grained manner, allowing frameworks to achieve data locality by taking turns reading data stored on each machine. To support the sophisticated schedulers of today’s frameworks, Mesos introduces a distributed two-level scheduling mechanism called resource offers. Mesos decides how many resources to offer each framework, while frameworks decide which resources to accept and which computations to run on them. Our results show that Mesos can achieve near-optimal data locality when sharing the cluster among diverse frameworks, can scale to 50,000 (emulated) nodes, and is resilient to failures.",
        "year": 2011,
        "authors": "Benjamin Hindman and Andy Konwinski and Matei Zaharia and Ali Ghodsi and Anthony D Joseph and Randy Katz and Scott Shenker and Ion Stoica"
      },
      {
        "title": "Spark sql: Relational data processing in spark",
        "abstract": "Spark SQL is a new module in Apache Spark that integrates relational processing with Spark's functional programming API. Built on our experience with Shark, Spark SQL lets Spark programmers leverage the benefits of relational processing (e.g. declarative queries and optimized storage), and lets SQL users call complex analytics libraries in Spark (e.g. machine learning). Compared to previous systems, Spark SQL makes two main additions. First, it offers much tighter integration between relational and procedural processing, through a declarative DataFrame API that integrates with procedural Spark code. Second, it includes a highly extensible optimizer, Catalyst, built using features of the Scala programming language, that makes it easy to add composable rules, control code generation, and define extension points. Using Catalyst, we have built a variety of features (e.g. schema inference for JSON, machine …",
        "year": 2015,
        "authors": "Michael Armbrust and Reynold S Xin and Cheng Lian and Yin Huai and Davies Liu and Joseph K Bradley and Xiangrui Meng and Tomer Kaftan and Michael J Franklin and Ali Ghodsi and Matei Zaharia"
      }
    ],
    "jM23vRsKxuIC": [
      {
        "title": "Explosive percolation in random networks",
        "abstract": "Networks in which the formation of connections is governed by a random process often undergo a percolation transition, wherein around a critical point, the addition of a small number of connections causes a sizable fraction of the network to suddenly become linked together. Typically such transitions are continuous, so that the percentage of the network linked together tends to zero right above the transition point. Whether percolation transitions could be discontinuous has been an open question. Here, we show that incorporating a limited amount of choice in the classic Erdös-Rényi network formation model causes its percolation transition to become discontinuous.",
        "year": 2009,
        "authors": "Dimitris Achlioptas and Raissa M D'souza and Joel Spencer"
      },
      {
        "title": "Suppressing cascades of load in interdependent networks",
        "abstract": "Understanding how interdependence among systems affects cascading behaviors is increasingly important across many fields of science and engineering. Inspired by cascades of load shedding in coupled electric grids and other infrastructure, we study the Bak–Tang–Wiesenfeld sandpile model on modular random graphs and on graphs based on actual, interdependent power grids. Starting from two isolated networks, adding some connectivity between them is beneficial, for it suppresses the largest cascades in each system. Too much interconnectivity, however, becomes detrimental for two reasons. First, interconnections open pathways for neighboring networks to inflict large cascades. Second, as in real infrastructure, new interconnections increase capacity and total possible load, which fuels even larger cascades. Using a multitype branching process and simulations we show these effects and estimate the …",
        "year": 2012,
        "authors": "Charles D Brummitt and Raissa M D’Souza and Elizabeth A Leicht"
      },
      {
        "title": "Target control of complex networks",
        "abstract": "Controlling large natural and technological networks is an outstanding challenge. It is typically neither feasible nor necessary to control the entire network, prompting us to explore target control: the efficient control of a preselected subset of nodes. We show that the structural controllability approach used for full control overestimates the minimum number of driver nodes needed for target control. Here we develop an alternate ‘k-walk’theory for directed tree networks, and we rigorously prove that one node can control a set of target nodes if the path length to each target node is unique. For more general cases, we develop a greedy algorithm to approximate the minimum set of driver nodes sufficient for target control. We find that degree heterogeneous networks are target controllable with higher efficiency than homogeneous networks and that the structure of many real-world networks are suitable for efficient target control.",
        "year": 2014,
        "authors": "Jianxi Gao and Yang-Yu Liu and Raissa M D'souza and Albert-László Barabási"
      }
    ],
    "lJwPbcUAAAAJ": [
      {
        "title": "Deepmimic: Example-guided deep reinforcement learning of physics-based character skills",
        "abstract": "A longstanding goal in character animation is to combine data-driven specification of behavior with a system that can execute a similar behavior in a physical simulation, thus enabling realistic responses to perturbations and environmental variation. We show that well-known reinforcement learning (RL) methods can be adapted to learn robust control policies capable of imitating a broad range of example motion clips, while also learning complex recoveries, adapting to changes in morphology, and accomplishing user-specified goals. Our method handles keyframed motions, highly-dynamic actions such as motion-captured flips and spins, and retargeted motions. By combining a motion-imitation objective with a task objective, we can train characters that react intelligently in interactive settings, e.g., by walking in a desired direction or throwing a ball at a user-specified target. This approach thus combines the …",
        "year": 2018,
        "authors": "Xue Bin Peng and Pieter Abbeel and Sergey Levine and Michiel Van de Panne"
      },
      {
        "title": "DeepLoco: Dynamic Locomotion Skills Using Hierarchical Deep Reinforcement Learning",
        "abstract": "Learning physics-based locomotion skills is a difficult problem, leading to solutions that typically exploit prior knowledge of various forms. In this paper we aim to learn a variety of environment-aware locomotion skills with a limited amount of prior knowledge. We adopt a two-level hierarchical control framework. First, low-level controllers are learned that operate at a fine timescale and which achieve robust walking gaits that satisfy stepping-target and style objectives. Second, high-level controllers are then learned which plan at the timescale of steps by invoking desired step targets for the low-level controller. The high-level controller makes decisions directly based on high-dimensional inputs, including terrain maps or other suitable representations of the surroundings. Both levels of the control policy are trained using deep reinforcement learning. Results are demonstrated on a simulated 3D biped. Low-level …",
        "year": 2017,
        "authors": "Xue Bin Peng and Glen Berseth and KangKang Yin and Michiel van de Panne"
      },
      {
        "title": "Simbicon: Simple biped locomotion control",
        "abstract": "Physics-based simulation and control of biped locomotion is difficult because bipeds are unstable, underactuated, high-dimensional dynamical systems. We develop a simple control strategy that can be used to generate a large variety of gaits and styles in real-time, including walking in all directions (forwards, backwards, sideways, turning), running, skipping, and hopping. Controllers can be authored using a small number of parameters, or their construction can be informed by motion capture data. The controllers are applied to 2D and 3D physically-simulated character models. Their robustness is demonstrated with respect to pushes in all directions, unexpected steps and slopes, and unexpected variations in kinematic and dynamic parameters. Direct transitions between controllers are demonstrated as well as parameterized control of changes in direction and speed. Feedback-error learning is applied to learn …",
        "year": 2007,
        "authors": "KangKang Yin and Kevin Loken and Michiel Van de Panne"
      }
    ],
    "h3qMa1kAAAAJ": [
      {
        "title": "Superhuman performance of surgical tasks by robots using iterative learning from human-guided demonstrations",
        "abstract": "In the future, robotic surgical assistants may assist surgeons by performing specific subtasks such as retraction and suturing to reduce surgeon tedium and reduce the duration of some operations. We propose an apprenticeship learning approach that has potential to allow robotic surgical assistants to autonomously execute specific trajectories with superhuman performance in terms of speed and smoothness. In the first step, we record a set of trajectories using human-guided backdriven motions of the robot. These are then analyzed to extract a smooth reference trajectory, which we execute at gradually increasing speeds using a variant of iterative learning control. We evaluate this approach on two representative tasks using the Berkeley Surgical Robots: a figure eight trajectory and a two handed knot-tie, a tedious suturing sub-task required in many surgical procedures. Results suggest that the approach enables (i …",
        "year": 2010,
        "authors": "Jur Van Den Berg and Stephen Miller and Daniel Duckworth and Humphrey Hu and Andrew Wan and Xiao-Yu Fu and Ken Goldberg and Pieter Abbeel"
      },
      {
        "title": "Cooperative control and modeling for narrow passage traversal with an ornithopter MAV and lightweight ground station",
        "abstract": "The power, size, and weight constraints of micro air vehicles (MAVs) limit their on-board sensing and computational resources. Ground vehicles have less mobility than MAVs, but relaxed size constraints, and typically more computing power. These specializations present many opportunities for robot-robot cooperation. In this work, we demonstrate cooperative target-seeking between a 13 gram ornithopter MAV and a lightweight ground station using computer vision. We develop models for the ornithopter, ground station, and cooperative system dynamics. We determine model parameters of the real systems through experimental system identification. Finally, we verify those models using experiments on narrow passage traversal, and arrive at a cooperative system model which accurately predicts the backwardsreachable region for successfully negotiating ornithopter flight through narrow passages.We also introduce a new ornithopter MAV, the 13 gram H2Bird. It features clap and fling wings, improves upon previous designs by utilizing a carbon fiber airframe, tail rotor, and elevator, and carries a 2.8 gram payload. We augment the ornithopter’s built-in gyroscope-based control with a lightweight ground station, which has power and weight requirements appropriate for deployment on ground vehicles with 10 gram payloads. The ground station provides heading estimates to the ornithopter by running a real-time motion tracking algorithm over a live video stream.",
        "year": 2013,
        "authors": "Ryan C Julian and Cameron J Rose and Humphrey Hu and Ronald S Fearing"
      },
      {
        "title": "Parametric covariance prediction for heteroscedastic noise",
        "abstract": "The ubiquitous additive Gaussian noise model is favored in statistical modeling applications for its flexibility and ease of use. Often noise is assumed to be well-represented by a constant covariance, while in reality error characteristics may change predictably. We present an efficient parametric covariance predictor based on the modified Cholesky decomposition that maps from features of the input to covariance matrices. In addition, we discuss fitting the predictor parameters using noise samples with simple regularization techniques. We demonstrate our approach by estimating observation covariances for range-bearing localization with simulated and experimental datasets and show that this results in increased filtering performance compared to traditional covariance adaptation and constant covariance baselines.",
        "year": 2015,
        "authors": "Humphrey Hu and George Kantor"
      }
    ],
    "siuZCjUAAAAJ": [
      {
        "title": "Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning",
        "abstract": "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.",
        "year": 2025,
        "authors": "Daya Guo and Dejian Yang and Haowei Zhang and Junxiao Song and Ruoyu Zhang and Runxin Xu and Qihao Zhu and Shirong Ma and Peiyi Wang and Xiao Bi and Xiaokang Zhang and Xingkai Yu and Yu Wu and ZF Wu and Zhibin Gou and Zhihong Shao and Zhuoshu Li and Ziyi Gao and Aixin Liu and Bing Xue and Bingxuan Wang and Bochao Wu and Bei Feng and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Qu and Hui Li and Jianzhong Guo and Jiashi Li and Jiawei Wang and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and JL Cai and Jiaqi Ni and Jian Liang and Jin Chen and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Liang Zhao and Litong Wang and Liyue Zhang and Lei Xu and Leyi Xia and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Meng Li and Miaojun Wang and Mingming Li and Ning Tian and Panpan Huang and Peng Zhang and Qiancheng Wang and Qinyu Chen and Qiushi Du and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and RJ Chen and RL Jin and Ruyi Chen and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shengfeng Ye and Shiyu Wang and Shuiping Yu and Shunfeng Zhou and Shuting Pan and SS Li and Shuang Zhou and Shaoqing Wu and Tao Yun and Tian Pei and Tianyu Sun and T Wang and Wangding Zeng and Wanjia Zhao and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and WL Xiao and Wei An and Xiaodong Liu and Xiaohan Wang and Xiaokang Chen and Xiaotao Nie and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and XQ Li and Xiangyue Jin and Xiaojin Shen and Xiaosha Chen and Xiaowen Sun and Xiaoxiang Wang and Xinnan Song and Xinyi Zhou and Xianzu Wang and Xinxia Shan and YK Li and YQ Wang and YX Wei and Yang Zhang and Yanhong Xu and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Wang and Yi Yu and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He"
      },
      {
        "title": "Deepseek-v3 technical report",
        "abstract": "We present DeepSeek-V3, a strong Mixture-of-Experts (MoE) language model with 671B total parameters with 37B activated for each token. To achieve efficient inference and cost-effective training, DeepSeek-V3 adopts Multi-head Latent Attention (MLA) and DeepSeekMoE architectures, which were thoroughly validated in DeepSeek-V2. Furthermore, DeepSeek-V3 pioneers an auxiliary-loss-free strategy for load balancing and sets a multi-token prediction training objective for stronger performance. We pre-train DeepSeek-V3 on 14.8 trillion diverse and high-quality tokens, followed by Supervised Fine-Tuning and Reinforcement Learning stages to fully harness its capabilities. Comprehensive evaluations reveal that DeepSeek-V3 outperforms other open-source models and achieves performance comparable to leading closed-source models. Despite its excellent performance, DeepSeek-V3 requires only 2.788M H800 GPU hours for its full training. In addition, its training process is remarkably stable. Throughout the entire training process, we did not experience any irrecoverable loss spikes or perform any rollbacks. The model checkpoints are available at https://github.com/deepseek-ai/DeepSeek-V3.",
        "year": 2024,
        "authors": "Aixin Liu and Bei Feng and Bing Xue and Bingxuan Wang and Bochao Wu and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Daya Guo and Dejian Yang and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Haowei Zhang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Li and Hui Qu and JL Cai and Jian Liang and Jianzhong Guo and Jiaqi Ni and Jiashi Li and Jiawei Wang and Jin Chen and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and Junxiao Song and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Lei Xu and Leyi Xia and Liang Zhao and Litong Wang and Liyue Zhang and Meng Li and Miaojun Wang and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Mingming Li and Ning Tian and Panpan Huang and Peiyi Wang and Peng Zhang and Qiancheng Wang and Qihao Zhu and Qinyu Chen and Qiushi Du and RJ Chen and RL Jin and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and Runxin Xu and Ruoyu Zhang and Ruyi Chen and SS Li and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shaoqing Wu and Shengfeng Ye and Shirong Ma and Shiyu Wang and Shuang Zhou and Shuiping Yu and Shunfeng Zhou and Shuting Pan and T Wang and Tao Yun and Tian Pei and Tianyu Sun and WL Xiao and Wangding Zeng and Wanjia Zhao and Wei An and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and XQ Li and Xiangyue Jin and Xianzu Wang and Xiao Bi and Xiaodong Liu and Xiaohan Wang and Xiaojin Shen and Xiaokang Chen and Xiaokang Zhang and Xiaosha Chen and Xiaotao Nie and Xiaowen Sun and Xiaoxiang Wang and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xingkai Yu and Xinnan Song and Xinxia Shan and Xinyi Zhou and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and YK Li and YQ Wang and YX Wei and YX Zhu and Yang Zhang and Yanhong Xu and Yanping Huang and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Li and Yaohui Wang and Yi Yu and Yi Zheng and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Ying Tang and Yishi Piao"
      },
      {
        "title": "MedDialog: Large-scale medical dialogue datasets",
        "abstract": "Medical dialogue systems are promising in assisting in telemedicine to increase access to healthcare services, improve the quality of patient care, and reduce medical costs. To facilitate the research and development of medical dialogue systems, we build large-scale medical dialogue datasets–MedDialog, which contain 1) a Chinese dataset with 3.4 million conversations between patients and doctors, 11.3 million utterances, 660.2 million tokens, covering 172 specialties of diseases, and 2) an English dataset with 0.26 million conversations, 0.51 million utterances, 44.53 million tokens, covering 96 specialties of diseases. To our best knowledge, MedDialog is the largest medical dialogue dataset to date. We pretrain several dialogue generation models on the Chinese MedDialog dataset, including Transformer, GPT, BERT-GPT, and compare their performance. It is shown that models trained on MedDialog are able to generate clinically correct and doctor-like medical dialogues. We also study the transferability of models trained on MedDialog to low-resource medical dialogue generation tasks. It is shown that via transfer learning which finetunes the models pretrained on MedDialog, the performance on medical dialogue generation tasks with small datasets can be greatly improved, as shown in human evaluation and automatic evaluation. The datasets and code are available at https://github. com/UCSD-AI4H/Medical-Dialogue-System",
        "year": 2020,
        "authors": "Guangtao Zeng and Wenmian Yang and Zeqian Ju and Yue Yang and Sicheng Wang and Ruisi Zhang and Meng Zhou and Jiaqi Zeng and Xiangyu Dong and Ruoyu Zhang and Hongchao Fang and Penghui Zhu and Shu Chen and Pengtao Xie"
      }
    ],
    "VT7peyEAAAAJ": [
      {
        "title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Soft actor-critic algorithms and applications",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Reinforcement learning with deep energy-based policies",
        "abstract": "We propose a method for learning expressive energy-based policies for continuous states and actions, which has been feasible only in tabular domains before. We apply our method to learning maximum entropy policies, resulting into a new algorithm, called soft Q-learning, that expresses the optimal policy via a Boltzmann distribution. We use the recently proposed amortized Stein variational gradient descent to learn a stochastic sampling network that approximates samples from this distribution. The benefits of the proposed algorithm include improved exploration and compositionality that allows transferring skills between tasks, which we confirm in simulated experiments with swimming and walking robots. We also draw a connection to actor-critic methods, which can be viewed performing approximate inference on the corresponding energy-based model.",
        "year": 2017,
        "authors": "Tuomas Haarnoja and Haoran Tang and Pieter Abbeel and Sergey Levine"
      }
    ],
    "Hyhp_zUAAAAJ": [
      {
        "title": "Research through design as a method for interaction design research in HCI",
        "abstract": "For years the HCI community has struggled to integrate design in research and practice. While design has gained a strong foothold in practice, it has had much less impact on the HCI research community. In this paper we propose a new model for interaction design research within HCI. Following a research through design approach, designers produce novel integrations of HCI research in an attempt to make the right thing: a product that transforms the world from its current state to a preferred state. This model allows interaction designers to make research contributions based on their strength in addressing under-constrained problems. To formalize this model, we provide a set of four lenses for evaluating the research contribution and a set of three examples to illustrate the benefits of this type of research.",
        "year": 2007,
        "authors": "John Zimmerman and Jodi Forlizzi and Shelley Evenson"
      },
      {
        "title": "Understanding experience in interactive systems",
        "abstract": "Understanding experience is a critical issue for a variety of professions, especially design. To understand experience and the user experience that results from interacting with products, designers conduct situated research activities focused on the interactions between people and products, and the experience that results. This paper attempts to clarify experience in interactive systems. We characterize current approaches to experience from a number of disciplines, and present a framework for designing experience for interactive system. We show how the framework can be applied by members of a multidisciplinary team to understand and generate the kinds of interactions and experiences new product and system designs might offer.",
        "year": 2004,
        "authors": "Jodi Forlizzi and Katja Battarbee"
      },
      {
        "title": "A stage-based model of personal informatics systems",
        "abstract": "People strive to obtain self-knowledge. A class of systems called personal informatics is appearing that help people collect and reflect on personal information. However, there is no comprehensive list of problems that users experience using these systems, and no guidance for making these systems more effective. To address this, we conducted surveys and interviews with people who collect and reflect on personal information. We derived a stage-based model of personal informatics systems composed of five stages (preparation, collection, integration, reflection, and action) and identified barriers in each of the stages. These stages have four essential properties: barriers cascade to later stages; they are iterative; they are user-driven and/or system-driven; and they are uni-faceted or multi-faceted. From these properties, we recommend that personal informatics systems should 1) be designed in a holistic manner …",
        "year": 2010,
        "authors": "Ian Li and Anind Dey and Jodi Forlizzi"
      }
    ],
    "DYUloYkAAAAJ": [
      {
        "title": "Entropy-sgd: Biasing gradient descent into wide valleys",
        "abstract": "This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in the sharp valleys. Conceptually, our algorithm resembles two nested loops of SGD where we use Langevin dynamics in the inner loop to compute the gradient of the local entropy before each update of the weights. We show that the new objective has a smoother energy landscape and show improved generalization over SGD using uniform stability, under …",
        "year": 2019,
        "authors": "Pratik Chaudhari and Anna Choromanska and Stefano Soatto and Yann LeCun and Carlo Baldassi and Christian Borgs and Jennifer Chayes and Levent Sagun and Riccardo Zecchina"
      },
      {
        "title": "Unreasonable effectiveness of learning neural networks: From accessible states and robust ensembles to basic algorithmic schemes",
        "abstract": "In artificial neural networks, learning from data is a computationally demanding task in which a large number of connection weights are iteratively tuned through stochastic-gradient-based heuristic processes over a cost function. It is not well understood how learning occurs in these systems, in particular how they avoid getting trapped in configurations with poor computational performance. Here, we study the difficult case of networks with discrete weights, where the optimization landscape is very rough even for simple architectures, and provide theoretical and numerical evidence of the existence of rare—but extremely dense and accessible—regions of configurations in the network weight space. We define a measure, the robust ensemble (RE), which suppresses trapping by isolated configurations and amplifies the role of these dense regions. We analytically compute the RE in some exactly solvable models and …",
        "year": 2016,
        "authors": "Carlo Baldassi and Christian Borgs and Jennifer T Chayes and Alessandro Ingrosso and Carlo Lucibello and Luca Saglietti and Riccardo Zecchina"
      },
      {
        "title": "Fast and accurate multivariate Gaussian modeling of protein families: predicting residue contacts and protein-interaction partners",
        "abstract": "In the course of evolution, proteins show a remarkable conservation of their three-dimensional structure and their biological function, leading to strong evolutionary constraints on the sequence variability between homologous proteins. Our method aims at extracting such constraints from rapidly accumulating sequence data, and thereby at inferring protein structure and function from sequence information alone. Recently, global statistical inference methods (e.g. direct-coupling analysis, sparse inverse covariance estimation) have achieved a breakthrough towards this aim, and their predictions have been successfully implemented into tertiary and quaternary protein structure prediction methods. However, due to the discrete nature of the underlying variable (amino-acids), exact inference requires exponential time in the protein length, and efficient approximations are needed for practical applicability. Here we propose a very efficient multivariate Gaussian modeling approach as a variant of direct-coupling analysis: the discrete amino-acid variables are replaced by continuous Gaussian random variables. The resulting statistical inference problem is efficiently and exactly solvable. We show that the quality of inference is comparable or superior to the one achieved by mean-field approximations to inference with discrete variables, as done by direct-coupling analysis. This is true for (i) the prediction of residue-residue contacts in proteins, and (ii) the identification of protein-protein interaction partner in bacterial signal transduction. An implementation of our multivariate Gaussian approach is available at the website http://areeweb.polito.it/ricerca/cmp/code.",
        "year": 2014,
        "authors": "Carlo Baldassi and Marco Zamparo and Christoph Feinauer and Andrea Procaccini and Riccardo Zecchina and Martin Weigt and Andrea Pagnani"
      }
    ],
    "ySwF8ioAAAAJ": [
      {
        "title": "On the capacity region for index coding",
        "abstract": "A new inner bound on the capacity region of the general index coding problem is established. Unlike most existing bounds that are based on graph theoretic or algebraic tools, the bound relies on a random coding scheme and optimal decoding, and has a simple polymatroidal single-letter expression. The utility of the inner bound is demonstrated by examples that include the capacity region for all index coding problems with up to five messages (there are 9846 nonisomorphic ones).",
        "year": 2013,
        "authors": "Fatemeh Arbabjolfaei and Bernd Bandemer and Young-Han Kim and Eren Şaşoğlu and Lele Wang"
      },
      {
        "title": "Specformer: Spectral graph neural networks meet transformers",
        "abstract": "Spectral graph neural networks (GNNs) learn graph representations via spectral-domain graph convolutions. However, most existing spectral graph filters are scalar-to-scalar functions, i.e., mapping a single eigenvalue to a single filtered value, thus ignoring the global pattern of the spectrum. Furthermore, these filters are often constructed based on some fixed-order polynomials, which have limited expressiveness and flexibility. To tackle these issues, we introduce Specformer, which effectively encodes the set of all eigenvalues and performs self-attention in the spectral domain, leading to a learnable set-to-set spectral filter. We also design a decoder with learnable bases to enable non-local graph convolution. Importantly, Specformer is equivariant to permutation. By stacking multiple Specformer layers, one can build a powerful spectral GNN. On synthetic datasets, we show that our Specformer can better recover ground-truth spectral filters than other spectral GNNs. Extensive experiments of both node-level and graph-level tasks on real-world graph datasets show that our Specformer outperforms state-of-the-art GNNs and learns meaningful spectrum patterns. Code and data are available at https://github.com/bdy9527/Specformer.",
        "year": 2023,
        "authors": "Deyu Bo and Chuan Shi and Lele Wang and Renjie Liao"
      },
      {
        "title": "Universal polarization",
        "abstract": "A method to polarize channels universally is introduced. The method is based on combining channels of unequal capacities in each polarization step, as opposed to the standard method of combining identical channels. The locations of the good and bad channels that emerge upon polarization are only a function of the polar transform chosen, and are otherwise independent of the channel being polarized. This yields a simple method to design universal polar codes for discrete memoryless channels. It is also shown that the less noisy ordering of channels is preserved under polarization, and thus, a good polar code for a given channel will perform well over a less noisy one.",
        "year": 2016,
        "authors": "Eren Şaşoğlu and Lele Wang"
      }
    ],
    "xkH30GgAAAAJ": [
      {
        "title": "RotatE: Knowledge Graph Embedding by Relational Rotation in Complex Space",
        "abstract": "We study the problem of learning representations of entities and relations in knowledge graphs for predicting missing links. The success of such a task heavily relies on the ability of modeling and inferring the patterns of (or between) the relations. In this paper, we present a new approach for knowledge graph embedding called RotatE, which is able to model and infer various relation patterns including: symmetry/antisymmetry, inversion, and composition. Specifically, the RotatE model defines each relation as a rotation from the source entity to the target entity in the complex vector space. In addition, we propose a novel self-adversarial negative sampling technique for efficiently and effectively training the RotatE model. Experimental results on multiple benchmark knowledge graphs show that the proposed RotatE model is not only scalable, but also able to infer and model various relation patterns and significantly outperform existing state-of-the-art models for link prediction.",
        "year": 2019,
        "authors": "Zhiqing Sun and Zhi-Hong Deng and Jian-Yun Nie and Jian Tang"
      },
      {
        "title": "Bloom: A 176b-parameter open-access multilingual language model",
        "abstract": "Large language models (LLMs) have been shown to be able to perform new tasks based on a few demonstrations or natural language instructions. While these capabilities have led to widespread adoption, most LLMs are developed by resource-rich organizations and are frequently kept from the public. As a step towards democratizing this powerful technology, we present BLOOM, a 176B-parameter open-access language model designed and built thanks to a collaboration of hundreds of researchers. BLOOM is a decoder-only Transformer language model that was trained on the ROOTS corpus, a dataset comprising hundreds of sources in 46 natural and 13 programming languages (59 in total). We find that BLOOM achieves competitive performance on a wide variety of benchmarks, with stronger results after undergoing multitask prompted finetuning. To facilitate future research and applications using LLMs, we publicly release our models and code under the Responsible AI License.",
        "year": 2022,
        "authors": "Teven Le Scao and Angela Fan and Christopher Akiki and Ellie Pavlick and Suzana Ilić and Daniel Hesslow and Roman Castagné and Alexandra Sasha Luccioni and François Yvon and Matthias Gallé and Jonathan Tow and Alexander M Rush and Stella Biderman and Albert Webson and Pawan Sasanka Ammanamanchi and Thomas Wang and Benoît Sagot and Niklas Muennighoff and Albert Villanova del Moral and Olatunji Ruwase and Rachel Bawden and Stas Bekman and Angelina McMillan-Major and Iz Beltagy and Huu Nguyen and Lucile Saulnier and Samson Tan and Pedro Ortiz Suarez and Victor Sanh and Hugo Laurençon and Yacine Jernite and Julien Launay and Margaret Mitchell and Colin Raffel and Aaron Gokaslan and Adi Simhi and Aitor Soroa and Alham Fikri Aji and Amit Alfassy and Anna Rogers and Ariel Kreisberg Nitzav and Canwen Xu and Chenghao Mou and Chris Emezue and Christopher Klamm and Colin Leong and Daniel van Strien and David Ifeoluwa Adelani and Dragomir Radev and Eduardo González Ponferrada and Efrat Levkovizh and Ethan Kim and Eyal Bar Natan and Francesco De Toni and Gérard Dupont and Kruszewski"
      },
      {
        "title": "MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices",
        "abstract": "Natural Language Processing (NLP) has recently achieved great success by using huge pre-trained models with hundreds of millions of parameters. However, these models suffer from heavy model sizes and high latency such that they cannot be deployed to resource-limited mobile devices. In this paper, we propose MobileBERT for compressing and accelerating the popular BERT model. Like the original BERT, MobileBERT is task-agnostic, that is, it can be generically applied to various downstream NLP tasks via simple fine-tuning. Basically, MobileBERT is a thin version of BERT_LARGE, while equipped with bottleneck structures and a carefully designed balance between self-attentions and feed-forward networks. To train MobileBERT, we first train a specially designed teacher model, an inverted-bottleneck incorporated BERT_LARGE model. Then, we conduct knowledge transfer from this teacher to MobileBERT. Empirical studies show that MobileBERT is 4.3x smaller and 5.5x faster than BERT_BASE while achieving competitive results on well-known benchmarks. On the natural language inference tasks of GLUE, MobileBERT achieves a GLUEscore o 77.7 (0.6 lower than BERT_BASE), and 62 ms latency on a Pixel 4 phone. On the SQuAD v1.1/v2.0 question answering task, MobileBERT achieves a dev F1 score of 90.0/79.2 (1.5/2.1 higher than BERT_BASE).",
        "year": 2020,
        "authors": "Zhiqing Sun and Hongkun Yu and Xiaodan Song and Renjie Liu and Yiming Yang and Denny Zhou"
      }
    ],
    "ftI1lBQAAAAJ": [
      {
        "title": "Variations in the Earth's Orbit: Pacemaker of the Ice Ages: For 500,000 years, major climatic changes have followed variations in obliquity and precession.",
        "abstract": "1) Three indices of global climate have been monitored in the record of the past 450,000 years in Southern Hemisphere ocean-floor sediments.2) Over the frequency range 10–4 to 10–5 cycle per year, climatic variance of these records is concentrated in three discrete spectral peaks at periods of 23,000, 42,000, and approximately 100,000 years. These peaks correspond to the dominant periods of the earth's solar orbit, and contain respectively about 10, 25, and 50 percent of the climatic variance.3) The 42,000-year climatic component has the same period as variations in the obliquity of the earth's axis and retains a constant phase relationship with it.4) The 23,000-year portion of the variance displays the same periods (about 23,000 and 19,000 years) as the quasi-periodic precession index.5) The dominant, 100,000-year climaticcomponent has an average period close to, and is in phase …",
        "year": 1976,
        "authors": "James D Hays and John Imbrie and Nicholas J Shackleton"
      },
      {
        "title": "Modeling the climatic response to orbital variations",
        "abstract": "According to the astronomical theory of climate, variations in the earth's orbit are the fundamental cause of the succession of Pleistocene ice ages. This article summarizes how the theory has evolved since the pioneer studies of James Croll and Milutin Milankovitch, reviews recent evidence that supports the theory, and argues that a major opportunity is at hand to investigate the physical mechanisms by which the climate system responds to orbital forcing. After a survey of the kinds of models that have been applied to this problem, a strategy is suggested for building simple, physically motivated models, and a time-dependent model is developed that simulates the history of planetary glaciation for the past 500,000 years. Ignoring anthropogenic and other possible sources of variation acting at frequencies higher than one cycle per 19,000 years, this model predicts that the long-term cooling trend which began some …",
        "year": 1980,
        "authors": "John Imbrie and John Z Imbrie"
      },
      {
        "title": "On many-body localization for quantum spin chains",
        "abstract": "For a one-dimensional spin chain with random local interactions, we prove that many-body localization follows from a physically reasonable assumption that limits the amount of level attraction in the system. The construction uses a sequence of local unitary transformations to diagonalize the Hamiltonian and connect the exact many-body eigenfunctions to the original basis vectors.",
        "year": 2016,
        "authors": "John Z Imbrie"
      }
    ],
    "UE9jz_MAAAAJ": [
      {
        "title": "AgentBench: Evaluating LLMs as Agents",
        "abstract": "Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks. As a result, there has been an urgent need to evaluate LLMs as agents on challenging tasks in interactive environments. We present AgentBench, a multi-dimensional evolving benchmark that currently consists of 8 distinct environments to assess LLM-as-Agent's reasoning and decision-making abilities in a multi-turn open-ended generation setting. Our extensive test over 27 API-based and open-sourced (OSS) LLMs shows that, while top commercial LLMs present a strong ability of acting as agents in complex environments, there is a significant disparity in performance between them and OSS competitors. We identify the typical reasons of failures in environments and LLMs, showing that poor long-term reasoning, decision-making, and instruction following abilities are the main obstacles for developing usable LLM agents. Training on code and high quality multi-turn alignment data could improve agent performance. Datasets, environments, and an integrated evaluation package for AgentBench are released at \\url{https://github.com/THUDM/AgentBench}.",
        "year": 2023,
        "authors": "Xiao Liu and Hao Yu and Hanchen Zhang and Yifan Xu and Xuanyu Lei and Hanyu Lai and Yu Gu and Hangliang Ding and Kaiwen Men and Kejuan Yang and Shudan Zhang and Xiang Deng and Aohan Zeng and Zhengxiao Du and Chenhui Zhang and Sheng Shen and Tianjun Zhang and Yu Su and Huan Sun and Minlie Huang and Yuxiao Dong and Jie Tang"
      },
      {
        "title": "Gorilla: Large language model connected with massive apis",
        "abstract": "Large Language Models (LLMs) have seen an impressive wave of advances, withmodels now excelling in a variety of tasks, such as mathematical reasoning andprogram synthesis. However, their potential to effectively use tools via API callsremains unfulfilled. This is a challenging task even for today’s state-of-the-artLLMs such as GPT-4 largely due to their unawareness of what APIs are availableand how to use them in a frequently updated tool set. We develop Gorilla, afinetuned LLaMA model that surpasses the performance of GPT-4 on writing APIcalls. Trained with the novel Retriever Aware Training (RAT), when combinedwith a document retriever, Gorilla demonstrates a strong capability to adapt totest-time document changes, allowing flexible user updates or version changes. It also substantially mitigates the issue of hallucination, commonly encounteredwhen prompting LLMs directly. To evaluate the model’s ability, we introduceAPIBench, a comprehensive dataset consisting of HuggingFace, TorchHub, andTensorHub APIs. The successful integration of the retrieval system with Gorillademonstrates the potential for LLMs to use tools more accurately, keep up withfrequently updated documentation, and consequently increase the reliability andapplicability of their outputs. Gorilla’s code, model, data, and demo are availableat: https://gorilla. cs. berkeley. edu",
        "year": 2024,
        "authors": "Shishir G Patil and Tianjun Zhang and Xin Wang and Joseph E Gonzalez"
      }
    ],
    "HBztuGIAAAAJ": [
      {
        "title": "InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets",
        "abstract": "This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods.",
        "year": 2016,
        "authors": "Xi Chen and Yan Duan and Rein Houthooft and John Schulman and Ilya Sutskever and Pieter Abbeel"
      },
      {
        "title": "Benchmarking Deep Reinforcement Learning for Continuous Control",
        "abstract": "Recently, researchers have made significant progress combining the advances in deep learning for learning feature representations with reinforcement learning. Some notable examples include training agents to play Atari games based on raw pixel data and to acquire advanced manipulation skills using raw sensory inputs. However, it has been difficult to quantify progress in the domain of continuous control due to the lack of a commonly adopted benchmark. In this work, we present a benchmark suite of continuous control tasks, including classic tasks like cart-pole swing-up, tasks with very high state and action dimensionality such as 3D humanoid locomotion, tasks with partial observations, and tasks with hierarchical structure. We report novel findings based on the systematic evaluation of a range of implemented reinforcement learning algorithms. Both the benchmark and reference implementations are released at https://github. com/rllab/rllab in order to facilitate experimental reproducibility and to encourage adoption by other researchers.",
        "year": 2016,
        "authors": "Yan Duan and Xi Chen and Rein Houthooft and John Schulman and Pieter Abbeel"
      },
      {
        "title": "VIME: Variational Information Maximizing Exploration",
        "abstract": "Scalable and effective exploration remains a key challenge in reinforcement learning (RL). While there are methods with optimality guarantees in the setting of discrete state and action spaces, these methods cannot be applied in high-dimensional deep RL scenarios. As such, most contemporary RL relies on simple heuristics such as epsilon-greedy exploration or adding Gaussian noise to the controls. This paper introduces Variational Information Maximizing Exploration (VIME), an exploration strategy based on maximization of information gain about the agent's belief of environment dynamics. We propose a practical implementation, using variational inference in Bayesian neural networks which efficiently handles continuous state and action spaces. VIME modifies the MDP reward function, and can be applied with several different underlying RL algorithms. We demonstrate that VIME achieves significantly better performance compared to heuristic exploration methods across a variety of continuous control tasks and algorithms, including tasks with very sparse rewards.",
        "year": 2016,
        "authors": "Rein Houthooft and Xi Chen and Yan Duan and John Schulman and Filip De Turck and Pieter Abbeel"
      }
    ],
    "iVLAQysAAAAJ": [
      {
        "title": "Denoising diffusion probabilistic models",
        "abstract": "We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.",
        "year": 2020,
        "authors": "Jonathan Ho and Ajay Jain and Pieter Abbeel"
      },
      {
        "title": "Photorealistic text-to-image diffusion models with deep language understanding",
        "abstract": "We present Imagen, a text-to-image diffusion model with an unprecedented degree of photorealism and a deep level of language understanding. Imagen builds on the power of large transformer language models in understanding text and hinges on the strength of diffusion models in high-fidelity image generation. Our key discovery is that generic large language models (eg, T5), pretrained on text-only corpora, are surprisingly effective at encoding text for image synthesis: increasing the size of the language model in Imagen boosts both sample fidelity and image-text alignment much more than increasing the size of the image diffusion model. Imagen achieves a new state-of-the-art FID score of 7.27 on the COCO dataset, without ever training on COCO, and human raters find Imagen samples to be on par with the COCO data itself in image-text alignment. To assess text-to-image models in greater depth, we introduce DrawBench, a comprehensive and challenging benchmark for text-to-image models. With DrawBench, we compare Imagen with recent methods including VQ-GAN+ CLIP, Latent Diffusion Models, and DALL-E 2, and find that human raters prefer Imagen over other models in side-by-side comparisons, both in terms of sample quality and image-text alignment.",
        "year": 2022,
        "authors": "Chitwan Saharia and William Chan and Saurabh Saxena and Lala Li and Jay Whang and Emily L Denton and Kamyar Ghasemipour and Raphael Gontijo Lopes and Burcu Karagol Ayan and Tim Salimans and Jonathan Ho and David J Fleet and Mohammad Norouzi"
      },
      {
        "title": "Classifier-free diffusion guidance",
        "abstract": "Classifier guidance is a recently introduced method to trade off mode coverage and sample fidelity in conditional diffusion models post training, in the same spirit as low temperature sampling or truncation in other types of generative models. Classifier guidance combines the score estimate of a diffusion model with the gradient of an image classifier and thereby requires training an image classifier separate from the diffusion model. It also raises the question of whether guidance can be performed without a classifier. We show that guidance can be indeed performed by a pure generative model without such a classifier: in what we call classifier-free guidance, we jointly train a conditional and an unconditional diffusion model, and we combine the resulting conditional and unconditional score estimates to attain a trade-off between sample quality and diversity similar to that obtained using classifier guidance.",
        "year": 2022,
        "authors": "Jonathan Ho and Tim Salimans"
      }
    ],
    "FXiSi-4AAAAJ": [
      {
        "title": "Observation of long-range tertiary interactions during ligand binding by the TPP riboswitch aptamer",
        "abstract": "The thiamine pyrophosphate (TPP) riboswitch is a cis-regulatory element in mRNA that modifies gene expression in response to TPP concentration. Its specificity is dependent upon conformational changes that take place within its aptamer domain. Here, the role of tertiary interactions in ligand binding was studied at the single-molecule level by combined force spectroscopy and Förster resonance energy transfer (smFRET), using an optical trap equipped for simultaneous smFRET. The ‘Force-FRET’ approach directly probes secondary and tertiary structural changes during folding, including events associated with binding. Concurrent transitions observed in smFRET signals and RNA extension revealed differences in helix-arm orientation between two previously-identified ligand-binding states that had been undetectable by spectroscopy alone. Our results show that the weaker binding state is able to bind to TPP, but is unable to form a tertiary docking interaction that completes the binding process. Long-range tertiary interactions stabilize global riboswitch structure and confer increased ligand specificity.DOI: http://dx.doi.org/10.7554/eLife.12362.001",
        "year": 2015,
        "authors": "Van K Duesterberg and Irena T Fischer-Hwang and Christian F Perez and Daniel W Hogan and Steven M Block"
      },
      {
        "title": "Classification and clustering of RNA crosslink-ligation data reveal complex structures and homodimers",
        "abstract": "The recent development and application of methods based on the general principle of “crosslinking and proximity ligation” (crosslink-ligation) are revolutionizing RNA structure studies in living cells. However, extracting structure information from such data presents unique challenges. Here, we introduce a set of computational tools for the systematic analysis of data from a wide variety of crosslink-ligation methods, specifically focusing on read mapping, alignment classification, and clustering. We design a new strategy to map short reads with irregular gaps at high sensitivity and specificity. Analysis of previously published data reveals distinct properties and bias caused by the crosslinking reactions. We perform rigorous and exhaustive classification of alignments and discover eight types of arrangements that provide distinct information on RNA structures and interactions. To deconvolve the dense and intertwined …",
        "year": 2022,
        "authors": "Minjie Zhang and Irena T Hwang and Kongpan Li and Jianhui Bai and Jian-Fu Chen and Tsachy Weissman and James Y Zou and Zhipeng Lu"
      },
      {
        "title": "Denoising of aligned genomic data",
        "abstract": "Noise in genomic sequencing data is known to have effects on various stages of genomic data analysis pipelines. Variant identification is an important step of many of these pipelines, and is increasingly being used in clinical settings to aid medical practices. We propose a denoising method, dubbed SAMDUDE, which operates on aligned genomic data in order to improve variant calling performance. Denoising human data with SAMDUDE resulted in improved variant identification in both individual chromosome as well as whole genome sequencing (WGS) data sets. In the WGS data set, denoising led to identification of almost 2,000 additional true variants, and elimination of over 1,500 erroneously identified variants. In contrast, we found that denoising with other state-of-the-art denoisers significantly worsens variant calling performance. SAMDUDE is written in Python and is freely available at https://github.com …",
        "year": 2019,
        "authors": "Irena Fischer-Hwang and Idoia Ochoa and Tsachy Weissman and Mikel Hernaez"
      }
    ],
    "CpMjT0YAAAAJ": [
      {
        "title": "NoScope: Optimizing Neural Network Queries over Video at Scale",
        "abstract": "Recent advances in computer vision-in the form of deep neural networks-have made it possible to query increasing volumes of video data with high accuracy. However, neural network inference is computationally expensive at scale: applying a state-of-the-art object detector in real time (i.e., 30+ frames per second) to a single video requires a $4000 GPU. In response, we present NoScope, a system for querying videos that can reduce the cost of neural network video analysis by up to three orders of magnitude via inference-optimized model search. Given a target video, object to detect, and reference neural network, NoScope automatically searches for and trains a sequence, or cascade, of models that preserves the accuracy of the reference network but is specialized to the target video and are therefore far less computationally expensive. NoScope cascades two types of models: specialized models that forego the full generality of the reference model but faithfully mimic its behavior for the target video and object; and difference detectors that highlight temporal differences across frames. We show that the optimal cascade architecture differs across videos and objects, so NoScope uses an efficient cost-based optimizer to search across models and cascades. With this approach, NoScope achieves two to three order of magnitude speed-ups (265-15,500x real-time) on binary classification tasks over fixed-angle webcam and surveillance video while maintaining accuracy within 1-5% of state-of-the-art neural networks.",
        "year": 2017,
        "authors": "Daniel Kang and John Emmons and Firas Abuzaid and Peter Bailis and Matei Zaharia"
      },
      {
        "title": "DAWNBench: An End-to-End Deep Learning Benchmark and Competition",
        "abstract": "Despite considerable research on systems, algorithms and hardware to speed up deep learning workloads, there is no standard means of evaluating end-to-end deep learning performance. Existing benchmarks measure proxy metrics, such as time to process one minibatch of data, that do not indicate whether the system as a whole will produce a high-quality result. In this work, we introduce DAWNBench, a benchmark and competition focused on end-to-end training time to achieve a state-of-the-art accuracy level, as well as inference time with that accuracy. Using time to accuracy as a target metric, we explore how different optimizations, including choice of optimizer, stochastic depth, and multi-GPU training, affect end-to-end training performance. Our results demonstrate that optimizations can interact in non-trivial ways when used in conjunction, producing lower speed-ups and less accurate models. We believe DAWNBench will provide a useful, reproducible means of evaluating the many trade-offs in deep learning systems.",
        "year": 2017,
        "authors": "Cody Coleman and Deepak Narayanan and Daniel Kang and Tian Zhao and Jian Zhang and Luigi Nardi and Peter Bailis and Kunle Olukotun and Chris Ré and Matei Zaharia"
      },
      {
        "title": "MLPerf Training Benchmark",
        "abstract": "Machine learning is experiencing an explosion of software and hardware solutions, and needs industry-standard performance benchmarks to drive design and enable competitive evaluation. However, machine learning training presents a number of unique challenges to benchmarking that do not exist in other domains:(1) some optimizations that improve training throughput actually increase time to solution,(2) training is stochastic and time to solution has high variance, and (3) the software and hardware systems are so diverse that they cannot be fairly benchmarked with the same binary, code, or even hyperparameters. We present MLPerf, a machine learning benchmark that overcomes these challenges. We quantitatively evaluate the efficacy of MLPerf in driving community progress on performance and scalability across two rounds of results from multiple vendors.",
        "year": 2019,
        "authors": "Peter Mattson and Christine Cheng and Cody Coleman and Greg Diamos and Paulius Micikevicius and David Patterson and Hanlin Tang and Gu-Yeon Wei and Peter Bailis and Victor Bittorf and David Brooks and Dehao Chen and Debojyoti Dutta and Udit Gupta and Kim Hazelwood and Andrew Hock and Xinyuan Huang and Bill Jia and Daniel Kang and David Kanter and Naveen Kumar and Jeffery Liao and Deepak Narayanan and Tayo Oguntebi and Gennady Pekhimenko and Lillian Pentecost and Vijay Janapa Reddi and Taylor Robie and Tom St John and Carole-Jean Wu and Lingjie Xu and Cliff Young and Matei Zaharia"
      }
    ],
    "Bl8GgEcAAAAJ": [
      {
        "title": "A view of cloud computing",
        "abstract": "Clearing the clouds away from the true potential and obstacles posed by this computing capability.",
        "year": 2010,
        "authors": "Michael Armbrust and Armando Fox and Rean Griffith and Anthony D Joseph and Randy Katz and Andy Konwinski and Gunho Lee and David Patterson and Ariel Rabkin and Ion Stoica and Matei Zaharia"
      },
      {
        "title": "Apache spark: a unified engine for big data processing",
        "abstract": "This open source computing framework unifies streaming, batch, and interactive big data workloads to unlock new applications.",
        "year": 2016,
        "authors": "Matei Zaharia and Reynold S Xin and Patrick Wendell and Tathagata Das and Michael Armbrust and Ankur Dave and Xiangrui Meng and Josh Rosen and Shivaram Venkataraman and Michael J Franklin and Ali Ghodsi and Joseph Gonzalez and Scott Shenker and Ion Stoica"
      },
      {
        "title": "Spark sql: Relational data processing in spark",
        "abstract": "Spark SQL is a new module in Apache Spark that integrates relational processing with Spark's functional programming API. Built on our experience with Shark, Spark SQL lets Spark programmers leverage the benefits of relational processing (e.g. declarative queries and optimized storage), and lets SQL users call complex analytics libraries in Spark (e.g. machine learning). Compared to previous systems, Spark SQL makes two main additions. First, it offers much tighter integration between relational and procedural processing, through a declarative DataFrame API that integrates with procedural Spark code. Second, it includes a highly extensible optimizer, Catalyst, built using features of the Scala programming language, that makes it easy to add composable rules, control code generation, and define extension points. Using Catalyst, we have built a variety of features (e.g. schema inference for JSON, machine …",
        "year": 2015,
        "authors": "Michael Armbrust and Reynold S Xin and Cheng Lian and Yin Huai and Davies Liu and Joseph K Bradley and Xiangrui Meng and Tomer Kaftan and Michael J Franklin and Ali Ghodsi and Matei Zaharia"
      }
    ],
    "4mVPFQ8AAAAJ": [
      {
        "title": "Cooperative Inverse Reinforcement Learning",
        "abstract": "For an autonomous system to be helpful to humans and to pose no unwarranted risks, it needs to align its values with those of the humans in its environment in such a way that its actions contribute to the maximization of value for the humans. We propose a formal definition of the value alignment problem as cooperative inverse reinforcement learning (CIRL). A CIRL problem is a cooperative, partial-information game with two agents, human and robot; both are rewarded according to the human’s reward function, but the robot does not initially know what this is. In contrast to classical IRL, where the human is assumed to act optimally in isolation, optimal CIRL solutions produce behaviors such as active teaching, active learning, and communicative actions that are more effective in achieving value alignment. We show that computing optimal joint policies in CIRL games can be reduced to solving a POMDP, prove that optimality in isolation is suboptimal in CIRL, and derive an approximate CIRL algorithm.",
        "year": 2016,
        "authors": "Dylan Hadfield-Menell and Stuart J Russell and Pieter Abbeel and Anca Dragan"
      },
      {
        "title": "Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback",
        "abstract": "Reinforcement learning from human feedback (RLHF) is a technique for training AI systems to align with human goals. RLHF has emerged as the central method used to finetune state-of-the-art large language models (LLMs). Despite this popularity, there has been relatively little public work systematizing its flaws. In this paper, we (1) survey open problems and fundamental limitations of RLHF and related methods; (2) overview techniques to understand, improve, and complement RLHF in practice; and (3) propose auditing and disclosure standards to improve societal oversight of RLHF systems. Our work emphasizes the limitations of RLHF and highlights the importance of a multi-faceted approach to the development of safer AI systems.",
        "year": 2023,
        "authors": "Stephen Casper and Xander Davies and Claudia Shi and Thomas Krendl Gilbert and Jérémy Scheurer and Javier Rando and Rachel Freedman and Tomasz Korbak and David Lindner and Pedro Freire and Tony Wang and Samuel Marks and Charbel-Raphaël Segerie and Micah Carroll and Andi Peng and Phillip Christoffersen and Mehul Damani and Stewart Slocum and Usman Anwar and Anand Siththaranjan and Max Nadeau and Eric J Michaud and Jacob Pfau and Dmitrii Krasheninnikov and Xin Chen and Lauro Langosco and Peter Hase and Erdem Bıyık and Anca Dragan and David Krueger and Dorsa Sadigh and Dylan Hadfield-Menell"
      },
      {
        "title": "Inverse Reward Design",
        "abstract": "Autonomous agents optimize the reward function we give them. What they don't know is how hard it is for us to design a reward function that actually captures what we want. When designing the reward, we might think of some specific training scenarios, and make sure that the reward will lead to the right behavior in those scenarios. Inevitably, agents encounter new scenarios (eg, new types of terrain) where optimizing that same reward may lead to undesired behavior. Our insight is that reward functions are merely observations about what the designer actually wants, and that they should be interpreted in the context in which they were designed. We introduce inverse reward design (IRD) as the problem of inferring the true objective based on the designed reward and the training MDP. We introduce approximate methods for solving IRD problems, and use their solution to plan risk-averse behavior in test MDPs. Empirical results suggest that this approach can help alleviate negative side effects of misspecified reward functions and mitigate reward hacking.",
        "year": 2017,
        "authors": "Dylan Hadfield-Menell and Smitha Milli and Pieter Abbeel and Stuart J Russell and Anca Dragan"
      }
    ],
    "dnZ8udEAAAAJ": [
      {
        "title": "Neural module networks",
        "abstract": "Visual question answering is fundamentally compositional in nature---a question like\" where is the dog?\" shares substructure with questions like\" what color is the dog?\" and\" where is the cat?\" This paper seeks to simultaneously exploit the representational capacity of deep networks and the compositional linguistic structure of questions. We describe a procedure for constructing and learning _neural module networks_, which compose collections of jointly-trained neural\" modules\" into deep networks for question answering. Our approach decomposes questions into their linguistic substructures, and uses these structures to dynamically instantiate modular networks (with reusable components for recognizing dogs, classifying colors, etc.). The resulting compound networks are jointly trained. We evaluate our approach on two challenging datasets for visual question answering, achieving state-of-the-art results on both the VQA natural image dataset and a new dataset of complex questions about abstract shapes.",
        "year": 2016,
        "authors": "Jacob Andreas and Marcus Rohrbach and Trevor Darrell and Dan Klein"
      },
      {
        "title": "Learning to reason: End-to-end module networks for visual question answering",
        "abstract": "Natural language questions are inherently compositional, and many are most easily answered by reasoning about their decomposition into modular sub-problems. For example, to answer\" is there an equal number of balls and boxes?\" we can look for balls, look for boxes, count them, and compare the results. The recently proposed Neural Module Network (NMN) architecture implements this approach to question answering by parsing questions into linguistic substructures and assembling question-specific deep networks from smaller modules that each solve one subtask. However, existing NMN implementations rely on brittle off-the-shelf parsers, and are restricted to the module configurations proposed by these parsers rather than learning them from data. In this paper, we propose End-to-End Module Networks (N2NMNs), which learn to reason by directly predicting instance-specific network layouts without the aid of a parser. Our model learns to generate network structures (by imitating expert demonstrations) while simultaneously learning network parameters (using the downstream task loss). Experimental results on the new CLEVR dataset targeted at compositional question answering show that N2NMNs achieve an error reduction of nearly 50% relative to state-of-the-art attentional approaches, while discovering interpretable network architectures specialized for each question.",
        "year": 2017,
        "authors": "Ronghang Hu and Jacob Andreas and Marcus Rohrbach and Trevor Darrell and Kate Saenko"
      },
      {
        "title": "Learning to Compose Neural Networks for Question Answering",
        "abstract": "We describe a question answering model that applies to both images and structured knowledge bases. The model uses natural language strings to automatically assemble neural networks from a collection of composable modules. Parameters for these modules are learned jointly with network-assembly parameters via reinforcement learning, with only (world, question, answer) triples as supervision. Our approach, which we term a dynamic neural model network, achieves state-of-the-art results on benchmark datasets in both visual and structured domains.",
        "year": 2016,
        "authors": "Jacob Andreas and Marcus Rohrbach and Trevor Darrell and Dan Klein"
      }
    ],
    "axX7PCwAAAAJ": [
      {
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models",
        "abstract": "DSpace at KOASAS: Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nKOASAS menu About KOASAS KAIST Library 검색 Advanced Search KOASAS About \nKOASAS Open Access Policy Browse Communities & Collections Researchers at KAIST Titles \nSubject By Date rss_1.0 rss_2.0 atom_1.0 sherpa SEARCH DSpace at KOASAS College of \nEngineering(공과대학)Kim Jaechul Graduate School of AI(김재철AI대학원)AI-Conference \nPapers(학술대회논문) Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nCited 0 time in webofscience Cited 0 time in scopus Hit : 2 Download : 0 Export DC(XML) Excel \nLim, Joseph Jaewhanresearcher Publisher IEEE Issue Date 2024-05-15 Citation IEEE \nInternational Conference on Robotics and Automation URI http://hdl.handle.net/10203/326144 \nAppears in Collection AI-Conference Papers(학술대회논문) Files in This Item There are no files …",
        "year": 2024,
        "authors": "Joseph Jaewhan Lim"
      },
      {
        "title": "Octo: An open-source generalist robot policy",
        "abstract": "Large policies pretrained on diverse robot datasets have the potential to transform robotic learning: instead of training new policies from scratch, such generalist robot policies may be finetuned with only a little in-domain data, yet generalize broadly. However, to be widely applicable across a range of robotic learning scenarios, environments, and tasks, such policies need to handle diverse sensors and action spaces, accommodate a variety of commonly used robotic platforms, and finetune readily and efficiently to new domains. In this work, we aim to lay the groundwork for developing open-source, widely applicable, generalist policies for robotic manipulation. As a first step, we introduce Octo, a large transformer-based policy trained on 800k trajectories from the Open X-Embodiment dataset, the largest robot manipulation dataset to date. It can be instructed via language commands or goal images and can be effectively finetuned to robot setups with new sensory inputs and action spaces within a few hours on standard consumer GPUs. In experiments across 9 robotic platforms, we demonstrate that Octo serves as a versatile policy initialization that can be effectively finetuned to new observation and action spaces. We also perform detailed ablations of design decisions for the Octo model, from architecture to training data, to guide future research on building generalist robot models.",
        "year": 2024,
        "authors": "Octo Model Team and Dibya Ghosh and Homer Walke and Karl Pertsch and Kevin Black and Oier Mees and Sudeep Dasari and Joey Hejna and Tobias Kreiman and Charles Xu and Jianlan Luo and You Liang Tan and Lawrence Yunliang Chen and Pannag Sanketi and Quan Vuong and Ted Xiao and Dorsa Sadigh and Chelsea Finn and Sergey Levine"
      },
      {
        "title": "Training diffusion models with reinforcement learning",
        "abstract": "Diffusion models are a class of flexible generative models trained with an approximation to the log-likelihood objective. However, most use cases of diffusion models are not concerned with likelihoods, but instead with downstream objectives such as human-perceived image quality or drug effectiveness. In this paper, we investigate reinforcement learning methods for directly optimizing diffusion models for such objectives. We describe how posing denoising as a multi-step decision-making problem enables a class of policy gradient algorithms, which we refer to as denoising diffusion policy optimization (DDPO), that are more effective than alternative reward-weighted likelihood approaches. Empirically, DDPO is able to adapt text-to-image diffusion models to objectives that are difficult to express via prompting, such as image compressibility, and those derived from human feedback, such as aesthetic quality. Finally, we show that DDPO can improve prompt-image alignment using feedback from a vision-language model without the need for additional data collection or human annotation. The project's website can be found at http://rl-diffusion.github.io .",
        "year": 2023,
        "authors": "Kevin Black and Michael Janner and Yilun Du and Ilya Kostrikov and Sergey Levine"
      }
    ],
    "mnAk4HIAAAAJ": [
      {
        "title": "System architecture directions for networked sensors",
        "abstract": "Technological progress in integrated, low-power, CMOS communication devices and sensors makes a rich design space of networked sensors viable. They can be deeply embedded in the physical world and spread throughout our environment like smart dust. The missing elements are an overall system architecture and a methodology for systematic advance. To this end, we identify key requirements, develop a small device that is representative of the class, design a tiny event-driven operating system, and show that it provides support for efficient modularity and concurrency-intensive operation. Our operating system fits in 178 bytes of memory, propagates events in the time it takes to copy 1.25 bytes of memory, context switches in the time it takes to copy 6 bytes of memory and supports two level scheduling. The analysis lays a groundwork for future architectural advances.",
        "year": 2000,
        "authors": "Jason Hill and Robert Szewczyk and Alec Woo and Seth Hollar and David Culler and Kristofer Pister"
      },
      {
        "title": "RPL: IPv6 routing protocol for low-power and lossy networks",
        "abstract": "0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1",
        "year": 2012,
        "authors": "Tim Winter and Pascal Thubert and Anders Brandt and Jonathan Hui and Richard Kelsey and Philip Levis and Kris Pister and Rene Struik and Jean-Philippe Vasseur and Roger Alexander"
      },
      {
        "title": "Next century challenges: mobile networking for “Smart Dust”",
        "abstract": "Large-scale networks of wireless sensors are becoming an active topic of research. Advances in hardware technology and engineering design have led to dramatic reductions in size, power consumption and cost for digital circuitry, wireless communications and Micro ElectroMechanical Systems (MEMS). This has enabled very compact, autonomous and mobile nodes, each containing one or more sensors, computation and communication capabilities, and a power supply. The missing ingredient is the networking and applications layers needed to harness this revolutionary capability into a complete system. We review the key elements of the emergent technology of “Smart Dust” and outline the research challenges they present to the mobile networking and systems community, which must provide coherent connectivity to large numbers of mobile network nodes co-located within a small volume.",
        "year": 1999,
        "authors": "Joseph M Kahn and Randy H Katz and Kristofer SJ Pister"
      }
    ],
    "CP5x1yEAAAAJ": [
      {
        "title": ": A Vision-Language-Action Flow Model for General Robot Control",
        "abstract": "Robot learning holds tremendous promise to unlock the full potential of flexible, general, and dexterous robot systems, as well as to address some of the deepest questions in artificial intelligence. However, bringing robot learning to the level of generality required for effective real-world systems faces major obstacles in terms of data, generalization, and robustness. In this paper, we discuss how generalist robot policies (i.e., robot foundation models) can address these challenges, and how we can design effective generalist robot policies for complex and highly dexterous tasks. We propose a novel flow matching architecture built on top of a pre-trained vision-language model (VLM) to inherit Internet-scale semantic knowledge. We then discuss how this model can be trained on a large and diverse dataset from multiple dexterous robot platforms, including single-arm robots, dual-arm robots, and mobile manipulators. We evaluate our model in terms of its ability to perform tasks in zero shot after pre-training, follow language instructions from people and from a high-level VLM policy, and its ability to acquire new skills via fine-tuning. Our results cover a wide variety of tasks, such as laundry folding, table cleaning, and assembling boxes.",
        "year": 2024,
        "authors": "Kevin Black and Noah Brown and Danny Driess and Adnan Esmail and Michael Equi and Chelsea Finn and Niccolo Fusai and Lachy Groom and Karol Hausman and Brian Ichter and Szymon Jakubczak and Tim Jones and Liyiming Ke and Sergey Levine and Adrian Li-Bell and Mohith Mothukuri and Suraj Nair and Karl Pertsch and Lucy Xiaoyang Shi and James Tanner and Quan Vuong and Anna Walling and Haohuan Wang and Ury Zhilinsky"
      },
      {
        "title": "Navigation with large language models: Semantic guesswork as a heuristic for planning",
        "abstract": "Navigation in unfamiliar environments presents a major challenge for robots: while mapping and planning techniques can be used to build up a representation of the world, quickly discovering a path to a desired goal in unfamiliar settings with such methods often requires lengthy mapping and exploration. Humans can rapidly navigate new environments, particularly indoor environments that are laid out logically, by leveraging semantics—eg, a kitchen often adjoins a living room, an exit sign indicates the way out, and so forth. Language models can provide robots with such knowledge, but directly using language models to instruct a robot how to reach some destination can also be impractical: while language models might produce a narrative about how to reach some goal, because they are not grounded in real-world observations, this narrative might be arbitrarily wrong. Therefore, in this paper we study how the “semantic guesswork” produced by language models can be utilized as a guiding heuristic for planning algorithms. Our method, Language Frontier Guide (LFG), uses the language model to bias exploration of novel real-world environments by incorporating the semantic knowledge stored in language models as a search heuristic for planning with either topological or metric maps. We evaluate LFG in challenging real-world environments and simulated benchmarks, outperforming uninformed exploration and other ways of using language models.",
        "year": 2023,
        "authors": "Dhruv Shah and Michael Robert Equi and Błażej Osiński and Fei Xia and Brian Ichter and Sergey Levine"
      }
    ],
    "0uTu7fYAAAAJ": [
      {
        "title": "Dropout as a bayesian approximation: Representing model uncertainty in deep learning",
        "abstract": "Deep learning tools have gained tremendous attention in applied machine learning. However such tools for regression and classification do not capture model uncertainty. In comparison, Bayesian models offer a mathematically grounded framework to reason about model uncertainty, but usually come with a prohibitive computational cost. In this paper we develop a new theoretical framework casting dropout training in deep neural networks (NNs) as approximate Bayesian inference in deep Gaussian processes. A direct result of this theory gives us tools to model uncertainty with dropout NNs–extracting information from existing models that has been thrown away so far. This mitigates the problem of representing uncertainty in deep learning without sacrificing either computational complexity or test accuracy. We perform an extensive study of the properties of dropout’s uncertainty. Various network architectures and non-linearities are assessed on tasks of regression and classification, using MNIST as an example. We show a considerable improvement in predictive log-likelihood and RMSE compared to existing state-of-the-art methods, and finish by using dropout’s uncertainty in deep reinforcement learning.",
        "year": 2016,
        "authors": "Yarin Gal and Zoubin Ghahramani"
      },
      {
        "title": "Semi-supervised learning using Gaussian fields and harmonic functions",
        "abstract": "An approach to semi-supervised learning is proposed that is based on a Gaussian random field model. Labeled and unlabeled data are represented as vertices in a weighted graph, with edge weights encoding the similarity between instances. The learning problem is then formulated in terms of a Gaussian random field on this graph, where the mean of the field is characterized in terms of harmonic functions, and is efficiently obtained using matrix methods or belief propagation. The resulting learning algorithms have intimate connections with random walks, electric networks, and spectral graph theory. We discuss methods to incorporate class priors and the predictions of classifiers obtained by supervised learning. We also propose a method of parameter learning by entropy minimization, and show the algorithm’s ability to perform feature selection. Promising experimental results are presented for synthetic data, digit classification, and text classification tasks.",
        "year": 2003,
        "authors": "Xiaojin Zhu and Zoubin Ghahramani and John Lafferty"
      },
      {
        "title": "An introduction to variational methods for graphical models",
        "abstract": "This paper presents a tutorial introduction to the use of variational methods for inference and learning in graphical models (Bayesian networks and Markov random fields). We present a number of examples of graphical models, including the QMR-DT database, the sigmoid belief network, the Boltzmann machine, and several variants of hidden Markov models, in which it is infeasible to run exact inference algorithms. We then introduce variational methods, which exploit laws of large numbers to transform the original graphical model into a simplified graphical model in which inference is efficient. Inference in the simpified model provides bounds on probabilities of interest in the original model. We describe a general framework for generating variational transformations based on convex duality. Finally we return to the examples and demonstrate how variational algorithms can be formulated in each case.",
        "year": 1999,
        "authors": "Michael I Jordan and Zoubin Ghahramani and Tommi S Jaakkola and Lawrence K Saul"
      }
    ],
    "tX3YzCcAAAAJ": [
      {
        "title": "American College of Rheumatology guidelines for screening, treatment, and management of lupus nephritis",
        "abstract": "In the US, approximately 35% of adults with systemic lupus erythematosus (SLE) have clinical evidence of nephritis at the time of diagnosis, with an estimated total of 50–60% developing nephritis during the first 10 years of disease (1–4). The prevalence of nephritis is significantly higher in African Americans and Hispanics than in whites, and is higher in men than in women. Renal damage is",
        "year": 2012,
        "authors": "Bevra H Hahn and Maureen A Mcmahon and Alan Wilkinson and W Dean Wallace and David I Daikh and John D Fitzgerald and George A Karpouzas and Joan T Merrill and Daniel J Wallace and Jinoos Yazdany and Rosalind Ramsey‐Goldman and Karandeep Singh and Mazdak Khalighi and Soo‐In Choi and Maneesh Gogia and Suzanne Kafaja and Mohammad Kamgar and Christine Lau and William J Martin and Sefali Parikh and Justin Peng and Anjay Rastogi and Weiling Chen and Jennifer M Grossman"
      },
      {
        "title": "Potential biases in machine learning algorithms using electronic health record data",
        "abstract": "A promise of machine learning in health care is the avoidance of biases in diagnosis and treatment; a computer algorithm could objectively synthesize and interpret the data in the medical record. Integration of machine learning with clinical decision support tools, such as computerized alerts or diagnostic support, may offer physicians and others who provide health care targeted and timely information that can improve clinical decisions. Machine learning algorithms, however, may also be subject to biases. The biases include those related to missing data and patients not identified by algorithms, sample size and underestimation, and misclassification and measurement error. There is concern that biases and deficiencies in the data used by machine learning algorithms may contribute to socioeconomic disparities in health care. This Special Communication outlines the potential biases that may be introduced into …",
        "year": 2018,
        "authors": "Milena A Gianfrancesco and Suzanne Tamang and Jinoos Yazdany and Gabriela Schmajuk"
      },
      {
        "title": "Characteristics associated with hospitalisation for COVID-19 in people with rheumatic disease: data from the COVID-19 Global Rheumatology Alliance physician-reported registry",
        "abstract": "ObjectivesCOVID-19 outcomes in people with rheumatic diseases remain poorly understood. The aim was to examine demographic and clinical factors associated with COVID-19 hospitalisation status in people with rheumatic disease.MethodsCase series of individuals with rheumatic disease and COVID-19 from the COVID-19 Global Rheumatology Alliance registry: 24 March 2020 to 20 April 2020. Multivariable logistic regression was used to estimate ORs and 95% CIs of hospitalisation. Age, sex, smoking status, rheumatic disease diagnosis, comorbidities and rheumatic disease medications taken immediately prior to infection were analysed.ResultsA total of 600 cases from 40 countries were included. Nearly half of the cases were hospitalised (277, 46%) and 55 (9%) died. In multivariable-adjusted models, prednisone dose ≥10 mg/day was associated with higher odds of hospitalisation (OR 2.05, 95% CI 1.06 to …",
        "year": 2020,
        "authors": "Milena Gianfrancesco and Kimme L Hyrich and Sarah Al-Adely and Loreto Carmona and Maria I Danila and Laure Gossec and Zara Izadi and Lindsay Jacobsohn and Patricia Katz and Saskia Lawson-Tovey and Elsa F Mateus and Stephanie Rush and Gabriela Schmajuk and Julia Simard and Anja Strangfeld and Laura Trupin and Katherine D Wysham and Suleman Bhana and Wendy Costello and Rebecca Grainger and Jonathan S Hausmann and Jean W Liew and Emily Sirotich and Paul Sufka and Zachary S Wallace and Jinoos Yazdany and Pedro M Machado and Philip C Robinson"
      }
    ],
    "LMtE3FQAAAAJ": [
      {
        "title": "Autonomous inverted helicopter flight via reinforcement learning",
        "abstract": "Helicopters have highly stochastic, nonlinear, dynamics, and autonomous helicopter flight is widely regarded to be a challenging control problem. As helicopters are highly unstable at low speeds, it is particularly difficult to design controllers for low speed aerobatic maneuvers. In this paper, we describe a successful application of reinforcement learning to designing a controller for sustained inverted flight on an autonomous helicopter. Using data collected from the helicopter in flight, we began by learning a stochastic, nonlinear model of the helicopter’s dynamics. Then, a reinforcement learning algorithm was applied to automatically learn a controller for autonomous inverted hovering. Finally, the resulting controller was successfully tested on our autonomous helicopter platform.",
        "year": 2006,
        "authors": "Andrew Y Ng and Adam Coates and Mark Diel and Varun Ganapathi and Jamie Schulte and Ben Tse and Eric Berger and Eric Liang"
      },
      {
        "title": "Real time motion capture using a single time-of-flight camera",
        "abstract": "Markerless tracking of human pose is a hard yet relevant problem. In this paper, we derive an efficient filtering algorithm for tracking human pose using a stream of monocular depth images. The key idea is to combine an accurate generative model - which is achievable in this setting using programmable graphics hardware - with a discriminative model that provides data-driven evidence about body part locations. In each filter iteration, we apply a form of local model-based search that exploits the nature of the kinematic chain. As fast movements and occlusion can disrupt the local search, we utilize a set of discriminatively trained patch classifiers to detect body parts. We describe a novel algorithm for propagating this noisy evidence about body part locations up the kinematic chain using the unscented transform. The resulting distribution of body configurations allows us to reinitialize the model-based search. We …",
        "year": 2010,
        "authors": "Varun Ganapathi and Christian Plagemann and Daphne Koller and Sebastian Thrun"
      },
      {
        "title": "Real-time identification and localization of body parts from depth images",
        "abstract": "We deal with the problem of detecting and identifying body parts in depth images at video frame rates. Our solution involves a novel interest point detector for mesh and range data that is particularly well suited for analyzing human shape. The interest points, which are based on identifying geodesic extrema on the surface mesh, coincide with salient points of the body, which can be classified as, e.g., hand, foot or head using local shape descriptors. Our approach also provides a natural way of estimating a 3D orientation vector for a given interest point. This can be used to normalize the local shape descriptors to simplify the classification problem as well as to directly estimate the orientation of body parts in space. Experiments involving ground truth labels acquired via an active motion capture system show that our interest points in conjunction with a boosted patch classifier are significantly better in detecting body …",
        "year": 2010,
        "authors": "Christian Plagemann and Varun Ganapathi and Daphne Koller and Sebastian Thrun"
      }
    ],
    "eM916YMAAAAJ": [
      {
        "title": "Conflict monitoring and cognitive control.",
        "abstract": "A neglected question regarding cognitive control is how control processes might detect situations calling for their involvement. The authors propose here that the demand for control may be evaluated in part by monitoring for conflicts in information processing. This hypothesis is supported by data concerning the anterior cingulate cortex, a brain area involved in cognitive control, which also appears to respond to the occurrence of conflict. The present article reports two computational modeling studies, serving to articulate the conflict monitoring hypothesis and examine its implications. The first study tests the sufficiency of the hypothesis to account for brain activation data, applying a measure of conflict to existing models of tasks shown to engage the anterior cingulate. The second study implements a feedback loop connecting conflict monitoring to cognitive control, using this to simulate a number of important …",
        "year": 2001,
        "authors": "Matthew M Botvinick and Todd S Braver and Deanna M Barch and Cameron S Carter and Jonathan D Cohen"
      },
      {
        "title": "Beta-VAE: Learning basic visual concepts with a constrained variational framework",
        "abstract": "Learning an interpretable factorised representation of the independent data generative factors of the world without supervision is an important precursor for the development of artificial intelligence that is able to learn and reason in the same way that humans do. We introduce beta-VAE, a new state-of-the-art framework for automated discovery of interpretable factorised latent representations from raw image data in a completely unsupervised manner. Our approach is a modification of the variational autoencoder (VAE) framework. We introduce an adjustable hyperparameter beta that balances latent channel capacity and independence constraints with reconstruction accuracy. We demonstrate that beta-VAE with appropriately tuned  beta > 1 qualitatively outperforms VAE (beta = 1), as well as state of the art unsupervised (InfoGAN) and semi-supervised (DC-IGN) approaches to disentangled factor learning on a …",
        "year": 2016,
        "authors": "Irina Higgins and Loic Matthey and Arka Pal and Christopher Burgess and Xavier Glorot and Matthew Botvinick and Shakir Mohamed and Alexander Lerchner"
      },
      {
        "title": "Rubber hands ‘feel’ touch that eyes see",
        "abstract": "Illusions have historically been of great use to psychology for what they can reveal about perceptual processes. We report here an illusion in which tactile sensations are referred to an alien limb. The effect reveals a three-way interaction between vision, touch and proprioception, and may supply evidence concerning the basis of bodily self-identification.",
        "year": 1998,
        "authors": "Matthew Botvinick and Jonathan Cohen"
      }
    ],
    "iyDxq0EAAAAJ": [
      {
        "title": "Chatbot arena: An open platform for evaluating llms by human preference",
        "abstract": "Large Language Models (LLMs) have unlocked new capabilities and applications; however, evaluating the alignment with human preferences still poses significant challenges. To address this issue, we introduce Chatbot Arena, an open platform for evaluating LLMs based on human preferences. Our methodology employs a pairwise comparison approach and leverages input from a diverse user base through crowdsourcing. The platform has been operational for several months, amassing over 240K votes. This paper describes the platform, analyzes the data we have collected so far, and explains the tried-and-true statistical methods we are using for efficient and accurate evaluation and ranking of models. We confirm that the crowdsourced questions are sufficiently diverse and discriminating and that the crowd-sourced human votes are in good agreement with those of expert raters. These analyses collectively establish a robust foundation for the credibility of Chatbot Arena. Because of its unique value and openness, Chatbot Arena has emerged as one of the most referenced LLM leaderboards, widely cited by leading LLM developers and companies. The platform is publicly available at https://chat.lmsys.org.",
        "year": 2024,
        "authors": "Wei-Lin Chiang and Lianmin Zheng and Ying Sheng and Anastasios Nikolas Angelopoulos and Tianle Li and Dacheng Li and Banghua Zhu and Hao Zhang and Michael Jordan and Joseph E Gonzalez and Ion Stoica"
      },
      {
        "title": "Bridging offline reinforcement learning and imitation learning: A tale of pessimism",
        "abstract": "Offline (or batch) reinforcement learning (RL) algorithms seek to learn an optimal policy from a fixed dataset without active data collection. Based on the composition of the offline dataset, two main methods are used: imitation learning which is suitable for expert datasets, and vanilla offline RL which often requires uniform coverage datasets. From a practical standpoint, datasets often deviate from these two extremes and the exact data composition is usually unknown. To bridge this gap, we present a new offline RL framework that smoothly interpolates between the two extremes of data composition, hence unifying imitation learning and vanilla offline RL. The new framework is centered around a weak version of the concentrability coefficient that measures the deviation of the behavior policy from the expert policy alone. Under this new framework, we ask: can one develop an algorithm that achieves a minimax optimal rate adaptive to unknown data composition? To address this question, we consider a lower confidence bound (LCB) algorithm developed based on pessimism in the face of uncertainty in offline RL. We study finite-sample properties of LCB as well as information-theoretic limits in multi-armed bandits, contextual bandits, and Markov decision processes (MDPs). Our analysis reveals surprising facts about optimality rates. In particular, in both contextual bandits and RL, LCB achieves a faster rate of  for nearly-expert datasets compared to the usual rate of  in offline RL, where  is the batch dataset sample size. In contextual bandits with at least two contexts, we prove that LCB is adaptively optimal for the entire data composition …",
        "year": 2021,
        "authors": "Paria Rashidinejad and Banghua Zhu and Cong Ma and Jiantao Jiao and Stuart Russell"
      },
      {
        "title": "Principled reinforcement learning with human feedback from pairwise or k-wise comparisons",
        "abstract": "We provide a theoretical framework for Reinforcement Learning with Human Feedback (RLHF). We show that when the underlying true reward is linear, under both Bradley-Terry-Luce (BTL) model (pairwise comparison) and Plackett-Luce (PL) model (-wise comparison), MLE converges under certain semi-norm for the family of linear reward. On the other hand, when training a policy based on the learned reward model, we show that MLE fails while a pessimistic MLE provides policies with good performance under certain coverage assumption. We also show that under the PL model, both the true MLE and a different MLE which splits the -wise comparison into pairwise comparisons converge, while the true MLE is asymptotically more efficient. Our results validate the empirical success of the existing RLHF algorithms, and provide new insights for algorithm design. Our analysis can also be applied for the problem of online RLHF and inverse reinforcement learning.",
        "year": 2023,
        "authors": "Banghua Zhu and Michael Jordan and Jiantao Jiao"
      }
    ],
    "Y9CoR7QAAAAJ": [
      {
        "title": "Improved read/write cost tradeoff in DNA-based data storage using LDPC codes",
        "abstract": "With the amount of data being stored increasing rapidly, there is significant interest in exploring alternative storage technologies. In this context, DNA-based storage systems can offer significantly higher storage densities (petabytes/gram) and durability (thousands of years) than current technologies. Specifically, DNA has been found to be stable over extended periods of time which has been demonstrated in the analysis of organisms long since extinct. Recent advances in DNA sequencing and synthesis pipelines have made DNA-based storage a promising candidate for the storage technology of the future.Recently, there have been multiple efforts in this direction, focusing on aspects such as error correction for synthesis/sequencing errors and erasure correction for handling missing sequences. The typical approach is to use separate codes for handling errors and erasures, but there is limited understanding of the …",
        "year": 2019,
        "authors": "Shubham Chandak and Kedar Tatwawadi and Billy Lau and Jay Mardia and Matthew Kubit and Joachim Neu and Peter Griffin and Mary Wootters and Tsachy Weissman and Hanlee Ji"
      },
      {
        "title": "Overcoming high nanopore basecaller error rates for DNA storage via basecaller-decoder integration and convolutional codes",
        "abstract": "As magnetization and semiconductor based storage technologies approach their limits, bio-molecules, such as DNA, have been identified as promising media for future storage systems, due to their high storage density (petabytes/gram) and long-term durability (thousands of years). Furthermore, nanopore DNA sequencing enables high-throughput sequencing using devices as small as a USB thumb drive and thus is ideally suited for DNA storage applications. Due to the high insertion/deletion error rates associated with base-called nanopore reads, current approaches rely heavily on consensus among multiple reads and thus incur very high reading costs. We propose a novel approach which overcomes the high error rates in basecalled sequences by integrating a Viterbi error correction decoder with the basecaller, enabling the decoder to exploit the soft information available in the deep learning based …",
        "year": 2020,
        "authors": "Shubham Chandak and Joachim Neu and Kedar Tatwawadi and Jay Mardia and Billy Lau and Matthew Kubit and Reyna Hulett and Peter Griffin and Mary Wootters and Tsachy Weissman and Hanlee Ji"
      },
      {
        "title": "Concentration inequalities for the empirical distribution of discrete distributions: beyond the method of types",
        "abstract": "We study concentration inequalities for the Kullback–Leibler (KL) divergence between the empirical distribution and the true distribution. Applying a recursion technique, we improve over the method of types bound uniformly in all regimes of sample size  and alphabet size , and the improvement becomes more significant when  is large. We discuss the applications of our results in obtaining tighter concentration inequalities for  deviations of the empirical distribution from the true distribution, and the difference between concentration around the expectation or zero. We also obtain asymptotically tight bounds on the variance of the KL divergence between the empirical and true distribution, and demonstrate their quantitatively different behaviours between small and large sample sizes compared to the alphabet size.",
        "year": 2020,
        "authors": "Jay Mardia and Jiantao Jiao and Ervin Tánczos and Robert D Nowak and Tsachy Weissman"
      }
    ],
    "YGQs1AYAAAAJ": [
      {
        "title": "Locally weighted learning",
        "abstract": "This paper surveys locally weighted learning, a form of lazy learning and memory-based learning, and focuses on locally weighted linear regression. The survey discusses distance functions, smoothing parameters, weighting functions, local model structures, regularization of the estimates and bias, assessing predictions, handling noisy data and outliers, improving the quality of predictions by tuning fit parameters, interference between old and new data, implementing locally weighted learning efficiently, and applications of locally weighted learning. A companion paper surveys how locally weighted learning can be used in robot learning and control.",
        "year": 1997,
        "authors": "C. G. Atkeson and A. Moore and S. Schaal"
      },
      {
        "title": "Is imitation learning the route to humanoid robots?",
        "abstract": "This review investigates two recent developments in artificial intelligence and neural computation: learning from imitation and the development of humanoid robots. It is postulated that the study of imitation learning offers a promising route to gain new insights into mechanisms of perceptual motor control that could ultimately lead to the creation of autonomous humanoid robots. Imitation learning focuses on three important issues: efficient motor learning, the connection between action and perception, and modular motor control in the form of movement primitives. It is reviewed here how research on representations of, and functional connections between, action and perception have contributed to our understanding of motor acts of other beings. The recent discovery that some areas in the primate brain are active during both movement perception and execution has provided a hypothetical neural basis of imitation …",
        "year": 1999,
        "authors": "Stefan Schaal"
      },
      {
        "title": "Dynamical movement primitives: learning attractor models for motor behaviors",
        "abstract": "Nonlinear dynamical systems have been used in many disciplines to model complex behaviors, including biological motor control, robotics, perception, economics, traffic prediction, and neuroscience. While often the unexpected emergent behavior of nonlinear systems is the focus of investigations, it is of equal importance to create goal-directed behavior (e.g., stable locomotion from a system of coupled oscillators under perceptual guidance). Modeling goal-directed behavior with nonlinear systems is, however, rather difficult due to the parameter sensitivity of these systems, their complex phase transitions in response to subtle parameter changes, and the difficulty of analyzing and predicting their long-term behavior; intuition and time-consuming parameter tuning play a major role. This letter presents and reviews dynamical movement primitives, a line of research for modeling attractor behaviors of autonomous …",
        "year": 2013,
        "authors": "Auke Jan Ijspeert and Jun Nakanishi and Heiko Hoffmann and Peter Pastor and Stefan Schaal"
      }
    ],
    "kppa2vgAAAAJ": [
      {
        "title": "Multi-agent actor-critic for mixed cooperative-competitive environments",
        "abstract": "We explore deep reinforcement learning methods for multi-agent domains. We begin by analyzing the difficulty of traditional algorithms in the multi-agent case: Q-learning is challenged by an inherent non-stationarity of the environment, while policy gradient suffers from a variance that increases as the number of agents grows. We then present an adaptation of actor-critic methods that considers action policies of other agents and is able to successfully learn policies that require complex multi-agent coordination. Additionally, we introduce a training regimen utilizing an ensemble of policies for each agent that leads to more robust multi-agent policies. We show the strength of our approach compared to existing methods in cooperative as well as competitive scenarios, where agent populations are able to discover various physical and informational coordination strategies.",
        "year": 2017,
        "authors": "Ryan Lowe and Yi I Wu and Aviv Tamar and Jean Harb and OpenAI Pieter Abbeel and Igor Mordatch"
      },
      {
        "title": "Constrained policy optimization",
        "abstract": "For many applications of reinforcement learning it can be more convenient to specify both a reward function and constraints, rather than trying to design behavior through the reward function. For example, systems that physically interact with or around humans should satisfy safety constraints. Recent advances in policy search algorithms (Mnih et al., 2016, Schulman et al., 2015, Lillicrap et al., 2016, Levine et al., 2016) have enabled new capabilities in high-dimensional control, but do not consider the constrained setting. We propose Constrained Policy Optimization (CPO), the first general-purpose policy search algorithm for constrained reinforcement learning with guarantees for near-constraint satisfaction at each iteration. Our method allows us to train neural network policies for high-dimensional control while making guarantees about policy behavior all throughout training. Our guarantees are based on a new theoretical result, which is of independent interest: we prove a bound relating the expected returns of two policies to an average divergence between them. We demonstrate the effectiveness of our approach on simulated robot locomotion tasks where the agent must satisfy constraints motivated by safety.",
        "year": 2017,
        "authors": "Joshua Achiam and David Held and Aviv Tamar and Pieter Abbeel"
      },
      {
        "title": "Value iteration networks",
        "abstract": "We introduce the value iteration network (VIN): a fully differentiable neural network with aplanning module'embedded within. VINs can learn to plan, and are suitable for predicting outcomes that involve planning-based reasoning, such as policies for reinforcement learning. Key to our approach is a novel differentiable approximation of the value-iteration algorithm, which can be represented as a convolutional neural network, and trained end-to-end using standard backpropagation. We evaluate VIN based policies on discrete and continuous path-planning domains, and on a natural-language based search task. We show that by learning an explicit planning computation, VIN policies generalize better to new, unseen domains.",
        "year": 2016,
        "authors": "Aviv Tamar and Yi Wu and Garrett Thomas and Sergey Levine and Pieter Abbeel"
      }
    ],
    "UAWfBEoAAAAJ": [
      {
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models",
        "abstract": "DSpace at KOASAS: Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nKOASAS menu About KOASAS KAIST Library 검색 Advanced Search KOASAS About \nKOASAS Open Access Policy Browse Communities & Collections Researchers at KAIST Titles \nSubject By Date rss_1.0 rss_2.0 atom_1.0 sherpa SEARCH DSpace at KOASAS College of \nEngineering(공과대학)Kim Jaechul Graduate School of AI(김재철AI대학원)AI-Conference \nPapers(학술대회논문) Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nCited 0 time in webofscience Cited 0 time in scopus Hit : 2 Download : 0 Export DC(XML) Excel \nLim, Joseph Jaewhanresearcher Publisher IEEE Issue Date 2024-05-15 Citation IEEE \nInternational Conference on Robotics and Automation URI http://hdl.handle.net/10203/326144 \nAppears in Collection AI-Conference Papers(학술대회논문) Files in This Item There are no files …",
        "year": 2024,
        "authors": "Joseph Jaewhan Lim"
      },
      {
        "title": "Droid: A large-scale in-the-wild robot manipulation dataset",
        "abstract": "The creation of large, diverse, high-quality robot manipulation datasets is an important stepping stone on the path toward more capable and robust robotic manipulation policies. However, creating such datasets is challenging: collecting robot manipulation data in diverse environments poses logistical and safety challenges and requires substantial investments in hardware and human labour. As a result, even the most general robot manipulation policies today are mostly trained on data collected in a small number of environments with limited scene and task diversity. In this work, we introduce DROID (Distributed Robot Interaction Dataset), a diverse robot manipulation dataset with 76k demonstration trajectories or 350 hours of interaction data, collected across 564 scenes and 84 tasks by 50 data collectors in North America, Asia, and Europe over the course of 12 months. We demonstrate that training with DROID leads to policies with higher performance and improved generalization ability. We open source the full dataset, policy learning code, and a detailed guide for reproducing our robot hardware setup.",
        "year": 2024,
        "authors": "Alexander Khazatsky and Karl Pertsch and Suraj Nair and Ashwin Balakrishna and Sudeep Dasari and Siddharth Karamcheti and Soroush Nasiriany and Mohan Kumar Srirama and Lawrence Yunliang Chen and Kirsty Ellis and Peter David Fagan and Joey Hejna and Masha Itkina and Marion Lepert and Yecheng Jason Ma and Patrick Tree Miller and Jimmy Wu and Suneel Belkhale and Shivin Dass and Huy Ha and Arhan Jain and Abraham Lee and Youngwoon Lee and Marius Memmel and Sungjae Park and Ilija Radosavovic and Kaiyuan Wang and Albert Zhan and Kevin Black and Cheng Chi and Kyle Beltran Hatch and Shan Lin and Jingpei Lu and Jean Mercat and Abdul Rehman and Pannag R Sanketi and Archit Sharma and Cody Simpson and Quan Vuong and Homer Rich Walke and Blake Wulfe and Ted Xiao and Jonathan Heewon Yang and Arefeh Yavary and Tony Z Zhao and Christopher Agia and Rohan Baijal and Mateo Guaman Castro and Daphne Chen and Qiuyu Chen and Trinity Chung and Jaimyn Drake and Ethan Paul Foster and Jensen Gao and Vitor Guizilini and David Antonio Herrera and Minho Heo and Kyle Hsu and Jiaheng Hu and Muhammad Zubair Irshad and Donovon Jackson and Charlotte Le and Yunshuang Li and Kevin Lin and Roy Lin and Zehan Ma and Abhiram Maddukuri and Suvir Mirchandani and Daniel Morton and Tony Nguyen and Abigail O'Neill and Rosario Scalise and Derick Seale and Victor Son and Stephen Tian and Emi Tran and Andrew E Wang and Yilin Wu and Annie Xie and Jingyun Yang and Patrick Yin and Yunchu Zhang and Osbert Bastani and Glen Berseth and Jeannette Bohg and Ken Goldberg and Abhinav Gupta and Abhishek Gupta and Dinesh Jayaraman and Joseph J Lim and Jitendra Malik and Roberto Martín-Martín and Subramanian Ramamoorthy and Dorsa Sadigh and Shuran Song and Jiajun Wu and Michael C Yip and Yuke Zhu and Thomas Kollar and Sergey Levine and Chelsea Finn"
      },
      {
        "title": "Cog: Connecting new skills to past experience with offline reinforcement learning",
        "abstract": "Reinforcement learning has been applied to a wide variety of robotics problems, but most of such applications involve collecting data from scratch for each new task. Since the amount of robot data we can collect for any single task is limited by time and cost considerations, the learned behavior is typically narrow: the policy can only execute the task in a handful of scenarios that it was trained on. What if there was a way to incorporate a large amount of prior data, either from previously solved tasks or from unsupervised or undirected environment interaction, to extend and generalize learned behaviors? While most prior work on extending robotic skills using pre-collected data focuses on building explicit hierarchies or skill decompositions, we show in this paper that we can reuse prior data to extend new skills simply through dynamic programming. We show that even when the prior data does not actually succeed at solving the new task, it can still be utilized for learning a better policy, by providing the agent with a broader understanding of the mechanics of its environment. We demonstrate the effectiveness of our approach by chaining together several behaviors seen in prior datasets for solving a new task, with our hardest experimental setting involving composing four robotic skills in a row: picking, placing, drawer opening, and grasping, where a +1/0 sparse reward is provided only on task completion. We train our policies in an end-to-end fashion, mapping high-dimensional image observations to low-level robot control commands, and present results in both simulated and real world domains. Additional materials and source code can be found on …",
        "year": 2020,
        "authors": "Avi Singh and Albert Yu and Jonathan Yang and Jesse Zhang and Aviral Kumar and Sergey Levine"
      }
    ],
    "-iPZaBcAAAAJ": [
      {
        "title": "Convit: Improving vision transformers with soft convolutional inductive biases",
        "abstract": "Convolutional architectures have proven extremely successful for vision tasks. Their hard inductive biases enable sample-efficient learning, but come at the cost of a potentially lower performance ceiling. Vision Transformers (ViTs) rely on more flexible self-attention layers, and have recently outperformed CNNs for image classification. However, they require costly pre-training on large external datasets or distillation from pre-trained convolutional networks. In this paper, we ask the following question: is it possible to combine the strengths of these two architectures while avoiding their respective limitations? To this end, we introduce gated positional self-attention (GPSA), a form of positional self-attention which can be equipped with a “soft\" convolutional inductive bias. We initialise the GPSA layers to mimic the locality of convolutional layers, then give each attention head the freedom to escape locality by adjusting a gating parameter regulating the attention paid to position versus content information. The resulting convolutional-like ViT architecture, ConViT, outperforms the DeiT on ImageNet, while offering a much improved sample efficiency. We further investigate the role of locality in learning by first quantifying how it is encouraged in vanilla self-attention layers, then analysing how it is escaped in GPSA layers. We conclude by presenting various ablations to better understand the success of the ConViT. Our code and models are released publicly at https://github. com/facebookresearch/convit.",
        "year": 2021,
        "authors": "Stéphane d’Ascoli and Hugo Touvron and Matthew L Leavitt and Ari S Morcos and Giulio Biroli and Levent Sagun"
      },
      {
        "title": "Entropy-sgd: Biasing gradient descent into wide valleys",
        "abstract": "This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in the sharp valleys. Conceptually, our algorithm resembles two nested loops of SGD where we use Langevin dynamics in the inner loop to compute the gradient of the local entropy before each update of the weights. We show that the new objective has a smoother energy landscape and show improved generalization over SGD using uniform stability, under …",
        "year": 2016,
        "authors": "Pratik Chaudhari and Anna Choromanska and Stefano Soatto and Yann LeCun and Carlo Baldassi and Christian Borgs and Jennifer Chayes and Levent Sagun and Riccardo Zecchina"
      },
      {
        "title": "Searchqa: A new q&a dataset augmented with context from a search engine",
        "abstract": "We publicly release a new large-scale dataset, called SearchQA, for machine comprehension, or question-answering. Unlike recently released datasets, such as DeepMind CNN/DailyMail and SQuAD, the proposed SearchQA was constructed to reflect a full pipeline of general question-answering. That is, we start not from an existing article and generate a question-answer pair, but start from an existing question-answer pair, crawled from J! Archive, and augment it with text snippets retrieved by Google. Following this approach, we built SearchQA, which consists of more than 140k question-answer pairs with each pair having 49.6 snippets on average. Each question-answer-context tuple of the SearchQA comes with additional meta-data such as the snippet's URL, which we believe will be valuable resources for future research. We conduct human evaluation as well as test two baseline methods, one simple word selection and the other deep learning based, on the SearchQA. We show that there is a meaningful gap between the human and machine performances. This suggests that the proposed dataset could well serve as a benchmark for question-answering.",
        "year": 2017,
        "authors": "Matthew Dunn and Levent Sagun and Mike Higgins and V Ugur Guney and Volkan Cirik and Kyunghyun Cho"
      }
    ],
    "SaiH1MIAAAAJ": [
      {
        "title": "BigBIRD: A Large-Scale 3D Database of Object Instances",
        "abstract": "The state of the art in computer vision has rapidly advanced over the past decade largely aided by shared image datasets. However, most of these datasets tend to consist of assorted collections of images from the web that do not include 3D information or pose information. Furthermore, they target the problem of object category recognition - whereas solving the problem of object instance recognition might be sufficient for many robotic tasks. To address these issues, we present a high-quality, large-scale dataset of 3D object instances, with accurate calibration information for every image. We anticipate that “solving” this dataset will effectively remove many perception-related problems for mobile, sensing-based robots. The contributions of this work consist of: (1) BigBIRD, a dataset of 100 objects (and growing), composed of, for each object, 600 3D point clouds and 600 high-resolution (12 MP) images spanning all …",
        "year": 2014,
        "authors": "Arjun Singh and James Sha and Karthik Narayan and Tudor Achim and Pieter Abbeel"
      },
      {
        "title": "Multimodal Blending for High-Accuracy Instance Recognition",
        "abstract": "Despite the rich information provided by sensors such as the Microsoft Kinect in the robotic perception setting, the problem of detecting object instances remains unsolved, even in the tabletop setting, where segmentation is greatly simplified. Existing object detection systems often focus on textured objects, for which local feature descriptors can be used to reliably obtain correspondences between different views of the same object. We examine the benefits of dense feature extraction and multimodal features for improving the accuracy and robustness of an instance recognition system. By combining multiple modalities and blending their scores through an ensemble-based method in order to generate our final object hypotheses, we obtain significant improvements over previously published results on two RGB-D datasets. On the Challenge dataset, our method results in only one missed detection (achieving 100 …",
        "year": 2013,
        "authors": "Ziang Xie and Arjun Singh and Justin Uang and Karthik Narayan and Pieter Abbeel"
      },
      {
        "title": "Range sensor and silhouette fusion for high-quality 3D Scanning",
        "abstract": "We consider the problem of building high-quality 3D object models from commodity RGB and depth sensors. Applications of such a database include instance and object recognition, robot grasping, virtual reality, graphics, and online shopping. Unfortunately, modern reconstruction approaches have difficulties in reconstructing objects with major transparencies (e.g., KinectFusion [22]) and/or concavities (e.g., visual hull). This paper presents a method to fuse visual hull information from off-the-shelf RGB cameras and KinectFusion cues from commodity depth sensors to produce models that are substantially better than either approach on its own. Extensive experiments on the recently published BigBIRD dataset [25] demonstrate that our reconstructions recover more accurate shape and detail than competing approaches, particularly on challenging objects with transparencies and/or concavities. Quantitative …",
        "year": 2015,
        "authors": "Karthik S Narayan and James Sha and Arjun Singh and Pieter Abbeel"
      }
    ],
    "w4yTWwoAAAAJ": [
      {
        "title": "Context autoencoder for self-supervised representation learning",
        "abstract": "We present a novel masked image modeling (MIM) approach, context autoencoder (CAE), for self-supervised representation pretraining. We pretrain an encoder by making predictions in the encoded representation space. The pretraining tasks include two tasks: masked representation prediction—predict the representations for the masked patches, and masked patch reconstruction—reconstruct the masked patches. The network is an encoder–regressor–decoder architecture: the encoder takes the visible patches as input; the regressor predicts the representations of the masked patches, which are expected to be aligned with the representations computed from the encoder, using the representations of visible patches and the positions of visible and masked patches; the decoder reconstructs the masked patches from the predicted encoded representations. The CAE design encourages the separation of learning the …",
        "year": 2024,
        "authors": "Xiaokang Chen and Mingyu Ding and Xiaodi Wang and Ying Xin and Shentong Mo and Yunhao Wang and Shumin Han and Ping Luo and Gang Zeng and Jingdong Wang"
      },
      {
        "title": "Davit: Dual attention vision transformers",
        "abstract": "In this work, we introduce Dual Attention Vision Transformers  (DaViT), a simple yet effective vision transformer architecture that is able to capture global context while maintaining computational efficiency. We propose approaching the problem from an orthogonal angle: exploiting self-attention mechanisms with both “spatial tokens” and “channel tokens”. With spatial tokens, the spatial dimension defines the token scope, and the channel dimension defines the token feature dimension. With channel tokens, we have the inverse: the channel dimension defines the token scope, and the spatial dimension defines the token feature dimension. We further group tokens along the sequence direction for both spatial and channel tokens to maintain the linear complexity of the entire model. We show that these two self-attentions complement each other: (i) since each channel token contains an abstract representation of the …",
        "year": 2022,
        "authors": "Mingyu Ding and Bin Xiao and Noel Codella and Ping Luo and Jingdong Wang and Lu Yuan"
      }
    ],
    "-ltRSM0AAAAJ": [
      {
        "title": "Fully convolutional networks for semantic segmentation",
        "abstract": "Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build\" fully convolutional\" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.",
        "year": 2015,
        "authors": "Jonathan Long and Evan Shelhamer and Trevor Darrell"
      },
      {
        "title": "Caffe: Convolutional architecture for fast feature embedding",
        "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community …",
        "year": 2014,
        "authors": "Yangqing Jia and Evan Shelhamer and Jeff Donahue and Sergey Karayev and Jonathan Long and Ross Girshick and Sergio Guadarrama and Trevor Darrell"
      },
      {
        "title": "Fully Convolutional Networks for Semantic Segmentation",
        "abstract": "Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation. Our key insight is to build “fully convolutional” networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to …",
        "year": 2016,
        "authors": "Evan Shelhamer and Jonathan Long and Trevor Darrell"
      }
    ],
    "gd04NQ8AAAAJ": [
      {
        "title": "A catalog of genetic loci associated with kidney function from analyses of a million individuals",
        "abstract": "Chronic kidney disease (CKD) is responsible for a public health burden with multi-systemic complications. Through trans-ancestry meta-analysis of genome-wide association studies of estimated glomerular filtration rate (eGFR) and independent replication (n = 1,046,070), we identified 264 associated loci (166 new). Of these, 147 were likely to be relevant for kidney function on the basis of associations with the alternative kidney function marker blood urea nitrogen (n = 416,178). Pathway and enrichment analyses, including mouse models with renal phenotypes, support the kidney as the main target organ. A genetic risk score for lower eGFR was associated with clinically diagnosed CKD in 452,264 independent individuals. Colocalization analyses of associations with eGFR among 783,978 European-ancestry individuals and gene expression across 46 human tissues, including tubulo-interstitial and …",
        "year": 2019,
        "authors": "Matthias Wuttke and Yong Li and Man Li and Karsten B Sieber and Mary F Feitosa and Mathias Gorski and Adrienne Tin and Lihua Wang and Audrey Y Chu and Anselm Hoppmann and Holger Kirsten and Ayush Giri and Jin-Fang Chai and Gardar Sveinbjornsson and Bamidele O Tayo and Teresa Nutile and Christian Fuchsberger and Jonathan Marten and Massimiliano Cocca and Sahar Ghasemi and Yizhe Xu and Katrin Horn and Damia Noce and Peter J Van der Most and Sanaz Sedaghat and Zhi Yu and Masato Akiyama and Saima Afaq and Tarunveer S Ahluwalia and Peter Almgren and Najaf Amin and Johan Ärnlöv and Stephan JL Bakker and Nisha Bansal and Daniela Baptista and Sven Bergmann and Mary L Biggs and Ginevra Biino and Michael Boehnke and Eric Boerwinkle and Mathilde Boissel and Erwin P Bottinger and Thibaud S Boutin and Hermann Brenner and Marco Brumat and Ralph Burkhardt and Adam S Butterworth and Eric Campana and Archie Campbell and Harry Campbell and Mickael Canouil and Robert J Carroll and Eulalia Catamo and John C Chambers and Miao-Ling Chee and Miao-Li Chee and Xu Chen and Ching-Yu Cheng and Yurong Cheng and Kaare Christensen and Renata Cifkova and Marina Ciullo and Maria Pina Concas and James P Cook and Josef Coresh and Tanguy Corre and Cinzia Felicita Sala and Daniele Cusi and John Danesh and E Warwick Daw and Martin H De Borst and Alessandro De Grandi and Renee De Mutsert and Aiko PJ De Vries and Frauke Degenhardt and Graciela Delgado and Ayse Demirkan and Emanuele Di Angelantonio and Katalin Dittrich and Jasmin Divers and Rajkumar Dorajoo and Kai-Uwe Eckardt and Georg Ehret and Paul Elliott and Karlhans Endlich and Michele K Evans and Janine F Felix and Valencia Hui Xian Foo and Oscar H Franco and Andre Franke and Barry I Freedman and Sandra Freitag-Wolf and Yechiel Friedlander and Philippe Froguel and Ron T Gansevoort and He Gao and Paolo Gasparini and J Michael Gaziano and Vilmantas Giedraitis and Christian Gieger and Giorgia Girotto and Franco Giulianini and Martin Gögele and Scott D Gordon and Daniel F Gudbjartsson and Vilmundur Gudnason and Toomas Haller and Pavel Hamet and Tamara B Harris and Catharina A Hartman and Caroline Hayward and Jacklyn N Hellwege and Chew-Kiat Heng and Andrew A Hicks and Edith Hofer and Wei Huang and Nina Hutri-Kähönen and Shih-Jen Hwang and M Arfan Ikram and Olafur S Indridason and Erik Ingelsson and Marcus Ising and Vincent WV Jaddoe and Johanna Jakobsdottir and Jost B Jonas and Peter K Joshi and Navya Shilpa Josyula and Bettina Jung and Mika Kähönen and Yoichiro Kamatani and Candace M Kammerer and Masahiro Kanai and Mika Kastarinen and Shona M Kerr and Chiea-Chuen Khor and Wieland Kiess and Marcus E Kleber and Wolfgang Koenig and Jaspal S Kooner and Antje Körner and Peter Kovacs and Aldi T Kraja and Alena Krajcoviechova and Holly Kramer and Bernhard K Krämer and Florian Kronenberg and Michiaki Kubo and Brigitte Kühnel and Mikko Kuokkanen and Johanna Kuusisto"
      },
      {
        "title": "Target genes, variants, tissues and transcriptional pathways influencing human serum urate levels",
        "abstract": "Elevated serum urate levels cause gout and correlate with cardiometabolic diseases via poorly understood mechanisms. We performed a trans-ancestry genome-wide association study of serum urate in 457,690 individuals, identifying 183 loci (147 previously unknown) that improve the prediction of gout in an independent cohort of 334,880 individuals. Serum urate showed significant genetic correlations with many cardiometabolic traits, with genetic causality analyses supporting a substantial role for pleiotropy. Enrichment analysis, fine-mapping of urate-associated loci and colocalization with gene expression in 47 tissues implicated the kidney and liver as the main target organs and prioritized potentially causal genes and variants, including the transcriptional master regulators in the liver and kidney, HNF1A and HNF4A. Experimental validation showed that HNF4A transactivated the promoter of ABCG2, encoding …",
        "year": 2019,
        "authors": "Adrienne Tin and Jonathan Marten and Victoria L Halperin Kuhns and Yong Li and Matthias Wuttke and Holger Kirsten and Karsten B Sieber and Chengxiang Qiu and Mathias Gorski and Zhi Yu and Ayush Giri and Gardar Sveinbjornsson and Man Li and Audrey Y Chu and Anselm Hoppmann and Luke J O’Connor and Bram Prins and Teresa Nutile and Damia Noce and Masato Akiyama and Massimiliano Cocca and Sahar Ghasemi and Peter J van Der Most and Katrin Horn and Yizhe Xu and Christian Fuchsberger and Sanaz Sedaghat and Saima Afaq and Najaf Amin and Johan Ärnlöv and Stephan JL Bakker and Nisha Bansal and Daniela Baptista and Sven Bergmann and Mary L Biggs and Ginevra Biino and Eric Boerwinkle and Erwin P Bottinger and Thibaud S Boutin and Marco Brumat and Ralph Burkhardt and Eric Campana and Archie Campbell and Harry Campbell and Robert J Carroll and Eulalia Catamo and John C Chambers and Marina Ciullo and Maria Pina Concas and Josef Coresh and Tanguy Corre and Daniele Cusi and Sala Cinzia Felicita and Martin H de Borst and Alessandro De Grandi and Renée de Mutsert and Aiko PJ de Vries and Graciela Delgado and Ayşe Demirkan and Olivier Devuyst and Katalin Dittrich and Kai-Uwe Eckardt and Georg Ehret and Karlhans Endlich and Michele K Evans and Ron T Gansevoort and Paolo Gasparini and Vilmantas Giedraitis and Christian Gieger and Giorgia Girotto and Martin Gögele and Scott D Gordon and Daniel F Gudbjartsson and Vilmundur Gudnason and German Chronic Kidney Disease Study and Toomas Haller and Pavel Hamet and Tamara B Harris and Caroline Hayward and Andrew A Hicks and Edith Hofer and Hilma Holm and Wei Huang and Nina Hutri-Kähönen and Shih-Jen Hwang and M Arfan Ikram and Raychel M Lewis and Erik Ingelsson and Johanna Jakobsdottir and Ingileif Jonsdottir and Helgi Jonsson and Peter K Joshi and Navya Shilpa Josyula and Bettina Jung and Mika Kähönen and Yoichiro Kamatani and Masahiro Kanai and Shona M Kerr and Wieland Kiess and Marcus E Kleber and Wolfgang Koenig and Jaspal S Kooner and Antje Körner and Peter Kovacs and Bernhard K Krämer and Florian Kronenberg and Michiaki Kubo and Brigitte Kühnel and Martina La Bianca and Leslie A Lange and Benjamin Lehne and Terho Lehtimäki and Lifelines Cohort Study and Jun Liu and Markus Loeffler and Ruth JF Loos and Leo-Pekka Lyytikäinen and Reedik Magi and Anubha Mahajan and Nicholas G Martin and Winfried März and Deborah Mascalzoni and Koichi Matsuda and Christa Meisinger and Thomas Meitinger and Andres Metspalu and Yuri Milaneschi and VA Million Veteran Program and Christopher J O’Donnell and Otis D Wilson and J Michael Gaziano and Pashupati P Mishra and Karen L Mohlke and Nina Mononen and Grant W Montgomery and Dennis O Mook-Kanamori and Martina Müller-Nurasyid and Girish N Nadkarni and Mike A Nalls and Matthias Nauck and Kjell Nikus and Boting Ning and Ilja M Nolte and Raymond Noordam and Jeffrey R O’Connell and Isleifur Olafsson and Sandosh Padmanabhan and Brenda WJH Penninx and Thomas Perls and Annette Peters"
      },
      {
        "title": "Information technology and lifestyle: a systematic evaluation of internet and mobile interventions for improving diet, physical activity, obesity, tobacco, and alcohol use",
        "abstract": "Novel interventions are needed to improve lifestyle and prevent noncommunicable diseases, the leading cause of death and disability globally. This study aimed to systematically review, synthesize, and grade scientific evidence on effectiveness of novel information and communication technology to reduce noncommunicable disease risk.We systematically searched PubMed for studies evaluating the effect of Internet, mobile phone, personal sensors, or stand‐alone computer software on diet, physical activity, adiposity, tobacco, or alcohol use. We included all interventional and prospective observational studies conducted among generally healthy adults published between January 1990 and November 2013. American Heart Association criteria were used to evaluate and grade the strength of evidence. From 8654 abstracts, 224 relevant reports were identified. Internet and mobile …",
        "year": 2016,
        "authors": "Ashkan Afshin and Damilola Babalola and Mireille Mclean and Zhi Yu and Wenjie Ma and Cheng‐Yu Chen and Mandana Arabi and Dariush Mozaffarian"
      }
    ],
    "sJDqACEAAAAJ": [
      {
        "title": "Starcoder: may the source be with you!",
        "abstract": "The BigCode community, an open-scientific collaboration working on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder and StarCoderBase: 15.5B parameter models with 8K context length, infilling capabilities and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories with inspection tools and an opt-out process. We fine-tuned StarCoderBase on 35B Python tokens, resulting in the creation of StarCoder. We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model. Furthermore, StarCoder outperforms every model that is fine-tuned on Python, can be prompted to achieve 40\\% pass@1 on HumanEval, and still retains its performance on other programming languages. We take several important steps towards a safe open-access model release, including an improved PII redaction pipeline and a novel attribution tracing tool, and make the StarCoder models publicly available under a more commercially viable version of the Open Responsible AI Model license.",
        "year": 2023,
        "authors": "Raymond Li and Loubna Ben Allal and Yangtian Zi and Niklas Muennighoff and Denis Kocetkov and Chenghao Mou and Marc Marone and Christopher Akiki and Jia Li and Jenny Chim and Qian Liu and Evgenii Zheltonozhskii and Terry Yue Zhuo and Thomas Wang and Olivier Dehaene and Mishig Davaadorj and Joel Lamy-Poirier and João Monteiro and Oleh Shliazhko and Nicolas Gontier and Nicholas Meade and Armel Zebaze and Ming-Ho Yee and Logesh Kumar Umapathi and Jian Zhu and Benjamin Lipkin and Muhtasham Oblokulov and Zhiruo Wang and Rudra Murthy and Jason Stillerman and Siva Sankalp Patel and Dmitry Abulkhanov and Marco Zocca and Manan Dey and Zhihan Zhang and Nour Fahmy and Urvashi Bhattacharyya and Wenhao Yu and Swayam Singh and Sasha Luccioni and Paulo Villegas and Maxim Kunakov and Fedor Zhdanov and Manuel Romero and Tony Lee and Nadav Timor and Jennifer Ding and Claire Schlesinger and Hailey Schoelkopf and Jan Ebert and Tri Dao and Mayank Mishra and Alex Gu and Jennifer Robinson and Carolyn Jane Anderson and Brendan Dolan-Gavitt and Danish Contractor and Siva Reddy and Daniel Fried and Dzmitry Bahdanau and Yacine Jernite and Carlos Muñoz Ferrandis and Sean Hughes and Thomas Wolf and Arjun Guha and Leandro von Werra and Harm de Vries"
      },
      {
        "title": "Incoder: A generative model for code infilling and synthesis",
        "abstract": "Code is seldom written in a single left-to-right pass and is instead repeatedly edited and refined. We introduce InCoder, a unified generative model that can perform program synthesis (via left-to-right generation) as well as editing (via infilling). InCoder is trained to generate code files from a large corpus of permissively licensed code, where regions of code have been randomly masked and moved to the end of each file, allowing code infilling with bidirectional context. Our model is the first generative model that is able to directly perform zero-shot code infilling, which we evaluate on challenging tasks such as type inference, comment generation, and variable re-naming. We find that the ability to condition on bidirectional context substantially improves performance on these tasks, while still performing comparably on standard program synthesis benchmarks in comparison to left-to-right only models pretrained at similar scale. The InCoder models and code are publicly released. https://sites.google.com/view/incoder-code-models",
        "year": 2022,
        "authors": "Daniel Fried and Armen Aghajanyan and Jessy Lin and Sida Wang and Eric Wallace and Freda Shi and Ruiqi Zhong and Wen-tau Yih and Luke Zettlemoyer and Mike Lewis"
      },
      {
        "title": "Speaker-follower models for vision-and-language navigation",
        "abstract": "Navigation guided by natural language instructions presents a challenging reasoning problem for instruction followers. Natural language instructions typically identify only a few high-level decisions and landmarks rather than complete low-level motor behaviors; much of the missing information must be inferred based on perceptual context. In machine learning settings, this is doubly challenging: it is difficult to collect enough annotated data to enable learning of this reasoning process from scratch, and also difficult to implement the reasoning process using generic sequence models. Here we describe an approach to vision-and-language navigation that addresses both these issues with an embedded speaker model. We use this speaker model to (1) synthesize new instructions for data augmentation and to (2) implement pragmatic reasoning, which evaluates how well candidate action sequences explain an instruction. Both steps are supported by a panoramic action space that reflects the granularity of human-generated instructions. Experiments show that all three components of this approach---speaker-driven data augmentation, pragmatic reasoning and panoramic action space---dramatically improve the performance of a baseline instruction follower, more than doubling the success rate over the best existing approach on a standard benchmark.",
        "year": 2018,
        "authors": "Daniel Fried and Ronghang Hu and Volkan Cirik and Anna Rohrbach and Jacob Andreas and Louis-Philippe Morency and Taylor Berg-Kirkpatrick and Kate Saenko and Dan Klein and Trevor Darrell"
      }
    ],
    "PpzsjioAAAAJ": [
      {
        "title": "Fast: Efficient action tokenization for vision-language-action models",
        "abstract": "Autoregressive sequence models, such as Transformer-based vision-language action (VLA) policies, can be tremendously effective for capturing complex and generalizable robotic behaviors. However, such models require us to choose a tokenization of our continuous action signals, which determines how the discrete symbols predicted by the model map to continuous robot actions. We find that current approaches for robot action tokenization, based on simple per-dimension, per-timestep binning schemes, typically perform poorly when learning dexterous skills from high-frequency robot data. To address this challenge, we propose a new compression-based tokenization scheme for robot actions, based on the discrete cosine transform. Our tokenization approach, Frequency-space Action Sequence Tokenization (FAST), enables us to train autoregressive VLAs for highly dexterous and high-frequency tasks where standard discretization methods fail completely. Based on FAST, we release FAST+, a universal robot action tokenizer, trained on 1M real robot action trajectories. It can be used as a black-box tokenizer for a wide range of robot action sequences, with diverse action spaces and control frequencies. Finally, we show that, when combined with the pi0 VLA, our method can scale to training on 10k hours of robot data and match the performance of diffusion VLAs, while reducing training time by up to 5x.",
        "year": 2025,
        "authors": "Karl Pertsch and Kyle Stachowicz and Brian Ichter and Danny Driess and Suraj Nair and Quan Vuong and Oier Mees and Chelsea Finn and Sergey Levine"
      },
      {
        "title": "Safety embedded differential dynamic programming using discrete barrier states",
        "abstract": "Certified safe control is a growing challenge in robotics, especially when performance and safety objectives must be concurrently achieved. In this work, we extend the barrier state (BaS) concept, recently proposed for safe stabilization of continuous time systems, to safety embedded trajectory optimization for discrete time systems using discrete barrier states (DBaS). The constructed DBaS is embedded into the discrete model of the safety-critical system integrating safety objectives into the system's dynamics and performance objectives. Thereby, the control policy is directly supplied by safety-critical information through the b rrier state. This allows us to employ the DBaS with differential dynamic programming (DDP) to plan and execute safe optimal trajectories. The proposed algorithm is leveraged on various safety-critical control and planning problems including a differential wheeled robot safe navigation in …",
        "year": 2022,
        "authors": "Hassan Almubarak and Kyle Stachowicz and Nader Sadegh and Evangelos A Theodorou"
      }
    ],
    "Rn_BmTYAAAAJ": [
      {
        "title": "Pacgan: The power of two samples in generative adversarial networks",
        "abstract": "Generative adversarial networks (GANs) are a technique for learning generative models of complex data distributions from samples. Despite remarkable advances in generating realistic images, a major shortcoming of GANs is the fact that they tend to produce samples with little diversity, even when trained on diverse datasets. This phenomenon, known as mode collapse, has been the focus of much recent work. We study a principled approach to handling mode collapse, which we call packing. The main idea is to modify the discriminator to make decisions based on multiple samples from the same class, either real or artificially generated. We draw analysis tools from binary hypothesis testing---in particular the seminal result of Blackwell---to prove a fundamental connection between packing and mode collapse. We show that packing naturally penalizes generators with mode collapse, thereby favoring generator distributions with less mode collapse during the training process. Numerical experiments on benchmark datasets suggest that packing provides significant improvements.",
        "year": 2018,
        "authors": "Zinan Lin and Ashish Khetan and Giulia Fanti and Sewoong Oh"
      },
      {
        "title": "Prism: Deconstructing the blockchain to approach physical limits",
        "abstract": "The concept of a blockchain was invented by Satoshi Nakamoto to maintain a distributed ledger. In addition to its security, important performance measures of a blockchain protocol are its transaction throughput and confirmation latency. In a decentralized setting, these measures are limited by two underlying physical network attributes: communication capacity and speed-of-light propagation delay. In this work we introduce Prism, a new proof-of-work blockchain protocol, which can achieve 1) security against up to 50% adversarial hashing power; 2) optimal throughput up to the capacity C of the network; 3) confirmation latency for honest transactions proportional to the propagation delay D, with confirmation error probability exponentially small in the bandwidth-delay product CD; 4) eventual total ordering of all transactions. Our approach to the design of this protocol is based on deconstructing Nakamoto's blockchain …",
        "year": 2019,
        "authors": "Vivek Bagaria and Sreeram Kannan and David Tse and Giulia Fanti and Pramod Viswanath"
      },
      {
        "title": "Building a RAPPOR with the unknown: Privacy-preserving learning of associations and data dictionaries",
        "abstract": "Techniques based on randomized response enable the collection of potentially sensitive data from clients in a privacy-preserving manner with strong local differential privacy guarantees. One of the latest such technologies, RAPPOR, allows the marginal frequencies of an arbitrary set of strings to be estimated via privacy-preserving crowdsourcing. However, this original estimation process requires a known set of possible strings; in practice, this dictionary can often be extremely large and sometimes completely unknown. In this paper, we propose a novel decoding algorithm for the RAPPOR mechanism that enables the estimation of \"unknown unknowns,\" i.e., strings we do not even know we should be estimating. To enable learning without explicit knowledge of the dictionary, we develop methodology for estimating the joint distribution of two or more variables collected with RAPPOR. This is a critical step towards understanding relationships between multiple variables collected in a privacy-preserving manner.",
        "year": 2015,
        "authors": "Giulia Fanti and Vasyl Pihur and Úlfar Erlingsson"
      }
    ],
    "YAHWbtkAAAAJ": [
      {
        "title": "Tackling climate change with machine learning",
        "abstract": "Climate change is one of the greatest challenges facing humanity, and we, as machine learning (ML) experts, may wonder how we can help. Here we describe how ML can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by ML, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the ML community to join the global effort against climate change.",
        "year": 2022,
        "authors": "David Rolnick and Priya L Donti and Lynn H Kaack and Kelly Kochanski and Alexandre Lacoste and Kris Sankaran and Andrew Slavin Ross and Nikola Milojevic-Dupont and Natasha Jaques and Anna Waldman-Brown and Alexandra Sasha Luccioni and Tegan Maharaj and Evan D Sherwin and S Karthik Mukkavilli and Konrad P Kording and Carla P Gomes and Andrew Y Ng and Demis Hassabis and John C Platt and Felix Creutzig and Jennifer Chayes and Yoshua Bengio"
      },
      {
        "title": "Maximizing social influence in nearly optimal time",
        "abstract": "Diffusion is a fundamental graph process, underpinning such phenomena as epidemic disease contagion and the spread of innovation by word-of-mouth. We address the algorithmic problem of finding a set of k initial seed nodes in a network so that the expected size of the resulting cascade is maximized, under the standard independent cascade model of network diffusion. Runtime is a primary consideration for this problem due to the massive size of the relevant input networks.We provide a fast algorithm for the influence maximization problem, obtaining the near-optimal approximation factor of , for any ∊ > 0, in time O((m + n)∊−3 log n). Our algorithm is runtime-optimal (up to a logarithmic factor) and substantially improves upon the previously best-known algorithms which run in time Ω(mnk · POLY(∊−1)). Furthermore, our algorithm can be modified to allow early termination: if it is terminated after O(β(m + n) logn …",
        "year": 2014,
        "authors": "Christian Borgs and Michael Brautbar and Jennifer Chayes and Brendan Lucier"
      },
      {
        "title": "Entropy-SGD: Biasing gradient descent into wide valleys",
        "abstract": "This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in the sharp valleys. Conceptually, our algorithm resembles two nested loops of SGD where we use Langevin dynamics in the inner loop to compute the gradient of the local entropy before each update of the weights. We show that the new objective has a smoother energy landscape and show improved generalization over SGD using uniform stability, under …",
        "year": 2019,
        "authors": "Pratik Chaudhari and Anna Choromanska and Stefano Soatto and Yann LeCun and Carlo Baldassi and Christian Borgs and Jennifer Chayes and Levent Sagun and Riccardo Zecchina"
      }
    ],
    "23LELwEAAAAJ": [
      {
        "title": "Synthetic Data for Text Localisation in Natural Images",
        "abstract": "In this paper we introduce a new method for text detection in natural images. The method comprises two contributions: First, a fast and scalable engine to generate synthetic images of text in clutter. This engine overlays synthetic text to existing background images in a natural way, accounting for the local 3D scene geometry. Second, we use the synthetic images to train a Fully-Convolutional Regression Network (FCRN) which efficiently performs text detection and bounding-box regression at all locations and multiple scales in an image. We discuss the relation of FCRN to the recently-introduced YOLO detector, as well as other end-to-end object detection systems based on deep learning. The resulting detection network significantly out performs current methods for text detection in natural images, achieving an F-measure of 84.2% on the standard ICDAR 2013 benchmark. Furthermore, it can process 15 images per second on a GPU.",
        "year": 2016,
        "authors": "Ankush Gupta and Andrea Vedaldi and Andrew Zisserman"
      },
      {
        "title": "VGG image annotator (VIA)",
        "abstract": "VGG Image Annotator (VIA) Page 1 VGG Image Annotator (VIA) Dr. Abhishek Dutta Research \nSoftware Engineer adutta@robots.ox.ac.uk Seebibyte: Show and Tell Event, 15 June 2017 Page 2 \nManual Image Annotation Define and describe regions in an image Page 3 Manual Image \nAnnotation Define and describe regions in an image Source: Matilde Malaspina, Faculty of Medieval \nand Modern Languages, Oxford. Page 4 Manual Image Annotation Define and describe regions in \nan image Source: Eli Walker, School of Geography and the Environment, Oxford Page 5 Manual \nImage Annotation Define and describe regions in an image Source: Eli Walker, School of \nGeography and the Environment, Oxford Page 6 Live Demo \nhttp://www.robots.ox.ac.uk/~vgg/software/via/via.html Page 7 VGG Image Annotator ● no installation \nrequired (runs in a web browser) ● Based solely on ~5000 lines of HTML, CSS & Javascript …",
        "year": 2016,
        "authors": "Abhishek Dutta and Ankush Gupta and Andrew Zissermann"
      },
      {
        "title": "CrossTransformers: spatially-aware few-shot transfer",
        "abstract": "Given new tasks with very little data---such as new classes in a classification problem or a domain shift in the input---performance of modern vision systems degrades remarkably quickly. In this work, we illustrate how the neural network representations which underpin modern vision systems are subject to supervision collapse, whereby they lose any information that is not necessary for performing the training task, including information that may be necessary for transfer to new tasks or domains. We then propose two methods to mitigate this problem. First, we employ self-supervised learning to encourage general-purpose features that transfer better. Second, we propose a novel Transformer based neural network architecture called CrossTransformers, which can take a small number of labeled images and an unlabeled query, find coarse spatial correspondence between the query and the labeled images, and then infer class membership by computing distances between spatially-corresponding features. The result is a classifier that is more robust to task and domain shift, which we demonstrate via state-of-the-art performance on Meta-Dataset, a recent dataset for evaluating transfer from ImageNet to many other vision datasets.",
        "year": 2020,
        "authors": "Carl Doersch and Ankush Gupta and Andrew Zisserman"
      }
    ],
    "XXUsEjsAAAAJ": [
      {
        "title": "Random features for large-scale kernel machines",
        "abstract": "To accelerate the training of kernel machines, we propose to map the input data to a randomized low-dimensional feature space and then apply existing fast linear methods. The features are designed so that the inner products of the transformed data are approximately equal to those in the feature space of a user specified shiftinvariant kernel. We explore two sets of random features, provide convergence bounds on their ability to approximate various radial basis kernels, and show that in large-scale classification and regression tasks linear machine learning algorithms applied to these features outperform state-of-the-art large-scale kernel machines.",
        "year": 2007,
        "authors": "Ali Rahimi and Benjamin Recht"
      },
      {
        "title": "Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning",
        "abstract": "Randomized neural networks are immortalized in this AI Koan: In the days when Sussman was a novice, Minsky once came to him as he sat hacking at the PDP-6. What are you doing?''asked Minsky. I am training a randomly wired neural net to play tic-tac-toe,''Sussman replied. Why is the net wired randomly?''asked Minsky. Sussman replied, I do not want it to have any preconceptions of how to play.''Minsky then shut his eyes. Why do you close your eyes?''Sussman asked his teacher. So that the room will be empty,''replied Minsky. At that moment, Sussman was enlightened. We analyze shallow random networks with the help of concentration of measure inequalities. Specifically, we consider architectures that compute a weighted sum of their inputs after passing them through a bank of arbitrary randomized nonlinearities. We identify conditions under which these networks exhibit good classification performance, and bound their test error in terms of the size of the dataset and the number of random nonlinearities.",
        "year": 2008,
        "authors": "Ali Rahimi and Benjamin Recht"
      },
      {
        "title": "The mobile sensing platform: An embedded activity recognition system",
        "abstract": "Activity-aware systems have inspired novel user interfaces and new applications in smart environments, surveillance, emergency response, and military missions. Systems that recognize human activities from body-worn sensors can further open the door to a world of healthcare applications, such as fitness monitoring, eldercare support, long-term preventive and chronic care, and cognitive assistance. Wearable systems have the advantage of being with the user continuously. So, for example, a fitness application could use real-time activity information to encourage users to perform opportunistic activities. Furthermore, the general public is more likely to accept such activity recognition systems because they are usually easy to turn off or remove.",
        "year": 2008,
        "authors": "Tanzeem Choudhury and Gaetano Borriello and Sunny Consolvo and Dirk Haehnel and Beverly Harrison and Bruce Hemingway and Jeffrey Hightower and Predrag Pedja and Karl Koscher and Anthony LaMarca and James A Landay and Louis LeGrand and Jonathan Lester and Ali Rahimi and Adam Rea and Danny Wyatt"
      }
    ],
    "chICXXMAAAAJ": [
      {
        "title": "Offline reinforcement learning with realizability and single-policy concentrability",
        "abstract": "Sample-efficiency guarantees for offline reinforcement learning (RL) often rely on strong assumptions on both the function classes (eg, Bellman-completeness) and the data coverage (eg, all-policy concentrability). Despite the recent efforts on relaxing these assumptions, existing works are only able to relax one of the two factors, leaving the strong assumption on the other factor intact. As an important open problem, can we achieve sample-efficient offline RL with weak assumptions on both factors? In this paper we answer the question in the positive. We analyze a simple algorithm based on the primal-dual formulation of MDPs, where the dual variables (discounted occupancy) are modeled using a density-ratio function against offline data. With proper regularization, the algorithm enjoys polynomial sample complexity, under only realizability and single-policy concentrability. We also provide alternative analyses based on different assumptions to shed light on the nature of primal-dual algorithms for offline RL.",
        "year": 2022,
        "authors": "Wenhao Zhan and Baihe Huang and Audrey Huang and Nan Jiang and Jason Lee"
      },
      {
        "title": "Policy mirror descent for regularized reinforcement learning: A generalized framework with linear convergence",
        "abstract": "Policy optimization, which learns the policy of interest by maximizing the value function via large-scale optimization techniques, lies at the heart of modern reinforcement learning (RL). In addition to value maximization, other practical considerations arise commonly as well, including the need of encouraging exploration, and that of ensuring certain structural properties of the learned policy due to safety, resource, and operational constraints. These considerations can often be accounted for by resorting to regularized RL, which augments the target value function with a structure-promoting regularization term. Focusing on an infinite-horizon discounted tabular Markov decision process, this paper proposes a generalized policy mirror descent (GPMD) algorithm for solving regularized RL. As a generalization of policy mirror descent [G. Lan, Math. Program., 198 (2023), pp. 1059–1106], the proposed algorithm …",
        "year": 2023,
        "authors": "Wenhao Zhan and Shicong Cen and Baihe Huang and Yuxin Chen and Jason D Lee and Yuejie Chi"
      },
      {
        "title": "Fl-ntk: A neural tangent kernel-based framework for federated learning analysis",
        "abstract": "Federated Learning (FL) is an emerging learning scheme that allows different distributed clients to train deep neural networks together without data sharing. Neural networks have become popular due to their unprecedented success. To the best of our knowledge, the theoretical guarantees of FL concerning neural networks with explicit forms and multi-step updates are unexplored. Nevertheless, training analysis of neural networks in FL is non-trivial for two reasons: first, the objective loss function we are optimizing is non-smooth and non-convex, and second, we are even not updating in the gradient direction. Existing convergence results for gradient descent-based methods heavily rely on the fact that the gradient direction is used for updating. The current paper presents a new class of convergence analysis for FL, Federated Neural Tangent Kernel (FL-NTK), which corresponds to overparamterized ReLU neural networks trained by gradient descent in FL and is inspired by the analysis in Neural Tangent Kernel (NTK). Theoretically, FL-NTK converges to a global-optimal solution at a linear rate with properly tuned learning parameters. Furthermore, with proper distributional assumptions, FL-NTK can also achieve good generalization. The proposed theoretical analysis scheme can be generalized to more complex neural networks.",
        "year": 2021,
        "authors": "Baihe Huang and Xiaoxiao Li and Zhao Song and Xin Yang"
      }
    ],
    "23ZXZvEAAAAJ": [
      {
        "title": "Analysis of protein-coding genetic variation in 60,706 humans",
        "abstract": "Large-scale reference data sets of human genetic variation are critical for the medical and functional interpretation of DNA sequence changes. Here we describe the aggregation and analysis of high-quality exome (protein-coding region) DNA sequence data for 60,706 individuals of diverse ancestries generated as part of the Exome Aggregation Consortium (ExAC). This catalogue of human genetic diversity contains an average of one variant every eight bases of the exome, and provides direct evidence for the presence of widespread mutational recurrence. We have used this catalogue to calculate objective metrics of pathogenicity for sequence variants, and to identify genes subject to strong selection against various classes of mutation; identifying 3,230 genes with near-complete depletion of predicted protein-truncating variants, with 72% of these genes having no currently established human disease phenotype …",
        "year": 2016,
        "authors": "Monkol Lek and Konrad J Karczewski and Eric V Minikel and Kaitlin E Samocha and Eric Banks and Timothy Fennell and Anne H O’Donnell-Luria and James S Ware and Andrew J Hill and Beryl B Cummings and Taru Tukiainen and Daniel P Birnbaum and Jack A Kosmicki and Laramie E Duncan and Karol Estrada and Fengmei Zhao and James Zou and Emma Pierce-Hoffman and Joanne Berghout and David N Cooper and Nicole Deflaux and Mark DePristo and Ron Do and Jason Flannick and Menachem Fromer and Laura Gauthier and Jackie Goldstein and Namrata Gupta and Daniel Howrigan and Adam Kiezun and Mitja I Kurki and Ami Levy Moonshine and Pradeep Natarajan and Lorena Orozco and Gina M Peloso and Ryan Poplin and Manuel A Rivas and Valentin Ruano-Rubio and Samuel A Rose and Douglas M Ruderfer and Khalid Shakir and Peter D Stenson and Christine Stevens and Brett P Thomas and Grace Tiao and Maria T Tusie-Luna and Ben Weisburd and Hong-Hee Won and Dongmei Yu and David M Altshuler and Diego Ardissino and Michael Boehnke and John Danesh and Stacey Donnelly and Roberto Elosua and Jose C Florez and Stacey B Gabriel and Gad Getz and Stephen J Glatt and Christina M Hultman and Sekar Kathiresan and Markku Laakso and Steven McCarroll and Mark I McCarthy and Dermot McGovern and Ruth McPherson and Benjamin M Neale and Aarno Palotie and Shaun M Purcell and Danish Saleheen and Jeremiah M Scharf and Pamela Sklar and Patrick F Sullivan and Jaakko Tuomilehto and Ming T Tsuang and Hugh C Watkins and James G Wilson and Mark J Daly and Daniel G MacArthur and Exome Aggregation Consortium"
      },
      {
        "title": "Man is to computer programmer as woman is to homemaker? debiasing word embeddings",
        "abstract": "The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is first shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender definition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between the words receptionist and female, while maintaining desired associations such as between the words queen and female. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias.",
        "year": 2016,
        "authors": "Tolga Bolukbasi and Kai-Wei Chang and James Y Zou and Venkatesh Saligrama and Adam T Kalai"
      },
      {
        "title": "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models",
        "abstract": "Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit \"breakthrough\" behavior at …",
        "year": 2022,
        "authors": "Aarohi Srivastava and Abhinav Rastogi and Abhishek Rao and Abu Awal Md Shoeb and Abubakar Abid and Adam Fisch and Adam R Brown and Adam Santoro and Aditya Gupta and Adrià Garriga-Alonso and Agnieszka Kluska and Aitor Lewkowycz and Akshat Agarwal and Alethea Power and Alex Ray and Alex Warstadt and Alexander W Kocurek and Ali Safaya and Ali Tazarv and Alice Xiang and Alicia Parrish and Allen Nie and Aman Hussain and Amanda Askell and Amanda Dsouza and Ambrose Slone and Ameet Rahane and Anantharaman S Iyer and Anders Andreassen and Andrea Madotto and Andrea Santilli and Andreas Stuhlmüller and Andrew Dai and Andrew La and Andrew Lampinen and Andy Zou and Angela Jiang and Angelica Chen and Anh Vuong and Animesh Gupta and Anna Gottardi and Antonio Norelli and Anu Venkatesh and Arash Gholamidavoodi and Arfa Tabassum and Arul Menezes and Arun Kirubarajan and Asher Mullokandov and Ashish Sabharwal and Austin Herrick and Avia Efrat and Aykut Erdem and Ayla Karakaş and B Ryan Roberts and Bao Sheng Loe and Barret Zoph and Bartłomiej Bojanowski and Batuhan Özyurt and Behnam Hedayatnia and Behnam Neyshabur and Benjamin Inden and Benno Stein and Berk Ekmekci and Bill Yuchen Lin and Blake Howald and Bryan Orinion and Cameron Diao and Cameron Dour and Catherine Stinson and Cedrick Argueta and César Ferri Ramírez and Chandan Singh and Charles Rathkopf and Chenlin Meng and Chitta Baral and Chiyu Wu and Chris Callison-Burch and Chris Waites and Christian Voigt and Christopher D Manning and Christopher Potts and Cindy Ramirez and Clara E Rivera and Clemencia Siro and Colin Raffel and Courtney Ashcraft and Cristina Garbacea and Damien Sileo and Dan Garrette and Dan Hendrycks and Dan Kilman and Dan Roth and Daniel Freeman and Daniel Khashabi and Daniel Levy and Daniel Moseguí González and Danielle Perszyk and Danny Hernandez and Danqi Chen and Daphne Ippolito and Dar Gilboa and David Dohan and David Drakard and David Jurgens and Debajyoti Datta and Deep Ganguli and Denis Emelin and Denis Kleyko and Deniz Yuret and Derek Chen and Derek Tam and Dieuwke Hupkes and Diganta Misra and Dilyar Buzan and Dimitri Coelho Mollo and Diyi Yang and Dong-Ho Lee and Dylan Schrader and Ekaterina Shutova and Ekin Dogus Cubuk and Elad Segal and Eleanor Hagerman and Elizabeth Barnes and Elizabeth Donoway and Ellie Pavlick and Emanuele Rodola and Emma Lam and Eric Chu and Eric Tang and Erkut Erdem and Ernie Chang and Ethan A Chi and Ethan Dyer and Ethan Jerzak and Ethan Kim and Eunice Engefu Manyasi and Evgenii Zheltonozhskii and Fanyue Xia and Fatemeh Siar and Fernando Martínez-Plumed and Francesca Happé and Francois Chollet and Frieda Rong and Gaurav Mishra and Genta Indra Winata and Gerard de Melo and Germán Kruszewski and Giambattista Parascandolo and Giorgio Mariani and Gloria Wang"
      }
    ],
    "b957ulAAAAAJ": [
      {
        "title": "Segmenting unknown 3d objects from real depth images using mask r-cnn trained on synthetic data",
        "abstract": "The ability to segment unknown objects in depth images has potential to enhance robot skills in grasping and object tracking. Recent computer vision research has demonstrated that Mask R-CNN can be trained to segment specific categories of objects in RGB images when massive hand-labeled datasets are available. As generating these datasets is time-consuming, we instead train with synthetic depth images. Many robots now use depth sensors, and recent results suggest training on synthetic depth data can transfer successfully to the real world. We present a method for automated dataset generation and rapidly generate a synthetic training dataset of 50,000 depth images and 320,000 object masks using simulated heaps of 3D CAD models. We train a variant of Mask R-CNN with domain randomization on the generated dataset to perform category-agnostic instance segmentation without any hand-labeled …",
        "year": 2019,
        "authors": "Michael Danielczuk and Matthew Matl and Saurabh Gupta and Andrew Li and Andrew Lee and Jeffrey Mahler and Ken Goldberg"
      },
      {
        "title": "Searching for fast model families on datacenter accelerators",
        "abstract": "Neural Architecture Search (NAS), together with model scaling, has shown remarkable progress in designing high accuracy and fast convolutional architecture families. However, as neither NAS nor model scaling considers sufficient hardware architecture details, they do not take full advantage of the emerging datacenter (DC) accelerators. In this paper, we search for fast and accurate CNN model families for efficient inference on DC accelerators. We first analyze DC accelerators and find that existing CNNs suffer from insufficient operational intensity, parallelism, and execution efficiency and exhibit FLOPs-latency nonproportionality. These insights let us create a DC-accelerator-optimized search space, with space-to-depth, space-to-batch, hybrid fused convolution structures with vanilla and depthwise convolutions, and block-wise activation functions. We further propose a latency-aware compound scaling (LACS), the first multi-objective compound scaling method optimizing both accuracy and latency. Our LACS discovers that network depth should grow much faster than image size and network width, which is quite different from the observations from previous compound scaling. With the new search space and LACS, our search and scaling on datacenter accelerators results in a new model series named EfficientNet-X. EfficientNet-X is up to more than 2X faster than EfficientNet (a model series with state-of-the-art trade-off on FLOPs and accuracy) on TPUv3 and GPUv100, with comparable accuracy. EfficientNet-X is also up to 7X faster than recent RegNet and ResNeSt on TPUv3 and GPUv100. Source code is at https://github. com/tensorflow/tpu …",
        "year": 2021,
        "authors": "Sheng Li and Mingxing Tan and Ruoming Pang and Andrew Li and Liqun Cheng and Quoc V Le and Norman P Jouppi"
      },
      {
        "title": "Segmenting unknown 3d objects from real depth images using mask r-cnn trained on synthetic point clouds",
        "abstract": "The ability to segment unknown objects in depth images has potential to enhance robot skills in grasping and object tracking. Recent computer vision research has demonstrated that Mask R-CNN can be trained to segment specific categories of objects in RGB images when massive handlabeled datasets are available. As generating these datasets is time-consuming, we instead train with synthetic depth images. Many robots now use depth sensors, and recent results suggest training on synthetic depth data can generalize well to the real world. We present a method for automated dataset generation and rapidly generate a training dataset of 50k depth images and 320k object masks synthetically using simulated scenes of 3D CAD models. We train a variant of Mask R-CNN on the generated dataset to perform category-agnostic instance segmentation without hand-labeled data. We evaluate the trained network, which we refer to as Synthetic Depth (SD) Mask R-CNN, on a set of real, high-resolution images of challenging, denselycluttered bins containing objects with highly-varied geometry. SD Mask R-CNN outperforms point cloud clustering baselines by an absolute 15% in Average Precision and 20% in Average Recall, and achieves performance levels similar to a Mask RCNN trained on a massive, hand-labeled RGB dataset and fine-tuned on real images from the experimental setup. The network also generalizes well to a lower-resolution depth sensor. We deploy the model in an instance-specific grasping pipeline to demonstrate its usefulness in a robotics application. Code, the synthetic training dataset, and supplementary material are …",
        "year": 2018,
        "authors": "Michael Danielczuk and Matthew Matl and Saurabh Gupta and Andrew Li and Andrew Lee and Jeffrey Mahler and Ken Goldberg"
      }
    ],
    "jyxO2akAAAAJ": [
      {
        "title": "Are we ready for autonomous driving? the kitti vision benchmark suite",
        "abstract": "Today, visual recognition systems are still rarely employed in robotics applications. Perhaps one of the main reasons for this is the lack of demanding benchmarks that mimic such scenarios. In this paper, we take advantage of our autonomous driving platform to develop novel challenging benchmarks for the tasks of stereo, optical flow, visual odometry/SLAM and 3D object detection. Our recording platform is equipped with four high resolution video cameras, a Velodyne laser scanner and a state-of-the-art localization system. Our benchmarks comprise 389 stereo and optical flow image pairs, stereo visual odometry sequences of 39.2 km length, and more than 200k 3D object annotations captured in cluttered scenarios (up to 15 cars and 30 pedestrians are visible per image). Results from state-of-the-art algorithms reveal that methods ranking high on established datasets such as Middlebury perform below average …",
        "year": 2012,
        "authors": "Andreas Geiger and Philip Lenz and Raquel Urtasun"
      },
      {
        "title": "Vision meets Robotics: The KITTI Dataset",
        "abstract": "We present a novel dataset captured from a VW station wagon for use in mobile robotics and autonomous driving research. In total, we recorded 6 hours of traffic scenarios at 10–100 Hz using a variety of sensor modalities such as high-resolution color and grayscale stereo cameras, a Velodyne 3D laser scanner and a high-precision GPS/IMU inertial navigation system. The scenarios are diverse, capturing real-world traffic situations, and range from freeways over rural areas to inner-city scenes with many static and dynamic objects. Our data is calibrated, synchronized and timestamped, and we provide the rectified and raw image sequences. Our dataset also contains object labels in the form of 3D tracklets, and we provide online benchmarks for stereo, optical flow, object detection and other tasks. This paper describes our recording platform, the data format and the utilities that we provide.",
        "year": 2013,
        "authors": "Andreas Geiger and Philip Lenz and Christoph Stiller and Raquel Urtasun"
      },
      {
        "title": "Aligning books and movies: Towards story-like visual explanations by watching movies and reading books",
        "abstract": "Books are a rich source of both fine-grained information, how a character, an object or a scene looks like, as well as high-level semantics, what someone is thinking, feeling and how these states evolve through a story. This paper aims to align books to their movie releases in order to provide rich descriptive explanations for visual content that go semantically far beyond the captions available in the current datasets. To align movies and books we propose a neural sentence embedding that is trained in an unsupervised way from a large corpus of books, as well as a video-text neural embedding for computing similarities between movie clips and sentences in the book. We propose a context-aware CNN to combine information from multiple sources. We demonstrate good quantitative performance for movie/book alignment and show several qualitative examples that showcase the diversity of tasks our model can be used for.",
        "year": 2015,
        "authors": "Yukun Zhu and Ryan Kiros and Rich Zemel and Ruslan Salakhutdinov and Raquel Urtasun and Antonio Torralba and Sanja Fidler"
      }
    ],
    "Op-47sgAAAAJ": [
      {
        "title": "From crowdsourced data to high-quality benchmarks: Arena-hard and benchbuilder pipeline",
        "abstract": "The rapid evolution of Large Language Models (LLMs) has outpaced the development of model evaluation, highlighting the need for continuous curation of new, challenging benchmarks. However, manual curation of high-quality, human-aligned benchmarks is expensive and time-consuming. To address this, we introduce BenchBuilder, an automated pipeline that leverages LLMs to curate high-quality, open-ended prompts from large, crowd-sourced datasets, enabling continuous benchmark updates without human in the loop. We apply BenchBuilder to datasets such as Chatbot Arena and WildChat-1M, extracting challenging prompts and utilizing LLM-as-a-Judge for automatic model evaluation. To validate benchmark quality, we propose new metrics to measure a benchmark's alignment with human preferences and ability to separate models. We release Arena-Hard-Auto, a benchmark consisting 500 challenging prompts curated by BenchBuilder. Arena-Hard-Auto provides 3x higher separation of model performances compared to MT-Bench and achieves 98.6% correlation with human preference rankings, all at a cost of $20. Our work sets a new framework for the scalable curation of automated benchmarks from extensive data.",
        "year": 2024,
        "authors": "Tianle Li and Wei-Lin Chiang and Evan Frick and Lisa Dunlap and Tianhao Wu and Banghua Zhu and Joseph E Gonzalez and Ion Stoica"
      },
      {
        "title": "Starling-7b: Improving llm helpfulness & harmlessness with rlaif",
        "abstract": "publications | Tianhao Wu Tianhao Wu Toggle navigation about blog publications (current) \ncv ctrl k publications 2024 1.Thinking LLMs: General Instruction Following with Thought \nGeneration Tianhao Wu, Janice Lan, Weizhe Yuan , and 3 more authors arXiv preprint arXiv:2410.10630, \n2024 HTML 2.EmbedLLM: Learning Compact Representations of Large Language Models \nRichard Zhuang, Tianhao Wu, Zhaojin Wen , and 3 more authors arXiv preprint arXiv:2410.02223, \n2024 HTML 3.Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge \nTianhao Wu, Weizhe Yuan, Olga Golovneva , and 5 more authors arXiv preprint arXiv:2407.19594, \n2024 HTML 4.From Crowdsourced Data to High-Quality Benchmarks: Arena-Hard and \nBenchBuilder Pipeline Tianle Li, Wei-Lin Chiang, Evan Frick , and 5 more authors arXiv \npreprint arXiv:2406.11939, 2024 HTML 5.RouteLLM: Learning to Route …",
        "year": 2023,
        "authors": "Banghua Zhu and Evan Frick and Tianhao Wu and Hanlin Zhu and Jiantao Jiao"
      }
    ],
    "cnncomYAAAAJ": [
      {
        "title": "Improve the Performance of CT-Based Pneumonia Classification via Source Data Reweighting",
        "abstract": "Pneumonia is a life-threatening disease. Computer tomography (CT) imaging is broadly used for diagnosing pneumonia. To assist radiologists in accurately and efficiently detecting pneumonia from CT scans, many deep learning methods have been developed. These methods require large amounts of annotated CT scans, which are difficult to obtain due to privacy concerns and high annotation costs. To address this problem, we develop a three-level optimization based method which leverages CT data from a source domain to mitigate the lack of labeled CT scans in a target domain. Our method automatically identifies and downweights low-quality source CT data examples which are noisy or have large domain discrepancy with target data, by minimizing the validation loss of a target model trained on reweighted source data. On a target dataset with 2218 CT scans and a source dataset with 349 CT images, our …",
        "year": 2023,
        "authors": "Pengtao Xie and Xingchen Zhao and Xuehai He"
      },
      {
        "title": "COVID-CT-dataset: a CT scan dataset about COVID-19",
        "abstract": "During the outbreak time of COVID-19, computed tomography (CT) is a useful manner for diagnosing COVID-19 patients. Due to privacy issues, publicly available COVID-19 CT datasets are highly difficult to obtain, which hinders the research and development of AI-powered diagnosis methods of COVID-19 based on CTs. To address this issue, we build an open-sourced dataset -- COVID-CT, which contains 349 COVID-19 CT images from 216 patients and 463 non-COVID-19 CTs. The utility of this dataset is confirmed by a senior radiologist who has been diagnosing and treating COVID-19 patients since the outbreak of this pandemic. We also perform experimental studies which further demonstrate that this dataset is useful for developing AI-based diagnosis models of COVID-19. Using this dataset, we develop diagnosis methods based on multi-task learning and self-supervised learning, that achieve an F1 of 0.90, an AUC of 0.98, and an accuracy of 0.89. According to the senior radiologist, models with such performance are good enough for clinical usage. The data and code are available at https://github.com/UCSD-AI4H/COVID-CT",
        "year": 2020,
        "authors": "Xingyi Yang and Xuehai He and Jinyu Zhao and Yichen Zhang and Shanghang Zhang and Pengtao Xie"
      },
      {
        "title": "A comprehensive survey on pretrained foundation models: A history from bert to chatgpt",
        "abstract": "Pretrained Foundation Models (PFMs) are regarded as the foundation for various downstream tasks across different data modalities. A PFM (e.g., BERT, ChatGPT, GPT-4) is trained on large-scale data, providing a solid parameter initialization for a wide range of downstream applications. In contrast to earlier methods that use convolution and recurrent modules for feature extraction, BERT learns bidirectional encoder representations from Transformers, trained on large datasets as contextual language models. Similarly, the Generative Pretrained Transformer (GPT) method employs Transformers as feature extractors and is trained on large datasets using an autoregressive paradigm. Recently, ChatGPT has demonstrated significant success in large language models, utilizing autoregressive language models with zero-shot or few-shot prompting. The remarkable success of PFMs has driven significant breakthroughs …",
        "year": 2024,
        "authors": "Ce Zhou and Qian Li and Chen Li and Jun Yu and Yixin Liu and Guangjing Wang and Kai Zhang and Cheng Ji and Qiben Yan and Lifang He and Hao Peng and Jianxin Li and Jia Wu and Ziwei Liu and Pengtao Xie and Caiming Xiong and Jian Pei and Philip S Yu and Lichao Sun"
      }
    ],
    "bslhbWgAAAAJ": [
      {
        "title": "On the opportunities and risks of foundation models",
        "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",
        "year": 2021,
        "authors": "Rishi Bommasani and Drew A Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher Ré and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W Thomas and Florian Tramèr and Rose E Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang"
      },
      {
        "title": "Just train twice: Improving group robustness without training group information",
        "abstract": "Standard training via empirical risk minimization (ERM) can produce models that achieve low error on average but high error on minority groups, especially in the presence of spurious correlations between the input and label. Prior approaches to this problem, like group distributionally robust optimization (group DRO), generally require group annotations for every training point. On the other hand, approaches that do not use group annotations generally do not improve minority performance. For example, we find that joint DRO, which dynamically upweights examples with high training loss, tends to optimize for examples that are irrelevant to the specific groups we seek to do well on. In this paper, we propose a simple two-stage approach, JTT, that achieves comparable performance to group DRO while only requiring group annotations on a significantly smaller validation set. JTT first attempts to identify informative training examples, which are often minority examples, by training an initial ERM classifier and selecting the examples with high training loss. Then, it trains a final classifier by upsampling the selected examples. Crucially, unlike joint DRO, JTT does not iteratively upsample examples that have high loss under the final classifier. On four image classification and natural language processing tasks with spurious correlations, we show that JTT closes 85% of the gap in accuracy on the worst group between ERM and group DRO.",
        "year": 2021,
        "authors": "Evan Z Liu* and Behzad Haghgoo* and Annie S Chen* and Aditi Raghunathan and Pang Wei Koh and Shiori Sagawa and Percy Liang and Chelsea Finn"
      },
      {
        "title": "Surgical fine-tuning improves adaptation to distribution shifts",
        "abstract": "A common approach to transfer learning under distribution shift is to fine-tune the last few layers of a pre-trained model, preserving learned features while also adapting to the new task. This paper shows that in such settings, selectively fine-tuning a subset of layers (which we term surgical fine-tuning) matches or outperforms commonly used fine-tuning approaches. Moreover, the type of distribution shift influences which subset is more effective to tune: for example, for image corruptions, fine-tuning only the first few layers works best. We validate our findings systematically across seven real-world data tasks spanning three types of distribution shifts. Theoretically, we prove that for two-layer neural networks in an idealized setting, first-layer tuning can outperform fine-tuning all layers. Intuitively, fine-tuning more parameters on a small target dataset can cause information learned during pre-training to be forgotten, and the relevant information depends on the type of shift.",
        "year": 2022,
        "authors": "Yoonho Lee* and Annie S Chen* and Fahim Tajwar and Ananya Kumar and Huaxiu Yao and Percy Liang and Chelsea Finn"
      }
    ],
    "bdHgGgEAAAAJ": [
      {
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models",
        "abstract": "DSpace at KOASAS: Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nKOASAS menu About KOASAS KAIST Library 검색 Advanced Search KOASAS About \nKOASAS Open Access Policy Browse Communities & Collections Researchers at KAIST Titles \nSubject By Date rss_1.0 rss_2.0 atom_1.0 sherpa SEARCH DSpace at KOASAS College of \nEngineering(공과대학)Kim Jaechul Graduate School of AI(김재철AI대학원)AI-Conference \nPapers(학술대회논문) Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nCited 0 time in webofscience Cited 0 time in scopus Hit : 2 Download : 0 Export DC(XML) Excel \nLim, Joseph Jaewhanresearcher Publisher IEEE Issue Date 2024-05-15 Citation IEEE \nInternational Conference on Robotics and Automation URI http://hdl.handle.net/10203/326144 \nAppears in Collection AI-Conference Papers(학술대회논문) Files in This Item There are no files …",
        "year": 2024,
        "authors": "Joseph Jaewhan Lim"
      },
      {
        "title": "Visual reinforcement learning with imagined goals",
        "abstract": "For an autonomous agent to fulfill a wide range of user-specified goals at test time, it must be able to learn broadly applicable and general-purpose skill repertoires. Furthermore, to provide the requisite level of generality, these skills must handle raw sensory input such as images. In this paper, we propose an algorithm that acquires such general-purpose skills by combining unsupervised representation learning and reinforcement learning of goal-conditioned policies. Since the particular goals that might be required at test-time are not known in advance, the agent performs a self-supervised\" practice\" phase where it imagines goals and attempts to achieve them. We learn a visual representation with three distinct purposes: sampling goals for self-supervised practice, providing a structured transformation of raw sensory inputs, and computing a reward signal for goal reaching. We also propose a retroactive goal relabeling scheme to further improve the sample-efficiency of our method. Our off-policy algorithm is efficient enough to learn policies that operate on raw image observations and goals in a real-world physical system, and substantially outperforms prior techniques.",
        "year": 2018,
        "authors": "Ashvin V Nair and Vitchyr Pong and Murtaza Dalal and Shikhar Bahl and Steven Lin and Sergey Levine"
      },
      {
        "title": "Residual reinforcement learning for robot control",
        "abstract": "Conventional feedback control methods can solve various types of robot control problems very efficiently by capturing the structure with explicit models, such as rigid body equations of motion. However, many control problems in modern manufacturing deal with contacts and friction, which are difficult to capture with first-order physical modeling. Hence, applying control design methodologies to these kinds of problems often results in brittle and inaccurate controllers, which have to be manually tuned for deployment. Reinforcement learning (RL) methods have been demonstrated to be capable of learning continuous robot controllers from interactions with the environment, even for problems that include friction and contacts. In this paper, we study how we can solve difficult control problems in the real world by decomposing them into a part that is solved efficiently by conventional feedback control methods, and the …",
        "year": 2019,
        "authors": "Tobias Johannink and Shikhar Bahl and Ashvin Nair and Jianlan Luo and Avinash Kumar and Matthias Loskyll and Juan Aparicio Ojea and Eugen Solowjow and Sergey Levine"
      }
    ],
    "GyoKzFwAAAAJ": [
      {
        "title": "Show, Attend and Tell: Neural Image Caption Generation with Visual Attention",
        "abstract": "Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO.",
        "year": 2015,
        "authors": "Kelvin Xu and Jimmy Ba and Ryan Kiros and Kyunghyun Cho and Aaron Courville and Ruslan Salakhutdinov and Richard Zemel and Yoshua Bengio"
      },
      {
        "title": "Gemini: a family of highly capable multimodal models",
        "abstract": "This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.",
        "year": 2023,
        "authors": "Gemini Team and Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M Dai and Anja Hauth and Katie Millican and David Silver and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Jack Krawczyk and Cosmo Du and Ed Chi and Heng-Tze Cheng and Eric Ni and Purvi Shah and Patrick Kane and Betty Chan and Manaal Faruqui and Aliaksei Severyn and Hanzhao Lin and YaGuang Li and Yong Cheng and Abe Ittycheriah and Mahdis Mahdieh and Mia Chen and Pei Sun and Dustin Tran and Sumit Bagri and Balaji Lakshminarayanan and Jeremiah Liu and Andras Orban and Fabian Güra and Hao Zhou and Xinying Song and Aurelien Boffy and Harish Ganapathy and Steven Zheng and HyunJeong Choe and Ágoston Weisz and Tao Zhu and Yifeng Lu and Siddharth Gopal and Jarrod Kahn and Maciej Kula and Jeff Pitman and Rushin Shah and Emanuel Taropa and Majd Al Merey and Martin Baeuml and Zhifeng Chen and Laurent El Shafey and Yujing Zhang and Olcan Sercinoglu and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Anaïs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Gaurav Singh Tomar and Evan Senter and Martin Chadwick and Ilya Kornakov and Nithya Attaluri and Iñaki Iturrate and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Xavier Garcia and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco"
      },
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien MR Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan"
      }
    ],
    "GUAoEcAAAAAJ": [
      {
        "title": "OpenFlow: enabling innovation in campus networks",
        "abstract": "This whitepaper proposes OpenFlow: a way for researchers to run experimental protocols in the networks they use every day. OpenFlow is based on an Ethernet switch, with an internal flow-table, and a standardized interface to add and remove flow entries. Our goal is to encourage networking vendors to add OpenFlow to their switch products for deployment in college campus backbones and wiring closets. We believe that OpenFlow is a pragmatic compromise: on one hand, it allows researchers to run experiments on heterogeneous switches in a uniform way at line-rate and with high port-density; while on the other hand, vendors do not need to expose the internal workings of their switches. In addition to allowing researchers to evaluate their ideas in real-world traffic settings, OpenFlow could serve as a useful campus component in proposed large-scale testbeds like GENI. Two buildings at Stanford University will …",
        "year": 2008,
        "authors": "Nick McKeown and Tom Anderson and Hari Balakrishnan and Guru Parulkar and Larry Peterson and Jennifer Rexford and Scott Shenker and Jonathan Turner"
      },
      {
        "title": "Spark: Cluster computing with working sets",
        "abstract": "MapReduce and its variants have been highly successful in implementing large-scale data-intensive applications on commodity clusters. However, most of these systems are built around an acyclic data flow model that is not suitable for other popular applications. This paper focuses on one such class of applications: those that reuse a working set of data across multiple parallel operations. This includes many iterative machine learning algorithms, as well as interactive data analysis tools. We propose a new framework called Spark that supports these applications while retaining the scalability and fault tolerance of MapReduce. To achieve these goals, Spark introduces an abstraction called resilient distributed datasets (RDDs). An RDD is a read-only collection of objects partitioned across a set of machines that can be rebuilt if a partition is lost. Spark can outperform Hadoop by 10x in iterative machine learning jobs, and can be used to interactively query a 39 GB dataset with sub-second response time.",
        "year": 2010,
        "authors": "Matei Zaharia and Mosharaf Chowdhury and Michael J Franklin and Scott Shenker and Ion Stoica"
      },
      {
        "title": "A scalable content-addressable network",
        "abstract": "Hash tables - which map \"keys\" onto \"values\" - are an essential building block in modern software systems. We believe a similar functionality would be equally valuable to large distributed systems. In this paper, we introduce the concept of a Content-Addressable Network (CAN) as a distributed infrastructure that provides hash table-like functionality on Internet-like scales. The CAN is scalable, fault-tolerant and completely self-organizing, and we demonstrate its scalability, robustness and low-latency properties through simulation.",
        "year": 2001,
        "authors": "Sylvia Ratnasamy and Paul Francis and Mark Handley and Richard Karp and Scott Shenker"
      }
    ],
    "zUJus70AAAAJ": [
      {
        "title": "Meta-reinforcement learning of structured exploration strategies",
        "abstract": "Exploration is a fundamental challenge in reinforcement learning (RL). Many current exploration methods for deep RL use task-agnostic objectives, such as information gain or bonuses based on state visitation. However, many practical applications of RL involve learning more than a single task, and prior tasks can be used to inform how exploration should be performed in new tasks. In this work, we study how prior tasks can inform an agent about how to explore effectively in new situations. We introduce a novel gradient-based fast adaptation algorithm–model agnostic exploration with structured noise (MAESN)–to learn exploration strategies from prior experience. The prior experience is used both to initialize a policy and to acquire a latent exploration space that can inject structured stochasticity into a policy, producing exploration strategies that are informed by prior knowledge and are more effective than random action-space noise. We show that MAESN is more effective at learning exploration strategies when compared to prior meta-RL methods, RL without learned exploration strategies, and task-agnostic exploration methods. We evaluate our method on a variety of simulated tasks: locomotion with a wheeled robot, locomotion with a quadrupedal walker, and object manipulation.",
        "year": 2018,
        "authors": "Abhishek Gupta and Russell Mendonca and YuXuan Liu and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Imitation from observation: Learning to imitate behaviors from raw video via context translation",
        "abstract": "Imitation learning is an effective approach for autonomous systems to acquire control policies when an explicit reward function is unavailable, using supervision provided as demonstrations from an expert, typically a human operator. However, standard imitation learning methods assume that the agent receives examples of observation-action tuples that could be provided, for instance, to a supervised learning algorithm. This stands in contrast to how humans and animals imitate: we observe another person performing some behavior and then figure out which actions will realize that behavior, compensating for changes in viewpoint, surroundings, object positions and types, and other factors. We term this kind of imitation learning “imitation-from-observation,” and propose an imitation learning method based on video prediction with context translation and deep reinforcement learning. This lifts the assumption in …",
        "year": 2018,
        "authors": "YuXuan Liu and Abhishek Gupta and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Learning invariant feature spaces to transfer skills with reinforcement learning",
        "abstract": "People can learn a wide range of tasks from their own experience, but can also learn from observing other creatures. This can accelerate acquisition of new skills even when the observed agent differs substantially from the learning agent in terms of morphology. In this paper, we examine how reinforcement learning algorithms can transfer knowledge between morphologically different agents (e.g., different robots). We introduce a problem formulation where two agents are tasked with learning multiple skills by sharing information. Our method uses the skills that were learned by both agents to train invariant feature spaces that can then be used to transfer other skills from one agent to another. The process of learning these invariant feature spaces can be viewed as a kind of \"analogy making\", or implicit learning of partial correspondences between two distinct domains. We evaluate our transfer learning algorithm in two simulated robotic manipulation skills, and illustrate that we can transfer knowledge between simulated robotic arms with different numbers of links, as well as simulated arms with different actuation mechanisms, where one robot is torque-driven while the other is tendon-driven.",
        "year": 2017,
        "authors": "Abhishek Gupta and Coline Devin and YuXuan Liu and Pieter Abbeel and Sergey Levine"
      }
    ],
    "uFJi3IUAAAAJ": [
      {
        "title": "TAG: A tiny aggregation service for ad-hoc sensor networks",
        "abstract": "We present the Tiny AGgregation (TAG) service for aggregation in low-power, distributed, wireless environments. TAG allows users to express simple, declarative queries and have them distributed and executed efficiently in networks of low-power, wireless sensors. We discuss various generic properties of aggregates, and show how those properties affect the performance of our in network approach. We include a performance study demonstrating the advantages of our approach over traditional centralized, out-of-network methods, and discuss a variety of optimizations for improving the performance and fault tolerance of the basic solution.",
        "year": 2002,
        "authors": "Samuel Madden and Michael J Franklin and Joseph M Hellerstein and Wei Hong"
      },
      {
        "title": "TinyDB: an acquisitional query processing system for sensor networks",
        "abstract": "We discuss the design of an acquisitional query processor for data collection in sensor networks. Acquisitional issues are those that pertain to where, when, and how often data is physically acquired (sampled) and delivered to query processing operators. By focusing on the locations and costs of acquiring data, we are able to significantly reduce power consumption over traditional passive systems that assume the a priori existence of data. We discuss simple extensions to SQL for controlling data acquisition, and show how acquisitional issues influence query optimization, dissemination, and execution. We evaluate these issues in the context of TinyDB, a distributed query processor for smart sensor devices, and show how acquisitional techniques can provide significant reductions in power consumption on our sensor devices.",
        "year": 2005,
        "authors": "Samuel R Madden and Michael J Franklin and Joseph M Hellerstein and Wei Hong"
      },
      {
        "title": "Distributed graphlab: A framework for machine learning in the cloud",
        "abstract": "While high-level data parallel frameworks, like MapReduce, simplify the design and implementation of large-scale data processing systems, they do not naturally or efficiently support many important data mining and machine learning algorithms and can lead to inefficient learning systems. To help fill this critical void, we introduced the GraphLab abstraction which naturally expresses asynchronous, dynamic, graph-parallel computation while ensuring data consistency and achieving a high degree of parallel performance in the shared-memory setting. In this paper, we extend the GraphLab framework to the substantially more challenging distributed setting while preserving strong data consistency guarantees. We develop graph based extensions to pipelined locking and data versioning to reduce network congestion and mitigate the effect of network latency. We also introduce fault tolerance to the GraphLab abstraction using the classic Chandy-Lamport snapshot algorithm and demonstrate how it can be easily implemented by exploiting the GraphLab abstraction itself. Finally, we evaluate our distributed implementation of the GraphLab abstraction on a large Amazon EC2 deployment and show 1-2 orders of magnitude performance gains over Hadoop-based implementations.",
        "year": 2012,
        "authors": "Yucheng Low and Joseph Gonzalez and Aapo Kyrola and Danny Bickson and Carlos Guestrin and Joseph M Hellerstein"
      }
    ],
    "Tsh90D8AAAAJ": [
      {
        "title": "Dex-Net 2.0: Deep Learning to Plan Robust Grasps with Synthetic Point Clouds and Analytic Grasp Metrics",
        "abstract": "To reduce data collection time for deep learning of robust robotic grasp plans, we explore training from a synthetic dataset of 6.7 million point clouds, grasps, and analytic grasp metrics generated from thousands of 3D models from Dex-Net 1.0 in randomized poses on a table. We use the resulting dataset, Dex-Net 2.0, to train a Grasp Quality Convolutional Neural Network (GQ-CNN) model that rapidly predicts the probability of success of grasps from depth images, where grasps are specified as the planar position, angle, and depth of a gripper relative to an RGB-D sensor. Experiments with over 1,000 trials on an ABB YuMi comparing grasp planning methods on singulated objects suggest that a GQ-CNN trained with only synthetic data from Dex-Net 2.0 can be used to plan grasps in 0.8sec with a success rate of 93% on eight known objects with adversarial geometry and is 3x faster than registering point clouds to a precomputed dataset of objects and indexing grasps. The Dex-Net 2.0 grasp planner also has the highest success rate on a dataset of 10 novel rigid objects and achieves 99% precision (one false positive out of 69 grasps classified as robust) on a dataset of 40 novel household objects, some of which are articulated or deformable. Code, datasets, videos, and supplementary material are available at http://berkeleyautomation.github.io/dex-net .",
        "year": 2017,
        "authors": "Jeffrey Mahler and Jacky Liang and Sherdil Niyaz and Michael Laskey and Richard Doan and Xinyu Liu and Juan Aparicio Ojea and Ken Goldberg"
      },
      {
        "title": "Dex-Net 3.0: Computing Robust Vacuum Suction Grasp Targets in Point Clouds using a New Analytic Model and Deep Learning",
        "abstract": "Vacuum-based end effectors are widely used in industry and are often preferred over parallel-jaw and multifinger grippers due to their ability to lift objects with a single point of contact. Suction grasp planners often target planar surfaces on point clouds near the estimated centroid of an object. In this paper, we propose a compliant suction contact model that computes the quality of the seal between the suction cup and local target surface and a measure of the ability of the suction grasp to resist an external gravity wrench. To characterize grasps, we estimate robustness to perturbations in end-effector and object pose, material properties, and external wrenches. We analyze grasps across 1,500 3D object models to generate Dex-Net 3.0, a dataset of 2.8 million point clouds, suction grasps, and grasp robustness labels. We use Dex-Net 3.0 to train a Grasp Quality Convolutional Neural Network (GQ-CNN) to classify …",
        "year": 2018,
        "authors": "Jeffrey Mahler and Matthew Matl and Xinyu Liu and Albert Li and David Gealy and Ken Goldberg"
      },
      {
        "title": "Learning ambidextrous robot grasping policies",
        "abstract": "Universal picking (UP), or reliable robot grasping of a diverse range of novel objects from heaps, is a grand challenge for e-commerce order fulfillment, manufacturing, inspection, and home service robots. Optimizing the rate, reliability, and range of UP is difficult due to inherent uncertainty in sensing, control, and contact physics. This paper explores “ambidextrous” robot grasping, where two or more heterogeneous grippers are used. We present Dexterity Network (Dex-Net) 4.0, a substantial extension to previous versions of Dex-Net that learns policies for a given set of grippers by training on synthetic datasets using domain randomization with analytic models of physics and geometry. We train policies for a parallel-jaw and a vacuum-based suction cup gripper on 5 million synthetic depth images, grasps, and rewards generated from heaps of three-dimensional objects. On a physical robot with two grippers, the Dex …",
        "year": 2019,
        "authors": "Jeffrey Mahler and Matthew Matl and Vishal Satish and Michael Danielczuk and Bill DeRose and Stephen McKinley and Ken Goldberg"
      }
    ],
    "zS3z8UgAAAAJ": [
      {
        "title": "Probing exchange pathways in one-dimensional aggregates with super-resolution microscopy",
        "abstract": "Supramolecular fibers are prominent structures in biology and chemistry. A quantitative understanding of molecular exchange pathways in these one-dimensional aggregates was obtained by a combination of super-resolution stochastic optical reconstruction microscopy and stochastic simulation. The potential of this methodology is demonstrated with a set of well-defined synthetic building blocks that self-assemble into supramolecular fibrils. Previous ensemble measurements hid all molecular phenomena underpinning monomer exchange, but the molecular pathway determined from single-aggregate studies revealed unexpected homogeneous exchange along the polymer backbone. These results pave the way for experimental investigation of the structure and exchange pathways of synthetic and natural supramolecular fibers.",
        "year": 2014,
        "authors": "Lorenzo Albertazzi and Daan Van Der Zwaag and Christianus MA Leenders and Robert Fitzner and Remco W Van Der Hofstad and EW Meijer"
      },
      {
        "title": "Scale-free networks well done",
        "abstract": "We bring rigor to the vibrant activity of detecting power laws in empirical degree distributions in real-world networks. We first provide a rigorous definition of power-law distributions, equivalent to the definition of regularly varying distributions that are widely used in statistics and other fields. This definition allows the distribution to deviate from a pure power law arbitrarily but without affecting the power-law tail exponent. We then identify three estimators of these exponents that are proven to be statistically consistent—that is, converging to the true value of the exponent for any regularly varying distribution—and that satisfy some additional niceness requirements. In contrast to estimators that are currently popular in network science, the estimators considered here are based on fundamental results in extreme value theory, and so are the proofs of their consistency. Finally, we apply these estimators to a representative …",
        "year": 2019,
        "authors": "Ivan Voitalov and Pim Van Der Hoorn and Remco Van Der Hofstad and Dmitri Krioukov"
      }
    ],
    "87nZphcAAAAJ": [
      {
        "title": "Judging llm-as-a-judge with mt-bench and chatbot arena",
        "abstract": "Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80\\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github. com/lm-sys/FastChat/tree/main/fastchat/llm_judge.",
        "year": 2023,
        "authors": "Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric Xing and Hao Zhang and Joseph E Gonzalez and Ion Stoica"
      },
      {
        "title": "Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks",
        "abstract": "Graph convolutional network (GCN) has been successfully applied to many graph-based applications; however, training a large-scale GCN remains challenging. Current SGD-based algorithms suffer from either a high computational cost that exponentially grows with number of GCN layers, or a large space requirement for keeping the entire graph and the embedding of each node in memory. In this paper, we propose Cluster-GCN, a novel GCN algorithm that is suitable for SGD-based training by exploiting the graph clustering structure. Cluster-GCN works as the following: at each step, it samples a block of nodes that associate with a dense subgraph identified by a graph clustering algorithm, and restricts the neighborhood search within this subgraph. This simple but effective strategy leads to significantly improved memory and computational efficiency while being able to achieve comparable test accuracy with …",
        "year": 2019,
        "authors": "Wei-Lin Chiang and Xuanqing Liu and Si Si and Yang Li and Samy Bengio and Cho-Jui Hsieh"
      }
    ],
    "OttawxUAAAAJ": [
      {
        "title": "Gradient descent finds global minima of deep neural networks",
        "abstract": "Gradient descent finds a global minimum in training deep neural networks despite the objective function being non-convex. The current paper proves gradient descent achieves zero training loss in polynomial time for a deep over-parameterized neural network with residual connections (ResNet). Our analysis relies on the particular structure of the Gram matrix induced by the neural network architecture. This structure allows us to show the Gram matrix is stable throughout the training process and this stability implies the global optimality of the gradient descent algorithm. We further extend our analysis to deep residual convolutional neural networks and obtain a similar convergence result.",
        "year": 2018,
        "authors": "Simon S Du and Jason D Lee and Haochuan Li and Liwei Wang and Xiyu Zhai"
      },
      {
        "title": "Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks",
        "abstract": "Recent works have cast some light on the mystery of why deep nets fit any data and generalize despite being very overparametrized. This paper analyzes training and generalization for a simple 2-layer ReLU net with random initialization, and provides the following improvements over recent works:(i) Using a tighter characterization of training speed than recent papers, an explanation for why training a neural net with random labels leads to slower training, as originally observed in [Zhang et al. ICLR’17].(ii) Generalization bound independent of network size, using a data-dependent complexity measure. Our measure distinguishes clearly between random labels and true labels on MNIST and CIFAR, as shown by experiments. Moreover, recent papers require sample complexity to increase (slowly) with the size, while our sample complexity is completely independent of the network size.(iii) Learnability of a broad class of smooth functions by 2-layer ReLU nets trained via gradient descent. The key idea is to track dynamics of training and generalization via properties of a related kernel.",
        "year": 2019,
        "authors": "Sanjeev Arora and Simon S Du and Wei Hu and Zhiyuan Li and Ruosong Wang"
      },
      {
        "title": "On exact computation with an infinitely wide neural net",
        "abstract": "How well does a classic deep net architecture like AlexNet or VGG19 classify on a standard dataset such as CIFAR-10 when its “width”—namely, number of channels in convolutional layers, and number of nodes in fully-connected internal layers—is allowed to increase to infinity? Such questions have come to the forefront in the quest to theoretically understand deep learning and its mysteries about optimization and generalization. They also connect deep learning to notions such as Gaussian processes and kernels. A recent paper [Jacot et al., 2018] introduced the Neural Tangent Kernel (NTK) which captures the behavior of fully-connected deep nets in the infinite width limit trained by gradient descent; this object was implicit in some other recent papers. An attraction of such ideas is that a pure kernel-based method is used to capture the power of a fully-trained deep net of infinite width.",
        "year": 2019,
        "authors": "Sanjeev Arora and Simon S Du and Wei Hu and Zhiyuan Li and Russ R Salakhutdinov and Ruosong Wang"
      }
    ],
    "mnU3HpcAAAAJ": [
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien MR Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan"
      },
      {
        "title": "Ethnic and regional variations in hospital mortality from COVID-19 in Brazil: a cross-sectional observational study",
        "abstract": "Brazil ranks second worldwide in total number of COVID-19 cases and deaths. Understanding the possible socioeconomic and ethnic health inequities is particularly important given the diverse population and fragile political and economic situation. We aimed to characterise the COVID-19 pandemic in Brazil and assess variations in mortality according to region, ethnicity, comorbidities, and symptoms.We conducted a cross-sectional observational study of COVID-19 hospital mortality using data from the SIVEP-Gripe (Sistema de Informação de Vigilância Epidemiológica da Gripe) dataset to characterise the COVID-19 pandemic in Brazil. In the study, we included hospitalised patients who had a positive RT-PCR test for severe acute respiratory syndrome coronavirus 2 and who had ethnicity information in the dataset. Ethnicity of participants was classified according to the five categories used by …",
        "year": 2020,
        "authors": "Pedro Baqui* and Ioana Bica* and Valerio Marra and Ari Ercole and Mihaela van Der Schaar"
      },
      {
        "title": "From real‐world patient data to individualized treatment effects using machine learning: current and future methods to address underlying challenges",
        "abstract": "Clinical decision making needs to be supported by evidence that treatments are beneficial to individual patients. Although randomized control trials (RCTs) are the gold standard for testing and introducing new drugs, due to the focus on specific questions with respect to establishing efficacy and safety vs. standard treatment, they do not provide a full characterization of the heterogeneity in the final intended treatment population. Conversely, real‐world observational data, such as electronic health records (EHRs), contain large amounts of clinical information about heterogeneous patients and their response to treatments. In this paper, we introduce the main opportunities and challenges in using observational data for training machine learning methods to estimate individualized treatment effects and make treatment recommendations. We describe the modeling choices of the state‐of‐the‐art machine learning …",
        "year": 2021,
        "authors": "Ioana Bica and Ahmed M Alaa and Craig Lambert and Mihaela Van Der Schaar"
      }
    ],
    "oizZKrsAAAAJ": [
      {
        "title": "Ref-nerf: Structured view-dependent appearance for neural radiance fields",
        "abstract": "Neural Radiance Fields (NeRF) is a popular view synthesis technique that represents a scene as a continuous volumetric function, parameterized by multilayer perceptrons that provide the volume density and view-dependent emitted radiance at each location. While NeRF-based techniques excel at representing fine geometric structures with smoothly varying view-dependent appearance, they often fail to accurately capture and reproduce the appearance of glossy surfaces. We address this limitation by introducing Ref-NeRF, which replaces NeRF's parameterization of view-dependent outgoing radiance with a representation of reflected radiance and structures this function using a collection of spatially-varying scene properties. We show that together with a regularizer on normal vectors, our model significantly improves the realism and accuracy of specular reflections. Furthermore, we show that our model's …",
        "year": 2022,
        "authors": "Dor Verbin and Peter Hedman and Ben Mildenhall and Todd Zickler and Jonathan T Barron and Pratul P Srinivasan"
      },
      {
        "title": "Statistics of real-world hyperspectral images",
        "abstract": "Hyperspectral images provide higher spectral resolution than typical RGB images by including per-pixel irradiance measurements in a number of narrow bands of wavelength in the visible spectrum. The additional spectral resolution may be useful for many visual tasks, including segmentation, recognition, and relighting. Vision systems that seek to capture and exploit hyperspectral data should benefit from statistical models of natural hyperspectral images, but at present, relatively little is known about their structure. Using a new collection of fifty hyperspectral images of indoor and outdoor scenes, we derive an optimized “spatio-spectral basis” for representing hyperspectral image patches, and explore statistical models for the coefficients in this basis.",
        "year": 2011,
        "authors": "Ayan Chakrabarti and Todd Zickler"
      },
      {
        "title": "Photometric stereo with non-parametric and spatially-varying reflectance",
        "abstract": "We present a method for simultaneously recovering shape and spatially varying reflectance of a surface from photometric stereo images. The distinguishing feature of our approach is its generality; it does not rely on a specific parametric reflectance model and is therefore purely ldquodata-drivenrdquo. This is achieved by employing novel bi-variate approximations of isotropic reflectance functions. By combining this new approximation with recent developments in photometric stereo, we are able to simultaneously estimate an independent surface normal at each point, a global set of non-parametric ldquobasis materialrdquo BRDFs, and per-point material weights. Our experimental results validate the approach and demonstrate the utility of bi-variate reflectance functions for general non-parametric appearance capture.",
        "year": 2008,
        "authors": "Neil Alldrin and Todd Zickler and David Kriegman"
      }
    ],
    "eIWg8NMAAAAJ": [
      {
        "title": "Face2face: Real-time face capture and reenactment of rgb videos",
        "abstract": "We present a novel approach for real-time facial reenactment of a monocular target video sequence (eg, Youtube video). The source sequence is also a monocular video stream, captured live with a commodity webcam. Our goal is to animate the facial expressions of the target video by a source actor and re-render the manipulated output video in a photo-realistic fashion. To this end, we first address the under-constrained problem of facial identity recovery from monocular video by non-rigid model-based bundling. At run time, we track facial expressions of both source and target video using a dense photometric consistency measure. Reenactment is then achieved by fast and efficient deformation transfer between source and target. The mouth interior that best matches the re-targeted expression is retrieved from the target sequence and warped to produce an accurate fit. Finally, we convincingly re-render the synthesized target face on top of the corresponding video stream such that it seamlessly blends with the real-world illumination. We demonstrate our method in a live setup, where Youtube videos are reenacted in real time.",
        "year": 2016,
        "authors": "Justus Thies and Michael Zollhöfer and Marc Stamminger and Christian Theobalt and Matthias Nießner"
      },
      {
        "title": "NeuS: Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction",
        "abstract": "We present a novel neural surface reconstruction method, called NeuS, for reconstructing objects and scenes with high fidelity from 2D image inputs. Existing neural surface reconstruction approaches, such as DVR and IDR, require foreground mask as supervision, easily get trapped in local minima, and therefore struggle with the reconstruction of objects with severe self-occlusion or thin structures. Meanwhile, recent neural methods for novel view synthesis, such as NeRF and its variants, use volume rendering to produce a neural scene representation with robustness of optimization, even for highly complex objects. However, extracting high-quality surfaces from this learned implicit representation is difficult because there are not sufficient surface constraints in the representation. In NeuS, we propose to represent a surface as the zero-level set of a signed distance function (SDF) and develop a new volume rendering method to train a neural SDF representation. We observe that the conventional volume rendering method causes inherent geometric errors (i.e. bias) for surface reconstruction, and therefore propose a new formulation that is free of bias in the first order of approximation, thus leading to more accurate surface reconstruction even without the mask supervision. Experiments on the DTU dataset and the BlendedMVS dataset show that NeuS outperforms the state-of-the-arts in high-quality surface reconstruction, especially for objects and scenes with complex structures and self-occlusion.",
        "year": 2021,
        "authors": "Peng Wang and Lingjie Liu and Yuan Liu and Christian Theobalt and Taku Komura and Wenping Wang"
      }
    ],
    "QxLpghAAAAAJ": [
      {
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models",
        "abstract": "DSpace at KOASAS: Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nKOASAS menu About KOASAS KAIST Library 검색 Advanced Search KOASAS About \nKOASAS Open Access Policy Browse Communities & Collections Researchers at KAIST Titles \nSubject By Date rss_1.0 rss_2.0 atom_1.0 sherpa SEARCH DSpace at KOASAS College of \nEngineering(공과대학)Kim Jaechul Graduate School of AI(김재철AI대학원)AI-Conference \nPapers(학술대회논문) Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nCited 0 time in webofscience Cited 0 time in scopus Hit : 2 Download : 0 Export DC(XML) Excel \nLim, Joseph Jaewhanresearcher Publisher IEEE Issue Date 2024-05-15 Citation IEEE \nInternational Conference on Robotics and Automation URI http://hdl.handle.net/10203/326144 \nAppears in Collection AI-Conference Papers(학술대회논문) Files in This Item There are no files …",
        "year": 2024,
        "authors": []
      },
      {
        "title": "Digit: A novel design for a low-cost compact high-resolution tactile sensor with application to in-hand manipulation",
        "abstract": "Despite decades of research, general purpose in-hand manipulation remains one of the unsolved challenges of robotics. One of the contributing factors that limit current robotic manipulation systems is the difficulty of precisely sensing contact forces - sensing and reasoning about contact forces are crucial to accurately control interactions with the environment. As a step towards enabling better robotic manipulation, we introduce DIGIT, an inexpensive, compact, and high-resolution tactile sensor geared towards in-hand manipulation. DIGIT improves upon past vision-based tactile sensors by miniaturizing the form factor to be mountable on multi-fingered hands, and by providing several design improvements that result in an easier, more repeatable manufacturing process, and enhanced reliability. We demonstrate the capabilities of the DIGIT sensor by training deep neural network model-based controllers to …",
        "year": 2020,
        "authors": "Mike Lambeta and Po-Wei Chou and Stephen Tian and Brian Yang and Benjamin Maloon and Victoria Rose Most and Dave Stroud and Raymond Santos and Ahmad Byagowi and Gregg Kammerer and Dinesh Jayaraman and Roberto Calandra"
      },
      {
        "title": "More Than a Feeling: Learning to Grasp and Regrasp using Vision and Touch",
        "abstract": "For humans, the process of grasping an object relies heavily on rich tactile feedback. Most recent robotic grasping work, however, has been based only on visual input, and thus cannot easily benefit from feedback after initiating contact. In this letter, we investigate how a robot can learn to use tactile information to iteratively and efficiently adjust its grasp. To this end, we propose an end-to-end action-conditional model that learns regrasping policies from raw visuo-tactile data. This model—a deep, multimodal convolutional network—predicts the outcome of a candidate grasp adjustment, and then executes a grasp by iteratively selecting the most promising actions. Our approach requires neither calibration of the tactile sensors nor any analytical modeling of contact forces, thus reducing the engineering effort required to obtain efficient grasping policies. We train our model with data from about 6450 grasping trials on a …",
        "year": 2018,
        "authors": "Roberto Calandra and Andrew Owens and Dinesh Jayaraman and Justin Lin and Wenzhen Yuan and Jitendra Malik and Edward H Adelson and Sergey Levine"
      }
    ],
    "0Qr2IGwAAAAJ": [
      {
        "title": "ROSETTA3: an object-oriented software suite for the simulation and design of macromolecules",
        "abstract": "We have recently completed a full rearchitecturing of the Rosetta molecular modeling program, generalizing and expanding its existing functionality. The new architecture enables the rapid prototyping of novel protocols by providing easy-to-use interfaces to powerful tools for molecular modeling. The source code of this rearchitecturing has been released as Rosetta3 and is freely available for academic use. At the time of its release, it contained 470,000 lines of code. Counting currently unpublished protocols at the time of this writing, the source includes 1,285,000 lines. Its rapid growth is a testament to its ease of use. This chapter describes the requirements for our new architecture, justifies the design decisions, sketches out central classes, and highlights a few of the common tasks that the new software can perform.",
        "year": 2011,
        "authors": "Andrew Leaver-Fay and Michael Tyka and Steven M Lewis and Oliver F Lange and James Thompson and Ron Jacak and Kristian Kaufman and P Douglas Renfrew and Colin A Smith and Will Sheffler and Ian W Davis and Seth Cooper and Adrien Treuille and Daniel J Mandell and Florian Richter and YE Ban and Sarel J Fleishman and Jacob E Corn and David E Kim and Sergey Lyskov and Monica Berrondo and Stuart Mentzer"
      },
      {
        "title": "Predicting protein structures with a multiplayer online game",
        "abstract": "People exert large amounts of problem-solving effort playing computer games. Simple image- and text-recognition tasks have been successfully ‘crowd-sourced’ through games,,, but it is not clear if more complex scientific problems can be solved with human-directed computing. Protein structure prediction is one such problem: locating the biologically relevant native conformation of a protein is a formidable computational challenge given the very large size of the search space. Here we describe Foldit, a multiplayer online game that engages non-scientists in solving hard prediction problems. Foldit players interact with protein structures using direct manipulation tools and user-friendly versions of algorithms from the Rosetta structure prediction methodology, while they compete and collaborate to optimize the computed energy. We show that top-ranked Foldit players excel at solving challenging structure refinement …",
        "year": 2010,
        "authors": "Seth Cooper and Firas Khatib and Adrien Treuille and Janos Barbero and Jeehyung Lee and Michael Beenen and Andrew Leaver-Fay and David Baker and Zoran Popović and Foldit Players"
      },
      {
        "title": "The space of human body shapes: reconstruction and parameterization from range scans",
        "abstract": "We develop a novel method for fitting high-resolution template meshes to detailed human body range scans with sparse 3D markers. We formulate an optimization problem in which the degrees of freedom are an affine transformation at each template vertex. The objective function is a weighted combination of three measures: proximity of transformed vertices to the range data, similarity between neighboring transformations, and proximity of sparse markers at corresponding locations on the template and target surface. We solve for the transformations with a non-linear optimizer, run at two resolutions to speed convergence. We demonstrate reconstruction and consistent parameterization of 250 human body models. With this parameterized set, we explore a variety of applications for human body modeling, including: morphing, texture transfer, statistical analysis of shape, model fitting from sparse markers, feature …",
        "year": 2003,
        "authors": "Brett Allen and Brian Curless and Zoran Popović"
      }
    ],
    "7HPdnqEAAAAJ": [
      {
        "title": "Straggler-proofing massive-scale distributed matrix multiplication with d-dimensional product codes",
        "abstract": "Distributed computing allows for large-scale computation and machine learning tasks by enabling parallel computing at massive scale. A critical challenge to speeding up distributed computing comes from stragglers, a crippling bottleneck to system performance [1]. Recently, coding theory has offered an attractive paradigm dubbed as coded computation [2] for addressing this challenge through the judicious introduction of redundant computing to combat stragglers. However, most existing approaches have limited applicability if the system scales to hundreds or thousands of workers, as is the trend in computing platforms. At these scales, previously proposed algorithms based on Maximum Distance Separable (MDS) codes are too expensive due to their hidden cost, i.e., computing and communication costs associated with the encoding/decoding procedures. Motivated by this limitation, we present a novel coded …",
        "year": 2018,
        "authors": "Tavor Baharav and Kangwook Lee and Orhan Ocal and Kannan Ramchandran"
      },
      {
        "title": "My fair bandit: Distributed learning of max-min fairness with multi-player bandits",
        "abstract": "Consider N cooperative but non-communicating players where each plays one out of M arms for T turns. Players have different utilities for each arm, representable as an NxM matrix. These utilities are unknown to the players. In each turn players receive noisy observations of their utility for their selected arm. However, if any other players selected the same arm that turn, they will all receive zero utility due to the conflict. No other communication or coordination between the players is possible. Our goal is to design a distributed algorithm that learns the matching between players and arms that achieves max-min fairness while minimizing the regret. We present an algorithm and prove that it is regret optimal up to a\\log\\log T factor. This is the first max-min fairness multi-player bandit algorithm with (near) order optimal regret.",
        "year": 2020,
        "authors": "Ilai Bistritz and Tavor Baharav and Amir Leshem and Nicholas Bambos"
      },
      {
        "title": "Spectral Jaccard Similarity: A new approach to estimating pairwise sequence alignments",
        "abstract": "Pairwise sequence alignment is often a computational bottleneck in genomic analysis pipelines, particularly in the context of third-generation sequencing technologies. To speed up this process, the pairwise k-mer Jaccard similarity is sometimes used as a proxy for alignment size in order to filter pairs of reads, and min-hashes are employed to efficiently estimate these similarities. However, when the k-mer distribution of a dataset is significantly non-uniform (e.g., due to GC biases and repeats), Jaccard similarity is no longer a good proxy for alignment size. In this work, we introduce a min-hash-based approach for estimating alignment sizes called Spectral Jaccard Similarity, which naturally accounts for uneven k-mer distributions. The Spectral Jaccard Similarity is computed by performing a singular value decomposition on a min-hash collision matrix. We empirically show that this new metric provides significantly …",
        "year": 2020,
        "authors": "Tavor Z Baharav and Govinda M Kamath and N Tse David and Ilan Shomorony"
      }
    ],
    "lH1PdF8AAAAJ": [
      {
        "title": "Meta-learning with differentiable convex optimization",
        "abstract": "Many meta-learning approaches for few-shot learning rely on simple base learners such as nearest-neighbor classifiers. However, even in the few-shot regime, discriminatively trained linear predictors can offer better generalization. We propose to use these predictors as base learners to learn representations for few-shot learning and show they offer better tradeoffs between feature size and performance across a range of few-shot recognition benchmarks. Our objective is to learn feature embeddings that generalize well under a linear classification rule for novel categories. To efficiently solve the objective, we exploit two properties of linear classifiers: implicit differentiation of the optimality conditions of the convex problem and the dual formulation of the optimization problem. This allows us to use high-dimensional embeddings with improved generalization at a modest increase in computational overhead. Our approach, named MetaOptNet, achieves state-of-the-art performance on miniImageNet, tieredImageNet, CIFAR-FS, and FC100 few-shot learning benchmarks.",
        "year": 2019,
        "authors": "Kwonjoon Lee and Subhransu Maji and Avinash Ravichandran and Stefano Soatto"
      },
      {
        "title": "Quick shift and kernel methods for mode seeking",
        "abstract": "We show that the complexity of the recently introduced medoid-shift algorithm in clustering N points is O(N 2), with a small constant, if the underlying distance is Euclidean. This makes medoid shift considerably faster than mean shift, contrarily to what previously believed. We then exploit kernel methods to extend both mean shift and the improved medoid shift to a large family of distances, with complexity bounded by the effective rank of the resulting kernel matrix, and with explicit regularization constraints. Finally, we show that, under certain conditions, medoid shift fails to cluster data points belonging to the same mode, resulting in over-fragmentation. We propose remedies for this problem, by introducing a novel, simple and extremely efficient clustering algorithm, called quick shift, that explicitly trades off under- and over-fragmentation. Like medoid shift, quick shift operates in non-Euclidean spaces …",
        "year": 2008,
        "authors": "Andrea Vedaldi and Stefano Soatto"
      }
    ],
    "hdTDzlQAAAAJ": [
      {
        "title": "Minimax estimation of functionals of discrete distributions",
        "abstract": "We propose a general methodology for the construction and analysis of essentially minimax estimators for a wide class of functionals of finite dimensional parameters, and elaborate on the case of discrete distributions, where the support size S is unknown and may be comparable with or even much larger than the number of observations n. We treat the respective regions where the functional is nonsmooth and smooth separately. In the nonsmooth regime, we apply an unbiased estimator for the best polynomial approximation of the functional whereas, in the smooth regime, we apply a bias-corrected version of the maximum likelihood estimator (MLE). We illustrate the merit of this approach by thoroughly analyzing the performance of the resulting schemes for estimating two important information measures: 1) the entropy H(P) = ΣSi=1 -pi ln pi and 2) Fα(P) = ΣSi=1 pαi, α > 0. We obtain the minimax L2 rates for …",
        "year": 2015,
        "authors": "Jiantao Jiao and Kartik Venkat and Yanjun Han and Tsachy Weissman"
      },
      {
        "title": "Batched multi-armed bandits problem",
        "abstract": "In this paper, we study the multi-armed bandit problem in the batched setting where the employed policy must split data into a small number of batches. While the minimax regret for the two-armed stochastic bandits has been completely characterized in\\cite {perchet2016batched}, the effect of the number of arms on the regret for the multi-armed case is still open. Moreover, the question whether adaptively chosen batch sizes will help to reduce the regret also remains underexplored. In this paper, we propose the BaSE (batched successive elimination) policy to achieve the rate-optimal regrets (within logarithmic factors) for batched multi-armed bandits, with matching lower bounds even if the batch sizes are determined in an adaptive manner.",
        "year": 2019,
        "authors": "Zijun Gao and Yanjun Han and Zhimei Ren and Zhengqing Zhou"
      },
      {
        "title": "Performance limits and geometric properties of array localization",
        "abstract": "Location-aware networks are of great importance and interest in both civil and military applications. This paper determines the localization accuracy of an agent, which is equipped with an antenna array and localizes itself using wireless measurements with anchor nodes, in a far-field environment. In view of the Cramér-Rao bound, we first derive the localization information for static scenarios and demonstrate that such information is a weighed sum of Fisher information matrices from each anchor-antenna measurement pair. Each matrix can be further decomposed into two parts: 1) a distance part with intensity proportional to the squared baseband effective bandwidth of the transmitted signal and 2) a direction part with intensity associated with the normalized anchor-antenna visual angle. Moreover, in dynamic scenarios, we show that the Doppler shift contributes additional direction information, with intensity …",
        "year": 2015,
        "authors": "Yanjun Han and Yuan Shen and Xiao-Ping Zhang and Moe Z Win and Huadong Meng"
      }
    ],
    "LIJQ_ZYAAAAJ": [
      {
        "title": "Do As I Can, Not As I Say: Grounding Language in Robotic Affordances",
        "abstract": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model's \"hands and eyes,\" while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally-extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project's website and the video can be found at https …",
        "year": 2022,
        "authors": "Michael Ahn and Anthony Brohan and Noah Brown and Yevgen Chebotar and Omar Cortes and Byron David and Chelsea Finn and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Daniel Ho and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Eric Jang and Rosario Jauregui Ruano and Kyle Jeffrey and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Kuang-Huei Lee and Sergey Levine and Yao Lu and Linda Luu and Carolina Parada and Peter Pastor and Jornell Quiambao and Kanishka Rao and Jarek Rettinghouse and Diego Reyes and Pierre Sermanet and Nicolas Sievers and Clayton Tan and Alexander Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Mengyuan Yan"
      },
      {
        "title": "RT-1: Robotics Transformer for Real-world Control at Scale",
        "abstract": "By transferring knowledge from large, diverse, task-agnostic datasets, modern machine learning models can solve specific downstream tasks either zero-shot or with small task-specific datasets to a high level of performance. While this capability has been demonstrated in other fields such as computer vision, natural language processing or speech recognition, it remains to be shown in robotics, where the generalization capabilities of the models are particularly critical due to the difficulty of collecting real-world robotic data. We argue that one of the keys to the success of such general robotic models lies with open-ended task-agnostic training, combined with high-capacity architectures that can absorb all of the diverse, robotic data. In this paper, we present a model class, dubbed Robotics Transformer, that exhibits promising scalable model properties. We verify our conclusions in a study of different model classes and their ability to generalize as a function of the data size, model size, and data diversity based on a large-scale data collection on real robots performing real-world tasks. The project's website and videos can be found at robotics-transformer1.github.io",
        "year": 2022,
        "authors": "Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Joseph Dabis and Chelsea Finn and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Tomas Jackson and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Kuang-Huei Lee and Sergey Levine and Yao Lu and Utsav Malla and Deeksha Manjunath and Igor Mordatch and Ofir Nachum and Carolina Parada and Jodilyn Peralta and Emily Perez and Karl Pertsch and Jornell Quiambao and Kanishka Rao and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Kevin Sayed and Jaspiar Singh and Sumedh Sontakke and Austin Stone and Clayton Tan and Huong Tran and Vincent Vanhoucke and Steve Vega and Quan Vuong and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich"
      },
      {
        "title": "RT-2: Vision-Language-Action Models Transfer Web Knowledge to Robotic Control",
        "abstract": "We study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robotic trajectory data and Internet-scale vision-language tasks, such as visual question answering. In contrast to other approaches, we propose a simple, general recipe to achieve this goal: in order to fit both natural language responses and robotic actions into the same format, we express the actions as text tokens and incorporate them directly into the training set of the model in the same way as natural language tokens. We refer to such category of models as vision-language-action models (VLA) and instantiate an example of such a model, which we call RT-2. Our extensive evaluation (6k evaluation trials) shows that our approach leads to performant robotic policies and enables RT-2 to obtain a range of emergent capabilities from Internet-scale training. This includes significantly improved generalization to novel objects, the ability to interpret commands not present in the robot training data (such as placing an object onto a particular number or icon), and the ability to perform rudimentary reasoning in response to user commands (such as picking up the smallest or largest object, or the one closest to another object). We further show that incorporating chain of …",
        "year": 2023,
        "authors": "Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Xi Chen and Krzysztof Choromanski and Tianli Ding and Danny Driess and Avinava Dubey and Chelsea Finn and Pete Florence and Chuyuan Fu and Montse Gonzalez Arenas and Keerthana Gopalakrishnan and Kehang Han and Karol Hausman and Alexander Herzog and Jasmine Hsu and Brian Ichter and Alex Irpan and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Lisa Lee and Tsang-Wei Edward Lee and Sergey Levine and Yao Lu and Henryk Michalewski and Igor Mordatch and Karl Pertsch and Kanishka Rao and Krista Reymann and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Pierre Sermanet and Jaspiar Singh and Anikait Singh and Radu Soricut and Huong Tran and Vincent Vanhoucke and Quan Vuong and Ayzaan Wahid and Stefan Welker and Paul Wohlhart and Jialin Wu and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich"
      }
    ],
    "IcaU830AAAAJ": [
      {
        "title": "Ray: A distributed framework for emerging {AI} applications",
        "abstract": "The next generation of AI applications will continuously interact with the environment and learn from these interactions. These applications impose new and demanding systems requirements, both in terms of performance and flexibility. In this paper, we consider these requirements and present Ray—a distributed system to address them. Ray implements a unified interface that can express both task-parallel and actor-based computations, supported by a single dynamic execution engine. To meet the performance requirements, Ray employs a distributed scheduler and a distributed and fault-tolerant store to manage the system’s control state. In our experiments, we demonstrate scaling beyond 1.8 million tasks per second and better performance than existing specialized systems for several challenging reinforcement learning applications.",
        "year": 2018,
        "authors": "Philipp Moritz and Robert Nishihara and Stephanie Wang and Alexey Tumanov and Richard Liaw and Eric Liang and Melih Elibol and Zongheng Yang and William Paul and Michael I Jordan and Ion Stoica"
      },
      {
        "title": "RLlib: Abstractions for distributed reinforcement learning",
        "abstract": "Reinforcement learning (RL) algorithms involve the deep nesting of highly irregular computation patterns, each of which typically exhibits opportunities for distributed computation. We argue for distributing RL components in a composable way by adapting algorithms for top-down hierarchical control, thereby encapsulating parallelism and resource requirements within short-running compute tasks. We demonstrate the benefits of this principle through RLlib: a library that provides scalable software primitives for RL. These primitives enable a broad range of algorithms to be implemented with high performance, scalability, and substantial code reuse. RLlib is available as part of the open source Ray project at http://rllib. io/.",
        "year": 2018,
        "authors": "Eric Liang and Richard Liaw and Robert Nishihara and Philipp Moritz and Roy Fox and Ken Goldberg and Joseph Gonzalez and Michael Jordan and Ion Stoica"
      },
      {
        "title": "Tune: A research platform for distributed model selection and training",
        "abstract": "Modern machine learning algorithms are increasingly computationally demanding, requiring specialized hardware and distributed computation to achieve high performance in a reasonable time frame. Many hyperparameter search algorithms have been proposed for improving the efficiency of model selection, however their adaptation to the distributed compute environment is often ad-hoc. We propose Tune, a unified framework for model selection and training that provides a narrow-waist interface between training scripts and search algorithms. We show that this interface meets the requirements for a broad range of hyperparameter search algorithms, allows straightforward scaling of search to large clusters, and simplifies algorithm implementation. We demonstrate the implementation of several state-of-the-art hyperparameter search algorithms in Tune. Tune is available at http://ray.readthedocs.io/en/latest/tune.html.",
        "year": 2018,
        "authors": "Richard Liaw and Eric Liang and Robert Nishihara and Philipp Moritz and Joseph E Gonzalez and Ion Stoica"
      }
    ],
    "6Q-289IAAAAJ": [
      {
        "title": "Precise Detection in Densely Packed Scenes",
        "abstract": "Man-made scenes are often densely packed, containing numerous objects, often identical, positioned in close proximity. We show that precise object detection in such scenes remains a challenging frontier even for state-of-the-art object detectors. We propose a novel, deep-learning based method for precise object detection, designed for such challenging settings. Our contributions include:(1) A layer for estimating the Jaccard index as a detection quality score;(2) a novel EM merging unit, which uses our quality scores to resolve detection overlap ambiguities; finally,(3) an extensive, annotated data set, SKU-110K, representing packed retail environments, released for training and testing under such extreme settings. Detection tests on SKU-110K, and counting tests on the CARPK and PUCPR+, show our method to outperform existing state-of-the-art with substantial margins.",
        "year": 2019,
        "authors": "Eran Goldman* and Roei Herzig* and Aviv Eisenschtat* and Jacob Goldberger and Tal Hassner"
      },
      {
        "title": "Something-Else: Compositional Action Recognition with Spatial-Temporal Interaction Networks",
        "abstract": "Human action is naturally compositional: humans can easily recognize and perform actions with objects that are different from those used in training demonstrations. In this paper, we study the compositionality of action by looking into the dynamics of subject-object interactions. We propose a novel model which can explicitly reason about the geometric relations between constituent objects and an agent performing an action. To train our model, we collect dense object box annotations on the Something-Something dataset. We propose a novel compositional action recognition task where the training combinations of verbs and nouns do not overlap with the test set. The novel aspects of our model are applicable to activities with prominent object interaction dynamics and to objects which can be tracked using state-of-the-art approaches; for activities without clearly defined spatial object-agent interactions, we rely on baseline scene-level spatio-temporal representations. We show the effectiveness of our approach not only on the proposed compositional action recognition task but also in a few-shot compositional setting which requires the model to generalize across both object appearance and action category.",
        "year": 2019,
        "authors": "Joanna Materzynska and Tete Xiao and Roei Herzig and Huijuan Xu and Xiaolong Wang and Trevor Darrell"
      },
      {
        "title": "DETReg: Unsupervised Pretraining with Region Priors for Object Detection",
        "abstract": "Recent self-supervised pretraining methods for object detection largely focus on pretraining the backbone of the object detector, neglecting key parts of detection architecture. Instead, we introduce DETReg, a new self-supervised method that pretrains the entire object detection network, including the object localization and embedding components. During pretraining, DETReg predicts object localizations to match the localizations from an unsupervised region proposal generator and simultaneously aligns the corresponding feature embeddings with embeddings from a self-supervised image encoder. We implement DETReg using the DETR family of detectors and show that it improves over competitive baselines when finetuned on COCO, PASCAL VOC, and Airbus Ship benchmarks. In low-data regimes, including semi-supervised and few-shot learning settings, DETReg establishes many state-of-the-art results, eg, on COCO we see a+ 6.0 AP improvement for 10-shot detection and+ 3.5 AP improvement when training with only 1% of the labels.",
        "year": 2021,
        "authors": "Amir Bar and Xin Wang and Vadim Kantorov and Colorado J Reed and Roei Herzig and Gal Chechik and Anna Rohrbach and Trevor Darrell and Amir Globerson"
      }
    ],
    "56EZh6YAAAAJ": [
      {
        "title": "Building a bird recognition app and large scale dataset with citizen scientists: The fine print in fine-grained dataset collection",
        "abstract": "We introduce tools and methodologies to collect high quality, large scale fine-grained computer vision datasets using citizen scientists--crowd annotators who are passionate and knowledgeable about specific domains such as birds or airplanes. We worked with citizen scientists and domain experts to collect NABirds, a new high quality dataset containing 48,562 images of North American birds with 555 categories, part annotations and bounding boxes. We find that citizen scientists are significantly more accurate than Mechanical Turkers at zero cost. We worked with bird experts to measure the quality of popular datasets like CUB-200-2011 and ImageNet and found class label error rates of at least 4%. Nevertheless, we found that learning algorithms are surprisingly robust to annotation errors and this level of training data corruption can lead to an acceptably small increase in test error if the training set has sufficient size. At the same time, we found that an expert-curated high quality test set like NABirds is necessary to accurately measure the performance of fine-grained computer vision systems. We used NABirds to train a publicly available bird recognition service deployed on the web site of the Cornell Lab of Ornithology.",
        "year": 2015,
        "authors": "Grant Van Horn and Steve Branson and Ryan Farrell and Scott Haber and Jessie Barry and Panos Ipeirotis and Pietro Perona and Serge Belongie"
      },
      {
        "title": "The designers' outpost: a tangible interface for collaborative web site",
        "abstract": "In our previous studies into web design, we found that pens, paper, walls, and tables were often used for explaining, developing, and communicating ideas during the early phases of design. These wall-scale paper-based design practices inspired The Designers' Outpost, a tangible user interface that combines the affordances of paper and large physical workspaces with the advantages of electronic media to support information design. With Outpost, users collaboratively author web site information architectures on an electronic whiteboard using physical media (Post-it notes and images), structuring and annotating that information with electronic pens. This interaction is enabled by a touch-sensitive SMART Board augmented with a robust computer vision system, employing a rear-mounted video camera for capturing movement and a front-mounted high-resolution camera for capturing ink. We conducted a …",
        "year": 2001,
        "authors": "Scott R Klemmer and Mark W Newman and Ryan Farrell and Mark Bilezikjian and James A Landay"
      },
      {
        "title": "Deformable part descriptors for fine-grained recognition and attribute prediction",
        "abstract": "Recognizing objects in fine-grained domains can be extremely challenging due to the subtle differences between subcategories. Discriminative markings are often highly localized, leading traditional object recognition approaches to struggle with the large pose variation often present in these domains. Pose-normalization seeks to align training exemplars, either piecewise by part or globally for the whole object, effectively factoring out differences in pose and in viewing angle. Prior approaches relied on computationally-expensive filter ensembles for part localization and required extensive supervision. This paper proposes two pose-normalized descriptors based on computationally-efficient deformable part models. The first leverages the semantics inherent in strongly-supervised DPM parts. The second exploits weak semantic annotations to learn cross-component correspondences, computing pose-normalized descriptors from the latent parts of a weakly-supervised DPM. These representations enable pooling across pose and viewpoint, in turn facilitating tasks such as fine-grained recognition and attribute prediction. Experiments conducted on the Caltech-UCSD Birds 200 dataset and Berkeley Human Attribute dataset demonstrate significant improvements over state-of-art algorithms.",
        "year": 2013,
        "authors": "Ning Zhang and Ryan Farrell and Forrest Iandola and Trevor Darrell"
      }
    ],
    "s_3ZE8kAAAAJ": [
      {
        "title": "Robust estimators in high-dimensions without the computational intractability",
        "abstract": "We study high-dimensional distribution learning in an agnostic setting where an adversary is allowed to arbitrarily corrupt an -fraction of the samples. Such questions have a rich history spanning statistics, machine learning, and theoretical computer science. Even in the most basic settings, the only known approaches are either computationally inefficient or lose dimension-dependent factors in their error guarantees. This raises the following question: Is high-dimensional agnostic distribution learning even possible, algorithmically? In this work, we obtain the first computationally efficient algorithms with dimension-independent error guarantees for agnostically learning several fundamental classes of high-dimensional distributions: (1) a single Gaussian, (2) a product distribution on the hypercube, (3) mixtures of two product distributions (under a natural balancedness condition), and (4) mixtures of spherical …",
        "year": 2019,
        "authors": "Ilias Diakonikolas and Gautam Kamath and Daniel Kane and Jerry Li and Ankur Moitra and Alistair Stewart"
      },
      {
        "title": "Sever: A robust meta-algorithm for stochastic optimization",
        "abstract": "In high dimensions, most machine learning methods are brittle to even a small fraction of structured outliers. To address this, we introduce a new meta-algorithm that can take in a base learner such as least squares or stochastic gradient descent, and harden the learner to be resistant to outliers. Our method, Sever, possesses strong theoretical guarantees yet is also highly scalable–beyond running the base learner itself, it only requires computing the top singular vector of a certain n {\\texttimes} d matrix. We apply Sever on a drug design dataset and a spam classification dataset, and find that in both cases it has substantially greater robustness than several baselines. On the spam dataset, with 1% corruptions, we achieved 7.4% test error, compared to 13.4%-20.5% for the baselines, and 3% error on the uncorrupted dataset. Similarly, on the drug design dataset, with 10% corruptions, we achieved 1.42 mean-squared error test error, compared to 1.51-2.33 for the baselines, and 1.23 error on the uncorrupted dataset.",
        "year": 2019,
        "authors": "Ilias Diakonikolas and Gautam Kamath and Daniel Kane and Jerry Li and Jacob Steinhardt and Alistair Stewart"
      },
      {
        "title": "Being robust (in high dimensions) can be practical",
        "abstract": "Robust estimation is much more challenging in high-dimensions than it is in one-dimension: Most techniques either lead to intractable optimization problems or estimators that can tolerate only a tiny fraction of errors. Recent work in theoretical computer science has shown that, in appropriate distributional models, it is possible to robustly estimate the mean and covariance with polynomial time algorithms that can tolerate a constant fraction of corruptions, independent of the dimension. However, the sample and time complexity of these algorithms is prohibitively large for high-dimensional applications. In this work, we address both of these issues by establishing sample complexity bounds that are optimal, up to logarithmic factors, as well as giving various refinements that allow the algorithms to tolerate a much larger fraction of corruptions. Finally, we show on both synthetic and real data that our algorithms have state-of-the-art performance and suddenly make high-dimensional robust estimation a realistic possibility.",
        "year": 2017,
        "authors": "Ilias Diakonikolas and Gautam Kamath and Daniel M Kane and Jerry Li and Ankur Moitra and Alistair Stewart"
      }
    ],
    "7P-gZioAAAAJ": [
      {
        "title": "Ray: A distributed framework for emerging {AI} applications",
        "abstract": "The next generation of AI applications will continuously interact with the environment and learn from these interactions. These applications impose new and demanding systems requirements, both in terms of performance and flexibility. In this paper, we consider these requirements and present Ray—a distributed system to address them. Ray implements a unified interface that can express both task-parallel and actor-based computations, supported by a single dynamic execution engine. To meet the performance requirements, Ray employs a distributed scheduler and a distributed and fault-tolerant store to manage the system’s control state. In our experiments, we demonstrate scaling beyond 1.8 million tasks per second and better performance than existing specialized systems for several challenging reinforcement learning applications.",
        "year": 2018,
        "authors": "Philipp Moritz and Robert Nishihara and Stephanie Wang and Alexey Tumanov and Richard Liaw and Eric Liang and Melih Elibol and Zongheng Yang and William Paul and Michael I Jordan and Ion Stoica"
      },
      {
        "title": "Heterogeneity and dynamicity of clouds at scale: Google trace analysis",
        "abstract": "To better understand the challenges in developing effective cloud-based resource schedulers, we analyze the first publicly available trace data from a sizable multi-purpose cluster. The most notable workload characteristic is heterogeneity: in resource types (e.g., cores:RAM per machine) and their usage (e.g., duration and resources needed). Such heterogeneity reduces the effectiveness of traditional slot- and core-based scheduling. Furthermore, some tasks are constrained as to the kind of machine types they can use, increasing the complexity of resource assignment and complicating task migration. The workload is also highly dynamic, varying over time and most workload features, and is driven by many short jobs that demand quick scheduling decisions. While few simplifying assumptions apply, we find that many longer-running jobs have relatively stable resource utilizations, which can help adaptive resource …",
        "year": 2012,
        "authors": "Charles Reiss and Alexey Tumanov and Gregory R Ganger and Randy H Katz and Michael A Kozuch"
      },
      {
        "title": "Serverless computing: One step forward, two steps back",
        "abstract": "Serverless computing offers the potential to program the cloud in an autoscaling, pay-as-you go manner. In this paper we address critical gaps in first-generation serverless computing, which place its autoscaling potential at odds with dominant trends in modern computing: notably data-centric and distributed computing, but also open source and custom hardware. Put together, these gaps make current serverless offerings a bad fit for cloud innovation and particularly bad for data systems innovation. In addition to pinpointing some of the main shortfalls of current serverless architectures, we raise a set of challenges we believe must be met to unlock the radical potential that the cloud---with its exabytes of storage and millions of cores---should offer to innovative developers.",
        "year": 2018,
        "authors": "Joseph M Hellerstein and Jose Faleiro and Joseph E Gonzalez and Johann Schleier-Smith and Vikram Sreekanti and Alexey Tumanov and Chenggang Wu"
      }
    ],
    "6QWsktwAAAAJ": [
      {
        "title": "Analysis of protein-coding genetic variation in 60,706 humans",
        "abstract": "Large-scale reference data sets of human genetic variation are critical for the medical and functional interpretation of DNA sequence changes. Here we describe the aggregation and analysis of high-quality exome (protein-coding region) DNA sequence data for 60,706 individuals of diverse ancestries generated as part of the Exome Aggregation Consortium (ExAC). This catalogue of human genetic diversity contains an average of one variant every eight bases of the exome, and provides direct evidence for the presence of widespread mutational recurrence. We have used this catalogue to calculate objective metrics of pathogenicity for sequence variants, and to identify genes subject to strong selection against various classes of mutation; identifying 3,230 genes with near-complete depletion of predicted protein-truncating variants, with 72% of these genes having no currently established human disease phenotype …",
        "year": 2016,
        "authors": "Monkol Lek and Konrad J Karczewski and Eric V Minikel and Kaitlin E Samocha and Eric Banks and Timothy Fennell and Anne H O’Donnell-Luria and James S Ware and Andrew J Hill and Beryl B Cummings and Taru Tukiainen and Daniel P Birnbaum and Jack A Kosmicki and Laramie E Duncan and Karol Estrada and Fengmei Zhao and James Zou and Emma Pierce-Hoffman and Joanne Berghout and David N Cooper and Nicole Deflaux and Mark DePristo and Ron Do and Jason Flannick and Menachem Fromer and Laura Gauthier and Jackie Goldstein and Namrata Gupta and Daniel Howrigan and Adam Kiezun and Mitja I Kurki and Ami Levy Moonshine and Pradeep Natarajan and Lorena Orozco and Gina M Peloso and Ryan Poplin and Manuel A Rivas and Valentin Ruano-Rubio and Samuel A Rose and Douglas M Ruderfer and Khalid Shakir and Peter D Stenson and Christine Stevens and Brett P Thomas and Grace Tiao and Maria T Tusie-Luna and Ben Weisburd and Hong-Hee Won and Dongmei Yu and David M Altshuler and Diego Ardissino and Michael Boehnke and John Danesh and Stacey Donnelly and Roberto Elosua and Jose C Florez and Stacey B Gabriel and Gad Getz and Stephen J Glatt and Christina M Hultman and Sekar Kathiresan and Markku Laakso and Steven McCarroll and Mark I McCarthy and Dermot McGovern and Ruth McPherson and Benjamin M Neale and Aarno Palotie and Shaun M Purcell and Danish Saleheen and Jeremiah M Scharf and Pamela Sklar and Patrick F Sullivan and Jaakko Tuomilehto and Ming T Tsuang and Hugh C Watkins and James G Wilson and Mark J Daly and Daniel G MacArthur and Exome Aggregation Consortium"
      },
      {
        "title": "Genome-wide polygenic scores for common diseases identify individuals with risk equivalent to monogenic mutations",
        "abstract": "A key public health need is to identify individuals at high risk for a given disease to enable enhanced screening or preventive therapies. Because most common diseases have a genetic component, one important approach is to stratify individuals based on inherited DNA variation. Proposed clinical applications have largely focused on finding carriers of rare monogenic mutations at several-fold increased risk. Although most disease risk is polygenic in nature, , –, it has not yet been possible to use polygenic predictors to identify individuals at risk comparable to monogenic mutations. Here, we develop and validate genome-wide polygenic scores for five common diseases. The approach identifies 8.0, 6.1, 3.5, 3.2, and 1.5% of the population at greater than threefold increased risk for coronary artery disease, atrial fibrillation, type 2 diabetes, inflammatory bowel disease, and breast cancer, respectively. For coronary …",
        "year": 2018,
        "authors": "Amit V Khera and Mark Chaffin and Krishna G Aragam and Mary E Haas and Carolina Roselli and Seung Hoan Choi and Pradeep Natarajan and Eric S Lander and Steven A Lubitz and Patrick T Ellinor and Sekar Kathiresan"
      },
      {
        "title": "Clonal hematopoiesis and risk of atherosclerotic cardiovascular disease",
        "abstract": "Clonal hematopoiesis of indeterminate potential (CHIP), which is defined as the presence of an expanded somatic blood-cell clone in persons without other hematologic abnormalities, is common among older persons and is associated with an increased risk of hematologic cancer. We previously found preliminary evidence for an association between CHIP and atherosclerotic cardiovascular disease, but the nature of this association was unclear.We used whole-exome sequencing to detect the presence of CHIP in peripheral-blood cells and associated such presence with coronary heart disease using samples from four case–control studies that together enrolled 4726 participants with coronary heart disease and 3529 controls. To assess causality, we perturbed the function of Tet2, the second most commonly mutated gene linked to clonal hematopoiesis, in the hematopoietic cells of …",
        "year": 2017,
        "authors": "Siddhartha Jaiswal and Pradeep Natarajan and Alexander J Silver and Christopher J Gibson and Alexander G Bick and Eugenia Shvartz and Marie McConkey and Namrata Gupta and Stacey Gabriel and Diego Ardissino and Usman Baber and Roxana Mehran and Valentin Fuster and John Danesh and Philippe Frossard and Danish Saleheen and Olle Melander and Galina K Sukhova and Donna Neuberg and Peter Libby and Sekar Kathiresan and Benjamin L Ebert"
      }
    ],
    "wKJeOQoAAAAJ": [
      {
        "title": "SCAFFOLD: Stochastic Controlled Averaging for Federated Learning",
        "abstract": "Federated learning is a key scenario in modern large-scale machine learning where the data remains distributed over a large number of clients and the task is to learn a centralized model without transmitting the client data. The standard optimization algorithm used in this setting is Federated Averaging (FedAvg) due to its low communication cost. We obtain a tight characterization of the convergence of FedAvg and prove that heterogeneity (non-iid-ness) in the client’s data results in a ‘drift’in the local updates resulting in poor performance. As a solution, we propose a new algorithm (SCAFFOLD) which uses control variates (variance reduction) to correct for the ‘client drift’. We prove that SCAFFOLD requires significantly fewer communication rounds and is not affected by data heterogeneity or client sampling. Further, we show that (for quadratics) SCAFFOLD can take advantage of similarity in the client’s data yielding even faster convergence. The latter is the first result to quantify the usefulness of local-steps in distributed optimization.",
        "year": 2019,
        "authors": "Sai Praneeth Karimireddy and Satyen Kale and Mehryar Mohri and Sashank J Reddi and Sebastian U Stich and Ananda Theertha Suresh"
      },
      {
        "title": "Error Feedback Fixes SignSGD and other Gradient Compression Schemes",
        "abstract": "Sign-based algorithms (eg signSGD) have been proposed as a biased gradient compression technique to alleviate the communication bottleneck in training large neural networks across multiple workers. We show simple convex counter-examples where signSGD does not converge to the optimum. Further, even when it does converge, signSGD may generalize poorly when compared with SGD. These issues arise because of the biased nature of the sign compression operator. We then show that using error-feedback, ie incorporating the error made by the compression operator into the next step, overcomes these issues. We prove that our algorithm (EF-SGD) with arbitrary compression operator achieves the same rate of convergence as SGD without any additional assumptions. Thus EF-SGD achieves gradient compression for free. Our experiments thoroughly substantiate the theory.",
        "year": 2019,
        "authors": "Sai Praneeth Karimireddy and Quentin Rebjock and Sebastian U Stich and Martin Jaggi"
      },
      {
        "title": "A Field Guide to Federated Optimization",
        "abstract": "Federated learning and analytics are a distributed approach for collaboratively learning models (or statistics) from decentralized data, motivated by and designed for privacy protection. The distributed learning process can be formulated as solving federated optimization problems, which emphasize communication efficiency, data heterogeneity, compatibility with privacy and system requirements, and other constraints that are not primary considerations in other problem settings. This paper provides recommendations and guidelines on formulating, designing, evaluating and analyzing federated optimization algorithms through concrete examples and practical implementation, with a focus on conducting effective simulations to infer real-world performance. The goal of this work is not to survey the current literature, but to inspire researchers and practitioners to design federated learning algorithms that can be used in various practical applications.",
        "year": 2021,
        "authors": "Jianyu Wang* and Zachary Charles* and Zheng Xu* and Gauri Joshi* and H Brendan McMahan and Maruan Al-Shedivat and Galen Andrew and Salman Avestimehr and Katharine Daly and Deepesh Data and Suhas Diggavi and Hubert Eichner and Advait Gadhikar and Zachary Garrett and Antonious M Girgis and Filip Hanzely and Andrew Hard and Chaoyang He and Samuel Horvath and Zhouyuan Huo and Alex Ingerman and Martin Jaggi and Tara Javidi and Peter Kairouz and Satyen Kale and Sai Praneeth Karimireddy and Jakub Konecny and Sanmi Koyejo and Tian Li and Luyang Liu and Mehryar Mohri and Hang Qi and Sashank J Reddi and Peter Richtarik and Karan Singhal and Virginia Smith and Mahdi Soltanolkotabi and Weikang Song and Ananda Theertha Suresh and Sebastian U Stich and Ameet Talwalkar and Hongyi Wang and Blake Woodworth and Shanshan Wu and Felix X Yu and Honglin Yuan and Manzil Zaheer and Mi Zhang and Tong Zhang and Chunxiang Zheng and Chen Zhu and Wennan Zhu"
      }
    ],
    "uemlfQYAAAAJ": [
      {
        "title": "Do as i can, not as i say: Grounding language in robotic affordances",
        "abstract": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model's \"hands and eyes,\" while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally-extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project's website and the video can be found at https …",
        "year": 2022,
        "authors": "Michael Ahn and Anthony Brohan and Noah Brown and Yevgen Chebotar and Omar Cortes and Byron David and Chelsea Finn and Chuyuan Fu and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Daniel Ho and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Eric Jang and Rosario Jauregui Ruano and Kyle Jeffrey and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Kuang-Huei Lee and Sergey Levine and Yao Lu and Linda Luu and Carolina Parada and Peter Pastor and Jornell Quiambao and Kanishka Rao and Jarek Rettinghouse and Diego Reyes and Pierre Sermanet and Nicolas Sievers and Clayton Tan and Alexander Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Mengyuan Yan and Andy Zeng"
      },
      {
        "title": "Rt-1: Robotics transformer for real-world control at scale",
        "abstract": "By transferring knowledge from large, diverse, task-agnostic datasets, modern machine learning models can solve specific downstream tasks either zero-shot or with small task-specific datasets to a high level of performance. While this capability has been demonstrated in other fields such as computer vision, natural language processing or speech recognition, it remains to be shown in robotics, where the generalization capabilities of the models are particularly critical due to the difficulty of collecting real-world robotic data. We argue that one of the keys to the success of such general robotic models lies with open-ended task-agnostic training, combined with high-capacity architectures that can absorb all of the diverse, robotic data. In this paper, we present a model class, dubbed Robotics Transformer, that exhibits promising scalable model properties. We verify our conclusions in a study of different model classes and their ability to generalize as a function of the data size, model size, and data diversity based on a large-scale data collection on real robots performing real-world tasks. The project's website and videos can be found at robotics-transformer1.github.io",
        "year": 2022,
        "authors": "Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Joseph Dabis and Chelsea Finn and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Tomas Jackson and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Kuang-Huei Lee and Sergey Levine and Yao Lu and Utsav Malla and Deeksha Manjunath and Igor Mordatch and Ofir Nachum and Carolina Parada and Jodilyn Peralta and Emily Perez and Karl Pertsch and Jornell Quiambao and Kanishka Rao and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Kevin Sayed and Jaspiar Singh and Sumedh Sontakke and Austin Stone and Clayton Tan and Huong Tran and Vincent Vanhoucke and Steve Vega and Quan Vuong and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich"
      },
      {
        "title": "Rt-2: Vision-language-action models transfer web knowledge to robotic control",
        "abstract": "We study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robotic trajectory data and Internet-scale vision-language tasks, such as visual question answering. In contrast to other approaches, we propose a simple, general recipe to achieve this goal: in order to fit both natural language responses and robotic actions into the same format, we express the actions as text tokens and incorporate them directly into the training set of the model in the same way as natural language tokens. We refer to such category of models as vision-language-action models (VLA) and instantiate an example of such a model, which we call RT-2. Our extensive evaluation (6k evaluation trials) shows that our approach leads to performant robotic policies and enables RT-2 to obtain a range of emergent capabilities from Internet-scale training. This includes significantly improved generalization to novel objects, the ability to interpret commands not present in the robot training data (such as placing an object onto a particular number or icon), and the ability to perform rudimentary reasoning in response to user commands (such as picking up the smallest or largest object, or the one closest to another object). We further show that incorporating chain of …",
        "year": 2023,
        "authors": "Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Xi Chen and Krzysztof Choromanski and Tianli Ding and Danny Driess and Avinava Dubey and Chelsea Finn and Pete Florence and Chuyuan Fu and Montse Gonzalez Arenas and Keerthana Gopalakrishnan and Kehang Han and Karol Hausman and Alexander Herzog and Jasmine Hsu and Brian Ichter and Alex Irpan and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Lisa Lee and Tsang-Wei Edward Lee and Sergey Levine and Yao Lu and Henryk Michalewski and Igor Mordatch and Karl Pertsch and Kanishka Rao and Krista Reymann and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Pierre Sermanet and Jaspiar Singh and Anikait Singh and Radu Soricut and Huong Tran and Vincent Vanhoucke and Quan Vuong and Ayzaan Wahid and Stefan Welker and Paul Wohlhart and Jialin Wu and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich"
      }
    ],
    "_7Q8uIYAAAAJ": [
      {
        "title": "Judging llm-as-a-judge with mt-bench and chatbot arena",
        "abstract": "Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80\\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github. com/lm-sys/FastChat/tree/main/fastchat/llm_judge.",
        "year": 2023,
        "authors": "Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric Xing and Hao Zhang and Joseph E Gonzalez and Ion Stoica"
      },
      {
        "title": "TVM: An automated end-to-end optimizing compiler for deep learning",
        "abstract": "There is an increasing need to bring machine learning to a wide diversity of hardware devices. Current frameworks rely on vendor-specific operator libraries and optimize for a narrow range of server-class GPUs. Deploying workloads to new platforms--such as mobile phones, embedded devices, and accelerators (eg, FPGAs, ASICs)--requires significant manual effort. We propose TVM, a compiler that exposes graph-level and operator-level optimizations to provide performance portability to deep learning workloads across diverse hardware back-ends. TVM solves optimization challenges specific to deep learning, such as high-level operator fusion, mapping to arbitrary hardware primitives, and memory latency hiding. It also automates optimization of low-level programs to hardware characteristics by employing a novel, learning-based cost modeling method for rapid exploration of code optimizations. Experimental results show that TVM delivers performance across hardware back-ends that are competitive with state-of-the-art, hand-tuned libraries for low-power CPU, mobile GPU, and server-class GPUs. We also demonstrate TVM's ability to target new accelerator back-ends, such as the FPGA-based generic deep learning accelerator. The system is open sourced and in production use inside several major companies.",
        "year": 2018,
        "authors": "Tianqi Chen and Thierry Moreau and Ziheng Jiang and Lianmin Zheng and Eddie Yan and Haichen Shen and Meghan Cowan and Leyuan Wang and Yuwei Hu and Luis Ceze and Carlos Guestrin and Arvind Krishnamurthy"
      }
    ],
    "i5srt20AAAAJ": [
      {
        "title": "Adaptive subgradient methods for online learning and stochastic optimization.",
        "abstract": "We present a new family of subgradient methods that dynamically incorporate knowledge of the geometry of the data observed in earlier iterations to perform more informative gradient-based learning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very predictive but rarely seen features. Our paradigm stems from recent advances in stochastic optimization and online learning which employ proximal functions to control the gradient steps of the algorithm. We describe and analyze an apparatus for adaptively modifying the proximal function, which significantly simplifies setting a learning rate and results in regret guarantees that are provably as good as the best proximal function that can be chosen in hindsight. We give several efficient algorithms for empirical risk minimization problems with common and important regularization functions and domain constraints. We experimentally study our theoretical analysis and show that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient algorithms.",
        "year": 2011,
        "authors": "John Duchi and Elad Hazan and Yoram Singer"
      },
      {
        "title": "Efficient projections onto the l1-ball for learning in high dimensions",
        "abstract": "We describe efficient algorithms for projecting a vector onto the l1-ball. We present two methods for projection. The first performs exact projection in O(n) expected time, where n is the dimension of the space. The second works on vectors k of whose elements are perturbed outside the l1-ball, projecting in O(k log(n)) time. This setting is especially useful for online learning in sparse feature spaces such as text categorization applications. We demonstrate the merits and effectiveness of our algorithms in numerous batch and online learning tasks. We show that variants of stochastic gradient projection methods augmented with our efficient projection procedures outperform interior point methods, which are considered state-of-the-art optimization techniques. We also show that in online settings gradient updates with l1 projections outperform the exponentiated gradient algorithm while obtaining models with high degrees …",
        "year": 2008,
        "authors": "John Duchi and Shai Shalev-Shwartz and Yoram Singer and Tushar Chandra"
      },
      {
        "title": "Local privacy and statistical minimax rates",
        "abstract": "Working under local differential privacy-a model of privacy in which data remains private even from the statistician or learner-we study the tradeoff between privacy guarantees and the utility of the resulting statistical estimators. We prove bounds on information-theoretic quantities, including mutual information and Kullback-Leibler divergence, that influence estimation rates as a function of the amount of privacy preserved. When combined with minimax techniques such as Le Cam's and Fano's methods, these inequalities allow for a precise characterization of statistical rates under local privacy constraints. In this paper, we provide a treatment of two canonical problem families: mean estimation in location family models and convex risk minimization. For these families, we provide lower and upper bounds for estimation of population quantities that match up to constant factors, giving privacy-preserving mechanisms and …",
        "year": 2013,
        "authors": "John C Duchi and Michael I Jordan and Martin J Wainwright"
      }
    ],
    "2oy3OXYAAAAJ": [
      {
        "title": "Algorithms for inverse reinforcement learning.",
        "abstract": "This paper addresses the problem of inverse reinforcement learning (IRL) in Markov de-cision processes, that is, the problem of extracting a reward function given observed, optimal behavior. IRL may be useful for apprenticeship learning to acquire skilled behavior, and for ascertaining the reward function being optimized by a natural system. We first characterize the set of all reward func-tions for which a given policy is optimal. We then derive three algorithms for IRL. The first two deal with the case where the entire policy is known; we handle tabulated reward functions on a finite state space and linear functional approximation of the reward function over a potentially infinite state space. The third algorithm deals with the more realistic case in which the policy is known only through a finite set of observed trajectories. In all cases, a key issue is degeneracy-the existence of a large set of reward functions for which the …",
        "year": 2000,
        "authors": "Andrew Y Ng and Stuart Russell"
      },
      {
        "title": "Distance metric learning with application to clustering with side-information",
        "abstract": "Many algorithms rely critically on being given a good metric over their inputs. For instance, data can often be clustered in many “plausible” ways, and if a clustering algorithm such as K-means initially fails to find one that is meaningful to a user, the only recourse may be for the user to manually tweak the metric until sufficiently good clusters are found. For these and other applications requiring good metrics, it is desirable that we provide a more systematic way for users to indicate what they consider “similar.” For instance, we may ask them to provide examples. In this paper, we present an algorithm that, given examples of similar (and, if desired, dissimilar) pairs of points in вдг, learns a distance metric over вег that respects these relationships. Our method is based on posing metric learning as a convex optimization problem, which allows us to give efficient, local-optima-free algorithms. We also demonstrate empirically that the learned metrics can be used to significantly improve clustering performance.",
        "year": 2002,
        "authors": "Eric Xing and Michael Jordan and Stuart J Russell and Andrew Ng"
      }
    ],
    "pfGI-KcAAAAJ": [
      {
        "title": "Ast: Audio spectrogram transformer",
        "abstract": "In the past decade, convolutional neural networks (CNNs) have been widely adopted as the main building block for end-to-end audio classification models, which aim to learn a direct mapping from audio spectrograms to corresponding labels. To better capture long-range global context, a recent trend is to add a self-attention mechanism on top of the CNN, forming a CNN-attention hybrid model. However, it is unclear whether the reliance on a CNN is necessary, and if neural networks purely based on attention are sufficient to obtain good performance in audio classification. In this paper, we answer the question by introducing the Audio Spectrogram Transformer (AST), the first convolution-free, purely attention-based model for audio classification. We evaluate AST on various audio classification benchmarks, where it achieves new state-of-the-art results of 0.485 mAP on AudioSet, 95.6% accuracy on ESC-50, and 98.1% accuracy on Speech Commands V2.",
        "year": 2021,
        "authors": "Yuan Gong and Yu-An Chung and James Glass"
      },
      {
        "title": "Speech database development at MIT: TIMIT and beyond",
        "abstract": "Automatic speech recognition by computers can provide the most natural and efficient method of communication between humans and computers. While in recent years high performance speech recognition systems are beginning to emerge from research institutions, scientists unequivocally agree that the deployment of speech recognition systems into realistic operating environments will require many hours of speech data to help us model the inherent variability in the speech signal. This paper describes the experiences of researchers at MIT in the collection of two large speech databases which have somewhat complementary objectives. The timit database was designed to be task and speaker-independent, and is suitable for general acoustic-phonetic research. The voyager database, on the other hand, was intended for development and evaluation of a system which incorporates both speech and natural …",
        "year": 1990,
        "authors": "Victor Zue and Stephanie Seneff and James Glass"
      },
      {
        "title": "JUPlTER: a telephone-based conversational interface for weather information",
        "abstract": "In early 1997, our group initiated a project to develop JUPITER, a conversational interface that allows users to obtain worldwide weather forecast information over the telephone using spoken dialogue. It has served as the primary research platform for our group on many issues related to human language technology, including telephone-based speech recognition, robust language understanding, language generation, dialogue modeling, and multilingual interfaces. Over a two year period since coming online in May 1997, JUPITER has received, via a toll-free number in North America, over 30000 calls (totaling over 180000 utterances), mostly from naive users. The purpose of this paper is to describe our development effort in terms of the underlying human language technologies as well as other system-related issues such as utterance rejection and content harvesting. We also present some evaluation results on …",
        "year": 2002,
        "authors": "Victor Zue and Stephanie Seneff and James R Glass and Joseph Polifroni and Christine Pao and Timothy J Hazen and Lee Hetherington"
      }
    ],
    "_EJrRVAAAAAJ": [
      {
        "title": "Decision transformer: Reinforcement learning via sequence modeling",
        "abstract": "We introduce a framework that abstracts Reinforcement Learning (RL) as a sequence modeling problem. This allows us to draw upon the simplicity and scalability of the Transformer architecture, and associated advances in language modeling such as GPT-x and BERT. In particular, we present Decision Transformer, an architecture that casts the problem of RL as conditional sequence modeling. Unlike prior approaches to RL that fit value functions or compute policy gradients, Decision Transformer simply outputs the optimal actions by leveraging a causally masked Transformer. By conditioning an autoregressive model on the desired return (reward), past states, and actions, our Decision Transformer model can generate future actions that achieve the desired return. Despite its simplicity, Decision Transformer matches or exceeds the performance of state-of-the-art model-free offline RL baselines on Atari, OpenAI Gym, and Key-to-Door tasks.",
        "year": 2021,
        "authors": "Lili Chen and Kevin Lu and Aravind Rajeswaran and Kimin Lee and Aditya Grover and Misha Laskin and Pieter Abbeel and Aravind Srinivas and Igor Mordatch"
      },
      {
        "title": "Learning complex dexterous manipulation with deep reinforcement learning and demonstrations",
        "abstract": "Dexterous multi-fingered hands are extremely versatile and provide a generic way to perform a multitude of tasks in human-centric environments. However, effectively controlling them remains challenging due to their high dimensionality and large number of potential contacts. Deep reinforcement learning (DRL) provides a model-agnostic approach to control complex dynamical systems, but has not been shown to scale to high-dimensional dexterous manipulation. Furthermore, deployment of DRL on physical systems remains challenging due to sample inefficiency. Consequently, the success of DRL in robotics has thus far been limited to simpler manipulators and tasks. In this work, we show that model-free DRL can effectively scale up to complex manipulation tasks with a high-dimensional 24-DoF hand, and solve them from scratch in simulated experiments. Furthermore, with the use of a small number of human demonstrations, the sample complexity can be significantly reduced, which enables learning with sample sizes equivalent to a few hours of robot experience. The use of demonstrations result in policies that exhibit very natural movements and, surprisingly, are also substantially more robust.",
        "year": 2018,
        "authors": "Aravind Rajeswaran and Vikash Kumar and Abhishek Gupta and Giulia Vezzani and John Schulman and Emanuel Todorov and Sergey Levine"
      },
      {
        "title": "Meta-Learning with Implicit Gradients",
        "abstract": "A core capability of intelligent systems is the ability to quickly learn new tasks by drawing on prior experience. Gradient (or optimization) based meta-learning has recently emerged as an effective approach for few-shot learning. In this formulation, meta-parameters are learned in the outer loop, while task-specific models are learned in the inner-loop, by using only a small amount of data from the current task. A key challenge in scaling these approaches is the need to differentiate through the inner loop learning process, which can impose considerable computational and memory burdens. By drawing upon implicit differentiation, we develop the implicit MAML algorithm, which depends only on the solution to the inner level optimization and not the path taken by the inner loop optimizer. This effectively decouples the meta-gradient computation from the choice of inner loop optimizer. As a result, our approach is agnostic to the choice of inner loop optimizer and can gracefully handle many gradient steps without vanishing gradients or memory constraints. Theoretically, we prove that implicit MAML can compute accurate meta-gradients with a memory footprint that is, up to small constant factors, no more than that which is required to compute a single inner loop gradient and at no overall increase in the total computational cost. Experimentally, we show that these benefits of implicit MAML translate into empirical gains on few-shot image recognition benchmarks.",
        "year": 2019,
        "authors": "Aravind Rajeswaran and Chelsea Finn and Sham Kakade and Sergey Levine"
      }
    ],
    "12uhMdIAAAAJ": [
      {
        "title": "Integrated person tracking using stereo, color, and pattern detection",
        "abstract": "We present an approach to real-time person tracking in crowded and/or unknown environments using integration of multiple visual modalities. We combine stereo, color, and face detection modules into a single robust system, and show an initial application in an interactive, face-responsive display. Dense, real-time stereo processing is used to isolate users from other objects and people in the background. Skin-hue classification identifies and tracks likely body parts within the silhouette of a user. Face pattern detection discriminates and localizes the face within the identified body parts. Faces and bodies of users are tracked over several temporal scales: short-term (user stays within the field of view), medium-term (user exits/reenters within minutes), and long term (user returns after hours or days). Short-term tracking is performed using simple region position and size correspondences, while medium and …",
        "year": 2000,
        "authors": "Trevor Darrell and Gaile Gordon and Michael Harville and John Woodfill"
      },
      {
        "title": "Integrated person tracking using stereo, color, and pattern detection",
        "abstract": "We present an approach to real-time person tracking in crowded and/or unknown environments using integration of multiple visual modalities. We combine stereo, color, and face detection modules into a single robust system, and show an initial application in an interactive, face-responsive display. Dense, real-time stereo processing is used to isolate users from other objects and people in the background. Skin-hue classification identifies and tracks likely body parts within the silhouette of a user. Face pattern detection discriminates and localizes the face within the identified body parts. Faces and bodies of users are tracked over several temporal scales: short-term (user stays within the field of view), medium-term (user exits/reenters within minutes), and long term (user returns after hours or days). Short-term tracking is performed using simple region position and size correspondences, while medium and …",
        "year": 1998,
        "authors": "Trevor Darrell and G Gordon and Michael Harville and John Woodfill"
      },
      {
        "title": "Method and apparatus for personnel detection and tracking",
        "abstract": "Techniques from computer vision and computer graphics are combined to robustly track a target (eg, a user) and perform a function based upon the image and/or the identity attrib uted to the target's face. Three primary modules are used to track a user's head: depth estimation, color Segmentation, and pattern classification. The combination of these three techniques allows for robust performance despite unknown background, crowded conditions, and rapidly changing pose or expression of the user. Each of the modules can also provide an identity classification module with valuable information So that the identity of a user can be estimated. With an estimate of the position of a target in 3-D and the target's identity, applications Such as individualized com puter programs or graphics techniques to distort and/or morph the shape or apparent material properties of the user's face can be performed. The System can track …",
        "year": 2001,
        "authors": "Trevor Darrell and Gaile Gordon and Michael Harville and John Woodfill and Harlyn Baker"
      }
    ],
    "_PZKLYUAAAAJ": [
      {
        "title": "Adwords and generalized online matching",
        "abstract": "How does a search engine company decide what ads to display with each query so as to maximize its revenue? This turns out to be a generalization of the online bipartite matching problem. We introduce the notion of a trade-off revealing LP and use it to derive an optimal algorithm achieving a competitive ratio of 1−1/e for this problem.",
        "year": 2007,
        "authors": "Aranyak Mehta and Amin Saberi and Umesh Vazirani and Vijay Vazirani"
      },
      {
        "title": "Random walks in peer-to-peer networks",
        "abstract": "We quantify the effectiveness of random walks for searching and construction of unstructured peer-to-peer (P2P) networks. We have identified two cases where the use of random walks for searching achieves better results than flooding: a) when the overlay topology is clustered, and h) when a client re-issues the same query while its horizon does not change much. For construction, we argue that an expander can he maintained dynamically with constant operations per addition. The key technical ingredient of our approach is a deep result of stochastic processes indicating that samples taken from consecutive steps of a random walk can achieve statistical properties similar to independent sampling (if the second eigenvalue of the transition matrix is hounded away from 1, which translates to good expansion of the network; such connectivity is desired, and believed to hold, in every reasonable network and network …",
        "year": 2004,
        "authors": "Christos Gkantsidis and Milena Mihail and Amin Saberi"
      },
      {
        "title": "On approximately fair allocations of indivisible goods",
        "abstract": "We study the problem of fairly allocating a set of indivisible goods to a set of people from an algorithmic perspective. fair division has been a central topic in the economic literature and several concepts of fairness have been suggested. The criterion that we focus on is envy-freeness. In our model, a monotone utility function is associated with every player specifying the value of each subset of the goods for the player. An allocation is envy-free if every player prefers her own share than the share of any other player. When the goods are divisible, envy-free allocations always exist. In the presence of indivisibilities, we show that there exist allocations in which the envy is bounded by the maximum marginal utility, and present a simple algorithm for computing such allocations. We then look at the optimization problem of finding an allocation with minimum possible envy. In the general case the problem is not solvable or …",
        "year": 2004,
        "authors": "Richard J Lipton and Evangelos Markakis and Elchanan Mossel and Amin Saberi"
      }
    ],
    "B_FTboQAAAAJ": [
      {
        "title": "The unreasonable effectiveness of deep features as a perceptual metric",
        "abstract": "While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, the underlying processes are thought to be quite complex. Despite this, the most widely used perceptual metrics today, such as PSNR and SSIM, are simple, shallow functions, and fail to account for many nuances of human perception. Recently, the deep learning community has found that features of the VGG network trained on ImageNet classification has been remarkably useful as a training loss for image synthesis. But how perceptual are these so-called``perceptual losses\"? What elements are critical for their success? To answer these questions, we introduce a new dataset of human perceptual similarity judgments. We systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. We find that deep features outperform all previous metrics by large margins on our dataset. More surprisingly, this result is not restricted to ImageNet-trained VGG features, but holds across different deep architectures and levels of supervision (supervised, self-supervised, or even unsupervised). Our results suggest that perceptual similarity is an emergent property shared across deep visual representations.",
        "year": 2018,
        "authors": "Richard Zhang and Phillip Isola and Alexei A Efros and Eli Shechtman and Oliver Wang"
      },
      {
        "title": "PatchMatch: A randomized correspondence algorithm for structural image editing",
        "abstract": "This paper presents interactive image editing tools using a new randomized algorithm for quickly finding approximate nearestneighbor matches between image patches. Previous research in graphics and vision has leveraged such nearest-neighbor searches to provide a variety of high-level digital image editing tools. However, the cost of computing a field of such matches for an entire image has eluded previous efforts to provide interactive performance. Our algorithm offers substantial performance improvements over the previous state of the art (20-100x), enabling its use in interactive editing tools. The key insights driving the algorithm are that some good patch matches can be found via random sampling, and that natural coherence in the imagery allows us to propagate such matches quickly to surrounding areas. We offer theoretical analysis of the convergence properties of the algorithm, as well as empirical and practical evidence for its high quality and performance. This one simple algorithm forms the basis for a variety of tools–image retargeting, completion and reshuffling–that can be used together in the context of a high-level image editing application. Finally, we propose additional intuitive constraints on the synthesis process that offer the user a level of control unavailable in previous methods.",
        "year": 2009,
        "authors": "Connelly Barnes and Eli Shechtman and Adam Finkelstein and Dan B Goldman"
      },
      {
        "title": "Actions as space-time shapes",
        "abstract": "Human action in video sequences can be seen as silhouettes of a moving torso and protruding limbs undergoing articulated motion. We regard human actions as three-dimensional shapes induced by the silhouettes in the space-time volume. We adopt a recent approach by Gorelick et al. (2004) for analyzing 2D shapes and generalize it to deal with volumetric space-time action shapes. Our method utilizes properties of the solution to the Poisson equation to extract space-time features such as local space-time saliency, action dynamics, shape structure and orientation. We show that these features are useful for action recognition, detection and clustering. The method is fast, does not require video alignment and is applicable in (but not limited to) many scenarios where the background is known. Moreover, we demonstrate the robustness of our method to partial occlusions, non-rigid deformations, significant changes …",
        "year": 2005,
        "authors": "Moshe Blank and Lena Gorelick and Eli Shechtman and Michal Irani and Ronen Basri"
      }
    ],
    "pvyI8GkAAAAJ": [
      {
        "title": "Long-term recurrent convolutional networks for visual recognition and description",
        "abstract": "Models comprised of deep convolutional network layers have dominated recent image interpretation tasks; we investigate whether models which are also compositional, or\" deep\", temporally are effective on tasks involving visual sequences or label sequences. We develop a novel recurrent convolutional architecture suitable for large-scale visual learning which is end-to-end trainable, and demonstrate the value of these models on benchmark video recognition tasks, image to sentence generation problems, and video narration challenges. In contrast to current models which assume a fixed spatio-temporal receptive field or simple temporal averaging for sequential processing, recurrent convolutional models are\" doubly deep\" in that they can be compositional in spatial and temporal\" layers\". Such models may have advantages when target concepts are complex and/or training data are limited. Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. Long-term RNN models are appealing in that they directly can map variable length inputs (ie video frames) to variable length outputs (ie natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent long-term models are directly connected to state-of-the-art visual convnet models and can jointly trained, updating temporal dynamics and convolutional perceptual representations simultaneously. Our results show such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined and/or optimized.",
        "year": 2015,
        "authors": "Jeffrey Donahue and Lisa Anne Hendricks and Sergio Guadarrama and Marcus Rohrbach and Subhashini Venugopalan and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Gemini: a family of highly capable multimodal models",
        "abstract": "This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.",
        "year": 2023,
        "authors": "Gemini Team and Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M Dai and Anja Hauth and Katie Millican and David Silver and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Jack Krawczyk and Cosmo Du and Ed Chi and Heng-Tze Cheng and Eric Ni and Purvi Shah and Patrick Kane and Betty Chan and Manaal Faruqui and Aliaksei Severyn and Hanzhao Lin and YaGuang Li and Yong Cheng and Abe Ittycheriah and Mahdis Mahdieh and Mia Chen and Pei Sun and Dustin Tran and Sumit Bagri and Balaji Lakshminarayanan and Jeremiah Liu and Andras Orban and Fabian Güra and Hao Zhou and Xinying Song and Aurelien Boffy and Harish Ganapathy and Steven Zheng and HyunJeong Choe and Ágoston Weisz and Tao Zhu and Yifeng Lu and Siddharth Gopal and Jarrod Kahn and Maciej Kula and Jeff Pitman and Rushin Shah and Emanuel Taropa and Majd Al Merey and Martin Baeuml and Zhifeng Chen and Laurent El Shafey and Yujing Zhang and Olcan Sercinoglu and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Anaïs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Gaurav Singh Tomar and Evan Senter and Martin Chadwick and Ilya Kornakov and Nithya Attaluri and Iñaki Iturrate and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Xavier Garcia and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco"
      },
      {
        "title": "Training compute-optimal large language models",
        "abstract": "We investigate the optimal model size and number of tokens for training a transformer language model under a given compute budget. We find that current large language models are significantly undertrained, a consequence of the recent focus on scaling language models whilst keeping the amount of training data constant. By training over 400 language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens, we find that for compute-optimal training, the model size and the number of training tokens should be scaled equally: for every doubling of model size the number of training tokens should also be doubled. We test this hypothesis by training a predicted compute-optimal model, Chinchilla, that uses the same compute budget as Gopher but with 70B parameters and 4 more more data. Chinchilla uniformly and significantly outperforms Gopher (280B), GPT-3 (175B), Jurassic-1 (178B), and Megatron-Turing NLG (530B) on a large range of downstream evaluation tasks. This also means that Chinchilla uses substantially less compute for fine-tuning and inference, greatly facilitating downstream usage. As a highlight, Chinchilla reaches a state-of-the-art average accuracy of 67.5% on the MMLU benchmark, greater than a 7% improvement over Gopher.",
        "year": 2022,
        "authors": "Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W Rae and Oriol Vinyals and Laurent Sifre"
      }
    ],
    "LAv0HTEAAAAJ": [
      {
        "title": "A computational approach to edge detection",
        "abstract": "This paper describes a computational approach to edge detection. The success of the approach depends on the definition of a comprehensive set of goals for the computation of edge points. These goals must be precise enough to delimit the desired behavior of the detector while making minimal assumptions about the form of the solution. We define detection and localization criteria for a class of edges, and present mathematical forms for these criteria as functionals on the operator impulse response. A third criterion is then added to ensure that the detector has only one response to a single edge. We use the criteria in numerical optimization to derive detectors for several common image features, including step edges. On specializing the analysis to step edges, we find that there is a natural uncertainty principle between detection and localization performance, which are the two main goals. With this principle we …",
        "year": 1986,
        "authors": "John Canny"
      },
      {
        "title": "The complexity of robot motion planning",
        "abstract": "The Complexity of Robot Motion Planning makes original contributions both to roboticsand to the analysis of algorithms. In this groundbreaking monograph John Canny resolveslong-standing problems concerning the complexity of motion planning and, for the central problem offinding a collision free path for a jointed robot in the presence of obstacles, obtains exponentialspeedups over existing algorithms by applying high-powered new mathematical techniques. Canny's newalgorithm for this\" generalized movers' problem,\" the most-studied and basic robot motion planningproblem, has a single exponential running time, and is polynomial for any given robot. The algorithmhas an optimal running time exponent and is based on the notion of roadmaps-one-dimensionalsubsets of the robot's configuration space. In deriving the single exponential bound, Cannyintroduces and reveals the power of two tools that have not been previously used in geometricalgorithms: the generalized (multivariable) resultant for a system of polynomials and Whitney'snotion of stratified sets. He has also developed a novel representation of object orientation basedon unnormalized quaternions which reduces the complexity of the algorithms and enhances theirpractical applicability. After dealing with the movers' problem, the book next attacks and derivesseveral lower bounds on extensions of the problem: finding the shortest path among polyhedralobstacles, planning with velocity limits, and compliant motion planning with uncertainty. Itintroduces a clever technique,\" path encoding,\" that allows a proof of NP-hardness for the first twoproblems and then shows that the …",
        "year": 1988,
        "authors": "John Canny"
      },
      {
        "title": "Finding edges and lines in images",
        "abstract": "The problem of detecting intensity changes in  images is canonical in vision. Edge detection  operators are typically designed to optimally  estimate first or second derivative over some  (usually small) support. Other criteria such as  output signal to noise ratio or bandwidth have  also been argued for. This thesis is an  attempt to formulate a set of edge detection  criteria that capture as directly as possible the  desirable properties of an edge operator.  Variational techniques are used to find a  solution over the space of all linear shift  invariant operators. The first criterion is that  the detector have low probability of error i.e.  failing to mark edges or falsely marking non-edges. The second is that the marked points  should be as close as possible to the centre  of the true edge. The third criterion is that  there should be low probability of more than  one response to a single edge. The technique  is used to find optimal operators for step  edges and for extended impulse profiles  (ridges or valleys in two dimensions). The  extension of the one dimensional operators to  two dimentions is then discussed. The result  is a set of operators of varying width, length  and orientation. The problem of combining  these outputs into a single description is  discussed, and a set of heuristics for the  integration are given.",
        "year": 1983,
        "authors": "John Francis Canny"
      }
    ],
    "gzpWXPcAAAAJ": [
      {
        "title": "Sources of bias in artificial intelligence that perpetuate healthcare disparities—A global review",
        "abstract": "Background While artificial intelligence (AI) offers possibilities of advanced clinical prediction and decision-making in healthcare, models trained on relatively homogeneous datasets, and populations poorly-representative of underlying diversity, limits generalisability and risks biased AI-based decisions. Here, we describe the landscape of AI in clinical medicine to delineate population and data-source disparities.   Methods We performed a scoping review of clinical papers published in PubMed in 2019 using AI techniques. We assessed differences in dataset country source, clinical specialty, and author nationality, sex, and expertise. A manually tagged subsample of PubMed articles was used to train a model, leveraging transfer-learning techniques (building upon an existing BioBERT model) to predict eligibility for inclusion (original, human, clinical AI literature). Of all eligible articles, database country source and clinical specialty were manually labelled. A BioBERT-based model predicted first/last author expertise. Author nationality was determined using corresponding affiliated institution information using Entrez Direct. And first/last author sex was evaluated using the Gendarize.io API.   Results Our search yielded 30,576 articles, of which 7,314 (23.9%) were eligible for further analysis. Most databases came from the US (40.8%) and China (13.7%). Radiology was the most represented clinical specialty (40.4%), followed by pathology (9.1%). Authors were primarily from either China (24.0%) or the US (18.4%). First and last authors were predominately data experts (i.e., statisticians) (59.6% and 53.9% respectively) rather than clinicians. And the …",
        "year": 2022,
        "authors": "Leo Anthony Celi and Jacqueline Cellini and Marie-Laure Charpignon and Edward Christopher Dee and Franck Dernoncourt and Rene Eber and William Greig Mitchell and Lama Moukheiber and Julian Schirmer and Julia Situ and Joseph Paguio and Joel Park and Judy Gichoya Wawira and Seth Yao"
      },
      {
        "title": "Analysis of discrepancies between pulse oximetry and arterial oxygen saturation measurements by race and ethnicity and association with organ dysfunction and mortality",
        "abstract": "Discrepancies in oxygen saturation measured by pulse oximetry (Spo2), when compared with arterial oxygen saturation (Sao2) measured by arterial blood gas (ABG), may differentially affect patients according to race and ethnicity. However, the association of these disparities with health outcomes is unknown.To examine racial and ethnic discrepancies between Sao2and Spo2measures and their associations with clinical outcomes.This multicenter, retrospective, cross-sectional study included 3 publicly available electronic health record (EHR) databases (ie, the Electronic Intensive Care Unit–Clinical Research Database and Medical Information Mart for Intensive Care III and IV) as well as Emory Healthcare (2014-2021) and Grady Memorial (2014-2020) databases, spanning 215 hospitals and 382 ICUs. From 141 600 hospital encounters with recorded ABG …",
        "year": 2021,
        "authors": "An-Kwok Ian Wong and Marie Charpignon and Han Kim and Christopher Josef and Anne AH De Hond and Jhalique Jane Fojas and Azade Tabaie and Xiaoli Liu and Eduardo Mireles-Cabodevila and Leandro Carvalho and Rishikesan Kamaleswaran and RWMA Madushani and Lasith Adhikari and Andre L Holder and Ewout W Steyerberg and Timothy G Buchman and Mary E Lough and Leo Anthony Celi"
      },
      {
        "title": "Modeling between-population variation in COVID-19 dynamics in Hubei, Lombardy, and New York City",
        "abstract": "As the COVID-19 pandemic continues, formulating targeted policy interventions that are informed by differential severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) transmission dynamics will be of vital importance to national and regional governments. We develop an individual-level model for SARS-CoV-2 transmission that accounts for location-dependent distributions of age, household structure, and comorbidities. We use these distributions together with age-stratified contact matrices to instantiate specific models for Hubei, China; Lombardy, Italy; and New York City, United States. Using data on reported deaths to obtain a posterior distribution over unknown parameters, we infer differences in the progression of the epidemic in the three locations. We also examine the role of transmission due to particular age groups on total infections and deaths. The effect of limiting contacts by a particular age …",
        "year": 2020,
        "authors": "Bryan Wilder and Marie Charpignon and Jackson A Killian and Han-Ching Ou and Aditya Mate and Shahin Jabbari and Andrew Perrault and Angel N Desai and Milind Tambe and Maimuna S Majumder"
      }
    ],
    "vKlrdpEAAAAJ": [
      {
        "title": "Accurate, large minibatch sgd: Training imagenet in 1 hour",
        "abstract": "Deep learning thrives with large neural networks and large datasets. However, larger networks and larger datasets result in longer training times that impede research and development progress. Distributed synchronous SGD offers a potential solution to this problem by dividing SGD minibatches over a pool of parallel workers. Yet to make this scheme efficient, the per-worker workload must be large, which implies nontrivial growth in the SGD minibatch size. In this paper, we empirically show that on the ImageNet dataset large minibatches cause optimization difficulties, but when these are addressed the trained networks exhibit good generalization. Specifically, we show no loss of accuracy when training with large minibatch sizes up to 8192 images. To achieve this result, we adopt a hyper-parameter-free linear scaling rule for adjusting learning rates as a function of minibatch size and develop a new warmup scheme that overcomes optimization challenges early in training. With these simple techniques, our Caffe2-based system trains ResNet-50 with a minibatch size of 8192 on 256 GPUs in one hour, while matching small minibatch accuracy. Using commodity hardware, our implementation achieves ~90% scaling efficiency when moving from 8 to 256 GPUs. Our findings enable training visual recognition models on internet-scale data with high efficiency.",
        "year": 2017,
        "authors": "Priya Goyal and Piotr Dollár and Ross Girshick and Pieter Noordhuis and Lukasz Wesolowski and Aapo Kyrola and Andrew Tulloch and Yangqing Jia and Kaiming He"
      },
      {
        "title": "Distributed graphlab: A framework for machine learning in the cloud",
        "abstract": "While high-level data parallel frameworks, like MapReduce, simplify the design and implementation of large-scale data processing systems, they do not naturally or efficiently support many important data mining and machine learning algorithms and can lead to inefficient learning systems. To help fill this critical void, we introduced the GraphLab abstraction which naturally expresses asynchronous, dynamic, graph-parallel computation while ensuring data consistency and achieving a high degree of parallel performance in the shared-memory setting. In this paper, we extend the GraphLab framework to the substantially more challenging distributed setting while preserving strong data consistency guarantees. We develop graph based extensions to pipelined locking and data versioning to reduce network congestion and mitigate the effect of network latency. We also introduce fault tolerance to the GraphLab abstraction using the classic Chandy-Lamport snapshot algorithm and demonstrate how it can be easily implemented by exploiting the GraphLab abstraction itself. Finally, we evaluate our distributed implementation of the GraphLab abstraction on a large Amazon EC2 deployment and show 1-2 orders of magnitude performance gains over Hadoop-based implementations.",
        "year": 2012,
        "authors": "Yucheng Low and Joseph Gonzalez and Aapo Kyrola and Danny Bickson and Carlos Guestrin and Joseph M Hellerstein"
      },
      {
        "title": "{GraphChi}:{Large-Scale} graph computation on just a {PC}",
        "abstract": "Current systems for graph computation require a distributed computing cluster to handle very large real-world problems, such as analysis on social networks or the web graph. While distributed computational resources have become more accessible, developing distributed graph algorithms still remains challenging, especially to non-experts.",
        "year": 2012,
        "authors": "Aapo Kyrola and Guy Blelloch and Carlos Guestrin"
      }
    ],
    "_qr34PIAAAAJ": [
      {
        "title": "Working with machines: The impact of algorithmic and data-driven management on human workers",
        "abstract": "Software algorithms are changing how people work in an ever-growing number of fields, managing distributed human workers at a large scale. In these work settings, human jobs are assigned, optimized, and evaluated through algorithms and tracked data. We explore the impact of this algorithmic, data-driven management on human workers and work practices in the context of Uber and Lyft, new ridesharing services. Our findings from a qualitative study describe how drivers responded when algorithms assigned work, provided informational support, and evaluated their performance, and how drivers used online forums to socially make sense of the algorithm features. Implications and future work are discussed.",
        "year": 2015,
        "authors": "Min Kyung Lee and Daniel Kusbit and Evan Metsky and Laura Dabbish"
      },
      {
        "title": "Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management",
        "abstract": "Algorithms increasingly make managerial decisions that people used to make. Perceptions of algorithms, regardless of the algorithms' actual performance, can significantly influence their adoption, yet we do not fully understand how people perceive decisions made by algorithms as compared with decisions made by humans. To explore perceptions of algorithmic management, we conducted an online experiment using four managerial decisions that required either mechanical or human skills. We manipulated the decision-maker (algorithmic or human), and measured perceived fairness, trust, and emotional response. With the mechanical tasks, algorithmic and human-made decisions were perceived as equally fair and trustworthy and evoked similar emotions; however, human managers' fairness and trustworthiness were attributed to the manager's authority, whereas algorithms' fairness and trustworthiness were …",
        "year": 2018,
        "authors": "Min Kyung Lee"
      },
      {
        "title": "Principles of smart home control",
        "abstract": "Seeking to be sensitive to users, smart home researchers have focused on the concept of control. They attempt to allow users to gain control over their lives by framing the problem as one of end-user programming. But families are not users as we typically conceive them, and a large body of ethnographic research shows how their activities and routines do not map well to programming tasks. End-user programming ultimately provides control of devices. But families want more control of their lives. In this paper, we explore this disconnect. Using grounded contextual fieldwork with dual-income families, we describe the control that families want, and suggest seven design principles that will help end-user programming systems deliver that control.",
        "year": 2006,
        "authors": "Scott Davidoff and Min Kyung Lee and Charles Yiu and John Zimmerman and Anind K Dey"
      }
    ],
    "-WZcuuwAAAAJ": [
      {
        "title": "Open X-Embodiment: Robotic Learning Datasets and RT-X Models : Open X-Embodiment Collaboration0",
        "abstract": "Large, high-capacity models trained on diverse datasets have shown remarkable successes on efficiently tackling downstream applications. In domains from NLP to Computer Vision, this has led to a consolidation of pretrained models, with general pretrained backbones serving as a starting point for many applications. Can such a consolidation happen in robotics? Conventionally, robotic learning methods train a separate model for every application, every robot, and even every environment. Can we instead train \"generalist\" X-robot policy that can be adapted efficiently to new robots, tasks, and environments? In this paper, we provide datasets in standardized data formats and models to make it possible to explore this possibility in the context of robotic manipulation, alongside experimental results that provide an example of effective X-robot policies. We assemble a dataset from 22 different robots collected through …",
        "year": 2024,
        "authors": "Abby O’Neill and Abdul Rehman and Abhiram Maddukuri and Abhishek Gupta and Abhishek Padalkar and Abraham Lee and Acorn Pooley and Agrim Gupta and Ajay Mandlekar and Ajinkya Jain and Albert Tung and Alex Bewley and Alex Herzog and Alex Irpan and Alexander Khazatsky and Anant Rai and Anchit Gupta and Andrew Wang and Anikait Singh and Animesh Garg and Aniruddha Kembhavi and Annie Xie and Anthony Brohan and Antonin Raffin and Archit Sharma and Arefeh Yavary and Arhan Jain and Ashwin Balakrishna and Ayzaan Wahid and Ben Burgess-Limerick and Beomjoon Kim and Bernhard Schölkopf and Blake Wulfe and Brian Ichter and Cewu Lu and Charles Xu and Charlotte Le and Chelsea Finn and Chen Wang and Chenfeng Xu and Cheng Chi and Chenguang Huang and Christine Chan and Christopher Agia and Chuer Pan and Chuyuan Fu and Coline Devin and Danfei Xu and Daniel Morton and Danny Driess and Daphne Chen and Deepak Pathak and Dhruv Shah and Dieter Büchler and Dinesh Jayaraman and Dmitry Kalashnikov and Dorsa Sadigh and Edward Johns and Ethan Foster and Fangchen Liu and Federico Ceola and Fei Xia and Feiyu Zhao and Freek Stulp and Gaoyue Zhou and Gaurav S Sukhatme and Gautam Salhotra and Ge Yan and Gilbert Feng and Giulio Schiavi and Glen Berseth and Gregory Kahn and Guanzhi Wang and Hao Su and Hao-Shu Fang and Haochen Shi and Henghui Bao and Heni Ben Amor and Henrik I Christensen and Hiroki Furuta and Homer Walke and Hongjie Fang and Huy Ha and Igor Mordatch and Ilija Radosavovic and Isabel Leal and Jacky Liang and Jad Abou-Chakra and Jaehyung Kim and Jaimyn Drake and Jan Peters and Jan Schneider and Jasmine Hsu and Jeannette Bohg and Jeffrey Bingham and Jeffrey Wu and Jensen Gao and Jiaheng Hu and Jiajun Wu and Jialin Wu and Jiankai Sun and Jianlan Luo and Jiayuan Gu and Jie Tan and Jihoon Oh and Jimmy Wu and Jingpei Lu and Jingyun Yang and Jitendra Malik and João Silvério and Joey Hejna and Jonathan Booher and Jonathan Tompson and Jonathan Yang and Jordi Salvador and Joseph J Lim and Junhyek Han and Kaiyuan Wang and Kanishka Rao and Karl Pertsch and Karol Hausman and Keegan Go and Keerthana Gopalakrishnan and Ken Goldberg and Kendra Byrne and Kenneth Oslund and Kento Kawaharazuka and Kevin Black and Kevin Lin and Kevin Zhang and Kiana Ehsani and Kiran Lekkala and Kirsty Ellis and Krishan Rana and Krishnan Srinivasan and Kuan Fang and Kunal Pratap Singh and Kuo-Hao Zeng and Kyle Hatch and Kyle Hsu and Laurent Itti and Lawrence Yunliang Chen and Lerrel Pinto and Li Fei-Fei and Liam Tan and Linxi Jim Fan and Lionel Ott and Lisa Lee and Luca Weihs and Magnum Chen"
      },
      {
        "title": "Deeploco: Dynamic locomotion skills using hierarchical deep reinforcement learning",
        "abstract": "Learning physics-based locomotion skills is a difficult problem, leading to solutions that typically exploit prior knowledge of various forms. In this paper we aim to learn a variety of environment-aware locomotion skills with a limited amount of prior knowledge. We adopt a two-level hierarchical control framework. First, low-level controllers are learned that operate at a fine timescale and which achieve robust walking gaits that satisfy stepping-target and style objectives. Second, high-level controllers are then learned which plan at the timescale of steps by invoking desired step targets for the low-level controller. The high-level controller makes decisions directly based on high-dimensional inputs, including terrain maps or other suitable representations of the surroundings. Both levels of the control policy are trained using deep reinforcement learning. Results are demonstrated on a simulated 3D biped. Low-level …",
        "year": 2017,
        "authors": "Xue Bin Peng and Glen Berseth and KangKang Yin and Michiel Van De Panne"
      },
      {
        "title": "Terrain-adaptive locomotion skills using deep reinforcement learning",
        "abstract": "Reinforcement learning offers a promising methodology for developing skills for simulated characters, but typically requires working with sparse hand-crafted features. Building on recent progress in deep reinforcement learning (DeepRL), we introduce a mixture of actor-critic experts (MACE) approach that learns terrain-adaptive dynamic locomotion skills using high-dimensional state and terrain descriptions as input, and parameterized leaps or steps as output actions. MACE learns more quickly than a single actor-critic approach and results in actor-critic experts that exhibit specialization. Additional elements of our solution that contribute towards efficient learning include Boltzmann exploration and the use of initial actor biases to encourage specialization. Results are demonstrated for multiple planar characters and terrain classes.",
        "year": 2016,
        "authors": "Xue Bin Peng and Glen Berseth and Michiel Van de Panne"
      }
    ],
    "rIjeeRsAAAAJ": [
      {
        "title": "ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection",
        "abstract": "Toxic language detection systems often falsely flag text that contains minority group mentions as toxic, as those groups are often the targets of online hate. Such over-reliance on spurious correlations also causes systems to struggle with detecting implicitly toxic language. To help mitigate these issues, we create ToxiGen, a new large-scale and machine-generated dataset of 274k toxic and benign statements about 13 minority groups. We develop a demonstration-based prompting framework and an adversarial classifier-in-the-loop decoding method to generate subtly toxic and benign text with a massive pretrained language model. Controlling machine generation in this way allows ToxiGen to cover implicitly toxic text at a larger scale, and about more demographic groups, than previous resources of human-written text. We conduct a human evaluation on a challenging subset of ToxiGen and find that annotators struggle to distinguish machine-generated text from human-written language. We also find that 94.5% of toxic examples are labeled as hate speech by human annotators. Using three publicly-available datasets, we show that finetuning a toxicity classifier on our data improves its performance on human-written data substantially. We also demonstrate that ToxiGen can be used to fight machine-generated toxicity as finetuning improves the classifier significantly on our evaluation subset. Our code and data can be found at https://github.com/microsoft/ToxiGen.",
        "year": 2022,
        "authors": "Thomas Hartvigsen and Saadia Gabriel and Hamid Palangi and Maarten Sap and Dipankar Ray and Ece Kamar"
      },
      {
        "title": "Aging with GRACE: Lifelong Model Editing with Discrete Key-Value Adaptors",
        "abstract": "Deployed language models decay over time due to shifting inputs, changing user needs, or emergent world-knowledge gaps. When such problems are identified, we want to make targeted edits while avoiding expensive retraining. However, current model editors, which modify such behaviors of pre-trained models, degrade model performance quickly across multiple, sequential edits. We propose GRACE, a\\textit {lifelong} model editing method, which implements spot-fixes on streaming errors of a deployed model, ensuring minimal impact on unrelated inputs. GRACE writes new mappings into a pre-trained model's latent space, creating a discrete, local codebook of edits without altering model weights. This is the first method enabling thousands of sequential edits using only streaming errors. Our experiments on T5, BERT, and GPT models show GRACE's state-of-the-art performance in making and retaining edits, while generalizing to unseen inputs. Our code is available at github. com/thartvigsen/grace.",
        "year": 2023,
        "authors": "Thomas Hartvigsen and Swami Sankaranarayanan and Hamid Palangi and Yoon Kim and Marzyeh Ghassemi"
      },
      {
        "title": "Are Language Models Actually Useful for Time Series Forecasting?",
        "abstract": "Large language models (LLMs) are being applied to time series forecasting. But are language models actually useful for time series? In a series of ablation studies on three recent and popular LLM-based time series forecasting methods, we find that removing the LLM component or replacing it with a basic attention layer does not degrade forecasting performance---in most cases, the results even improve! We also find that despite their significant computational cost, pretrained LLMs do no better than models trained from scratch, do not represent the sequential dependencies in time series, and do not assist in few-shot settings. Additionally, we explore time series encoders and find that patching and attention structures perform similarly to LLM-based forecasters. All resources needed to reproduce our work are available: https://github. com/BennyTMT/LLMsForTimeSeries.",
        "year": 2024,
        "authors": "Mingtian Tan and Mike A Merrill and Vinayak Gupta and Tim Althoff and Thomas Hartvigsen"
      }
    ],
    "adnTgaAAAAAJ": [
      {
        "title": "Equality of opportunity in supervised learning",
        "abstract": "We propose a criterion for discrimination against a specified sensitive attribute in supervised learning, where the goal is to predict some target based on available features. Assuming data about the predictor, target, and membership in the protected group are available, we show how to optimally adjust any learned predictor so as to remove discrimination according to our definition. Our framework also improves incentives by shifting the cost of poor classification from disadvantaged groups to the decision maker, who can respond by improving the classification accuracy.",
        "year": 2016,
        "authors": "Moritz Hardt and Eric Price and Nati Srebro"
      },
      {
        "title": "Understanding deep learning requires rethinking generalization",
        "abstract": "Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models.",
        "year": 2017,
        "authors": "Chiyuan Zhang and Samy Bengio and Moritz Hardt and Benjamin Recht and Oriol Vinyals"
      },
      {
        "title": "Fairness through awareness",
        "abstract": "We study fairness in classification, where individuals are classified, e.g., admitted to a university, and the goal is to prevent discrimination against individuals based on their membership in some group, while maintaining utility for the classifier (the university). The main conceptual contribution of this paper is a framework for fair classification comprising (1) a (hypothetical) task-specific metric for determining the degree to which individuals are similar with respect to the classification task at hand; (2) an algorithm for maximizing utility subject to the fairness constraint, that similar individuals are treated similarly. We also present an adaptation of our approach to achieve the complementary goal of \"fair affirmative action,\" which guarantees statistical parity (i.e., the demographics of the set of individuals receiving any classification are the same as the demographics of the underlying population), while treating similar …",
        "year": 2012,
        "authors": "Cynthia Dwork and Moritz Hardt and Toniann Pitassi and Omer Reingold and Richard Zemel"
      }
    ],
    "kXB8FBoAAAAJ": [
      {
        "title": "One-shot learning for semantic segmentation",
        "abstract": "Low-shot learning methods for image classification support learning from sparse data. We extend these techniques to support dense semantic image segmentation. Specifically, we train a network that, given a small set of annotated images, produces parameters for a Fully Convolutional Network (FCN). We use this FCN to perform dense pixel-level prediction on a test image for the new semantic class. Our architecture shows a 25% relative meanIoU improvement compared to the best baseline methods for one-shot segmentation on unseen classes in the PASCAL VOC 2012 dataset and is at least 3 times faster.",
        "year": 2017,
        "authors": "Amirreza Shaban and Shray Bansal and Zhen Liu and Irfan Essa and Byron Boots"
      },
      {
        "title": "Information theoretic MPC for model-based reinforcement learning",
        "abstract": "We introduce an information theoretic model predictive control (MPC) algorithm capable of handling complex cost criteria and general nonlinear dynamics. The generality of the approach makes it possible to use multi-layer neural networks as dynamics models, which we incorporate into our MPC algorithm in order to solve model-based reinforcement learning tasks. We test the algorithm in simulation on a cart-pole swing up and quadrotor navigation task, as well as on actual hardware in an aggressive driving task. Empirical results demonstrate that the algorithm is capable of achieving a high level of performance and does so only utilizing data collected from the system.",
        "year": 2017,
        "authors": "Grady Williams and Nolan Wagener and Brian Goldfain and Paul Drews and James M Rehg and Byron Boots and Evangelos A Theodorou"
      },
      {
        "title": "Differentiable mpc for end-to-end planning and control",
        "abstract": "We present foundations for using Model Predictive Control (MPC) as a differentiable policy class for reinforcement learning. This provides one way of leveraging and combining the advantages of model-free and model-based approaches. Specifically, we differentiate through MPC by using the KKT conditions of the convex approximation at a fixed point of the controller. Using this strategy, we are able to learn the cost and dynamics of a controller via end-to-end learning. Our experiments focus on imitation learning in the pendulum and cartpole domains, where we learn the cost and dynamics terms of an MPC policy class. We show that our MPC policies are significantly more data-efficient than a generic neural network and that our method is superior to traditional system identification in a setting where the expert is unrealizable.",
        "year": 2018,
        "authors": "Brandon Amos and Ivan Jimenez and Jacob Sacks and Byron Boots and J Zico Kolter"
      }
    ],
    "UWZA0v4AAAAJ": [
      {
        "title": "Animating human athletics",
        "abstract": "This paper describes algorithms for the animation of men and women performing three dynamic athletic behaviors: running, bicycling, and vaulting. We animate these behaviors using control algorithms that cause a physically realistic model to perform the desired maneuver. For example, control algorithms allow the simulated humans to maintain balance while moving their arms, to run or bicycle at a variety of speeds, and to perform a handspring vault. Algorithms for group behaviors allow a number of simulated bicyclists to ride as a group while avoiding simple patterns of obstacles. We add secondary motion to the animations with springmass simulations of clothing driven by the rigid-body motion of the simulated human. For each simulation, we compare the computed motion to that of humans performing similar maneuvers both qualitatively through the comparison of real and simulated video images and …",
        "year": 1995,
        "authors": "Jessica K Hodgins and Wayne L Wooten and David C Brogan and James F O'Brien"
      },
      {
        "title": "Shape transformation using variational implicit functions",
        "abstract": "Traditionally, shape transformation using implicit functions is performed in two distinct steps: 1) creating two implicit functions, and 2) interpolating between these two functions. We present a new shape transformation method that combines these two tasks into a single step. We create a transformation between two N-dimensional objects by casting this as a scattered data interpolation problem in N + 1 dimensions. For the case of 2D shapes, we place all of our data constraints within two planes, one for each shape. These planes are placed parallel to one another in 3D. Zero-valued constraints specify the locations of shape boundaries and positive-valued constraints are placed along the normal direction in towards the center of the shape. We then invoke a variational interpolation technique (the 3D generalization of thin-plate interpolation), and this yields a single implicit function in 3D. Intermediate shapes are …",
        "year": 2005,
        "authors": "Greg Turk and James F O'brien"
      },
      {
        "title": "Graphical modeling and animation of brittle fracture",
        "abstract": "In this paper, we augment existing techniques for simulating flexible objects to include models for crack initiation and propagation in three-dimensional volumes. By analyzing the stress tensors computed over a finite element model, the simulation determines where cracks should initiate and in what directions they should propagate. We demonstrate our results with animations of breaking bowls, cracking walls, and objects that fracture when they collide. By varying the shape of the objects, the material properties, and the initial conditions of the simulations, we can create strikingly different effects ranging from a wall that shatters when it is hit by a wrecking ball to a bowl that breaks in two when it is dropped on edge.",
        "year": 1999,
        "authors": "James F O'brien and Jessica K Hodgins"
      }
    ],
    "UAwKvEsAAAAJ": [
      {
        "title": "Finding scientific topics",
        "abstract": "A first step in identifying the content of a document is determining which topics that document addresses. We describe a generative model for documents, introduced by Blei, Ng, and Jordan [Blei, D. M., Ng, A. Y. & Jordan, M. I. (2003) J. Machine Learn. Res. 3, 993-1022], in which each document is generated by choosing a distribution over topics and then choosing each word in the document from a topic selected according to this distribution. We then present a Markov chain Monte Carlo algorithm for inference in this model. We use this algorithm to analyze abstracts from PNAS by using Bayesian model selection to establish the number of topics. We show that the extracted topics capture meaningful structure in the data, consistent with the class designations provided by the authors of the articles, and outline further applications of this analysis, including identifying “hot topics” by examining temporal dynamics and …",
        "year": 2004,
        "authors": "Thomas L Griffiths and Mark Steyvers"
      },
      {
        "title": "Tree of thoughts: Deliberate problem solving with large language models",
        "abstract": "Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models’ problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\\% of tasks, our method achieved a success rate of 74\\%. Code repo with all prompts: https://github. com/princeton-nlp/tree-of-thought-llm.",
        "year": 2023,
        "authors": "Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Tom Griffiths and Yuan Cao and Karthik Narasimhan"
      },
      {
        "title": "Probabilistic topic models",
        "abstract": "Many chapters in this book illustrate that applying a statistical method such as latent semantic analysis (LSA; Landauer & Dumais, 1997; Landauer, Foltz, & Laham, 1998) to large databases can yield insight into human cognition. The LSA approach makes three claims: that semantic information can be derived from a word-document co-occurrence matrix; that dimensionality reduction is an essential part of this derivation; and that words and documents can be represented as points in Euclidean space. This chapter pursues an approach that is consistent with the first two of these claims, but differs in the third, describing a class of statistical models in which the semantic properties of words and documents are expressed in terms of probabilistic topics.",
        "year": 2007,
        "authors": "Mark Steyvers and Tom Griffiths"
      }
    ],
    "UFlWdvUAAAAJ": [
      {
        "title": "The many faces of robustness: A critical analysis of out-of-distribution generalization",
        "abstract": "We introduce four new real-world distribution shift datasets consisting of changes in image style, image blurriness, geographic location, camera operation, and more. With our new datasets, we take stock of previously proposed methods for improving out-of-distribution robustness and put them to the test. We find that using larger models and artificial data augmentations can improve robustness on real-world distribution shifts, contrary to claims in prior work. We find improvements in artificial robustness benchmarks can transfer to real-world distribution shifts, contrary to claims in prior work. Motivated by our observation that data augmentations can help with real-world distribution shifts, we also introduce a new data augmentation method which advances the state-of-the-art and outperforms models pretrained with 1000x more labeled data. Overall we find that some methods consistently help with distribution shifts in texture and local image statistics, but these methods do not help with some other distribution shifts like geographic changes. Our results show that future research must study multiple distribution shifts simultaneously, as we demonstrate that no evaluated method consistently improves robustness.",
        "year": 2021,
        "authors": "Dan Hendrycks and Steven Basart and Norman Mu and Saurav Kadavath and Frank Wang and Evan Dorundo and Rahul Desai and Tyler Zhu and Samyak Parajuli and Mike Guo and Dawn Song and Jacob Steinhardt and Justin Gilmer"
      },
      {
        "title": "Slip: Self-supervision meets language-image pre-training",
        "abstract": "Recent work has shown that self-supervised pre-training leads to improvements over supervised learning on challenging visual recognition tasks. CLIP, an exciting new approach to learning with language supervision, demonstrates promising performance on a wide variety of benchmarks. In this work, we explore whether self-supervised learning can aid in the use of language supervision for visual representation learning with Vision Transformers. We introduce SLIP, a multi-task learning framework for combining self-supervised learning and CLIP pre-training. After pre-training, we thoroughly evaluate representation quality and compare performance to both CLIP and self-supervised learning under three distinct settings: zero-shot transfer, linear classification, and end-to-end finetuning. Across ImageNet and a battery of additional datasets, we find that SLIP improves accuracy by a large margin. We validate our …",
        "year": 2022,
        "authors": "Norman Mu and Alexander Kirillov and David Wagner and Saining Xie"
      }
    ],
    "3Y4egcYAAAAJ": [
      {
        "title": "Model-based reinforcement learning for atari",
        "abstract": "Model-free reinforcement learning (RL) can be used to learn effective policies for complex tasks, such as Atari games, even from image observations. However, this typically requires very large amounts of interaction -- substantially more, in fact, than a human would need to learn the same games. How can people learn so quickly? Part of the answer may be that people can learn how the game works and predict which actions will lead to desirable outcomes. In this paper, we explore how video prediction models can similarly enable agents to solve Atari games with fewer interactions than model-free methods. We describe Simulated Policy Learning (SimPLe), a complete model-based deep RL algorithm based on video prediction models and present a comparison of several model architectures, including a novel architecture that yields the best results in our setting. Our experiments evaluate SimPLe on a range of Atari games in low data regime of 100k interactions between the agent and the environment, which corresponds to two hours of real-time play. In most games SimPLe outperforms state-of-the-art model-free algorithms, in some games by over an order of magnitude.",
        "year": 2019,
        "authors": "Lukasz Kaiser and Mohammad Babaeizadeh and Piotr Milos and Blazej Osinski and Roy H Campbell and Konrad Czechowski and Dumitru Erhan and Chelsea Finn and Piotr Kozakowski and Sergey Levine and Afroz Mohiuddin and Ryan Sepassi and George Tucker and Henryk Michalewski"
      },
      {
        "title": "Stochastic Variational Video Prediction",
        "abstract": "Predicting the future in real-world settings, particularly from raw sensory observations such as images, is exceptionally challenging. Real-world events can be stochastic and unpredictable, and the high dimensionality and complexity of natural images requires the predictive model to build an intricate understanding of the natural world. Many existing methods tackle this problem by making simplifying assumptions about the environment. One common assumption is that the outcome is deterministic and there is only one plausible future. This can lead to low-quality predictions in real-world settings with stochastic dynamics. In this paper, we develop a stochastic variational video prediction (SV2P) method that predicts a different possible future for each sample of its latent variables. To the best of our knowledge, our model is the first to provide effective stochastic multi-frame prediction for real-world video. We demonstrate the capability of the proposed method in predicting detailed future frames of videos on multiple real-world datasets, both action-free and action-conditioned. We find that our proposed method produces substantially improved video predictions when compared to the same model without stochasticity, and to other stochastic video prediction methods. Our SV2P implementation will be open sourced upon publication.",
        "year": 2018,
        "authors": "Mohammad Babaeizadeh and Chelsea Finn and Dumitru Erhan and Roy H Campbell and Sergey Levine"
      },
      {
        "title": "Phenaki: Variable length video generation from open domain textual description",
        "abstract": "We present Phenaki, a model capable of realistic video synthesis, given a sequence of textual prompts. Generating videos from text is particularly challenging due to the computational cost, limited quantities of high quality text-video data and variable length of videos. To address these issues, we introduce a new model for learning video representation which compresses the video to a small representation of discrete tokens. This tokenizer uses causal attention in time, which allows it to work with variable-length videos. To generate video tokens from text we are using a bidirectional masked transformer conditioned on pre-computed text tokens. The generated video tokens are subsequently de-tokenized to create the actual video. To address data issues, we demonstrate how joint training on a large corpus of image-text pairs as well as a smaller number of video-text examples can result in generalization beyond what is available in the video datasets. Compared to the previous video generation methods, Phenaki can generate arbitrary long videos conditioned on a sequence of prompts (i.e. time variable text or a story) in open domain. To the best of our knowledge, this is the first time a paper studies generating videos from time variable prompts. In addition, compared to the per-frame baselines, the proposed video encoder-decoder computes fewer tokens per video but results in better spatio-temporal consistency.",
        "year": 2022,
        "authors": "Ruben Villegas and Mohammad Babaeizadeh and Pieter-Jan Kindermans and Hernan Moraldo and Han Zhang and Mohammad Taghi Saffar and Santiago Castro and Julius Kunze and Dumitru Erhan"
      }
    ],
    "eml8HfQAAAAJ": [
      {
        "title": "Translating videos to natural language using deep recurrent neural networks",
        "abstract": "Solving the visual symbol grounding problem has long been a goal of artificial intelligence. The field appears to be advancing closer to this goal with recent breakthroughs in deep learning for natural language grounding in static images. In this paper, we propose to translate videos directly to sentences using a unified deep neural network with both convolutional and recurrent structure. Described video datasets are scarce, and most existing methods have been applied to toy domains with a small vocabulary of possible words. By transferring knowledge from 1.2M+ images with category labels and 100,000+ images with captions, our method is able to create sentence descriptions of open-domain videos with large vocabularies. We compare our approach with recent work using language generation metrics, subject, verb, and object prediction accuracy, and a human evaluation.",
        "year": 2014,
        "authors": "Subhashini Venugopalan and Huijuan Xu and Jeff Donahue and Marcus Rohrbach and Raymond Mooney and Kate Saenko"
      },
      {
        "title": "Ask, attend and answer: Exploring question-guided spatial attention for visual question answering",
        "abstract": "We address the problem of Visual Question Answering (VQA), which requires joint image and language understanding to answer a question about a given photograph. Recent approaches have applied deep image captioning methods based on convolutional-recurrent networks to this problem, but have failed to model spatial inference. To remedy this, we propose a model we call the Spatial Memory Network and apply it to the VQA task. Memory networks are recurrent neural networks with an explicit attention mechanism that selects certain parts of the information stored in memory. Our Spatial Memory Network stores neuron activations from different spatial regions of the image in its memory, and uses attention to choose regions relevant for computing the answer. We propose a novel question-guided spatial attention architecture that looks for regions relevant to either individual words or the entire …",
        "year": 2016,
        "authors": "Huijuan Xu and Kate Saenko"
      },
      {
        "title": "R-C3D: Region convolutional 3d network for temporal activity detection",
        "abstract": "We address the problem of activity detection in continuous, untrimmed video streams. This is a difficult task that requires extracting meaningful spatio-temporal features to capture activities, accurately localizing the start and end times of each activity. We introduce a new model, Region Convolutional 3D Network (R-C3D), which encodes the video streams using a three-dimensional fully convolutional network, then generates candidate temporal regions containing activities, and finally classifies selected regions into specific activities. Computation is saved due to the sharing of convolutional features between the proposal and the classification pipelines. The entire model is trained end-to-end with jointly optimized localization and classification losses. R-C3D is faster than existing methods (569 frames per second on a single Titan X Maxwell GPU) and achieves state-of-the-art results on THUMOS'14. We further demonstrate that our model is a general activity detection framework that does not rely on assumptions about particular dataset properties by evaluating our approach on ActivityNet and Charades. Our code is available at http://ai. bu. edu/r-c3d/.",
        "year": 2017,
        "authors": "Huijuan Xu and Abir Das and Kate Saenko"
      }
    ],
    "wy0FA1cAAAAJ": [
      {
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models",
        "abstract": "DSpace at KOASAS: Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nKOASAS menu About KOASAS KAIST Library 검색 Advanced Search KOASAS About \nKOASAS Open Access Policy Browse Communities & Collections Researchers at KAIST Titles \nSubject By Date rss_1.0 rss_2.0 atom_1.0 sherpa SEARCH DSpace at KOASAS College of \nEngineering(공과대학)Kim Jaechul Graduate School of AI(김재철AI대학원)AI-Conference \nPapers(학술대회논문) Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nCited 0 time in webofscience Cited 0 time in scopus Hit : 2 Download : 0 Export DC(XML) Excel \nLim, Joseph Jaewhanresearcher Publisher IEEE Issue Date 2024-05-15 Citation IEEE \nInternational Conference on Robotics and Automation URI http://hdl.handle.net/10203/326144 \nAppears in Collection AI-Conference Papers(학술대회논문) Files in This Item There are no files …",
        "year": 2024,
        "authors": "Joseph Jaewhan Lim"
      },
      {
        "title": "Providing {SLOs} for {Resource-Harvesting}{VMs} in cloud platforms",
        "abstract": "Cloud providers rent the resources they do not allocate as evictable virtual machines (VMs), like spot instances. In this paper, we first characterize the unallocated resources in Microsoft Azure, and show that they are plenty but may vary widely over time and across servers. Based on the characterization, we propose a new class of VM, called Harvest VM, to harvest and monetize the unallocated resources. A Harvest VM is more flexible and efficient than a spot instance, because it grows and shrinks according to the amount of unallocated resources at its underlying server; it is only evicted/killed when the provider needs its minimum set of resources. Next, we create models that predict the availability of the unallocated resources for Harvest VM deployments. Based on these predictions, we provide Service Level Objectives (SLOs) for the survival rate (eg, 65% of the Harvest VMs will survive more than a week) and the average number of cores that can be harvested. Our short-term predictions have an average error under 2% and less than 6% for longer terms. We also extend a popular cluster scheduling framework to leverage the harvested resources. Using our SLOs and framework, we can offset the rare evictions with extra harvested cores and achieve the same computational power as regular-priority VMs, but at 91% lower cost. Finally, we outline lessons and results from running Harvest VMs and our framework in production.",
        "year": 2020,
        "authors": "Pradeep Ambati and Íñigo Goiri and Felipe Frujeri and Alper Gun and Ke Wang and Brian Dolan and Brian Corell and Sekhar Pasupuleti and Thomas Moscibroda and Sameh Elnikety and Marcus Fontoura and Ricardo Bianchini"
      },
      {
        "title": "Toward ml-centric cloud platforms",
        "abstract": "Exploring the opportunities to use ML, the possible designs, and our experience with Microsoft Azure.",
        "year": 2020,
        "authors": "Ricardo Bianchini and Marcus Fontoura and Eli Cortez and Anand Bonde and Alexandre Muzio and Ana-Maria Constantin and Thomas Moscibroda and Gabriel Magalhaes and Girish Bablani and Mark Russinovich"
      }
    ],
    "qwCO618AAAAJ": [
      {
        "title": "Designing quantum memories with embedded control: photonic circuits for autonomous quantum error correction",
        "abstract": "We propose an approach to quantum error correction based on coding and continuous syndrome readout via scattering of coherent probe fields, in which the usual steps of measurement and discrete restoration are replaced by direct physical processing of the probe beams and coherent feedback to the register qubits. Our approach is well matched to physical implementations that feature solid-state qubits embedded in planar electromagnetic circuits, providing an autonomous and “on-chip” quantum memory design requiring no external clocking or control logic.",
        "year": 2010,
        "authors": "Joseph Kerckhoff and Hendra I Nurdin and Dmitri S Pavlichin and Hideo Mabuchi"
      },
      {
        "title": "Neural circuits mediate electrosensory behavior in Caenorhabditis elegans",
        "abstract": "The nematode Caenorhabditis elegans deliberately crawls toward the negative pole in an electric field. By quantifying the movements of individual worms navigating electric fields, we show that C. elegans prefers to crawl at specific angles to the direction of the electric field in persistent periods of forward movement and that the preferred angle is proportional to field strength. C. elegans reorients itself in response to time-varying electric fields by using sudden turns and reversals, standard reorientation maneuvers that C. elegans uses during other modes of motile behavior. Mutation or laser ablation that disrupts the structure and function of amphid sensory neurons also disrupts electrosensory behavior. By imaging intracellular calcium dynamics among the amphid sensory neurons of immobilized worms, we show that specific amphid sensory neurons are sensitive to the direction and strength of electric fields. We …",
        "year": 2007,
        "authors": "Christopher V Gabel and Harrison Gabel and Dmitri Pavlichin and Albert Kao and Damon A Clark and Aravinthan DT Samuel"
      },
      {
        "title": "Single Molecule Analysis Research Tool (SMART): an integrated approach for analyzing single molecule data",
        "abstract": "Single molecule studies have expanded rapidly over the past decade and have the ability to provide an unprecedented level of understanding of biological systems. A common challenge upon introduction of novel, data-rich approaches is the management, processing, and analysis of the complex data sets that are generated. We provide a standardized approach for analyzing these data in the freely available software package SMART: Single Molecule Analysis Research Tool. SMART provides a format for organizing and easily accessing single molecule data, a general hidden Markov modeling algorithm for fitting an array of possible models specified by the user, a standardized data structure and graphical user interfaces to streamline the analysis and visualization of data. This approach guides experimental design, facilitating acquisition of the maximal information from single molecule experiments. SMART also provides a standardized format to allow dissemination of single molecule data and transparency in the analysis of reported data.",
        "year": 2012,
        "authors": "Max Greenfeld and Dmitri S Pavlichin and Hideo Mabuchi and Daniel Herschlag"
      }
    ],
    "DMTuJzAAAAAJ": [
      {
        "title": "Scalable deep reinforcement learning for vision-based robotic manipulation",
        "abstract": "In this paper, we study the problem of learning vision-based dynamic manipulation skills using a scalable reinforcement learning approach. We study this problem in the context of grasping, a longstanding challenge in robotic manipulation. In contrast to static learning behaviors that choose a grasp point and then execute the desired grasp, our method enables closed-loop vision-based control, whereby the robot continuously updates its grasp strategy based on the most recent observations to optimize long-horizon grasp success. To that end, we introduce QT-Opt, a scalable self-supervised vision-based reinforcement learning framework that can leverage over 580k real-world grasp attempts to train a deep neural network Q-function with over 1.2 M parameters to perform closed-loop, real-world grasping that generalizes to 96% grasp success on unseen objects. Aside from attaining a very high success rate, our method exhibits behaviors that are quite distinct from more standard grasping systems: using only RGB vision-based perception from an over-the-shoulder camera, our method automatically learns regrasping strategies, probes objects to find the most effective grasps, learns to reposition objects and perform other non-prehensile pre-grasp manipulations, and responds dynamically to disturbances and perturbations.",
        "year": 2018,
        "authors": "Dmitry Kalashnikov and Alex Irpan and Peter Pastor and Julian Ibarz and Alexander Herzog and Eric Jang and Deirdre Quillen and Ethan Holly and Mrinal Kalakrishnan and Vincent Vanhoucke and Sergey Levine"
      },
      {
        "title": "STOMP: Stochastic trajectory optimization for motion planning",
        "abstract": "We present a new approach to motion planning using a stochastic trajectory optimization framework. The approach relies on generating noisy trajectories to explore the space around an initial (possibly infeasible) trajectory, which are then combined to produced an updated trajectory with lower cost. A cost function based on a combination of obstacle and smoothness cost is optimized in each iteration. No gradient information is required for the particular optimization algorithm that we use and so general costs for which derivatives may not be available (e.g. costs corresponding to constraints and motor torques) can be included in the cost function. We demonstrate the approach both in simulation and on a mobile manipulation system for unconstrained and constrained tasks. We experimentally show that the stochastic nature of STOMP allows it to overcome local minima that gradient-based methods like CHOMP can …",
        "year": 2011,
        "authors": "Mrinal Kalakrishnan and Sachin Chitta and Evangelos Theodorou and Peter Pastor and Stefan Schaal"
      },
      {
        "title": "Using simulation and domain adaptation to improve efficiency of deep robotic grasping",
        "abstract": "Instrumenting and collecting annotated visual grasping datasets to train modern machine learning algorithms can be extremely time-consuming and expensive. An appealing alternative is to use off-the-shelf simulators to render synthetic data for which ground-truth annotations are generated automatically. Unfortunately, models trained purely on simulated data often fail to generalize to the real world. We study how randomized simulated environments and domain adaptation methods can be extended to train a grasping system to grasp novel objects from raw monocular RGB images. We extensively evaluate our approaches with a total of more than 25,000 physical test grasps, studying a range of simulation conditions and domain adaptation methods, including a novel extension of pixel-level domain adaptation that we term the GraspGAN. We show that, by using synthetic data and domain adaptation, we are able to …",
        "year": 2018,
        "authors": "Konstantinos Bousmalis and Alex Irpan and Paul Wohlhart and Yunfei Bai and Matthew Kelcey and Mrinal Kalakrishnan and Laura Downs and Julian Ibarz and Peter Pastor and Kurt Konolige and Sergey Levine and Vincent Vanhoucke"
      }
    ],
    "b0ehAgIAAAAJ": [
      {
        "title": "Identifying the best machine learning algorithms for brain tumor segmentation, progression assessment, and overall survival prediction in the BRATS challenge",
        "abstract": "Gliomas are the most common primary brain malignancies, with different degrees of aggressiveness, variable prognosis and various heterogeneous histologic sub-regions, i.e., peritumoral edematous/invaded tissue, necrotic core, active and non-enhancing core. This intrinsic heterogeneity is also portrayed in their radio-phenotype, as their sub-regions are depicted by varying intensity profiles disseminated across multi-parametric magnetic resonance imaging (mpMRI) scans, reflecting varying biological properties. Their heterogeneous shape, extent, and location are some of the factors that make these tumors difficult to resect, and in some cases inoperable. The amount of resected tumor is a factor also considered in longitudinal scans, when evaluating the apparent tumor for potential diagnosis of progression. Furthermore, there is mounting evidence that accurate segmentation of the various tumor sub-regions can offer the basis for quantitative image analysis towards prediction of patient overall survival. This study assesses the state-of-the-art machine learning (ML) methods used for brain tumor image analysis in mpMRI scans, during the last seven instances of the International Brain Tumor Segmentation (BraTS) challenge, i.e., 2012-2018. Specifically, we focus on i) evaluating segmentations of the various glioma sub-regions in pre-operative mpMRI scans, ii) assessing potential tumor progression by virtue of longitudinal growth of tumor sub-regions, beyond use of the RECIST/RANO criteria, and iii) predicting the overall survival from pre-operative mpMRI scans of patients that underwent gross total resection. Finally, we investigate the …",
        "year": 2018,
        "authors": "Spyridon Bakas and Mauricio Reyes and Andras Jakab and Stefan Bauer and Markus Rempfler and Alessandro Crimi and Russell Takeshi Shinohara and Christoph Berger and Sung Min Ha and Martin Rozycki and Marcel Prastawa and Esther Alberts and Jana Lipkova and John Freymann and Justin Kirby and Michel Bilello and Hassan Fathallah-Shaykh and Roland Wiest and Jan Kirschke and Benedikt Wiestler and Rivka Colen and Aikaterini Kotrotsou and Pamela Lamontagne and Daniel Marcus and Mikhail Milchenko and Arash Nazeri and Marc-Andre Weber and Abhishek Mahajan and Ujjwal Baid and Elizabeth Gerstner and Dongjin Kwon and Gagan Acharya and Manu Agarwal and Mahbubul Alam and Alberto Albiol and Antonio Albiol and Francisco J Albiol and Varghese Alex and Nigel Allinson and Pedro HA Amorim and Abhijit Amrutkar and Ganesh Anand and Simon Andermatt and Tal Arbel and Pablo Arbelaez and Aaron Avery and Muneeza Azmat and W Bai and Subhashis Banerjee and Bill Barth and Thomas Batchelder and Kayhan Batmanghelich and Enzo Battistella and Andrew Beers and Mikhail Belyaev and Martin Bendszus and Eze Benson and Jose Bernal and Halandur Nagaraja Bharath and George Biros and Sotirios Bisdas and James Brown and Mariano Cabezas and Shilei Cao and Jorge M Cardoso and Eric N Carver and Adrià Casamitjana and Laura Silvana Castillo and Marcel Catà and Philippe Cattin and Albert Cerigues and Vinicius S Chagas and Siddhartha Chandra and Yi-Ju Chang and Shiyu Chang and Ken Chang and Joseph Chazalon and Shengcong Chen and Wei Chen and Jefferson W Chen and Zhaolin Chen and Kun Cheng and Ahana Roy Choudhury and Roger Chylla and Albert Clérigues and Steven Colleman and Ramiro German Rodriguez Colmeiro and Marc Combalia and Anthony Costa and Xiaomeng Cui and Zhenzhen Dai and Lutao Dai and Laura Alexandra Daza and Eric Deutsch and Changxing Ding and Chao Dong and Shidu Dong and Wojciech Dudzik and Zach Eaton-Rosen and Gary Egan and Guilherme Escudero and Théo Estienne and Richard Everson and Jonathan Fabrizio and Yong Fan and Longwei Fang and Xue Feng and Enzo Ferrante and Lucas Fidon and Martin Fischer and Andrew P French and Naomi Fridman and Huan Fu and David Fuentes and Yaozong Gao and Evan Gates and David Gering and Amir Gholami and Willi Gierke and Ben Glocker and Mingming Gong and Sandra González-Villá and T Grosges and Yuanfang Guan and Sheng Guo and Sudeep Gupta and Woo-Sup Han and Il Song Han and Konstantin Harmuth and Huiguang He and Aura Hernández-Sabaté and Evelyn Herrmann and Naveen Himthani and Winston Hsu and Cheyu Hsu and Xiaojun Hu and Xiaobin Hu and Yan Hu and Yifan Hu and Rui Hua and Teng-Yi Huang and Weilin Huang and Sabine Van Huffel and Quan Huo and Vivek HV and Khan M Iftekharuddin and Fabian Isensee and Mobarakol Islam and Aaron S Jackson and Sachin R Jambawalikar"
      },
      {
        "title": "A Survey of Quantization Methods for Efficient Neural Network Inference",
        "abstract": "This chapter provides approaches to the problem of quantizing the numerical values in deep Neural Network computations, covering the advantages/disadvantages of current methods. Over the past decade, people have observed significant improvements in the accuracy of Neural Networks (NNs) for a wide range of problems, often achieved by highly over-parameterized models. Achieving efficient, real-time NNs with optimal accuracy requires rethinking the design, training, and deployment of NN models. Model distillation involves training a large model and then using it as a teacher to train a more compact model. Loosely related to NN quantization is work in neuroscience that suggests that the human brain stores information in a discrete/quantized form, rather than in a continuous form. Gray and Neuhoff have written a very nice survey of the history of quantization up to 1998.",
        "year": 2021,
        "authors": "Amir Gholami and Sehoon Kim and Zhen Dong and Zhewei Yao and Michael W Mahoney and Kurt Keutzer"
      },
      {
        "title": "Characterizing possible failure modes in physics-informed neural networks",
        "abstract": "Recent work in scientific machine learning has developed so-called physics-informed neural network (PINN) models. The typical approach is to incorporate physical domain knowledge as soft constraints on an empirical loss function and use existing machine learning methodologies to train the model. We demonstrate that, while existing PINN methodologies can learn good models for relatively trivial problems, they can easily fail to learn relevant physical phenomena for even slightly more complex problems. In particular, we analyze several distinct situations of widespread physical interest, including learning differential equations with convection, reaction, and diffusion operators. We provide evidence that the soft regularization in PINNs, which involves PDE-based differential operators, can introduce a number of subtle problems, including making the problem more ill-conditioned. Importantly, we show that these possible failure modes are not due to the lack of expressivity in the NN architecture, but that the PINN's setup makes the loss landscape very hard to optimize. We then describe two promising solutions to address these failure modes. The first approach is to use curriculum regularization, where the PINN's loss term starts from a simple PDE regularization, and becomes progressively more complex as the NN gets trained. The second approach is to pose the problem as a sequence-to-sequence learning task, rather than learning to predict the entire space-time at once. Extensive testing shows that we can achieve up to 1-2 orders of magnitude lower error with these methods as compared to regular PINN training.",
        "year": 2021,
        "authors": "Aditi Krishnapriyan and Amir Gholami and Shandian Zhe and Robert Kirby and Michael W Mahoney"
      }
    ],
    "-9geUIIAAAAJ": [
      {
        "title": "Phi-3 technical report: A highly capable language model locally on your phone",
        "abstract": "We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and GPT-3.5 (e.g., phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench), despite being small enough to be deployed on a phone. Our training dataset is a scaled-up version of the one used for phi-2, composed of heavily filtered publicly available web data and synthetic data. The model is also further aligned for robustness, safety, and chat format. We also provide parameter-scaling results with a 7B, 14B models trained for 4.8T tokens, called phi-3-small, phi-3-medium, both significantly more capable than phi-3-mini (e.g., respectively 75%, 78% on MMLU, and 8.7, 8.9 on MT-bench). To enhance multilingual, multimodal, and long-context capabilities, we introduce three models in the phi-3.5 series: phi-3.5-mini, phi-3.5-MoE, and phi-3.5-Vision. The phi-3.5-MoE, a 16 x 3.8B MoE model with 6.6 billion active parameters, achieves superior performance in language reasoning, math, and code tasks compared to other open-source models of similar scale, such as Llama 3.1 and the Mixtral series, and on par with Gemini-1.5-Flash and GPT-4o-mini. Meanwhile, phi-3.5-Vision, a 4.2 billion parameter model derived from phi-3.5-mini, excels in reasoning tasks and is adept at handling both single-image and text prompts, as well as multi-image and text prompts.",
        "year": 2024,
        "authors": "Marah Abdin and Jyoti Aneja and Hany Awadalla and Ahmed Awadallah and Ammar Ahmad Awan and Nguyen Bach and Amit Bahree and Arash Bakhtiari and Jianmin Bao and Harkirat Behl and Alon Benhaim and Misha Bilenko and Johan Bjorck and Sébastien Bubeck and Martin Cai and Qin Cai and Vishrav Chaudhary and Dong Chen and Dongdong Chen and Weizhu Chen and Yen-Chun Chen and Yi-Ling Chen and Hao Cheng and Parul Chopra and Xiyang Dai and Matthew Dixon and Ronen Eldan and Victor Fragoso and Jianfeng Gao and Mei Gao and Min Gao and Amit Garg and Allie Del Giorno and Abhishek Goswami and Suriya Gunasekar and Emman Haider and Junheng Hao and Russell J Hewett and Wenxiang Hu and Jamie Huynh and Dan Iter and Sam Ade Jacobs and Mojan Javaheripi and Xin Jin and Nikos Karampatziakis and Piero Kauffmann and Mahoud Khademi and Dongwoo Kim and Young Jin Kim and Lev Kurilenko and James R Lee and Yin Tat Lee and Yuanzhi Li and Yunsheng Li and Chen Liang and Lars Liden and Xihui Lin and Zeqi Lin and Ce Liu and Liyuan Liu and Mengchen Liu and Weishung Liu and Xiaodong Liu and Chong Luo and Piyush Madan and Ali Mahmoudzadeh and David Majercak and Matt Mazzola and Caio César Teodoro Mendes and Arindam Mitra and Hardik Modi and Anh Nguyen and Brandon Norick and Barun Patra and Daniel Perez-Becker and Thomas Portet and Reid Pryzant and Heyang Qin and Marko Radmilac and Liliang Ren and Gustavo de Rosa and Corby Rosset and Sambudha Roy and Olatunji Ruwase and Olli Saarikivi and Amin Saied and Adil Salim and Michael Santacroce and Shital Shah and Ning Shang and Hiteshi Sharma and Yelong Shen and Swadheen Shukla and Xia Song and Masahiro Tanaka and Andrea Tupini and Praneetha Vaddamanu and Chunyu Wang and Guanhua Wang and Lijuan Wang and Shuohang Wang and Xin Wang and Yu Wang and Rachel Ward and Wen Wen and Philipp Witte and Haiping Wu and Xiaoxia Wu and Michael Wyatt and Bin Xiao and Can Xu and Jiahang Xu and Weijian Xu and Jilong Xue and Sonali Yadav and Fan Yang and Jianwei Yang and Yifan Yang and Ziyi Yang and Donghan Yu and Lu Yuan and Chenruidong Zhang and Cyril Zhang and Jianwen Zhang and Li Lyna Zhang and Yi Zhang and Yue Zhang and Yunan Zhang and Xiren Zhou"
      },
      {
        "title": "Model-free reinforcement learning in infinite-horizon average-reward markov decision processes",
        "abstract": "Model-free reinforcement learning is known to be memory and computation efficient and more amendable to large scale problems. In this paper, two model-free algorithms are introduced for learning infinite-horizon average-reward Markov Decision Processes (MDPs). The first algorithm reduces the problem to the discounted-reward version and achieves  regret after  steps, under the minimal assumption of weakly communicating MDPs. To our knowledge, this is the first model-free algorithm for general MDPs in this setting. The second algorithm makes use of recent advances in adaptive algorithms for adversarial multi-armed bandits and improves the regret to , albeit with a stronger ergodic assumption. This result significantly improves over the  regret achieved by the only existing model-free algorithm by Abbasi-Yadkori et al.(2019) for ergodic MDPs in the infinite-horizon average-reward setting.",
        "year": 2020,
        "authors": "Chen-Yu Wei and Mehdi Jafarnia Jahromi and Haipeng Luo and Hiteshi Sharma and Rahul Jain"
      },
      {
        "title": "Evaluating cognitive maps and planning in large language models with cogeval",
        "abstract": "Recently an influx of studies claims emergent cognitive abilities in large language models (LLMs). Yet, most rely on anecdotes, overlook contamination of training sets, or lack systematic Evaluation involving multiple tasks, control conditions, multiple iterations, and statistical robustness tests. Here we make two major contributions. First, we propose CogEval, a cognitive science-inspired protocol for the systematic evaluation of cognitive capacities in LLMs. The CogEval protocol can be followed for the evaluation of various abilities. Second, here we follow CogEval to systematically evaluate cognitive maps and planning ability across eight LLMs (OpenAI GPT-4, GPT-3.5-turbo-175B, davinci-003-175B, Google Bard, Cohere-xlarge-52.4 B, Anthropic Claude-1-52B, LLaMA-13B, and Alpaca-7B). We base our task prompts on human experiments, which offer both established construct validity for evaluating planning, and are absent from LLM training sets. We find that, while LLMs show apparent competence in a few planning tasks with simpler structures, systematic evaluation reveals striking failure modes in planning tasks, including hallucinations of invalid trajectories and falling in loops. These findings do not support the idea of emergent out-of-the-box planning ability in LLMs. This could be because LLMs do not understand the latent relational structures underlying planning problems, known as cognitive maps, and fail at unrolling goal-directed trajectories based on the underlying structure. Implications for application and future directions are discussed.",
        "year": 2023,
        "authors": "Ida Momennejad and Hosein Hasanbeig and Felipe Vieira Frujeri and Hiteshi Sharma and Nebojsa Jojic and Hamid Palangi and Robert Ness and Jonathan Larson"
      }
    ],
    "Vdu_sqwAAAAJ": [
      {
        "title": "Self-Refine: Iterative Refinement with Self-Feedback",
        "abstract": "Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides* feedback* for its output and uses it to* refine* itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner and the feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. Across all evaluated tasks, outputs generated with Self-Refine are preferred by humans and automatic metrics over those generated with the same LLM using conventional one-step generation, improving by 20\\% absolute on average in task performance. Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test-time using our simple, standalone approach.",
        "year": 2024,
        "authors": "Aman Madaan and Niket Tandon and Prakhar Gupta and Skyler Hallinan and Luyu Gao and Sarah Wiegreffe and Uri Alon and Nouha Dziri and Shrimai Prabhumoye and Yiming Yang and Shashank Gupta and Bodhisattwa Prasad Majumder and Katherine Hermann and Sean Welleck and Amir Yazdanbakhsh and Peter Clark"
      },
      {
        "title": "AxBench: A Multiplatform Benchmark Suite for Approximate Computing",
        "abstract": "Approximate computing is claimed to be a powerful knob for alleviating the peak power and energy-efficiency issues. However, providing a consistent benchmark suit with diverse applications amenable to approximate computing is crucial to ensure fair and reproducible comparisons. This article makes an important attempt toward it in the form of the AxBench suite, which contains applications for CPUs, GPUs, and hardware design with necessary annotations to mark the approximable regions and output quality metrics. -Muhammad Shafique, Vienna University of Technology.",
        "year": 2017,
        "authors": "Amir Yazdanbakhsh and Divya Mahajan and Hadi Esmaeilzadeh and Pejman Lotfi-Kamran"
      },
      {
        "title": "General-purpose Code Acceleration with Limited-precision Analog Computation",
        "abstract": "As improvements in per-transistor speed and energy efficiency diminish, radical departures from conventional approaches are becoming critical to improving the performance and energy efficiency of general-purpose processors. We propose a solution--from circuit to compiler-that enables general-purpose use of limited-precision, analog hardwareto accelerate \"approximable\" code---code that can tolerate imprecise execution. We utilize an algorithmic transformation that automatically converts approximable regions of code from a von Neumann model to an \"analog\" neural model. We outline the challenges of taking an analog approach, including restricted-range value encoding, limited precision in computation, circuit inaccuracies, noise, and constraints on supported topologies. We address these limitations with a combination of circuit techniques, a hardware/software interface, neuralnetwork training techniques …",
        "year": 2014,
        "authors": "Renée St. Amant and Amir Yazdanbakhsh and Jongse Park and Bradley Thwaites and Hadi Esmaeilzadeh and Arjang Hassibi and Luis Ceze and Doug Burger"
      }
    ],
    "x04W_mMAAAAJ": [
      {
        "title": "Imagenet classification with deep convolutional neural networks",
        "abstract": "We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7\\% and 18.9\\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.",
        "year": 2012,
        "authors": "Alex Krizhevsky and Ilya Sutskever and Geoffrey E Hinton"
      },
      {
        "title": "Tensorflow: Large-scale machine learning on heterogeneous distributed systems",
        "abstract": "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.",
        "year": 2016,
        "authors": "Martín Abadi and Ashish Agarwal and Paul Barham and Eugene Brevdo and Zhifeng Chen and Craig Citro and Greg S Corrado and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Ian Goodfellow and Andrew Harp and Geoffrey Irving and Michael Isard and Yangqing Jia and Rafal Józefowicz and Lukasz Kaiser and Manjunath Kudlur and Josh Levenberg and Dan Mané and Rajat Monga and Sherry Moore and Derek Murray and Chris Olah and Mike Schuster and Jonathon Shlens and Benoit Steiner and Ilya Sutskever and Kunal Talwar and Paul Tucker and Vincent Vanhoucke and Vijay Vasudevan and Fernanda Viegas and Oriol Vinyals and Pete Warden and Martin Wattenberg and Martin Wicke and Yuan Yu and Xiaoqiang Zheng"
      },
      {
        "title": "Dropout: a simple way to prevent neural networks from overfitting",
        "abstract": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves …",
        "year": 2014,
        "authors": "Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov"
      }
    ],
    "hRB3wSgAAAAJ": [
      {
        "title": "Recent advances in graph partitioning",
        "abstract": "We survey recent trends in practical algorithms for balanced graph partitioning, point to applications and discuss future research directions.",
        "year": 2016,
        "authors": "Aydın Buluç and Henning Meyerhenke and Ilya Safro and Peter Sanders and Christian Schulz"
      },
      {
        "title": "Parallel sparse matrix-vector and matrix-transpose-vector multiplication using compressed sparse blocks",
        "abstract": "This paper introduces a storage format for sparse matrices, called compressed sparse blocks (CSB), which allows both Ax and A,x to be computed efficiently in parallel, where A is an n×n sparse matrix with nnzen nonzeros and x is a dense n-vector. Our algorithms use Θ(nnz) work (serial running time) and Θ(√nlgn) span (critical-path length), yielding a parallelism of Θ(nnz/√nlgn), which is amply high for virtually any large matrix. The storage requirement for CSB is the same as that for the more-standard compressed-sparse-rows (CSR) format, for which computing Ax in parallel is easy but A,x is difficult. Benchmark results indicate that on one processor, the CSB algorithms for Ax and A,x run just as fast as the CSR algorithm for Ax, but the CSB algorithms also scale up linearly with processors until limited by off-chip memory bandwidth.",
        "year": 2009,
        "authors": "Aydin Buluç and Jeremy T Fineman and Matteo Frigo and John R Gilbert and Charles E Leiserson"
      },
      {
        "title": "The Combinatorial BLAS: Design, implementation, and applications",
        "abstract": "This paper presents a scalable high-performance software library to be used for graph analysis and data mining. Large combinatorial graphs appear in many applications of high-performance computing, including computational biology, informatics, analytics, web search, dynamical systems, and sparse matrix methods. Graph computations are difficult to parallelize using traditional approaches due to their irregular nature and low operational intensity. Many graph computations, however, contain sufficient coarse-grained parallelism for thousands of processors, which can be uncovered by using the right primitives. We describe the parallel Combinatorial BLAS, which consists of a small but powerful set of linear algebra primitives specifically targeting graph and data mining applications. We provide an extensible library interface and some guiding principles for future development. The library is evaluated using two …",
        "year": 2011,
        "authors": "Aydın Buluç and John R Gilbert"
      }
    ],
    "fA0rYxMAAAAJ": [
      {
        "title": "Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models",
        "abstract": "Model-based reinforcement learning (RL) algorithms can attain excellent sample efficiency, but often lag behind the best model-free algorithms in terms of asymptotic performance. This is especially true with high-capacity parametric function approximators, such as deep networks. In this paper, we study how to bridge this gap, by employing uncertainty-aware dynamics models. We propose a new algorithm called probabilistic ensembles with trajectory sampling (PETS) that combines uncertainty-aware deep network dynamics models with sampling-based uncertainty propagation. Our comparison to state-of-the-art model-based and model-free deep RL algorithms shows that our approach matches the asymptotic performance of model-free algorithms on several challenging benchmark tasks, while requiring significantly fewer samples (eg 8 and 125 times fewer samples than Soft Actor Critic and Proximal Policy Optimization respectively on the half-cheetah task).",
        "year": 2018,
        "authors": "Kurtland Chua and Roberto Calandra and Rowan McAllister and Sergey Levine"
      },
      {
        "title": "DIGIT: A novel design for a low-cost compact high-resolution tactile sensor with application to in-hand manipulation",
        "abstract": "Despite decades of research, general purpose in-hand manipulation remains one of the unsolved challenges of robotics. One of the contributing factors that limit current robotic manipulation systems is the difficulty of precisely sensing contact forces - sensing and reasoning about contact forces are crucial to accurately control interactions with the environment. As a step towards enabling better robotic manipulation, we introduce DIGIT, an inexpensive, compact, and high-resolution tactile sensor geared towards in-hand manipulation. DIGIT improves upon past vision-based tactile sensors by miniaturizing the form factor to be mountable on multi-fingered hands, and by providing several design improvements that result in an easier, more repeatable manufacturing process, and enhanced reliability. We demonstrate the capabilities of the DIGIT sensor by training deep neural network model-based controllers to …",
        "year": 2020,
        "authors": "Mike Lambeta and Po-Wei Chou and Stephen Tian and Brian Yang and Benjamin Maloon and Victoria Rose Most and Dave Stroud and Raymond Santos and Ahmad Byagowi and Gregg Kammerer and Dinesh Jayaraman and Roberto Calandra"
      },
      {
        "title": "Learning invariant representations for reinforcement learning without reconstruction",
        "abstract": "We study how representation learning can accelerate reinforcement learning from rich observations, such as images, without relying either on domain knowledge or pixel-reconstruction. Our goal is to learn representations that both provide for effective downstream control and invariance to task-irrelevant details. Bisimulation metrics quantify behavioral similarity between states in continuous MDPs, which we propose using to learn robust latent representations which encode only the task-relevant information from observations. Our method trains encoders such that distances in latent space equal bisimulation distances in state space. We demonstrate the effectiveness of our method at disregarding task-irrelevant information using modified visual MuJoCo tasks, where the background is replaced with moving distractors and natural videos, while achieving SOTA performance. We also test a first-person highway driving task where our method learns invariance to clouds, weather, and time of day. Finally, we provide generalization results drawn from properties of bisimulation metrics, and links to causal inference.",
        "year": 2020,
        "authors": "Amy Zhang and Rowan McAllister and Roberto Calandra and Yarin Gal and Sergey Levine"
      }
    ],
    "lPycXNcAAAAJ": [
      {
        "title": "Fundamentals of wireless communication",
        "abstract": "The past decade has seen many advances in physical layer wireless communication theory and their implementation in wireless systems. This textbook takes a unified view of the fundamentals of wireless communication and explains the web of concepts underpinning these advances at a level accessible to an audience with a basic background in probability and digital communication. Topics covered include MIMO (multi-input, multi-output) communication, space-time coding, opportunistic communication, OFDM and CDMA. The concepts are illustrated using many examples from real wireless systems such as GSM, IS-95 (CDMA), IS-856 (1 x EV-DO), Flash OFDM and UWB (ultra-wideband). Particular emphasis is placed on the interplay between concepts and their implementation in real systems. An abundant supply of exercises and figures reinforce the material in the text. This book is intended for use on graduate courses in electrical and computer engineering and will also be of great interest to practising engineers.",
        "year": 2005,
        "authors": "David Tse and Pramod Viswanath"
      },
      {
        "title": "Opportunistic beamforming using dumb antennas",
        "abstract": "Multiuser diversity is a form of diversity inherent in a wireless network, provided by independent time-varying channels across the different users. The diversity benefit is exploited by tracking the channel fluctuations of the users and scheduling transmissions to users when their instantaneous channel quality is near the peak. The diversity gain increases with the dynamic range of the fluctuations and is thus limited in environments with little scattering and/or slow fading. In such environments, we propose the use of multiple transmit antennas to induce large and fast channel fluctuations so that multiuser diversity can still be exploited. The scheme can be interpreted as opportunistic beamforming and we show that true beamforming gains can be achieved when there are sufficient users, even though very limited channel feedback is needed. Furthermore, in a cellular system, the scheme plays an additional role of …",
        "year": 2002,
        "authors": "Pramod Viswanath and David N. C.  Tse and Rajiv Laroia"
      },
      {
        "title": "Sum capacity of the vector Gaussian broadcast channel and uplink–downlink duality",
        "abstract": "We characterize the sum capacity of the vector Gaussian broadcast channel by showing that the existing inner bound of Marton and the existing upper bound of Sato are tight for this channel. We exploit an intimate four-way connection between the vector broadcast channel, the corresponding point-to-point channel (where the receivers can cooperate), the multiple-access channel (MAC) (where the role of transmitters and receivers are reversed), and the corresponding point-to-point channel (where the transmitters can cooperate).",
        "year": 2003,
        "authors": "Pramod Viswanath and David N. C.  Tse"
      }
    ],
    "fMDLYCUAAAAJ": [
      {
        "title": "ROS: an open-source Robot Operating System",
        "abstract": "This paper gives an overview of ROS, an opensource robot operating system. ROS is not an operating system in the traditional sense of process management and scheduling; rather, it provides a structured communications layer above the host operating systems of a heterogenous compute cluster. In this paper, we discuss how ROS relates to existing robot software frameworks, and briefly overview some of the available application software which uses ROS.",
        "year": 2009,
        "authors": "Morgan Quigley and Ken Conley and Brian Gerkey and Josh Faust and Tully Foote and Jeremy Leibs and Rob Wheeler and Andrew Y Ng"
      },
      {
        "title": "An application of reinforcement learning to aerobatic helicopter flight",
        "abstract": "Autonomous helicopter flight is widely regarded to be a highly challenging control problem. This paper presents the first successful autonomous completion on a real RC helicopter of the following four aerobatic maneuvers: forward flip and sideways roll at low speed, tail-in funnel, and nose-in funnel. Our experimental results significantly extend the state of the art in autonomous helicopter flight. We used the following approach: First we had a pilot fly the helicopter to help us find a helicopter dynamics model and a reward (cost) function. Then we used a reinforcement learning (optimal control) algorithm to find a controller that is optimized for the resulting model and reward function. More specifically, we used differential dynamic programming (DDP), an extension of the linear quadratic regulator (LQR).",
        "year": 2006,
        "authors": "Pieter Abbeel and Adam Coates and Morgan Quigley and Andrew Ng"
      },
      {
        "title": "Supporting wilderness search and rescue using a camera‐equipped mini UAV",
        "abstract": "Wilderness Search and Rescue (WiSAR) entails searching over large regions in often rugged remote areas. Because of the large regions and potentially limited mobility of ground searchers, WiSAR is an ideal application for using small (human‐packable) unmanned aerial vehicles (UAVs) to provide aerial imagery of the search region. This paper presents a brief analysis of the WiSAR problem with emphasis on practical aspects of visual‐based aerial search. As part of this analysis, we present and analyze a generalized contour search algorithm, and relate this search to existing coverage searches. Extending beyond laboratory analysis, lessons from field trials with search and rescue personnel indicated the immediate need to improve two aspects of UAV‐enabled search: How video information is presented to searchers and how UAV technology is integrated into existing WiSAR teams. In response to the first …",
        "year": 2008,
        "authors": "Michael A Goodrich and Bryan S Morse and Damon Gerhardt and Joseph L Cooper and Morgan Quigley and Julie A Adams and Curtis Humphrey"
      }
    ],
    "c_z5hWEAAAAJ": [
      {
        "title": "Dive into deep learning",
        "abstract": "Deep learning has revolutionized pattern recognition, introducing tools that power a wide range of technologies in such diverse ﬁelds as computer vision, natural language processing, and automatic speech recognition. Applying deep learning requires you to simultaneously understand how to cast a problem, the basic mathematics of modeling, the algorithms for ﬁtting your models to data, and the engineering techniques to implement it all. This book is a comprehensive resource that makes deep learning approachable, while still providing sufficient technical depth to enable engineers, scientists, and students to use deep learning in their own work. No previous background in machine learning or deep learning is required-every concept is explained from scratch and the appendix provides a refresher on the mathematics needed. Runnable code is featured throughout, allowing you to develop your own intuition by putting key ideas into practice.",
        "year": 2023,
        "authors": "Aston Zhang and Zachary Lipton and Li and Mu and Alexander J Smola and Pratik Chaudhari and Rasool Fakoor and Kavosh Asadi and Andrew G Wilson and A Klein and M Seeger and Archambeau. Cedric and S Zhang and Y Tay and B Werness and Rachel Hu and A Dagar and Y. Tang"
      },
      {
        "title": "Entropy-SGD: Biasing gradient descent into wide valleys",
        "abstract": "This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in the sharp valleys. Conceptually, our algorithm resembles two nested loops of SGD where we use Langevin dynamics in the inner loop to compute the gradient of the local entropy before each update of the weights. We show that the new objective has a smoother energy landscape and show improved generalization over SGD using uniform stability, under …",
        "year": 2019,
        "authors": "Pratik Chaudhari and Anna Choromanska and Stefano Soatto and Yann LeCun and Carlo Baldassi and Christian Borgs and Jennifer Chayes and Levent Sagun and Riccardo Zecchina"
      },
      {
        "title": "Entropy-SGD: biasing gradient descent into wide valleys",
        "abstract": "This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in the sharp valleys. Conceptually, our algorithm resembles two nested loops of SGD where we use Langevin dynamics in the inner loop to compute the gradient of the local entropy before each update of the weights. We show that the new objective has a smoother energy landscape and show improved generalization over SGD using uniform stability, under …",
        "year": 2017,
        "authors": "Pratik Chaudhari and Anna Choromanska and Stefano Soatto and Yann LeCun and Carlo Baldassi and Christian Borgs and Jennifer Chayes and Levent Sagun and Riccardo Zecchina"
      }
    ],
    "czxMUzcAAAAJ": [
      {
        "title": "A survey of quantization methods for efficient neural network inference",
        "abstract": "This chapter provides approaches to the problem of quantizing the numerical values in deep Neural Network computations, covering the advantages/disadvantages of current methods. Over the past decade, people have observed significant improvements in the accuracy of Neural Networks (NNs) for a wide range of problems, often achieved by highly over-parameterized models. Achieving efficient, real-time NNs with optimal accuracy requires rethinking the design, training, and deployment of NN models. Model distillation involves training a large model and then using it as a teacher to train a more compact model. Loosely related to NN quantization is work in neuroscience that suggests that the human brain stores information in a discrete/quantized form, rather than in a continuous form. Gray and Neuhoff have written a very nice survey of the history of quantization up to 1998.",
        "year": 2022,
        "authors": "Amir Gholami* and Sehoon Kim* and Zhen Dong* and Zhewei Yao* and Michael W Mahoney and Kurt Keutzer"
      },
      {
        "title": "Q-bert: Hessian based ultra low precision quantization of bert",
        "abstract": "Transformer based architectures have become de-facto models used for a range of Natural Language Processing tasks. In particular, the BERT based models achieved significant accuracy gain for GLUE tasks, CoNLL-03 and SQuAD. However, BERT based models have a prohibitive memory footprint and latency. As a result, deploying BERT based models in resource constrained environments has become a challenging task. In this work, we perform an extensive analysis of fine-tuned BERT models using second order Hessian information, and we use our results to propose a novel method for quantizing BERT models to ultra low precision. In particular, we propose a new group-wise quantization scheme, and we use Hessian-based mix-precision method to compress the model further. We extensively test our proposed method on BERT downstream tasks of SST-2, MNLI, CoNLL-03, and SQuAD. We can achieve comparable performance to baseline with at most 2.3% performance degradation, even with ultra-low precision quantization down to 2 bits, corresponding up to 13× compression of the model parameters, and up to 4× compression of the embedding table as well as activations. Among all tasks, we observed the highest performance loss for BERT fine-tuned on SQuAD. By probing into the Hessian based analysis as well as visualization, we show that this is related to the fact that current training/fine-tuning strategy of BERT does not converge for SQuAD.",
        "year": 2020,
        "authors": "Sheng Shen* and Zhen Dong* and Jiayu Ye* and Linjian Ma and Zhewei Yao and Amir Gholami and Michael W Mahoney and Kurt Keutzer"
      },
      {
        "title": "Hawq: Hessian aware quantization of neural networks with mixed-precision",
        "abstract": "Model size and inference speed/power have become a major challenge in the deployment of neural networks for many applications. A promising approach to address these problems is quantization. However, uniformly quantizing a model to ultra-low precision leads to significant accuracy degradation. A novel solution for this is to use mixed-precision quantization, as some parts of the network may allow lower precision as compared to other layers. However, there is no systematic way to determine the precision of different layers. A brute force approach is not feasible for deep networks, as the search space for mixed-precision is exponential in the number of layers. Another challenge is a similar factorial complexity for determining block-wise fine-tuning order when quantizing the model to a target precision. Here, we introduce Hessian AWare Quantization (HAWQ), a novel second-order quantization method to address these problems. HAWQ allows for the automatic selection of the relative quantization precision of each layer, based on the layer's Hessian spectrum. Moreover, HAWQ provides a deterministic fine-tuning order for quantizing layers. We show the results of our method on Cifar-10 using ResNet20, and on ImageNet using Inception-V3, ResNet50 and SqueezeNext models. Comparing HAWQ with state-of-the-art shows that we can achieve similar/better accuracy with 8x activation compression ratio on ResNet20, as compared to DNAS, and up to 1% higher accuracy with up to 14% smaller models on ResNet50 and Inception-V3, compared to recently proposed methods of RVQuant and HAQ. Furthermore, we show that we can quantize …",
        "year": 2019,
        "authors": "Zhen Dong and Zhewei Yao and Amir Gholami and Michael W Mahoney and Kurt Keutzer"
      }
    ],
    "Q-v0BgUAAAAJ": [
      {
        "title": "A framework for variation discovery and genotyping using next-generation DNA sequencing data",
        "abstract": "Recent advances in sequencing technology make it possible to comprehensively catalog genetic variation in population samples, creating a foundation for understanding human disease, ancestry and evolution. The amounts of raw data produced are prodigious, and many computational steps are required to translate this output into high-quality variant calls. We present a unified analytic framework to discover and genotype variation among multiple samples simultaneously that achieves sensitive and specific results across five sequencing technologies and three distinct, canonical experimental designs. Our process includes (i) initial read mapping; (ii) local realignment around indels; (iii) base quality score recalibration; (iv) SNP discovery and genotyping to find all potential variants; and (v) machine learning to separate true segregating variation from machine artifacts common to next-generation sequencing …",
        "year": 2011,
        "authors": "Mark A DePristo and Eric Banks and Ryan Poplin and Kiran V Garimella and Jared R Maguire and Christopher Hartl and Anthony A Philippakis and Guillermo Del Angel and Manuel A Rivas and Matt Hanna and Aaron McKenna and Tim J Fennell and Andrew M Kernytsky and Andrey Y Sivachenko and Kristian Cibulskis and Stacey B Gabriel and David Altshuler and Mark J Daly"
      },
      {
        "title": "A map of human genome variation from population scale sequencing",
        "abstract": "The 1000 Genomes Project aims to provide a deep characterisation of human genome sequence variation as a foundation for investigating the relationship between genotype and phenotype. We present results of the pilot phase of the project, designed to develop and compare different strategies for genome wide sequencing with high throughput sequencing platforms. We undertook three projects: low coverage whole genome sequencing of 179 individuals from four populations, high coverage sequencing of two mother-father-child trios, and exon targeted sequencing of 697 individuals from seven populations. We describe the location, allele frequency and local haplotype structure of approximately 15 million SNPs, 1 million short insertions and deletions and 20,000 structural variants, the majority of which were previously undescribed. We show that over 95% of the currently accessible variants found in any …",
        "year": 2010,
        "authors": "1000 Genomes Project Consortium"
      },
      {
        "title": "Diversity and complexity in DNA recognition by transcription factors",
        "abstract": "Sequence preferences of DNA binding proteins are a primary mechanism by which cells interpret the genome. Despite the central importance of these proteins in physiology, development, and evolution, comprehensive DNA binding specificities have been determined experimentally for only a few proteins. Here, we used microarrays containing all 10–base pair sequences to examine the binding specificities of 104 distinct mouse DNA binding proteins representing 22 structural classes. Our results reveal a complex landscape of binding, with virtually every protein analyzed possessing unique preferences. Roughly half of the proteins each recognized multiple distinctly different sequence motifs, challenging our molecular understanding of how proteins interact with their DNA binding sites. This complexity in DNA recognition may be important in gene regulation and in the evolution of transcriptional regulatory networks.",
        "year": 2009,
        "authors": "Gwenael Badis and Michael F Berger and Anthony A Philippakis and Shaheynoor Talukder and Andrew R Gehrke and Savina A Jaeger and Esther T Chan and Genita Metzler and Anastasia Vedenko and Xiaoyu Chen and Hanna Kuznetsov and Chi-Fong Wang and David Coburn and Daniel E Newburger and Quaid Morris and Timothy R Hughes and Martha L Bulyk"
      }
    ],
    "kg4bCpgAAAAJ": [
      {
        "title": "Multi-Scale Context Aggregation by Dilated Convolutions",
        "abstract": "State-of-the-art models for semantic segmentation are based on adaptations of convolutional networks that had originally been designed for image classification. However, dense prediction and image classification are structurally different. In this work, we develop a new convolutional network module that is specifically designed for dense prediction. The presented module uses dilated convolutions to systematically aggregate multi-scale contextual information without losing resolution. The architecture is based on the fact that dilated convolutions support exponential expansion of the receptive field without loss of resolution or coverage. We show that the presented context module increases the accuracy of state-of-the-art semantic segmentation systems. In addition, we examine the adaptation of image classification networks to dense prediction and show that simplifying the adapted network can increase accuracy.",
        "year": 2016,
        "authors": "Fisher Yu and Vladlen Koltun"
      },
      {
        "title": "An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling",
        "abstract": "For most deep learning practitioners, sequence modeling is synonymous with recurrent networks. Yet recent results indicate that convolutional architectures can outperform recurrent networks on tasks such as audio synthesis and machine translation. Given a new sequence modeling task or dataset, which architecture should one use? We conduct a systematic evaluation of generic convolutional and recurrent architectures for sequence modeling. The models are evaluated across a broad range of standard tasks that are commonly used to benchmark recurrent networks. Our results indicate that a simple convolutional architecture outperforms canonical recurrent networks such as LSTMs across a diverse range of tasks and datasets, while demonstrating longer effective memory. We conclude that the common association between sequence modeling and recurrent networks should be reconsidered, and convolutional networks should be regarded as a natural starting point for sequence modeling tasks. To assist related work, we have made code available at http://github.com/locuslab/TCN .",
        "year": 2018,
        "authors": "Shaojie Bai and J Zico Kolter and Vladlen Koltun"
      },
      {
        "title": "CARLA: An Open Urban Driving Simulator",
        "abstract": "We introduce CARLA, an open-source simulator for autonomous driving research. CARLA has been developed from the ground up to support development, training, and validation of autonomous urban driving systems. In addition to open-source code and protocols, CARLA provides open digital assets (urban layouts, buildings, vehicles) that were created for this purpose and can be used freely. The simulation platform supports flexible specification of sensor suites and environmental conditions. We use CARLA to study the performance of three approaches to autonomous driving: a classic modular pipeline, an end-to-end model trained via imitation learning, and an end-to-end model trained via reinforcement learning. The approaches are evaluated in controlled scenarios of increasing difficulty, and their performance is examined via metrics provided by CARLA, illustrating the platform’s utility for autonomous driving research.",
        "year": 2017,
        "authors": "Alexey Dosovitskiy and German Ros and Felipe Codevilla and Antonio López and Vladlen Koltun"
      }
    ],
    "4Z6vo5QAAAAJ": [
      {
        "title": "Introduction to automata theory, languages, and computation",
        "abstract": "In the preface from the 1979 predecessor to thOR book, Hopcroft and U11man marveled at the fact that the subject of automata had exploded, compared with its state at the time they wrote their first book, in 1969. Truly, the 1979 book contained many topics not found in the earlier work and was about twice its size. If you compare this book with the 1979 book, you will find that, like the automobiles of the 1970's, this book is\" larger on the outside, but smaller on the inside.\" That sounds like a retrograde step, but we are happy with the changes for several reasons. First, in 1979, automata and language theory was still an area of active research. A purpose of that book was to encourage mathematically inclined students to make new contributions to the field. Today, there is little direct research in automata theory (as opposed to its applications), and thus little motivation for us to ret~ n the succinct, highly mathematical tone …",
        "year": 2001,
        "authors": "John E Hopcroft and Rajeev Motwani and Jeffrey D Ullman"
      },
      {
        "title": "The design and analysis of computer algorithms",
        "abstract": "The study of algorithms is at the very heart of computer science. In recent years a number of significant advances in the field of algorithms have been made. These advances have ranged from the development of faster algorithms, such as the fast Fourier transform, to the startling discovery of certain natural problems for which all algorithms are inefficient. These results have kindled considerable interest in the study of algorithms, and the area of algorithm design and analysis has blossomed into a field of intense interest. The intent of this book is to bring together the fundamental results in this area, so the unifying principles and underlying concepts of algorithm design may more easily be taught.",
        "year": 1974,
        "authors": "Alfred V Aho and John E Hopcroft"
      },
      {
        "title": "Data structures and algorithms",
        "abstract": "We have expanded that coverage and have added material on algorithms for external storage and memory management. As a consequence, this book should be suitable as a text for a first course on data structures and algorithms. The only prerequisite we assume is familiarity with some high-level programming language such as Pascal.We have attempted to cover data structures and algorithms in the broader context of solving problems using computers. We use abstract data types informally in the description and implementation of algorithms. Although abstract data types are only starting to appear in widely available programming languages, we feel they are a useful tool in designing programs, no matter what the language.",
        "year": 1983,
        "authors": "John E Hopcroft and Jeffrey D Ullman and Alfred Vaino Aho"
      }
    ],
    "DulpV-cAAAAJ": [
      {
        "title": "Robust estimators in high-dimensions without the computational intractability",
        "abstract": "We study high-dimensional distribution learning in an agnostic setting where an adversary is allowed to arbitrarily corrupt an -fraction of the samples. Such questions have a rich history spanning statistics, machine learning, and theoretical computer science. Even in the most basic settings, the only known approaches are either computationally inefficient or lose dimension-dependent factors in their error guarantees. This raises the following question: Is high-dimensional agnostic distribution learning even possible, algorithmically? In this work, we obtain the first computationally efficient algorithms with dimension-independent error guarantees for agnostically learning several fundamental classes of high-dimensional distributions: (1) a single Gaussian, (2) a product distribution on the hypercube, (3) mixtures of two product distributions (under a natural balancedness condition), and (4) mixtures of spherical …",
        "year": 2019,
        "authors": "Ilias Diakonikolas and Gautam Kamath and Daniel Kane and Jerry Li and Ankur Moitra and Alistair Stewart"
      },
      {
        "title": "Sparser johnson-lindenstrauss transforms",
        "abstract": "We give two different and simple constructions for dimensionality reduction in ℓ2 via linear mappings that are sparse: only an O(ε)-fraction of entries in each column of our embedding matrices are non-zero to achieve distortion 1 + ε with high probability, while still achieving the asymptotically optimal number of rows. These are the first constructions to provide subconstant sparsity for all values of parameters, improving upon previous works of Achlioptas [2003] and Dasgupta et al. [2010]. Such distributions can be used to speed up applications where ℓ2 dimensionality reduction is used.",
        "year": 2014,
        "authors": "Daniel M Kane and Jelani Nelson"
      },
      {
        "title": "An optimal algorithm for the distinct elements problem",
        "abstract": "We give the first optimal algorithm for estimating the number of distinct elements in a data stream, closing a long line of theoretical research on this problem begun by Flajolet and Martin in their seminal paper in FOCS 1983. This problem has applications to query optimization, Internet routing, network topology, and data mining. For a stream of indices in {1,...,n}, our algorithm computes a (1 ± ε)-approximation using an optimal O(1/ε-2 + log(n)) bits of space with 2/3 success probability, where 0<ε<1 is given. This probability can be amplified by independent repetition. Furthermore, our algorithm processes each stream update in O(1) worst-case time, and can report an estimate at any point midstream in O(1) worst-case time, thus settling both the space and time complexities simultaneously.We also give an algorithm to estimate the Hamming norm of a stream, a generalization of the number of distinct elements, which …",
        "year": 2010,
        "authors": "Daniel M Kane and Jelani Nelson and David P Woodruff"
      }
    ],
    "ZQ1Bbb8AAAAJ": [
      {
        "title": "Nowhere-zero 3-flows and modulo k-orientations",
        "abstract": "The main theorem of this paper provides partial results on some major open problems in graph theory, such as Tutteʼs 3-flow conjecture (from the 1970s) that every 4-edge connected graph admits a nowhere-zero 3-flow, the conjecture of Jaeger, Linial, Payan and Tarsi (1992) that every 5-edge-connected graph is Z 3-connected, Jaegerʼs circular flow conjecture (1984) that for every odd natural number k⩾ 3, every (2 k− 2)-edge-connected graph has a modulo k-orientation, etc. It was proved recently by Thomassen that, for every odd number k⩾ 3, every (2 k 2+ k)-edge-connected graph G has a modulo k-orientation; and every 8-edge-connected graph G is Z 3-connected and admits therefore a nowhere-zero 3-flow. In the present paper, Thomassenʼs method is refined to prove the following: For every odd number k⩾ 3, every (3 k− 3)-edge-connected graph has a modulo k-orientation. As a special case of the …",
        "year": 2013,
        "authors": "László Miklós Lovász and Carsten Thomassen and Yezhou Wu and Cun-Quan Zhang"
      },
      {
        "title": "A tight bound for Green's arithmetic triangle removal lemma in vector spaces",
        "abstract": "Let p be a fixed prime. A triangle in  is an ordered triple (x, y, z) of points satisfying x+y+ z = 0. Let  Green proved an arithmetic triangle removal lemma which says that for every ∊ > 0 and prime p, there is a δ > 0 such that if  and the number of triangles in X × Y × Z is at most δN2, then we can delete ∊N elements from X, Y, and Z and remove all triangles. Green posed the problem of improving the quantitative bounds on the arithmetic triangle removal lemma, and, in particular, asked whether a polynomial bound holds. Despite considerable attention, prior to this paper, the best known bound, due to the first author, showed that 1/δ can be taken to be an exponential tower of twos of height logarithmic in 1/∊.We solve Green's problem, proving an essentially tight bound for Green's arithmetic triangle removal lemma in  We show that a polynomial bound holds, and further determine the best possible exponent. Namely …",
        "year": 2017,
        "authors": "Jacob Fox and László Miklós Lovász"
      },
      {
        "title": "A tight lower bound for Szemer\\'edi's regularity lemma",
        "abstract": "Addressing a question of Gowers, we determine the order of the tower height for the partition size in a version of Szemer\\'edi's regularity lemma.",
        "year": 2014,
        "authors": "Jacob Fox and László Miklós Lovász"
      }
    ],
    "wmZTE5gAAAAJ": [
      {
        "title": "Ray: A Distributed Framework for Emerging AI Applications",
        "abstract": "The next generation of AI applications will continuously interact with the environment and learn from these interactions. These applications impose new and demanding systems requirements, both in terms of performance and flexibility. In this paper, we consider these requirements and present Ray—a distributed system to address them. Ray implements a unified interface that can express both task-parallel and actor-based computations, supported by a single dynamic execution engine. To meet the performance requirements, Ray employs a distributed scheduler and a distributed and fault-tolerant store to manage the system’s control state. In our experiments, we demonstrate scaling beyond 1.8 million tasks per second and better performance than existing specialized systems for several challenging reinforcement learning applications.",
        "year": 2018,
        "authors": "Philipp Moritz and Robert Nishihara and Stephanie Wang and Alexey Tumanov and Richard Liaw and Eric Liang and Melih Elibol and Zongheng Yang and William Paul and Michael I Jordan and Ion Stoica"
      },
      {
        "title": "RLlib: Abstractions for distributed reinforcement learning",
        "abstract": "Reinforcement learning (RL) algorithms involve the deep nesting of highly irregular computation patterns, each of which typically exhibits opportunities for distributed computation. We argue for distributing RL components in a composable way by adapting algorithms for top-down hierarchical control, thereby encapsulating parallelism and resource requirements within short-running compute tasks. We demonstrate the benefits of this principle through RLlib: a library that provides scalable software primitives for RL. These primitives enable a broad range of algorithms to be implemented with high performance, scalability, and substantial code reuse. RLlib is available as part of the open source Ray project at http://rllib. io/.",
        "year": 2017,
        "authors": "Eric Liang and Richard Liaw and Philipp Moritz and Robert Nishihara and Roy Fox and Ken Goldberg and Joseph E Gonzalez and Michael I Jordan and Ion Stoica"
      },
      {
        "title": "Tune: A research platform for distributed model selection and training",
        "abstract": "Modern machine learning algorithms are increasingly computationally demanding, requiring specialized hardware and distributed computation to achieve high performance in a reasonable time frame. Many hyperparameter search algorithms have been proposed for improving the efficiency of model selection, however their adaptation to the distributed compute environment is often ad-hoc. We propose Tune, a unified framework for model selection and training that provides a narrow-waist interface between training scripts and search algorithms. We show that this interface meets the requirements for a broad range of hyperparameter search algorithms, allows straightforward scaling of search to large clusters, and simplifies algorithm implementation. We demonstrate the implementation of several state-of-the-art hyperparameter search algorithms in Tune. Tune is available at http://ray.readthedocs.io/en/latest/tune.html.",
        "year": 2018,
        "authors": "Richard Liaw and Eric Liang and Robert Nishihara and Philipp Moritz and Joseph E Gonzalez and Ion Stoica"
      }
    ],
    "xUGZX_MAAAAJ": [
      {
        "title": "PRECOG: PREdiction Conditioned On Goals in Visual Multi-Agent Settings",
        "abstract": "For autonomous vehicles (AVs) to behave appropriately on roads populated by human-driven vehicles, they must be able to reason about the uncertain intentions and decisions of other drivers from rich perceptual information. Towards these capabilities, we present a probabilistic forecasting model of future interactions between a variable number of agents. We perform both standard forecasting and the novel task of conditional forecasting, which reasons about how all agents will likely respond to the goal of a controlled agent (here, the AV). We train models on real and simulated data to forecast vehicle trajectories given past positions and LIDAR. Our evaluation shows that our model is substantially more accurate in multi-agent driving scenarios compared to existing state-of-the-art. Beyond its general ability to perform conditional forecasting queries, we show that our model's predictions of all agents improve when conditioned on knowledge of the AV's goal, further illustrating its capability to model agent interactions.",
        "year": 2019,
        "authors": "Nicholas Rhinehart and Rowan McAllister and Kris Kitani and Sergey Levine"
      },
      {
        "title": "R2P2: A Reparameterized Pushforward Policy for Diverse, Precise Generative Path Forecasting",
        "abstract": "We propose a method to forecast a vehicle's ego-motion as a distribution over spatiotemporal paths, conditioned on features (eg, from LIDAR and images) embedded in an overhead map. The method learns a policy inducing a distribution over simulated trajectories that is both diverse (produces most paths likely under the data) and precise (mostly produces paths likely under the data). This balance is achieved through minimization of a symmetrized cross-entropy between the distribution and demonstration data. By viewing the simulated-outcome distribution as the pushforward of a simple distribution under a simulation operator, we obtain expressions for the cross-entropy metrics that can be efficiently evaluated and differentiated, enabling stochastic-gradient optimization. We propose concrete policy architectures for this model, discuss our evaluation metrics relative to previously-used metrics, and demonstrate the superiority of our method relative to state-of-the-art methods in both the KITTI dataset and a similar but novel and larger real-world dataset explicitly designed for the vehicle forecasting domain.",
        "year": 2018,
        "authors": "Nicholas Rhinehart and Kris M. Kitani and Paul Vernaza"
      },
      {
        "title": "Can autonomous vehicles identify, recover from, and adapt to distribution shifts?",
        "abstract": "Out-of-training-distribution (OOD) scenarios are a common challenge of learning agents at deployment, typically leading to arbitrary deductions and poorly-informed decisions. In principle, detection of and adaptation to OOD scenes can mitigate their adverse effects. In this paper, we highlight the limitations of current approaches to novel driving scenes and propose an epistemic uncertainty-aware planning method, called\\emph {robust imitative planning}(RIP). Our method can detect and recover from some distribution shifts, reducing the overconfident and catastrophic extrapolations in OOD scenes. If the model’s uncertainty is too great to suggest a safe course of action, the model can instead query the expert driver for feedback, enabling sample-efficient online adaptation, a variant of our method we term\\emph {adaptive robust imitative planning}(AdaRIP). Our methods outperform current state-of-the-art approaches in the nuScenes\\emph {prediction} challenge, but since no benchmark evaluating OOD detection and adaption currently exists to assess\\emph {control}, we introduce an autonomous car novel-scene benchmark,\\texttt {CARNOVEL}, to evaluate the robustness of driving agents to a suite of tasks with distribution shifts, where our methods outperform all the baselines.",
        "year": 2020,
        "authors": "Angelos Filos and Panagiotis Tigkas and Rowan McAllister and Nicholas Rhinehart and Sergey Levine and Yarin Gal"
      }
    ],
    "hhm6ZzUAAAAJ": [
      {
        "title": "Path planning for autonomous vehicles using model predictive control",
        "abstract": "Path planning for autonomous vehicles in dynamic environments is an important but challenging problem, due to the constraints of vehicle dynamics and existence of surrounding vehicles. Typical trajectories of vehicles involve different modes of maneuvers, including lane keeping, lane change, ramp merging, and intersection crossing. There exist prior arts using the rule-based high-level decision making approaches to decide the mode switching. Instead of using explicit rules, we propose a unified path planning approach using Model Predictive Control (MPC), which automatically decides the mode of maneuvers. To ensure safety, we model surrounding vehicles as polygons and develop a type of constraints in MPC to enforce the collision avoidance between the ego vehicle and surrounding vehicles. To achieve comfortable and natural maneuvers, we include a lane-associated potential field in the objective …",
        "year": 2017,
        "authors": "Chang Liu and Seungho Lee and Scott Varnhagen and H Eric Tseng"
      },
      {
        "title": "Learning a deep neural net policy for end-to-end control of autonomous vehicles",
        "abstract": "Deep neural networks are frequently used for computer vision, speech recognition and text processing. The reason is their ability to regress highly nonlinear functions. We present an end-to-end controller for steering autonomous vehicles based on a convolutional neural network (CNN). The deployed framework does not require explicit hand-engineered algorithms for lane detection, object detection or path planning. The trained neural net directly maps pixel data from a front-facing camera to steering commands and does not require any other sensors. We compare the controller performance with the steering behavior of a human driver.",
        "year": 2017,
        "authors": "Viktor Rausch and Andreas Hansen and Eugen Solowjow and Chang Liu and Edwin Kreuzer and J Karl Hedrick"
      },
      {
        "title": "Kalman filter-based tracking of moving objects using linear ultrasonic sensor array for road vehicles",
        "abstract": "Detection and tracking of objects in the side-near-field has attracted much attention for the development of advanced driver assistance systems. This paper presents a cost-effective approach to track moving objects around vehicles using linearly arrayed ultrasonic sensors. To understand the detection characteristics of a single sensor, an empirical detection model was developed considering the shapes and surface materials of various detected objects. Eight sensors were arrayed linearly to expand the detection range for further application in traffic environment recognition. Two types of tracking algorithms, including an Extended Kalman filter (EKF) and an Unscented Kalman filter (UKF), for the sensor array were designed for dynamic object tracking. The ultrasonic sensor array was designed to have two types of fire sequences: mutual firing or serial firing. The effectiveness of the designed algorithms were verified in …",
        "year": 2018,
        "authors": "Shengbo Eben Li and Guofa Li and Jiaying Yu and Chang Liu and Bo Cheng and Jianqiang Wang and Keqiang Li"
      }
    ],
    "xOWBOKQAAAAJ": [
      {
        "title": "A survey of research on cloud robotics and automation",
        "abstract": "The Cloud infrastructure and its extensive set of Internet-accessible resources has potential to provide significant benefits to robots and automation systems. We consider robots and automation systems that rely on data or code from a network to support their operation, i.e., where not all sensing, computation, and memory is integrated into a standalone system. This survey is organized around four potential benefits of the Cloud: 1) Big Data: access to libraries of images, maps, trajectories, and descriptive data; 2) Cloud Computing: access to parallel grid computing on demand for statistical analysis, learning, and motion planning; 3) Collective Robot Learning: robots sharing trajectories, control policies, and outcomes; and 4) Human Computation: use of crowdsourcing to tap human skills for analyzing images and video, classification, learning, and error recovery. The Cloud can also improve robots and automation …",
        "year": 2015,
        "authors": "Ben Kehoe and Sachin Patil and Pieter Abbeel and Ken Goldberg"
      },
      {
        "title": "Motion planning with sequential convex optimization and convex collision checking",
        "abstract": "We present a new optimization-based approach for robotic motion planning among obstacles. Like CHOMP (Covariant Hamiltonian Optimization for Motion Planning), our algorithm can be used to find collision-free trajectories from naïve, straight-line initializations that might be in collision. At the core of our approach are (a) a sequential convex optimization procedure, which penalizes collisions with a hinge loss and increases the penalty coefficients in an outer loop as necessary, and (b) an efficient formulation of the no-collisions constraint that directly considers continuous-time safety Our algorithm is implemented in a software package called TrajOpt.We report results from a series of experiments comparing TrajOpt with CHOMP and randomized planners from OMPL, with regard to planning time and path quality. We consider motion planning for 7 DOF robot arms, 18 DOF full-body robots, statically stable walking …",
        "year": 2014,
        "authors": "John Schulman and Yan Duan and Jonathan Ho and Alex Lee and Ibrahim Awwal and Henry Bradlow and Jia Pan and Sachin Patil and Ken Goldberg and Pieter Abbeel"
      },
      {
        "title": "Motion planning under uncertainty using iterative local optimization in belief space",
        "abstract": "We present a new approach to motion planning under sensing and motion uncertainty by computing a locally optimal solution to a continuous partially observable Markov decision process (POMDP). Our approach represents beliefs (the distributions of the robot’s state estimate) by Gaussian distributions and is applicable to robot systems with non-linear dynamics and observation models. The method follows the general POMDP solution framework in which we approximate the belief dynamics using an extended Kalman filter and represent the value function by a quadratic function that is valid in the vicinity of a nominal trajectory through belief space. Using a belief space variant of iterative LQG (iLQG), our approach iterates with second-order convergence towards a linear control policy over the belief space that is locally optimal with respect to a user-defined cost function. Unlike previous work, our approach does not …",
        "year": 2012,
        "authors": "Jur Van Den Berg and Sachin Patil and Ron Alterovitz"
      }
    ],
    "QXyvv94AAAAJ": [
      {
        "title": "A five-site model for liquid water and the reproduction of the density anomaly by rigid, nonpolarizable potential functions",
        "abstract": "The ability of simple potential functions to reproduce accurately the density of liquid water from 37 to 100 C at 1 to 10 000 atm has been further explored. The result is the five-site TIP5P model, which yields significantly improved results; the average error in the density over the 100 temperature range from 37.5 to 62.5 C at 1 atm is only 0.006 g cm 3. Classical Monte Carlo statistical mechanics calculations have been performed to optimize the parameters, especially the position of the negative charges along the lone-pair directions. Initial calculations with 216 molecules in the NPT ensemble at 1 atm focused on finding a model that reproduced the shape of the liquid density curve as a function of temperature. Calculations performed for 512 molecules with the final TIP5P model demonstrate that the density maximum near 4 C at 1 atm is reproduced, while high-quality structural and thermodynamic results are …",
        "year": 2000,
        "authors": "Michael W Mahoney and William L Jorgensen"
      },
      {
        "title": "Community structure in large networks: Natural cluster sizes and the absence of large well-defined clusters",
        "abstract": "A large body of work has been devoted to defining and identifying clusters or communities in social and information networks, i.e., in graphs in which the nodes represent underlying social entities and the edges represent some sort of interaction between pairs of nodes. Most such research begins with the premise that a community or a cluster should be thought of as a set of nodes that has more and/or better connections between its members than to the remainder of the network. In this paper, we explore from a novel perspective several questions related to identifying meaningful communities in large social and information networks, and we come to several striking conclusions.Rather than defining a procedure to extract sets of nodes from a graph and then attempting to interpret these sets as \"real\" communities, we employ approximation algorithms for the graph-partitioning problem to characterize as a function of …",
        "year": 2009,
        "authors": "Jure Leskovec and Kevin J Lang and Anirban Dasgupta and Michael W Mahoney"
      },
      {
        "title": "A survey of quantization methods for efficient neural network inference",
        "abstract": "This chapter provides approaches to the problem of quantizing the numerical values in deep Neural Network computations, covering the advantages/disadvantages of current methods. Over the past decade, people have observed significant improvements in the accuracy of Neural Networks (NNs) for a wide range of problems, often achieved by highly over-parameterized models. Achieving efficient, real-time NNs with optimal accuracy requires rethinking the design, training, and deployment of NN models. Model distillation involves training a large model and then using it as a teacher to train a more compact model. Loosely related to NN quantization is work in neuroscience that suggests that the human brain stores information in a discrete/quantized form, rather than in a continuous form. Gray and Neuhoff have written a very nice survey of the history of quantization up to 1998.",
        "year": 2022,
        "authors": "Amir Gholami and Sehoon Kim and Zhen Dong and Zhewei Yao and Michael W Mahoney and Kurt Keutzer"
      }
    ],
    "x78TL58AAAAJ": [
      {
        "title": "A highly sensitive graphene woven fabric strain sensor for wearable wireless musical instruments",
        "abstract": "Highly flexible and sensitive strain sensors are essential components of wearable electronic devices. Herein, we present a novel graphene woven fabric (GWF)/polydimethylsiloxane (PDMS) composite as a highly flexible, sensitive strain sensor capable of detecting feeble human motions with an extremely high piezoresistive gauge factor of 223 at a strain of 3% and excellent durability. A wireless wearable musical instrument prototype made of the composite sensor demonstrates conversion of human motions to music of different instruments and sounds.",
        "year": 2017,
        "authors": "Xu Liu and Chen Tang and Xiaohan Du and Shuai Xiong and Siyuan Xi and Yuefeng Liu and Xi Shen and Qingbin Zheng and Zhenyu Wang and Ying Wu and Andrew Horner and Jang-Kyo Kim"
      },
      {
        "title": "Deep reinforcement learning for robotics: A survey of real-world successes",
        "abstract": "Reinforcement learning (RL), particularly its combination with deep neural networks referred to as deep RL (DRL), has shown tremendous promise across a wide range of applications, suggesting its potential for enabling the development of sophisticated robotic behaviors. Robotics problems, however, pose fundamental difficulties for the application of RL, stemming from the complexity and cost of interacting with the physical world. These challenges notwithstanding, recent advances have enabled DRL to succeed at some real-world robotic tasks. However, state-of-the-art DRL solutions’ maturity varies significantly across robotic applications. In this talk, I will review the current progress of DRL in real-world robotic applications based on our recent survey paper (with Tang, Abbatematteo, Hu, Chandra, and Martı́n-Martı́n), with a particular focus on evaluating the real-world successes achieved with DRL in realizing several key robotic competencies, including locomotion, navigation, stationary manipulation, mobile manipulation, human-robot interaction, and multi-robot interaction. The analysis aims to identify the key factors underlying those exciting successes, reveal underexplored areas, and provide an overall characterization of the status of DRL in robotics. I will also highlight several important avenues for future work, emphasizing the need for stable and sample-efficient real-world RL paradigms, holistic approaches for discovering and integrating various competencies to tackle complex long-horizon, open-world tasks, and principled development and evaluation procedures. The talk is designed to offer insights for RL practitioners and roboticists …",
        "year": 2025,
        "authors": "Chen Tang and Ben Abbatematteo and Jiaheng Hu and Rohan Chandra and Roberto Martín-Martín and Peter Stone"
      },
      {
        "title": "Hierarchical planning through goal-conditioned offline reinforcement learning",
        "abstract": "Offline Reinforcement learning (RL) has shown potent in many safe-critical tasks in robotics where exploration is risky and expensive. However, it still struggles to acquire skills in temporally extended tasks. In this paper, we study the problem of offline RL for temporally extended tasks. We propose a hierarchical planning framework, consisting of a low-level goal-conditioned RL policy and a high-level goal planner. The low-level policy is trained via offline RL. We improve the offline training to deal with out-of-distribution goals by a perturbed goal sampling process. The high-level planner selects intermediate sub-goals by taking advantages of model-based planning methods. It plans over future sub-goal sequences based on the learned value function of the low-level policy. We adopt a Conditional Variational Autoencoder to sample meaningful high-dimensional sub-goal candidates and to solve the high-level long …",
        "year": 2022,
        "authors": "Jinning Li and Chen Tang and Masayoshi Tomizuka and Wei Zhan"
      }
    ],
    "neGbgzYAAAAJ": [
      {
        "title": "Soft actor-critic algorithms and applications",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Large-scale evolution of image classifiers",
        "abstract": "Neural networks have proven effective at solving difficult problems but designing their architectures can be challenging, even for image classification problems alone. Our goal is to minimize human participation, so we employ evolutionary algorithms to discover such networks automatically. Despite significant computational requirements, we show that it is now possible to evolve models with accuracies within the range of those published in the last year. Specifically, we employ simple evolutionary techniques at unprecedented scales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting from trivial initial conditions and reaching accuracies of 94.6\\%(95.6\\% for ensemble) and 77.0\\%, respectively. To do this, we use novel and intuitive mutation operators that navigate large search spaces; we stress that no human participation is required once evolution starts and that the output is a fully-trained model. Throughout this work, we place special emphasis on the repeatability of results, the variability in the outcomes and the computational requirements.",
        "year": 2017,
        "authors": "Esteban Real and Sherry Moore and Andrew Selle and Saurabh Saxena and Yutaka Leon Suematsu and Jie Tan and Quoc Le and Alex Kurakin"
      },
      {
        "title": "Sim-to-real: Learning agile locomotion for quadruped robots",
        "abstract": "Designing agile locomotion for quadruped robots often requires extensive expertise and tedious manual tuning. In this paper, we present a system to automate this process by leveraging deep reinforcement learning techniques. Our system can learn quadruped locomotion from scratch using simple reward signals. In addition, users can provide an open loop reference to guide the learning process when more control over the learned gait is needed. The control policies are learned in a physics simulator and then deployed on real robots. In robotics, policies trained in simulation often do not transfer to the real world. We narrow this reality gap by improving the physics simulator and learning robust policies. We improve the simulation using system identification, developing an accurate actuator model and simulating latency. We learn robust controllers by randomizing the physical environments, adding perturbations and designing a compact observation space. We evaluate our system on two agile locomotion gaits: trotting and galloping. After learning in simulation, a quadruped robot can successfully perform both gaits in the real world.",
        "year": 2018,
        "authors": "Jie Tan and Tingnan Zhang and Erwin Coumans and Atil Iscen and Yunfei Bai and Danijar Hafner and Steven Bohez and Vincent Vanhoucke"
      }
    ],
    "1HO5UacAAAAJ": [
      {
        "title": "Microsoft coco captions: Data collection and evaluation server",
        "abstract": "In this paper we describe the Microsoft COCO Caption dataset and evaluation server. When completed, the dataset will contain over one and a half million captions describing over 330,000 images. For the training and validation images, five independent human generated captions will be provided. To ensure consistency in evaluation of automatic caption generation algorithms, an evaluation server is used. The evaluation server receives candidate captions and scores them using several popular metrics, including BLEU, METEOR, ROUGE and CIDEr. Instructions for using the evaluation server are provided.",
        "year": 2015,
        "authors": "Xinlei Chen and Hao Fang and Tsung-Yi Lin and Ramakrishna Vedantam and Saurabh Gupta and Piotr Dollár and C Lawrence Zitnick"
      },
      {
        "title": "Learning rich features from RGB-D images for object detection and segmentation",
        "abstract": "In this paper we study the problem of object detection for RGB-D images using semantically rich image and depth features. We propose a new geocentric embedding for depth images that encodes height above ground and angle with gravity for each pixel in addition to the horizontal disparity. We demonstrate that this geocentric embedding works better than using raw depth images for learning feature representations with convolutional neural networks. Our final object detection system achieves an average precision of 37.3%, which is a 56% relative improvement over existing methods. We then focus on the task of instance segmentation where we label pixels belonging to object instances found by our detector. For this task, we propose a decision forest approach that classifies pixels in the detection window as foreground or background using a family of unary and binary tests that query shape and …",
        "year": 2014,
        "authors": "Saurabh Gupta and Ross Girshick and Pablo Arbeláez and Jitendra Malik"
      },
      {
        "title": "From captions to visual concepts and back",
        "abstract": "This paper presents a novel approach for automatically generating image descriptions: visual detectors, language models, and multimodal similarity models learnt directly from a dataset of image captions. We use multiple instance learning to train visual detectors for words that commonly occur in captions, including many different parts of speech such as nouns, verbs, and adjectives. The word detector outputs serve as conditional inputs to a maximum-entropy language model. The language model learns from a set of over 400,000 image descriptions to capture the statistics of word usage. We capture global semantics by re-ranking caption candidates using sentence-level features and a deep multimodal similarity model. Our system is state-of-the-art on the official Microsoft COCO benchmark, producing a BLEU-4 score of 29.1%. When human judges compare the system captions to ones written by other people on our held-out test set, the system captions have equal or better quality 34% of the time.",
        "year": 2015,
        "authors": "Hao Fang* and Saurabh Gupta* and Forrest Iandola* and Rupesh K Srivastava* and Li Deng and Piotr Dollár and Jianfeng Gao and Xiaodong He and Margaret Mitchell and John C Platt and C Lawrence Zitnick and Geoffrey Zweig"
      }
    ],
    "3F52RjoAAAAJ": [
      {
        "title": "Search for gamma-ray emission from dark matter annihilation in the large magellanic cloud with the fermi large area telescope",
        "abstract": "At a distance of 50 kpc and with a dark matter mass of , the large magellanic cloud (LMC) is a natural target for indirect dark matter searches. We use five years of data from the Fermi Large Area Telescope (LAT) and updated models of the gamma-ray emission from standard astrophysical components to search for a dark matter annihilation signal from the LMC. We perform a rotation curve analysis to determine the dark matter distribution, setting a robust minimum on the amount of dark matter in the LMC, which we use to set conservative bounds on the annihilation cross section. The LMC emission is generally very well described by the standard astrophysical sources, with at most a  excess identified near the kinematic center of the LMC once systematic uncertainties are taken into account. We place competitive bounds on the dark matter annihilation cross section as a function of dark matter particle …",
        "year": 2015,
        "authors": "Matthew R Buckley and Eric Charles and Jennifer M Gaskins and Alyson M Brooks and Alex Drlica-Wagner and Pierrick Martin and Geng Zhao"
      },
      {
        "title": "Interference, bias, and variance in two-sided marketplace experimentation: Guidance for platforms",
        "abstract": " Two-sided marketplace platforms often run experiments (or A/B tests) to test the effect of an intervention before launching it platform-wide. A typical approach is to randomize users into a treatment group, which receives the intervention, and a control group, which does not. The platform then compares the performance in the two groups to estimate the effect if the intervention were launched to everyone. We focus on two common experiment types, where the platform randomizes users either on the supply side or on the demand side. For these experiments, it is known that the resulting estimates of the treatment effect are typically biased: individuals in the market compete with each other, which creates interference and leads to a biased estimate. Here, we observe that economic interactions (competition among demand and supply) lead to statistical phenomenon (biased estimates). We develop a simple, tractable …",
        "year": 2022,
        "authors": "Hannah Li and Geng Zhao and Ramesh Johari and Gabriel Y Weintraub"
      },
      {
        "title": "Online learning in stackelberg games with an omniscient follower",
        "abstract": "We study the problem of online learning in a two-player decentralized cooperative Stackelberg game. In each round, the leader first takes an action, followed by the follower who takes their action after observing the leader’s move. The goal of the leader is to learn to minimize the cumulative regret based on the history of interactions. Differing from the traditional formulation of repeated Stackelberg games, we assume the follower is omniscient, with full knowledge of the true reward, and that they always best-respond to the leader’s actions. We analyze the sample complexity of regret minimization in this repeated Stackelberg game. We show that depending on the reward structure, the existence of the omniscient follower may change the sample complexity drastically, from constant to exponential, even for linear cooperative Stackelberg games. This poses unique challenges for the learning process of the leader and the subsequent regret analysis.",
        "year": 2023,
        "authors": "Geng Zhao and Banghua Zhu and Jiantao Jiao and Michael Jordan"
      }
    ],
    "AIZoRQIAAAAJ": [
      {
        "title": "Addressing the elephant in the room: microaggressions in medicine",
        "abstract": "It was the beginning of the academic year. The intern was caring for a patient who needed a laceration repair. Earlier in the week, the intern had witnessed a nursing colleague prepare suture materials for a male resident without being asked. Today, the intern asked the same nurse whether she could help obtain suture materials for their patient, to which the nurse responded,“That’s your job, not mine.” Unconscious and conscious sex-based bias toward female physicians is increasingly recognized in the medical community 1, 2 and consistent with societal expectations of physicians and leaders being male. 3 From residency lore to mainstream press, 4, 5 there are mentions of female physicians being called “sweetie” or “honey”; in response, many become well versed at reminding patients and colleagues of their qualifications as physicians. Although these encounters are traditionally associated with male patients …",
        "year": 2020,
        "authors": "Melanie F Molina and Adaira I Landry and Anita N Chary and Sherri-Ann M Burnett-Bowie"
      },
      {
        "title": "Prevalence of emergency department social risk and social needs",
        "abstract": "Introduction Social risks, or adverse social conditions associated with poor health, are prevalent in emergency department (ED) patients, but little is known about how the prevalence of social risk compares to a patient’s reported social need, which incorporates patient preference for intervention. The goal of this study was to describe the relationship between social risk and social need, and identify factors associated with differential responses to social risk and social need questions. Methods We conducted a cross-sectional study with 48 hours of time-shift sampling in a large urban ED. Consenting patients completed a demographic questionnaire and assessments of social risk and social need. We applied descriptive statistics to the prevalence of social risk and social need, and multivariable logistic regression to assess factors associated with social risk, social need, or both. Results Of the 269 participants, 100 (37 …",
        "year": 2020,
        "authors": "Melanie F Molina and Caitlin N Li and Emily C Manchanda and Benjamin White and Mohammad K Faridi and Janice A Espinola and Henry Ashworth and Gia Ciccolo and Carlos A Camargo Jr and Margaret Samuels-Kalow"
      }
    ],
    "8fztli4AAAAJ": [
      {
        "title": "Eigentaste: A constant time collaborative filtering algorithm",
        "abstract": "Eigentaste is a collaborative filtering algorithm that uses universal queries to elicit real-valued user ratings on a common set of items and applies principal component analysis (PCA) to the resulting dense subset of the ratings matrix. PCA facilitates dimensionality reduction for offline clustering of users and rapid computation of recommendations. For a database of n users, standard nearest-neighbor techniques require O(n) processing time to compute recommendations, whereas Eigentaste requires O(1) (constant) time. We compare Eigentaste to alternative algorithms using data from Jester, an online joke recommending system.Jester has collected approximately 2,500,000 ratings from 57,000 users. We use the Normalized Mean Absolute Error (NMAE) measure to compare performance of different algorithms. In the Appendix we use Uniform and Normal distribution models to derive analytic …",
        "year": 2001,
        "authors": "Ken Goldberg and Theresa Roeder and Dhruv Gupta and Chris Perkins"
      },
      {
        "title": "Dex-net 2.0: Deep learning to plan robust grasps with synthetic point clouds and analytic grasp metrics",
        "abstract": "To reduce data collection time for deep learning of robust robotic grasp plans, we explore training from a synthetic dataset of 6.7 million point clouds, grasps, and analytic grasp metrics generated from thousands of 3D models from Dex-Net 1.0 in randomized poses on a table. We use the resulting dataset, Dex-Net 2.0, to train a Grasp Quality Convolutional Neural Network (GQ-CNN) model that rapidly predicts the probability of success of grasps from depth images, where grasps are specified as the planar position, angle, and depth of a gripper relative to an RGB-D sensor. Experiments with over 1,000 trials on an ABB YuMi comparing grasp planning methods on singulated objects suggest that a GQ-CNN trained with only synthetic data from Dex-Net 2.0 can be used to plan grasps in 0.8sec with a success rate of 93% on eight known objects with adversarial geometry and is 3x faster than registering point clouds to a precomputed dataset of objects and indexing grasps. The Dex-Net 2.0 grasp planner also has the highest success rate on a dataset of 10 novel rigid objects and achieves 99% precision (one false positive out of 69 grasps classified as robust) on a dataset of 40 novel household objects, some of which are articulated or deformable. Code, datasets, videos, and supplementary material are available at http://berkeleyautomation.github.io/dex-net .",
        "year": 2017,
        "authors": "Jeffrey Mahler and Jacky Liang and Sherdil Niyaz and Michael Laskey and Richard Doan and Xinyu Liu and Juan Aparicio Ojea and Ken Goldberg"
      },
      {
        "title": "RLlib: Abstractions for distributed reinforcement learning",
        "abstract": "Reinforcement learning (RL) algorithms involve the deep nesting of highly irregular computation patterns, each of which typically exhibits opportunities for distributed computation. We argue for distributing RL components in a composable way by adapting algorithms for top-down hierarchical control, thereby encapsulating parallelism and resource requirements within short-running compute tasks. We demonstrate the benefits of this principle through RLlib: a library that provides scalable software primitives for RL. These primitives enable a broad range of algorithms to be implemented with high performance, scalability, and substantial code reuse. RLlib is available as part of the open source Ray project at http://rllib. io/.",
        "year": 2018,
        "authors": "Eric Liang and Richard Liaw and Robert Nishihara and Philipp Moritz and Roy Fox and Ken Goldberg and Joseph Gonzalez and Michael Jordan and Ion Stoica"
      }
    ],
    "ZcWO2AEAAAAJ": [
      {
        "title": "Removing camera shake from a single photograph",
        "abstract": "Camera shake during exposure leads to objectionable image blur and ruins many photographs. Conventional blind deconvolution methods typically assume frequency-domain constraints on images, or overly simplified parametric forms for the motion path during camera shake. Real camera motions can follow convoluted paths, and a spatial domain prior can better maintain visually salient image characteristics. We introduce a method to remove the effects of camera shake from seriously blurred images. The method assumes a uniform camera blur over the image and negligible in-plane camera rotation. In order to estimate the blur from the camera shake, the user must specify an image region without saturation effects. We show results for a variety of digital photographs taken from personal photo collections.",
        "year": 2006,
        "authors": "Rob Fergus and Barun Singh and Aaron Hertzmann and Sam T Roweis and William T Freeman"
      },
      {
        "title": "Gaussian Process Dynamical Models for Human Motion",
        "abstract": "We introduce Gaussian process dynamical models (GPDMs) for nonlinear time series analysis, with applications to learning models of human pose and motion from high-dimensional motion capture data. A GPDM is a latent variable model. It comprises a low-dimensional latent space with associated dynamics, as well as a map from the latent space to an observation space. We marginalize out the model parameters in closed form by using Gaussian process priors for both the dynamical and the observation mappings. This results in a nonparametric model for dynamical systems that accounts for uncertainty in the model. We demonstrate the approach and compare four learning algorithms on human motion capture data, in which each pose is 50-dimensional. Despite the use of small data sets, the GPDM learns an effective representation of the nonlinear dynamics in these spaces.",
        "year": 2008,
        "authors": "JM Wang and DJ Fleet and A Hertzmann"
      }
    ],
    "Ob0bNAUAAAAJ": [
      {
        "title": "Guided online distillation: Promoting safe reinforcement learning by offline demonstration",
        "abstract": "Safe Reinforcement Learning (RL) aims to find a policy that achieves high rewards while satisfying cost constraints. When learning from scratch, safe RL agents tend to be overly conservative, which impedes exploration and restrains the overall performance. In many realistic tasks, e.g. autonomous driving, large-scale expert demonstration data are available. We argue that extracting expert policy from offline data to guide online exploration is a promising solution to mitigate the conserveness issue. Large-capacity models, e.g. decision transformers (DT), have been proven to be competent in offline policy learning. However, data collected in realworld scenarios rarely contain dangerous cases (e.g., collisions), which makes it prohibitive for the policies to learn safety concepts. Besides, these bulk policy networks cannot meet the computation speed requirements at inference time on real-world tasks such as …",
        "year": 2024,
        "authors": "Jinning Li and Xinyi Liu and Banghua Zhu and Jiantao Jiao and Masayoshi Tomizuka and Chen Tang and Wei Zhan"
      },
      {
        "title": "SplaTraj: Camera Trajectory Generation with Semantic Gaussian Splatting",
        "abstract": "Many recent developments for robots to represent environments have focused on photorealistic reconstructions. This paper particularly focuses on generating sequences of images from the photorealistic Gaussian Splatting models, that match instructions that are given by user-inputted language. We contribute a novel framework, SplaTraj, which formulates the generation of images within photorealistic environment representations as a continuous-time trajectory optimization problem. Costs are designed so that a camera following the trajectory poses will smoothly traverse through the environment and render the specified spatial information in a photogenic manner. This is achieved by querying a photorealistic representation with language embedding to isolate regions that correspond to the user-specified inputs. These regions are then projected to the camera's view as it moves over time and a cost is constructed. We can then apply gradient-based optimization and differentiate through the rendering to optimize the trajectory for the defined cost. The resulting trajectory moves to photogenically view each of the specified objects. We empirically evaluate our approach on a suite of environments and instructions, and demonstrate the quality of generated image sequences.",
        "year": 2024,
        "authors": "Xinyi Liu and Tianyi Zhang and Matthew Johnson-Roberson and Weiming Zhi"
      },
      {
        "title": "Predicting Sagittal-Plane Swing Hip Kinematics in Response to Trips",
        "abstract": "State-of-the-art wearable lower-limb robot controllers typically use established baseline human kinematics during common mobility tasks. Unfortunately due to the variability in human response during perturbations, these lower-limb controllers are unable to effectively assist with perturbation recovery. Accurate and quick predictions of kinematic responses to unexpected disturbances during motion can help assistive robotic devices safely aid with an individual’s recovery. This paper presents three methods for predicting swing hip kinematics during trip recovery: a Gaussian process regression (GPR) model; a time-series neural network; and a pendulum model with linear feedback. Data were collected in an experiment where 16 subjects were tripped at random percentages of swing phase. The three prediction methods were applied to these data and evaluated for simulation accuracy and computation time. Both …",
        "year": 2022,
        "authors": "Shannon M Danforth and Xinyi Liu and Martin J Ward and Patrick D Holmes and Ram Vasudevan"
      }
    ],
    "ckZ7q_gAAAAJ": [
      {
        "title": "Octo: An open-source generalist robot policy",
        "abstract": "Large policies pretrained on diverse robot datasets have the potential to transform robotic learning: instead of training new policies from scratch, such generalist robot policies may be finetuned with only a little in-domain data, yet generalize broadly. However, to be widely applicable across a range of robotic learning scenarios, environments, and tasks, such policies need to handle diverse sensors and action spaces, accommodate a variety of commonly used robotic platforms, and finetune readily and efficiently to new domains. In this work, we aim to lay the groundwork for developing open-source, widely applicable, generalist policies for robotic manipulation. As a first step, we introduce Octo, a large transformer-based policy trained on 800k trajectories from the Open X-Embodiment dataset, the largest robot manipulation dataset to date. It can be instructed via language commands or goal images and can be effectively finetuned to robot setups with new sensory inputs and action spaces within a few hours on standard consumer GPUs. In experiments across 9 robotic platforms, we demonstrate that Octo serves as a versatile policy initialization that can be effectively finetuned to new observation and action spaces. We also perform detailed ablations of design decisions for the Octo model, from architecture to training data, to guide future research on building generalist robot models.",
        "year": 2024,
        "authors": "Octo Model Team and Dibya Ghosh and Homer Walke and Karl Pertsch and Kevin Black and Oier Mees and Sudeep Dasari and Joey Hejna and Tobias Kreiman and Charles Xu and Jianlan Luo and You Liang Tan and Lawrence Yunliang Chen and Pannag Sanketi and Quan Vuong and Ted Xiao and Dorsa Sadigh and Chelsea Finn and Sergey Levine"
      },
      {
        "title": "Octo: An open-source generalist robot policy",
        "abstract": "Octo: An Open-Source Generalist Robot Policy | OpenReview OpenReview.net Login back arrow \nGo to DBLP homepage Octo: An Open-Source Generalist Robot Policy Open Webpage Dibya \nGhosh, Homer Rich Walke, Karl Pertsch, Kevin Black, Oier Mees, Sudeep Dasari, Joey Hejna, \nTobias Kreiman, Charles Xu, Jianlan Luo, You Liang Tan, Lawrence Yunliang Chen, Quan \nVuong, Ted Xiao, Pannag R. Sanketi, Dorsa Sadigh, Chelsea Finn, Sergey Levine Published: \n01 Jan 2024, Last Modified: 23 Mar 2025Robotics: Science and Systems 2024Everyone\nRevisionsBibTeXCC BY-SA 4.0 Loading About OpenReview Hosting a Venue All Venues \nContact Feedback Sponsors Join the Team Frequently Asked Questions Terms of Use Privacy \nPolicy About OpenReview Hosting a Venue All Venues Sponsors Join the Team Frequently \nAsked Questions Contact Feedback Terms of Use Privacy Policy OpenReview is a long-…",
        "year": 2024,
        "authors": "Dibya Ghosh and Homer Rich Walke and Karl Pertsch and Kevin Black and Oier Mees and Sudeep Dasari and Joey Hejna and Tobias Kreiman and Charles Xu and Jianlan Luo and You Liang Tan and Lawrence Yunliang Chen and Quan Vuong and Ted Xiao and Pannag R Sanketi and Dorsa Sadigh and Chelsea Finn and Sergey Levine"
      },
      {
        "title": "Serl: A software suite for sample-efficient robotic reinforcement learning",
        "abstract": "In recent years, significant progress has been made in the field of robotic reinforcement learning (RL), enabling methods that handle complex image observations, train in the real world, and incorporate auxiliary data, such as demonstrations and prior experience. However, despite these advances, robotic RL remains hard to use. It is acknowledged among practitioners that the particular implementation details of these algorithms are often just as important (if not more so) for performance as the choice of algorithm. We posit that a significant challenge to the widespread adoption of robotic RL, as well as the further development of robotic RL methods, is the comparative inaccessibility of such methods. To address this challenge, we developed a carefully implemented library containing a sample efficient off-policy deep RL method, together with methods for computing rewards and resetting the environment, a high …",
        "year": 2024,
        "authors": "Jianlan Luo and Zheyuan Hu and Charles Xu and You Liang Tan and Jacob Berg and Archit Sharma and Stefan Schaal and Chelsea Finn and Abhishek Gupta and Sergey Levine"
      }
    ],
    "TmWYBeEAAAAJ": [
      {
        "title": "Long-term recurrent convolutional networks for visual recognition and description",
        "abstract": "Models comprised of deep convolutional network layers have dominated recent image interpretation tasks; we investigate whether models which are also compositional, or\" deep\", temporally are effective on tasks involving visual sequences or label sequences. We develop a novel recurrent convolutional architecture suitable for large-scale visual learning which is end-to-end trainable, and demonstrate the value of these models on benchmark video recognition tasks, image to sentence generation problems, and video narration challenges. In contrast to current models which assume a fixed spatio-temporal receptive field or simple temporal averaging for sequential processing, recurrent convolutional models are\" doubly deep\" in that they can be compositional in spatial and temporal\" layers\". Such models may have advantages when target concepts are complex and/or training data are limited. Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. Long-term RNN models are appealing in that they directly can map variable length inputs (ie video frames) to variable length outputs (ie natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent long-term models are directly connected to state-of-the-art visual convnet models and can jointly trained, updating temporal dynamics and convolutional perceptual representations simultaneously. Our results show such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined and/or optimized.",
        "year": 2015,
        "authors": "Jeffrey Donahue and Lisa Anne Hendricks and Sergio Guadarrama and Marcus Rohrbach and Subhashini Venugopalan and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs",
        "abstract": "Deep learning is a family of computational methods that allow an algorithm to program itself by learning from a large set of examples that demonstrate the desired behavior, removing the need to specify rules explicitly. Application of these methods to medical imaging requires further assessment and validation.To apply deep learning to create an algorithm for automated detection of diabetic retinopathy and diabetic macular edema in retinal fundus photographs.A specific type of neural network optimized for image classification called a deep convolutional neural network was trained using a retrospective development data set of 128 175 retinal images, which were graded 3 to 7 times for diabetic retinopathy, diabetic macular edema, and image gradability by a panel of 54 US licensed ophthalmologists and ophthalmology senior residents between May and December 2015 …",
        "year": 2016,
        "authors": "Varun Gulshan and Lily Peng and Marc Coram and Martin C Stumpe and Derek Wu and Arunachalam Narayanaswamy and Subhashini Venugopalan and Kasumi Widner and Tom Madams and Jorge Cuadros and Ramasamy Kim and Rajiv Raman and Philip C Nelson and Jessica L Mega and Dale R Webster"
      },
      {
        "title": "Sequence to sequence-video to text",
        "abstract": "Real-world videos often have complex dynamics; methods for generating open-domain video descriptions should be senstive to temporal structure and allow both input (sequence of frames) and output (sequence of words) of variable length. To approach this problem we propose a novel end-to-end sequence-to-sequence model to generate captions for videos. For this we exploit recurrent neural networks, specifically LSTMs, which have demonstrated state-of-the-art performance in image caption generation. Our LSTM model is trained on video-sentence pairs and learns to associate a sequence of video frames to a sequence of words in order to generate a description of the event in the video clip. Our model naturally is able to learn the temporal structure of the sequence of frames as well as the sequence model of the generated sentences, ie a language model. We evaluate several variants of our model that exploit different visual features on a standard set of YouTube videos and two movie description datasets (M-VAD and MPII-MD).",
        "year": 2015,
        "authors": "Subhashini Venugopalan and Marcus Rohrbach and Jeffrey Donahue and Raymond Mooney and Trevor Darrell and Kate Saenko"
      }
    ],
    "3XLQbL8AAAAJ": [
      {
        "title": "Linear matrix inequalities in system and control theory",
        "abstract": "The basic topic of this book is solving problems from system and control theory using convex optimization. We show that a wide variety of problems arising in system and control theory can be reduced to a handful of standard convex and quasiconvex optimization problems that involve matrix inequalities. For a few special cases there are “analytic solutions” to these problems, but our main point is that they can be solved numerically in all cases. These standard problems can be solved in polynomial-time (by, e.g., the ellipsoid algorithm of Shor, Nemirovskii, and Yudin), and so are tractable, at least in a theoretical sense. Recently developed interior-point methods for these standard problems have been found to be extremely efficient in practice. Therefore, we consider the original problems from system and control theory as solved.This book is primarily intended for the researcher in system and control theory, but can …",
        "year": 1994,
        "authors": "Stephen Boyd and Laurent El Ghaoui and Eric Feron and Venkataramanan Balakrishnan"
      },
      {
        "title": "Robust optimization",
        "abstract": "To be uncertain is to be uncomfortable, but to be certain is to be ridiculous. Chinese proverb",
        "year": 2009,
        "authors": "Aharon Ben-Tal and Arkadi Nemirovski and Laurent El Ghaoui"
      },
      {
        "title": "Theoretically principled trade-off between robustness and accuracy",
        "abstract": "We identify a trade-off between robustness and accuracy that serves as a guiding principle in the design of defenses against adversarial examples. Although this problem has been widely studied empirically, much remains unknown concerning the theory underlying this trade-off. In this work, we decompose the prediction error for adversarial examples (robust error) as the sum of the natural (classification) error and boundary error, and provide a differentiable upper bound using the theory of classification-calibrated loss, which is shown to be the tightest possible upper bound uniform over all probability distributions and measurable predictors. Inspired by our theoretical analysis, we also design a new defense method, TRADES, to trade adversarial robustness off against accuracy. Our proposed algorithm performs well experimentally in real-world datasets. The methodology is the foundation of our entry to the NeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of 2,000 submissions, surpassing the runner-up approach by 11.41% in terms of mean L_2 perturbation distance.",
        "year": 2019,
        "authors": "Hongyang Zhang and Yaodong Yu and Jiantao Jiao and Eric Xing and Laurent El Ghaoui and Michael Jordan"
      }
    ],
    "KcPrLhIAAAAJ": [
      {
        "title": "Jump-start reinforcement learning",
        "abstract": "Reinforcement learning (RL) provides a theoretical framework for continuously improving an agent’s behavior via trial and error. However, efficiently learning policies from scratch can be very difficult, particularly for tasks that present exploration challenges. In such settings, it might be desirable to initialize RL with an existing policy, offline data, or demonstrations. However, naively performing such initialization in RL often works poorly, especially for value-based methods. In this paper, we present a meta algorithm that can use offline data, demonstrations, or a pre-existing policy to initialize an RL policy, and is compatible with any RL approach. In particular, we propose Jump-Start Reinforcement Learning (JSRL), an algorithm that employs two policies to solve tasks: a guide-policy, and an exploration-policy. By using the guide-policy to form a curriculum of starting states for the exploration-policy, we are able to efficiently improve performance on a set of simulated robotic tasks. We show via experiments that it is able to significantly outperform existing imitation and reinforcement learning algorithms, particularly in the small-data regime. In addition, we provide an upper bound on the sample complexity of JSRL and show that with the help of a guide-policy, one can improve the sample complexity for non-optimism exploration methods from exponential in horizon to polynomial.",
        "year": 2023,
        "authors": "Ikechukwu Uchendu and Ted Xiao and Yao Lu and Banghua Zhu and Mengyuan Yan and Joséphine Simon and Matthew Bennice and Chuyuan Fu and Cong Ma and Jiantao Jiao and Sergey Levine and Karol Hausman"
      },
      {
        "title": "Scalable diagnostic screening of mild cognitive impairment using AI dialogue agent",
        "abstract": "The search for early biomarkers of mild cognitive impairment (MCI) has been central to the Alzheimer’s Disease (AD) and dementia research community in recent years. To identify MCI status at the earliest possible point, recent studies have shown that linguistic markers such as word choice, utterance and sentence structures can potentially serve as preclinical behavioral markers. Here we present an adaptive dialogue algorithm (an AI-enabled dialogue agent) to identify sequences of questions (a dialogue policy) that distinguish MCI from normal (NL) cognitive status. Our AI agent adapts its questioning strategy based on the user’s previous responses to reach an individualized conversational strategy per user. Because the AI agent is adaptive and scales favorably with additional data, our method provides a potential avenue for large-scale preclinical screening of neurocognitive decline as a new digital biomarker …",
        "year": 2020,
        "authors": "Fengyi Tang and Ikechukwu Uchendu and Fei Wang and Hiroko H Dodge and Jiayu Zhou"
      },
      {
        "title": "Archgym: An open-source gymnasium for machine learning assisted architecture design",
        "abstract": "Machine learning (ML) has become a prevalent approach to tame the complexity of design space exploration for domain-specific architectures. While appealing, using ML for design space exploration poses several challenges. First, it is not straightforward to identify the most suitable algorithm from an ever-increasing pool of ML methods. Second, assessing the trade-offs between performance and sample efficiency across these methods is inconclusive. Finally, the lack of a holistic framework for fair, reproducible, and objective comparison across these methods hinders the progress of adopting ML-aided architecture design space exploration and impedes creating repeatable artifacts. To mitigate these challenges, we introduce ArchGym, an open-source gymnasium and easy-to-extend framework that connects a diverse range of search algorithms to architecture simulators. To demonstrate its utility, we evaluate …",
        "year": 2023,
        "authors": "Srivatsan Krishnan and Amir Yazdanbakhsh and Shvetank Prakash and Jason Jabbour and Ikechukwu Uchendu and Susobhan Ghosh and Behzad Boroujerdian and Daniel Richins and Devashree Tripathy and Aleksandra Faust and Vijay Janapa Reddi"
      }
    ],
    "AIy7QHIAAAAJ": [
      {
        "title": "Fedml: A research library and benchmark for federated machine learning",
        "abstract": "Federated learning (FL) is a rapidly growing research field in machine learning. However, existing FL libraries cannot adequately support diverse algorithmic development; inconsistent dataset and model usage make fair algorithm comparison challenging. In this work, we introduce FedML, an open research library and benchmark to facilitate FL algorithm development and fair performance comparison. FedML supports three computing paradigms: on-device training for edge devices, distributed computing, and single-machine simulation. FedML also promotes diverse algorithmic research with flexible and generic API design and comprehensive reference baseline implementations (optimizer, models, and datasets). We hope FedML could provide an efficient and reproducible means for developing and evaluating FL algorithms that would benefit the FL research community. We maintain the source code, documents, and user community at https://fedml.ai.",
        "year": 2020,
        "authors": "Chaoyang He and Songze Li and Jinhyun So and Xiao Zeng and Mi Zhang and Hongyi Wang and Xiaoyang Wang and Praneeth Vepakomma and Abhishek Singh and Hang Qiu and Xinghua Zhu and Jianzong Wang and Li Shen and Peilin Zhao and Yan Kang and Yang Liu and Ramesh Raskar and Qiang Yang and Murali Annavaram and Salman Avestimehr"
      },
      {
        "title": "Turbo-aggregate: Breaking the quadratic aggregation barrier in secure federated learning",
        "abstract": "Federated learning is a distributed framework for training machine learning models over the data residing at mobile devices, while protecting the privacy of individual users. A major bottleneck in scaling federated learning to a large number of users is the overhead of secure model aggregation across many users. In particular, the overhead of the state-of-the-art protocols for secure model aggregation grows quadratically with the number of users. In this article, we propose the first secure aggregation framework, named Turbo-Aggregate, that in a network with N users achieves a secure aggregation overhead of O(NlogN), as opposed to O(N2), while tolerating up to a user dropout rate of 50%. Turbo-Aggregate employs a multi-group circular strategy for efficient model aggregation, and leverages additive secret sharing and novel coding techniques for injecting aggregation redundancy in order to handle user dropouts …",
        "year": 2021,
        "authors": "Jinhyun So and Başak Güler and A Salman Avestimehr"
      },
      {
        "title": "Byzantine-resilient secure federated learning",
        "abstract": "Secure federated learning is a privacy-preserving framework to improve machine learning models by training over large volumes of data collected by mobile users. This is achieved through an iterative process where, at each iteration, users update a global model using their local datasets. Each user then masks its local update via random keys, and the masked models are aggregated at a central server to compute the global model for the next iteration. As the local updates are protected by random masks, the server cannot observe their true values. This presents a major challenge for the resilience of the model against adversarial (Byzantine) users, who can manipulate the global model by modifying their local updates or datasets. Towards addressing this challenge, this paper presents the first single-server Byzantine-resilient secure aggregation framework (BREA) for secure federated learning. BREA is based on …",
        "year": 2021,
        "authors": "Jinhyun So and Başak Güler and A Salman Avestimehr"
      }
    ],
    "EjtpMaoAAAAJ": [
      {
        "title": "Storm@ twitter",
        "abstract": "This paper describes the use of Storm at Twitter. Storm is a real-time fault-tolerant and distributed stream data processing system. Storm is currently being used to run various critical computations in Twitter at scale, and in real-time. This paper describes the architecture of Storm and its methods for distributed scale-out and fault-tolerance. This paper also describes how queries (aka. topologies) are executed in Storm, and presents some operational stories based on running Storm at Twitter. We also present results from an empirical evaluation demonstrating the resilience of Storm in dealing with machine failures. Storm is under active development at Twitter and we also present some potential directions for future work.",
        "year": 2014,
        "authors": "Ankit Toshniwal and Siddarth Taneja and Amit Shukla and Karthik Ramasamy and Jignesh M Patel and Sanjeev Kulkarni and Jason Jackson and Krishna Gade and Maosong Fu and Jake Donham and Nikunj Bhagat and Sailesh Mittal and Dmitriy Ryaboy"
      },
      {
        "title": "Earlybird: Real-time search at twitter",
        "abstract": "The web today is increasingly characterized by social and real-time signals, which we believe represent two frontiers in information retrieval. In this paper, we present Early bird, the core retrieval engine that powers Twitter's real-time search service. Although Early bird builds and maintains inverted indexes like nearly all modern retrieval engines, its index structures differ from those built to support traditional web search. We describe these differences and present the rationale behind our design. A key requirement of real-time search is the ability to ingest content rapidly and make it searchable immediately, while concurrently supporting low-latency, high-throughput query evaluation. These demands are met with a single-writer, multiple-reader concurrency model and the targeted use of memory barriers. Early bird represents a point in the design space of real-time search engines that has worked well for Twitter's …",
        "year": 2012,
        "authors": "Michael Busch and Krishna Gade and Brian Larson and Patrick Lok and Samuel Luckenbill and Jimmy Lin"
      },
      {
        "title": "Explainable AI in industry",
        "abstract": "Artificial Intelligence is increasingly playing an integral role in determining our day-to-day experiences. Moreover, with proliferation of AI based solutions in areas such as hiring, lending, criminal justice, healthcare, and education, the resulting personal and professional implications of AI are far-reaching. The dominant role played by AI models in these domains has led to a growing concern regarding potential bias in these models, and a demand for model transparency and interpretability. In addition, model explainability is a prerequisite for building trust and adoption of AI systems in high stakes domains requiring reliability and safety such as healthcare and automated transportation, and critical industrial applications with significant economic implications such as predictive maintenance, exploration of natural resources, and climate change modeling.As a consequence, AI researchers and practitioners have …",
        "year": 2019,
        "authors": "Krishna Gade and Sahin Cem Geyik and Krishnaram Kenthapadi and Varun Mithal and Ankur Taly"
      }
    ],
    "qlwwdfEAAAAJ": [
      {
        "title": "Offline reinforcement learning as one big sequence modeling problem",
        "abstract": "Reinforcement learning (RL) is typically viewed as the problem of estimating single-step policies (for model-free RL) or single-step models (for model-based RL), leveraging the Markov property to factorize the problem in time. However, we can also view RL as a sequence modeling problem: predict a sequence of actions that leads to a sequence of high rewards. Viewed in this way, it is tempting to consider whether powerful, high-capacity sequence prediction models that work well in other supervised learning domains, such as natural-language processing, can also provide simple and effective solutions to the RL problem. To this end, we explore how RL can be reframed as\" one big sequence modeling\" problem, using state-of-the-art Transformer architectures to model distributions over sequences of states, actions, and rewards. Addressing RL as a sequence modeling problem significantly simplifies a range of design decisions: we no longer require separate behavior policy constraints, as is common in prior work on offline model-free RL, and we no longer require ensembles or other epistemic uncertainty estimators, as is common in prior work on model-based RL. All of these roles are filled by the same Transformer sequence model. In our experiments, we demonstrate the flexibility of this approach across imitation learning, goal-conditioned RL, and offline RL.",
        "year": 2021,
        "authors": "Michael Janner and Qiyang Li and Sergey Levine"
      },
      {
        "title": "Openeqa: Embodied question answering in the era of foundation models",
        "abstract": "We present a modern formulation of Embodied Question Answering (EQA) as the task of understanding an environment well enough to answer questions about it in natural language. An agent can achieve such an understanding by either drawing upon episodic memory exemplified by agents on smart glasses or by actively exploring the environment as in the case of mobile robots. We accompany our formulation with OpenEQA--the first open-vocabulary benchmark dataset for EQA supporting both episodic memory and active exploration use cases. OpenEQA contains over 1600 high-quality human generated questions drawn from over 180 real-world environments. In addition to the dataset we also provide an automatic LLM-powered evaluation protocol that has excellent correlation with human judgement. Using this dataset and evaluation protocol we evaluate several state-of-the-art foundation models including GPT-4V and find that they significantly lag behind human-level performance. Consequently OpenEQA stands out as a straightforward measurable and practically relevant benchmark that poses a considerable challenge to current generation of foundation models. We hope this inspires and stimulates future research at the intersection of Embodied AI conversational agents and world models.",
        "year": 2024,
        "authors": "Arjun Majumdar and Anurag Ajay and Xiaohan Zhang and Pranav Putta and Sriram Yenamandra and Mikael Henaff and Sneha Silwal and Paul Mcvay and Oleksandr Maksymets and Sergio Arnaud and Karmesh Yadav and Qiyang Li and Ben Newman and Mohit Sharma and Vincent Berges and Shiqi Zhang and Pulkit Agrawal and Yonatan Bisk and Dhruv Batra and Mrinal Kalakrishnan and Franziska Meier and Chris Paxton and Alexander Sax and Aravind Rajeswaran"
      },
      {
        "title": "Timbretron: A wavenet (cyclegan (cqt (audio))) pipeline for musical timbre transfer",
        "abstract": "In this work, we address the problem of musical timbre transfer, where the goal is to manipulate the timbre of a sound sample from one instrument to match another instrument while preserving other musical content, such as pitch, rhythm, and loudness. In principle, one could apply image-based style transfer techniques to a time-frequency representation of an audio signal, but this depends on having a representation that allows independent manipulation of timbre as well as high-quality waveform generation. We introduce TimbreTron, a method for musical timbre transfer which applies \"image\" domain style transfer to a time-frequency representation of the audio signal, and then produces a high-quality waveform using a conditional WaveNet synthesizer. We show that the Constant Q Transform (CQT) representation is particularly well-suited to convolutional architectures due to its approximate pitch equivariance. Based on human perceptual evaluations, we confirmed that TimbreTron recognizably transferred the timbre while otherwise preserving the musical content, for both monophonic and polyphonic samples.",
        "year": 2018,
        "authors": "Sicong Huang and Qiyang Li and Cem Anil and Xuchan Bao and Sageev Oore and Roger B Grosse"
      }
    ],
    "1M79iLwAAAAJ": [
      {
        "title": "Chatbot arena: An open platform for evaluating llms by human preference",
        "abstract": "Large Language Models (LLMs) have unlocked new capabilities and applications; however, evaluating the alignment with human preferences still poses significant challenges. To address this issue, we introduce Chatbot Arena, an open platform for evaluating LLMs based on human preferences. Our methodology employs a pairwise comparison approach and leverages input from a diverse user base through crowdsourcing. The platform has been operational for several months, amassing over 240K votes. This paper describes the platform, analyzes the data we have collected so far, and explains the tried-and-true statistical methods we are using for efficient and accurate evaluation and ranking of models. We confirm that the crowdsourced questions are sufficiently diverse and discriminating and that the crowd-sourced human votes are in good agreement with those of expert raters. These analyses collectively establish a robust foundation for the credibility of Chatbot Arena. Because of its unique value and openness, Chatbot Arena has emerged as one of the most referenced LLM leaderboards, widely cited by leading LLM developers and companies. The platform is publicly available at https://chat.lmsys.org.",
        "year": 2024,
        "authors": "Wei-Lin Chiang and Lianmin Zheng and Ying Sheng and Anastasios Nikolas Angelopoulos and Tianle Li and Dacheng Li and Banghua Zhu and Hao Zhang and Michael Jordan and Joseph E Gonzalez and Ion Stoica"
      },
      {
        "title": "Lmsys-chat-1m: A large-scale real-world llm conversation dataset",
        "abstract": "Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is publicly available at https://huggingface.co/datasets/lmsys/lmsys-chat-1m.",
        "year": 2023,
        "authors": "Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Tianle Li and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zhuohan Li and Zi Lin and Eric P Xing and Joseph E Gonzalez and Ion Stoica and Hao Zhang"
      },
      {
        "title": "From crowdsourced data to high-quality benchmarks: Arena-hard and benchbuilder pipeline",
        "abstract": "The rapid evolution of Large Language Models (LLMs) has outpaced the development of model evaluation, highlighting the need for continuous curation of new, challenging benchmarks. However, manual curation of high-quality, human-aligned benchmarks is expensive and time-consuming. To address this, we introduce BenchBuilder, an automated pipeline that leverages LLMs to curate high-quality, open-ended prompts from large, crowd-sourced datasets, enabling continuous benchmark updates without human in the loop. We apply BenchBuilder to datasets such as Chatbot Arena and WildChat-1M, extracting challenging prompts and utilizing LLM-as-a-Judge for automatic model evaluation. To validate benchmark quality, we propose new metrics to measure a benchmark's alignment with human preferences and ability to separate models. We release Arena-Hard-Auto, a benchmark consisting 500 challenging prompts curated by BenchBuilder. Arena-Hard-Auto provides 3x higher separation of model performances compared to MT-Bench and achieves 98.6% correlation with human preference rankings, all at a cost of $20. Our work sets a new framework for the scalable curation of automated benchmarks from extensive data.",
        "year": 2024,
        "authors": "Tianle Li and Wei-Lin Chiang and Evan Frick and Lisa Dunlap and Tianhao Wu and Banghua Zhu and Joseph E Gonzalez and Ion Stoica"
      }
    ],
    "no_BfYgAAAAJ": [
      {
        "title": "Wasserstein fair classification",
        "abstract": "We propose an approach to fair classification that enforces independence between the classifier outputs and sensitive information by minimizing Wasserstein-1 distances. The approach has desirable theoretical properties and is robust to specific choices of the threshold used to obtain class predictions from model outputs. We introduce different methods that enable hid-ing sensitive information at test time or have a simple and fast implementation. We show empirical performance against different fair-ness baselines on several benchmark fairness datasets.",
        "year": 2020,
        "authors": "Ray Jiang and Aldo Pacchiano and Tom Stepleton and Heinrich Jiang and Silvia Chiappa"
      },
      {
        "title": "Effective diversity in population based reinforcement learning",
        "abstract": "Exploration is a key problem in reinforcement learning, since agents can only learn from data they acquire in the environment. With that in mind, maintaining a population of agents is an attractive method, as it allows data be collected with a diverse set of behaviors. This behavioral diversity is often boosted via multi-objective loss functions. However, those approaches typically leverage mean field updates based on pairwise distances, which makes them susceptible to cycling behaviors and increased redundancy. In addition, explicitly boosting diversity often has a detrimental impact on optimizing already fruitful behaviors for rewards. As such, the reward-diversity trade off typically relies on heuristics. Finally, such methods require behavioral representations, often handcrafted and domain specific. In this paper, we introduce an approach to optimize all members of a population simultaneously. Rather than using pairwise distance, we measure the volume of the entire population in a behavioral manifold, defined by task-agnostic behavioral embeddings. In addition, our algorithm Diversity via Determinants (DvD), adapts the degree of diversity during training using online learning techniques. We introduce both evolutionary and gradient-based instantiations of DvD and show they effectively improve exploration without reducing performance when better exploration is not required.",
        "year": 2020,
        "authors": "Jack Parker-Holder and Aldo Pacchiano and Krzysztof M Choromanski and Stephen J Roberts"
      },
      {
        "title": "Es-maml: Simple hessian-free meta learning",
        "abstract": "We introduce ES-MAML, a new framework for solving the model agnostic meta learning (MAML) problem based on Evolution Strategies (ES). Existing algorithms for MAML are based on policy gradients, and incur significant difficulties when attempting to estimate second derivatives using backpropagation on stochastic policies. We show how ES can be applied to MAML to obtain an algorithm which avoids the problem of estimating second derivatives, and is also conceptually simple and easy to implement. Moreover, ES-MAML can handle new types of nonsmooth adaptation operators, and other techniques for improving performance and estimation of ES methods become applicable. We show empirically that ES-MAML is competitive with existing methods and often yields better adaptation with fewer queries.",
        "year": 2019,
        "authors": "Xingyou Song and Wenbo Gao and Yuxiang Yang and Krzysztof Choromanski and Aldo Pacchiano and Yunhao Tang"
      }
    ],
    "2k5j4eMAAAAJ": [
      {
        "title": "Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing",
        "abstract": "This article surveys and organizes research works in a new paradigm in natural language processing, which we dub “prompt-based learning.” Unlike traditional supervised learning, which trains a model to take in an input x and predict an output y as P(y|x), prompt-based learning is based on language models that model the probability of text directly. To use these models to perform prediction tasks, the original input x is modified using a template into a textual string prompt x′ that has some unfilled slots, and then the language model is used to probabilistically fill the unfilled information to obtain a final string x̂, from which the final output y can be derived. This framework is powerful and attractive for a number of reasons: It allows the language model to be pre-trained on massive amounts of raw text, and by defining a new prompting function the model is able to perform few-shot or even zero-shot learning, adapting …",
        "year": 2023,
        "authors": "Pengfei Liu and Weizhe Yuan and Jinlan Fu and Zhengbao Jiang and Hiroaki Hayashi and Graham Neubig"
      },
      {
        "title": "Bartscore: Evaluating generated text as text generation",
        "abstract": "A wide variety of NLP applications, such as machine translation, summarization, and dialog, involve text generation. One major challenge for these applications is how to evaluate whether such generated texts are actually fluent, accurate, or effective. In this work, we conceptualize the evaluation of generated text as a text generation problem, modeled using pre-trained sequence-to-sequence models. The general idea is that models trained to convert the generated text to/from a reference output or the source text will achieve higher scores when the generated text is better. We operationalize this idea using BART, an encoder-decoder based pre-trained model, and propose a metric BARTScore with a number of variants that can be flexibly applied in an unsupervised fashion to evaluation of text from different perspectives (eg informativeness, fluency, or factuality). BARTScore is conceptually simple and empirically effective. It can outperform existing top-scoring metrics in 16 of 22 test settings, covering evaluation of 16 datasets (eg, machine translation, text summarization) and 7 different perspectives (eg, informativeness, factuality). Code to calculate BARTScore is available at https://github. com/neulab/BARTScore, and we have released an interactive leaderboard for meta-evaluation at http://explainaboard. nlpedia. ai/leaderboard/task-meval/on the ExplainaBoard platform, which allows us to interactively understand the strengths, weaknesses, and complementarity of each metric.",
        "year": 2021,
        "authors": "Weizhe Yuan and Graham Neubig and Pengfei Liu"
      }
    ],
    "VbNwxKYAAAAJ": [
      {
        "title": "Spatio-temporal graph dual-attention network for multi-agent prediction and tracking",
        "abstract": "An effective understanding of the environment and accurate trajectory prediction of surrounding dynamic obstacles are indispensable for intelligent mobile systems (e.g., autonomous vehicles, social robots) to achieve safe and high-quality planning when they navigate in highly interactive and crowded scenarios. Due to the existence of frequent interactions and uncertainty in the scene evolution, it is desired for the prediction system to enable relational reasoning on different entities and provide a distribution of future trajectories for each agent. In this paper, we propose a generic generative neural system (called STG-DAT) for multi-agent trajectory prediction involving heterogeneous agents. The system takes a step forward to explicit interaction modeling by incorporating relational inductive biases with a dynamic graph representation and leverages both trajectory and scene context information. We also employ an …",
        "year": 2021,
        "authors": "Jiachen Li and Hengbo Ma and Zhihao Zhang and Jinning Li and Masayoshi Tomizuka"
      },
      {
        "title": "Hierarchical planning through goal-conditioned offline reinforcement learning",
        "abstract": "Offline Reinforcement learning (RL) has shown potent in many safe-critical tasks in robotics where exploration is risky and expensive. However, it still struggles to acquire skills in temporally extended tasks. In this paper, we study the problem of offline RL for temporally extended tasks. We propose a hierarchical planning framework, consisting of a low-level goal-conditioned RL policy and a high-level goal planner. The low-level policy is trained via offline RL. We improve the offline training to deal with out-of-distribution goals by a perturbed goal sampling process. The high-level planner selects intermediate sub-goals by taking advantages of model-based planning methods. It plans over future sub-goal sequences based on the learned value function of the low-level policy. We adopt a Conditional Variational Autoencoder to sample meaningful high-dimensional sub-goal candidates and to solve the high-level long …",
        "year": 2022,
        "authors": "Jinning Li and Chen Tang and Masayoshi Tomizuka and Wei Zhan"
      },
      {
        "title": "A safe hierarchical planning framework for complex driving scenarios based on reinforcement learning",
        "abstract": "Autonomous vehicles need to handle various traffic conditions and make safe and efficient decisions and maneuvers. However, on the one hand, a single optimization/sampling-based motion planner cannot efficiently generate safe trajectories in real time, particularly when there are many interactive vehicles near by. On the other hand, end-to-end learning methods cannot assure the safety of the outcomes. To address this challenge, we propose a hierarchical behavior planning framework with a set of low-level safe controllers and a high-level reinforcement learning algorithm (H-CtRL) as a coordinator for the low-level controllers. Safety is guaranteed by the low-level optimization/sampling-based controllers, while the high-level reinforcement learning algorithm makes H-CtRL an adaptive and efficient behavior planner. To train and test our proposed algorithm, we built a simulator that can reproduce traffic scenes …",
        "year": 2021,
        "authors": "Jinning Li and Liting Sun and Jianyu Chen and Masayoshi Tomizuka and Wei Zhan"
      }
    ],
    "rBJV6QUAAAAJ": [
      {
        "title": "Robotic vertical jumping agility via series-elastic power modulation",
        "abstract": "Several arboreal mammals have the ability to rapidly and repeatedly jump vertical distances of 2 m, starting from rest. We characterize this performance by a metric we call vertical jumping agility. Through basic kinetic relations, we show that this agility metric is fundamentally constrained by available actuator power. Although rapid high jumping is an important performance characteristic, the ability to control forces during stance also appears critical for sophisticated behaviors. The animal with the highest vertical jumping agility, the galago (Galago senegalensis), is known to use a power-modulating strategy to obtain higher peak power than that of muscle alone. Few previous robots have used series-elastic power modulation (achieved by combining series-elastic actuation with variable mechanical advantage), and because of motor power limits, the best current robot has a vertical jumping agility of only 55% of a …",
        "year": 2016,
        "authors": "Duncan W Haldane and Mark M Plecnik and Justin K Yim and Ronald S Fearing"
      },
      {
        "title": "Repetitive extreme-acceleration (14-g) spatial jumping with Salto-1P",
        "abstract": "In this work we present a new robotic system, Salto-1P, for exploring extreme jumping locomotion. Salto-1P weighs 0.098 kg, and has an active leg length of 14.4 cm. The robot is able to perform a standing vertical leap of 1.25 m, continuously hop to heights over 1 m, and jump over 2 m horizontally. Salto-1P uses aerodynamic thrusters and an inertial tail to control its attitude in the air. A linearized Raibert step controller was sufficient to enable unconstrained in-place hopping and forwards-backwards locomotion with external position feedback. We present studies of extreme jumping locomotion in which the robot spends just 7.7% of its time on the ground, experiencing accelerations of 14 times earth gravity in its stance phase. An experimentally collected dataset of 772 observed jumps was used to establish the range of achievable horizontal and vertical impulses for Salto-1P.",
        "year": 2017,
        "authors": "Duncan W Haldane and Justin K Yim and Ronald S Fearing"
      },
      {
        "title": "Animal-inspired design and aerodynamic stabilization of a hexapedal millirobot",
        "abstract": "The VelociRoACH is a 10 cm long, 30 gram hexapedal millirobot capable of running at 2.7 m/s, making it the fastest legged robot built to date, relative to scale. We present the design by dynamic similarity technique and the locomotion adaptations which have allowed for this highly dynamic performance. In addition, we demonstrate that rotational dynamics become critical for stability as the scale of a robotic system is reduced. We present a new method of experimental dynamic tuning for legged millirobots, aimed at finding stable limit cycles with minimal rotational energy. By implementing an aerodynamic rotational damper, we further reduced the rotational energy in the system, and demonstrated that stable limit cycles with lower rotational energy are more robust to disturbances. This method increased the stability of the system without detracting from forward speed.",
        "year": 2013,
        "authors": "Duncan W Haldane and Kevin C Peterson and Fernando L Garcia Bermudez and Ronald S Fearing"
      }
    ],
    "PkfChMgAAAAJ": [
      {
        "title": "A view of cloud computing",
        "abstract": "Clearing the clouds away from the true potential and obstacles posed by this computing capability.",
        "year": 2010,
        "authors": "Michael Armbrust and Armando Fox and Rean Griffith and Anthony D Joseph and Randy Katz and Andy Konwinski and Gunho Lee and David Patterson and Ariel Rabkin and Ion Stoica and Matei Zaharia"
      },
      {
        "title": "Above the clouds: A berkeley view of cloud computing",
        "abstract": "Cloud Computing, the long-held dream of computing as a utility, has the potential to transform a large part of the IT industry, making software even more attractive as a service and shaping the way IT hardware is designed and purchased. Developers with innovative ideas for new Internet services no longer require the large capital outlays in hardware to deploy their service or the human expense to operate it. They need not be concerned about overprovisioning for a service whose popularity does not meet their predictions, thus wasting costly resources, or underprovisioning for one that becomes wildly popular, thus missing potential customers and revenue. Moreover, companies with large batch-oriented tasks can get results as quickly as their programs can scale, since using 1000 servers for one hour costs no more than using one server for 1000 hours. This elasticity of resources, without paying a premium for large scale, is unprecedented in the history of IT.Cloud Computing refers to both the applications delivered as services over the Internet and the hardware and systems software in the datacenters that provide those services. The services themselves have long been referred to as Software as a Service (SaaS). The datacenter hardware and software is what we will call a Cloud. When a Cloud is made available in a pay-as-you-go manner to the general public, we call it a Public Cloud; the service being sold is Utility Computing. We use the term Private Cloud to refer to internal datacenters of a business or other organization, not made available to the general public. Thus, Cloud Computing is the sum of SaaS and Utility Computing, but does not …",
        "year": 2009,
        "authors": "Michael Armbrust and Armando Fox and Rean Griffith and Anthony D Joseph and Randy H Katz and Andrew Konwinski and Gunho Lee and David A Patterson and Ariel Rabkin and Ion Stoica and Matei Zaharia"
      },
      {
        "title": "A case for redundant arrays of inexpensive disks (RAID)",
        "abstract": "Increasing performance of CPUs and memories will be squandered if not matched by a similar performance increase in I/O. While the capacity of Single Large Expensive Disks (SLED) has grown rapidly, the performance improvement of SLED has been modest. Redundant Arrays of Inexpensive Disks (RAID), based on the magnetic disk technology developed for personal computers, offers an attractive alternative to SLED, promising improvements of an order of magnitude in performance, reliability, power consumption, and scalability. This paper introduces five levels of RAIDs, giving their relative cost/performance, and compares RAID to an IBM 3380 and a Fujitsu Super Eagle.",
        "year": 1988,
        "authors": "David A Patterson and Garth Gibson and Randy H Katz"
      }
    ],
    "l-la0GQAAAAJ": [
      {
        "title": "In-datacenter performance analysis of a tensor processing unit",
        "abstract": "Many architects believe that major improvements in cost-energy-performance must now come from domain-specific hardware. This paper evaluates a custom ASIC---called a Tensor Processing Unit (TPU) --- deployed in datacenters since 2015 that accelerates the inference phase of neural networks (NN). The heart of the TPU is a 65,536 8-bit MAC matrix multiply unit that offers a peak throughput of 92 TeraOps/second (TOPS) and a large (28 MiB) software-managed on-chip memory. The TPU's deterministic execution model is a better match to the 99th-percentile response-time requirement of our NN applications than are the time-varying optimizations of CPUs and GPUs that help average throughput more than guaranteed latency. The lack of such features helps explain why, despite having myriad MACs and a big memory, the TPU is relatively small and low power. We compare the TPU to a server-class Intel …",
        "year": 2017,
        "authors": "Norman P Jouppi and Cliff Young and Nishant Patil and David Patterson and Gaurav Agrawal and Raminder Bajwa and Sarah Bates and Suresh Bhatia and Nan Boden and Al Borchers and Rick Boyle and Pierre-luc Cantin and Clifford Chao and Chris Clark and Jeremy Coriell and Mike Daley and Matt Dau and Jeffrey Dean and Ben Gelb and Tara Vazir Ghaemmaghami and Rajendra Gottipati and William Gulland and Robert Hagmann and C Richard Ho and Doug Hogberg and John Hu and Robert Hundt and Dan Hurt and Julian Ibarz and Aaron Jaffey and Alek Jaworski and Alexander Kaplan and Harshit Khaitan and Daniel Killebrew and Andy Koch and Naveen Kumar and Steve Lacy and James Laudon and James Law and Diemthu Le and Chris Leary and Zhuyuan Liu and Kyle Lucke and Alan Lundin and Gordon MacKean and Adriana Maggiore and Maire Mahony and Kieran Miller and Rahul Nagarajan and Ravi Narayanaswami and Ray Ni and Kathy Nix and Thomas Norrie and Mark Omernick and Narayana Penukonda and Andy Phelps and Jonathan Ross and Matt Ross and Amir Salek and Emad Samadiani and Chris Severn and Gregory Sizikov and Matthew Snelham and Jed Souter and Dan Steinberg and Andy Swing and Mercedes Tan and Gregory Thorson and Bo Tian and Horia Toma and Erick Tuttle and Vijay Vasudevan and Richard Walter and Walter Wang and Eric Wilcox and Doe Hyun Yoon"
      },
      {
        "title": "Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection",
        "abstract": "We describe a learning-based approach to hand-eye coordination for robotic grasping from monocular images. To learn hand-eye coordination for grasping, we trained a large convolutional neural network to predict the probability that task-space motion of the gripper will result in successful grasps, using only monocular camera images independent of camera calibration or the current robot pose. This requires the network to observe the spatial relationship between the gripper and objects in the scene, thus learning hand-eye coordination. We then use this network to servo the gripper in real time to achieve successful grasps. We describe two large-scale experiments that we conducted on two separate robotic platforms. In the first experiment, about 800,000 grasp attempts were collected over the course of two months, using between 6 and 14 robotic manipulators at any given time, with differences in camera …",
        "year": 2018,
        "authors": "Sergey Levine and Peter Pastor and Alex Krizhevsky and Julian Ibarz and Deirdre Quillen"
      },
      {
        "title": "Do as i can, not as i say: Grounding language in robotic affordances",
        "abstract": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model’s “hands and eyes,” while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project’s website, video, and open source can be …",
        "year": 2023,
        "authors": "Anthony Brohan and Yevgen Chebotar and Chelsea Finn and Karol Hausman and Alexander Herzog and Daniel Ho and Julian Ibarz and Alex Irpan and Eric Jang and Ryan Julian and Dmitry Kalashnikov and Sergey Levine and Yao Lu and Carolina Parada and Kanishka Rao and Pierre Sermanet and Alexander T Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Mengyuan Yan and Noah Brown and Michael Ahn and Omar Cortes and Nicolas Sievers and Clayton Tan and Sichun Xu and Diego Reyes and Jarek Rettinghouse and Jornell Quiambao and Peter Pastor and Linda Luu and Kuang-Huei Lee and Yuheng Kuang and Sally Jesmonth and Nikhil J Joshi and Kyle Jeffrey and Rosario Jauregui Ruano and Jasmine Hsu and Keerthana Gopalakrishnan and Byron David and Andy Zeng and Chuyuan Kelly Fu"
      }
    ],
    "T7uctwYAAAAJ": [
      {
        "title": "Going deeper with convolutions",
        "abstract": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation of this architecture, GoogLeNet, a 22 layers deep network, was used to assess its quality in the context of object detection and classification.",
        "year": 2015,
        "authors": "Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich"
      },
      {
        "title": "Rethinking the inception architecture for computer vision",
        "abstract": "Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible. We benchmark our methods on the ILSVRC 2012 classification challenge validation set and demonstrate substantial gains over the state of the art via to carefully factorized convolutions and aggressive regularization: 21.2% top-1 and 5.6% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters.",
        "year": 2016,
        "authors": "Christian Szegedy and Vincent Vanhoucke and Sergey Ioffe and Jon Shlens and Zbigniew Wojna"
      },
      {
        "title": "Inception-v4, inception-resnet and the impact of residual connections on learning",
        "abstract": "Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question: Are there any benefits to combining Inception architectures with residual connections? Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4 networks, we achieve 3.08% top-5 error on the test set of the ImageNet classification (CLS) challenge.",
        "year": 2017,
        "authors": "Christian Szegedy and Sergey Ioffe and Vincent Vanhoucke and Alexander Alemi"
      }
    ],
    "ThJ-Ju4AAAAJ": [
      {
        "title": "Analytical approach to parallel repetition",
        "abstract": "We propose an analytical framework for studying parallel repetition, a basic product operation for one-round twoplayer games. In this framework, we consider a relaxation of the value of projection games. We show that this relaxation is multiplicative with respect to parallel repetition and that it provides a good approximation to the game value. Based on this relaxation, we prove the following improved parallel repetition bound: For every projection game G with value at most ρ, the k-fold parallel repetition G⊗k has value at most[EQUATION]This statement implies a parallel repetition bound for projection games with low value ρ. Previously, it was not known whether parallel repetition decreases the value of such games. This result allows us to show that approximating set cover to within factor (1 --- ε) ln n is NP-hard for every ε > 0, strengthening Feige's quasi-NP-hardness and also building on previous work by …",
        "year": 2014,
        "authors": "Irit Dinur and David Steurer"
      },
      {
        "title": "Graph expansion and the unique games conjecture",
        "abstract": "The edge expansion of a subset of vertices S ⊆ V in a graph G measures the fraction of edges that leave S. In a d-regular graph, the edge expansion/conductance Φ(S) of a subset S ⊆ V is defined as Φ(S) = (|E(S, V\\S)|)/(d|S|). Approximating the conductance of small linear sized sets (size δ n) is a natural optimization question that is a variant of the well-studied Sparsest Cut problem. However, there are no known algorithms to even distinguish between almost complete edge expansion (Φ(S) = 1-ε), and close to 0 expansion. In this work, we investigate the connection between Graph Expansion and the Unique Games Conjecture. Specifically, we show the following: We show that a simple decision version of the problem of approximating small set expansion reduces to Unique Games. Thus if approximating edge expansion of small sets is hard, then Unique Games is hard. Alternatively, a refutation of the UGC will …",
        "year": 2010,
        "authors": "Prasad Raghavendra and David Steurer"
      }
    ],
    "AEsPCAUAAAAJ": [
      {
        "title": "Context encoders: Feature learning by inpainting",
        "abstract": "We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction. By analogy with auto-encoders, we propose Context Encoders--a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part (s). When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss. The latter produces much sharper results because it can better handle multiple modes in the output. We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures. We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classification, detection, and segmentation tasks. Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods.",
        "year": 2016,
        "authors": "Deepak Pathak and Philipp Krahenbuhl and Jeff Donahue and Trevor Darrell and Alexei A Efros"
      },
      {
        "title": "Curiosity-driven exploration by self-supervised prediction",
        "abstract": "In many real-world scenarios, rewards extrinsic to the agent are extremely sparse, or absent altogether. In such cases, curiosity can serve as an intrinsic reward signal to enable the agent to explore its environment and learn skills that might be useful later in its life. We formulate curiosity as the error in an agent’s ability to predict the consequence of its own actions in a visual feature space learned by a self-supervised inverse dynamics model. Our formulation scales to high-dimensional continuous state spaces like images, bypasses the difficulties of directly predicting pixels, and, critically, ignores the aspects of the environment that cannot affect the agent. The proposed approach is evaluated in two environments: VizDoom and Super Mario Bros. Three broad settings are investigated: 1) sparse extrinsic reward, where curiosity allows for far fewer interactions with the environment to reach the goal; 2) exploration with no extrinsic reward, where curiosity pushes the agent to explore more efficiently; and 3) generalization to unseen scenarios (eg new levels of the same game) where the knowledge gained from earlier experience helps the agent explore new places much faster than starting from scratch.",
        "year": 2017,
        "authors": "Deepak Pathak and Pulkit Agrawal and Alexei A Efros and Trevor Darrell"
      },
      {
        "title": "Toward Multimodal Image-to-Image Translation",
        "abstract": "Many image-to-image translation problems are ambiguous, as a single input image may correspond to multiple possible outputs. In this work, we aim to model a distribution of possible outputs in a conditional generative modeling setting. The ambiguity of the mapping is distilled in a low-dimensional latent vector, which can be randomly sampled at test time. A generator learns to map the given input, combined with this latent code, to the output. We explicitly encourage the connection between output and the latent code to be invertible. This helps prevent a many-to-one mapping from the latent code to the output during training, also known as the problem of mode collapse, and produces more diverse results. We explore several variants of this approach by employing different training objectives, network architectures, and methods of injecting the latent code. Our proposed method encourages bijective consistency between the latent encoding and output modes. We present a systematic comparison of our method and other variants on both perceptual realism and diversity.",
        "year": 2017,
        "authors": "Jun-Yan Zhu and Richard Zhang and Deepak Pathak and Trevor Darrell and Alexei A. Efros and Oliver Wang and Eli Shechtman"
      }
    ],
    "SaboshYAAAAJ": [
      {
        "title": "Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing",
        "abstract": "We present Resilient Distributed Datasets (RDDs), a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a fault-tolerant manner. RDDs are motivated by two types of applications that current computing frameworks handle inefficiently: iterative algorithms and interactive data mining tools. In both cases, keeping data in memory can improve performance by an order of magnitude. To achieve fault tolerance efficiently, RDDs provide a restricted form of shared memory, based on coarse-grained transformations rather than fine-grained updates to shared state. However, we show that RDDs are expressive enough to capture a wide class of computations, including recent specialized programming models for iterative jobs, such as Pregel, and new applications that these models do not capture. We have implemented RDDs in a system called Spark, which we evaluate through a variety of user applications and benchmarks.",
        "year": 2012,
        "authors": "Matei Zaharia and Mosharaf Chowdhury and Tathagata Das and Ankur Dave and Justin Ma and Murphy McCauley and Michael J Franklin and Scott Shenker and Ion Stoica"
      },
      {
        "title": "GraphX: Graph Processing in a Distributed Dataflow Framework",
        "abstract": "In pursuit of graph processing performance, the systems community has largely abandoned general-purpose distributed dataflow frameworks in favor of specialized graph processing systems that provide tailored programming abstractions and accelerate the execution of iterative graph algorithms. In this paper we argue that many of the advantages of specialized graph processing systems can be recovered in a modern general-purpose distributed dataflow system. We introduce GraphX, an embedded graph processing framework built on top of Apache Spark, a widely used distributed dataflow system. GraphX presents a familiar composable graph abstraction that is sufficient to express existing graph APIs, yet can be implemented using only a few basic dataflow operators (eg, join, map, group-by). To achieve performance parity with specialized graph systems, GraphX recasts graph-specific optimizations as distributed join optimizations and materialized view maintenance. By leveraging advances in distributed dataflow frameworks, GraphX brings low-cost fault tolerance to graph processing. We evaluate GraphX on real workloads and demonstrate that GraphX achieves an order of magnitude performance gain over the base dataflow framework and matches the performance of specialized graph processing systems while enabling a wider range of computation.",
        "year": 2014,
        "authors": "Joseph E Gonzalez and Reynold S Xin and Ankur Dave and Daniel Crankshaw and Michael J Franklin and Ion Stoica"
      },
      {
        "title": "Apache spark: a unified engine for big data processing",
        "abstract": "This open source computing framework unifies streaming, batch, and interactive big data workloads to unlock new applications.",
        "year": 2016,
        "authors": "Matei Zaharia and Reynold S Xin and Patrick Wendell and Tathagata Das and Michael Armbrust and Ankur Dave and Xiangrui Meng and Josh Rosen and Shivaram Venkataraman and Michael J Franklin and Ali Ghodsi and Joseph Gonzalez and Scott Shenker and Ion Stoica"
      }
    ],
    "Wewcpo4AAAAJ": [
      {
        "title": "Stochastic blockmodels and community structure in networks",
        "abstract": "Stochastic blockmodels have been proposed as a tool for detecting community structure in networks as well as for generating synthetic networks for use as benchmarks. Most blockmodels, however, ignore variation in vertex degree, making them unsuitable for applications to real-world networks, which typically display broad degree distributions that can significantly affect the results. Here we demonstrate how the generalization of blockmodels to incorporate this missing element leads to an improved objective function for community detection in complex networks. We also propose a heuristic algorithm for community detection using this objective function or its non-degree-corrected counterpart and show that the degree-corrected version dramatically outperforms the uncorrected one in both real-world and synthetic networks.",
        "year": 2011,
        "authors": "Brian Karrer and Mark EJ Newman"
      },
      {
        "title": "The Anatomy of the Facebook Social Graph",
        "abstract": "We study the structure of the social graph of active Facebook users, the largest social network ever analyzed. We compute numerous features of the graph including the number of users and friendships, the degree distribution, path lengths, clustering, and mixing patterns. Our results center around three main observations. First, we characterize the global structure of the graph, determining that the social network is nearly fully connected, with 99.91% of individuals belonging to a single large connected component, and we confirm the \"six degrees of separation\" phenomenon on a global scale. Second, by studying the average local clustering coefficient and degeneracy of graph neighborhoods, we show that while the Facebook graph as a whole is clearly sparse, the graph neighborhoods of users contain surprisingly dense structure. Third, we characterize the assortativity patterns present in the graph by studying the basic demographic and network properties of users. We observe clear degree assortativity and characterize the extent to which \"your friends have more friends than you\". Furthermore, we observe a strong effect of age on friendship preferences as well as a globally modular community structure driven by nationality, but we do not find any strong gender homophily. We compare our results with those from smaller social networks and find mostly, but not entirely, agreement on common structural network characteristics.",
        "year": 2011,
        "authors": "Johan Ugander and Brian Karrer and Lars Backstrom and Cameron Marlow"
      },
      {
        "title": "BoTorch: a framework for efficient Monte-Carlo Bayesian optimization",
        "abstract": "Bayesian optimization provides sample-efficient global optimization for a broad range of applications, including automatic machine learning, engineering, physics, and experimental design. We introduce BoTorch, a modern programming framework for Bayesian optimization that combines Monte-Carlo (MC) acquisition functions, a novel sample average approximation optimization approach, auto-differentiation, and variance reduction techniques. BoTorch's modular design facilitates flexible specification and optimization of probabilistic models written in PyTorch, simplifying implementation of new acquisition functions. Our approach is backed by novel theoretical convergence results and made practical by a distinctive algorithmic foundation that leverages fast predictive distributions, hardware acceleration, and deterministic optimization. We also propose a novel\" one-shot\" formulation of the Knowledge Gradient, enabled by a combination of our theoretical and software contributions. In experiments, we demonstrate the improved sample efficiency of BoTorch relative to other popular libraries.",
        "year": 2020,
        "authors": "Maximilian Balandat and Brian Karrer and Daniel Jiang and Samuel Daulton and Ben Letham and Andrew G Wilson and Eytan Bakshy"
      }
    ],
    "Uly5spMAAAAJ": [
      {
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models",
        "abstract": "DSpace at KOASAS: Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nKOASAS menu About KOASAS KAIST Library 검색 Advanced Search KOASAS About \nKOASAS Open Access Policy Browse Communities & Collections Researchers at KAIST Titles \nSubject By Date rss_1.0 rss_2.0 atom_1.0 sherpa SEARCH DSpace at KOASAS College of \nEngineering(공과대학)Kim Jaechul Graduate School of AI(김재철AI대학원)AI-Conference \nPapers(학술대회논문) Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nCited 0 time in webofscience Cited 0 time in scopus Hit : 2 Download : 0 Export DC(XML) Excel \nLim, Joseph Jaewhanresearcher Publisher IEEE Issue Date 2024-05-15 Citation IEEE \nInternational Conference on Robotics and Automation URI http://hdl.handle.net/10203/326144 \nAppears in Collection AI-Conference Papers(학술대회논문) Files in This Item There are no files …",
        "year": 2024,
        "authors": "Joseph Jaewhan Lim"
      },
      {
        "title": "Meta-reinforcement learning of structured exploration strategies",
        "abstract": "Exploration is a fundamental challenge in reinforcement learning (RL). Many current exploration methods for deep RL use task-agnostic objectives, such as information gain or bonuses based on state visitation. However, many practical applications of RL involve learning more than a single task, and prior tasks can be used to inform how exploration should be performed in new tasks. In this work, we study how prior tasks can inform an agent about how to explore effectively in new situations. We introduce a novel gradient-based fast adaptation algorithm–model agnostic exploration with structured noise (MAESN)–to learn exploration strategies from prior experience. The prior experience is used both to initialize a policy and to acquire a latent exploration space that can inject structured stochasticity into a policy, producing exploration strategies that are informed by prior knowledge and are more effective than random action-space noise. We show that MAESN is more effective at learning exploration strategies when compared to prior meta-RL methods, RL without learned exploration strategies, and task-agnostic exploration methods. We evaluate our method on a variety of simulated tasks: locomotion with a wheeled robot, locomotion with a quadrupedal walker, and object manipulation.",
        "year": 2018,
        "authors": "Abhishek Gupta and Russell Mendonca and YuXuan Liu and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Affordances from human videos as a versatile representation for robotics",
        "abstract": "Building a robot that can understand and learn to interact by watching humans has inspired several vision problems. However, despite some successful results on static datasets, it remains unclear how current models can be used on a robot directly. In this paper, we aim to bridge this gap by leveraging videos of human interactions in an environment centric manner. Utilizing internet videos of human behavior, we train a visual affordance model that estimates where and how in the scene a human is likely to interact. The structure of these behavioral affordances directly enables the robot to perform many complex tasks. We show how to seamlessly integrate our affordance model with four robot learning paradigms including offline imitation learning, exploration, goal-conditioned learning, and action parameterization for reinforcement learning. We show the efficacy of our approach, which we call Vision-Robotics Bridge (VRB) across 4 real world environments, over 10 different tasks, and 2 robotic platforms operating in the wild.",
        "year": 2023,
        "authors": "Shikhar Bahl and Russell Mendonca and Lili Chen and Unnat Jain and Deepak Pathak"
      }
    ],
    "3_toKJ4AAAAJ": [
      {
        "title": "{TimeGraph}:{GPU} Scheduling for {Real-Time}{Multi-Tasking} Environments",
        "abstract": "The Graphics Processing Unit (GPU) is now commonly used for graphics and data-parallel computing. As more and more applications tend to accelerate on the GPU in multi-tasking environments where multiple tasks access the GPU concurrently, operating systems must provide prioritization and isolation capabilities in GPU resource management, particularly in real-time setups. We present TimeGraph, a real-time GPU scheduler at the device-driver level for protecting important GPU workloads from performance interference. TimeGraph adopts a new event-driven model that synchronizes the GPU with the CPU to monitor GPU commands issued from the user space and control GPU resource usage in a responsive manner. TimeGraph supports two prioritybased scheduling policies in order to address the tradeoff between response times and throughput introduced by the asynchronous and non-preemptive nature of GPU processing. Resource reservation mechanisms are also employed to account and enforce GPU resource usage, which prevent misbehaving tasks from exhausting GPU resources. Prediction of GPU command execution costs is further provided to enhance isolation. Our experiments using OpenGL graphics benchmarks demonstrate that TimeGraph maintains the frame-rates of primary GPU tasks at the desired level even in the face of extreme GPU workloads, whereas these tasks become nearly unresponsive without TimeGraph support. Our findings also include that the performance overhead imposed on TimeGraph can be limited to 4-10%, and its event-driven scheduler improves throughput by about 30 times over the existing …",
        "year": 2011,
        "authors": "Shinpei Kato and Karthik Lakshmanan and Ragunathan Rajkumar and Yutaka Ishikawa"
      },
      {
        "title": "Scheduling parallel real-time tasks on multi-core processors",
        "abstract": "Massively multi-core processors are rapidly gaining market share with major chip vendors offering an ever increasing number of cores per processor. From a programming perspective, the sequential programming model does not scale very well for such multi-core systems. Parallel programming models such as OpenMP present promising solutions for more effectively using multiple processor cores. In this paper, we study the problem of scheduling periodic real-time tasks on multiprocessors under the fork join structure used in OpenMP. We illustrate the theoretical best-case and worst-case periodic fork-join task sets from a processor utilization perspective. Based on our observations of these task sets, we provide a partitioned preemptive fixed-priority scheduling algorithm for periodic fork-join tasks. The proposed multiprocessor scheduling algorithm is shown to have a resource augmentation bound of 3.42, which …",
        "year": 2010,
        "authors": "Karthik Lakshmanan and Shinpei Kato and Ragunathan Rajkumar"
      },
      {
        "title": "U-connect: a low-latency energy-efficient asynchronous neighbor discovery protocol",
        "abstract": "Mobile sensor nodes can be used for a wide variety of applications such as social networks and location tracking. An important requirement for all such applications is that the mobile nodes need to actively discover their neighbors with minimal energy and latency. Nodes in mobile networks are not necessarily synchronized with each other, making the neighbor discovery problem all the more challenging. In this paper, we propose a neighbor discovery protocol called U-Connect, which achieves neighbor discovery at minimal and predictable energy costs while allowing nodes to pick dissimilar duty-cycles. We provide a theoretical formulation of this asynchronous neighbor discovery problem, and evaluate it using the power-latency product metric. We analytically establish that U-Connect is an 1.5-approximation algorithm for the symmetric asynchronous neighbor discovery problem, whereas existing protocols like …",
        "year": 2010,
        "authors": "Arvind Kandhalu and Karthik Lakshmanan and Ragunathan Rajkumar"
      }
    ],
    "Vzr1RukAAAAJ": [
      {
        "title": "Multi-agent actor-critic for mixed cooperative-competitive environments",
        "abstract": "We explore deep reinforcement learning methods for multi-agent domains. We begin by analyzing the difficulty of traditional algorithms in the multi-agent case: Q-learning is challenged by an inherent non-stationarity of the environment, while policy gradient suffers from a variance that increases as the number of agents grows. We then present an adaptation of actor-critic methods that considers action policies of other agents and is able to successfully learn policies that require complex multi-agent coordination. Additionally, we introduce a training regimen utilizing an ensemble of policies for each agent that leads to more robust multi-agent policies. We show the strength of our approach compared to existing methods in cooperative as well as competitive scenarios, where agent populations are able to discover various physical and informational coordination strategies.",
        "year": 2017,
        "authors": "Ryan Lowe and Yi I Wu and Aviv Tamar and Jean Harb and OpenAI Pieter Abbeel and Igor Mordatch"
      },
      {
        "title": "Decision transformer: Reinforcement learning via sequence modeling",
        "abstract": "We introduce a framework that abstracts Reinforcement Learning (RL) as a sequence modeling problem. This allows us to draw upon the simplicity and scalability of the Transformer architecture, and associated advances in language modeling such as GPT-x and BERT. In particular, we present Decision Transformer, an architecture that casts the problem of RL as conditional sequence modeling. Unlike prior approaches to RL that fit value functions or compute policy gradients, Decision Transformer simply outputs the optimal actions by leveraging a causally masked Transformer. By conditioning an autoregressive model on the desired return (reward), past states, and actions, our Decision Transformer model can generate future actions that achieve the desired return. Despite its simplicity, Decision Transformer matches or exceeds the performance of state-of-the-art model-free offline RL baselines on Atari, OpenAI Gym, and Key-to-Door tasks.",
        "year": 2021,
        "authors": "Lili Chen and Kevin Lu and Aravind Rajeswaran and Kimin Lee and Aditya Grover and Misha Laskin and Pieter Abbeel and Aravind Srinivas and Igor Mordatch"
      },
      {
        "title": "Palm-e: An embodied multimodal language model",
        "abstract": "Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.",
        "year": 2023,
        "authors": "Danny Driess and Fei Xia and Mehdi SM Sajjadi and Corey Lynch and Aakanksha Chowdhery and Ayzaan Wahid and Jonathan Tompson and Quan Vuong and Tianhe Yu and Wenlong Huang and Yevgen Chebotar and Pierre Sermanet and Daniel Duckworth and Sergey Levine and Vincent Vanhoucke and Karol Hausman and Marc Toussaint and Klaus Greff and Andy Zeng and Igor Mordatch and Pete Florence"
      }
    ],
    "MN9Kfg8AAAAJ": [
      {
        "title": "A critical review of recurrent neural networks for sequence learning",
        "abstract": "Countless learning tasks require dealing with sequential data. Image captioning, speech synthesis, and music generation all require that a model produce outputs that are sequences. In other domains, such as time series prediction, video analysis, and musical information retrieval, a model must learn from inputs that are sequences. Interactive tasks, such as translating natural language, engaging in dialogue, and controlling a robot, often demand both capabilities. Recurrent neural networks (RNNs) are connectionist models that capture the dynamics of sequences via cycles in the network of nodes. Unlike standard feedforward neural networks, recurrent networks retain a state that can represent information from an arbitrarily long context window. Although recurrent neural networks have traditionally been difficult to train, and often contain millions of parameters, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful large-scale learning with them. In recent years, systems based on long short-term memory (LSTM) and bidirectional (BRNN) architectures have demonstrated ground-breaking performance on tasks as varied as image captioning, language translation, and handwriting recognition. In this survey, we review and synthesize the research that over the past three decades first yielded and then made practical these powerful learning models. When appropriate, we reconcile conflicting notation and nomenclature. Our goal is to provide a self-contained explication of the state of the art together with a historical perspective and references to primary research.",
        "year": 2015,
        "authors": "Zachary C Lipton and John Berkowitz and Charles Elkan"
      }
    ],
    "BDmtLHsAAAAJ": [
      {
        "title": "Conceptfusion: Open-set multimodal 3d mapping",
        "abstract": "Building 3D maps of the environment is central to robot navigation, planning, and interaction with objects in a scene. Most existing approaches that integrate semantic concepts with 3D maps largely remain confined to the closed-set setting: they can only reason about a finite set of concepts, pre-defined at training time. Further, these maps can only be queried using class labels, or in recent work, using text prompts. We address both these issues with ConceptFusion, a scene representation that is (1) fundamentally open-set, enabling reasoning beyond a closed set of concepts and (ii) inherently multimodal, enabling a diverse range of possible queries to the 3D map, from language, to images, to audio, to 3D geometry, all working in concert. ConceptFusion leverages the open-set capabilities of today's foundation models pre-trained on internet-scale data to reason about concepts across modalities such as natural language, images, and audio. We demonstrate that pixel-aligned open-set features can be fused into 3D maps via traditional SLAM and multi-view fusion approaches. This enables effective zero-shot spatial reasoning, not needing any additional training or finetuning, and retains long-tailed concepts better than supervised approaches, outperforming them by more than 40% margin on 3D IoU. We extensively evaluate ConceptFusion on a number of real-world datasets, simulated home environments, a real-world tabletop manipulation task, and an autonomous driving platform. We showcase new avenues for blending foundation models with 3D open-set multimodal mapping. For more information, visit our project page https://concept …",
        "year": 2023,
        "authors": "Krishna Murthy Jatavallabhula and Alihusein Kuwajerwala and Qiao Gu and Mohd Omama and Tao Chen and Alaa Maalouf and Shuang Li and Ganesh Iyer and Soroush Saryazdi and Nikhil Keetha and Ayush Tewari and Joshua B Tenenbaum and Celso Miguel de Melo and Madhava Krishna and Liam Paull and Florian Shkurti and Antonio Torralba"
      },
      {
        "title": "Conceptgraphs: Open-vocabulary 3d scene graphs for perception and planning",
        "abstract": "For robots to perform a wide variety of tasks, they require a 3D representation of the world that is semantically rich, yet compact and efficient for task-driven perception and planning. Recent approaches have attempted to leverage features from large vision-language models to encode semantics in 3D representations. However, these approaches tend to produce maps with per-point feature vectors, which do not scale well in larger environments, nor do they contain semantic spatial relationships between entities in the environment, which are useful for downstream planning. In this work, we propose ConceptGraphs, an open-vocabulary graph-structured representation for 3D scenes. ConceptGraphs is built by leveraging 2D foundation models and fusing their output to 3D by multi-view association. The resulting representations generalize to novel semantic classes, without the need to collect large 3D datasets or …",
        "year": 2024,
        "authors": "Qiao Gu and Ali Kuwajerwala and Sacha Morin and Krishna Murthy Jatavallabhula and Bipasha Sen and Aditya Agarwal and Corban Rivera and William Paul and Kirsty Ellis and Rama Chellappa and Chuang Gan and Celso Miguel de Melo and Joshua B Tenenbaum and Antonio Torralba and Florian Shkurti and Liam Paull"
      },
      {
        "title": "Generating adversarial driving scenarios in high-fidelity simulators",
        "abstract": "In recent years self-driving vehicles have become more commonplace on public roads, with the promise of bringing safety and efficiency to modern transportation systems. Increasing the reliability of these vehicles on the road requires an extensive suite of software tests, ideally performed on high-fidelity simulators, where multiple vehicles and pedestrians interact with the self-driving vehicle. It is therefore of critical importance to ensure that self-driving software is assessed against a wide range of challenging simulated driving scenarios. The state of the art in driving scenario generation, as adopted by some of the front-runners of the self-driving car industry, still relies on human input [1]. In this paper we propose to automate the process using Bayesian optimization to generate adversarial self-driving scenarios that expose poorly-engineered or poorly-trained self-driving policies, and increase the risk of collision with …",
        "year": 2019,
        "authors": "Yasasa Abeysirigoonawardena and Florian Shkurti and Gregory Dudek"
      }
    ],
    "LUe32ToAAAAJ": [
      {
        "title": "Learning robot objectives from physical human interaction",
        "abstract": "When humans and robots work in close proximity, physical interaction is inevitable. Traditionally, robots treat physical interaction as a disturbance, and resume their original behavior after the interaction ends. In contrast, we argue that physical human interaction is informative: it is useful information about how the robot should be doing its task. We formalize learning from such interactions as a dynamical system in which the task objective has parameters that are part of the hidden state, and physical human interactions are observations about these parameters. We derive an online approximation of the robot’s optimal policy in this system, and test it in a user study. The results suggest that learning from physical interaction leads to better robot task performance with less human effort.",
        "year": 2017,
        "authors": "Andrea Bajcsy and Dylan P Losey and Marcia K O’malley and Anca D Dragan"
      },
      {
        "title": "Probabilistically safe robot planning with confidence-based human predictions",
        "abstract": "In order to safely operate around humans, robots can employ predictive models of human motion. Unfortunately, these models cannot capture the full complexity of human behavior and necessarily introduce simplifying assumptions. As a result, predictions may degrade whenever the observed human behavior departs from the assumed structure, which can have negative implications for safety. In this paper, we observe that how \"rational\" human actions appear under a particular model can be viewed as an indicator of that model's ability to describe the human's current motion. By reasoning about this model confidence in a real-time Bayesian framework, we show that the robot can very quickly modulate its predictions to become more uncertain when the model performs poorly. Building on recent work in provably-safe trajectory planning, we leverage these confidence-aware human motion predictions to generate assured autonomous robot motion. Our new analysis combines worst-case tracking error guarantees for the physical robot with probabilistic time-varying human predictions, yielding a quantitative, probabilistic safety certificate. We demonstrate our approach with a quadcopter navigating around a human.",
        "year": 2018,
        "authors": "Jaime F Fisac and Andrea Bajcsy and Sylvia L Herbert and David Fridovich-Keil and Steven Wang and Claire J Tomlin and Anca D Dragan"
      },
      {
        "title": "Confidence-aware motion prediction for real-time collision avoidance1",
        "abstract": "One of the most difficult challenges in robot motion planning is to account for the behavior of other moving agents, such as humans. Commonly, practitioners employ predictive models to reason about where other agents are going to move. Though there has been much recent work in building predictive models, no model is ever perfect: an agent can always move unexpectedly, in a way that is not predicted or not assigned sufficient probability. In such cases, the robot may plan trajectories that appear safe but, in fact, lead to collision. Rather than trust a model’s predictions blindly, we propose that the robot should use the model’s current predictive accuracy to inform the degree of confidence in its future predictions. This model confidence inference allows us to generate probabilistic motion predictions that exploit modeled structure when the structure successfully explains human motion, and degrade gracefully …",
        "year": 2020,
        "authors": "David Fridovich-Keil and Andrea Bajcsy and Jaime F Fisac and Sylvia L Herbert and Steven Wang and Anca D Dragan and Claire J Tomlin"
      }
    ],
    "Dtw3YBoAAAAJ": [
      {
        "title": "How Does Batch Normalization Help Optimization?",
        "abstract": "Batch Normalization (BatchNorm) is a widely adopted technique that enables faster and more stable training of deep neural networks (DNNs). Despite its pervasiveness, the exact reasons for BatchNorm's effectiveness are still poorly understood. The popular belief is that this effectiveness stems from controlling the change of the layers' input distributions during training to reduce the so-called\" internal covariate shift\". In this work, we demonstrate that such distributional stability of layer inputs has little to do with the success of BatchNorm. Instead, we uncover a more fundamental impact of BatchNorm on the training process: it makes the optimization landscape significantly smoother. This smoothness induces a more predictive and stable behavior of the gradients, allowing for faster training.",
        "year": 2018,
        "authors": "Shibani Santurkar and Dimitris Tsipras and Andrew Ilyas and Aleksander Madry"
      },
      {
        "title": "Adversarial examples are not bugs, they are features",
        "abstract": "Adversarial examples have attracted significant attention in machine learning, but the reasons for their existence and pervasiveness remain unclear. We demonstrate that adversarial examples can be directly attributed to the presence of non-robust features: features (derived from patterns in the data distribution) that are highly predictive, yet brittle and (thus) incomprehensible to humans. After capturing these features within a theoretical framework, we establish their widespread existence in standard datasets. Finally, we present a simple setting where we can rigorously tie the phenomena we observe in practice to a {\\em misalignment} between the (human-specified) notion of robustness and the inherent geometry of the data.",
        "year": 2019,
        "authors": "Andrew Ilyas and Shibani Santurkar and Dimitris Tsipras and Logan Engstrom and Brandon Tran and Aleksander Madry"
      },
      {
        "title": "Synthesizing robust adversarial examples",
        "abstract": "Standard methods for generating adversarial examples for neural networks do not consistently fool neural network classifiers in the physical world due to a combination of viewpoint shifts, camera noise, and other natural transformations, limiting their relevance to real-world systems. We demonstrate the existence of robust 3D adversarial objects, and we present the first algorithm for synthesizing examples that are adversarial over a chosen distribution of transformations. We synthesize two-dimensional adversarial images that are robust to noise, distortion, and affine transformation. We apply our algorithm to complex three-dimensional objects, using 3D-printing to manufacture the first physical adversarial objects. Our results demonstrate the existence of 3D adversarial objects in the physical world.",
        "year": 2017,
        "authors": "Anish Athalye and Logan Engstrom and Andrew Ilyas and Kevin Kwok"
      }
    ],
    "5pKTRxEAAAAJ": [
      {
        "title": "Distance metric learning with application to clustering with side-information",
        "abstract": "Many algorithms rely critically on being given a good metric over their inputs. For instance, data can often be clustered in many “plausible” ways, and if a clustering algorithm such as K-means initially fails to find one that is meaningful to a user, the only recourse may be for the user to manually tweak the metric until sufficiently good clusters are found. For these and other applications requiring good metrics, it is desirable that we provide a more systematic way for users to indicate what they consider “similar.” For instance, we may ask them to provide examples. In this paper, we present an algorithm that, given examples of similar (and, if desired, dissimilar) pairs of points in вдг, learns a distance metric over вег that respects these relationships. Our method is based on posing metric learning as a convex optimization problem, which allows us to give efficient, local-optima-free algorithms. We also demonstrate empirically that the learned metrics can be used to significantly improve clustering performance.",
        "year": 2002,
        "authors": "Eric Xing and Michael Jordan and Stuart J Russell and Andrew Ng"
      },
      {
        "title": "Judging llm-as-a-judge with mt-bench and chatbot arena",
        "abstract": "Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80\\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github. com/lm-sys/FastChat/tree/main/fastchat/llm_judge.",
        "year": 2023,
        "authors": "Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric Xing and Hao Zhang and Joseph E Gonzalez and Ion Stoica"
      }
    ],
    "mu5Y2rYAAAAJ": [
      {
        "title": "Going deeper with convolutions",
        "abstract": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation of this architecture, GoogLeNet, a 22 layers deep network, was used to assess its quality in the context of object detection and classification.",
        "year": 2015,
        "authors": "Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich"
      },
      {
        "title": "Caffe: Convolutional architecture for fast feature embedding",
        "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community …",
        "year": 2014,
        "authors": "Yangqing Jia and Evan Shelhamer and Jeff Donahue and Sergey Karayev and Jonathan Long and Ross Girshick and Sergio Guadarrama and Trevor Darrell"
      },
      {
        "title": "Tensorflow: Large-scale machine learning on heterogeneous distributed systems",
        "abstract": "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.",
        "year": 2016,
        "authors": "Martín Abadi and Ashish Agarwal and Paul Barham and Eugene Brevdo and Zhifeng Chen and Craig Citro and Greg S Corrado and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Ian Goodfellow and Andrew Harp and Geoffrey Irving and Michael Isard and Yangqing Jia and Rafal Józefowicz and Lukasz Kaiser and Manjunath Kudlur and Josh Levenberg and Dan Mané and Rajat Monga and Sherry Moore and Derek Murray and Chris Olah and Mike Schuster and Jonathon Shlens and Benoit Steiner and Ilya Sutskever and Kunal Talwar and Paul Tucker and Vincent Vanhoucke and Vijay Vasudevan and Fernanda Viegas and Oriol Vinyals and Pete Warden and Martin Wattenberg and Martin Wicke and Yuan Yu and Xiaoqiang Zheng"
      }
    ],
    "vboGT0EAAAAJ": [
      {
        "title": "Critical exponents of the classical three-dimensional Heisenberg model: A single-cluster Monte Carlo study",
        "abstract": "We have simulated the three-dimensional Heisenberg model on simple cubic lattices, using the single-cluster Monte Carlo update algorithm. The expected pronounced reduction of critical slowing down at the phase transition is verified. This allows simulations on significantly larger lattices than in previous studies and consequently a better control over systematic errors. In one set of simulations we employ the usual finite-size scaling methods to compute the critical exponents ν, α, β, γ, η from a few measurements in the vicinity of the critical point, making extensive use of histogram reweighting and optimization techniques. In another set of simulations we report measurements of improved estimators for the spatial correlation length and the susceptibility in the high-temperature phase, obtained on lattices with up to 100 3 spins. This enables us to compute independent estimates of ν and γ from power-law fits of their …",
        "year": 1993,
        "authors": "Christian Holm and Wolfhard Janke"
      },
      {
        "title": "Convergent strong-coupling expansions from divergent weak-coupling perturbation theory",
        "abstract": "Divergent weak-coupling perturbation expansions for physical quantities can be converted into sequences of uniformly and exponentially fast converging approximations. This is possible with the help of an additional variational parameter to be optimized order by order. The uniformity of the convergence for any coupling strength allows us to take all expressions directly to the strong-coupling limit, yielding a simple calculation scheme for the coefficients of convergent strong-coupling expansions. As an example, we determine these coefficients for the ground state energy of the anharmonic oscillator up to 22nd order with a precision of about 20 digits.",
        "year": 1995,
        "authors": "W Janke and H Kleinert"
      },
      {
        "title": "Multicanonical monte carlo simulations",
        "abstract": "Canonical Monte Carlo simulations of disordered systems like spin glasses and systems undergoing first-order phase transitions are severely hampered by rare event states which lead to exponentially diverging autocorrelation times with increasing system size and hence to exponentially large statistical errors. One possibility to overcome this problem is the multicanonical reweighting method. Using standard local update algorithms it could be demonstrated that the dependence of autocorrelation times on the system size V is well described by a less divergent power law, τ ∝ V α, with 1<α<3, depending on the system. After a brief review of the basic ideas, combinations of multicanonical reweighting with non-local update algorithms will be discussed. With the multibondic algorithm, which combines multicanonical reweighting with cluster updates, the dynamical exponent α can be reduced to unity, the optimal value …",
        "year": 1998,
        "authors": "Wolfhard Janke"
      }
    ],
    "wIDVzroAAAAJ": [
      {
        "title": "Cal-QL: Calibrated offline rl pre-training for efficient online fine-tuning",
        "abstract": "A compelling use case of offline reinforcement learning (RL) is to obtain a policy initialization from existing datasets followed by fast online fine-tuning with limited interaction. However, existing offline RL methods tend to behave poorly during fine-tuning. In this paper, we devise an approach for learning an effective initialization from offline data that also enables fast online fine-tuning capabilities. Our approach, calibrated Q-learning (Cal-QL), accomplishes this by learning a conservative value function initialization that underestimates the value of the learned policy from offline data, while also being calibrated, in the sense that the learned Q-values are at a reasonable scale. We refer to this property as calibration, and define it formally as providing a lower bound on the true value function of the learned policy and an upper bound on the value of some other (suboptimal) reference policy, which may simply be the behavior policy. We show that offline RL algorithms that learn such calibrated value functions lead to effective online fine-tuning, enabling us to take the benefits of offline initializations in online fine-tuning. In practice, Cal-QL can be implemented on top of the conservative Q learning (CQL) for offline RL within a one-line code change. Empirically, Cal-QL outperforms state-of-the-art methods on 9/11 fine-tuning benchmark tasks that we study in this paper. Code and video are available at https://nakamotoo. github. io/Cal-QL",
        "year": 2024,
        "authors": "Mitsuhiko Nakamoto and Simon Zhai and Anikait Singh and Max Sobol Mark and Yi Ma and Chelsea Finn and Aviral Kumar and Sergey Levine"
      },
      {
        "title": "Zero-shot robotic manipulation with pretrained image-editing diffusion models",
        "abstract": "If generalist robots are to operate in truly unstructured environments, they need to be able to recognize and reason about novel objects and scenarios. Such objects and scenarios might not be present in the robot's own training data. We propose SuSIE, a method that leverages an image-editing diffusion model to act as a high-level planner by proposing intermediate subgoals that a low-level controller can accomplish. Specifically, we finetune InstructPix2Pix on video data, consisting of both human videos and robot rollouts, such that it outputs hypothetical future \"subgoal\" observations given the robot's current observation and a language command. We also use the robot data to train a low-level goal-conditioned policy to act as the aforementioned low-level controller. We find that the high-level subgoal predictions can utilize Internet-scale pretraining and visual understanding to guide the low-level goal-conditioned policy, achieving significantly better generalization and precision than conventional language-conditioned policies. We achieve state-of-the-art results on the CALVIN benchmark, and also demonstrate robust generalization on real-world manipulation tasks, beating strong baselines that have access to privileged information or that utilize orders of magnitude more compute and training data. The project website can be found at http://rail-berkeley.github.io/susie .",
        "year": 2023,
        "authors": "Kevin Black* and Mitsuhiko Nakamoto* and Pranav Atreya and Homer Walke and Chelsea Finn and Aviral Kumar and Sergey Levine"
      },
      {
        "title": "Pre-Training for Robots: Offline RL Enables Learning New Tasks from a Handful of Trials",
        "abstract": "Progress in deep learning highlights the tremendous potential of utilizing diverse robotic datasets for attaining effective generalization and makes it enticing to consider leveraging broad datasets for attaining robust generalization in robotic learning as well. However, in practice, we often want to learn a new skill in a new environment that is unlikely to be contained in the prior data. Therefore we ask: how can we leverage existing diverse offline datasets in combination with small amounts of task-specific data to solve new tasks, while still enjoying the generalization benefits of training on large amounts of data? In this paper, we demonstrate that end-to-end offline RL can be an effective approach for doing this, without the need for any representation learning or vision-based pre-training. We present pre-training for robots (PTR), a framework based on offline RL that attempts to effectively learn new tasks by combining pre-training on existing robotic datasets with rapid fine-tuning on a new task, with as few as 10 demonstrations. PTR utilizes an existing offline RL method, conservative Q-learning (CQL), but extends it to include several crucial design decisions that enable PTR to actually work and outperform a variety of prior methods. To our knowledge, PTR is the first RL method that succeeds at learning new tasks in a new domain on a real WidowX robot with as few as 10 task demonstrations, by effectively leveraging an existing dataset of diverse multi-task robot data collected in a variety of toy kitchens. We also demonstrate that PTR can enable effective autonomous fine-tuning and improvement in a handful of trials, without needing any …",
        "year": 2022,
        "authors": "Aviral Kumar and Anikait Singh and Frederik Ebert and Mitsuhiko Nakamoto and Yanlai Yang and Chelsea Finn and Sergey Levine"
      }
    ],
    "ZvX1hXcAAAAJ": [
      {
        "title": "FastSecAgg: Scalable Secure Aggregation for Privacy-Preserving Federated Learning",
        "abstract": "Recent attacks on federated learning demonstrate that keeping the training data on clients' devices does not provide sufficient privacy, as the model parameters shared by clients can leak information about their training data. A 'secure aggregation' protocol enables the server to aggregate clients' models in a privacy-preserving manner. However, existing secure aggregation protocols incur high computation/communication costs, especially when the number of model parameters is larger than the number of clients participating in an iteration -- a typical scenario in federated learning. In this paper, we propose a secure aggregation protocol, FastSecAgg, that is efficient in terms of computation and communication, and robust to client dropouts. The main building block of FastSecAgg is a novel multi-secret sharing scheme, FastShare, based on the Fast Fourier Transform (FFT), which may be of independent interest. FastShare is information-theoretically secure, and achieves a trade-off between the number of secrets, privacy threshold, and dropout tolerance. Riding on the capabilities of FastShare, we prove that FastSecAgg is (i) secure against the server colluding with 'any' subset of some constant fraction (e.g. ) of the clients in the honest-but-curious setting; and (ii) tolerates dropouts of a 'random' subset of some constant fraction (e.g. ) of the clients. FastSecAgg achieves significantly smaller computation cost than existing schemes while achieving the same (orderwise) communication cost. In addition, it guarantees security against adaptive adversaries, which can perform client corruptions dynamically during the execution of the protocol.",
        "year": 2020,
        "authors": "Swanand Kadhe and Nived Rajaraman and O Ozan Koyluoglu and Kannan Ramchandran"
      },
      {
        "title": "Toward the fundamental limits of imitation learning",
        "abstract": "Imitation learning (IL) aims to mimic the behavior of an expert policy in a sequential decision-making problem given only demonstrations. In this paper, we focus on understanding the minimax statistical limits of IL in episodic Markov Decision Processes (MDPs). We first consider the setting where the learner is provided a dataset of  expert trajectories ahead of time, and cannot interact with the MDP. Here, we show that the policy which mimics the expert whenever possible is in expectation  suboptimal compared to the value of the expert, even when the expert plays a stochastic policy. Here  is the state space and  is the length of the episode. Furthermore, we establish a suboptimality lower bound of  which applies even if the expert is constrained to be deterministic, or if the learner is allowed to actively query the expert at visited states while interacting with the MDP for  episodes. To our knowledge, this is the first algorithm with suboptimality having no dependence on the number of actions, under no additional assumptions. We then propose a novel algorithm based on minimum-distance functionals in the setting where the transition model is given and the expert is deterministic. The algorithm is suboptimal by , matching our lower bound up to a  factor, and breaks the  error compounding barrier of IL.",
        "year": 2020,
        "authors": "Nived Rajaraman and Lin Yang and Jiantao Jiao and Kannan Ramchandran"
      },
      {
        "title": "Not just age but age and quality of information",
        "abstract": "A versatile scheduling problem to model a three-way tradeoff between age of information (AoI), quality/distortion, and energy is considered. The considered problem called the age and quality of information (AQI) is to select which packets to transmit at each time slot to minimize a linear combination of the utility driven by quality, the AoI, and the energy transmission cost in an online fashion. AQI problem combines tradeoffs from some important distinct problems, such as AoI with multiple sources, the remote sampling problem with sampling constraint, the classical speed scaling problem among others. The arbitrary/adversarial case input model is considered in the online setting, where the performance metric is the competitive ratio. A greedy algorithm is proposed that is shown to be 2-competitive, independent of all parameters of the problem. For the special case of AQI problem, a maximum weight matching based …",
        "year": 2021,
        "authors": "Nived Rajaraman and Rahul Vaze and Goonwanth Reddy"
      }
    ],
    "F_ASWCUAAAAJ": [
      {
        "title": "Real-time optimization of personalized assortments",
        "abstract": "Motivated by the availability of real-time data on customer characteristics, we consider the problem of personalizing the assortment of products for each arriving customer. Using actual sales data from an online retailer, we demonstrate that personalization based on each customer's location can lead to over 10% improvements in revenue compared to a policy that treats all customers the same. We propose a family of index-based policies that effectively coordinate the real-time assortment decisions with the back-end supply chain constraints. We allow the demand process to be arbitrary and prove that our algorithms achieve an optimal competitive ratio. In addition, we show that our algorithms perform even better if the demand is known to be stationary. Our approach is also flexible and can be combined with existing methods in the literature, resulting in a hybrid algorithm that brings out the advantages of other …",
        "year": 2014,
        "authors": "Negin Golrezaei and Hamid Nazerzadeh and Paat Rusmevichientong"
      },
      {
        "title": "Online optimization with uncertain information",
        "abstract": "We introduce a new framework for designing online algorithms that can incorporate additional information about the input sequence, while maintaining a reasonable competitive ratio if the additional information is incorrect. Within this framework, we present online algorithms for several problems including allocation of online advertisement space, load balancing, and facility location.",
        "year": 2012,
        "authors": "Mohammad Mahdian and Hamid Nazerzadeh and Amin Saberi"
      },
      {
        "title": "Dynamic pricing in high-dimensions",
        "abstract": "We study the pricing problem faced by a firm that sells a large number of products, described via a wide range of features, to customers that arrive over time. Customers independently make purchasing decisions according to a general choice model that includes products features and customers' characteristics, encoded as d-dimensional numerical vectors, as well as the price offered. The parameters of the choice model are a priori unknown to the firm, but can be learned as the (binary-valued) sales data accrues over time. The firm's objective is to maximize its revenue. We benchmark the performance using the classic regret minimization framework where the regret is defined as the expected revenue loss against a clairvoyant policy that knows the parameters of the choice model in advance, and always offers the revenue-maximizing price. This setting is motivated in part by the prevalence of online marketplaces that allow for real-time pricing.We assume a structured choice model, parameters of which depend on s0 out of the d product features. Assuming that the market noise distribution is known, we propose a dynamic policy, called Regularized Maximum Likelihood Pricing (RMLP) that leverages the (sparsity) structure of the high-dimensional model and obtains a logarithmic regret in T. More specifically, the regret of our algorithm is of O(s0 log d · log T). Furthermore, we show that no policy can obtain regret better than O(s0(log d + log T)). In addition, we propose a generalization of our policy to a setting that the market noise distribution is unknown but belongs to a parametrized family of distributions. This policy obtains regret of O(√(log d)T …",
        "year": 2019,
        "authors": "Adel Javanmard and Hamid Nazerzadeh"
      }
    ],
    "7ShMBcwAAAAJ": [
      {
        "title": "Wilds: A benchmark of in-the-wild distribution shifts",
        "abstract": "Distribution shifts—where the training distribution differs from the test distribution—can substantially degrade the accuracy of machine learning (ML) systems deployed in the wild. Despite their ubiquity in the real-world deployments, these distribution shifts are under-represented in the datasets widely used in the ML community today. To address this gap, we present WILDS, a curated benchmark of 10 datasets reflecting a diverse range of distribution shifts that naturally arise in real-world applications, such as shifts across hospitals for tumor identification; across camera traps for wildlife monitoring; and across time and location in satellite imaging and poverty mapping. On each dataset, we show that standard training yields substantially lower out-of-distribution than in-distribution performance. This gap remains even with models trained by existing methods for tackling distribution shifts, underscoring the need for new methods for training models that are more robust to the types of distribution shifts that arise in practice. To facilitate method development, we provide an open-source package that automates dataset loading, contains default model architectures and hyperparameters, and standardizes evaluations. The full paper, code, and leaderboards are available at https://wilds. stanford. edu.",
        "year": 2021,
        "authors": "Pang Wei Koh and Shiori Sagawa and Henrik Marklund and Sang Michael Xie and Marvin Zhang and Akshay Balsubramani and Weihua Hu and Michihiro Yasunaga and Richard Lanas Phillips and Irena Gao and Tony Lee and Etienne David and Ian Stavness and Wei Guo and Berton Earnshaw and Imran Haque and Sara M Beery and Jure Leskovec and Anshul Kundaje and Emma Pierson and Sergey Levine and Chelsea Finn and Percy Liang"
      },
      {
        "title": "When to trust your model: Model-based policy optimization",
        "abstract": "Designing effective model-based reinforcement learning algorithms is difficult because the ease of data generation must be weighed against the bias of model-generated data. In this paper, we study the role of model usage in policy optimization both theoretically and empirically. We first formulate and analyze a model-based reinforcement learning algorithm with a guarantee of monotonic improvement at each step. In practice, this analysis is overly pessimistic and suggests that real off-policy data is always preferable to model-generated on-policy data, but we show that an empirical estimate of model generalization can be incorporated into such analysis to justify model usage. Motivated by this analysis, we then demonstrate that a simple procedure of using short model-generated rollouts branched from real data has the benefits of more complicated model-based algorithms without the usual pitfalls. In particular, this approach surpasses the sample efficiency of prior model-based methods, matches the asymptotic performance of the best model-free algorithms, and scales to horizons that cause other model-based methods to fail entirely.",
        "year": 2019,
        "authors": "Michael Janner and Justin Fu and Marvin Zhang and Sergey Levine"
      }
    ],
    "5JE9m1EAAAAJ": [
      {
        "title": "Resilient distributed datasets: A {Fault-Tolerant} abstraction for {In-Memory} cluster computing",
        "abstract": "We present Resilient Distributed Datasets (RDDs), a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a fault-tolerant manner. RDDs are motivated by two types of applications that current computing frameworks handle inefficiently: iterative algorithms and interactive data mining tools. In both cases, keeping data in memory can improve performance by an order of magnitude. To achieve fault tolerance efficiently, RDDs provide a restricted form of shared memory, based on coarse-grained transformations rather than fine-grained updates to shared state. However, we show that RDDs are expressive enough to capture a wide class of computations, including recent specialized programming models for iterative jobs, such as Pregel, and new applications that these models do not capture. We have implemented RDDs in a system called Spark, which we evaluate through a variety of user applications and benchmarks.",
        "year": 2012,
        "authors": "Matei Zaharia and Mosharaf Chowdhury and Tathagata Das and Ankur Dave and Justin Ma and Murphy McCauly and Michael J Franklin and Scott Shenker and Ion Stoica"
      },
      {
        "title": "Apache spark: a unified engine for big data processing",
        "abstract": "This open source computing framework unifies streaming, batch, and interactive big data workloads to unlock new applications.",
        "year": 2016,
        "authors": "Matei Zaharia and Reynold S Xin and Patrick Wendell and Tathagata Das and Michael Armbrust and Ankur Dave and Xiangrui Meng and Josh Rosen and Shivaram Venkataraman and Michael J Franklin and Ali Ghodsi and Joseph Gonzalez and Scott Shenker and Ion Stoica"
      },
      {
        "title": "Discretized streams: Fault-tolerant streaming computation at scale",
        "abstract": "Many \"big data\" applications must act on data in real time. Running these applications at ever-larger scales requires parallel platforms that automatically handle faults and stragglers. Unfortunately, current distributed stream processing models provide fault recovery in an expensive manner, requiring hot replication or long recovery times, and do not handle stragglers. We propose a new processing model, discretized streams (D-Streams), that overcomes these challenges. D-Streams enable a parallel recovery mechanism that improves efficiency over traditional replication and backup schemes, and tolerates stragglers. We show that they support a rich set of operators while attaining high per-node throughput similar to single-node systems, linear scaling to 100 nodes, sub-second latency, and sub-second fault recovery. Finally, D-Streams can easily be composed with batch and interactive query models like …",
        "year": 2013,
        "authors": "Matei Zaharia and Tathagata Das and Haoyuan Li and Timothy Hunter and Scott Shenker and Ion Stoica"
      }
    ],
    "fNOReswAAAAJ": [
      {
        "title": "Direct-coupling analysis of residue coevolution captures native contacts across many protein families",
        "abstract": "The similarity in the three-dimensional structures of homologous proteins imposes strong constraints on their sequence variability. It has long been suggested that the resulting correlations among amino acid compositions at different sequence positions can be exploited to infer spatial contacts within the tertiary protein structure. Crucial to this inference is the ability to disentangle direct and indirect correlations, as accomplished by the recently introduced direct-coupling analysis (DCA). Here we develop a computationally efficient implementation of DCA, which allows us to evaluate the accuracy of contact prediction by DCA for a large number of protein domains, based purely on sequence information. DCA is shown to yield a large number of correctly predicted contacts, recapitulating the global structure of the contact map for the majority of the protein domains examined. Furthermore, our analysis captures clear …",
        "year": 2011,
        "authors": "Faruck Morcos and Andrea Pagnani and Bryan Lunt and Arianna Bertolino and Debora S Marks and Chris Sander and Riccardo Zecchina and José N Onuchic and Terence Hwa and Martin Weigt"
      },
      {
        "title": "Protein 3D structure computed from evolutionary sequence variation",
        "abstract": "The evolutionary trajectory of a protein through sequence space is constrained by its function. Collections of sequence homologs record the outcomes of millions of evolutionary experiments in which the protein evolves according to these constraints. Deciphering the evolutionary record held in these sequences and exploiting it for predictive and engineering purposes presents a formidable challenge. The potential benefit of solving this challenge is amplified by the advent of inexpensive high-throughput genomic sequencing.In this paper we ask whether we can infer evolutionary constraints from a set of sequence homologs of a protein. The challenge is to distinguish true co-evolution couplings from the noisy set of observed correlations. We address this challenge using a maximum entropy model of the protein sequence, constrained by the statistics of the multiple sequence alignment, to infer residue pair couplings. Surprisingly, we find that the strength of these inferred couplings is an excellent predictor of residue-residue proximity in folded structures. Indeed, the top-scoring residue couplings are sufficiently accurate and well-distributed to define the 3D protein fold with remarkable accuracy.We quantify this observation by computing, from sequence alone, all-atom 3D structures of fifteen test proteins from different fold classes, ranging in size from 50 to 260 residues., including a G-protein coupled receptor. These blinded inferences are de novo, i.e., they do not use homology modeling or sequence-similar fragments from known structures. The co-evolution signals provide sufficient information to determine accurate 3D protein structure to …",
        "year": 2011,
        "authors": "Debora S Marks and Lucy J Colwell and Robert Sheridan and Thomas A Hopf and Andrea Pagnani and Riccardo Zecchina and Chris Sander"
      },
      {
        "title": "Analytic and algorithmic solution of random satisfiability problems",
        "abstract": "We study the satisfiability of random Boolean expressions built from many clauses with K variables per clause (K-satisfiability). Expressions with a ratio α of clauses to variables less than a threshold αc are almost always satisfiable, whereas those with a ratio above this threshold are almost always unsatisfiable. We show the existence of an intermediate phase below αc, where the proliferation of metastable states is responsible for the onset of complexity in search algorithms. We introduce a class of optimization algorithms that can deal with these metastable states; one such algorithm has been tested successfully on the largest existing benchmark of K-satisfiability.",
        "year": 2002,
        "authors": "Marc Mézard and Giorgio Parisi and Riccardo Zecchina"
      }
    ],
    "p9RsPG4AAAAJ": [
      {
        "title": "Content-based book recommending using learning for text categorization",
        "abstract": "Recommender systems improve access to relevant products and information by making personalized suggestions based on previous examples of a user's likes and dislikes.  Most existing recommender systems use collaborative filtering methods that base recommendations on other users' preferences. By contrast,content-based methods use information about an item itself to make suggestions.This approach has the advantage of being able to recommend previously unrated items to users with unique interests and to provide explanations for its recommendations. We describe a content-based book recommending system that utilizes information extraction and a machine-learning algorithm for text categorization.  Initial experimental results demonstrate that this approach can produce accurate recommendations.",
        "year": 2000,
        "authors": "Raymond J Mooney and Loriene Roy"
      },
      {
        "title": "Content-boosted collaborative filtering for improved recommendations",
        "abstract": "Most recommender systems use Collaborative Filtering or Content-based methods to predict new items of interest for a user. While both methods have their own advantages, individually they fail to provide good recommendations in many situations. Incorporating components from both methods, a hybrid recommender system can overcome these shortcomings. In this paper, we present an elegant and effective framework for combining content and collaboration. Our approach uses a content-based predictor to enhance existing user data, and then provides personalized suggestions through collaborative filtering. We present experimental results that show how this approach, Content-Boosted Collaborative Filtering, performs better than a pure content-based predictor, pure collaborative filter, and a naive hybrid approach.",
        "year": 2002,
        "authors": "Prem Melville and Raymond J Mooney and Ramadass Nagarajan"
      },
      {
        "title": "Sequence to sequence-video to text",
        "abstract": "Real-world videos often have complex dynamics; methods for generating open-domain video descriptions should be senstive to temporal structure and allow both input (sequence of frames) and output (sequence of words) of variable length. To approach this problem we propose a novel end-to-end sequence-to-sequence model to generate captions for videos. For this we exploit recurrent neural networks, specifically LSTMs, which have demonstrated state-of-the-art performance in image caption generation. Our LSTM model is trained on video-sentence pairs and learns to associate a sequence of video frames to a sequence of words in order to generate a description of the event in the video clip. Our model naturally is able to learn the temporal structure of the sequence of frames as well as the sequence model of the generated sentences, ie a language model. We evaluate several variants of our model that exploit different visual features on a standard set of YouTube videos and two movie description datasets (M-VAD and MPII-MD).",
        "year": 2015,
        "authors": "Subhashini Venugopalan and Marcus Rohrbach and Jeffrey Donahue and Raymond Mooney and Trevor Darrell and Kate Saenko"
      }
    ],
    "8-p9CLsAAAAJ": [
      {
        "title": "Motion planning with sequential convex optimization and convex collision checking",
        "abstract": "We present a new optimization-based approach for robotic motion planning among obstacles. Like CHOMP (Covariant Hamiltonian Optimization for Motion Planning), our algorithm can be used to find collision-free trajectories from naïve, straight-line initializations that might be in collision. At the core of our approach are (a) a sequential convex optimization procedure, which penalizes collisions with a hinge loss and increases the penalty coefficients in an outer loop as necessary, and (b) an efficient formulation of the no-collisions constraint that directly considers continuous-time safety Our algorithm is implemented in a software package called TrajOpt.We report results from a series of experiments comparing TrajOpt with CHOMP and randomized planners from OMPL, with regard to planning time and path quality. We consider motion planning for 7 DOF robot arms, 18 DOF full-body robots, statically stable walking …",
        "year": 2014,
        "authors": "John Schulman and Yan Duan and Jonathan Ho and Alex Lee and Ibrahim Awwal and Henry Bradlow and Jia Pan and Sachin Patil and Ken Goldberg and Pieter Abbeel"
      },
      {
        "title": "Finding locally optimal, collision-free trajectories with sequential convex optimization.",
        "abstract": "We present a novel approach for incorporating collision avoidance into trajectory optimization as a method of solving robotic motion planning problems. At the core of our approach are (i) A sequential convex optimization procedure, which penalizes collisions with a hinge loss and increases the penalty coefficients in an outer loop as necessary.(ii) An efficient formulation of the no-collisions constraint that directly considers continuous-time safety and enables the algorithm to reliably solve motion planning problems, including problems involving thin and complex obstacles.We benchmarked our algorithm against several other motion planning algorithms, solving a suite of 7-degree-of-freedom (DOF) arm-planning problems and 18-DOF full-body planning problems. We compared against sampling-based planners from OMPL, and we also compared to CHOMP, a leading approach for trajectory optimization. Our algorithm was faster than the alternatives, solved more problems, and yielded higher quality paths.",
        "year": 2013,
        "authors": "John Schulman and Jonathan Ho and Alex X Lee and Ibrahim Awwal and Henry Bradlow and Pieter Abbeel"
      },
      {
        "title": "Stochastic adversarial video prediction",
        "abstract": "Being able to predict what may happen in the future requires an in-depth understanding of the physical and causal rules that govern the world. A model that is able to do so has a number of appealing applications, from robotic planning to representation learning. However, learning to predict raw future observations, such as frames in a video, is exceedingly challenging -- the ambiguous nature of the problem can cause a naively designed model to average together possible futures into a single, blurry prediction. Recently, this has been addressed by two distinct approaches: (a) latent variational variable models that explicitly model underlying stochasticity and (b) adversarially-trained models that aim to produce naturalistic images. However, a standard latent variable model can struggle to produce realistic results, and a standard adversarially-trained model underutilizes latent variables and fails to produce diverse predictions. We show that these distinct methods are in fact complementary. Combining the two produces predictions that look more realistic to human raters and better cover the range of possible futures. Our method outperforms prior and concurrent work in these aspects.",
        "year": 2018,
        "authors": "Alex X Lee and Richard Zhang and Frederik Ebert and Pieter Abbeel and Chelsea Finn and Sergey Levine"
      }
    ],
    "OSg3D9MAAAAJ": [
      {
        "title": "Recasting gradient-based meta-learning as hierarchical Bayes",
        "abstract": "Meta-learning allows an intelligent agent to leverage prior learning episodes as a basis for quickly improving performance on a novel task. Bayesian hierarchical modeling provides a theoretical framework for formalizing meta-learning as inference for a set of parameters that are shared across tasks. Here, we reformulate the model-agnostic meta-learning algorithm (MAML) of Finn et al. (2017) as a method for probabilistic inference in a hierarchical Bayesian model. In contrast to prior methods for meta-learning via hierarchical Bayes, MAML is naturally applicable to complex function approximators through its use of a scalable gradient descent procedure for posterior inference. Furthermore, the identification of MAML as hierarchical Bayes provides a way to understand the algorithm's operation as a meta-learning procedure, as well as an opportunity to make use of computational strategies for efficient inference. We use this opportunity to propose an improvement to the MAML algorithm that makes use of techniques from approximate inference and curvature estimation.",
        "year": 2018,
        "authors": "Erin Grant and Chelsea Finn and Sergey Levine and Trevor Darrell and Thomas L Griffiths"
      },
      {
        "title": "Are convolutional neural networks or transformers more like human vision?",
        "abstract": "Modern machine learning models for computer vision exceed humans in accuracy on specific visual recognition tasks, notably on datasets like ImageNet. However, high accuracy can be achieved in many ways. The particular decision function found by a machine learning system is determined not only by the data to which the system is exposed, but also the inductive biases of the model, which are typically harder to characterize. In this work, we follow a recent trend of in-depth behavioral analyses of neural network models that go beyond accuracy as an evaluation metric by looking at patterns of errors. Our focus is on comparing a suite of standard Convolutional Neural Networks (CNNs) and a recently-proposed attention-based network, the Vision Transformer (ViT), which relaxes the translation-invariance constraint of CNNs and therefore represents a model with a weaker set of inductive biases. Attention-based networks have previously been shown to achieve higher accuracy than CNNs on vision tasks, and we demonstrate, using new metrics for examining error consistency with more granularity, that their errors are also more consistent with those of humans. These results have implications both for building more human-like vision models, as well as for understanding visual object recognition in humans.",
        "year": 2021,
        "authors": "Shikhar Tuli and Ishita Dasgupta and Erin Grant and Thomas L Griffiths"
      },
      {
        "title": "Doing more with less: Meta-reasoning and meta-learning in humans and machines",
        "abstract": "Artificial intelligence systems use an increasing amount of computation and data to solve very specific problems. By contrast, human minds solve a wide range of problems using a fixed amount of computation and limited experience. We identify two abilities that we see as crucial to this kind of general intelligence: meta-reasoning (deciding how to allocate computational resources) and meta-learning (modeling the learning environment to make better use of limited data). We summarize the relevant AI literature and relate the resulting ideas to recent work in psychology.",
        "year": 2019,
        "authors": "Thomas L Griffiths and Frederick Callaway and Michael B Chang and Erin Grant and Paul M Krueger and Falk Lieder"
      }
    ],
    "yA4rb60AAAAJ": [
      {
        "title": "Image-to-image translation with conditional adversarial networks",
        "abstract": "We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Moreover, since the release of the pix2pix software associated with this paper, hundreds of twitter users have posted their own artistic experiments using our system. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without handengineering our loss functions either.",
        "year": 2017,
        "authors": "Phillip Isola and Jun-Yan Zhu and Tinghui Zhou and Alexei A Efros"
      },
      {
        "title": "Unsupervised learning of depth and ego-motion from video",
        "abstract": "We present an unsupervised learning framework for the task of dense 3D geometry and camera motion estimation from unstructured video sequences. In common with recent work, we use an end-to-end learning approach with view synthesis as the supervisory signal. In contrast to these works, our method is completely unsupervised, requiring only a sequence of images as input. We achieve this with a network that estimates the 6-DoF camera pose parameters of the input set, along with dense depth for a reference view using single-view inference. Our loss is constructed by projecting the nearby posed views into the reference view via the depth map. Results using the KITTI dataset demonstrate the effectiveness of our approach, which performs on par with another deep learning approach that assumes ground-truth pose information at training time.",
        "year": 2017,
        "authors": "Tinghui Zhou and Matthew Brown and Noah Snavely and David G Lowe"
      },
      {
        "title": "Rethinking the value of network pruning",
        "abstract": "Network pruning is widely used for reducing the heavy inference cost of deep models in low-resource settings. A typical pruning algorithm is a three-stage pipeline, i.e., training (a large model), pruning and fine-tuning. During pruning, according to a certain criterion, redundant weights are pruned and important weights are kept to best preserve the accuracy. In this work, we make several surprising observations which contradict common beliefs. For all state-of-the-art structured pruning algorithms we examined, fine-tuning a pruned model only gives comparable or worse performance than training that model with randomly initialized weights. For pruning algorithms which assume a predefined target network architecture, one can get rid of the full pipeline and directly train the target network from scratch. Our observations are consistent for multiple network architectures, datasets, and tasks, which imply that: 1) training a large, over-parameterized model is often not necessary to obtain an efficient final model, 2) learned \"important\" weights of the large model are typically not useful for the small pruned model, 3) the pruned architecture itself, rather than a set of inherited \"important\" weights, is more crucial to the efficiency in the final model, which suggests that in some cases pruning can be useful as an architecture search paradigm. Our results suggest the need for more careful baseline evaluations in future research on structured pruning methods. We also compare with the \"Lottery Ticket Hypothesis\" (Frankle & Carbin 2019), and find that with optimal learning rate, the \"winning ticket\" initialization as used in Frankle & Carbin (2019) does not bring …",
        "year": 2018,
        "authors": "Zhuang Liu and Mingjie Sun and Tinghui Zhou and Gao Huang and Trevor Darrell"
      }
    ],
    "q4zv0KYAAAAJ": [
      {
        "title": "Raptor codes on binary memoryless symmetric channels",
        "abstract": "In this paper, we will investigate the performance of Raptor codes on arbitrary binary input memoryless symmetric channels (BIMSCs). In doing so, we generalize some of the results that were proved before for the erasure channel. We will generalize the stability condition to the class of Raptor codes. This generalization gives a lower bound on the fraction of output nodes of degree 2 of a Raptor code if the error probability of the belief-propagation decoder converges to zero. Using information-theoretic arguments, we will show that if a sequence of output degree distributions is to achieve the capacity of the underlying channel, then the fraction of nodes of degree 2 in these degree distributions has to converge to a certain quantity depending on the channel. For the class of erasure channels this quantity is independent of the erasure probability of the channel, but for many other classes of BIMSCs, this fraction depends …",
        "year": 2006,
        "authors": "Omid Etesami and Amin Shokrollahi"
      },
      {
        "title": "Dynamics of bid optimization in online advertisement auctions",
        "abstract": "We consider the problem of online keyword advertising auctions among multiple bidders with limited budgets, and study a natural bidding heuristic in which advertisers attempt to optimize their utility by equalizing their return-on-investment across all keywords. We show that existing auction mechanisms combined with this heuristic can experience cycling (as has been observed in many current systems), and therefore propose a modified class of mechanisms with small random perturbations. This perturbation is reminiscent of the small time-dependent perturbations employed in the dynamical systems literature to convert many types of chaos into attracting motions. We show that the perturbed mechanism provably converges in the case of first-price auctions and experimentally converges in the case of second-price auctions. Moreover, the point of convergence has a natural economic interpretation as the unique …",
        "year": 2007,
        "authors": "Christian Borgs and Jennifer Chayes and Nicole Immorlica and Kamal Jain and Omid Etesami and Mohammad Mahdian"
      },
      {
        "title": "Mafia: A theoretical study of players and coalitions in a partial information environment",
        "abstract": "In this paper, we study a game called “Mafia,” in which different players have different types of information, communication and functionality. The players communicate and function in a way that resembles some real-life situations. We consider two types of operations. First, there are operations that follow an open democratic discussion. Second, some subgroups of players who may have different interests make decisions based on their own group interest. A key ingredient here is that the identity of each subgroup is known only to the members of that group.In this paper, we are interested in the best strategies for the different groups in such scenarios and in evaluating their relative power. The main focus of the paper is the question: How large and strong should a subgroup be in order to dominate the game?The concrete model studied here is based on the popular game “Mafia.” In this game, there are three …",
        "year": 2008,
        "authors": "Mark Braverman and Omid Etesami and Elchanan Mossel"
      }
    ],
    "-zaDQ10AAAAJ": [
      {
        "title": "Super learner",
        "abstract": "When trying to learn a model for the prediction of an outcome given a set of covariates, a statistician has many estimation procedures in their toolbox.  A few examples of these candidate learners are: least squares, least angle regression, random forests, and spline regression.  Previous articles (van der Laan and Dudoit (2003); van der Laan et al. (2006); Sinisi et al. (2007)) theoretically validated the use of cross validation to select an optimal learner among many candidate learners.  Motivated by this use of cross validation, we propose a new prediction method for creating a weighted combination of many candidate learners to build the super learner.  This article proposes a fast algorithm for constructing a super learner in prediction which uses V-fold cross-validation to select weights to combine an initial set of candidate learners.  In addition, this paper contains a practical demonstration of the adaptivity of this so …",
        "year": 2007,
        "authors": "Mark J Van der Laan and Eric C Polley and Alan E Hubbard"
      },
      {
        "title": "Targeted learning: causal inference for observational and experimental data",
        "abstract": "The statistics profession is at a unique point in history. The need for valid statistical tools is greater than ever; data sets are massive, often measuring hundreds of thousands of measurements for a single subject. The field is ready to move towards clear objective benchmarks under which tools can be evaluated. Targeted learning allows (1) the full generalization and utilization of cross-validation as an estimator selection tool so that the subjective choices made by humans are now made by the machine, and (2) targeting the fitting of the probability distribution of the data toward the target parameter representing the scientific question of interest.",
        "year": 2011,
        "authors": "Mark van der Laan and Sherri Rose"
      }
    ],
    "hiGI9v0AAAAJ": [
      {
        "title": "MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels",
        "abstract": "Recent deep networks are capable of memorizing the entire data even when the labels are completely random. To overcome the overfitting on corrupted labels, we propose a novel technique of learning another neural network, called MentorNet, to supervise the training of the base deep networks, namely, StudentNet. During training, MentorNet provides a curriculum (sample weighting scheme) for StudentNet to focus on the sample the label of which is probably correct. Unlike the existing curriculum that is usually predefined by human experts, MentorNet learns a data-driven curriculum dynamically with StudentNet. Experimental results demonstrate that our approach can significantly improve the generalization performance of deep networks trained on corrupted training data. Notably, to the best of our knowledge, we achieve the best-published result on WebVision, a large benchmark containing 2.2 million images of real-world noisy labels.",
        "year": 2018,
        "authors": "Lu Jiang and Zhengyuan Zhou and Thomas Leung and Li-Jia Li and Li Fei-Fei"
      },
      {
        "title": "Learning in games with continuous action sets and unknown payoff functions",
        "abstract": "This paper examines the convergence of no-regret learning in games with continuous action sets. For concreteness, we focus on learning via “dual averaging”, a widely used class of no-regret learning schemes where players take small steps along their individual payoff gradients and then “mirror” the output back to their action sets. In terms of feedback, we assume that players can only estimate their payoff gradients up to a zero-mean error with bounded variance. To study the convergence of the induced sequence of play, we introduce the notion of variational stability, and we show that stable equilibria are locally attracting with high probability whereas globally stable equilibria are globally attracting with probability 1. We also discuss some applications to mixed-strategy learning in finite games, and we provide explicit estimates of the method’s convergence speed.",
        "year": 2019,
        "authors": "Panayotis Mertikopoulos and Zhengyuan Zhou"
      },
      {
        "title": "Estimation considerations in contextual bandits",
        "abstract": "Contextual bandit algorithms are sensitive to the estimation method of the outcome model as well as the exploration method used, particularly in the presence of rich heterogeneity or complex outcome models, which can lead to difficult estimation problems along the path of learning. We study a consideration for the exploration vs. exploitation framework that does not arise in multi-armed bandits but is crucial in contextual bandits; the way exploration and exploitation is conducted in the present affects the bias and variance in the potential outcome model estimation in subsequent stages of learning. We develop parametric and non-parametric contextual bandits that integrate balancing methods from the causal inference literature in their estimation to make it less prone to problems of estimation bias. We provide the first regret bound analyses for contextual bandits with balancing in the domain of linear contextual bandits that match the state of the art regret bounds. We demonstrate the strong practical advantage of balanced contextual bandits on a large number of supervised learning datasets and on a synthetic example that simulates model mis-specification and prejudice in the initial training data. Additionally, we develop contextual bandits with simpler assignment policies by leveraging sparse model estimation methods from the econometrics literature and demonstrate empirically that in the early stages they can improve the rate of learning and decrease regret.",
        "year": 2017,
        "authors": "Maria Dimakopoulou and Zhengyuan Zhou and Susan Athey and Guido Imbens"
      }
    ],
    "gFLW9qcAAAAJ": [
      {
        "title": "The Blessings of Multiple Causes",
        "abstract": "Causal inference from observational data is a vital problem, but it comes with strong assumptions. Most methods assume that we observe all confounders, variables that affect both the causal variables and the outcome variables. This assumption is standard but it is also untestable. In this article, we develop the deconfounder, a way to do causal inference with weaker assumptions than the traditional methods require. The deconfounder is designed for problems of multiple causal inference: scientific studies that involve multiple causes whose effects are simultaneously of interest. Specifically, the deconfounder combines unsupervised machine learning and predictive model checking to use the dependencies among multiple causes as indirect evidence for some of the unobserved confounders. We develop the deconfounder algorithm, prove that it is unbiased, and show that it requires weaker assumptions than …",
        "year": 2019,
        "authors": "Yixin Wang and David M Blei"
      },
      {
        "title": "Frequentist Consistency of Variational Bayes",
        "abstract": "A key challenge for modern Bayesian statistics is how to perform scalable inference of posterior distributions. To address this challenge, variational Bayes (VB) methods have emerged as a popular alternative to the classical Markov chain Monte Carlo (MCMC) methods. VB methods tend to be faster while achieving comparable predictive performance. However, there are few theoretical results around VB. In this article, we establish frequentist consistency and asymptotic normality of VB methods. Specifically, we connect VB methods to point estimates based on variational approximations, called frequentist variational approximations, and we use the connection to prove a variational Bernstein–von Mises theorem. The theorem leverages the theoretical characterizations of frequentist variational approximations to understand asymptotic properties of VB. In summary, we prove that (1) the VB posterior converges to the …",
        "year": 2019,
        "authors": "Yixin Wang and David M Blei"
      },
      {
        "title": "Causal inference for recommender systems",
        "abstract": "The task of recommender systems is classically framed as a prediction of users’ preferences and users’ ratings. However, its spirit is to answer a counterfactual question: “What would the rating be if we ‘forced’ the user to watch the movie?” This is a question about an intervention, that is a causal inference question. The key challenge of this causal inference is unobserved confounders, variables that affect both which items the users decide to interact with and how they rate them. To this end, we develop an algorithm that leverages classical recommendation models for causal recommendation. Across simulated and real datasets, we demonstrate that the proposed algorithm is more robust to unobserved confounders and improves recommendation.",
        "year": 2020,
        "authors": "Yixin Wang and Dawen Liang and Laurent Charlin and David M Blei"
      }
    ],
    "ExXP2_AAAAAJ": [
      {
        "title": "Motion planning with sequential convex optimization and convex collision checking",
        "abstract": "We present a new optimization-based approach for robotic motion planning among obstacles. Like CHOMP (Covariant Hamiltonian Optimization for Motion Planning), our algorithm can be used to find collision-free trajectories from naïve, straight-line initializations that might be in collision. At the core of our approach are (a) a sequential convex optimization procedure, which penalizes collisions with a hinge loss and increases the penalty coefficients in an outer loop as necessary, and (b) an efficient formulation of the no-collisions constraint that directly considers continuous-time safety Our algorithm is implemented in a software package called TrajOpt.We report results from a series of experiments comparing TrajOpt with CHOMP and randomized planners from OMPL, with regard to planning time and path quality. We consider motion planning for 7 DOF robot arms, 18 DOF full-body robots, statically stable walking …",
        "year": 2014,
        "authors": "John Schulman and Yan Duan and Jonathan Ho and Alex Lee and Ibrahim Awwal and Henry Bradlow and Jia Pan and Sachin Patil and Ken Goldberg and Pieter Abbeel"
      },
      {
        "title": "Finding locally optimal, collision-free trajectories with sequential convex optimization.",
        "abstract": "We present a novel approach for incorporating collision avoidance into trajectory optimization as a method of solving robotic motion planning problems. At the core of our approach are (i) A sequential convex optimization procedure, which penalizes collisions with a hinge loss and increases the penalty coefficients in an outer loop as necessary.(ii) An efficient formulation of the no-collisions constraint that directly considers continuous-time safety and enables the algorithm to reliably solve motion planning problems, including problems involving thin and complex obstacles.We benchmarked our algorithm against several other motion planning algorithms, solving a suite of 7-degree-of-freedom (DOF) arm-planning problems and 18-DOF full-body planning problems. We compared against sampling-based planners from OMPL, and we also compared to CHOMP, a leading approach for trajectory optimization. Our algorithm was faster than the alternatives, solved more problems, and yielded higher quality paths.",
        "year": 2013,
        "authors": "John Schulman and Jonathan Ho and Alex X Lee and Ibrahim Awwal and Henry Bradlow and Pieter Abbeel"
      },
      {
        "title": "Characterization of user’s behavior variations for design of replayable mobile workloads",
        "abstract": "Mobile systems leverage heterogeneous cores to deliver a desired user experience. However, how these cores cooperate in executing interactive mobile applications in the hands of a real user is unclear, preventing more realistic studies on mobile platforms. In this paper, we study how 33 users run applications on modern smartphones over a period of a month. We analyze the usage of CPUs, GPUs and associated memory operations in real user interactions, and develop microbenchmarks on an automated methodology which describes realistic and replayable test runs that statistically mimic user variations. Based on the generated test runs, we further empirically characterize memory bandwidth and power consumption of CPUs and GPUs to show the impact of user variations in the system, and identify user variation-aware optimization opportunities in actual mobile application uses.",
        "year": 2015,
        "authors": "Shruti Patil and Yeseong Kim and Kunal Korgaonkar and Ibrahim Awwal and Tajana S Rosing"
      }
    ],
    "lMkTx0EAAAAJ": [
      {
        "title": "Gene selection for cancer classification using support vector machines",
        "abstract": "DNA micro-arrays now permit scientists to screen thousands of genes simultaneously and determine whether those genes are active, hyperactive or silent in normal or cancerous tissue. Because these new micro-array devices generate bewildering amounts of raw data, new analytical methods must be developed to sort out whether cancer tissues have distinctive signatures of gene expression over normal tissues or other types of cancer tissues.In this paper, we address the problem of selection of a small subset of genes from broad patterns of gene expression data, recorded on DNA micro-arrays. Using available training examples from cancer and normal patients, we build a classifier suitable for genetic diagnosis, as well as drug discovery. Previous attempts to address this problem select genes with correlation techniques. We propose a new method of gene selection utilizing Support Vector …",
        "year": 2002,
        "authors": "Isabelle Guyon and Jason Weston and Stephen Barnhill and Vladimir Vapnik"
      },
      {
        "title": "Natural language processing (almost) from scratch",
        "abstract": "We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.",
        "year": 2011,
        "authors": "Ronan Collobert and Jason Weston and Léon Bottou and Michael Karlen and Koray Kavukcuoglu and Pavel Kuksa"
      },
      {
        "title": "Translating embeddings for modeling multi-relational data",
        "abstract": "We consider the problem of embedding entities and relationships of multi-relational data in low-dimensional vector spaces. Our objective is to propose a canonical model which is easy to train, contains a reduced number of parameters and can scale up to very large databases. Hence, we propose, TransE, a method which models relationships by interpreting them as translations operating on the low-dimensional embeddings of the entities. Despite its simplicity, this assumption proves to be powerful since extensive experiments show that TransE significantly outperforms state-of-the-art methods in link prediction on two knowledge bases. Besides, it can be successfully trained on a large scale data set with 1M entities, 25k relationships and more than 17M training samples.",
        "year": 2013,
        "authors": "Antoine Bordes and Nicolas Usunier and Alberto Garcia-Duran and Jason Weston and Oksana Yakhnenko"
      }
    ],
    "wMcPTbEAAAAJ": [
      {
        "title": "RMA: Rapid motor adaptation for legged robots",
        "abstract": "Successful real-world deployment of legged robots would require them to adapt in real-time to unseen scenarios like changing terrains, changing payloads, wear and tear. This paper presents Rapid Motor Adaptation (RMA) algorithm to solve this problem of real-time online adaptation in quadruped robots. RMA consists of two components: a base policy and an adaptation module. The combination of these components enables the robot to adapt to novel situations in fractions of a second. RMA is trained completely in simulation without using any domain knowledge like reference trajectories or predefined foot trajectory generators and is deployed on the A1 robot without any fine-tuning. We train RMA on a varied terrain generator using bioenergetics-inspired rewards and deploy it on a variety of difficult terrains including rocky, slippery, deformable surfaces in environments with grass, long vegetation, concrete, pebbles, stairs, sand, etc. RMA shows state-of-the-art performance across diverse real-world as well as simulation experiments. Video results at https://ashish-kmr.github.io/rma-legged-robots/",
        "year": 2021,
        "authors": "Ashish Kumar and Zipeng Fu and Deepak Pathak and Jitendra Malik"
      },
      {
        "title": "Mobile ALOHA: Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation",
        "abstract": "Imitation learning from human demonstrations has shown impressive performance in robotics. However, most results focus on table-top manipulation, lacking the mobility and dexterity necessary for generally useful tasks. In this work, we develop a system for imitating mobile manipulation tasks that are bimanual and require whole-body control. We first present Mobile ALOHA, a low-cost and whole-body teleoperation system for data collection. It augments the ALOHA system with a mobile base, and a whole-body teleoperation interface. Using data collected with Mobile ALOHA, we then perform supervised behavior cloning and find that co-training with existing static ALOHA datasets boosts performance on mobile manipulation tasks. With 50 demonstrations for each task, co-training can increase success rates by up to 90%, allowing Mobile ALOHA to autonomously complete complex mobile manipulation tasks such as sauteing and serving a piece of shrimp, opening a two-door wall cabinet to store heavy cooking pots, calling and entering an elevator, and lightly rinsing a used pan using a kitchen faucet. Project website: https://mobile-aloha.github.io",
        "year": 2024,
        "authors": "Zipeng Fu and Tony Z Zhao and Chelsea Finn"
      }
    ],
    "8iCb2TwAAAAJ": [
      {
        "title": "Tackling climate change with machine learning",
        "abstract": "Climate change is one of the greatest challenges facing humanity, and we, as machine learning (ML) experts, may wonder how we can help. Here we describe how ML can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by ML, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the ML community to join the global effort against climate change.",
        "year": 2019,
        "authors": "David Rolnick and Priya L Donti and Lynn H Kaack and Kelly Kochanski and Alexandre Lacoste and Kris Sankaran and Andrew Slavin Ross and Nikola Milojevic-Dupont and Natasha Jaques and Anna Waldman-Brown and Alexandra Luccioni and Tegan Maharaj and Evan D Sherwin and S Karthik Mukkavilli and Konrad P Kording and Carla Gomes and Andrew Y Ng and Demis Hassabis and John C Platt and Felix Creutzig and Jennifer Chayes and Yoshua Bengio"
      },
      {
        "title": "Social influence as intrinsic motivation for multi-agent deep reinforcement learning",
        "abstract": "We propose a unified mechanism for achieving coordination and communication in Multi-Agent Reinforcement Learning (MARL), through rewarding agents for having causal influence over other agents’ actions. Causal influence is assessed using counterfactual reasoning. At each timestep, an agent simulates alternate actions that it could have taken, and computes their effect on the behavior of other agents. Actions that lead to bigger changes in other agents’ behavior are considered influential and are rewarded. We show that this is equivalent to rewarding agents for having high mutual information between their actions. Empirical results demonstrate that influence leads to enhanced coordination and communication in challenging social dilemma environments, dramatically increasing the learning curves of the deep RL agents, and leading to more meaningful learned communication protocols. The influence rewards for all agents can be computed in a decentralized way by enabling agents to learn a model of other agents using deep neural networks. In contrast, key previous works on emergent communication in the MARL setting were unable to learn diverse policies in a decentralized manner and had to resort to centralized training. Consequently, the influence reward opens up a window of new opportunities for research in this area.",
        "year": 2019,
        "authors": "Natasha Jaques and Angeliki Lazaridou and Edward Hughes and Caglar Gulcehre and Pedro A Ortega and DJ Strouse and Joel Z Leibo and Nando De Freitas"
      },
      {
        "title": "Way off-policy batch deep reinforcement learning of implicit human preferences in dialog",
        "abstract": "Most deep reinforcement learning (RL) systems are not able to learn effectively from off-policy data, especially if they cannot explore online in the environment. These are critical shortcomings for applying RL to real-world problems where collecting data is expensive, and models must be tested offline before being deployed to interact with the environment -- e.g. systems that learn from human interaction. Thus, we develop a novel class of off-policy batch RL algorithms, which are able to effectively learn offline, without exploring, from a fixed batch of human interaction data. We leverage models pre-trained on data as a strong prior, and use KL-control to penalize divergence from this prior during RL training. We also use dropout-based uncertainty estimates to lower bound the target Q-values as a more efficient alternative to Double Q-Learning. The algorithms are tested on the problem of open-domain dialog generation -- a challenging reinforcement learning problem with a 20,000-dimensional action space. Using our Way Off-Policy algorithm, we can extract multiple different reward functions post-hoc from collected human interaction data, and learn effectively from all of these. We test the real-world generalization of these systems by deploying them live to converse with humans in an open-domain setting, and demonstrate that our algorithm achieves significant improvements over prior methods in off-policy batch RL.",
        "year": 2019,
        "authors": "Natasha Jaques and Asma Ghandeharioun and Judy Hanwen Shen and Craig Ferguson and Agata Lapedriza and Noah Jones and Shixiang Gu and Rosalind Picard"
      }
    ],
    "r81Ss1cAAAAJ": [
      {
        "title": "Social information filtering: Algorithms for automating “word of mouth”",
        "abstract": "This paper describes a technique for making personalized recommendations from any type of database to a user based on similarities between the interest profile of that user and those of other users. In particular, we discuss the implementation of a networked system called Ringo, which makes personalized recommendations for music albums and artists. Ringo's database of users and artists grows dynamically as more people use the system and enter more information. Four different algorithms for making recommendations by using social information filtering were tested and compared. We present quantitative and qualitative results obtained from the use of Ringo by more than 2000 people.",
        "year": 1995,
        "authors": "Upendra Shardanand and Pattie Maes"
      },
      {
        "title": "Agents that reduce work and information overload",
        "abstract": "Publisher SummaryComputers are becoming the vehicle for an increasing range of everyday activities. Acquisition of news and information, mail and even social interactions and entertainment have become more and more computer based. These technological developments are not in line with a change in the way people interact with computers. Techniques from the field of AI, in particular so-called autonomous agents, can be used to implement a complementary style of interaction, which has been referred to as indirect management. Agents assist users in a range of different ways. They hide the complexity of difficult tasks, they perform tasks on the user's behalf, they can train or teach the user, they help different users collaborate, and they monitor events and procedures. The chapter focuses on an approach to building interface agents. It presents results from several prototype agents that have been built using …",
        "year": 1995,
        "authors": "Pattie Maes"
      },
      {
        "title": "Concepts and experiments in computational reflection",
        "abstract": "This paper brings some perspective to various concepts in computational reflection. A definition of computational reflection is presented, the importance of computational reflection is discussed and the architecture of languages that support reflection is studied. Further, this paper presents a survey of some experiments in reflection which have been performed. Examples of existing procedural, logic-based and rule-based languages with an architecture for reflection are briefly presented. The main part of the paper describes an original experiment to introduce a reflective architecture in an object-oriented language. It stresses the contributions of this language to the field of object-oriented programming and illustrates the new programming style made possible. The examples show that a lot of programming problems that were previously handled on an ad hoc basis, can in a reflective architecture be solved more elegantly.",
        "year": 1987,
        "authors": "Pattie Maes"
      }
    ],
    "xaYqRfAAAAAJ": [
      {
        "title": "Modeling and simulation for automatic control",
        "abstract": "Modeling and simulation of dynamic processes are very important subjects in control systems design. Most processes that are encountered in practical controller design are very well described in the engineering literature, and it is important that the control engineer is able to take advantage of this information. It is a problem that several books must be used to get the relevant modeling information of a particular process, and it may take a long time to go through all the necessary material. The idea of this book is to supply the control engineer with a sufficient modeling background to design controllers for a wide range of processes. In addition, the book provides a good starting point for going into the specialist literature of different engineering disciplines. In this connection the references indicate where to start. The book also contains more material than what will normally be covered in the lectures of a typical course, so that students may return to the book at a later stage and find additional information about a particular subject. This will be more efficient than to extract the required information from a series of other books. In this sense the book will be of great value for practicing control engineers. The development of new products and systems is often done in a team of experts with different backgrounds. It is hoped that this book will help control engineers to communicate with other experts in this type of team. To achieve this we have been careful to use standard terminology and notation from the different engineering disciplines in question. Here we deliberately break the tradition evident in many books in the control literature where the emphasis is on …",
        "year": 2002,
        "authors": "Olav Egeland and Jan Tommy Gravdahl"
      },
      {
        "title": "Satellite attitude control by quaternion-based backstepping",
        "abstract": "In this paper a result on attitude control of a microsatellite by integrator backstepping based on quaternion feedback is presented, and the controller is shown to make the closed loop equilibrium points asymptotic stable in the sense of Lyapunov. This is a part of a study of possible control methods for the spacecraft European Student Earth Orbiter (ESEO), a spacecraft included in the Student Space Exploration and Technology Initiative (SSETI) project initiated by ESA. The spacecraft is actuated by four reaction control thrusters and one reaction wheel, and simulation results based on data from the satellite are presented.",
        "year": 2005,
        "authors": "Raymond Kristiansen and Per Johan Nicklasson"
      },
      {
        "title": "Snake robots: modelling, mechatronics, and control",
        "abstract": "Snake Robots is a novel treatment of theoretical and practical topics related to snake robots: robotic mechanisms designed to move like biological snakes and able to operate in challenging environments in which human presence is either undesirable or impossible. Future applications of such robots include search and rescue, inspection and maintenance, and subsea operations. Locomotion in unstructured environments is a focus for this book.The text targets the disparate muddle of approaches to modelling, development and control of snake robots in current literature, giving a unified presentation of recent research results on snake robot locomotion to increase the reader’s basic understanding of these mechanisms and their motion dynamics and clarify the state of the art in the field. The book is a complete treatment of snake robotics, with topics ranging from mathematical modelling techniques, through …",
        "year": 2013,
        "authors": "Pål Liljebäck and Kristin Y Pettersen and Øyvind Stavdahl and Jan Tommy Gravdahl"
      }
    ],
    "tk3X1QkAAAAJ": [
      {
        "title": "Point-based value iteration for continuous POMDPs",
        "abstract": "We propose a novel approach to optimize Partially Observable Markov Decisions Processes (POMDPs) defined on continuous spaces. To date, most algorithms for model-based POMDPs are restricted to discrete states, actions, and observations, but many real-world problems such as, for instance, robot navigation, are naturally defined on continuous spaces. In this work, we demonstrate that the value function for continuous POMDPs is convex in the beliefs over continuous state spaces, and piecewise-linear convex for the particular case of discrete observations and actions but still continuous states. We also demonstrate that continuous Bellman backups are contracting and isotonic ensuring the monotonic convergence of value-iteration algorithms. Relying on those properties, we extend the algorithm, originally developed for discrete POMDPs, to work in continuous state spaces by representing the observation, transition, and reward models using Gaussian mixtures, and the beliefs using Gaussian mixtures or particle sets. With these representations, the integrals that appear in the Bellman backup can be computed in closed form and, therefore, the algorithm is computationally feasible. Finally, we further extend to deal with continuous action and observation sets by designing effective sampling approaches.",
        "year": 2006,
        "authors": "Josep M Porta and Nikos Vlassis and Matthijs TJ Spaan and Pascal Poupart"
      },
      {
        "title": "Information-based compact Pose SLAM",
        "abstract": " Pose SLAM is the variant of simultaneous localization and map building (SLAM) is the variant of SLAM, in which only the robot trajectory is estimated and where landmarks are only used to produce relative constraints between robot poses. To reduce the computational cost of the information filter form of Pose SLAM and, at the same time, to delay inconsistency as much as possible, we introduce an approach that takes into account only highly informative loop-closure links and nonredundant poses. This approach includes constant time procedures to compute the distance between poses, the expected information gain for each potential link, and the exact marginal covariances while moving in open loop, as well as a procedure to recover the state after a loop closure that, in practical situations, scales linearly in terms of both time and memory. Using these procedures, the robot operates most of the time in open loop …",
        "year": 2010,
        "authors": "Viorela Ila and Josep M Porta and Juan Andrade-Cetto"
      },
      {
        "title": "Path planning under kinematic constraints by rapidly exploring manifolds",
        "abstract": "The situation arising in path planning under kinematic constraints, where the valid configurations define a manifold embedded in the joint ambient space, can be seen as a limit case of the well-known narrow corridor problem. With kinematic constraints, the probability of obtaining a valid configuration by sampling in the joint ambient space is not low but null, which complicates the direct application of sampling-based path planners. This paper presents the AtlasRRT algorithm, which is a planner especially tailored for such constrained systems that builds on recently developed tools for higher-dimensional continuation. These tools provide procedures to define charts that locally parametrize a manifold and to coordinate the charts, forming an atlas that fully covers it. AtlasRRT simultaneously builds an atlas and a bidirectional rapidly exploring random tree (RRT), using the atlas to sample configurations and to grow the …",
        "year": 2013,
        "authors": "Léonard Jaillet and Josep M Porta"
      }
    ],
    "5lB_d78AAAAJ": [
      {
        "title": "Imitation learning as f-divergence minimization",
        "abstract": "We address the problem of imitation learning with multi-modal demonstrations. Instead of attempting to learn all modes, we argue that in many tasks it is sufficient to imitate any one of them. We show that the state-of-the-art methods such as GAIL and behavior cloning, due to their choice of loss function, often incorrectly interpolate between such modes. Our key insight is to minimize the right divergence between the learner and the expert state-action distributions, namely the reverse KL divergence or I-projection. We propose a general imitation learning framework for estimating and minimizing any f-Divergence. By plugging in different divergences, we are able to recover existing algorithms such as Behavior Cloning (Kullback-Leibler), GAIL (Jensen Shannon) and DAgger (Total Variation). Empirical results show that our approximate I-projection technique is able to imitate multi-modal behaviors more reliably …",
        "year": 2021,
        "authors": "Liyiming Ke and Sanjiban Choudhury and Matt Barnes and Wen Sun and Gilwoo Lee and Siddhartha Srinivasa"
      },
      {
        "title": "Regionally accelerated batch informed trees (rabit*): A framework to integrate local information into optimal path planning",
        "abstract": "Sampling-based optimal planners, such as RRT*, almost-surely converge asymptotically to the optimal solution, but have provably slow convergence rates in high dimensions. This is because their commitment to finding the global optimum compels them to prioritize exploration of the entire problem domain even as its size grows exponentially. Optimization techniques, such as CHOMP, have fast convergence on these problems but only to local optima. This is because they are exploitative, prioritizing the immediate improvement of a path even though this may not find the global optimum of nonconvex cost functions.",
        "year": 2016,
        "authors": "Sanjiban Choudhury and Jonathan D Gammell and Timothy D Barfoot and Siddhartha S Srinivasa and Sebastian Scherer"
      },
      {
        "title": "Learning Heuristic Search via Imitation",
        "abstract": "Robotic motion planning problems are typically solved by constructing a search tree of valid maneuvers from a start to a goal configuration. Limited onboard computation and real-time planning constraints impose a limit on how large this search tree can grow. Heuristics play a crucial role in such situations by guiding the search towards potentially good directions and consequently minimizing search effort. Moreover, it must infer such directions in an efficient manner using only the information uncovered by the search up until that time. However, state of the art methods do not address the problem of computing a heuristic that\\emphexplicitly minimizes search effort. In this paper, we do so by training a heuristic policy that maps the partial information from the search to decide which node of the search tree to expand. Unfortunately, naively training such policies leads to slow convergence and poor local minima. We present\\textscSaIL, an efficient algorithm that trains heuristic policies by imitating\\emphclairvoyant oracles-oracles that have full information about the world and demonstrate decisions that minimize search effort. We leverage the fact that such oracles can be efficiently computed using dynamic programming and derive performance guarantees for the learnt heuristic. We validate the approach on a spectrum of environments which show that\\textscSaIL consistently outperforms state of the art algorithms. Our approach paves the way forward for learning heuristics that demonstrate an anytime nature-finding feasible solutions quickly and incrementally refining it over time. Open-source code and details can be found here: https://goo. gl/YXkQAC.",
        "year": 2017,
        "authors": "Mohak Bhardwaj and Sanjiban Choudhury and Sebastian Scherer"
      }
    ],
    "H3Uq3FcAAAAJ": [
      {
        "title": "Recipes for building an open-domain chatbot",
        "abstract": "Building open-domain chatbots is a challenging area for machine learning research. While prior work has shown that scaling neural models in the number of parameters and the size of the data they are trained on gives improved results, we show that other ingredients are important for a high-performing chatbot. Good conversation requires a number of skills that an expert conversationalist blends in a seamless way: providing engaging talking points and listening to their partners, and displaying knowledge, empathy and personality appropriately, while maintaining a consistent persona. We show that large scale models can learn these skills when given appropriate training data and choice of generation strategy. We build variants of these recipes with 90M, 2.7B and 9.4B parameter models, and make our models and code publicly available. Human evaluations show our best models are superior to existing approaches in multi-turn dialogue in terms of engagingness and humanness measurements. We then discuss the limitations of this work by analyzing failure cases of our models.",
        "year": 2020,
        "authors": "Stephen Roller and Emily Dinan and Naman Goyal and Da Ju and Mary Williamson and Yinhan Liu and Jing Xu and Myle Ott and Kurt Shuster and Eric M Smith and Y-Lan Boureau and Jason Weston"
      },
      {
        "title": "Chain-of-verification reduces hallucination in large language models",
        "abstract": "Generation of plausible yet incorrect factual information, termed hallucination, is an unsolved issue in large language models. We study the ability of language models to deliberate on the responses they give in order to correct their mistakes. We develop the Chain-of-Verification (CoVe) method whereby the model first (i) drafts an initial response; then (ii) plans verification questions to fact-check its draft; (iii) answers those questions independently so the answers are not biased by other responses; and (iv) generates its final verified response. In experiments, we show CoVe decreases hallucinations across a variety of tasks, from list-based questions from Wikidata, closed book MultiSpanQA and longform text generation.",
        "year": 2023,
        "authors": "Shehzaad Dhuliawala and Mojtaba Komeili and Jing Xu and Roberta Raileanu and Xian Li and Asli Celikyilmaz and Jason Weston"
      }
    ],
    "2ylcZSsAAAAJ": [
      {
        "title": "Jupyter Notebooks–a publishing format for reproducible computational workflows",
        "abstract": "It is increasingly necessary for researchers in all fields to write computer code, and in order to reproduce research results, it is important that this code is published. We present Jupyter notebooks, a document format for publishing code, results and explanations in a form that is both readable and executable. We discuss various tools and use cases for notebook documents.",
        "year": 2016,
        "authors": "Thomas Kluyver and Benjamin Ragan-Kelley and Fernando Pérez and Brian Granger and Matthias Bussonnier and Jonathan Frederic and Kyle Kelley and Jessica Hamrick and Jason Grout and Sylvain Corlay and Paul Ivanov and Damián Avila and Safia Abdalla and Carol Willing"
      },
      {
        "title": "Relational inductive biases, deep learning, and graph networks",
        "abstract": "Artificial intelligence (AI) has undergone a renaissance recently, making major progress in key domains such as vision, language, control, and decision-making. This has been due, in part, to cheap data and cheap compute resources, which have fit the natural strengths of deep learning. However, many defining characteristics of human intelligence, which developed under much different pressures, remain out of reach for current approaches. In particular, generalizing beyond one's experiences--a hallmark of human intelligence from infancy--remains a formidable challenge for modern AI. The following is part position paper, part review, and part unification. We argue that combinatorial generalization must be a top priority for AI to achieve human-like abilities, and that structured representations and computations are key to realizing this objective. Just as biology uses nature and nurture cooperatively, we reject the false choice between \"hand-engineering\" and \"end-to-end\" learning, and instead advocate for an approach which benefits from their complementary strengths. We explore how using relational inductive biases within deep learning architectures can facilitate learning about entities, relations, and rules for composing them. We present a new building block for the AI toolkit with a strong relational inductive bias--the graph network--which generalizes and extends various approaches for neural networks that operate on graphs, and provides a straightforward interface for manipulating structured knowledge and producing structured behaviors. We discuss how graph networks can support relational reasoning and combinatorial generalization …",
        "year": 2018,
        "authors": "Peter W Battaglia and Jessica B Hamrick and Victor Bapst and Alvaro Sanchez-Gonzalez and Vinicius Zambaldi and Mateusz Malinowski and Andrea Tacchetti and David Raposo and Adam Santoro and Ryan Faulkner and Caglar Gulcehre and Francis Song and Andrew Ballard and Justin Gilmer and George Dahl and Ashish Vaswani and Kelsey Allen and Charles Nash and Victoria Langston and Chris Dyer and Nicolas Heess and Daan Wierstra and Pushmeet Kohli and Matt Botvinick and Oriol Vinyals and Yujia Li and Razvan Pascanu"
      },
      {
        "title": "Simulation as an engine of physical scene understanding",
        "abstract": "In a glance, we can perceive whether a stack of dishes will topple, a branch will support a child’s weight, a grocery bag is poorly packed and liable to tear or crush its contents, or a tool is firmly attached to a table or free to be lifted. Such rapid physical inferences are central to how people interact with the world and with each other, yet their computational underpinnings are poorly understood. We propose a model based on an “intuitive physics engine,” a cognitive mechanism similar to computer engines that simulate rich physics in video games and graphics, but that uses approximate, probabilistic simulations to make robust and fast inferences in complex natural scenes where crucial information is unobserved. This single model fits data from five distinct psychophysical tasks, captures several illusions and biases, and explains core aspects of human mental models and common-sense reasoning that are …",
        "year": 2013,
        "authors": "Peter W Battaglia and Jessica B Hamrick and Joshua B Tenenbaum"
      }
    ],
    "-gJkPHIAAAAJ": [
      {
        "title": "Gemini: a family of highly capable multimodal models",
        "abstract": "This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.",
        "year": 2023,
        "authors": "Gemini Team and Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M Dai and Anja Hauth and Katie Millican and David Silver and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Jack Krawczyk and Cosmo Du and Ed Chi and Heng-Tze Cheng and Eric Ni and Purvi Shah and Patrick Kane and Betty Chan and Manaal Faruqui and Aliaksei Severyn and Hanzhao Lin and YaGuang Li and Yong Cheng and Abe Ittycheriah and Mahdis Mahdieh and Mia Chen and Pei Sun and Dustin Tran and Sumit Bagri and Balaji Lakshminarayanan and Jeremiah Liu and Andras Orban and Fabian Güra and Hao Zhou and Xinying Song and Aurelien Boffy and Harish Ganapathy and Steven Zheng and HyunJeong Choe and Ágoston Weisz and Tao Zhu and Yifeng Lu and Siddharth Gopal and Jarrod Kahn and Maciej Kula and Jeff Pitman and Rushin Shah and Emanuel Taropa and Majd Al Merey and Martin Baeuml and Zhifeng Chen and Laurent El Shafey and Yujing Zhang and Olcan Sercinoglu and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Anaïs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Gaurav Singh Tomar and Evan Senter and Martin Chadwick and Ilya Kornakov and Nithya Attaluri and Iñaki Iturrate and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Xavier Garcia and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco"
      },
      {
        "title": "Soft actor-critic algorithms and applications",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Offline reinforcement learning: Tutorial, review, and perspectives on open problems",
        "abstract": "In this tutorial article, we aim to provide the reader with the conceptual tools needed to get started on research on offline reinforcement learning algorithms: reinforcement learning algorithms that utilize previously collected data, without additional online data collection. Offline reinforcement learning algorithms hold tremendous promise for making it possible to turn large datasets into powerful decision making engines. Effective offline reinforcement learning methods would be able to extract policies with the maximum possible utility out of the available data, thereby allowing automation of a wide range of decision-making domains, from healthcare and education to robotics. However, the limitations of current algorithms make this difficult. We will aim to provide the reader with an understanding of these challenges, particularly in the context of modern deep reinforcement learning methods, and describe some potential solutions that have been explored in recent work to mitigate these challenges, along with recent applications, and a discussion of perspectives on open problems in the field.",
        "year": 2020,
        "authors": "Sergey Levine and Aviral Kumar and George Tucker and Justin Fu"
      }
    ],
    "Yxh9WWoAAAAJ": [
      {
        "title": "Data cleaning: Overview and emerging challenges",
        "abstract": "Detecting and repairing dirty data is one of the perennial challenges in data analytics, and failure to do so can result in inaccurate analytics and unreliable decisions. Over the past few years, there has been a surge of interest from both industry and academia on data cleaning problems including new abstractions, interfaces, approaches for scalability, and statistical techniques. To better understand the new advances in the field, we will first present a taxonomy of the data cleaning literature in which we highlight the recent interest in techniques that use constraints, rules, or patterns to detect errors, which we call qualitative data cleaning. We will describe the state-of-the-art techniques and also highlight their limitations with a series of illustrative examples. While traditionally such approaches are distinct from quantitative approaches such as outlier detection, we also discuss recent work that casts such approaches into …",
        "year": 2016,
        "authors": "Xu Chu and Ihab F Ilyas and Sanjay Krishnan and Jiannan Wang"
      },
      {
        "title": "Communication-efficient distributed dual coordinate ascent",
        "abstract": "Communication remains the most significant bottleneck in the performance of distributed optimization algorithms for large-scale machine learning. In this paper, we propose a communication-efficient framework, COCOA, that uses local computation in a primal-dual setting to dramatically reduce the amount of necessary communication. We provide a strong convergence rate analysis for this class of algorithms, as well as experiments on real-world distributed datasets with implementations in Spark. In our experiments, we find that as compared to state-of-the-art mini-batch versions of SGD and SDCA algorithms, COCOA converges to the same. 001-accurate solution quality on average 25× as quickly.",
        "year": 2014,
        "authors": "Martin Jaggi and Virginia Smith and Martin Takác and Jonathan Terhorst and Sanjay Krishnan and Thomas Hofmann and Michael I Jordan"
      },
      {
        "title": "Activeclean: Interactive data cleaning for statistical modeling",
        "abstract": "Analysts often clean dirty data iteratively--cleaning some data, executing the analysis, and then cleaning more data based on the results. We explore the iterative cleaning process in the context of statistical model training, which is an increasingly popular form of data analytics. We propose ActiveClean, which allows for progressive and iterative cleaning in statistical modeling problems while preserving convergence guarantees. ActiveClean supports an important class of models called convex loss models (e.g., linear regression and SVMs), and prioritizes cleaning those records likely to affect the results. We evaluate ActiveClean on five real-world datasets UCI Adult, UCI EEG, MNIST, IMDB, and Dollars For Docs with both real and synthetic errors. The results show that our proposed optimizations can improve model accuracy by up-to 2.5x for the same amount of data cleaned. Furthermore for a fixed cleaning budget …",
        "year": 2016,
        "authors": "Sanjay Krishnan and Jiannan Wang and Eugene Wu and Michael J Franklin and Ken Goldberg"
      }
    ],
    "4D1n8scAAAAJ": [
      {
        "title": "Airsim: High-fidelity visual and physical simulation for autonomous vehicles",
        "abstract": "Developing and testing algorithms for autonomous vehicles in real world is an expensive and time consuming process. Also, in order to utilize recent advances in machine intelligence and deep learning we need to collect a large amount of annotated training data in a variety of conditions and environments. We present a new simulator built on Unreal Engine that offers physically and visually realistic simulations for both of these goals. Our simulator includes a physics engine that can operate at a high frequency for real-time hardware-in-the-loop (HITL) simulations with support for popular protocols (e.g. MavLink). The simulator is designed from the ground up to be extensible to accommodate new types of vehicles, hardware platforms and software protocols. In addition, the modular design enables various components to be easily usable independently in other projects. We demonstrate the simulator by first …",
        "year": 2018,
        "authors": "Shital Shah and Debadeepta Dey and Chris Lovett and Ashish Kapoor"
      },
      {
        "title": "Automatic prediction of frustration",
        "abstract": "Predicting when a person might be frustrated can provide an intelligent system with important information about when to initiate interaction. For example, an automated Learning Companion or Intelligent Tutoring System might use this information to intervene, providing support to the learner who is likely to otherwise quit, while leaving engaged learners free to discover things without interruption. This paper presents the first automated method that assesses, using multiple channels of affect-related information, whether a learner is about to click on a button saying “I’m frustrated.” The new method was tested on data gathered from 24 participants using an automated Learning Companion. Their indication of frustration was automatically predicted from the collected data with 79% accuracy (chance=58%). The new assessment method is based on Gaussian process classification and Bayesian inference. Its performance …",
        "year": 2007,
        "authors": "Ashish Kapoor and Winslow Burleson and Rosalind W Picard"
      },
      {
        "title": "Chatgpt for robotics: Design principles and model abilities",
        "abstract": "This paper presents an experimental study regarding the use of OpenAI’s ChatGPT for robotics applications. We outline a strategy that combines design principles for prompt engineering and the creation of a high-level function library which allows ChatGPT to adapt to different robotics tasks, simulators, and form factors. We focus our evaluations on the effectiveness of different prompt engineering techniques and dialog strategies towards the execution of various types of robotics tasks. We explore ChatGPT’s ability to use free-form dialog, parse XML tags, and to synthesize code, in addition to the use of task-specific prompting functions and closed-loop reasoning through dialogues. Our study encompasses a range of tasks within the robotics domain, from basic logical, geometrical, and mathematical reasoning all the way to complex domains such as aerial navigation, manipulation, and embodied agents. We show …",
        "year": 2024,
        "authors": "Sai H Vemprala and Rogerio Bonatti and Arthur Bucker and Ashish Kapoor"
      }
    ],
    "eVYhlDQAAAAJ": [
      {
        "title": "Soft Actor-Critic Algorithms and Applications",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "End-to-End Robotic Reinforcement Learning without Reward Engineering",
        "abstract": "The combination of deep neural network models and reinforcement learning algorithms can make it possible to learn policies for robotic behaviors that directly read in raw sensory inputs, such as camera images, effectively subsuming both estimation and control into one model. However, real-world applications of reinforcement learning must specify the goal of the task by means of a manually programmed reward function, which in practice requires either designing the very same perception pipeline that end-to-end reinforcement learning promises to avoid, or else instrumenting the environment with additional sensors to determine if the task has been performed successfully. In this paper, we propose an approach for removing the need for manual engineering of reward specifications by enabling a robot to learn from a modest number of examples of successful outcomes, followed by actively solicited queries, where the robot shows the user a state and asks for a label to determine whether that state represents successful completion of the task. While requesting labels for every single state would amount to asking the user to manually provide the reward signal, our method requires labels for only a tiny fraction of the states seen during training, making it an efficient and practical approach for learning skills without manually engineered rewards. We evaluate our method on real-world robotic manipulation tasks where the observations consist of images viewed by the robot's camera. In our experiments, our method effectively learns to arrange objects, place books, and drape cloth, directly from images and without any manually specified reward …",
        "year": 2019,
        "authors": "Avi Singh and Larry Yang and Kristian Hartikainen and Chelsea Finn and Sergey Levine"
      },
      {
        "title": "Latent Space Policies for Hierarchical Reinforcement Learning",
        "abstract": "We address the problem of learning hierarchical deep neural network policies for reinforcement learning. In contrast to methods that explicitly restrict or cripple lower layers of a hierarchy to force them to use higher-level modulating signals, each layer in our framework is trained to directly solve the task, but acquires a range of diverse strategies via a maximum entropy reinforcement learning objective. Each layer is also augmented with latent random variables, which are sampled from a prior distribution during the training of that layer. The maximum entropy objective causes these latent variables to be incorporated into the layer’s policy, and the higher level layer can directly control the behavior of the lower layer through this latent space. Furthermore, by constraining the mapping from latent variables to actions to be invertible, higher layers retain full expressivity: neither the higher layers nor the lower layers are constrained in their behavior. Our experimental evaluation demonstrates that we can improve on the performance of single-layer policies on standard benchmark tasks simply by adding additional layers, and that our method can solve more complex sparse-reward tasks by learning higher-level policies on top of high-entropy skills optimized for simple low-level objectives.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Kristian Hartikainen and Pieter Abbeel and Sergey Levine"
      }
    ],
    "MO7qaUIAAAAJ": [
      {
        "title": "Optimal Transport Mapping via Input Convex Neural Networks",
        "abstract": "In this paper, we present a novel and principled approach to learn the optimal transport between two distributions, from samples. Guided by the optimal transport theory, we learn the optimal Kantorovich potential which induces the optimal transport map. This involves learning two convex functions, by solving a novel minimax optimization. Building upon recent advances in the field of input convex neural networks, we propose a new framework to estimate the optimal transport mapping as the gradient of a convex function that is trained via minimax optimization. Numerical experiments confirm the accuracy of the learned transport map. Our approach can be readily used to train a deep generative model. When trained between a simple distribution in the latent space and a target distribution, the learned optimal transport map acts as a deep generative model. Although scaling this to a large dataset is challenging, we demonstrate two important strengths over standard adversarial training: robustness and discontinuity. As we seek the optimal transport, the learned generative model provides the same mapping regardless of how we initialize the neural networks. Further, a gradient of a neural network can easily represent discontinuous mappings, unlike standard neural networks that are constrained to be continuous. This allows the learned transport map to match any target distribution with many discontinuous supports and achieve sharp boundaries.",
        "year": 2020,
        "authors": "Ashok Makkuva and Amirhossein Taghvaei and Sewoong Oh and Jason Lee"
      },
      {
        "title": "KO Codes: Inventing Nonlinear Encoding and Decoding for Reliable Wireless Communication via Deep-learning",
        "abstract": "Landmark codes underpin reliable physical layer communication, eg, Reed-Muller, BCH, Convolution, Turbo, LDPC, and Polar codes: each is a linear code and represents a mathematical breakthrough. The impact on humanity is huge: each of these codes has been used in global wireless communication standards (satellite, WiFi, cellular). Reliability of communication over the classical additive white Gaussian noise (AWGN) channel enables benchmarking and ranking of the different codes. In this paper, we construct KO codes, a computationally efficient family of deep-learning driven (encoder, decoder) pairs that outperform the state-of-the-art reliability performance on the standardized AWGN channel. KO codes beat state-of-the-art Reed-Muller and Polar codes, under the low-complexity successive cancellation decoding, in the challenging short-to-medium block length regime on the AWGN channel. We show that the gains of KO codes are primarily due to the nonlinear mapping of information bits directly to transmit symbols (bypassing modulation) and yet possess an efficient, high-performance decoder. The key technical innovation that renders this possible is design of a novel family of neural architectures inspired by the computation tree of the {\\bf K} ronecker {\\bf O} peration (KO) central to Reed-Muller and Polar codes. These architectures pave way for the discovery of a much richer class of hitherto unexplored nonlinear algebraic structures.",
        "year": 2021,
        "authors": "Ashok V Makkuva and Xiyang Liu and Mohammad Vahid Jamali and Hessam Mahdavifar and Sewoong Oh and Pramod Viswanath"
      },
      {
        "title": "Equivalence of Additive-Combinatorial Linear Inequalities for Shannon Entropy and Differential Entropy",
        "abstract": "This paper addresses the correspondence between linear inequalities for Shannon entropy and differential entropy for sums of independent group-valued random variables. We show that any balanced (with the sum of coefficients being zero) linear inequality for Shannon entropy holds if and only if its differential entropy counterpart also holds; moreover, any linear inequality for differential entropy must be balanced. In particular, our result shows that recently proved differential entropy inequalities by Kontoyiannis and Madiman can be deduced from their discrete counterparts due to Tao in a unified manner. Generalizations to certain abelian groups are also obtained. Our proof of extending inequalities for Shannon entropy to differential entropy relies on a result of Rényi which relates the Shannon entropy of a finely discretized random variable to its differential entropy and also helps in establishing that the entropy of …",
        "year": 2018,
        "authors": "Ashok Vardhan Makkuva and Yihong Wu"
      }
    ],
    "MDeIveMAAAAJ": [
      {
        "title": "Turbo-aggregate: Breaking the quadratic aggregation barrier in secure federated learning",
        "abstract": "Federated learning is a distributed framework for training machine learning models over the data residing at mobile devices, while protecting the privacy of individual users. A major bottleneck in scaling federated learning to a large number of users is the overhead of secure model aggregation across many users. In particular, the overhead of the state-of-the-art protocols for secure model aggregation grows quadratically with the number of users. In this article, we propose the first secure aggregation framework, named Turbo-Aggregate, that in a network with N users achieves a secure aggregation overhead of O(NlogN), as opposed to O(N2), while tolerating up to a user dropout rate of 50%. Turbo-Aggregate employs a multi-group circular strategy for efficient model aggregation, and leverages additive secret sharing and novel coding techniques for injecting aggregation redundancy in order to handle user dropouts …",
        "year": 2021,
        "authors": "Jinhyun So and Başak Güler and A Salman Avestimehr"
      },
      {
        "title": "Byzantine-resilient secure federated learning",
        "abstract": "Secure federated learning is a privacy-preserving framework to improve machine learning models by training over large volumes of data collected by mobile users. This is achieved through an iterative process where, at each iteration, users update a global model using their local datasets. Each user then masks its local update via random keys, and the masked models are aggregated at a central server to compute the global model for the next iteration. As the local updates are protected by random masks, the server cannot observe their true values. This presents a major challenge for the resilience of the model against adversarial (Byzantine) users, who can manipulate the global model by modifying their local updates or datasets. Towards addressing this challenge, this paper presents the first single-server Byzantine-resilient secure aggregation framework (BREA) for secure federated learning. BREA is based on …",
        "year": 2020,
        "authors": "Jinhyun So and Başak Güler and A Salman Avestimehr"
      },
      {
        "title": "Lightsecagg: a lightweight and versatile design for secure aggregation in federated learning",
        "abstract": "Secure model aggregation is a key component of federated learning (FL) that aims at protecting the privacy of each user’s individual model while allowing for their global aggregation. It can be applied to any aggregation-based FL approach for training a global or personalized model. Model aggregation needs to also be resilient against likely user dropouts in FL systems, making its design substantially more complex. State-of-the-art secure aggregation protocols rely on secret sharing of the random-seeds used for mask generations at the users to enable the reconstruction and cancellation of those belonging to the dropped users. The complexity of such approaches, however, grows substantially with the number of dropped users. We propose a new approach, named LightSecAgg, to overcome this bottleneck by changing the design from random-seed reconstruction of the dropped users''to one-shot aggregate-mask reconstruction of the active users via mask encoding/decoding''. We show that LightSecAgg achieves the same privacy and dropout-resiliency guarantees as the state-of-the-art protocols while significantly reducing the overhead for resiliency against dropped users. We also demonstrate that, unlike existing schemes, LightSecAgg can be applied to secure aggregation in the asynchronous FL setting. Furthermore, we provide a modular system design and optimized on-device parallelization for scalable implementation, by enabling computational overlapping between model training and on-device encoding, as well as improving the speed of concurrent receiving and sending of chunked masks. We evaluate LightSecAgg via extensive …",
        "year": 2022,
        "authors": "Jinhyun So and Chaoyang He and Chien-Sheng Yang and Songze Li and Qian Yu and Ramy E Ali and Basak Guler and Salman Avestimehr"
      }
    ],
    "0nPi5YYAAAAJ": [
      {
        "title": "Going deeper with convolutions",
        "abstract": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation of this architecture, GoogLeNet, a 22 layers deep network, was used to assess its quality in the context of object detection and classification.",
        "year": 2015,
        "authors": "Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich"
      },
      {
        "title": "Overfeat: Integrated recognition, localization and detection using convolutional networks",
        "abstract": "We present an integrated framework for using Convolutional Networks for classification, localization and detection. We show how a multiscale and sliding window approach can be efficiently implemented within a ConvNet. We also introduce a novel deep learning approach to localization by learning to predict object boundaries. Bounding boxes are then accumulated rather than suppressed in order to increase detection confidence. We show that different tasks can be learned simultaneously using a single shared network. This integrated framework is the winner of the localization task of the ImageNet Large Scale Visual Recognition Challenge 2013 (ILSVRC2013) and obtained very competitive results for the detection and classifications tasks. In post-competition work, we establish a new state of the art for the detection task. Finally, we release a feature extractor from our best model called OverFeat.",
        "year": 2013,
        "authors": "Pierre Sermanet and David Eigen and Xiang Zhang and Michaël Mathieu and Rob Fergus and Yann LeCun"
      },
      {
        "title": "Do as i can, not as i say: Grounding language in robotic affordances",
        "abstract": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model's \"hands and eyes,\" while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally-extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project's website and the video can be found at https …",
        "year": 2022,
        "authors": "Michael Ahn and Anthony Brohan and Noah Brown and Yevgen Chebotar and Omar Cortes and Byron David and Chelsea Finn and Chuyuan Fu and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Daniel Ho and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Eric Jang and Rosario Jauregui Ruano and Kyle Jeffrey and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Kuang-Huei Lee and Sergey Levine and Yao Lu and Linda Luu and Carolina Parada and Peter Pastor and Jornell Quiambao and Kanishka Rao and Jarek Rettinghouse and Diego Reyes and Pierre Sermanet and Nicolas Sievers and Clayton Tan and Alexander Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Mengyuan Yan and Andy Zeng"
      }
    ],
    "Wk2gAZUAAAAJ": [
      {
        "title": "An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion",
        "abstract": "Text-to-image models offer unprecedented freedom to guide creation through natural language. Yet, it is unclear how such freedom can be exercised to generate images of specific unique concepts, modify their appearance, or compose them in new roles and novel scenes. In other words, we ask: how can we use language-guided models to turn our cat into a painting, or imagine a new product based on our favorite toy? Here we present a simple approach that allows such creative freedom. Using only 3-5 images of a user-provided concept, like an object or a style, we learn to represent it through new \"words\" in the embedding space of a frozen text-to-image model. These \"words\" can be composed into natural language sentences, guiding personalized creation in an intuitive way. Notably, we find evidence that a single word embedding is sufficient for capturing unique and varied concepts. We compare our approach to a wide range of baselines, and demonstrate that it can more faithfully portray the concepts across a range of applications and tasks. Our code, data and new words will be available at: https://textual-inversion.github.io",
        "year": 2022,
        "authors": "Rinon Gal and Yuval Alaluf and Yuval Atzmon and Or Patashnik and Amit H Bermano and Gal Chechik and Daniel Cohen-Or"
      },
      {
        "title": "Large scale online learning of image similarity through ranking",
        "abstract": "Learning a measure of similarity between pairs of objects is an important generic problem in machine learning. It is particularly useful in large scale applications like searching for an image that is similar to a given image or finding videos that are relevant to a given video. In these tasks, users look for objects that are not only visually similar but also semantically related to a given object. Unfortunately, the approaches that exist today for learning such semantic similarity do not scale to large data sets. This is both because typically their CPU and storage requirements grow quadratically with the sample size, and because many methods impose complex positivity constraints on the space of learned similarity functions.The current paper presents OASIS, an Online Algorithm for Scalable Image Similarity learning that learns a bilinear similarity measure over sparse representations. OASIS is an online dual approach using the passive-aggressive family of learning algorithms with a large margin criterion and an efficient hinge loss cost. Our experiments show that OASIS is both fast and accurate at a wide range of scales: for a data set with thousands of images, it achieves better results than existing state-of-the-art methods, while being an order of magnitude faster. For large, web scale, data sets, OASIS can be trained on more than two million images from 150K text queries within 3 days on a single CPU. On this large scale data set, human evaluations showed that 35% of the ten nearest neighbors of a given test image, as found by OASIS, were semantically relevant to that image. This suggests that query independent similarity could be accurately learned …",
        "year": 2010,
        "authors": "Gal Chechik and Varun Sharma and Uri Shalit and Samy Bengio"
      }
    ],
    "JWmiQR0AAAAJ": [
      {
        "title": "Attention is all you need",
        "abstract": "The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms. We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.",
        "year": 2017,
        "authors": "Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N Gomez and Łukasz Kaiser and Illia Polosukhin"
      },
      {
        "title": "Tensorflow: Large-scale machine learning on heterogeneous distributed systems",
        "abstract": "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.",
        "year": 2016,
        "authors": "Martín Abadi and Ashish Agarwal and Paul Barham and Eugene Brevdo and Zhifeng Chen and Craig Citro and Greg S Corrado and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Ian Goodfellow and Andrew Harp and Geoffrey Irving and Michael Isard and Yangqing Jia and Rafal Józefowicz and Lukasz Kaiser and Manjunath Kudlur and Josh Levenberg and Dan Mané and Rajat Monga and Sherry Moore and Derek Murray and Chris Olah and Mike Schuster and Jonathon Shlens and Benoit Steiner and Ilya Sutskever and Kunal Talwar and Paul Tucker and Vincent Vanhoucke and Vijay Vasudevan and Fernanda Viegas and Oriol Vinyals and Pete Warden and Martin Wattenberg and Martin Wicke and Yuan Yu and Xiaoqiang Zheng"
      },
      {
        "title": "Gpt-4 technical report",
        "abstract": "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.",
        "year": 2023,
        "authors": "Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew"
      }
    ],
    "kZh8vUMAAAAJ": [
      {
        "title": "EmbedLLM: Learning Compact Representations of Large Language Models",
        "abstract": "With hundreds of thousands of language models available on Huggingface today, efficiently evaluating and utilizing these models across various downstream, tasks has become increasingly critical. Many existing methods repeatedly learn task-specific representations of Large Language Models (LLMs), which leads to inefficiencies in both time and computational resources. To address this, we propose EmbedLLM, a framework designed to learn compact vector representations, of LLMs that facilitate downstream applications involving many models, such as model routing. We introduce an encoder-decoder approach for learning such embeddings, along with a systematic framework to evaluate their effectiveness. Empirical results show that EmbedLLM outperforms prior methods in model routing both in accuracy and latency. Additionally, we demonstrate that our method can forecast a model's performance on multiple benchmarks, without incurring additional inference cost. Extensive probing experiments validate that the learned embeddings capture key model characteristics, e.g. whether the model is specialized for coding tasks, even without being explicitly trained on them. We open source our dataset, code and embedder to facilitate further research and application.",
        "year": 2024,
        "authors": "Richard Zhuang and Tianhao Wu and Zhaojin Wen and Andrew Li and Jiantao Jiao and Kannan Ramchandran"
      },
      {
        "title": "P‐47: A Measurement Method for Lateral Current Leakage Effect of OLED Panels",
        "abstract": "A method is proposed to measure the lateral current leakage effect to the brightness and colors, especially at low graylevels, for OLED panels.",
        "year": 2023,
        "authors": "Hao Tang and Andrew Li and Gang Xu"
      },
      {
        "title": "SMIR: Efficient Synthetic Data Pipeline To Improve Multi-Image Reasoning",
        "abstract": "Vision-Language Models (VLMs) have shown strong performance in understanding single images, aided by numerous high-quality instruction datasets. However, multi-image reasoning tasks are still under-explored in the open-source community due to two main challenges: (1) scaling datasets with multiple correlated images and complex reasoning instructions is resource-intensive and maintaining quality is difficult, and (2) there is a lack of robust evaluation benchmarks for multi-image tasks. To address these issues, we introduce SMIR, an efficient synthetic data-generation pipeline for multi-image reasoning, and a high-quality dataset generated using this pipeline. Our pipeline efficiently extracts highly correlated images using multimodal embeddings, combining visual and descriptive information and leverages open-source LLMs to generate quality instructions. Using this pipeline, we generated 160K synthetic training samples, offering a cost-effective alternative to expensive closed-source solutions. Additionally, we present SMIR-BENCH, a novel multi-image reasoning evaluation benchmark comprising 200 diverse examples across 7 complex multi-image reasoning tasks. SMIR-BENCH is multi-turn and utilizes a VLM judge to evaluate free-form responses, providing a comprehensive assessment of model expressiveness and reasoning capability across modalities. We demonstrate the effectiveness of SMIR dataset by fine-tuning several open-source VLMs and evaluating their performance on SMIR-BENCH. Our results show that models trained on our dataset outperform baseline models in multi-image reasoning tasks up to 8% with a much …",
        "year": 2025,
        "authors": "Andrew Li and Rahul Thapa and Rahul Chalamala and Qingyang Wu and Kezhen Chen and James Zou"
      }
    ],
    "_ws9LLgAAAAJ": [
      {
        "title": "Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection",
        "abstract": "We describe a learning-based approach to hand-eye coordination for robotic grasping from monocular images. To learn hand-eye coordination for grasping, we trained a large convolutional neural network to predict the probability that task-space motion of the gripper will result in successful grasps, using only monocular camera images independent of camera calibration or the current robot pose. This requires the network to observe the spatial relationship between the gripper and objects in the scene, thus learning hand-eye coordination. We then use this network to servo the gripper in real time to achieve successful grasps. We describe two large-scale experiments that we conducted on two separate robotic platforms. In the first experiment, about 800,000 grasp attempts were collected over the course of two months, using between 6 and 14 robotic manipulators at any given time, with differences in camera …",
        "year": 2018,
        "authors": "Sergey Levine and Peter Pastor and Alex Krizhevsky and Julian Ibarz and Deirdre Quillen"
      },
      {
        "title": "Dynamical movement primitives: learning attractor models for motor behaviors",
        "abstract": "Nonlinear dynamical systems have been used in many disciplines to model complex behaviors, including biological motor control, robotics, perception, economics, traffic prediction, and neuroscience. While often the unexpected emergent behavior of nonlinear systems is the focus of investigations, it is of equal importance to create goal-directed behavior (e.g., stable locomotion from a system of coupled oscillators under perceptual guidance). Modeling goal-directed behavior with nonlinear systems is, however, rather difficult due to the parameter sensitivity of these systems, their complex phase transitions in response to subtle parameter changes, and the difficulty of analyzing and predicting their long-term behavior; intuition and time-consuming parameter tuning play a major role. This letter presents and reviews dynamical movement primitives, a line of research for modeling attractor behaviors of autonomous …",
        "year": 2013,
        "authors": "Auke Jan Ijspeert and Jun Nakanishi and Heiko Hoffmann and Peter Pastor and Stefan Schaal"
      },
      {
        "title": "Scalable deep reinforcement learning for vision-based robotic manipulation",
        "abstract": "In this paper, we study the problem of learning vision-based dynamic manipulation skills using a scalable reinforcement learning approach. We study this problem in the context of grasping, a longstanding challenge in robotic manipulation. In contrast to static learning behaviors that choose a grasp point and then execute the desired grasp, our method enables closed-loop vision-based control, whereby the robot continuously updates its grasp strategy based on the most recent observations to optimize long-horizon grasp success. To that end, we introduce QT-Opt, a scalable self-supervised vision-based reinforcement learning framework that can leverage over 580k real-world grasp attempts to train a deep neural network Q-function with over 1.2 M parameters to perform closed-loop, real-world grasping that generalizes to 96% grasp success on unseen objects. Aside from attaining a very high success rate, our method exhibits behaviors that are quite distinct from more standard grasping systems: using only RGB vision-based perception from an over-the-shoulder camera, our method automatically learns regrasping strategies, probes objects to find the most effective grasps, learns to reposition objects and perform other non-prehensile pre-grasp manipulations, and responds dynamically to disturbances and perturbations.",
        "year": 2018,
        "authors": "Dmitry Kalashnikov and Alex Irpan and Peter Pastor and Julian Ibarz and Alexander Herzog and Eric Jang and Deirdre Quillen and Ethan Holly and Mrinal Kalakrishnan and Vincent Vanhoucke and Sergey Levine"
      }
    ],
    "ID9QePIAAAAJ": [
      {
        "title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size",
        "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet). The SqueezeNet architecture is available for download here: https://github.com/DeepScale/SqueezeNet",
        "year": 2016,
        "authors": "Forrest N Iandola and Song Han and Matthew W Moskewicz and Khalid Ashraf and William J Dally and Kurt Keutzer"
      },
      {
        "title": "The landscape of parallel computing research: A view from berkeley",
        "abstract": "The recent switch to parallel microprocessors is a milestone in the history of computing. Industry has laid out a roadmap for multicore designs that preserves the programming paradigm of the past via binary compatibility and cache coherence. Conventional wisdom is now to double the number of cores on a chip with each silicon generation. A multidisciplinary group of Berkeley researchers met nearly two years to discuss this change. Our view is that this evolutionary approach to parallel hardware and software may work from 2 or 8 processor systems, but is likely to face diminishing returns as 16 and 32 processor systems are realized, just as returns fell with greater instruction-level parallelism. We believe that much can be learned by examining the success of parallelism at the extremes of the computing spectrum, namely embedded computing and high performance computing. This led us to frame the parallel landscape with seven questions, and to recommend the following: • The overarching goal should be to make it easy to write programs that execute efficiently on highly parallel computing systems • The target should be 1000s of cores per chip, as these chips are built from processing elements that are the most efficient in MIPS (Million Instructions per Second) per watt, MIPS per area of silicon, and MIPS per development dollar. • Instead of traditional benchmarks, use 13 “Dwarfs” to design and evaluate parallel programming models and architectures. (A dwarf is an algorithmic method that captures a pattern of computation and communication.) • “Autotuners” should play a larger role than conventional compilers in translating parallel programs …",
        "year": 2006,
        "authors": "Krste Asanovic and Ras Bodik and Bryan Catanzaro and Joseph Gebis and Parry Husbands and Kurt Keutzer and David Patterson and William Plishker and John Shalf and Samuel Webb Williams"
      },
      {
        "title": "Identifying the best machine learning algorithms for brain tumor segmentation, progression assessment, and overall survival prediction in the BRATS challenge",
        "abstract": "Gliomas are the most common primary brain malignancies, with different degrees of aggressiveness, variable prognosis and various heterogeneous histologic sub-regions, i.e., peritumoral edematous/invaded tissue, necrotic core, active and non-enhancing core. This intrinsic heterogeneity is also portrayed in their radio-phenotype, as their sub-regions are depicted by varying intensity profiles disseminated across multi-parametric magnetic resonance imaging (mpMRI) scans, reflecting varying biological properties. Their heterogeneous shape, extent, and location are some of the factors that make these tumors difficult to resect, and in some cases inoperable. The amount of resected tumor is a factor also considered in longitudinal scans, when evaluating the apparent tumor for potential diagnosis of progression. Furthermore, there is mounting evidence that accurate segmentation of the various tumor sub-regions can offer the basis for quantitative image analysis towards prediction of patient overall survival. This study assesses the state-of-the-art machine learning (ML) methods used for brain tumor image analysis in mpMRI scans, during the last seven instances of the International Brain Tumor Segmentation (BraTS) challenge, i.e., 2012-2018. Specifically, we focus on i) evaluating segmentations of the various glioma sub-regions in pre-operative mpMRI scans, ii) assessing potential tumor progression by virtue of longitudinal growth of tumor sub-regions, beyond use of the RECIST/RANO criteria, and iii) predicting the overall survival from pre-operative mpMRI scans of patients that underwent gross total resection. Finally, we investigate the …",
        "year": 2018,
        "authors": "Spyridon Bakas and Mauricio Reyes and Andras Jakab and Stefan Bauer and Markus Rempfler and Alessandro Crimi and Russell Takeshi Shinohara and Christoph Berger and Sung Min Ha and Martin Rozycki and Marcel Prastawa and Esther Alberts and Jana Lipkova and John Freymann and Justin Kirby and Michel Bilello and Hassan Fathallah-Shaykh and Roland Wiest and Jan Kirschke and Benedikt Wiestler and Rivka Colen and Aikaterini Kotrotsou and Pamela Lamontagne and Daniel Marcus and Mikhail Milchenko and Arash Nazeri and Marc-Andre Weber and Abhishek Mahajan and Ujjwal Baid and Elizabeth Gerstner and Dongjin Kwon and Gagan Acharya and Manu Agarwal and Mahbubul Alam and Alberto Albiol and Antonio Albiol and Francisco J Albiol and Varghese Alex and Nigel Allinson and Pedro HA Amorim and Abhijit Amrutkar and Ganesh Anand and Simon Andermatt and Tal Arbel and Pablo Arbelaez and Aaron Avery and Muneeza Azmat and W Bai and Subhashis Banerjee and Bill Barth and Thomas Batchelder and Kayhan Batmanghelich and Enzo Battistella and Andrew Beers and Mikhail Belyaev and Martin Bendszus and Eze Benson and Jose Bernal and Halandur Nagaraja Bharath and George Biros and Sotirios Bisdas and James Brown and Mariano Cabezas and Shilei Cao and Jorge M Cardoso and Eric N Carver and Adrià Casamitjana and Laura Silvana Castillo and Marcel Catà and Philippe Cattin and Albert Cerigues and Vinicius S Chagas and Siddhartha Chandra and Yi-Ju Chang and Shiyu Chang and Ken Chang and Joseph Chazalon and Shengcong Chen and Wei Chen and Jefferson W Chen and Zhaolin Chen and Kun Cheng and Ahana Roy Choudhury and Roger Chylla and Albert Clérigues and Steven Colleman and Ramiro German Rodriguez Colmeiro and Marc Combalia and Anthony Costa and Xiaomeng Cui and Zhenzhen Dai and Lutao Dai and Laura Alexandra Daza and Eric Deutsch and Changxing Ding and Chao Dong and Shidu Dong and Wojciech Dudzik and Zach Eaton-Rosen and Gary Egan and Guilherme Escudero and Théo Estienne and Richard Everson and Jonathan Fabrizio and Yong Fan and Longwei Fang and Xue Feng and Enzo Ferrante and Lucas Fidon and Martin Fischer and Andrew P French and Naomi Fridman and Huan Fu and David Fuentes and Yaozong Gao and Evan Gates and David Gering and Amir Gholami and Willi Gierke and Ben Glocker and Mingming Gong and Sandra González-Villá and T Grosges and Yuanfang Guan and Sheng Guo and Sudeep Gupta and Woo-Sup Han and Il Song Han and Konstantin Harmuth and Huiguang He and Aura Hernández-Sabaté and Evelyn Herrmann and Naveen Himthani and Winston Hsu and Cheyu Hsu and Xiaojun Hu and Xiaobin Hu and Yan Hu and Yifan Hu and Rui Hua and Teng-Yi Huang and Weilin Huang and Sabine Van Huffel and Quan Huo and Vivek HV and Khan M Iftekharuddin and Fabian Isensee and Mobarakol Islam and Aaron S Jackson and Sachin R Jambawalikar"
      }
    ],
    "T9To2C0AAAAJ": [
      {
        "title": "Offline reinforcement learning: Tutorial, review, and perspectives on open problems",
        "abstract": "In this tutorial article, we aim to provide the reader with the conceptual tools needed to get started on research on offline reinforcement learning algorithms: reinforcement learning algorithms that utilize previously collected data, without additional online data collection. Offline reinforcement learning algorithms hold tremendous promise for making it possible to turn large datasets into powerful decision making engines. Effective offline reinforcement learning methods would be able to extract policies with the maximum possible utility out of the available data, thereby allowing automation of a wide range of decision-making domains, from healthcare and education to robotics. However, the limitations of current algorithms make this difficult. We will aim to provide the reader with an understanding of these challenges, particularly in the context of modern deep reinforcement learning methods, and describe some potential solutions that have been explored in recent work to mitigate these challenges, along with recent applications, and a discussion of perspectives on open problems in the field.",
        "year": 2020,
        "authors": "Sergey Levine and Aviral Kumar and George Tucker and Justin Fu"
      },
      {
        "title": "D4rl: Datasets for deep data-driven reinforcement learning",
        "abstract": "The offline reinforcement learning (RL) setting (also known as full batch RL), where a policy is learned from a static dataset, is compelling as progress enables RL methods to take advantage of large, previously-collected datasets, much like how the rise of large datasets has fueled results in supervised learning. However, existing online RL benchmarks are not tailored towards the offline setting and existing offline RL benchmarks are restricted to data generated by partially-trained agents, making progress in offline RL difficult to measure. In this work, we introduce benchmarks specifically designed for the offline setting, guided by key properties of datasets relevant to real-world applications of offline RL. With a focus on dataset collection, examples of such properties include: datasets generated via hand-designed controllers and human demonstrators, multitask datasets where an agent performs different tasks in the same environment, and datasets collected with mixtures of policies. By moving beyond simple benchmark tasks and data collected by partially-trained RL agents, we reveal important and unappreciated deficiencies of existing algorithms. To facilitate research, we have released our benchmark tasks and datasets with a comprehensive evaluation of existing algorithms, an evaluation protocol, and open-source examples. This serves as a common starting point for the community to identify shortcomings in existing offline RL methods and a collaborative route for progress in this emerging area.",
        "year": 2020,
        "authors": "Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine"
      },
      {
        "title": "Stabilizing off-policy q-learning via bootstrapping error reduction",
        "abstract": "Off-policy reinforcement learning aims to leverage experience collected from prior policies for sample-efficient learning. However, in practice, commonly used off-policy approximate dynamic programming methods based on Q-learning and actor-critic methods are highly sensitive to the data distribution, and can make only limited progress without collecting additional on-policy data. As a step towards more robust off-policy algorithms, we study the setting where the off-policy experience is fixed and there is no further interaction with the environment. We identify\\emph {bootstrapping error} as a key source of instability in current methods. Bootstrapping error is due to bootstrapping from actions that lie outside of the training data distribution, and it accumulates via the Bellman backup operator. We theoretically analyze bootstrapping error, and demonstrate how carefully constraining action selection in the backup can mitigate it. Based on our analysis, we propose a practical algorithm, bootstrapping error accumulation reduction (BEAR). We demonstrate that BEAR is able to learn robustly from different off-policy distributions, including random data and suboptimal demonstrations, on a range of continuous control tasks.",
        "year": 2019,
        "authors": "Aviral Kumar and Justin Fu and Matthew Soh and George Tucker and Sergey Levine"
      }
    ],
    "42m4tGIAAAAJ": [
      {
        "title": "REVEL: an ensemble method for predicting the pathogenicity of rare missense variants",
        "abstract": "The vast majority of coding variants are rare, and assessment of the contribution of rare variants to complex traits is hampered by low statistical power and limited functional data. Improved methods for predicting the pathogenicity of rare coding variants are needed to facilitate the discovery of disease variants from exome sequencing studies. We developed REVEL (rare exome variant ensemble learner), an ensemble method for predicting the pathogenicity of missense variants on the basis of individual tools: MutPred, FATHMM, VEST, PolyPhen, SIFT, PROVEAN, MutationAssessor, MutationTaster, LRT, GERP, SiPhy, phyloP, and phastCons. REVEL was trained with recently discovered pathogenic and rare neutral missense variants, excluding those previously used to train its constituent tools. When applied to two independent test sets, REVEL had the best overall performance (p < 10−12) as compared to any …",
        "year": 2016,
        "authors": "Nilah M Ioannidis and Joseph H Rothstein and Vikas Pejaver and Sumit Middha and Shannon K McDonnell and Saurabh Baheti and Anthony Musolf and Qing Li and Emily Holzinger and Danielle Karyadi and Lisa A Cannon-Albright and Craig C Teerlink and Janet L Stanford and William B Isaacs and Jianfeng Xu and Kathleen A Cooney and Ethan M Lange and Johanna Schleutker and John D Carpten and Isaac J Powell and Olivier Cussenot and Geraldine Cancel-Tassin and Graham G Giles and Robert J MacInnis and Christiane Maier and Chih-Lin Hsieh and Fredrik Wiklund and William J Catalona and William D Foulkes and Diptasri Mandal and Rosalind A Eeles and Zsofia Kote-Jarai and Carlos D Bustamante and Daniel J Schaid and Trevor Hastie and Elaine A Ostrander and Joan E Bailey-Wilson and Predrag Radivojac and Stephen N Thibodeau and Alice S Whittemore and Weiva Sieh"
      },
      {
        "title": "The kinetochore-bound Ska1 complex tracks depolymerizing microtubules and binds to curved protofilaments",
        "abstract": "To ensure equal chromosome segregation during mitosis, the macromolecular kinetochore must remain attached to depolymerizing microtubules, which drive chromosome movements. How kinetochores associate with depolymerizing microtubules, which undergo dramatic structural changes forming curved protofilaments, has yet to be defined in vertebrates. Here, we demonstrate that the conserved kinetochore-localized Ska1 complex tracks with depolymerizing microtubule ends and associates with both the microtubule lattice and curved protofilaments. In contrast, the Ndc80 complex, a central player in the kinetochore-microtubule interface, binds only to the straight microtubule lattice and lacks tracking activity. We demonstrate that the Ska1 complex imparts its tracking capability to the Ndc80 complex. Finally, we present a structure of the Ska1 microtubule-binding domain that reveals its interaction with …",
        "year": 2012,
        "authors": "Jens C Schmidt and Haribabu Arthanari and Andras Boeszoermenyi and Natalia M Dashkevich and Elizabeth M Wilson-Kubalek and Nilah Monnier and Michelle Markus and Monika Oberer and Ron A Milligan and Mark Bathe and Gerhard Wagner and Ekaterina L Grishchuk and Iain M Cheeseman"
      },
      {
        "title": "Inferring transient particle transport dynamics in live cells",
        "abstract": "Live-cell imaging and particle tracking provide rich information on mechanisms of intracellular transport. However, trajectory analysis procedures to infer complex transport dynamics involving stochastic switching between active transport and diffusive motion are lacking. We applied Bayesian model selection to hidden Markov modeling to infer transient transport states from trajectories of mRNA-protein complexes in live mouse hippocampal neurons and metaphase kinetochores in dividing human cells. The software is available at http://hmm-bayes.org/.",
        "year": 2015,
        "authors": "Nilah Monnier and Zachary Barry and Hye Yoon Park and Kuan-Chung Su and Zachary Katz and Brian P English and Arkajit Dey and Keyao Pan and Iain M Cheeseman and Robert H Singer and Mark Bathe"
      }
    ],
    "CzOD0S4AAAAJ": [
      {
        "title": "Comprehensive molecular characterization of gastric adenocarcinoma",
        "abstract": "Gastric cancer is a leading cause of cancer deaths, but analysis of its molecular and clinical characteristics has been complicated by histological and aetiological heterogeneity. Here we describe a comprehensive molecular evaluation of 295 primary gastric adenocarcinomas as part of The Cancer Genome Atlas (TCGA) project. We propose a molecular classification dividing gastric cancer into four subtypes: tumours positive for Epstein–Barr virus, which display recurrent PIK3CA mutations, extreme DNA hypermethylation, and amplification of JAK2, CD274 (also known as PD-L1) and PDCD1LG2 (also known as PD-L2); microsatellite unstable tumours, which show elevated mutation rates, including mutations of genes encoding targetable oncogenic signalling proteins; genomically stable tumours, which are enriched for the diffuse histological variant and mutations of RHOA or fusions involving RHO-family GTPase …",
        "year": 2014,
        "authors": "Cancer Genome Atlas Research Network"
      },
      {
        "title": "Genomic classification of cutaneous melanoma",
        "abstract": "We describe the landscape of genomic alterations in cutaneous melanomas through DNA, RNA, and protein-based analysis of 333 primary and/or metastatic melanomas from 331 patients. We establish a framework for genomic classification into one of four subtypes based on the pattern of the most prevalent significantly mutated genes: mutant BRAF, mutant RAS, mutant NF1, and Triple-WT (wild-type). Integrative analysis reveals enrichment of KIT mutations and focal amplifications and complex structural rearrangements as a feature of the Triple-WT subtype. We found no significant outcome correlation with genomic classification, but samples assigned a transcriptomic subclass enriched for immune gene expression associated with lymphocyte infiltrate on pathology review and high LCK protein expression, a T cell marker, were associated with improved patient survival. This clinicopathological and multi …",
        "year": 2015,
        "authors": "Rehan Akbani and Kadir C Akdemir and B Arman Aksoy and Monique Albert and Adrian Ally and Samirkumar B Amin and Harindra Arachchi and Arshi Arora and J Todd Auman and Brenda Ayala and Julien Baboud and Miruna Balasundaram and Saianand Balu and Nandita Barnabas and John Bartlett and Pam Bartlett and Boris C Bastian and Stephen B Baylin and Madhusmita Behera and Dmitry Belyaev and Christopher Benz and Brady Bernard and Rameen Beroukhim and Natalie Bir and Aaron D Black and Tom Bodenheimer and Lori Boice and Genevieve M Boland and Riccardo Bono and Moiz S Bootwalla and Marcus Bosenberg and Jay Bowen and Reanne Bowlby and Christopher A Bristow and Laura Brockway-Lunardi and Denise Brooks and Jakub Brzezinski and Wiam Bshara and Elizabeth Buda and William R Burns and Yaron SN Butterfield and Michael Button and Tiffany Calderone and Giancarlo Antonini Cappellini and Candace Carter and Scott L Carter and Lynn Cherney and Andrew D Cherniack and Aaron Chevalier and Lynda Chin and Juok Cho and Raymond J Cho and Yoon-La Choi and Andy Chu and Sudha Chudamani and Kristian Cibulskis and Giovanni Ciriello and Amanda Clarke and Stephen Coons and Leslie Cope and Daniel Crain and Erin Curley and Ludmila Danilova and Stefania D’Atri and Tanja Davidsen and Michael A Davies and Keith A Delman and John A Demchok and Qixia A Deng and Yonathan Lissanu Deribe and Noreen Dhalla and Rajiv Dhir and Daniel DiCara and Michael Dinikin and Michael Dubina and J Stephen Ebrom and Sophie Egea and Greg Eley and Jay Engel and Jennifer M Eschbacher and Konstantin V Fedosenko and Ina Felau and Timothy Fennell and Martin L Ferguson and Sheila Fisher and Keith T Flaherty and Scott Frazer and Jessica Frick and Victoria Fulidou and Stacey B Gabriel and Jianjiong Gao and Johanna Gardner and Levi A Garraway and Julie M Gastier-Foster and Carmelo Gaudioso and Nils Gehlenborg and Giannicola Genovese and Mark Gerken and Jeffrey E Gershenwald and Gad Getz and Carmen Gomez-Fernandez and Thomas Gribbin and Jonna Grimsby and Benjamin Gross and Ranabir Guin and Tony Gutschner and Angela Hadjipanayis and Ruth Halaban and Benjamin Hanf and David Haussler and Lauren E Haydu and D Neil Hayes and Nicholas K Hayward and David I Heiman and Lynn Herbert and James G Herman and Peter Hersey and Katherine A Hoadley and Eran Hodis and Robert A Holt and Dave SB Hoon and Susan Hoppough and Alan P Hoyle and Franklin W Huang and Mei Huang and Sharon Huang and Carolyn M Hutter and Matthew Ibbs and Lisa Iype and Anders Jacobsen and Valerie Jakrot and Alyssa Janning and William R Jeck and Stuart R Jefferys and Mark A Jensen and Corbin D Jones and Steven JM Jones and Zhenlin Ju and Hojabr Kakavand and Hyojin Kang and Richard F Kefford and Fadlo R Khuri and Jaegil Kim and John M Kirkwood and Joachim Klode and Anil Korkut and Konstanty Korski and Michael Krauthammer and Raju Kucherlapati and Lawrence N Kwong"
      },
      {
        "title": "Integrated genomic characterization of papillary thyroid carcinoma",
        "abstract": "Papillary thyroid carcinoma (PTC) is the most common type of thyroid cancer. Here, we describe the genomic landscape of 496 PTCs. We observed a low frequency of somatic alterations (relative to other carcinomas) and extended the set of known PTC driver alterations to include EIF1AX, PPM1D, and CHEK2 and diverse gene fusions. These discoveries reduced the fraction of PTC cases with unknown oncogenic driver from 25% to 3.5%. Combined analyses of genomic variants, gene expression, and methylation demonstrated that different driver groups lead to different pathologies with distinct signaling and differentiation characteristics. Similarly, we identified distinct molecular subgroups of BRAF-mutant tumors, and multidimensional analyses highlighted a potential involvement of oncomiRs in less-differentiated subgroups. Our results propose a reclassification of thyroid cancers into molecular subtypes that …",
        "year": 2014,
        "authors": "Nishant Agrawal and Rehan Akbani and B Arman Aksoy and Adrian Ally and Harindra Arachchi and Sylvia L Asa and J Todd Auman and Miruna Balasundaram and Saianand Balu and Stephen B Baylin and Madhusmita Behera and Brady Bernard and Rameen Beroukhim and Justin A Bishop and Aaron D Black and Tom Bodenheimer and Lori Boice and Moiz S Bootwalla and Jay Bowen and Reanne Bowlby and Christopher A Bristow and Robin Brookens and Denise Brooks and Robert Bryant and Elizabeth Buda and Yaron SN Butterfield and Tobias Carling and Rebecca Carlsen and Scott L Carter and Sally E Carty and Timothy A Chan and Amy Y Chen and Andrew D Cherniack and Dorothy Cheung and Lynda Chin and Juok Cho and Andy Chu and Eric Chuah and Kristian Cibulskis and Giovanni Ciriello and Amanda Clarke and Gary L Clayman and Leslie Cope and John A Copland and Kyle Covington and Ludmila Danilova and Tanja Davidsen and John A Demchok and Daniel DiCara and Noreen Dhalla and Rajiv Dhir and Sheliann S Dookran and Gideon Dresdner and Jonathan Eldridge and Greg Eley and Adel K El-Naggar and Stephanie Eng and James A Fagin and Timothy Fennell and Robert L Ferris and Sheila Fisher and Scott Frazer and Jessica Frick and Stacey B Gabriel and Ian Ganly and Jianjiong Gao and Levi A Garraway and Julie M Gastier-Foster and Gad Getz and Nils Gehlenborg and Ronald Ghossein and Richard A Gibbs and Thomas J Giordano and Karen Gomez-Hernandez and Jonna Grimsby and Benjamin Gross and Ranabir Guin and Angela Hadjipanayis and Hollie A Harper and D Neil Hayes and David I Heiman and James G Herman and Katherine A Hoadley and Matan Hofree and Robert A Holt and Alan P Hoyle and Franklin W Huang and Mei Huang and Carolyn M Hutter and Trey Ideker and Lisa Iype and Anders Jacobsen and Stuart R Jefferys and Corbin D Jones and Steven JM Jones and Katayoon Kasaian and Electron Kebebew and Fadlo R Khuri and Jaegil Kim and Roger Kramer and Richard Kreisberg and Raju Kucherlapati and David J Kwiatkowski and Marc Ladanyi and Phillip H Lai and Peter W Laird and Eric Lander and Michael S Lawrence and Darlene Lee and Eunjung Lee and Semin Lee and William Lee and Kristen M Leraas and Tara M Lichtenberg and Lee Lichtenstein and Pei Lin and Shiyun Ling and Jinze Liu and Wenbin Liu and Yingchun Liu and Virginia A LiVolsi and Yiling Lu and Yussanne Ma and Harshad S Mahadeshwar and Marco A Marra and Michael Mayo and David G McFadden and Shaowu Meng and Matthew Meyerson and Piotr A Mieczkowski and Michael Miller and Gordon Mills and Richard A Moore and Lisle E Mose and Andrew J Mungall and Bradley A Murray and Yuri E Nikiforov and Michael S Noble and Akinyemi I Ojesina and Taofeek K Owonikoko and Bradley A Ozenberger and Angeliki Pantazi and Michael Parfenov and Peter J Park and Joel S Parker and Evan O Paull and Chandra Sekhar Pedamallu and Charles M Perou and Jan F Prins and Alexei Protopopov"
      }
    ],
    "zxB06pcAAAAJ": [
      {
        "title": "Diagnosing and responding to violations in the positivity assumption",
        "abstract": "The assumption of positivity or experimental treatment assignment requires that observed treatment levels vary within confounder strata. This article discusses the positivity assumption in the context of assessing model and parameter-specific identifiability of causal effects. Positivity violations occur when certain subgroups in a sample rarely or never receive some treatments of interest. The resulting sparsity in the data may increase bias with or without an increase in variance and can threaten valid inference. The parametric bootstrap is presented as a tool to assess the severity of such threats and its utility as a diagnostic is explored using simulated and real data. Several approaches for improving the identifiability of parameters in the presence of positivity violations are reviewed. Potential responses to data sparsity include restriction of the covariate adjustment set, use of an alternative projection function to define …",
        "year": 2012,
        "authors": "Maya L Petersen and Kristin E Porter and Susan Gruber and Yue Wang and Mark J Van Der Laan"
      },
      {
        "title": "Promoting transparency in social science research",
        "abstract": "There is growing appreciation for the advantages of experimentation in the social sciences. Policy-relevant claims that in the past were backed by theoretical arguments and inconclusive correlations are now being investigated using more credible methods. Changes have been particularly pronounced in development economics, where hundreds of randomized trials have been carried out over the last decade. When experimentation is difficult or impossible, researchers are using quasi-experimental designs. Governments and advocacy groups display a growing appetite for evidence-based policy-making. In 2005, Mexico established an independent government agency to rigorously evaluate social programs, and in 2012, the U.S. Office of Management and Budget advised federal agencies to present evidence from randomized program evaluations in budget requests (, ).",
        "year": 2014,
        "authors": "Edward Miguel and Colin Camerer and Katherine Casey and Joshua Cohen and Kevin M Esterling and Alan Gerber and Rachel Glennerster and Don P Green and Macartan Humphreys and Guido Imbens and David Laitin and Temina Madon and Leif Nelson and Brian A Nosek and Maya Petersen and Richard Sedlmayr and Joseph P Simmons and Uri Simonsohn and Mark Van der Laan"
      },
      {
        "title": "Estimation of direct causal effects",
        "abstract": "Many common problems in epidemiologic and clinical research involve estimating the effect of an exposure on an outcome while blocking the exposure's effect on an intermediate variable. Effects of this kind are termed direct effects. Estimation of direct effects is typically the goal of research aimed at understanding mechanistic pathways by which an exposure acts to cause or prevent disease, as well as in many other settings. Although multivariable regression is commonly used to estimate direct effects, this approach requires assumptions beyond those required for the estimation of total causal effects. In addition, when the exposure and intermediate variables interact to cause disease, multivariable regression estimates a particular type of direct effect—the effect of an exposure on an outcome when the intermediate is fixed at a specified level. Using the counterfactual framework, we distinguish this definition of a …",
        "year": 2006,
        "authors": "Maya L Petersen and Sandra E Sinisi and Mark J van der Laan"
      }
    ],
    "67kghxAAAAAJ": [
      {
        "title": "Towards evaluating the robustness of neural networks",
        "abstract": "Neural networks provide state-of-the-art results for most machine learning tasks. Unfortunately, neural networks are vulnerable to adversarial examples: given an input x and any target classification t, it is possible to find a new input x' that is similar to x but classified as t. This makes it difficult to apply neural networks in security-critical areas. Defensive distillation is a recently proposed approach that can take an arbitrary neural network, and increase its robustness, reducing the success rate of current attacks' ability to find adversarial examples from 95% to 0.5%. In this paper, we demonstrate that defensive distillation does not significantly increase the robustness of neural networks by introducing three new attack algorithms that are successful on both distilled and undistilled neural networks with 100% probability. Our attacks are tailored to three distance metrics used previously in the literature, and when compared to …",
        "year": 2017,
        "authors": "Nicholas Carlini and David Wagner"
      },
      {
        "title": "Practical techniques for searches on encrypted data",
        "abstract": "It is desirable to store data on data storage servers such as mail servers and file servers in encrypted form to reduce security and privacy risks. But this usually implies that one has to sacrifice functionality for security. For example, if a client wishes to retrieve only documents containing certain words, it was not previously known how to let the data storage server perform the search and answer the query, without loss of data confidentiality. We describe our cryptographic schemes for the problem of searching on encrypted data and provide proofs of security for the resulting crypto systems. Our techniques have a number of crucial advantages. They are provably secure: they provide provable secrecy for encryption, in the sense that the untrusted server cannot learn anything about the plaintext when only given the ciphertext; they provide query isolation for searches, meaning that the untrusted server cannot learn …",
        "year": 2000,
        "authors": "Dawn Xiaoding Song and David Wagner and Adrian Perrig"
      },
      {
        "title": "Secure routing in wireless sensor networks: Attacks and countermeasures",
        "abstract": "We consider routing security in wireless sensor networks. Many sensor network routing protocols have been proposed, but none of them have been designed with security as a goal. We propose security goals for routing in sensor networks, show how attacks against ad-hoc and peer-to-peer networks can be adapted into powerful attacks against sensor networks, introduce two classes of novel attacks against sensor networks––sinkholes and HELLO floods, and analyze the security of all the major sensor network routing protocols. We describe crippling attacks against all of them and suggest countermeasures and design considerations. This is the first such analysis of secure routing in sensor networks.",
        "year": 2003,
        "authors": "Chris Karlof and David Wagner"
      }
    ],
    "xaQuPloAAAAJ": [
      {
        "title": "Chain of thought prompting elicits reasoning in large language models",
        "abstract": "We explore how generating a chain of thought---a series of intermediate reasoning steps---significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.",
        "year": 2022,
        "authors": "Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Ed Chi and Quoc Le and Denny Zhou"
      },
      {
        "title": "Self-consistency improves chain of thought reasoning in language models",
        "abstract": "Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It first samples a diverse set of reasoning paths instead of only taking the greedy one, and then selects the most consistent answer by marginalizing out the sampled reasoning paths. Self-consistency leverages the intuition that a complex reasoning problem typically admits multiple different ways of thinking leading to its unique correct answer. Our extensive empirical evaluation shows that self-consistency boosts the performance of chain-of-thought prompting with a striking margin on a range of popular arithmetic and commonsense reasoning benchmarks, including GSM8K (+17.9%), SVAMP (+11.0%), AQuA (+12.2%), StrategyQA (+6.4%) and ARC-challenge (+3.9%).",
        "year": 2022,
        "authors": "Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou"
      },
      {
        "title": "Least-to-most prompting enables complex reasoning in large language models",
        "abstract": "Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difficult problems than those seen in the prompts. A notable finding is that when the GPT-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark SCAN in any split (including length split) with an accuracy of at least 99% using just 14 exemplars, compared to only 16% accuracy with chain-of-thought prompting. This is particularly noteworthy because neural-symbolic models in the literature that specialize in solving SCAN are trained on the entire training set containing over 15,000 examples. We have included prompts for all the tasks in the Appendix.",
        "year": 2022,
        "authors": "Denny Zhou and Nathanael Schärli and Le Hou and Jason Wei and Nathan Scales and Xuezhi Wang and Dale Schuurmans and Claire Cui and Olivier Bousquet and Quoc Le and Ed Chi"
      }
    ],
    "rMDVDA8AAAAJ": [
      {
        "title": "EmbedLLM: Learning Compact Representations of Large Language Models",
        "abstract": "With hundreds of thousands of language models available on Huggingface today, efficiently evaluating and utilizing these models across various downstream, tasks has become increasingly critical. Many existing methods repeatedly learn task-specific representations of Large Language Models (LLMs), which leads to inefficiencies in both time and computational resources. To address this, we propose EmbedLLM, a framework designed to learn compact vector representations, of LLMs that facilitate downstream applications involving many models, such as model routing. We introduce an encoder-decoder approach for learning such embeddings, along with a systematic framework to evaluate their effectiveness. Empirical results show that EmbedLLM outperforms prior methods in model routing both in accuracy and latency. Additionally, we demonstrate that our method can forecast a model's performance on multiple benchmarks, without incurring additional inference cost. Extensive probing experiments validate that the learned embeddings capture key model characteristics, e.g. whether the model is specialized for coding tasks, even without being explicitly trained on them. We open source our dataset, code and embedder to facilitate further research and application.",
        "year": 2024,
        "authors": "Richard Zhuang and Tianhao Wu and Zhaojin Wen and Andrew Li and Jiantao Jiao and Kannan Ramchandran"
      },
      {
        "title": "Position: Evolving AI collectives enhance human diversity and enable self-regulation",
        "abstract": "Large language model behavior is shaped by the language of those with whom they interact. This capacity and their increasing prevalence online portend that they will intentionally or unintentionally \"program\" one another and form emergent AI subjectivities, relationships, and collectives. Here, we call upon the research community to investigate these \"societies\" of interacting artificial intelligences to increase their rewards and reduce their risks for human society and the health of online environments. We use a small \"community\" of models and their evolving outputs to illustrate how such emergent, decentralized AI collectives can spontaneously expand the bounds of human diversity and reduce the risk of toxic, anti-social behavior online. Finally, we discuss opportunities for AI cross-moderation and address ethical issues and design challenges associated with creating and maintaining free-formed AI collectives.",
        "year": 2024,
        "authors": "Shiyang Lai and Yujin Potter and Junsol Kim and Richard Zhuang and Dawn Song and James Evans"
      },
      {
        "title": "Evolving AI Collectives to Enhance Human Diversity and Enable Self-Regulation",
        "abstract": "Large language model behavior is shaped by the language of those with whom they interact. This capacity and their increasing prevalence online portend that they will intentionally or unintentionally \"program\" one another and form emergent AI subjectivities, relationships, and collectives. Here, we call upon the research community to investigate these \"societies\" of interacting artificial intelligences to increase their rewards and reduce their risks for human society and the health of online environments. We use a small \"community\" of models and their evolving outputs to illustrate how such emergent, decentralized AI collectives can spontaneously expand the bounds of human diversity and reduce the risk of toxic, anti-social behavior online. Finally, we discuss opportunities for AI cross-moderation and address ethical issues and design challenges associated with creating and maintaining free-formed AI collectives.",
        "year": 2024,
        "authors": "Shiyang Lai and Yujin Potter and Junsol Kim and Richard Zhuang and Dawn Song and James Evans"
      }
    ],
    "l-mlF7YAAAAJ": [
      {
        "title": "The loss surfaces of multilayer networks",
        "abstract": "We study the connection between the highly non-convex loss function of a simple model of the fully-connected feed-forward neural network and the Hamiltonian of the spherical spin-glass model under the assumptions of: i) variable independence, ii) redundancy in network parametrization, and iii) uniformity. These assumptions enable us to explain the complexity of the fully decoupled neural network through the prism of the results from random matrix theory. We show that for large-size decoupled networks the lowest critical values of the random loss function form a layered structure and they are located in a well-defined band lower-bounded by the global minimum. The number of local minima outside that band diminishes exponentially with the size of the network. We empirically verify that the mathematical model exhibits similar behavior as the computer simulations, despite the presence of high dependencies in real networks. We conjecture that both simulated annealing and SGD converge to the band of low critical points, and that all critical points found there are local minima of high quality measured by the test error. This emphasizes a major difference between large-and small-size networks where for the latter poor quality local minima have non-zero probability of being recovered. Finally, we prove that recovering the global minimum becomes harder as the network size increases and that it is in practice irrelevant as global minimum often leads to overfitting.",
        "year": 2015,
        "authors": "Anna Choromanska and Mikael Henaff and Michael Mathieu and Gérard Ben Arous and Yann LeCun"
      },
      {
        "title": "Entropy SGD: biasing gradient descent into wide valleys",
        "abstract": "This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in the sharp valleys. Conceptually, our algorithm resembles two nested loops of SGD where we use Langevin dynamics in the inner loop to compute the gradient of the local entropy before each update of the weights. We show that the new objective has a smoother energy landscape and show improved generalization over SGD using uniform stability, under …",
        "year": 2017,
        "authors": "P Chaudhari and A Choromanska and S Soatto and Y LeCun and C Baldassi and C Borgs and J Chayes and L Sagun and R Zecchina"
      },
      {
        "title": "Deep learning with elastic averaging SGD",
        "abstract": "We study the problem of stochastic optimization for deep learning in the parallel computing environment under communication constraints. A new algorithm is proposed in this setting where the communication and coordination of work among concurrent processes (local workers), is based on an elastic force which links the parameters they compute with a center variable stored by the parameter server (master). The algorithm enables the local workers to perform more exploration, ie the algorithm allows the local variables to fluctuate further from the center variable by reducing the amount of communication between local workers and the master. We empirically demonstrate that in the deep learning setting, due to the existence of many local optima, allowing more exploration can lead to the improved performance. We propose synchronous and asynchronous variants of the new algorithm. We provide the stability analysis of the asynchronous variant in the round-robin scheme and compare it with the more common parallelized method ADMM. We show that the stability of EASGD is guaranteed when a simple stability condition is satisfied, which is not the case for ADMM. We additionally propose the momentum-based version of our algorithm that can be applied in both synchronous and asynchronous settings. Asynchronous variant of the algorithm is applied to train convolutional neural networks for image classification on the CIFAR and ImageNet datasets. Experiments demonstrate that the new algorithm accelerates the training of deep architectures compared to DOWNPOUR and other common baseline approaches and furthermore is very …",
        "year": 2015,
        "authors": "Sixin Zhang and Anna E Choromanska and Yann LeCun"
      }
    ],
    "JKVR2ksAAAAJ": [
      {
        "title": " -Resolvability",
        "abstract": "The conventional channel resolvability refers to the minimum rate needed for an input process to approximate the channel output distribution in total variation distance. In this paper, we study Eγ-resolvability, in which total variation is replaced by the more general Eγ distance. A general one-shot achievability bound for the precision of such an approximation is developed. Let QX|U be a random transformation, n be an integer, and E ∈ (0, +∞). We show that in the asymptotic setting where γ = exp(nE), a (nonnegative) randomness rate above inf QU:D(QXIIπX)≤E{D(QXIIπX) + I(QU, QX|U) - E} is sufficient to approximate the output distribution πX⊗n using the channel QX|U⊗n, where QU → QX|U → QX, and is also necessary in the case of finite U and X . In particular, a randomness rate of inf QU I(QU, QX|U) - E is always sufficient. We also study the convergence of the approximation error under the high-probability …",
        "year": 2016,
        "authors": "Jingbo Liu and Paul Cuff and Sergio Verdú"
      },
      {
        "title": "Secret key generation with limited interaction",
        "abstract": "A basic two-terminal secret key generation model is considered, where the interactive communication rate between the terminals may be limited, and in particular may not be enough to achieve the maximum key rate. We first prove a multi-letter characterization of the key-communication rate region (where the number of auxiliary random variables depends on the number of rounds of the communication), and then provide an equivalent but simpler characterization in terms of concave envelopes in the case of unlimited number of rounds. Two extreme cases are given special attention. First, in the regime of very low communication rates, the key bits per interaction bit (KBIB) is expressed with a new “symmetric strong data processing constant”, which has a concave envelope characterization analogous to that of the conventional strong data processing constant. The symmetric strong data processing constant can be …",
        "year": 2017,
        "authors": "Jingbo Liu and P Cuff and Sergio Verdú"
      },
      {
        "title": "Anisotropic diffusion for image denoising based on diffusion tensors",
        "abstract": "In this paper, the anisotropic diffusion for image denoising is considered. A new method to construct diffusion tensors is proposed. The tensors obtained by our approach depend on four directional derivatives of the intensity of an image, and hence they are adaptively determined by local image structure. It is shown that the proposed diffusion filter is isotropic in the interior of a region, whereas it is anisotropic at edges. This property of tensors allows us to efficiently remove noise in an image, particularly noise at edges. Several numerical experiments are conducted on both synthetic and real images.",
        "year": 2012,
        "authors": "Feng Liu and Jingbo Liu"
      }
    ],
    "bQowYEYAAAAJ": [
      {
        "title": "Zero-Shot Robotic Manipulation with Pre-Trained Image-Editing Diffusion Models",
        "abstract": "If generalist robots are to operate in truly unstructured environments, they need to be able to recognize and reason about novel objects and scenarios. Such objects and scenarios might not be present in the robot's own training data. We propose SuSIE, a method that leverages an image-editing diffusion model to act as a high-level planner by proposing intermediate subgoals that a low-level controller can accomplish. Specifically, we finetune InstructPix2Pix on video data, consisting of both human videos and robot rollouts, such that it outputs hypothetical future \"subgoal\" observations given the robot's current observation and a language command. We also use the robot data to train a low-level goal-conditioned policy to act as the aforementioned low-level controller. We find that the high-level subgoal predictions can utilize Internet-scale pretraining and visual understanding to guide the low-level goal-conditioned policy, achieving significantly better generalization and precision than conventional language-conditioned policies. We achieve state-of-the-art results on the CALVIN benchmark, and also demonstrate robust generalization on real-world manipulation tasks, beating strong baselines that have access to privileged information or that utilize orders of magnitude more compute and training data. The project website can be found at http://rail-berkeley.github.io/susie .",
        "year": 2023,
        "authors": "Kevin Black and Mitsuhiko Nakamoto and Pranav Atreya and Homer Walke and Chelsea Finn and Aviral Kumar and Sergey Levine"
      },
      {
        "title": "VI-IKD: High-Speed Accurate Off-Road Navigation using Learned Visual-Inertial Inverse Kinodynamics",
        "abstract": "One of the key challenges in high-speed off-road navigation on ground vehicles is that the kinodynamics of the vehicle-terrain interaction can differ dramatically depending on the terrain. Previous approaches to addressing this challenge have considered learning an inverse kinodynamics (IKD) model, conditioned on inertial information of the vehicle to sense the kinodynamic interactions. In this paper, we hypothesize that to enable accurate high-speed off-road navigation using a learned IKD model, in addition to inertial information from the past, one must also anticipate the kinodynamic interactions of the vehicle with the terrain in the future. To this end, we introduce Visual-Inertial Inverse Kinodynamics (VI-IKD), a novel learning based IKD model that is conditioned on visual information from a terrain patch ahead of the robot in addition to past inertial information, enabling it to anticipate kinodynamic interactions in …",
        "year": 2022,
        "authors": "Haresh Karnan and Kavan Singh Sikand and Pranav Atreya and Sadegh Rabiee and Xuesu Xiao and Garrett Warnell and Peter Stone and Joydeep Biswas"
      },
      {
        "title": "High-Speed Accurate Robot Control using Learned Forward Kinodynamics and Non-linear Least Squares Optimization",
        "abstract": "Accurate control of robots at high speeds requires a control system that can take into account the kinodynamic interactions of the robot with the environment. Prior works on learning inverse kinodynamic (IKD) models of robots have shown success in capturing the complex kinodynamic effects. However, the types of control problems these approaches can be applied to are limited only to that of following pre-computed kinodynamically feasible trajectories. In this paper we present Optim-FKD, a new formulation for accurate, high-speed robot control that makes use of a learned forward kinodynamic (FKD) model and non-linear least squares optimization. Optim-FKD can be used for accurate, high speed control on any control task specifiable by a non-linear least squares objective. Optim-FKD can solve for control objectives such as path following and time-optimal control in real time, without needing access to pre …",
        "year": 2022,
        "authors": "Pranav Atreya and Haresh Karnan and Kavan Singh Sikand and Xuesu Xiao and Sadegh Rabiee and Joydeep Biswas"
      }
    ],
    "SlZavnIAAAAJ": [
      {
        "title": "Satisfiability Modulo Theories",
        "abstract": "Satisfiability Modulo Theories (SMT) refers to the problem of determining whether a first-order formula is satisfiable with respect to some logical theory. Solvers based on SMT are used as back-end engines in model-checking applications such as bounded, interpolation-based, and predicate-abstraction-based model checking. After a brief illustration of these uses, we survey the predominant techniques for solving SMT problems with an emphasis on the lazy approach, in which a propositional satisfiability (SAT) solver is combined with one or more theory solvers. We discuss the architecture of a lazy SMT solver, give examples of theory solvers, show how to combine such solvers modularly, and mention several extensions of the lazy approach. We also briefly describe the eager approach in which the SMT problem is reduced to a SAT problem. Finally, we discuss how the basic framework for determining …",
        "year": 2021,
        "authors": "Clark Barrett and Roberto Sebastiani and Sanjit A. Seshia and Cesare Tinelli"
      },
      {
        "title": "Introduction to embedded systems: A cyber-physical systems approach",
        "abstract": "An introduction to the engineering principles of embedded systems, with a focus on modeling, design, and analysis of cyber-physical systems. The most visible use of computers and software is processing information for human consumption. The vast majority of computers in use, however, are much less visible. They run the engine, brakes, seatbelts, airbag, and audio system in your car. They digitally encode your voice and construct a radio signal to send it from your cell phone to a base station. They command robots on a factory floor, power generation in a power plant, processes in a chemical plant, and traffic lights in a city. These less visible computers are called embedded systems, and the software they run is called embedded software. The principal challenges in designing and analyzing embedded systems stem from their interaction with physical processes. This book takes a cyber-physical approach to embedded systems, introducing the engineering concepts underlying embedded systems as a technology and as a subject of study. The focus is on modeling, design, and analysis of cyber-physical systems, which integrate computation, networking, and physical processes. The second edition offers two new chapters, several new exercises, and other improvements. The book can be used as a textbook at the advanced undergraduate or introductory graduate level and as a professional reference for practicing engineers and computer scientists. Readers should have some familiarity with machine structures, computer programming, basic discrete mathematics and algorithms, and signals and systems.",
        "year": 2017,
        "authors": "Edward Ashford Lee and Sanjit Arunkumar Seshia"
      },
      {
        "title": "Semantics-aware malware detection",
        "abstract": "A malware detector is a system that attempts to determine whether a program has malicious intent. In order to evade detection, malware writers (hackers) frequently use obfuscation to morph malware. Malware detectors that use a pattern-matching approach (such as commercial virus scanners) are susceptible to obfuscations used by hackers. The fundamental deficiency in the pattern-matching approach to malware detection is that it is purely syntactic and ignores the semantics of instructions. In this paper, we present a malware-detection algorithm that addresses this deficiency by incorporating instruction semantics to detect malicious program traits. Experimental evaluation demonstrates that our malware-detection algorithm can detect variants of malware with a relatively low run-time overhead. Moreover our semantics-aware malware detection algorithm is resilient to common obfuscations used by hackers.",
        "year": 2005,
        "authors": "Mihai Christodorescu and Somesh Jha and Sanjit A Seshia and Dawn Song and Randal E Bryant"
      }
    ],
    "t2X4Mg8AAAAJ": [
      {
        "title": "Palm-e: An embodied multimodal language model",
        "abstract": "Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.",
        "year": 2023,
        "authors": "Danny Driess and Fei Xia and Mehdi SM Sajjadi and Corey Lynch and Aakanksha Chowdhery and Ayzaan Wahid and Jonathan Tompson and Quan Vuong and Tianhe Yu and Wenlong Huang and Yevgen Chebotar and Pierre Sermanet and Daniel Duckworth and Sergey Levine and Vincent Vanhoucke and Karol Hausman and Marc Toussaint and Klaus Greff and Andy Zeng and Igor Mordatch and Pete Florence"
      },
      {
        "title": "Using machine learning to focus iterative optimization",
        "abstract": "Iterative compiler optimization has been shown to outperform static approaches. This, however, is at the cost of large numbers of evaluations of the program. This paper develops a new methodology to reduce this number and hence speed up iterative optimization. It uses predictive modelling from the domain of machine learning to automatically focus search on those areas likely to give greatest performance. This approach is independent of search algorithm, search space or compiler infrastructure and scales gracefully with the compiler optimization space size. Off-line, a training set of programs is iteratively evaluated and the shape of the spaces and program features are modelled. These models are learnt and used to focus the iterative optimization of a new program. We evaluate two learnt models, an independent and Markov model, and evaluate their worth on two embedded platforms, the Texas Instrument …",
        "year": 2006,
        "authors": "Felix Agakov and Edwin Bonilla and John Cavazos and Björn Franke and Grigori Fursin and Michael FP O'Boyle and John Thomson and Marc Toussaint and Christopher KI Williams"
      },
      {
        "title": "Robot trajectory optimization using approximate inference",
        "abstract": "The general stochastic optimal control (SOC) problem in robotics scenarios is often too complex to be solved exactly and in near real time. A classical approximate solution is to first compute an optimal (deterministic) trajectory and then solve a local linear-quadratic-gaussian (LQG) perturbation model to handle the system stochasticity. We present a new algorithm for this approach which improves upon previous algorithms like iLQG. We consider a probabilistic model for which the maximum likelihood (ML) trajectory coincides with the optimal trajectory and which, in the LQG case, reproduces the classical SOC solution. The algorithm then utilizes approximate inference methods (similar to expectation propagation) that efficiently generalize to non-LQG systems. We demonstrate the algorithm on a simulated 39-DoF humanoid robot.",
        "year": 2009,
        "authors": "Marc Toussaint"
      }
    ],
    "LQR0kNcAAAAJ": [
      {
        "title": "The nature of computation",
        "abstract": "Computational complexity is one of the most beautiful fields of modern mathematics, and it is increasingly relevant to other sciences ranging from physics to biology. But this beauty is often buried underneath layers of unnecessary formalism, and exciting recent results like interactive proofs, phase transitions, and quantum computing are usually considered too advanced for the typical student. This book bridges these gaps by explaining the deep ideas of theoretical computer science in a clear and enjoyable fashion, making them accessible to non-computer scientists and to computer scientists who finally want to appreciate their field from a new point of view. The authors start with a lucid and playful explanation of the P vs. NP problem, explaining why it is so fundamental, and so hard to resolve. They then lead the reader through the complexity of mazes and games; optimization in theory and practice; randomized algorithms, interactive proofs, and pseudorandomness; Markov chains and phase transitions; and the outer reaches of quantum computing. At every turn, they use a minimum of formalism, providing explanations that are both deep and accessible. The book is intended for graduate and undergraduate students, scientists from other areas who have long wanted to understand this subject, and experts who want to fall in love with this field all over again.",
        "year": 2011,
        "authors": "Cristopher Moore and Stephan Mertens"
      },
      {
        "title": "Threshold values of random K‐SAT from the cavity method",
        "abstract": "Using the cavity equations of Mézard, Parisi, and Zecchina Science 297 (2002), 812; Mézard and Zecchina, Phys Rev E 66 (2002), 056126 we derive the various threshold values for the number of clauses per variable of the random K‐satisfiability problem, generalizing the previous results to K ≥ 4. We also give an analytic solution of the equations, and some closed expressions for these thresholds, in an expansion around large K. The stability of the solution is also computed. For any K, the satisfiability threshold is found to be in the stable region of the solution, which adds further credit to the conjecture that this computation gives the exact satisfiability threshold.© 2005 Wiley Periodicals, Inc. Random Struct. Alg., 2006",
        "year": 2006,
        "authors": "Stephan Mertens and Marc Mézard and Riccardo Zecchina"
      },
      {
        "title": "Continuum percolation thresholds in two dimensions",
        "abstract": "A wide variety of methods have been used to compute percolation thresholds. In lattice percolation, the most powerful of these methods consists of microcanonical simulations using the union-find algorithm to efficiently determine the connected clusters, and (in two dimensions) using exact values from conformal field theory for the probability, at the phase transition, that various kinds of wrapping clusters exist on the torus. We apply this approach to percolation in continuum models, finding overlaps between objects with real-valued positions and orientations. In particular, we find precise values of the percolation transition for disks, squares, rotated squares, and rotated sticks in two dimensions and confirm that these transitions behave as conformal field theory predicts. The running time and memory use of our algorithm are essentially linear as a function of the number of objects at criticality.",
        "year": 2012,
        "authors": "Stephan Mertens and Cristopher Moore"
      }
    ],
    "todsDfQAAAAJ": [
      {
        "title": "The Laplacian pyramid as a compact image code",
        "abstract": "We describe a technique for image encoding in which local operators of many scales but identical shape serve as the basis functions. The representation differs from established techniques in that the code elements are localized in spatial frequency as well as in space.Pixel-to-pixel correlations are first removed by subtracting a low-pass filtered copy of the image from the image itself. The result is a net data compression since the difference, or error, image has low variance and entropy, and the low-pass filtered image may represented at reduced sample density. Further data compression is achieved by quantizing the difference image. These steps are then repeated to compress the low-pass image. Iteration of the process at appropriately expanded scales generates a pyramid data structure.The encoding process is equivalent to sampling the image with Laplacian operators of many scales. Thus, the code tends to …",
        "year": 1987,
        "authors": "Peter J Burt and Edward H Adelson"
      },
      {
        "title": "Spatiotemporal energy models for the perception of motion",
        "abstract": "A motion sequence may be represented as a single pattern in x–y–t space; a velocity of motion corresponds to a three-dimensional orientation in this space. Motion sinformation can be extracted by a system that responds to the oriented spatiotemporal energy. We discuss a class of models for human motion mechanisms in which the first stage consists of linear filters that are oriented in space-time and tuned in spatial frequency. The outputs of quadrature pairs of such filters are squared and summed to give a measure of motion energy. These responses are then fed into an opponent stage. Energy models can be built from elements that are consistent with known physiology and psychophysics, and they permit a qualitative understanding of a variety of motion phenomena.",
        "year": 1985,
        "authors": "Edward H Adelson and James R Bergen"
      },
      {
        "title": "The design and use of steerable filters",
        "abstract": "Oriented ﬁlters are useful in many early vision and image processing tasks. One often needs to apply the same ﬁlter, rotated to different angles under adaptive control, or wishes to calculate the ﬁlter response at various orientations. We present an efﬁcient architecture to synthesize ﬁlters of arbitrary orientations from linear combinations of basis ﬁlters, allowing one to adaptively “steer” a ﬁlter to any orientation, and to determine analytically the ﬁlter output as a function of orientation. Steerable ﬁlters may be designed in quadrature pairs to allow adaptive control over phase as well as orientation. We show how to design and steer the ﬁlters and present examples of their use in several tasks: the analysis of orientation and phase, angularly adaptive ﬁltering, edge detection, and shape from shading. One can also build a self-similar steerable pyramid representation. The same concepts can be generalized to the design of 3 …",
        "year": 1991,
        "authors": "William T Freeman and Edward H Adelson"
      }
    ],
    "Rne0FzEAAAAJ": [
      {
        "title": "Taking the human out of the loop: A review of Bayesian optimization",
        "abstract": "Big Data applications are typically associated with systems involving large numbers of users, massive complex software systems, and large-scale heterogeneous computing and storage architectures. The construction of such systems involves many distributed design choices. The end products (e.g., recommendation systems, medical analysis tools, real-time game engines, speech recognizers) thus involve many tunable configuration parameters. These parameters are often specified and hard-coded into the software by various developers or teams. If optimized jointly, these parameters can result in significant improvements. Bayesian optimization is a powerful tool for the joint optimization of design choices that is gaining great popularity in recent years. It promises greater automation so as to increase both product quality and human productivity. This review paper introduces Bayesian optimization, highlights some …",
        "year": 2015,
        "authors": "Bobak Shahriari and Kevin Swersky and Ziyu Wang and Ryan P Adams and Nando De Freitas"
      },
      {
        "title": "Dueling network architectures for deep reinforcement learning",
        "abstract": "In recent years there have been many successes of using deep representations in reinforcement learning. Still, many of these applications use conventional architectures, such as convolutional networks, LSTMs, or auto-encoders. In this paper, we present a new neural network architecture for model-free reinforcement learning. Our dueling network represents two separate estimators: one for the state value function and one for the state-dependent action advantage function. The main benefit of this factoring is to generalize learning across actions without imposing any change to the underlying reinforcement learning algorithm. Our results show that this architecture leads to better policy evaluation in the presence of many similar-valued actions. Moreover, the dueling architecture enables our RL agent to outperform the state-of-the-art on the Atari 2600 domain.",
        "year": 2016,
        "authors": "Ziyu Wang and Tom Schaul and Matteo Hessel and Hado Hasselt and Marc Lanctot and Nando Freitas"
      },
      {
        "title": "Grandmaster level in StarCraft II using multi-agent reinforcement learning",
        "abstract": "Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions 1, 2, 3, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems 4. Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players. We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent …",
        "year": 2019,
        "authors": "Oriol Vinyals and Igor Babuschkin and Wojciech M Czarnecki and Michaël Mathieu and Andrew Dudzik and Junyoung Chung and David H Choi and Richard Powell and Timo Ewalds and Petko Georgiev and Junhyuk Oh and Dan Horgan and Manuel Kroiss and Ivo Danihelka and Aja Huang and Laurent Sifre and Trevor Cai and John P Agapiou and Max Jaderberg and Alexander S Vezhnevets and Rémi Leblond and Tobias Pohlen and Valentin Dalibard and David Budden and Yury Sulsky and James Molloy and Tom L Paine and Caglar Gulcehre and Ziyu Wang and Tobias Pfaff and Yuhuai Wu and Roman Ring and Dani Yogatama and Dario Wünsch and Katrina McKinney and Oliver Smith and Tom Schaul and Timothy Lillicrap and Koray Kavukcuoglu and Demis Hassabis and Chris Apps and David Silver"
      }
    ],
    "SiBVfPUAAAAJ": [
      {
        "title": "Rules of the road: Predicting driving behavior with a convolutional model of semantic interactions",
        "abstract": "We focus on the problem of predicting future states of entities in complex, real-world driving scenarios. Previous research has approached this problem via low-level signals to predict short time horizons, and has not addressed how to leverage key assets relied upon heavily by industry self-driving systems:(1) large 3D perception efforts which provide highly accurate 3D states of agents with rich attributes, and (2) detailed and accurate semantic maps of the environment (lanes, traffic lights, crosswalks, etc). We present a unified representation which encodes such high-level semantic information in a spatial grid, allowing the use of deep convolutional models to fuse complex scene context. This enables learning entity-entity and entity-environment interactions with simple, feed-forward computations in each timestep within an overall temporal model of an agent's behavior. We propose different ways of modelling the future as a distribution over future states using standard supervised learning. We introduce a novel dataset providing industry-grade rich perception and semantic inputs, and empirically show we can effectively learn fundamentals of driving behavior.",
        "year": 2019,
        "authors": "Joey Hong and Benjamin Sapp and James Philbin"
      },
      {
        "title": "When Should We Prefer Offline Reinforcement Learning Over Behavioral Cloning?",
        "abstract": "Offline reinforcement learning (RL) algorithms can acquire effective policies by utilizing previously collected experience, without any online interaction. It is widely understood that offline RL is able to extract good policies even from highly suboptimal data, a scenario where imitation learning finds suboptimal solutions that do not improve over the demonstrator that generated the dataset. However, another common use case for practitioners is to learn from data that resembles demonstrations. In this case, one can choose to apply offline RL, but can also use behavioral cloning (BC) algorithms, which mimic a subset of the dataset via supervised learning. Therefore, it seems natural to ask: when can an offline RL method outperform BC with an equal amount of expert data, even when BC is a natural choice? To answer this question, we characterize the properties of environments that allow offline RL methods to perform better than BC methods, even when only provided with expert data. Additionally, we show that policies trained on sufficiently noisy suboptimal data can attain better performance than even BC algorithms with expert data, especially on long-horizon problems. We validate our theoretical results via extensive experiments on both diagnostic and high-dimensional domains including robotic manipulation, maze navigation, and Atari games, with a variety of data distributions. We observe that, under specific but common conditions such as sparse rewards or noisy data sources, modern offline RL methods can significantly outperform BC.",
        "year": 2021,
        "authors": "Aviral Kumar and Joey Hong and Anikait Singh and Sergey Levine"
      },
      {
        "title": "Trajectory prediction on top-down scenes",
        "abstract": "BOOW 30/095 (2012.01) GOIS 13/86(2006.01) GOIS 13/89(2006.01) G05D 1/00(2006.01) G06K 9/00(2006.01) GOON 5/04(2006.01)(52) US CI. CPC G05D 1/0221 (2013.01); B60W 30/0956 (2013.01); GOIS 13/865 (2013.01); GOIS 13/89 (2013.01); G05D 1/0088 (2013.01); G06K 900825 (2013.01); G06N 504 (2013.01); G06N 20/00 (2019.01); G05D 2201/0213 (2013.01)",
        "year": 2021,
        "authors": "Xi Joey Hong and Benjamin John Sapp"
      }
    ],
    "94RFSSsAAAAJ": [
      {
        "title": "{PowerGraph}: Distributed {Graph-Parallel} computation on natural graphs",
        "abstract": "Large-scale graph-structured computation is central to tasks ranging from targeted advertising to natural language processing and has led to the development of several graph-parallel abstractions including Pregel and GraphLab. However, the natural graphs commonly found in the real-world have highly skewed power-law degree distributions, which challenge the assumptions made by these abstractions, limiting performance and scalability.",
        "year": 2012,
        "authors": "Joseph E Gonzalez and Yucheng Low and Haijie Gu and Danny Bickson and Carlos Guestrin"
      },
      {
        "title": "Clipper: A {Low-Latency} online prediction serving system",
        "abstract": "Machine learning is being deployed in a growing number of applications which demand real-time, accurate, and robust predictions under heavy query load. However, most machine learning frameworks and systems only address model training and not deployment.",
        "year": 2017,
        "authors": "Daniel Crankshaw and Xin Wang and Guilio Zhou and Michael J Franklin and Joseph E Gonzalez and Ion Stoica"
      },
      {
        "title": "InferLine: latency-aware provisioning and scaling for prediction serving pipelines",
        "abstract": "Serving ML prediction pipelines spanning multiple models and hardware accelerators is a key challenge in production machine learning. Optimally configuring these pipelines to meet tight end-to-end latency goals is complicated by the interaction between model batch size, the choice of hardware accelerator, and variation in the query arrival process.In this paper we introduce InferLine, a system which provisions and manages the individual stages of prediction pipelines to meet end-to-end tail latency constraints while minimizing cost. InferLine consists of a low-frequency combinatorial planner and a high-frequency auto-scaling tuner. The low-frequency planner leverages stage-wise profiling, discrete event simulation, and constrained combinatorial search to automatically select hardware type, replication, and batching parameters for each stage in the pipeline. The high-frequency tuner uses network calculus to …",
        "year": 2020,
        "authors": "Daniel Crankshaw and Gur-Eyal Sela and Xiangxi Mo and Corey Zumar and Ion Stoica and Joseph Gonzalez and Alexey Tumanov"
      }
    ],
    "vgfGtykAAAAJ": [
      {
        "title": "Gemini: a family of highly capable multimodal models",
        "abstract": "This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.",
        "year": 2023,
        "authors": "Gemini Team and Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M Dai and Anja Hauth and Katie Millican and David Silver and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Jack Krawczyk and Cosmo Du and Ed Chi and Heng-Tze Cheng and Eric Ni and Purvi Shah and Patrick Kane and Betty Chan and Manaal Faruqui and Aliaksei Severyn and Hanzhao Lin and YaGuang Li and Yong Cheng and Abe Ittycheriah and Mahdis Mahdieh and Mia Chen and Pei Sun and Dustin Tran and Sumit Bagri and Balaji Lakshminarayanan and Jeremiah Liu and Andras Orban and Fabian Güra and Hao Zhou and Xinying Song and Aurelien Boffy and Harish Ganapathy and Steven Zheng and HyunJeong Choe and Ágoston Weisz and Tao Zhu and Yifeng Lu and Siddharth Gopal and Jarrod Kahn and Maciej Kula and Jeff Pitman and Rushin Shah and Emanuel Taropa and Majd Al Merey and Martin Baeuml and Zhifeng Chen and Laurent El Shafey and Yujing Zhang and Olcan Sercinoglu and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Anaïs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Gaurav Singh Tomar and Evan Senter and Martin Chadwick and Ilya Kornakov and Nithya Attaluri and Iñaki Iturrate and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Xavier Garcia and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco"
      },
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien MR Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan"
      },
      {
        "title": "A Compositional Object-Based Approach To Learning Physical Dynamics",
        "abstract": "We present the Neural Physics Engine (NPE), a framework for learning simulators of intuitive physics that naturally generalize across variable object count and different scene configurations. We propose a factorization of a physical scene into composable object-based representations and a neural network architecture whose compositional structure factorizes object dynamics into pairwise interactions. Like a symbolic physics engine, the NPE is endowed with generic notions of objects and their interactions; realized as a neural network, it can be trained via stochastic gradient descent to adapt to specific object properties and dynamics of different worlds. We evaluate the efficacy of our approach on simple rigid body dynamics in two-dimensional worlds. By comparing to less structured architectures, we show that the NPE's compositional representation of the structure in physical interactions improves its ability to predict movement, generalize across variable object count and different scene configurations, and infer latent properties of objects such as mass.",
        "year": 2016,
        "authors": "Michael B Chang and Tomer Ullman and Antonio Torralba and Joshua B Tenenbaum"
      }
    ],
    "1eBgIWsAAAAJ": [
      {
        "title": "Unbalanced random matching markets: The stark effect of competition",
        "abstract": "We study competition in matching markets with random heterogeneous preferences and an unequal number of agents on either side. First, we show that even the slightest imbalance yields an essentially unique stable matching. Second, we give a tight description of stable outcomes, showing that matching markets are extremely competitive. Each agent on the short side of the market is matched with one of his top choices, and each agent on the long side either is unmatched or does almost no better than being matched with a random partner. Our results suggest that any matching market is likely to have a small core, explaining why small cores are empirically ubiquitous.",
        "year": 2017,
        "authors": "Itai Ashlagi and Yash Kanoria and Jacob D Leshno"
      },
      {
        "title": "Efficient dynamic barter exchange",
        "abstract": "We study dynamic matching policies in a stochastic marketplace for barter, with agents arriving over time. Each agent is endowed with an item and is interested in an item possessed by another agent homogeneously with probability p, independently for all pairs of agents. Three settings are considered with respect to the types of allowed exchanges: (a) only two-way cycles, in which two agents swap items, (b) two-way or three-way cycles, (c) (unbounded) chains initiated by an agent who provides an item but expects nothing in return.We consider the average waiting time as a measure of efficiency and find that the cost outweighs the benefit from waiting to thicken the market. In particular, in each of the above settings, a policy that conducts exchanges in a greedy fashion is near optimal. Further, for small p, we find that allowing three-way cycles greatly reduces the waiting time over just two-way cycles, and conducting …",
        "year": 2017,
        "authors": "Ross Anderson and Itai Ashlagi and Y Kanoria and D Gamarnik"
      },
      {
        "title": "Managing congestion in matching markets",
        "abstract": "  Problem definition : Participants in matching markets face search and screening costs when seeking a match. We study how platform design can reduce the effort required to find a suitable partner.  Practical/academic relevance : The success of matching platforms requires designs that minimize search effort and facilitate efficient market clearing.  Methodology : We study a game-theoretic model in which “applicants” and “employers” pay costs to search and screen. An important feature of our model is that both sides may waste effort: Some applications are never screened, and employers screen applicants who may have already matched. We prove existence and uniqueness of equilibrium and characterize welfare for participants on both sides of the market.  Results : We identify that the market operates in one of two regimes: It is either screening-limited or application-limited. In screening-limited markets, employer …",
        "year": 2018,
        "authors": "Nick Arnosti and Ramesh Johari and Yash Kanoria"
      }
    ],
    "BZBkjNYAAAAJ": [
      {
        "title": "Open X-Embodiment: Robotic Learning Datasets and RT-X Models",
        "abstract": "Large, high-capacity models trained on diverse datasets have shown remarkable successes on efficiently tackling downstream applications. In domains from NLP to Computer Vision, this has led to a consolidation of pretrained models, with general pretrained backbones serving as a starting point for many applications. Can such a consolidation happen in robotics? Conventionally, robotic learning methods train a separate model for every application, every robot, and even every environment. Can we instead train \"generalist\" X-robot policy that can be adapted efficiently to new robots, tasks, and environments? In this paper, we provide datasets in standardized data formats and models to make it possible to explore this possibility in the context of robotic manipulation, alongside experimental results that provide an example of effective X-robot policies. We assemble a dataset from 22 different robots collected through …",
        "year": 2024,
        "authors": "Abby O’Neill and Abdul Rehman and Abhiram Maddukuri and Abhishek Gupta and Abhishek Padalkar and Abraham Lee and Acorn Pooley and Agrim Gupta and Ajay Mandlekar and Ajinkya Jain and Albert Tung and Alex Bewley and Alex Herzog and Alex Irpan and Alexander Khazatsky and Anant Rai and Anchit Gupta and Andrew Wang and Anikait Singh and Animesh Garg and Aniruddha Kembhavi and Annie Xie and Anthony Brohan and Antonin Raffin and Archit Sharma and Arefeh Yavary and Arhan Jain and Ashwin Balakrishna and Ayzaan Wahid and Ben Burgess-Limerick and Beomjoon Kim and Bernhard Schölkopf and Blake Wulfe and Brian Ichter and Cewu Lu and Charles Xu and Charlotte Le and Chelsea Finn and Chen Wang and Chenfeng Xu and Cheng Chi and Chenguang Huang and Christine Chan and Christopher Agia and Chuer Pan and Chuyuan Fu and Coline Devin and Danfei Xu and Daniel Morton and Danny Driess and Daphne Chen and Deepak Pathak and Dhruv Shah and Dieter Büchler and Dinesh Jayaraman and Dmitry Kalashnikov and Dorsa Sadigh and Edward Johns and Ethan Foster and Fangchen Liu and Federico Ceola and Fei Xia and Feiyu Zhao and Freek Stulp and Zhou"
      },
      {
        "title": "Recurrent autoregressive networks for online multi-object tracking",
        "abstract": "The main challenge of online multi-object tracking is to reliably associate object trajectories with detections in each video frame based on their tracking history. In this work, we propose the Recurrent Autoregressive Network (RAN), a temporal generative modeling framework to characterize the appearance and motion dynamics of multiple objects over time. The RAN couples an external memory and an internal memory. The external memory explicitly stores previous inputs of each trajectory in a time window, while the internal memory learns to summarize long-term tracking history and associate detections by processing the external memory. We conduct experiments on the MOT 2015 and 2016 datasets to demonstrate the robustness of our tracking method in highly crowded and occluded scenes. Our method achieves top-ranked results on the two benchmarks.",
        "year": 2018,
        "authors": "Kuan Fang and Yu Xiang and Xiaocheng Li and Silvio Savarese"
      },
      {
        "title": "Learning task-oriented grasping for tool manipulation from simulated self-supervision",
        "abstract": "Tool manipulation is vital for facilitating robots to complete challenging task goals. It requires reasoning about the desired effect of the task and, thus, properly grasping and manipulating the tool to achieve the task. Most work in robotics has focused on task-agnostic grasping, which optimizes for only grasp robustness without considering the subsequent manipulation tasks. In this article, we propose the Task-Oriented Grasping Network (TOG-Net) to jointly optimize both task-oriented grasping of a tool and the manipulation policy for that tool. The training process of the model is based on large-scale simulated self-supervision with procedurally generated tool objects. We perform both simulated and real-world experiments on two tool-based manipulation tasks: sweeping and hammering. Our model achieves overall 71.1% task success rate for sweeping and 80.0% task success rate for hammering.",
        "year": 2018,
        "authors": "Kuan Fang and Yuke Zhu and Animesh Garg and Andrey Kurenkov and Viraj Mehta and Li Fei-Fei and Silvio Savarese"
      }
    ],
    "mDNhPjAAAAAJ": [
      {
        "title": "Vizwiz: nearly real-time answers to visual questions",
        "abstract": "The lack of access to visual information like text labels, icons, and colors can cause frustration and decrease independence for blind people. Current access technology uses automatic approaches to address some problems in this space, but the technology is error-prone, limited in scope, and quite expensive. In this paper, we introduce VizWiz, a talking application for mobile phones that offers a new alternative to answering visual questions in nearly real-time - asking multiple people on the web. To support answering questions quickly, we introduce a general approach for intelligently recruiting human workers in advance called quikTurkit so that workers are available when new questions arrive. A field deployment with 11 blind participants illustrates that blind people can effectively use VizWiz to cheaply answer questions in their everyday lives, highlighting issues that automatic approaches will need to address to …",
        "year": 2010,
        "authors": "Jeffrey P Bigham and Chandrika Jayant and Hanjie Ji and Greg Little and Andrew Miller and Robert C Miller and Robin Miller and Aubrey Tatarowicz and Brandyn White and Samual White and Tom Yeh"
      },
      {
        "title": "Photo-based mobile deixis system and related techniques",
        "abstract": "(51) Int. Cl. A mobile deixis device includes a camera to capture an image H04N 5/225(2006.01) and a wireless handheld device, coupled to the camera and to (52) US Cl.................................................... 348/2O7. 1 a wireless network, to communicate the image with existing (58) Field of Classification Search.............. 348/207.1; databases to find similar images. The mobile deixis device 382/305, 190, 165; 455/456.1, 457 further includes a processor, coupled to the device, to process See application file for complete search history. found database records related to similarimages and a display (56) Ref Cited to view found database records that include webpages includ eerees e",
        "year": 2011,
        "authors": "Trevor J Darrell and Tom Yeh and Konrad Tollmar"
      },
      {
        "title": "Sikuli: using GUI screenshots for search and automation",
        "abstract": "We present Sikuli, a visual approach to search and automation of graphical user interfaces using screenshots. Sikuli allows users to take a screenshot of a GUI element (such as a toolbar button, icon, or dialog box) and query a help system using the screenshot instead of the element's name. Sikuli also provides a visual scripting API for automating GUI interactions, using screenshot patterns to direct mouse and keyboard events. We report a web-based user study showing that searching by screenshot is easy to learn and faster to specify than keywords. We also demonstrate several automation tasks suitable for visual scripting, such as map navigation and bus tracking, and show how visual scripting can improve interactive help systems previously proposed in the literature.",
        "year": 2009,
        "authors": "Tom Yeh and Tsung-Hsiang Chang and Robert C Miller"
      }
    ],
    "LfcroyAAAAAJ": [
      {
        "title": "Recurrent neural networks for multivariate time series with missing values",
        "abstract": "Multivariate time series data in practical applications, such as health care, geoscience, and biology, are characterized by a variety of missing values. In time series prediction and other related tasks, it has been noted that missing values and their missing patterns are often correlated with the target labels, a.k.a., informative missingness. There is very limited work on exploiting the missing patterns for effective imputation and improving prediction performance. In this paper, we develop novel deep learning models, namely GRU-D, as one of the early attempts. GRU-D is based on Gated Recurrent Unit (GRU), a state-of-the-art recurrent neural network. It takes two representations of missing patterns, i.e., masking and time interval, and effectively incorporates them into a deep model architecture so that it not only captures the long-term temporal dependencies in time series, but also utilizes the missing patterns to achieve …",
        "year": 2018,
        "authors": "Zhengping Che and Sanjay Purushotham and Kyunghyun Cho and David Sontag and Yan Liu"
      },
      {
        "title": "Character-aware neural language models",
        "abstract": "We describe a simple neural language model that relies only on character-level inputs. Predictions are still made at the word-level. Our model employs a convolutional neural network (CNN) and a highway net work over characters, whose output is given to a long short-term memory (LSTM) recurrent neural network language model (RNN-LM). On the English Penn Treebank the model is on par with the existing state-of-the-art despite having 60% fewer parameters. On languages with rich morphology (Arabic, Czech, French, German, Spanish, Russian), the model outperforms word-level/morpheme-level LSTM baselines, again with fewer parameters. The results suggest that on many languages, character inputs are sufficient for language modeling. Analysis of word representations obtained from the character composition part of the model reveals that the model is able to encode, from characters only, both semantic and orthographic information.",
        "year": 2016,
        "authors": "Yoon Kim and Yacine Jernite and David Sontag and Alexander M Rush"
      },
      {
        "title": "Estimating individual treatment effect: generalization bounds and algorithms",
        "abstract": "There is intense interest in applying machine learning to problems of causal inference in fields such as healthcare, economics and education. In particular, individual-level causal inference has important applications such as precision medicine. We give a new theoretical analysis and family of algorithms for predicting individual treatment effect (ITE) from observational data, under the assumption known as strong ignorability. The algorithms learn a “balanced” representation such that the induced treated and control distributions look similar, and we give a novel and intuitive generalization-error bound showing the expected ITE estimation error of a representation is bounded by a sum of the standard generalization-error of that representation and the distance between the treated and control distributions induced by the representation. We use Integral Probability Metrics to measure distances between distributions, deriving explicit bounds for the Wasserstein and Maximum Mean Discrepancy (MMD) distances. Experiments on real and simulated data show the new algorithms match or outperform the state-of-the-art.",
        "year": 2017,
        "authors": "Uri Shalit and Fredrik Johansson and David Sontag"
      }
    ],
    "yE4WT_0AAAAJ": [
      {
        "title": "A survey on deep learning and its applications",
        "abstract": "Deep learning, a branch of machine learning, is a frontier for artificial intelligence, aiming to be closer to its primary goal—artificial intelligence. This paper mainly adopts the summary and the induction methods of deep learning. Firstly, it introduces the global development and the current situation of deep learning. Secondly, it describes the structural principle, the characteristics, and some kinds of classic models of deep learning, such as stacked auto encoder, deep belief network, deep Boltzmann machine, and convolutional neural network. Thirdly, it presents the latest developments and applications of deep learning in many fields such as speech processing, computer vision, natural language processing, and medical applications. Finally, it puts forward the problems and the future research directions of deep learning.",
        "year": 2021,
        "authors": "Shi Dong and Ping Wang and Khushnood Abbas"
      },
      {
        "title": "A Survey on Distributed Denial of Service (DDoS) Attacks in SDN and Cloud Computing Environments",
        "abstract": "Recently, software defined networks (SDNs) and cloud computing have been widely adopted by researchers and industry. However, widespread acceptance of these novel networking paradigms has been hampered by the security threats. Advances in the processing technologies have helped attackers in increasing the attacks too, for instance, the development of Denial of Service (DoS) attacks to distributed DoS (DDoS) attacks which are seldom identified by conventional firewalls. In this paper, we present the state of art of the DDoS attacks in SDN and cloud computing scenarios. Especially, we focus on the analysis of SDN and cloud computing architecture. Besides, we also overview the research works and open problems in identifying and tackling the DDoS attacks.",
        "year": 2019,
        "authors": "Shi Dong and Khushnood Abbas and Raj Jain"
      },
      {
        "title": "DDoS attack detection method based on improved KNN with the degree of DDoS attack in softwaredefined networks",
        "abstract": "The Distributed Denial of Service (DDoS) attack has seriously impaired network availability for decades and still there is no effective defense mechanism against it. However, the emerging Software Defined Networking (SDN) provides a new way to reconsider the defense against DDoS attacks. In this paper, we propose two methods to detect the DDoS attack in SDN. One method adopts the degree of DDoS attack to identify the DDoS attack. The other method uses the improved K-Nearest Neighbors (KNN) algorithm based on Machine Learning (ML) to discover the DDoS attack. The results of the theoretical analysis and the experimental results on datasets show that our proposed methods can better detect the DDoS attack compared with other methods.",
        "year": 2019,
        "authors": "Mudar Sarum Shi Dong"
      }
    ],
    "8O8MQEUAAAAJ": [
      {
        "title": "Universally optimal distribution of points on spheres",
        "abstract": "We study configurations of points on the unit sphere that minimize potential energy for a broad class of potential functions (viewed as functions of the squared Euclidean distance between points). Call a configuration sharp if there are  distances between distinct points in it and it is a spherical -design. We prove that every sharp configuration minimizes potential energy for all completely monotonic potential functions. Examples include the minimal vectors of the  and Leech lattices. We also prove the same result for the vertices of the -cell, which do not form a sharp configuration. For most known cases, we prove that they are the unique global minima for energy, as long as the potential function is strictly completely monotonic. For certain potential functions, some of these configurations were previously analyzed by Yudin, Kolushov, and Andreev; we build on their techniques. We also generalize our results …",
        "year": 2007,
        "authors": "Henry Cohn and Abhinav Kumar"
      },
      {
        "title": "The sphere packing problem in dimension 24",
        "abstract": "Computer code for verifying the calculations in this paper is available for download here.",
        "year": 2017,
        "authors": "Henry Cohn and Abhinav Kumar and Stephen D Miller and Danylo Radchenko and Maryna Viazovska"
      },
      {
        "title": "New upper bounds on sphere packings I",
        "abstract": "We develop an analogue for sphere packing of the linear programming bounds for error-correcting codes, and use it to prove upper bounds for the density of sphere packings, which are the best bounds known at least for dimensions 4 through 36. We conjecture that our approach can be used to solve the sphere packing problem in dimensions 8 and 24.",
        "year": 2003,
        "authors": "Henry Cohn and Noam Elkies"
      }
    ],
    "Zldo9CAAAAAJ": [
      {
        "title": "Revisiting distributed synchronous SGD",
        "abstract": "Distributed training of deep learning models on large-scale training data is typically conducted with asynchronous stochastic optimization to maximize the rate of updates, at the cost of additional noise introduced from asynchrony. In contrast, the synchronous approach is often thought to be impractical due to idle time wasted on waiting for straggling workers. We revisit these conventional beliefs in this paper, and examine the weaknesses of both approaches. We demonstrate that a third approach, synchronous optimization with backup workers, can avoid asynchronous noise while mitigating for the worst stragglers. Our approach is empirically validated and shown to converge faster and to better test accuracies.",
        "year": 2016,
        "authors": "Jianmin Chen and Xinghao Pan and Rajat Monga and Samy Bengio and Rafal Jozefowicz"
      },
      {
        "title": "Perturbed iterate analysis for asynchronous stochastic optimization",
        "abstract": "We introduce and analyze stochastic optimization methods where the input to each update is perturbed by bounded noise. We show that this framework forms the basis of a unified approach to analyzing asynchronous implementations of stochastic optimization algorithms, by viewing them as  serial methods operating on noisy inputs. Using our perturbed iterate framework, we provide new analyses of the Hogwild! algorithm and asynchronous stochastic coordinate descent that are simpler than earlier analyses, remove many assumptions of previous models, and in some cases yield improved upper bounds on the convergence rates. We proceed to apply our framework to develop and analyze KroMagnon: a novel, parallel, sparse stochastic variance-reduced gradient (SVRG) algorithm. We demonstrate experimentally on a 16-core machine that the sparse and parallel version of SVRG is in some cases more than …",
        "year": 2017,
        "authors": "Horia Mania and Xinghao Pan and Dimitris Papailiopoulos and Benjamin Recht and Kannan Ramchandran and Michael I Jordan"
      },
      {
        "title": "MLI: An API for distributed machine learning",
        "abstract": "MLI is an Application Programming Interface designed to address the challenges of building Machine Learning algorithms in a distributed setting based on data-centric computing. Its primary goal is to simplify the development of high-performance, scalable, distributed algorithms. Our initial results show that, relative to existing systems, this interface can be used to build distributed implementations of a wide variety of common Machine Learning algorithms with minimal complexity and highly competitive performance and scalability.",
        "year": 2013,
        "authors": "Evan R Sparks and Ameet Talwalkar and Virginia Smith and Jey Kottalam and Xinghao Pan and Joseph Gonzalez and Michael J Franklin and Michael I Jordan and Tim Kraska"
      }
    ],
    "i7V1kJgAAAAJ": [
      {
        "title": "Politeness transfer: A tag and generate approach",
        "abstract": "This paper introduces a new task of politeness transfer which involves converting non-polite sentences to polite sentences while preserving the meaning. We also provide a dataset of more than 1.39 instances automatically labeled for politeness to encourage benchmark evaluations on this new task. We design a tag and generate pipeline that identifies stylistic attributes and subsequently generates a sentence in the target style while preserving most of the source content. For politeness as well as five other transfer tasks, our model outperforms the state-of-the-art methods on automatic metrics for content preservation, with a comparable or better performance on style transfer accuracy. Additionally, our model surpasses existing methods on human evaluations for grammaticality, meaning preservation and transfer accuracy across all the six style transfer tasks. The data and code is located at https://github.com/tag-and-generate.",
        "year": 2020,
        "authors": "Aman Madaan and Amrith Setlur and Tanmay Parekh and Barnabas Poczos and Graham Neubig and Yiming Yang and Ruslan Salakhutdinov and Alan W Black and Shrimai Prabhumoye"
      },
      {
        "title": "Rewarding progress: Scaling automated process verifiers for llm reasoning",
        "abstract": "A promising approach for improving reasoning in large language models is to use process reward models (PRMs). PRMs provide feedback at each step of a multi-step reasoning trace, potentially improving credit assignment over outcome reward models (ORMs) that only provide feedback at the final step. However, collecting dense, per-step human labels is not scalable, and training PRMs from automatically-labeled data has thus far led to limited gains. To improve a base policy by running search against a PRM or using it as dense rewards for reinforcement learning (RL), we ask: \"How should we design process rewards?\". Our key insight is that, to be effective, the process reward for a step should measure progress: a change in the likelihood of producing a correct response in the future, before and after taking the step, corresponding to the notion of step-level advantages in RL. Crucially, this progress should be measured under a prover policy distinct from the base policy. We theoretically characterize the set of good provers and our results show that optimizing process rewards from such provers improves exploration during test-time search and online RL. In fact, our characterization shows that weak prover policies can substantially improve a stronger base policy, which we also observe empirically. We validate our claims by training process advantage verifiers (PAVs) to predict progress under such provers, and show that compared to ORMs, test-time search against PAVs is  more accurate, and  more compute-efficient. Online RL with dense rewards from PAVs enables one of the first results with  gain in sample efficiency, and …",
        "year": 2024,
        "authors": "Amrith Setlur and Chirag Nagpal and Adam Fisch and Xinyang Geng and Jacob Eisenstein and Rishabh Agarwal and Alekh Agarwal and Jonathan Berant and Aviral Kumar"
      },
      {
        "title": "Explaining the efficacy of counterfactually augmented data",
        "abstract": "In attempts to produce ML models less reliant on spurious patterns in NLP datasets, researchers have recently proposed curating counterfactually augmented data (CAD) via a human-in-the-loop process in which given some documents and their (initial) labels, humans must revise the text to make a counterfactual label applicable. Importantly, edits that are not necessary to flip the applicable label are prohibited. Models trained on the augmented data appear, empirically, to rely less on semantically irrelevant words and to generalize better out of domain. While this work draws loosely on causal thinking, the underlying causal model (even at an abstract level) and the principles underlying the observed out-of-domain improvements remain unclear. In this paper, we introduce a toy analog based on linear Gaussian models, observing interesting relationships between causal models, measurement noise, out-of-domain generalization, and reliance on spurious signals. Our analysis provides some insights that help to explain the efficacy of CAD. Moreover, we develop the hypothesis that while adding noise to causal features should degrade both in-domain and out-of-domain performance, adding noise to non-causal features should lead to relative improvements in out-of-domain performance. This idea inspires a speculative test for determining whether a feature attribution technique has identified the causal spans. If adding noise (e.g., by random word flips) to the highlighted spans degrades both in-domain and out-of-domain performance on a battery of challenge datasets, but adding noise to the complement gives improvements out-of-domain, it …",
        "year": 2020,
        "authors": "Divyansh Kaushik and Amrith Setlur and Eduard Hovy and Zachary C Lipton"
      }
    ],
    "zp8V7ZMAAAAJ": [
      {
        "title": "Progprompt: Generating situated robot task plans using large language models",
        "abstract": "Task planning can require defining myriad domain knowledge about the world in which a robot needs to act. To ameliorate that effort, large language models (LLMs) can be used to score potential next actions during task planning, and even generate action sequences directly, given an instruction in natural language with no additional domain information. However, such methods either require enumerating all possible next steps for scoring, or generate free-form text that may contain actions not possible on a given robot in its current context. We present a programmatic LLM prompt structure that enables plan generation functional across situated environments, robot capabilities, and tasks. Our key insight is to prompt the LLM with program-like specifications of the available actions and objects in an environment, as well as with example programs that can be executed. We make concrete recommendations about …",
        "year": 2023,
        "authors": "Ishika Singh and Valts Blukis and Arsalan Mousavian and Ankit Goyal and Danfei Xu and Jonathan Tremblay and Dieter Fox and Jesse Thomason and Animesh Garg"
      },
      {
        "title": "Making sense of vision and touch: Self-supervised learning of multimodal representations for contact-rich tasks",
        "abstract": "Contact-rich manipulation tasks in unstructured environments often require both haptic and visual feedback. However, it is non-trivial to manually design a robot controller that combines modalities with very different characteristics. While deep reinforcement learning has shown success in learning control policies for high-dimensional inputs, these algorithms are generally intractable to deploy on real robots due to sample complexity. We use self-supervision to learn a compact and multimodal representation of our sensory inputs, which can then be used to improve the sample efficiency of our policy learning. We evaluate our method on a peg insertion task, generalizing over different geometry, configurations, and clearances, while being robust to external perturbations. We present results in simulation and on a real robot.",
        "year": 2019,
        "authors": "Michelle A Lee and Yuke Zhu and Krishnan Srinivasan and Parth Shah and Silvio Savarese and Li Fei-Fei and Animesh Garg and Jeannette Bohg"
      }
    ],
    "dYt8FGcAAAAJ": [
      {
        "title": "Entropy rate estimation for Markov chains with large state space",
        "abstract": "Entropy estimation is one of the prototypical problems in distribution property testing. To consistently estimate the Shannon entropy of a distribution on  elements with independent samples, the optimal sample complexity scales sublinearly with  as  as shown by Valiant and Valiant\\cite {Valiant--Valiant2011}. Extending the theory and algorithms for entropy estimation to dependent data, this paper considers the problem of estimating the entropy rate of a stationary reversible Markov chain with  states from a sample path of  observations. We show that\\begin {itemize}\\item Provided the Markov chain mixes not too slowly,\\textit {ie}, the relaxation time is at most , consistent estimation is achievable when .\\item Provided the Markov chain has some slight dependency,\\textit {ie}, the relaxation time is at least , consistent estimation is impossible when .\\end {itemize} Under both assumptions, the optimal estimation accuracy is shown to be . In comparison, the empirical entropy rate requires at least  samples to be consistent, even when the Markov chain is memoryless. In addition to synthetic experiments, we also apply the estimators that achieve the optimal sample complexity to estimate the entropy rate of the English language in the Penn Treebank and the Google One Billion Words corpora, which provides a natural benchmark for language modeling and relates it directly to the widely used perplexity measure.",
        "year": 2018,
        "authors": "Yanjun Han and Jiantao Jiao and Chuan-Zheng Lee and Tsachy Weissman and Yihong Wu and Tiancheng Yu"
      },
      {
        "title": "Over-the-air statistical estimation",
        "abstract": "We study schemes and lower bounds for distributed minimax statistical estimation over a Gaussian multiple-access channel (MAC) under squared error loss. Our framework combines statistical estimation and wireless communication. First, we develop “analog” joint estimation-communication schemes that exploit the superposition property of the Gaussian MAC. We characterize their risk in terms of the number of nodes and dimension of the parameter space. Then, we derive information-theoretic lower bounds on the minimax risk of any estimation scheme that is restricted to communicate the samples over a given number of uses of the channel. This shows that the risk achieved by our proposed schemes is within a logarithmic factor of these lower bounds. We compare both achievability and lower bound results to previous “digital” lower bounds, where nodes transmit errorless bits at the Shannon capacity of the …",
        "year": 2021,
        "authors": "Chuan-Zheng Lee and Leighton Pate Barnes and Ayfer Özgür"
      },
      {
        "title": "Lower bounds for over-the-air statistical estimation",
        "abstract": "We study lower bounds for minimax statistical estimation over a Gaussian multiple-access channel (MAC) under squared error loss, using techniques from both statistical estimation and information theory. We characterize these bounds in terms of the number of nodes  and the dimension of the parameter space , showing that the risk must be . This is within a  factor of previous analog achievability results. While lower bounds for minimax statistical estimation have been previously studied under quantization constraints that abstract the physical layer as noiseless bit pipes, to our knowledge our paper provides the first lower bounds for statistical estimation over noisy multi-user channels. This adds to a body of works showing how analog schemes that consider the physical layer jointly with the estimation scheme, can outperform digital schemes that separate the two with an abstraction layer.",
        "year": 2021,
        "authors": "Chuan-Zheng Lee and Leighton Pate Barnes and Ayfer Özgür"
      }
    ],
    "-5_ksIkAAAAJ": [
      {
        "title": "Quadrotor helicopter flight dynamics and control: Theory and experiment",
        "abstract": "Quadrotor helicopters are emerging as a popular platform for unmanned aerial vehicle (UAV) research, due to the simplicity of their construction and maintenance, their ability to hover, and their vertical take off and landing (VTOL) capability. Current designs have often considered only nominal operating conditions for vehicle control design. This work seeks to address issues that arise when deviating significantly from the hover flight regime. Aided by well established research for helicopter flight control, three separate aerodynamic effects are investigated as they pertain to quadrotor flight, due to vehicular velocity, angle of attack, and airframe design. They cause moments that affect attitude control, and thrust variation that affects altitude control. Where possible, a theoretical development is first presented, and is then validated through both thrust test stand measurements and vehicle flight tests using the Stanford …",
        "year": 2007,
        "authors": "Gabriel Hoffmann and Haomiao Huang and Steven Waslander and Claire Tomlin"
      },
      {
        "title": "Conflict resolution for air traffic management: A study in multiagent hybrid systems",
        "abstract": "Air traffic management (ATM) of the future allows for the possibility of free flight, in which aircraft choose their own optimal routes, altitudes, and velocities. The safe resolution of trajectory conflicts between aircraft is necessary to the success of such a distributed control system. In this paper, we present a method to synthesize provably safe conflict resolution manoeuvres. The method models the aircraft and the manoeuvre as a hybrid control system and calculates the maximal set of safe initial conditions for each aircraft so that separation is assured in the presence of uncertainties in the actions of the other aircraft. Examples of manoeuvres using both speed and heading changes are worked out in detail.",
        "year": 2002,
        "authors": "Claire Tomlin and George J Pappas and Shankar Sastry"
      },
      {
        "title": "A time-dependent Hamilton-Jacobi formulation of reachable sets for continuous dynamic games",
        "abstract": "We describe and implement an algorithm for computing the set of reachable states of a continuous dynamic game. The algorithm is based on a proof that the reachable set is the zero sublevel set of the viscosity solution of a particular time-dependent Hamilton-Jacobi-Isaacs partial differential equation. While alternative techniques for computing the reachable set have been proposed, the differential game formulation allows treatment of nonlinear systems with inputs and uncertain parameters. Because the time-dependent equation's solution is continuous and defined throughout the state space, methods from the level set literature can be used to generate more accurate approximations than are possible for formulations with potentially discontinuous solutions. A numerical implementation of our formulation is described and has been released on the web. Its correctness is verified through a two vehicle, three …",
        "year": 2005,
        "authors": "Ian M Mitchell and Alexandre M Bayen and Claire J Tomlin"
      }
    ],
    "Ci-_QYIAAAAJ": [
      {
        "title": "End-to-end recovery of human shape and pose",
        "abstract": "We describe Human Mesh Recovery (HMR), an end-to-end framework for reconstructing a full 3D mesh of a human body from a single RGB image. In contrast to most current methods that compute 2D or 3D joint locations, we produce a richer and more useful mesh representation that is parameterized by shape and 3D joint angles. The main objective is to minimize the reprojection loss of keypoints, which allows our model to be trained using in-the-wild images that only have ground truth 2D annotations. However, the reprojection loss alone is highly underconstrained. In this work we address this problem by introducing an adversary trained to tell whether human body shape and pose are real or not using a large database of 3D human meshes. We show that HMR can be trained with and without using any paired 2D-to-3D supervision. We do not rely on intermediate 2D keypoint detections and infer 3D pose and shape parameters directly from image pixels. Our model runs in real-time given a bounding box containing the person. We demonstrate our approach on various images in-the-wild and out-perform previous optimization-based methods that output 3D meshes and show competitive results on tasks such as 3D joint location estimation and part segmentation.",
        "year": 2018,
        "authors": "Angjoo Kanazawa and Michael J Black and David W Jacobs and Jitendra Malik"
      },
      {
        "title": "Keep it SMPL: Automatic estimation of 3D human pose and shape from a single image",
        "abstract": "We describe the first method to automatically estimate the 3D pose of the human body as well as its 3D shape from a single unconstrained image. We estimate a full 3D mesh and show that 2D joints alone carry a surprising amount of information about body shape. The problem is challenging because of the complexity of the human body, articulation, occlusion, clothing, lighting, and the inherent ambiguity in inferring 3D from 2D. To solve this, we first use a recently published CNN-based method, DeepCut, to predict (bottom-up) the 2D body joint locations. We then fit (top-down) a recently published statistical body shape model, called SMPL, to the 2D joints. We do so by minimizing an objective function that penalizes the error between the projected 3D model joints and detected 2D joints. Because SMPL captures correlations in human shape across the population, we are able to robustly fit it to very little …",
        "year": 2016,
        "authors": "Federica Bogo and Angjoo Kanazawa and Christoph Lassner and Peter Gehler and Javier Romero and Michael J Black"
      },
      {
        "title": "pixelnerf: Neural radiance fields from one or few images",
        "abstract": "We propose pixelNeRF, a learning framework that predicts a continuous neural scene representation conditioned on one or few input images. The existing approach for constructing neural radiance fields (NeRFs) involves optimizing the representation to every scene independently, requiring many calibrated views and significant compute time. We take a step towards resolving these shortcomings by introducing an architecture that conditions a NeRF on image inputs in a fully convolutional manner. This allows the network to be trained across multiple scenes to learn a scene prior, allowing it to perform novel view synthesis in a feed-forward manner from a sparse set of views (as few as one). Leveraging the volume rendering approach of NeRF, our model can be trained directly from images with no explicit 3D supervision. We conduct extensive experiments on ShapeNet benchmarks for single image novel view synthesis tasks under category specific and category agnostic settings. We further demonstrate the flexibility of pixelNeRF by demonstrating it on multi-object ShapeNet scenes as well as real scenes from the DTU dataset. In all cases, pixelNeRF outperforms current state-of-the-art baselines for novel view synthesis and single image 3D reconstruction.",
        "year": 2021,
        "authors": "Alex Yu and Vickie Ye and Matthew Tancik and Angjoo Kanazawa"
      }
    ],
    "DxoenfgAAAAJ": [
      {
        "title": "Natural questions: a benchmark for question answering research",
        "abstract": "We present the Natural Questions corpus, a question answering data set. Questions                     consist of real anonymized, aggregated queries issued to the Google search                     engine. An annotator is presented with a question along with a Wikipedia page                     from the top 5 search results, and annotates a long answer (typically a                     paragraph) and a short answer (one or more entities) if present on the page, or                     marks null if no long/short answer is present. The public release consists of                     307,373 training examples with single annotations; 7,830 examples with 5-way                     annotations for development data; and a further 7,842 examples with 5-way                     annotated sequestered as test data. We present experiments validating quality of                     the data. We also describe analysis of 25-way annotations on 302 examples,                     giving insights into …",
        "year": 2019,
        "authors": "Tom Kwiatkowski and Jennimaria Palomaki and Olivia Redfield and Michael Collins and Ankur Parikh and Chris Alberti and Danielle Epstein and Illia Polosukhin and Jacob Devlin and Kenton Lee and Kristina Toutanova and Llion Jones and Matthew Kelcey and Ming-Wei Chang and Andrew M Dai and Jakob Uszkoreit and Quoc Le and Slav Petrov"
      },
      {
        "title": "Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms",
        "abstract": "We describe new algorithms for training tagging models, as an alternative to maximum-entropy models or conditional random fields (CRFs). The algorithms rely on Viterbi decoding of training examples, combined with simple additive updates. We describe theory justifying the algorithms through a modification of the proof of convergence of the perceptron algorithm for classification problems. We give experimental results on part-of-speech tagging and base noun phrase chunking, in both cases showing improvements over results for a maximum-entropy tagger.",
        "year": 2002,
        "authors": "Michael Collins"
      },
      {
        "title": "Head-driven statistical models for natural language parsing",
        "abstract": "This article describes three statistical models for natural language parsing. The models extend methods from probabilistic context-free grammars to lexicalized grammars, leading to approaches in which a parse tree is represented as the sequence of decisions corresponding to a head-centered, top-down derivation of the tree. Independence assumptions then lead to parameters that encode the X-bar schema, subcategorization, ordering of complements, placement of adjuncts, bigram lexical dependencies, wh-movement, and preferences for close attachment. All of these preferences are expressed by probabilities conditioned on lexical heads. The models are evaluated on the Penn Wall Street Journal Treebank, showing that their accuracy is competitive with other models in the literature. To gain a better understanding of the models, we also give results on different constituent types, as well as a breakdown of …",
        "year": 2003,
        "authors": "Michael Collins"
      }
    ],
    "_DNzXTcAAAAJ": [
      {
        "title": "Robotic learning of haptic adjectives through physical interaction",
        "abstract": "To perform useful tasks in everyday human environments, robots must be able to both understand and communicate the sensations they experience during haptic interactions with objects. Toward this goal, we augmented the Willow Garage PR2 robot with a pair of SynTouch BioTac sensors to capture rich tactile signals during the execution of four exploratory procedures on 60 household objects. In a parallel experiment, human subjects blindly touched the same objects and selected binary haptic adjectives from a predetermined set of 25 labels. We developed several machine-learning algorithms to discover the meaning of each adjective from the robot’s sensory data. The most successful algorithms were those that intelligently combine static and dynamic components of the data recorded during all four exploratory procedures. The best of our approaches produced an average adjective classification F 1 score of 0 …",
        "year": 2015,
        "authors": "Vivian Chu and Ian McMahon and Lorenzo Riano and Craig G McDonald and Qin He and Jorge Martinez Perez-Tejada and Michael Arrigo and Trevor Darrell and Katherine J Kuchenbecker"
      },
      {
        "title": "Using robotic exploratory procedures to learn the meaning of haptic adjectives",
        "abstract": "Delivering on the promise of real-world robotics will require robots that can communicate with humans through natural language by learning new words and concepts through their daily experiences. Our research strives to create a robot that can learn the meaning of haptic adjectives by directly touching objects. By equipping the PR2 humanoid robot with state-of-the-art biomimetic tactile sensors that measure temperature, pressure, and fingertip deformations, we created a platform uniquely capable of feeling the physical properties of everyday objects. The robot used five exploratory procedures to touch 51 objects that were annotated by human participants with 34 binary adjective labels. We present both static and dynamic learning methods to discover the meaning of these adjectives from the labeled objects, achieving average F1 scores of 0.57 and 0.79 on a set of eight previously unfelt items.",
        "year": 2013,
        "authors": "Vivian Chu and Ian McMahon and Lorenzo Riano and Craig G McDonald and Qin He and Jorge Martinez Perez-Tejada and Michael Arrigo and Naomi Fitter and John C Nappo and Trevor Darrell and Katherine J Kuchenbecker"
      },
      {
        "title": "Systems and methods for information extraction using contextual pattern discovery",
        "abstract": "BACKGROUNDInformation extraction (IE) is a process for analyzing and extracting structured information from unstructured or semi structured text. Typically, IE systems are configured to focus on a specific domain or particular types of events, entities, or relationships. For example, an IE system may be constructed to analyze certain news stories. Such as mergers or criminal activity, financial reports, legal opinions, press releases, and relationships between entities in a series of email messages. IE analysis results may take multiple forms, such as entity identification (eg, persons, corporations, organizations), relationship identification (eg, person-employer, merging companies), and co-reference resolution, which resolves dif ferent identities for a common entity (eg, United States, United States of America, US, America). Many different techniques have been used to analyze text and to particularize IE processes for …",
        "year": 2014,
        "authors": "Sebastian Johannes Blohm and Vivian Yaw-Wen Chu and Ching-Tien Ho and Yunyao Li and Huaiyu Zhu"
      }
    ],
    "yy0UFOwAAAAJ": [
      {
        "title": "Palm-e: An embodied multimodal language model",
        "abstract": "Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.",
        "year": 2023,
        "authors": "Danny Driess and Fei Xia and Mehdi SM Sajjadi and Corey Lynch and Aakanksha Chowdhery and Ayzaan Wahid and Jonathan Tompson and Quan Vuong and Tianhe Yu and Wenlong Huang and Yevgen Chebotar and Pierre Sermanet and Daniel Duckworth and Sergey Levine and Vincent Vanhoucke and Karol Hausman and Marc Toussaint and Klaus Greff and Andy Zeng and Igor Mordatch and Pete Florence"
      },
      {
        "title": "Do as i can, not as i say: Grounding language in robotic affordances",
        "abstract": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model's \"hands and eyes,\" while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally-extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project's website and the video can be found at https …",
        "year": 2022,
        "authors": "Michael Ahn and Anthony Brohan and Noah Brown and Yevgen Chebotar and Omar Cortes and Byron David and Chelsea Finn and Chuyuan Fu and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Daniel Ho and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Eric Jang and Rosario Jauregui Ruano and Kyle Jeffrey and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Kuang-Huei Lee and Sergey Levine and Yao Lu and Linda Luu and Carolina Parada and Peter Pastor and Jornell Quiambao and Kanishka Rao and Jarek Rettinghouse and Diego Reyes and Pierre Sermanet and Nicolas Sievers and Clayton Tan and Alexander Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Mengyuan Yan and Andy Zeng"
      },
      {
        "title": "Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning",
        "abstract": "Meta-reinforcement learning algorithms can enable robots to acquire new skills much more quickly, by leveraging prior experience to learn how to learn. However, much of the current research on meta-reinforcement learning focuses on task distributions that are very narrow. For example, a commonly used meta-reinforcement learning benchmark uses different running velocities for a simulated robot as different tasks. When policies are meta-trained on such narrow task distributions, they cannot possibly generalize to more quickly acquire entirely new tasks. Therefore, if the aim of these methods is enable faster acquisition of entirely new behaviors, we must evaluate them on task distributions that are sufficiently broad to enable generalization to new behaviors. In this paper, we propose an open-source simulated benchmark for meta-reinforcement learning and multitask learning consisting of 50 distinct robotic manipulation tasks. Our aim is to make it possible to develop algorithms that generalize to accelerate the acquisition of entirely new, held-out tasks. We evaluate 6 state-of-the-art meta-reinforcement learning and multi-task learning algorithms on these tasks. Surprisingly, while each task and its variations (eg, with different object positions) can be learned with reasonable success, these algorithms struggle to learn with multiple tasks at the same time, even with as few as ten distinct training tasks. Our analysis and open-source environments pave the way for future research in multi-task learning and meta-learning that can enable meaningful generalization, thereby unlocking the full potential of these methods. 1.",
        "year": 2020,
        "authors": "Tianhe Yu and Deirdre Quillen and Zhanpeng He and Ryan Julian and Karol Hausman and Chelsea Finn and Sergey Levine"
      }
    ],
    "wtRVnsYAAAAJ": [
      {
        "title": "Unsupervised pixel-level domain adaptation with generative adversarial networks",
        "abstract": "Collecting well-annotated image datasets to train modern machine learning algorithms is prohibitively expensive for many tasks. One appealing alternative is rendering synthetic data where ground-truth annotations are generated automatically. Unfortunately, models trained purely on rendered images fail to generalize to real images. To address this shortcoming, prior work introduced unsupervised domain adaptation algorithms that have tried to either map representations between the two domains, or learn to extract features that are domain-invariant. In this work, we approach the problem in a new light by learning in an unsupervised manner a transformation in the pixel space from one domain to the other. Our generative adversarial network (GAN)-based method adapts source-domain images to appear as if drawn from the target domain. Our approach not only produces plausible samples, but also outperforms the state-of-the-art on a number of unsupervised domain adaptation scenarios by large margins. Finally, we demonstrate that the adaptation process generalizes to object classes unseen during training.",
        "year": 2017,
        "authors": "Konstantinos Bousmalis and Nathan Silberman and David Dohan and Dumitru Erhan and Dilip Krishnan"
      },
      {
        "title": "Domain separation networks",
        "abstract": "The cost of large scale data collection and annotation often makes the application of machine learning algorithms to new tasks or datasets prohibitively expensive. One approach circumventing this cost is training models on synthetic data where annotations are provided automatically. Despite their appeal, such models often fail to generalize from synthetic to real images, necessitating domain adaptation algorithms to manipulate these models before they can be successfully applied. Existing approaches focus either on mapping representations from one domain to the other, or on learning to extract features that are invariant to the domain from which they were extracted. However, by focusing only on creating a mapping or shared representation between the two domains, they ignore the individual characteristics of each domain. We hypothesize that explicitly modeling what is unique to each domain can improve a model's ability to extract domain-invariant features. Inspired by work on private-shared component analysis, we explicitly learn to extract image representations that are partitioned into two subspaces: one component which is private to each domain and one which is shared across domains. Our model is trained to not only perform the task we care about in the source domain, but also to use the partitioned representation to reconstruct the images from both domains. Our novel architecture results in a model that outperforms the state-of-the-art on a range of unsupervised domain adaptation scenarios and additionally produces visualizations of the private and shared representations enabling interpretation of the domain adaptation process.",
        "year": 2016,
        "authors": "Konstantinos Bousmalis and George Trigeorgis and Nathan Silberman and Dilip Krishnan and Dumitru Erhan"
      },
      {
        "title": "Using simulation and domain adaptation to improve efficiency of deep robotic grasping",
        "abstract": "Instrumenting and collecting annotated visual grasping datasets to train modern machine learning algorithms can be extremely time-consuming and expensive. An appealing alternative is to use off-the-shelf simulators to render synthetic data for which ground-truth annotations are generated automatically. Unfortunately, models trained purely on simulated data often fail to generalize to the real world. We study how randomized simulated environments and domain adaptation methods can be extended to train a grasping system to grasp novel objects from raw monocular RGB images. We extensively evaluate our approaches with a total of more than 25,000 physical test grasps, studying a range of simulation conditions and domain adaptation methods, including a novel extension of pixel-level domain adaptation that we term the GraspGAN. We show that, by using synthetic data and domain adaptation, we are able to …",
        "year": 2018,
        "authors": "Konstantinos Bousmalis and Alex Irpan and Paul Wohlhart and Yunfei Bai and Matthew Kelcey and Mrinal Kalakrishnan and Laura Downs and Julian Ibarz and Peter Pastor and Kurt Konolige and Sergey Levine and Vincent Vanhoucke"
      }
    ]
  },
  "author_levels": {
    "input_authors": [
      "B96GkdgAAAAJ",
      "vtwH6GkAAAAJ",
      "a_dbdxAAAAAJ",
      "B847xq8AAAAJ",
      "_pv1sEcAAAAJ",
      "UgHB5oAAAAAJ",
      "84WzBlYAAAAJ",
      "_tNCgxMAAAAJ",
      "aO8KpGcAAAAJ",
      "8R35rCwAAAAJ",
      "a4unsk4AAAAJ",
      "bh-uRFMAAAAJ",
      "Wi25oKoAAAAJ",
      "LKv32bgAAAAJ"
    ],
    "direct_co_authors": [
      "iYN86KEAAAAJ",
      "qTCXoLQAAAAJ",
      "Pk-959EAAAAJ",
      "S8D-DqEAAAAJ",
      "Kzj3HC8AAAAJ",
      "1FrpQaQAAAAJ",
      "jQl9RtkAAAAJ",
      "zvz6LIYAAAAJ",
      "okcbLqoAAAAJ",
      "X22nUYgAAAAJ",
      "nGUcGrYAAAAJ",
      "fkGi-JMAAAAJ",
      "jH_7A6gAAAAJ",
      "Sbpra_AAAAAJ",
      "65FCPpwAAAAJ",
      "wfGiqXEAAAAJ",
      "p0sQC6sAAAAJ",
      "QCBdB7AAAAAJ",
      "zP0S_ikAAAAJ",
      "U89FHq4AAAAJ",
      "gRxBNZoAAAAJ",
      "a3K-f2YAAAAJ",
      "bo0P2qYAAAAJ",
      "FWp7728AAAAJ",
      "5bc-9A4AAAAJ",
      "osxb7aMAAAAJ",
      "nTiSnwUAAAAJ",
      "sgsLkM0AAAAJ",
      "BtwmZfQAAAAJ",
      "euc0GX4AAAAJ",
      "uA0kNBUAAAAJ",
      "jERkdhIAAAAJ",
      "MbF6rTEAAAAJ",
      "o6LlkNMAAAAJ",
      "sPlonWcAAAAJ",
      "krrh6OUAAAAJ",
      "odFQXSYAAAAJ",
      "UfbuDH8AAAAJ",
      "Ch9iRwQAAAAJ",
      "k-nF0qgAAAAJ",
      "ZKRs0oEAAAAJ",
      "KCdL5B0AAAAJ",
      "oAlCitYAAAAJ",
      "E__5Lr0AAAAJ",
      "MaSXNhUAAAAJ",
      "4bl7qAgAAAAJ",
      "fn13u8IAAAAJ",
      "-j0q9B4AAAAJ",
      "oOwNKsAAAAAJ",
      "zBUwaGkAAAAJ",
      "OI7zFmwAAAAJ",
      "0lZoXCUAAAAJ",
      "XqLiBQMAAAAJ",
      "pzw1-J4AAAAJ",
      "y1lVpBEAAAAJ",
      "xRmmtzIAAAAJ",
      "APgaFK0AAAAJ",
      "BsOkXDsAAAAJ",
      "1wLVDP4AAAAJ",
      "5LLV29oAAAAJ",
      "nXBQn7gAAAAJ",
      "4zybTq4AAAAJ",
      "H1vNRiUAAAAJ",
      "jo2C_wkAAAAJ",
      "r3q68rcAAAAJ",
      "mqpjAt4AAAAJ",
      "YLOz1kgAAAAJ",
      "7t4jbPQAAAAJ",
      "grQ_GBgAAAAJ",
      "WX0pI3wAAAAJ",
      "mAo_lUwAAAAJ",
      "WLN3QrAAAAAJ",
      "z76PBfYAAAAJ",
      "QZCU3NkAAAAJ",
      "y-8unsgAAAAJ",
      "n7hxT4oAAAAJ",
      "-S_9ZRcAAAAJ",
      "B96GkdgAAAAJ",
      "e1P1rNkAAAAJ",
      "izZZAegAAAAJ",
      "aOklxsQAAAAJ",
      "xVN3UxYAAAAJ",
      "YYT8-7kAAAAJ",
      "GBQ6w8IAAAAJ",
      "UgHB5oAAAAAJ",
      "wSstCv0AAAAJ",
      "eWRBqsYAAAAJ",
      "d97bGd8AAAAJ",
      "Vb3FLmkAAAAJ",
      "wMjQdBcAAAAJ",
      "NDyEvlQAAAAJ",
      "LKv32bgAAAAJ",
      "nxNkEiYAAAAJ",
      "8C2_ZVsAAAAJ",
      "yABlzrsAAAAJ",
      "PTS2AOgAAAAJ",
      "nABXo3sAAAAJ",
      "Nn990CkAAAAJ",
      "HPoaHyQAAAAJ",
      "1TqAq5AAAAAJ",
      "ygFAcZwAAAAJ",
      "5NGAbT4AAAAJ",
      "mQf5cE0AAAAJ",
      "xMhGYpgAAAAJ",
      "ScoZZPsAAAAJ",
      "NpOg5soAAAAJ",
      "RLvsC94AAAAJ",
      "2X0cwhkAAAAJ",
      "pqP5_PgAAAAJ",
      "5VaXUQsAAAAJ",
      "OFlBL2kAAAAJ",
      "XCZpOcAAAAAJ",
      "FwxfQosAAAAJ",
      "UpZmJI0AAAAJ",
      "Ivot3fkAAAAJ",
      "wVGqmWkAAAAJ",
      "1b2kKWoAAAAJ",
      "xBH73TYAAAAJ",
      "0jSdqoEAAAAJ",
      "I1EvjZsAAAAJ",
      "JwiByPoAAAAJ",
      "7c1B_fIAAAAJ",
      "8jVzL_YAAAAJ",
      "vYougn0AAAAJ",
      "CUlqK5EAAAAJ",
      "qWak04oAAAAJ",
      "bMZFLZ_V4goC",
      "dD7EpwQAAAAJ",
      "kukA0LcAAAAJ",
      "xuLKJboAAAAJ",
      "x-n9rIMAAAAJ",
      "VecEj6kAAAAJ",
      "B7oP0bIAAAAJ",
      "m8m9nD0AAAAJ",
      "VYiRfCwAAAAJ",
      "j_xavDQAAAAJ",
      "55TAOdgAAAAJ",
      "xT19Jc0AAAAJ",
      "vS8b6GwAAAAJ",
      "_vjPh4UAAAAJ",
      "bLUllHEAAAAJ",
      "XP_Hxm4AAAAJ",
      "wCRav7EAAAAJ",
      "dB6ftCcAAAAJ",
      "GR_DsT0AAAAJ",
      "7GSWYLQAAAAJ",
      "SgST3LkAAAAJ",
      "K3QJPdMAAAAJ",
      "ZaJEZpYAAAAJ",
      "on2DUKoAAAAJ",
      "GdOmgYwAAAAJ",
      "FLJ86DwAAAAJ",
      "jIs-Y2gAAAAJ",
      "rTw-pq0AAAAJ",
      "dq3yXjkAAAAJ",
      "2DBmo-wAAAAJ",
      "lsbreWwAAAAJ",
      "fpVf9QkAAAAJ",
      "LjsKfKYAAAAJ",
      "wLf0Vw0AAAAJ",
      "df-THM0AAAAJ",
      "XM97iScAAAAJ",
      "i38QlUwAAAAJ",
      "umivlPQAAAAJ",
      "3yQFuR4AAAAJ",
      "6uIhh6MAAAAJ",
      "zkvW8FQAAAAJ",
      "jikMhF4AAAAJ",
      "VjsNXysAAAAJ",
      "-XCiamcAAAAJ",
      "yDVn5LEAAAAJ",
      "d5y4iKAAAAAJ",
      "VZHxoh8AAAAJ",
      "C-ZlBWMAAAAJ",
      "qRAQ5BsAAAAJ",
      "LeshmV8AAAAJ",
      "3kDtybgAAAAJ",
      "aa9LMvoAAAAJ",
      "itSa94cAAAAJ",
      "OP6ejqgAAAAJ",
      "Bk5q_pAAAAAJ",
      "BAAZ_ysAAAAJ",
      "PGdm9MUAAAAJ",
      "0qfCL-QAAAAJ",
      "0bwP0i4AAAAJ",
      "PS-TM94AAAAJ",
      "fmSHtE8AAAAJ",
      "j8ULfMsAAAAJ",
      "tfN6V84AAAAJ",
      "ri1sE34AAAAJ",
      "MzKvJhAAAAAJ",
      "rNcmwggAAAAJ",
      "WXbhp_4AAAAJ",
      "y2pH4jcAAAAJ",
      "-CeUxegAAAAJ",
      "wxnzyjwAAAAJ",
      "gTWUZlsAAAAJ",
      "O43_7KUAAAAJ",
      "NkzyCvUAAAAJ",
      "lyadgWkAAAAJ",
      "B8wslVsAAAAJ",
      "b4PmtFkAAAAJ",
      "0ei9XEUAAAAJ",
      "n-B0jr4AAAAJ",
      "Qhe5ua0AAAAJ",
      "V42yp08AAAAJ",
      "Jp6Mz1sAAAAJ",
      "t4dSV4YAAAAJ",
      "Q8kbUQEAAAAJ",
      "84WzBlYAAAAJ",
      "zX3ba1kAAAAJ",
      "mVkGg80AAAAJ",
      "q-buMEoAAAAJ",
      "ESCWolcAAAAJ",
      "MhDyxdYAAAAJ",
      "7HCKL10AAAAJ",
      "wRyjJfMAAAAJ",
      "FH9nKOAAAAAJ",
      "ED5iKYYAAAAJ",
      "i28fU0MAAAAJ",
      "t9HPFawAAAAJ",
      "hiOfejkAAAAJ",
      "SOt7sr4AAAAJ",
      "_TkfqdgAAAAJ",
      "8m8taGEAAAAJ",
      "9xDADY4AAAAJ",
      "HaN8b2YAAAAJ",
      "ZWH5jCwAAAAJ",
      "ADkiClQAAAAJ",
      "BgQkdsYAAAAJ",
      "IzUjvBYAAAAJ",
      "U_Jw8DUAAAAJ",
      "UnEHCNkAAAAJ",
      "KgZxzjsAAAAJ",
      "5Iqe53IAAAAJ",
      "wb-DKCIAAAAJ",
      "tcfl2hUAAAAJ",
      "_koixUEAAAAJ",
      "CgItEbQAAAAJ",
      "zFNvU34AAAAJ",
      "Wd8_fOcAAAAJ",
      "Q6F3O0sAAAAJ",
      "f2NAF7QAAAAJ",
      "rRJ9wTJMUB8C",
      "9yRwkr4AAAAJ",
      "RU0ZAp4AAAAJ",
      "czyretsAAAAJ",
      "r44N6h8AAAAJ",
      "N_rVVG8AAAAJ",
      "yyIoQu4AAAAJ",
      "slQp6UYAAAAJ",
      "zXhuhtwAAAAJ",
      "GHpxNQIAAAAJ",
      "BOAOkNQAAAAJ",
      "e9gUdKwAAAAJ",
      "DkUUhXEAAAAJ",
      "xEWgxBsAAAAJ",
      "4V1nNm4AAAAJ",
      "xdGKgtcAAAAJ",
      "gQpYbRsAAAAJ",
      "hHkuxSUAAAAJ",
      "szDNg-0AAAAJ",
      "p1DZVX8AAAAJ",
      "wORhZLMAAAAJ",
      "yxUduqMAAAAJ",
      "cl7CnNYAAAAJ",
      "EMDboA4AAAAJ",
      "0mgEF28AAAAJ",
      "Wj4ZBFIAAAAJ",
      "m0WCd-4AAAAJ",
      "Ctp3igcAAAAJ",
      "07qshUgAAAAJ",
      "H3LMjtoAAAAJ",
      "ITZ1e7MAAAAJ",
      "3ifikJ0AAAAJ",
      "bZ9oyW8AAAAJ",
      "NSWI3OwAAAAJ",
      "FdNHp8QAAAAJ",
      "D1okUccAAAAJ",
      "_kJ-zUYAAAAJ",
      "evUv2MAAAAAJ",
      "fftO_HsAAAAJ",
      "k7NgVSUAAAAJ",
      "b8OxVWUAAAAJ",
      "xegzhJcAAAAJ",
      "bRWa8q8AAAAJ",
      "DpLFv4gAAAAJ",
      "FUOEBDUAAAAJ",
      "9GMg6q8AAAAJ",
      "5JserkUAAAAJ",
      "owqhKD8AAAAJ",
      "DplAah0AAAAJ",
      "YTO4ex4AAAAJ",
      "m_HQ-WQAAAAJ",
      "eQujqDgAAAAJ",
      "1O83J5MAAAAJ",
      "OZ7PjVoAAAAJ",
      "6dskOSUAAAAJ",
      "7OTD-LEAAAAJ",
      "vN-is70AAAAJ",
      "x1mbRloAAAAJ",
      "IB_jPZ0AAAAJ",
      "DZ-fHPgAAAAJ",
      "9I7kD8sAAAAJ",
      "DcV-5RAAAAAJ",
      "pouyVyUAAAAJ",
      "X0EXfT8AAAAJ",
      "P4nfoKYAAAAJ",
      "L5jDQS8AAAAJ",
      "HQRnt54AAAAJ",
      "hISpTpQAAAAJ",
      "lS96SqoAAAAJ",
      "a8Y2OJMAAAAJ",
      "1p3dDesAAAAJ",
      "opbZfw0AAAAJ",
      "_QlCijoAAAAJ",
      "NvKHgzkAAAAJ",
      "NmHgX-wAAAAJ",
      "dzOd2hgAAAAJ",
      "MzD8rjoAAAAJ",
      "4pWLoJEAAAAJ",
      "tsXh_hwAAAAJ",
      "Y8O9N_0AAAAJ",
      "kiFd6A8AAAAJ",
      "aO8KpGcAAAAJ",
      "6-e-ZBEAAAAJ",
      "QWzsNMDsvlIC",
      "EWJYRncAAAAJ",
      "POlWWAsAAAAJ",
      "n1zDCkQAAAAJ",
      "SqFoZNUAAAAJ",
      "3yT6IX4AAAAJ",
      "_1hCq3UAAAAJ",
      "78WTKm4AAAAJ",
      "znnl0kwAAAAJ",
      "nCFeUqYAAAAJ",
      "LWlN_BUAAAAJ",
      "C2_ZXdcAAAAJ",
      "ijmuZ0wAAAAJ",
      "LajpoI8AAAAJ",
      "jrfFYAIAAAAJ",
      "62e5CygAAAAJ",
      "NOoKltoAAAAJ",
      "L-diWvQAAAAJ",
      "YNoe5GAAAAAJ",
      "ajIYB6wAAAAJ",
      "QxbpIMUAAAAJ",
      "DZ3S--MAAAAJ",
      "FyQAwaEAAAAJ",
      "-QopmQoAAAAJ",
      "MSCQE-YAAAAJ",
      "vfPE6hgAAAAJ",
      "nfX25MMAAAAJ",
      "2ItLnFgAAAAJ",
      "aC55XVgAAAAJ",
      "sRpY9TIAAAAJ",
      "w-xdg4sAAAAJ",
      "DRnOvU8AAAAJ",
      "BIwrJuQAAAAJ",
      "T6PbwPIAAAAJ",
      "MK6zHkYAAAAJ",
      "NTb14PgAAAAJ",
      "5MTY7-wAAAAJ",
      "85XK-uAAAAAJ",
      "DwdjBUUAAAAJ",
      "X-Sd3-8AAAAJ",
      "eurA6WgAAAAJ",
      "FFWXLHUAAAAJ",
      "t8v3JXsAAAAJ",
      "Fsz9BAUAAAAJ",
      "a5nY-pYAAAAJ",
      "gYiCq88AAAAJ",
      "lRUi-A8AAAAJ",
      "W8VIEZgAAAAJ",
      "YsXNU78AAAAJ",
      "jM23vRsKxuIC",
      "lJwPbcUAAAAJ",
      "h3qMa1kAAAAJ",
      "siuZCjUAAAAJ",
      "VT7peyEAAAAJ",
      "Hyhp_zUAAAAJ",
      "DYUloYkAAAAJ",
      "ySwF8ioAAAAJ",
      "xkH30GgAAAAJ",
      "ftI1lBQAAAAJ",
      "UE9jz_MAAAAJ",
      "HBztuGIAAAAJ",
      "iVLAQysAAAAJ",
      "FXiSi-4AAAAJ",
      "CpMjT0YAAAAJ",
      "Bl8GgEcAAAAJ",
      "4mVPFQ8AAAAJ",
      "dnZ8udEAAAAJ",
      "axX7PCwAAAAJ",
      "mnAk4HIAAAAJ",
      "CP5x1yEAAAAJ",
      "0uTu7fYAAAAJ",
      "tX3YzCcAAAAJ",
      "LMtE3FQAAAAJ",
      "eM916YMAAAAJ",
      "iyDxq0EAAAAJ",
      "Y9CoR7QAAAAJ",
      "YGQs1AYAAAAJ",
      "kppa2vgAAAAJ",
      "UAWfBEoAAAAJ",
      "-iPZaBcAAAAJ",
      "SaiH1MIAAAAJ",
      "w4yTWwoAAAAJ",
      "-ltRSM0AAAAJ",
      "gd04NQ8AAAAJ",
      "sJDqACEAAAAJ",
      "PpzsjioAAAAJ",
      "Rn_BmTYAAAAJ",
      "YAHWbtkAAAAJ",
      "23LELwEAAAAJ",
      "XXUsEjsAAAAJ",
      "chICXXMAAAAJ",
      "23ZXZvEAAAAJ",
      "b957ulAAAAAJ",
      "jyxO2akAAAAJ",
      "Op-47sgAAAAJ",
      "cnncomYAAAAJ",
      "bslhbWgAAAAJ",
      "bdHgGgEAAAAJ",
      "GyoKzFwAAAAJ",
      "GUAoEcAAAAAJ",
      "zUJus70AAAAJ",
      "uFJi3IUAAAAJ",
      "Tsh90D8AAAAJ",
      "zS3z8UgAAAAJ",
      "87nZphcAAAAJ",
      "OttawxUAAAAJ",
      "mnU3HpcAAAAJ",
      "oizZKrsAAAAJ",
      "eIWg8NMAAAAJ",
      "QxLpghAAAAAJ",
      "0Qr2IGwAAAAJ",
      "7HPdnqEAAAAJ",
      "lH1PdF8AAAAJ",
      "hdTDzlQAAAAJ",
      "LIJQ_ZYAAAAJ",
      "IcaU830AAAAJ",
      "6Q-289IAAAAJ",
      "56EZh6YAAAAJ",
      "s_3ZE8kAAAAJ",
      "7P-gZioAAAAJ",
      "6QWsktwAAAAJ",
      "wKJeOQoAAAAJ",
      "uemlfQYAAAAJ",
      "_7Q8uIYAAAAJ",
      "i5srt20AAAAJ",
      "2oy3OXYAAAAJ",
      "pfGI-KcAAAAJ",
      "_EJrRVAAAAAJ",
      "12uhMdIAAAAJ",
      "_PZKLYUAAAAJ",
      "B_FTboQAAAAJ",
      "pvyI8GkAAAAJ",
      "LAv0HTEAAAAJ",
      "gzpWXPcAAAAJ",
      "vKlrdpEAAAAJ",
      "_qr34PIAAAAJ",
      "-WZcuuwAAAAJ",
      "rIjeeRsAAAAJ",
      "bh-uRFMAAAAJ",
      "adnTgaAAAAAJ",
      "kXB8FBoAAAAJ",
      "UWZA0v4AAAAJ",
      "UAwKvEsAAAAJ",
      "UFlWdvUAAAAJ",
      "3Y4egcYAAAAJ",
      "eml8HfQAAAAJ",
      "wy0FA1cAAAAJ",
      "qwCO618AAAAJ",
      "DMTuJzAAAAAJ",
      "b0ehAgIAAAAJ",
      "-9geUIIAAAAJ",
      "Vdu_sqwAAAAJ",
      "x04W_mMAAAAJ",
      "hRB3wSgAAAAJ",
      "fA0rYxMAAAAJ",
      "lPycXNcAAAAJ",
      "fMDLYCUAAAAJ",
      "c_z5hWEAAAAJ",
      "czxMUzcAAAAJ",
      "Q-v0BgUAAAAJ",
      "kg4bCpgAAAAJ",
      "4Z6vo5QAAAAJ",
      "DulpV-cAAAAJ",
      "ZQ1Bbb8AAAAJ",
      "wmZTE5gAAAAJ",
      "xUGZX_MAAAAJ",
      "hhm6ZzUAAAAJ",
      "xOWBOKQAAAAJ",
      "QXyvv94AAAAJ",
      "x78TL58AAAAJ",
      "neGbgzYAAAAJ",
      "1HO5UacAAAAJ",
      "3F52RjoAAAAJ",
      "AIZoRQIAAAAJ",
      "8fztli4AAAAJ",
      "ZcWO2AEAAAAJ",
      "Ob0bNAUAAAAJ",
      "ckZ7q_gAAAAJ",
      "TmWYBeEAAAAJ",
      "3XLQbL8AAAAJ",
      "KcPrLhIAAAAJ",
      "AIy7QHIAAAAJ",
      "EjtpMaoAAAAJ",
      "qlwwdfEAAAAJ",
      "1M79iLwAAAAJ",
      "no_BfYgAAAAJ",
      "2k5j4eMAAAAJ",
      "VbNwxKYAAAAJ",
      "rBJV6QUAAAAJ",
      "PkfChMgAAAAJ",
      "l-la0GQAAAAJ",
      "T7uctwYAAAAJ",
      "ThJ-Ju4AAAAJ",
      "AEsPCAUAAAAJ",
      "SaboshYAAAAJ",
      "Wewcpo4AAAAJ",
      "Uly5spMAAAAJ",
      "3_toKJ4AAAAJ",
      "Vzr1RukAAAAJ",
      "8R35rCwAAAAJ",
      "MN9Kfg8AAAAJ",
      "BDmtLHsAAAAJ",
      "LUe32ToAAAAJ",
      "Dtw3YBoAAAAJ",
      "5pKTRxEAAAAJ",
      "mu5Y2rYAAAAJ",
      "vboGT0EAAAAJ",
      "wIDVzroAAAAJ",
      "ZvX1hXcAAAAJ",
      "F_ASWCUAAAAJ",
      "7ShMBcwAAAAJ",
      "5JE9m1EAAAAJ",
      "fNOReswAAAAJ",
      "p9RsPG4AAAAJ",
      "8-p9CLsAAAAJ",
      "OSg3D9MAAAAJ",
      "yA4rb60AAAAJ",
      "q4zv0KYAAAAJ",
      "-zaDQ10AAAAJ",
      "hiGI9v0AAAAJ",
      "gFLW9qcAAAAJ",
      "ExXP2_AAAAAJ",
      "lMkTx0EAAAAJ",
      "wMcPTbEAAAAJ",
      "8iCb2TwAAAAJ",
      "r81Ss1cAAAAJ",
      "xaYqRfAAAAAJ",
      "tk3X1QkAAAAJ",
      "5lB_d78AAAAJ",
      "H3Uq3FcAAAAJ",
      "2ylcZSsAAAAJ",
      "-gJkPHIAAAAJ",
      "Yxh9WWoAAAAJ",
      "4D1n8scAAAAJ",
      "eVYhlDQAAAAJ",
      "MO7qaUIAAAAJ",
      "MDeIveMAAAAJ",
      "0nPi5YYAAAAJ",
      "Wk2gAZUAAAAJ",
      "JWmiQR0AAAAJ",
      "kZh8vUMAAAAJ",
      "_ws9LLgAAAAJ",
      "ID9QePIAAAAJ",
      "T9To2C0AAAAJ",
      "42m4tGIAAAAJ",
      "CzOD0S4AAAAJ",
      "zxB06pcAAAAJ",
      "67kghxAAAAAJ",
      "xaQuPloAAAAJ",
      "rMDVDA8AAAAJ",
      "l-mlF7YAAAAJ",
      "JKVR2ksAAAAJ",
      "bQowYEYAAAAJ",
      "SlZavnIAAAAJ",
      "t2X4Mg8AAAAJ",
      "LQR0kNcAAAAJ",
      "todsDfQAAAAJ",
      "Rne0FzEAAAAJ",
      "SiBVfPUAAAAJ",
      "94RFSSsAAAAJ",
      "vgfGtykAAAAJ",
      "1eBgIWsAAAAJ",
      "BZBkjNYAAAAJ",
      "mDNhPjAAAAAJ",
      "LfcroyAAAAAJ",
      "yE4WT_0AAAAJ",
      "8O8MQEUAAAAJ",
      "Zldo9CAAAAAJ",
      "i7V1kJgAAAAJ",
      "vtwH6GkAAAAJ",
      "zp8V7ZMAAAAJ",
      "dYt8FGcAAAAJ",
      "-5_ksIkAAAAJ",
      "Ci-_QYIAAAAJ",
      "DxoenfgAAAAJ",
      "_DNzXTcAAAAJ",
      "yy0UFOwAAAAJ",
      "wtRVnsYAAAAJ"
    ],
    "second_level_co_authors": [
      "QOmjMZ0AAAAJ",
      "QQUxxaIAAAAJ",
      "eVv0MrsAAAAJ",
      "4bL3ThUAAAAJ",
      "Spe0xdkAAAAJ",
      "ZzURcb4AAAAJ",
      "IkpNZAoAAAAJ",
      "-GRqX-QAAAAJ",
      "U69fiZMAAAAJ",
      "UMG3OGgAAAAJ",
      "-rs_IzoAAAAJ",
      "F-ytPfAAAAAJ",
      "W8zwlYQAAAAJ",
      "rlmROVsAAAAJ",
      "F_RBceUAAAAJ",
      "_jOpRuIAAAAJ",
      "kNtDoX8AAAAJ",
      "6OZMoP0AAAAJ",
      "fkGi-JMAAAAJ",
      "uO3mk-IAAAAJ",
      "2oq9614AAAAJ",
      "ElNDOmUAAAAJ",
      "UGpC1zgAAAAJ",
      "6IFj7SkAAAAJ",
      "AYbfPEAAAAAJ",
      "G7_tE4wAAAAJ",
      "Nv6G5DwAAAAJ",
      "VyGrp0QAAAAJ",
      "KWH1qbsAAAAJ",
      "zMqwIkIAAAAJ",
      "jAAj8DAAAAAJ",
      "SiCHxTkAAAAJ",
      "yLenCKUAAAAJ",
      "jNCbl2IAAAAJ",
      "X6EqGFoAAAAJ",
      "wS2Fyv8AAAAJ",
      "C4QFdvAAAAAJ",
      "zLuqh-0AAAAJ",
      "J9-meToAAAAJ",
      "AxUAEQ4AAAAJ",
      "5yNbjSoAAAAJ",
      "t0ZfFH8AAAAJ",
      "EeYGZCwAAAAJ",
      "y2bVjBIAAAAJ",
      "dN7AziAAAAAJ",
      "jKcs76MAAAAJ",
      "xMOPRkQAAAAJ",
      "58As-bYAAAAJ",
      "tAxVl44AAAAJ",
      "TanjFwoAAAAJ",
      "gq_ESzoAAAAJ",
      "JyABkTwAAAAJ",
      "k4oSgRkAAAAJ",
      "MDWCSOQAAAAJ",
      "9JaVNVAAAAAJ",
      "ewqmB6sAAAAJ",
      "ePC7IC0AAAAJ",
      "TNMSbOkAAAAJ",
      "B847xq8AAAAJ",
      "Ey5aInIAAAAJ",
      "t23kOGIAAAAJ",
      "oAlCitYAAAAJ",
      "hCbFmUUAAAAJ",
      "vY7MdLYAAAAJ",
      "KjZluVoAAAAJ",
      "RId1qZ8AAAAJ",
      "NWPDSEsAAAAJ",
      "9cboKEYAAAAJ",
      "xMne5ZUAAAAJ",
      "fn13u8IAAAAJ",
      "tAUdLM0AAAAJ",
      "KtOqcRUAAAAJ",
      "RPPi79MAAAAJ",
      "41GA5O4AAAAJ",
      "AvvaaJcAAAAJ",
      "Zqqw2FQAAAAJ",
      "xdlBKc8AAAAJ",
      "ZKEDQXYAAAAJ",
      "H50SekAAAAAJ",
      "0OtX_6gAAAAJ",
      "LxpnsSMAAAAJ",
      "UjpM6IAAAAAJ",
      "x-AvvrYAAAAJ",
      "uggxDWIAAAAJ",
      "H1vNRiUAAAAJ",
      "B8bCdHsAAAAJ",
      "ZL-p_cIAAAAJ",
      "FayXlTYAAAAJ",
      "XmLMNyUAAAAJ",
      "65-B1ZwAAAAJ",
      "IbcqwaoAAAAJ",
      "y-khfzIAAAAJ",
      "HeaQbWsAAAAJ",
      "KJNUEgkAAAAJ",
      "s5-PGF8AAAAJ",
      "wbZtij8AAAAJ",
      "LidK--MAAAAJ",
      "5KBfZzYAAAAJ",
      "27o6cX4AAAAJ",
      "gd8q19oAAAAJ",
      "Gxz1fqwAAAAJ",
      "EsIJmL0AAAAJ",
      "ZDG9RD8AAAAJ",
      "GQWTo4MAAAAJ",
      "li9AfUUAAAAJ",
      "roooUB0AAAAJ",
      "sAdDcvQAAAAJ",
      "1bwPKXpo97YC",
      "O0W9jEQAAAAJ",
      "PF-7nJMAAAAJ",
      "U3KDpBUAAAAJ",
      "1zu2Oh0AAAAJ",
      "YhWnhQEAAAAJ",
      "lWDq-ygAAAAJ",
      "IEvwT5kAAAAJ",
      "0a58TKgAAAAJ",
      "R3sUe_EAAAAJ",
      "QQtOq2EAAAAJ",
      "_uBxMwkAAAAJ",
      "nbZ6QlsAAAAJ",
      "PEK-v-EAAAAJ",
      "SrVnrPcAAAAJ",
      "2X0cwhkAAAAJ",
      "BH86MaMAAAAJ",
      "pKnD8WcAAAAJ",
      "uBkIL7YAAAAJ",
      "9fPuoP4AAAAJ",
      "4OBGbW0AAAAJ",
      "7mrPM4kAAAAJ",
      "-spRnaQAAAAJ",
      "PKz_a_AAAAAJ",
      "V48OV8YAAAAJ",
      "AT1_prkAAAAJ",
      "1P8Zu04AAAAJ",
      "qjDVoqQAAAAJ",
      "iHh7IJQAAAAJ",
      "76B8lrgAAAAJ",
      "RbCKRPcAAAAJ",
      "fiRkCU0AAAAJ",
      "9Sf0vd4AAAAJ",
      "UesKv-0AAAAJ",
      "6w3KEiEAAAAJ",
      "to3X9roAAAAJ",
      "qXVG1AEAAAAJ",
      "pGh242UAAAAJ",
      "SO1MfpcAAAAJ",
      "8jVzL_YAAAAJ",
      "bcojPRoAAAAJ",
      "CUlqK5EAAAAJ",
      "qhgWjNkAAAAJ",
      "mnVqk28AAAAJ",
      "w9jtLkIAAAAJ",
      "soiDQbQAAAAJ",
      "I5gPRf0AAAAJ",
      "LC_8eS4AAAAJ",
      "tP5IBFkAAAAJ",
      "hwnskpoAAAAJ",
      "odVYodIAAAAJ",
      "zzbWQE4AAAAJ",
      "uqesapEAAAAJ",
      "zl70inwAAAAJ",
      "RiDdF2YAAAAJ",
      "QP1aKqcAAAAJ",
      "W9BOLA8AAAAJ",
      "kZch-sMAAAAJ",
      "r4_ZQ2AAAAAJ",
      "QOO8OCcAAAAJ",
      "UvxP_J4AAAAJ",
      "HEulGGsAAAAJ",
      "NjZsLZwAAAAJ",
      "lDzimQIAAAAJ",
      "J5kGUDMAAAAJ",
      "9ZGqm5QAAAAJ",
      "cQ5w0L0AAAAJ",
      "tL9zHywAAAAJ",
      "GR_DsT0AAAAJ",
      "whi3UisAAAAJ",
      "BEGRf_EAAAAJ",
      "Amky96kAAAAJ",
      "qCmF95EAAAAJ",
      "SLNZE7kAAAAJ",
      "WDJ7tY0AAAAJ",
      "eGj3ay4AAAAJ",
      "W6gQqWcAAAAJ",
      "ri4rEPMAAAAJ",
      "xf_n4xUAAAAJ",
      "nLnKIikAAAAJ",
      "_ZxvlzoAAAAJ",
      "dKDdHFsAAAAJ",
      "-CbjdL8AAAAJ",
      "6C-udIUAAAAJ",
      "mMifMdoAAAAJ",
      "MEz23joAAAAJ",
      "wewitucAAAAJ",
      "u7Kad50AAAAJ",
      "W7fLMpsAAAAJ",
      "AtfVA6wAAAAJ",
      "YgFOewgAAAAJ",
      "2aqrWocAAAAJ",
      "Pd8-ju0AAAAJ",
      "S1F-gScAAAAJ",
      "7XY3l2wAAAAJ",
      "vB_P3HUAAAAJ",
      "SqMUez0AAAAJ",
      "huxkCSoAAAAJ",
      "v-hyE4MAAAAJ",
      "x58fnLQAAAAJ",
      "rFL468UAAAAJ",
      "I1mOQpAAAAAJ",
      "Kr8JjF0AAAAJ",
      "OM1hDLcAAAAJ",
      "4swDjMAAAAAJ",
      "JTtnJUIAAAAJ",
      "klxwxyUAAAAJ",
      "YR_MYrAAAAAJ",
      "njJoC7wAAAAJ",
      "ASf9Q04AAAAJ",
      "SgbYgdsAAAAJ",
      "jEf5Q-4AAAAJ",
      "zc6Iy0IAAAAJ",
      "r2E5Ak8AAAAJ",
      "B3t_szAAAAAJ",
      "ZIlzcYcAAAAJ",
      "VZHxoh8AAAAJ",
      "4hC_FYoAAAAJ",
      "YPineKcAAAAJ",
      "45Jrl1YAAAAJ",
      "bbfGi6sAAAAJ",
      "qosS83IAAAAJ",
      "eUW2DUEAAAAJ",
      "WIvjYUIAAAAJ",
      "5eoD8UwAAAAJ",
      "OP6ejqgAAAAJ",
      "eZ51GLAAAAAJ",
      "VajMetgAAAAJ",
      "BP0WzIQAAAAJ",
      "maa1m0oAAAAJ",
      "VU4chlsAAAAJ",
      "fmSHtE8AAAAJ",
      "FmMT4CcAAAAJ",
      "G9HyayYAAAAJ",
      "rlMZibgAAAAJ",
      "ShGrv3kAAAAJ",
      "iJbdUkQAAAAJ",
      "PQtLkV0AAAAJ",
      "J6VzIsYAAAAJ",
      "-CeUxegAAAAJ",
      "hvr3ALkAAAAJ",
      "DJ9puk8AAAAJ",
      "4hbasIcAAAAJ",
      "GINhGvwAAAAJ",
      "Pb2O3oYAAAAJ",
      "TfetUkcAAAAJ",
      "Klc6YZcAAAAJ",
      "wQSRT18AAAAJ",
      "SJi-EFwAAAAJ",
      "Ige4r2YAAAAJ",
      "DBXWBqcAAAAJ",
      "1jPQEVMAAAAJ",
      "M7y1dj8AAAAJ",
      "D-AN9vQAAAAJ",
      "BNEeEosAAAAJ",
      "RljePdcAAAAJ",
      "Z6nLCukAAAAJ",
      "ZKDLDQoAAAAJ",
      "hwn3OPIAAAAJ",
      "iJuDBhEAAAAJ",
      "c5JFDEgAAAAJ",
      "NQ-n2M0AAAAJ",
      "D-SlUjsAAAAJ",
      "wRyjJfMAAAAJ",
      "oavgGaMAAAAJ",
      "72yPqG4AAAAJ",
      "qWGk7FUAAAAJ",
      "6ggnUzYAAAAJ",
      "LGF6qesAAAAJ",
      "lZPXUgoAAAAJ",
      "8hU4uvEAAAAJ",
      "_7QgnUcAAAAJ",
      "CRNmfCAAAAAJ",
      "D5CISpEAAAAJ",
      "QZVQEWAAAAAJ",
      "h-GyeogAAAAJ",
      "8m8taGEAAAAJ",
      "BSDXhwgAAAAJ",
      "2r2NuDAAAAAJ",
      "wQv9q3cAAAAJ",
      "eqmeFRoAAAAJ",
      "kxUld9MAAAAJ",
      "5031vK4AAAAJ",
      "qIg8KFYAAAAJ",
      "RffbjzgAAAAJ",
      "FcRGdiwAAAAJ",
      "3YZTd_UAAAAJ",
      "Ue4wghAAAAAJ",
      "cwff2XYAAAAJ",
      "N0tU5N4AAAAJ",
      "cZneVpUAAAAJ",
      "C6kPjgwAAAAJ",
      "bWoGh8UAAAAJ",
      "5Iqe53IAAAAJ",
      "7oepLUoAAAAJ",
      "IjJXgWAa708C",
      "8sqAOOoAAAAJ",
      "WSN7T_YAAAAJ",
      "TtU74NAAAAAJ",
      "T-f6XlEAAAAJ",
      "HT85tXsAAAAJ",
      "jAAj2XoAAAAJ",
      "yVLaR1QAAAAJ",
      "hmq4rGIAAAAJ",
      "gGh0i8AAAAAJ",
      "s3l225EAAAAJ",
      "Ln5Ksv0AAAAJ",
      "smm3MNcAAAAJ",
      "lveaf5IAAAAJ",
      "N5pB4l4AAAAJ",
      "OZKad_UAAAAJ",
      "siCYLcUAAAAJ",
      "luSyn1AAAAAJ",
      "mWdYMZ8AAAAJ",
      "B0MzhZwAAAAJ",
      "Yxv1EwcAAAAJ",
      "4VVgg_UAAAAJ",
      "13Tv6dkAAAAJ",
      "H_1utcUAAAAJ",
      "17TY2TMAAAAJ",
      "RvtEObEAAAAJ",
      "w3B9Qs8AAAAJ",
      "9eyvm28AAAAJ",
      "fNUgQjMAAAAJ",
      "xEWgxBsAAAAJ",
      "9EnJFEEAAAAJ",
      "K-SafJUAAAAJ",
      "_U-HwfkAAAAJ",
      "7fQYGjcAAAAJ",
      "2kPveDIAAAAJ",
      "Vlfz-_IAAAAJ",
      "friM_CIAAAAJ",
      "3B2c31wAAAAJ",
      "QGpxkvkAAAAJ",
      "C8bGfr0AAAAJ",
      "Q9jd0mgAAAAJ",
      "yYE8Xo8AAAAJ",
      "lLTdYUYAAAAJ",
      "4_uj0xcAAAAJ",
      "0GMYDB8AAAAJ",
      "ZjyUJyIAAAAJ",
      "s7-TjaIAAAAJ",
      "Ikt1e-0AAAAJ",
      "LWZtl74AAAAJ",
      "GelzUJgAAAAJ",
      "DKx4XFkAAAAJ",
      "JvY2c4YAAAAJ",
      "CMZAKkEAAAAJ",
      "zQkIKOcAAAAJ",
      "3ifikJ0AAAAJ",
      "iMlmLO4AAAAJ",
      "v8xm0csAAAAJ",
      "Jy0SwIcAAAAJ",
      "WKpjMHsAAAAJ",
      "oAU5b1wAAAAJ",
      "di5RZ1MAAAAJ",
      "6hsn3EYAAAAJ",
      "hEhQmT8AAAAJ",
      "AvH7tJwAAAAJ",
      "TpglobcAAAAJ",
      "Sczy43gAAAAJ",
      "vM8t8zwAAAAJ",
      "6IvhxBkAAAAJ",
      "y_PW-TcAAAAJ",
      "Sm14jYIAAAAJ",
      "1aou7GkAAAAJ",
      "Nt9r1_IAAAAJ",
      "JDaHecMAAAAJ",
      "RCTeTV0AAAAJ",
      "y1bnRg4AAAAJ",
      "qkn2yIIAAAAJ",
      "qA3IkiwAAAAJ",
      "mWGyYMsAAAAJ",
      "eUtEs6YAAAAJ",
      "SdPinGIAAAAJ",
      "Lncr-VoAAAAJ",
      "9nnDvooAAAAJ",
      "Ffwbco4AAAAJ",
      "AK_7EBgAAAAJ",
      "VOWP8TUAAAAJ",
      "JEEwSlQAAAAJ",
      "Y6L6ZYsAAAAJ",
      "MHLyZY4AAAAJ",
      "D4Z3yrwAAAAJ",
      "KsYfSCIAAAAJ",
      "BRWwxYwAAAAJ",
      "MIfpzUQAAAAJ",
      "KdA9qBkAAAAJ",
      "x1mbRloAAAAJ",
      "bmlgkM4AAAAJ",
      "FPVUA-YAAAAJ",
      "YMAOvHYAAAAJ",
      "Qb7xQQ0AAAAJ",
      "8erqrHcAAAAJ",
      "DnRJBwUAAAAJ",
      "oExGuP8AAAAJ",
      "8osGCyAAAAAJ",
      "ZRjM4EgAAAAJ",
      "Yi5nK1EAAAAJ",
      "n41vSUAAAAAJ",
      "4Ea9RSkAAAAJ",
      "KarsBWAAAAAJ",
      "WKpSlhQAAAAJ",
      "DZtU6KMAAAAJ",
      "8vXcIKoAAAAJ",
      "gYCRa7wAAAAJ",
      "471mb4wAAAAJ",
      "JBGlsDoAAAAJ",
      "g5CD7dQAAAAJ",
      "3TQ5YmMAAAAJ",
      "2fwi6UIAAAAJ",
      "FQn7YigAAAAJ",
      "_moJlrIAAAAJ",
      "kdbzgK4AAAAJ",
      "JS-_0nUAAAAJ",
      "KxQfzRcAAAAJ",
      "rUOpCEYAAAAJ",
      "Hp5uEnUAAAAJ",
      "gl3ZczYAAAAJ",
      "QLsu5OQAAAAJ",
      "K-dWyGEAAAAJ",
      "0VQ1sjcAAAAJ",
      "YJd3v4QAAAAJ",
      "j03zZgcAAAAJ",
      "kiFd6A8AAAAJ",
      "BT4XTP4AAAAJ",
      "ncy_2xUAAAAJ",
      "Z21g5_wAAAAJ",
      "avCEoT8AAAAJ",
      "U_R0PWEAAAAJ",
      "AnLxYd8AAAAJ",
      "dnjq-FgAAAAJ",
      "1YduZuMAAAAJ",
      "d7_f7LsAAAAJ",
      "Gd9HQn2UsNoC",
      "c_ssivMAAAAJ",
      "bb_q7tYAAAAJ",
      "dUPre_sAAAAJ",
      "eU0C31YAAAAJ",
      "v84zUXYAAAAJ",
      "gB87zD4AAAAJ",
      "SfDzdgEAAAAJ",
      "OBagQ_4AAAAJ",
      "g7Op2tgAAAAJ",
      "jrfFYAIAAAAJ",
      "ReXgGMEAAAAJ",
      "gp6HUP0AAAAJ",
      "Z9uBjIEAAAAJ",
      "qyPWUBcAAAAJ",
      "fGv6xi0AAAAJ",
      "TPnedXMAAAAJ",
      "iX1CFmYAAAAJ",
      "fsjokJUAAAAJ",
      "sc5iZ3EAAAAJ",
      "rQ2WAxoAAAAJ",
      "wC19wG0AAAAJ",
      "sSPq-ZEAAAAJ",
      "a1ngrCIAAAAJ",
      "9PvqaoEAAAAJ",
      "26eh1jAAAAAJ",
      "tJGm3-YAAAAJ",
      "bnQMuzgAAAAJ",
      "Ecjx73cAAAAJ",
      "nVWQwHkAAAAJ",
      "H4XxdCQAAAAJ",
      "XUI4PMEAAAAJ",
      "qX2I6KIAAAAJ",
      "wsLqB5UAAAAJ",
      "Ikz6_Y0AAAAJ",
      "tR3AZbwAAAAJ",
      "Zd2MrfUAAAAJ",
      "e5P8uR4AAAAJ",
      "7MoHiJ8AAAAJ",
      "h1Z5hk8AAAAJ",
      "kCxHiwUAAAAJ",
      "YvdzeM8AAAAJ",
      "70Rmp1oAAAAJ",
      "u-T21zUAAAAJ",
      "X-Sd3-8AAAAJ",
      "3A098eMAAAAJ",
      "Zm0kSvgAAAAJ",
      "q9UyGCIAAAAJ",
      "dLx3Um4AAAAJ",
      "hbNllP0AAAAJ",
      "oyWpVa8AAAAJ",
      "csgUXLsAAAAJ",
      "QIZWnnQAAAAJ",
      "CQ1cqKkAAAAJ",
      "KIxRFxQAAAAJ",
      "kzFmAkYAAAAJ",
      "v-AEFIEAAAAJ",
      "F27Q6V4AAAAJ",
      "49PCVw0AAAAJ",
      "-A_CtWMAAAAJ",
      "ge-OinUAAAAJ",
      "YGGcq5EAAAAJ",
      "xwbHbUQAAAAJ",
      "HJDxXUsAAAAJ",
      "qIvZT74AAAAJ",
      "IhMQa-MAAAAJ",
      "PUSWc4EAAAAJ",
      "HYrDojkAAAAJ",
      "ALVSZAYAAAAJ",
      "EmmO7LcAAAAJ",
      "M-y2aLUAAAAJ",
      "OM0D_3wAAAAJ",
      "SbYoEmQAAAAJ",
      "I1fl4oAAAAAJ",
      "FLY_0BEAAAAJ",
      "SO9llAMAAAAJ",
      "U3Eub-EAAAAJ",
      "RM2vMNcAAAAJ",
      "TBoc26oAAAAJ",
      "UNXPtTMAAAAJ",
      "-iPZaBcAAAAJ",
      "0irVeiQAAAAJ",
      "XaFhuG8AAAAJ",
      "tWoesqcAAAAJ",
      "La3_EQwAAAAJ",
      "LZUyMg8AAAAJ",
      "yyG8xWcAAAAJ",
      "8HZzDSwAAAAJ",
      "8GDPQboAAAAJ",
      "XsYoY2QAAAAJ",
      "WwqlChAAAAAJ",
      "Qk_ziKsAAAAJ",
      "huBJSMwAAAAJ",
      "plYoF-MAAAAJ",
      "vg_IkckAAAAJ",
      "CmoKVuUAAAAJ",
      "nwPxp24AAAAJ",
      "EFVk-mwAAAAJ",
      "yfy_BGIAAAAJ",
      "Mu7NXDwAAAAJ",
      "NB4pgZYAAAAJ",
      "m7LvuTkAAAAJ",
      "tMrZjn0AAAAJ",
      "EZdKx4IAAAAJ",
      "olerUhcAAAAJ",
      "g3DjOkMAAAAJ",
      "aS2nvbsAAAAJ",
      "nrsWSt4AAAAJ",
      "ATOfqHEAAAAJ",
      "gBkMDloAAAAJ",
      "A33FhJMAAAAJ",
      "5QaaYmQAAAAJ",
      "czzhE8wAAAAJ",
      "xvnfpkMAAAAJ",
      "lsiZ9CsAAAAJ",
      "SAW3KDUAAAAJ",
      "KkkebI8AAAAJ",
      "ejchAEYAAAAJ",
      "r9JOIloAAAAJ",
      "EeYvAfIAAAAJ",
      "qOtlP1AAAAAJ",
      "DC9wzBgAAAAJ",
      "5IFSlsIAAAAJ",
      "2HE7cTEAAAAJ",
      "IcaU830AAAAJ",
      "b1y1LooAAAAJ",
      "_EJDz50AAAAJ",
      "UzlqiSMAAAAJ",
      "843JJtgAAAAJ",
      "k8uWc34AAAAJ",
      "qCU8duAAAAAJ",
      "-_hcRfgAAAAJ",
      "b2LJDtMAAAAJ",
      "BUDh_4wAAAAJ",
      "67nE-wQ_g_cC",
      "9oDqFwkAAAAJ",
      "SKb4VyUAAAAJ",
      "_7Q8uIYAAAAJ",
      "IpBjTKQAAAAJ",
      "GFvVRzwAAAAJ",
      "iV2sKq8AAAAJ",
      "_EJrRVAAAAAJ",
      "AkRWtMUAAAAJ",
      "ca7sXDUAAAAJ",
      "7b858c0AAAAJ",
      "LfkSQW4AAAAJ",
      "48PsswEAAAAJ",
      "4FeC1wQAAAAJ",
      "LAv0HTEAAAAJ",
      "DwTbLh4AAAAJ",
      "3f2wPekAAAAJ",
      "6Ff2c8wAAAAJ",
      "ki6yi04AAAAJ",
      "PtFGOakAAAAJ",
      "G4MBruQAAAAJ",
      "GkMfzy4AAAAJ",
      "qSo45J0AAAAJ",
      "OOcllDwAAAAJ",
      "z-b7JmcAAAAJ",
      "r5mA7Q8AAAAJ",
      "Zmvi6PMAAAAJ",
      "l6oz33MAAAAJ",
      "AaqB_F4AAAAJ",
      "kgZtMGsAAAAJ",
      "u7WiGLQAAAAJ",
      "JEihq_0AAAAJ",
      "eD9_J3wAAAAJ",
      "EYk7M80AAAAJ",
      "H2qBVBIAAAAJ",
      "SD46w90AAAAJ",
      "--0WA_UAAAAJ",
      "9hX-JksAAAAJ",
      "Te94nKAAAAAJ",
      "FlY-U3kAAAAJ",
      "lPycXNcAAAAJ",
      "EMrV8BIAAAAJ",
      "QrXQQ2kAAAAJ",
      "fMDLYCUAAAAJ",
      "6-YuY60AAAAJ",
      "xyrOk5EAAAAJ",
      "Ab_XjfQAAAAJ",
      "9Kz5vKYAAAAJ",
      "yfORTKUAAAAJ",
      "rDQK5tkAAAAJ",
      "SvinO8kAAAAJ",
      "6Evj9YwAAAAJ",
      "HHmGYdEAAAAJ",
      "o8BdwuMAAAAJ",
      "uoDW9hkAAAAJ",
      "1wnZg6UAAAAJ",
      "l-VuKFsAAAAJ",
      "3aO6KH4AAAAJ",
      "qWDmIgIAAAAJ",
      "Qo72ORkAAAAJ",
      "1fNDr6wAAAAJ",
      "6dFFudUAAAAJ",
      "qVaQXcoAAAAJ",
      "Voph3LUAAAAJ",
      "IrM4gpwAAAAJ",
      "Vs9YD9kAAAAJ",
      "DsR4PucAAAAJ",
      "KB5XZGIAAAAJ",
      "Py_StfUAAAAJ",
      "_8DDVkAAAAAJ",
      "JFap1psAAAAJ",
      "nFzWaPMAAAAJ",
      "gWygCaAAAAAJ",
      "mM9e90oAAAAJ",
      "WiTNe3kAAAAJ",
      "c26ONgMAAAAJ",
      "LZacO0sAAAAJ",
      "rBJV6QUAAAAJ",
      "PkfChMgAAAAJ",
      "begDaeQAAAAJ",
      "UW2Ji5MAAAAJ",
      "xL45YGMAAAAJ",
      "rBH-cpMAAAAJ",
      "eO-yR-0AAAAJ",
      "wA5TK_0AAAAJ",
      "KjR3yVQAAAAJ",
      "-g58LsoAAAAJ",
      "L6TpGPMAAAAJ",
      "1Yu0vQkAAAAJ",
      "VhL7NugAAAAJ",
      "s0njcGgAAAAJ",
      "xWrOthYAAAAJ",
      "TIST9HIAAAAJ",
      "-fUDeigAAAAJ",
      "3plYmtsAAAAJ",
      "Dkf39REAAAAJ",
      "gqB23VMAAAAJ",
      "6fqNXooAAAAJ",
      "pOSMWfQAAAAJ",
      "dUWUGcEAAAAJ",
      "plbHxNUAAAAJ",
      "JhIiSHQAAAAJ",
      "TnJqhXIAAAAJ",
      "6VW1kJgAAAAJ",
      "nZEtlZoAAAAJ",
      "ju7dyZMAAAAJ",
      "E1jZijwAAAAJ",
      "BOL2qeUAAAAJ",
      "Eed2gcMAAAAJ",
      "YLHQ1QoAAAAJ",
      "w_XDRRsAAAAJ",
      "IrMKDiIAAAAJ",
      "NLBZuoEAAAAJ",
      "5tyrt68AAAAJ",
      "wMcPTbEAAAAJ",
      "0_bSbIoAAAAJ",
      "dp5LnVAAAAAJ",
      "V9EUwCEAAAAJ",
      "pGgB_xAAAAAJ",
      "KTzRHmwAAAAJ",
      "B1lAghgAAAAJ",
      "_3q6KBIAAAAJ",
      "ZbA-z1cAAAAJ",
      "j6bKU_kAAAAJ",
      "EjXmTH4AAAAJ",
      "3TlBVXkAAAAJ",
      "6zm5XD8AAAAJ",
      "_UJsz3AAAAAJ",
      "G2zXCNkAAAAJ",
      "WNIxd2UAAAAJ",
      "jZXvcOsAAAAJ",
      "evR07usAAAAJ",
      "MO7qaUIAAAAJ",
      "ca_O-WQAAAAJ",
      "ZjX0crAAAAAJ",
      "wBMdXsgAAAAJ",
      "gJE5IssAAAAJ",
      "b8d5wS-QfscC",
      "SQ1eGN4AAAAJ",
      "2SmbjHAAAAAJ",
      "cEepZOEAAAAJ",
      "aeJGZxIAAAAJ",
      "BWADJUkAAAAJ",
      "J5Nwk-UAAAAJ",
      "P73-vsoAAAAJ",
      "k4l-zNYAAAAJ",
      "ejWucigAAAAJ",
      "bQKreEMAAAAJ",
      "FL61g6wAAAAJ",
      "n_N-PJkAAAAJ",
      "zu8U47oAAAAJ",
      "FuYln-oAAAAJ",
      "1gQvWvUAAAAJ",
      "9cWszHUu9eAC",
      "2-e0jiEAAAAJ",
      "dvDLaPkAAAAJ",
      "l-mlF7YAAAAJ",
      "o1IZjggAAAAJ",
      "XBg0AAkAAAAJ",
      "SIHPQ28AAAAJ",
      "AY6InkoAAAAJ",
      "7HmZizkAAAAJ",
      "Q8yp6zQAAAAJ",
      "7GK8LQMAAAAJ",
      "qdINILwAAAAJ",
      "VIZvaGsAAAAJ",
      "XYy_Nm4AAAAJ",
      "jZwEDZoAAAAJ",
      "FodLUKcAAAAJ",
      "Cvn7Y5YAAAAJ",
      "FpI8dFwAAAAJ",
      "MaSuaDkAAAAJ",
      "XRyUF6gAAAAJ",
      "cSxeVz0AAAAJ",
      "kek70IwAAAAJ",
      "9rUGrpwAAAAJ",
      "bdwy3iIAAAAJ",
      "gFN4QUYAAAAJ",
      "bBnvK8cAAAAJ",
      "tX0GARYAAAAJ",
      "0ee8P-cAAAAJ",
      "nI2URPQAAAAJ",
      "D04RyEcAAAAJ",
      "pv54dqMAAAAJ",
      "OXtNAU4AAAAJ",
      "1MtIU9YAAAAJ",
      "LUn8dAEAAAAJ",
      "wQanfTIAAAAJ",
      "5g3iJvYAAAAJ",
      "oU2jyxMAAAAJ",
      "InutcIUAAAAJ",
      "0dz0hyQAAAAJ",
      "AQ6AppgAAAAJ",
      "ENJA2f8AAAAJ",
      "eQvG-qoAAAAJ",
      "-9X2XCkAAAAJ",
      "TLfsJRwAAAAJ",
      "xF7oivwAAAAJ",
      "ej3Nb5wAAAAJ",
      "ZDL6ITwAAAAJ",
      "V4Y4ETQAAAAJ",
      "1lHiuAQAAAAJ",
      "oI6AIkMAAAAJ",
      "bBHxY_MAAAAJ",
      "TbQXQ7EAAAAJ",
      "DnQMAnwAAAAJ",
      "16srx18AAAAJ",
      "-EZBCBAAAAAJ",
      "9CEJKM4AAAAJ",
      "bHFAmtgAAAAJ",
      "bRGcMbIAAAAJ",
      "t1u0f5QAAAAJ",
      "zx4X0fwAAAAJ",
      "Hm0UA64AAAAJ",
      "Iw-G2qIAAAAJ",
      "mU40GkMAAAAJ",
      "nscLxl4AAAAJ",
      "j29kMCwAAAAJ",
      "MhoS1_oAAAAJ",
      "rgLGzAQAAAAJ",
      "7TVJf1gAAAAJ",
      "LJiQRJIAAAAJ",
      "UFsTIAEAAAAJ",
      "j4VWFL4AAAAJ",
      "nGUcGrYAAAAJ",
      "kz2aIc8AAAAJ",
      "IR-Vw9kAAAAJ",
      "GljRwkUAAAAJ",
      "Z_WO2w0AAAAJ",
      "EdV_R7oAAAAJ",
      "8Sfj7q8AAAAJ",
      "QCBdB7AAAAAJ",
      "pJB4fIEAAAAJ",
      "7AZp7ycAAAAJ",
      "xC13Kb4AAAAJ",
      "a3K-f2YAAAAJ",
      "2l1fWEoAAAAJ",
      "GwEdlMkAAAAJ",
      "4gdSoOYAAAAJ",
      "bWBQzhQAAAAJ",
      "y_4QsYAAAAAJ",
      "66lkylsAAAAJ",
      "rs1M7CAAAAAJ",
      "yc4nBNgAAAAJ",
      "kDHs7DYAAAAJ",
      "YtfPZDAAAAAJ",
      "Bq9Osr8AAAAJ",
      "hlEPkxAAAAAJ",
      "OY1lJEAAAAAJ",
      "7IDZrScAAAAJ",
      "yBs28hUAAAAJ",
      "BxbKTYkAAAAJ",
      "1NQRXHQAAAAJ",
      "R9L0aqAAAAAJ",
      "_y-8nrcAAAAJ",
      "k-nF0qgAAAAJ",
      "SormeOgAAAAJ",
      "_hrEN-sAAAAJ",
      "e4MjcOEAAAAJ",
      "LoT0z6oAAAAJ",
      "-JOkpfQAAAAJ",
      "m3wdswkAAAAJ",
      "62Uqu6wAAAAJ",
      "GyVPmtYAAAAJ",
      "kWAlOAkAAAAJ",
      "Snxa14EAAAAJ",
      "ZZWygh8AAAAJ",
      "vnsFRJUAAAAJ",
      "0dQzZH8AAAAJ",
      "cr53lHIAAAAJ",
      "3343olgAAAAJ",
      "VAamLcEAAAAJ",
      "lJol4lAAAAAJ",
      "zCsB5XsAAAAJ",
      "44jDM6EAAAAJ",
      "0cZ_KWMAAAAJ",
      "AIsTDk4AAAAJ",
      "qdGelXoAAAAJ",
      "vI5qd9AAAAAJ",
      "FUEBroEAAAAJ",
      "oN7gaqMAAAAJ",
      "sGFyDIUAAAAJ",
      "aAe-LN0AAAAJ",
      "CxeH4uoAAAAJ",
      "7uXCsMgAAAAJ",
      "hpbQN-AAAAAJ",
      "QWKWvbEAAAAJ",
      "BsMsRuIAAAAJ",
      "jo2C_wkAAAAJ",
      "o_M5CBMAAAAJ",
      "HFHcNf0AAAAJ",
      "BffFdd0AAAAJ",
      "NzCaPZsAAAAJ",
      "z76PBfYAAAAJ",
      "dN9QZfEAAAAJ",
      "Q0crxvwAAAAJ",
      "XPAkzTEAAAAJ",
      "NvMCACEAAAAJ",
      "y-8unsgAAAAJ",
      "fnDzqzIAAAAJ",
      "JoClQPUAAAAJ",
      "eHn2VXEAAAAJ",
      "n7hxT4oAAAAJ",
      "SHO5PDkAAAAJ",
      "H9x5YXkAAAAJ",
      "izZZAegAAAAJ",
      "e1P1rNkAAAAJ",
      "v6U3T4wAAAAJ",
      "kezPqwoAAAAJ",
      "CZa9GB4AAAAJ",
      "G2-nFaIAAAAJ",
      "Y2q1wVEAAAAJ",
      "BIdzgnwAAAAJ",
      "wSstCv0AAAAJ",
      "Ae9GkVQAAAAJ",
      "OAJ2PSEAAAAJ",
      "5NUgdPcAAAAJ",
      "sE3j8joAAAAJ",
      "VgYU_m8AAAAJ",
      "m1VxcKcAAAAJ",
      "hvpur7kAAAAJ",
      "dGSrRTYAAAAJ",
      "O-DazBUAAAAJ",
      "KXNUYWgAAAAJ",
      "YDCsS5EAAAAJ",
      "7bgABaoAAAAJ",
      "2iusLHoAAAAJ",
      "KhCiiawAAAAJ",
      "OafZcSMAAAAJ",
      "Ew7QLzsAAAAJ",
      "1RmD-YsAAAAJ",
      "i0LZR2gAAAAJ",
      "Qq70O4UAAAAJ",
      "h9E2XBi3aTAC",
      "aDKi5l8AAAAJ",
      "bW1gAI8AAAAJ",
      "cVZZ7PAAAAAJ",
      "3PqA9YYAAAAJ",
      "YC-3YaYAAAAJ",
      "Mb40Pw0AAAAJ",
      "XcD1ffwAAAAJ",
      "yMszfuMAAAAJ",
      "iO6xAdgAAAAJ",
      "xlSoLCYAAAAJ",
      "-XWZKZAAAAAJ",
      "FwxfQosAAAAJ",
      "gKUEEY4AAAAJ",
      "V1qU5dwAAAAJ",
      "TvyZkdwAAAAJ",
      "kRJkDakAAAAJ",
      "krfIJPUAAAAJ",
      "7CohtIMAAAAJ",
      "NFJ9kUEAAAAJ",
      "QLW0lzcAAAAJ",
      "e7oZHCsAAAAJ",
      "BxmyKVoAAAAJ",
      "ANPFix4AAAAJ",
      "hOlkT4sAAAAJ",
      "-F1rk68AAAAJ",
      "YTyBTmgAAAAJ",
      "F3ba0dEAAAAJ",
      "lQumblsAAAAJ",
      "8DKNKhkAAAAJ",
      "MYIW1psAAAAJ",
      "q1fmhDkAAAAJ",
      "HWxGEesAAAAJ",
      "FKOqtF8AAAAJ",
      "Ek8r82kAAAAJ",
      "s9eCQn4AAAAJ",
      "2k18_1IAAAAJ",
      "sqCGBtYAAAAJ",
      "AMGqrI0AAAAJ",
      "EuBrsZQAAAAJ",
      "P-G3sjYAAAAJ",
      "5vUydbcAAAAJ",
      "MnBxiMsAAAAJ",
      "9N0LSLsAAAAJ",
      "G5SAV7gAAAAJ",
      "wv5oKToAAAAJ",
      "DN8QtscAAAAJ",
      "Oyx-_UIAAAAJ",
      "kLqUY1gAAAAJ",
      "Akmpg4gAAAAJ",
      "VecEj6kAAAAJ",
      "WZS_HSgAAAAJ",
      "JrX99ekAAAAJ",
      "PHJokEQAAAAJ",
      "OfUOpAQAAAAJ",
      "lPDGYhwAAAAJ",
      "q39nzokAAAAJ",
      "22dxhNQAAAAJ",
      "eDQsOFMAAAAJ",
      "EzQhcfwAAAAJ",
      "XP_Hxm4AAAAJ",
      "HDHOS0QAAAAJ",
      "g3UpmeoAAAAJ",
      "cc4Qi_IAAAAJ",
      "zYhq-BEAAAAJ",
      "uRrSKVIAAAAJ",
      "Zw1pfxYAAAAJ",
      "EBeIYOwAAAAJ",
      "VnvkluIAAAAJ",
      "flCzpwcAAAAJ",
      "UUKLPMYAAAAJ",
      "PJSVA_QAAAAJ",
      "S39CcbQAAAAJ",
      "Tgbsbs8AAAAJ",
      "eiBfCmUAAAAJ",
      "reqGWxMAAAAJ",
      "FN3Lb2gAAAAJ",
      "p8Y0xJEAAAAJ",
      "RfHXG5EAAAAJ",
      "Ycmx6l8AAAAJ",
      "uBial08AAAAJ",
      "BVD_LdgAAAAJ",
      "q1G89okAAAAJ",
      "tZprM8IAAAAJ",
      "33yNvIgAAAAJ",
      "9oNkK7YAAAAJ",
      "8RJ07aQAAAAJ",
      "psuwztYAAAAJ",
      "6G5SEVkAAAAJ",
      "3yQFuR4AAAAJ",
      "uiqXutMAAAAJ",
      "cLDqm1AAAAAJ",
      "3y7spRQAAAAJ",
      "XggqoHyV3KQC",
      "zKaxWRIAAAAJ",
      "yDVn5LEAAAAJ",
      "JiiMY_wAAAAJ",
      "PNvJsN0AAAAJ",
      "V5FDxaAAAAAJ",
      "Mxio0T8AAAAJ",
      "ZocLOAMAAAAJ",
      "YXrj9aIAAAAJ",
      "0T7HVEIAAAAJ",
      "zQwXlaYAAAAJ",
      "B2XPxEkAAAAJ",
      "8NudxYsAAAAJ",
      "Ddfev5kAAAAJ",
      "Y-KJRwoAAAAJ",
      "nfWGSK0AAAAJ",
      "mlSE-YwAAAAJ",
      "EuFF9kUAAAAJ",
      "-epU9OsAAAAJ",
      "lCwsfosAAAAJ",
      "l8WuQJgAAAAJ",
      "ULgz3noAAAAJ",
      "35hM-PkAAAAJ",
      "0yDoR0AAAAAJ",
      "PtIe6OkAAAAJ",
      "jrkrn3sAAAAJ",
      "BLPO9lMAAAAJ",
      "hR249csAAAAJ",
      "gMndACUAAAAJ",
      "VW1EQEQAAAAJ",
      "23SZHUwAAAAJ",
      "mZfgLA4AAAAJ",
      "n-q-55wAAAAJ",
      "ZU1fTMYAAAAJ",
      "nujTx04AAAAJ",
      "vth4SIcAAAAJ",
      "lWpXUrMAAAAJ",
      "9hk7seYAAAAJ",
      "sM41KiAAAAAJ",
      "0b7ZqlcAAAAJ",
      "q0AgQ2MAAAAJ",
      "cGrUZpwAAAAJ",
      "N4kcAKIAAAAJ",
      "fmwchbsAAAAJ",
      "-R2kv9MAAAAJ",
      "sdNtK6QAAAAJ",
      "m2-OwQEAAAAJ",
      "NdY_HacAAAAJ",
      "u3ogi00AAAAJ",
      "ZWH5jCwAAAAJ",
      "yN7CEicAAAAJ",
      "k0nZO90AAAAJ",
      "ADkiClQAAAAJ",
      "4j3sGYwAAAAJ",
      "xVB9askAAAAJ",
      "bda1zGQAAAAJ",
      "qWmCkDMAAAAJ",
      "7kaXqgMAAAAJ",
      "i27Wt-cAAAAJ",
      "ZxeB6xkAAAAJ",
      "8n5W2FMAAAAJ",
      "RnVPcI0AAAAJ",
      "91WQXlIAAAAJ",
      "b3HMX-sAAAAJ",
      "B4J3SkcAAAAJ",
      "mx0jp-YAAAAJ",
      "GRMLwjAAAAAJ",
      "UlXfwrkAAAAJ",
      "t41vrrQAAAAJ",
      "bOM9qN8AAAAJ",
      "-Km63D4AAAAJ",
      "o-PadiwAAAAJ",
      "DbrKNSQAAAAJ",
      "qJsC_XsAAAAJ",
      "U9nP_RcAAAAJ",
      "23uzLe0AAAAJ",
      "Nsxpe_kAAAAJ",
      "MB0OgPEAAAAJ",
      "U42j5MkAAAAJ",
      "_gfwCNwAAAAJ",
      "3p-KQUwAAAAJ",
      "yvhVTMgAAAAJ",
      "JL5DcncAAAAJ",
      "xdGKgtcAAAAJ",
      "naoTbnIAAAAJ",
      "nRM32-QAAAAJ",
      "8gw3UCMAAAAJ",
      "QY-earAAAAAJ",
      "nrcJfPEAAAAJ",
      "Fykyo9gAAAAJ",
      "nEUGF3YAAAAJ",
      "tQPt2LcAAAAJ",
      "cl7CnNYAAAAJ",
      "U5xRA6QAAAAJ",
      "tal4mMkAAAAJ",
      "7ja8HqUAAAAJ",
      "dPX0wQcAAAAJ",
      "lgHhJQ8AAAAJ",
      "X1-ovCkAAAAJ",
      "K-BdgNwAAAAJ",
      "gWocpdkAAAAJ",
      "tKlt2LgAAAAJ",
      "VNAFWVoAAAAJ",
      "STgsgLAAAAAJ",
      "O25d8jcAAAAJ",
      "zRy-zdAAAAAJ",
      "gpyHJmcAAAAJ",
      "NC1KaRwAAAAJ",
      "iuRC7jgAAAAJ",
      "JeXmlI0AAAAJ",
      "kc4-e8oAAAAJ",
      "VrswntoAAAAJ",
      "-0YOKRoAAAAJ",
      "-cCry1cAAAAJ",
      "mezKJyoAAAAJ",
      "D3BKoHMAAAAJ",
      "xAFGASEAAAAJ",
      "3Q8LdcYAAAAJ",
      "Km1V8WwAAAAJ",
      "wADiNucAAAAJ",
      "VK4ytuIAAAAJ",
      "pr6rIJEAAAAJ",
      "9uWuZkUAAAAJ",
      "H-KEzkUAAAAJ",
      "wZFmjwYAAAAJ",
      "IhhuIZcAAAAJ",
      "2kwHHWMAAAAJ",
      "Hahkg24AAAAJ",
      "O1DeDyEAAAAJ",
      "X2Qs7XYAAAAJ",
      "uT8fgagAAAAJ",
      "2kfmAzEAAAAJ",
      "pwUdiCYAAAAJ",
      "w4UK_9kAAAAJ",
      "dfddm3cAAAAJ",
      "cjUid0YAAAAJ",
      "QKw1XxAAAAAJ",
      "-6Pj3IYAAAAJ",
      "MBM_oOUAAAAJ",
      "Jkss014AAAAJ",
      "XXNAaWQAAAAJ",
      "vRkNXhwAAAAJ",
      "DytvG6cAAAAJ",
      "-Z4XFnEAAAAJ",
      "1p3dDesAAAAJ",
      "BSJyuqQAAAAJ",
      "IOxo6sIAAAAJ",
      "S2vB4tAAAAAJ",
      "LiqLdKYAAAAJ",
      "2Dymb8oAAAAJ",
      "STnhSioAAAAJ",
      "rIUE-FoAAAAJ",
      "aa5Ou7gAAAAJ",
      "vswo4rQAAAAJ",
      "k5RXEZYAAAAJ",
      "LTKmex0AAAAJ",
      "Bkq-JK8AAAAJ",
      "Nd6tX_kAAAAJ",
      "WgAGy7wAAAAJ",
      "3N7aVh8AAAAJ",
      "d87RjDgAAAAJ",
      "Nn_Ee0IAAAAJ",
      "E-oOiwwAAAAJ",
      "Glo43TUAAAAJ",
      "h4kYmRYAAAAJ",
      "DV8z8DYAAAAJ",
      "fMN7wNwAAAAJ",
      "0hHqYoAAAAAJ",
      "n6GdeeIAAAAJ",
      "i6tMWAoAAAAJ",
      "MzAzFm8AAAAJ",
      "1pFBWgoAAAAJ",
      "SSTIBK0AAAAJ",
      "FecYwZ0AAAAJ",
      "vc_x1E0AAAAJ",
      "tbbfR50AAAAJ",
      "ZSRwsn6tjckC",
      "-e6KzSUAAAAJ",
      "Dj3gptkAAAAJ",
      "p28z3SQAAAAJ",
      "l96zhjwAAAAJ",
      "LphRgywAAAAJ",
      "cB7hK3sAAAAJ",
      "n63DmP8AAAAJ",
      "d53muYsAAAAJ",
      "spWVns8AAAAJ",
      "_td9cSEAAAAJ",
      "hjTzNuQAAAAJ",
      "9aA5QTUAAAAJ",
      "_ruE6kgAAAAJ",
      "fHfJh9cAAAAJ",
      "nBcay4oAAAAJ",
      "qhu-DxwAAAAJ",
      "GoarRRwAAAAJ",
      "t9iq5TwAAAAJ",
      "viFEu_8AAAAJ",
      "BCKhEoAAAAAJ",
      "AH5j40kAAAAJ",
      "cWMhYJcAAAAJ",
      "1RElnvEAAAAJ",
      "vjPJvwYAAAAJ",
      "Ggudr9EAAAAJ",
      "twlFI3sAAAAJ",
      "Jek-NhkAAAAJ",
      "TmbrLRMAAAAJ",
      "uQg2t8EAAAAJ",
      "mCuJP1UAAAAJ",
      "trMUyZIAAAAJ",
      "fcqkLtcAAAAJ",
      "XwutB1AAAAAJ",
      "QF_rhCIAAAAJ",
      "212SLn0AAAAJ",
      "Bj1tRlsAAAAJ",
      "6rjdDasAAAAJ",
      "Npd4ZzgAAAAJ",
      "eSOXB6IAAAAJ",
      "c4XKzcIAAAAJ",
      "Jt1tl0YAAAAJ",
      "QHS_pZAAAAAJ",
      "EIAYEl4AAAAJ",
      "O-tJRckAAAAJ",
      "Es-YRKMAAAAJ",
      "dOad5HoAAAAJ",
      "Yc94070AAAAJ",
      "85XK-uAAAAAJ",
      "WKsaDwQAAAAJ",
      "Fsz9BAUAAAAJ",
      "sjaZfDIAAAAJ",
      "gYiCq88AAAAJ",
      "Zu68lkkAAAAJ",
      "uobCsQgAAAAJ",
      "p6DCMrQAAAAJ",
      "MB7c7CYAAAAJ",
      "XTaVGqYAAAAJ",
      "hI5X8UYAAAAJ",
      "yK4caV0AAAAJ",
      "bmZbi_UNs-oC",
      "0YstIVMAAAAJ",
      "KMqMQAcAAAAJ",
      "emo91rIAAAAJ",
      "PW6eQ6YAAAAJ",
      "HG08FCMAAAAJ",
      "xPhnaK0AAAAJ",
      "8PR-AaoAAAAJ",
      "uBFV6SUAAAAJ",
      "U8nclXkAAAAJ",
      "ykWqS0YAAAAJ",
      "kamjbL0AAAAJ",
      "PCUwf-8AAAAJ",
      "0ncQNL8AAAAJ",
      "4mVPFQ8AAAAJ",
      "Yy6WaDkAAAAJ",
      "pDkhB5EAAAAJ",
      "BqV8LaoAAAAJ",
      "E9EgKkMAAAAJ",
      "kQ0HeQIAAAAJ",
      "idOI-IAAAAAJ",
      "YatAkqAAAAAJ",
      "p2ttvlEAAAAJ",
      "b_svo9QAAAAJ",
      "RJ_c4xkAAAAJ",
      "ZvFaPxUAAAAJ",
      "YGQs1AYAAAAJ",
      "PEzAWAwAAAAJ",
      "8BeTDr0AAAAJ",
      "kppa2vgAAAAJ",
      "ATnKn1UAAAAJ",
      "-ltRSM0AAAAJ",
      "3t2upi8AAAAJ",
      "PpzsjioAAAAJ",
      "ohL-Y50AAAAJ",
      "KiQW8wMAAAAJ",
      "xEFh0AgAAAAJ",
      "Ak7gyjQAAAAJ",
      "Xdnc5IMAAAAJ",
      "jWIWqfcAAAAJ",
      "Ar4h7jkAAAAJ",
      "rb6gXycAAAAJ",
      "IMAwpekAAAAJ",
      "G7XaqUcAAAAJ",
      "Y3pGXxwAAAAJ",
      "zujScxwAAAAJ",
      "POWKkqEAAAAJ",
      "7eLKa3IAAAAJ",
      "wS0qP_MAAAAJ",
      "TrdtzgwAAAAJ",
      "NxrQ794AAAAJ",
      "-VQxD1UAAAAJ",
      "LVOGjXYAAAAJ",
      "J7QDRmwAAAAJ",
      "TxVfH8QAAAAJ",
      "DJEiH1IAAAAJ",
      "jkV6H1gAAAAJ",
      "Kn3znAMAAAAJ",
      "a2jB6z0AAAAJ",
      "KDqGTIUAAAAJ",
      "L4bNmsMAAAAJ",
      "U71Ps4kAAAAJ",
      "dT7yOrwAAAAJ",
      "nI2oJqkAAAAJ",
      "YjPIezoAAAAJ",
      "qOFs67oAAAAJ",
      "4CcAPCgAAAAJ",
      "PiZymREAAAAJ",
      "AkgfxXUAAAAJ",
      "BbzYzsgAAAAJ",
      "xMvt3NEAAAAJ",
      "aJ_Fr4MAAAAJ",
      "Um4ZbbgAAAAJ",
      "iCdq_ZsAAAAJ",
      "EzMN4zkAAAAJ",
      "C1H80hoAAAAJ",
      "sNGk-9MAAAAJ",
      "fgDB2BoAAAAJ",
      "QkYiDCwAAAAJ",
      "bLb3VdIAAAAJ",
      "Zau87Y0AAAAJ",
      "-SfNafoAAAAJ",
      "baDPMxkAAAAJ",
      "vaSdahkAAAAJ",
      "abUmi6QAAAAJ",
      "okfWOCsAAAAJ",
      "blTzjfsAAAAJ",
      "lu2yOLkAAAAJ",
      "J7fyX_sAAAAJ",
      "z_1mfIkAAAAJ",
      "u-OHPhAAAAAJ",
      "mATAz-wAAAAJ",
      "eYg0_cEAAAAJ",
      "Xsn1VsgAAAAJ",
      "l4lTuMcAAAAJ",
      "U4tFPMQAAAAJ",
      "nHh9PSsAAAAJ",
      "owcAYmEAAAAJ",
      "Td0j6cUAAAAJ",
      "Cgx9W6UAAAAJ",
      "bYhGFrwAAAAJ",
      "Q1W6RzMAAAAJ",
      "MocRuzIAAAAJ",
      "ETGZXo4AAAAJ",
      "S9LHLKEAAAAJ",
      "KOrhfVMAAAAJ",
      "eml8HfQAAAAJ",
      "FHwvVmkAAAAJ",
      "g558OVoAAAAJ",
      "6G8BRLsAAAAJ",
      "dto2FacAAAAJ",
      "LBEIm8gAAAAJ",
      "bKMKO_AAAAAJ",
      "VoyeryMAAAAJ",
      "HJHSuxUAAAAJ",
      "OMo39G8AAAAJ",
      "I-rLzGcAAAAJ",
      "qU1NHTwAAAAJ",
      "CDPa3AgAAAAJ",
      "K9_XuM8AAAAJ",
      "-wflT2wAAAAJ",
      "EpT5sLAAAAAJ",
      "cGvYY4YAAAAJ",
      "qHG9PB8AAAAJ",
      "7C7SiMEAAAAJ",
      "aEOTSMEAAAAJ",
      "C5D_E04AAAAJ",
      "sOzdfjYAAAAJ",
      "jZgjlGUAAAAJ",
      "VFQRIOwAAAAJ",
      "IcasIiwAAAAJ",
      "plJC8R0AAAAJ",
      "mmEb3AwAAAAJ",
      "MBKRLlgAAAAJ",
      "JSv1FOYAAAAJ",
      "IpkkT5oAAAAJ",
      "c1FYGAQAAAAJ",
      "n1grp7EAAAAJ",
      "6Vt1qbwAAAAJ",
      "RHXdl6EAAAAJ",
      "1uucMrsAAAAJ",
      "h-3xd3EAAAAJ",
      "fwJ4_WUAAAAJ",
      "Dq93mOUAAAAJ",
      "GyvseMkAAAAJ",
      "j8JGVvoAAAAJ",
      "5i2hUToAAAAJ",
      "N3wwcYYAAAAJ",
      "1k8gBxEAAAAJ",
      "5PS-lv8AAAAJ",
      "_AoZDGEAAAAJ",
      "qpD0AVMAAAAJ",
      "uDP7UX0AAAAJ",
      "kuIqfXkAAAAJ",
      "EaMsuB0AAAAJ",
      "FxyRWlcAAAAJ",
      "tAK5l1IAAAAJ",
      "LWrdpCsAAAAJ",
      "O3gezzcAAAAJ",
      "qff5rRYAAAAJ",
      "0ZA7y4UAAAAJ",
      "vvUmC_EAAAAJ",
      "CotFJJsAAAAJ",
      "O_PbKNMAAAAJ",
      "q5GIWC0AAAAJ",
      "8HdRoroAAAAJ",
      "TbUEDGIAAAAJ",
      "YlmiyYkAAAAJ",
      "z2F7CSEAAAAJ",
      "9QO16LcAAAAJ",
      "6p0ygKUAAAAJ",
      "h0pQOHgAAAAJ",
      "u1Qs7YIAAAAJ",
      "Ou5x9LkAAAAJ",
      "iNcA81MAAAAJ",
      "HTf7H58AAAAJ",
      "rZtxlqAAAAAJ",
      "0kTel90AAAAJ",
      "cXkm3rsAAAAJ",
      "6sI8lowAAAAJ",
      "BzyVxVUAAAAJ",
      "fU63KdQAAAAJ",
      "OuSPv-AAAAAJ",
      "h2L2Xp0AAAAJ",
      "WsM7ybkAAAAJ",
      "bRT7t28AAAAJ",
      "YP9KtBQAAAAJ",
      "zKORw8wAAAAJ",
      "OPlpj2YAAAAJ",
      "CAfsMIsAAAAJ",
      "jUOcawkAAAAJ",
      "-xwtUkYAAAAJ",
      "5lB_d78AAAAJ",
      "gCbeGRIAAAAJ",
      "fMEMNKMAAAAJ",
      "17UDvBAAAAAJ",
      "Kc8zXcgAAAAJ",
      "6OfjaHQAAAAJ",
      "hm9dWCsAAAAJ",
      "k8rlJ8AAAAAJ",
      "oUmv8xgAAAAJ",
      "XW62DrcAAAAJ",
      "IiSNwnAAAAAJ",
      "B_rKfusAAAAJ",
      "yZS4ce8AAAAJ",
      "RK72t68AAAAJ",
      "IQ3hcw4AAAAJ",
      "j67B9Q4AAAAJ",
      "lAiZXhYAAAAJ",
      "hYMvCbwAAAAJ",
      "9GJn5FIAAAAJ",
      "Sc2tw28AAAAJ",
      "Q7VKnRYAAAAJ",
      "vWTI60AAAAAJ",
      "k2DcM6IAAAAJ",
      "tgfOQwEAAAAJ",
      "UvponD8AAAAJ",
      "HfGUt6AAAAAJ",
      "hrI8aH8AAAAJ",
      "Nt4rO1EAAAAJ",
      "8gfs8XIAAAAJ",
      "FTx_BNsAAAAJ",
      "SqsLFwMAAAAJ",
      "KVUCqGwAAAAJ",
      "FDpwmgQAAAAJ",
      "mNfCP3gAAAAJ",
      "UzTo6o4AAAAJ",
      "oDDqnQ4AAAAJ",
      "IgWjDugAAAAJ",
      "kde_TOYAAAAJ",
      "QkpYowMAAAAJ",
      "TH5szrcAAAAJ",
      "KcM-4NsAAAAJ",
      "u8p5Y1EAAAAJ",
      "NMPUDa0AAAAJ",
      "un0eGzEAAAAJ",
      "ScxqPn4AAAAJ",
      "kTZ5VE0AAAAJ",
      "Owy8RMEAAAAJ",
      "5fU-QMwAAAAJ",
      "2MOwmwYAAAAJ",
      "d77eUbgAAAAJ",
      "N1q-egYAAAAJ",
      "_6XYKXMpK34C",
      "5IzwG1AAAAAJ",
      "asRzBf4AAAAJ",
      "9sCGe-gAAAAJ",
      "0MkHY9cAAAAJ",
      "RHV5YCkAAAAJ",
      "FsBCAfgAAAAJ",
      "kmGkycYAAAAJ",
      "vcw0TJIAAAAJ",
      "1YBLp6MAAAAJ",
      "O-3bc_EAAAAJ",
      "8O8MQEUAAAAJ",
      "Alsv0h8AAAAJ",
      "-1nmmKgAAAAJ",
      "h5IXxToAAAAJ",
      "_GgST9AAAAAJ",
      "l1uvSZIAAAAJ",
      "8d8jP60AAAAJ",
      "HDzOsYAAAAAJ",
      "g3McheUAAAAJ",
      "4zyy7esAAAAJ",
      "A3ObLdMAAAAJ",
      "A3wg18wAAAAJ",
      "Mbg9vJMAAAAJ",
      "3JrkBn4AAAAJ",
      "H3ZnCqYAAAAJ",
      "TmAQaboAAAAJ",
      "QkWtGNkAAAAJ",
      "w8JK9v0AAAAJ",
      "qoFYHTMAAAAJ",
      "HSPbKTAAAAAJ",
      "559LF80AAAAJ",
      "MvKQ0B4AAAAJ",
      "ipTsozQAAAAJ",
      "7nlvOMQAAAAJ",
      "8UinjA0AAAAJ",
      "kQisE-gAAAAJ",
      "cMDQJIoAAAAJ",
      "culGbtkAAAAJ",
      "LAIIfV0AAAAJ",
      "YizAq4gAAAAJ",
      "k7aMOCsAAAAJ",
      "W0H5bc0AAAAJ",
      "pnypNygAAAAJ",
      "IxCZDBQAAAAJ",
      "ep52oxEAAAAJ",
      "1XbRknQAAAAJ",
      "wEFxCvMAAAAJ",
      "LyQ0SoMAAAAJ",
      "1mKHwfIAAAAJ",
      "kbN88gsAAAAJ",
      "X9fd67gAAAAJ",
      "V6rOl-gAAAAJ",
      "BA0BaS4AAAAJ",
      "fjuWXroAAAAJ",
      "PbEw81gAAAAJ",
      "2y5YF-gAAAAJ",
      "II8VI8IAAAAJ",
      "1VI_oYUAAAAJ",
      "fa193PsAAAAJ",
      "iccBxJIAAAAJ",
      "nTiSnwUAAAAJ",
      "YMaEuzoAAAAJ",
      "wPNgzO4AAAAJ",
      "BxkylVAAAAAJ",
      "cQ1P1qoAAAAJ",
      "jERkdhIAAAAJ",
      "SY6gzIgAAAAJ",
      "q34R9psAAAAJ",
      "r-mWYj0AAAAJ",
      "C1FZEtkAAAAJ",
      "MGXRuXYAAAAJ",
      "cYReSuEAAAAJ",
      "Xmv0998AAAAJ",
      "02kSQ3IAAAAJ",
      "sPlonWcAAAAJ",
      "KeltSA4AAAAJ",
      "_THez4oAAAAJ",
      "4YL23GMAAAAJ",
      "dZJy8_8AAAAJ",
      "ygM8WtMAAAAJ",
      "Ch9iRwQAAAAJ",
      "rJvU7ngAAAAJ",
      "jxF7YgYAAAAJ",
      "66cQtjcAAAAJ",
      "yIg7b2gAAAAJ",
      "Wsru2ZYAAAAJ",
      "0KvXR0AAAAAJ",
      "F24vXggAAAAJ",
      "SWQxcO8AAAAJ",
      "MaSXNhUAAAAJ",
      "te2go-MAAAAJ",
      "YZHj-Y4AAAAJ",
      "n8w3bg8AAAAJ",
      "Pkj8OSoAAAAJ",
      "RoGOW9AAAAAJ",
      "6T1XtW8AAAAJ",
      "4hda5e8AAAAJ",
      "w24_ETkAAAAJ",
      "HFwSkGIAAAAJ",
      "B2YRmGgAAAAJ",
      "Znp3UkEAAAAJ",
      "lHPTxGsAAAAJ",
      "E8DVVYQAAAAJ",
      "l2pAq_0AAAAJ",
      "61lw9YIAAAAJ",
      "cht-q2UAAAAJ",
      "lMAcwtwAAAAJ",
      "qMDr8HUAAAAJ",
      "q3EGms8AAAAJ",
      "JCrug-YAAAAJ",
      "kgsF7uEAAAAJ",
      "AgN0kSEAAAAJ",
      "hZhJhmIAAAAJ",
      "uqWkLzMAAAAJ",
      "bWTPrLEAAAAJ",
      "BQ_S4vMAAAAJ",
      "iDq2Hu8AAAAJ",
      "cwGB7lwAAAAJ",
      "MDIyLnwAAAAJ",
      "PqQAVcAAAAAJ",
      "ObkOmdMAAAAJ",
      "Q0mfsAMAAAAJ",
      "2FmzuDMAAAAJ",
      "YMgdDBwAAAAJ",
      "exClNSsAAAAJ",
      "gQOKAggAAAAJ",
      "RjScbooAAAAJ",
      "0koVxB4AAAAJ",
      "vKflaosAAAAJ",
      "B96GkdgAAAAJ",
      "XYtB2GUAAAAJ",
      "gq138e4AAAAJ",
      "i3pEsbgAAAAJ",
      "uvsSrnoAAAAJ",
      "s1X82zMAAAAJ",
      "uc4Q6bYAAAAJ",
      "B48DDQoAAAAJ",
      "9MsdbKoAAAAJ",
      "OBLWtdcAAAAJ",
      "azSz1VYAAAAJ",
      "F2gY_WkAAAAJ",
      "kI2nR5gAAAAJ",
      "Zfzp_GIAAAAJ",
      "2Dt0VJ4AAAAJ",
      "OtEdQpcAAAAJ",
      "s165sfUAAAAJ",
      "bsqhvmAAAAAJ",
      "8RgDBoEAAAAJ",
      "5NGAbT4AAAAJ",
      "cAYgoH4AAAAJ",
      "9RJdEXMAAAAJ",
      "VgbZ7z8AAAAJ",
      "z7tPc9IAAAAJ",
      "nrE1OroAAAAJ",
      "nZsD8XwAAAAJ",
      "PH5VIGIAAAAJ",
      "hnf_dHwAAAAJ",
      "cTIwrjoAAAAJ",
      "RLvsC94AAAAJ",
      "NLLMDCkAAAAJ",
      "7qdaJT8AAAAJ",
      "eRCF2KsAAAAJ",
      "VIFfuYgAAAAJ",
      "LCzQ6GMAAAAJ",
      "lTXMC44AAAAJ",
      "tk0e5lYAAAAJ",
      "xEidIpMAAAAJ",
      "6UIvmp4AAAAJ",
      "7lP7XcMAAAAJ",
      "Z9gvBegAAAAJ",
      "58ShSfwAAAAJ",
      "JS7sVyQAAAAJ",
      "C_4IMR4AAAAJ",
      "1wzEtxcAAAAJ",
      "wVGqmWkAAAAJ",
      "yW593xUAAAAJ",
      "a4t8q5MAAAAJ",
      "SJE16yoAAAAJ",
      "QIp7IMUAAAAJ",
      "ov9EcNEAAAAJ",
      "VnJUnMoAAAAJ",
      "JgO4NqIAAAAJ",
      "4fOVJ7UAAAAJ",
      "YCtmdaMAAAAJ",
      "I1EvjZsAAAAJ",
      "RYvdtGcAAAAJ",
      "lkPKfjgAAAAJ",
      "u4epKYoAAAAJ",
      "qxkui7UAAAAJ",
      "4DUcuysAAAAJ",
      "JwiByPoAAAAJ",
      "GPRnVkMAAAAJ",
      "WY8DOSMAAAAJ",
      "yzU6g24AAAAJ",
      "ePfXtkoAAAAJ",
      "B1Dy3WMAAAAJ",
      "EqKRQ4YAAAAJ",
      "rmCtisEAAAAJ",
      "vYUDlsEAAAAJ",
      "Z8U0BwcAAAAJ",
      "ZUEtS-EAAAAJ",
      "qd06pUgAAAAJ",
      "cSTLkv8AAAAJ",
      "KwjvGLUAAAAJ",
      "D22GptUAAAAJ",
      "j_xavDQAAAAJ",
      "VJODuGkAAAAJ",
      "332L1coAAAAJ",
      "o0qh7IUAAAAJ",
      "GsWe1fgAAAAJ",
      "jBvRff0AAAAJ",
      "xjzc-TwAAAAJ",
      "ZYc-LuMAAAAJ",
      "rUiWchkAAAAJ",
      "Ke__1Z8AAAAJ",
      "z8tUc2IAAAAJ",
      "fWCoyDcAAAAJ",
      "iTsZVuoAAAAJ",
      "PeCI8KcAAAAJ",
      "wUUxGfAAAAAJ",
      "e8Gzgo4AAAAJ",
      "lJCOQ1cAAAAJ",
      "H6ArRNYAAAAJ",
      "bO45VHYAAAAJ",
      "qVuN4MIAAAAJ",
      "LG_E-4EAAAAJ",
      "jIs-Y2gAAAAJ",
      "qQMFzBgAAAAJ",
      "rrJTgX0AAAAJ",
      "ilJgXHkAAAAJ",
      "ANBocsYAAAAJ",
      "RhtDZvYAAAAJ",
      "KlrXkXkAAAAJ",
      "D9eVSd8AAAAJ",
      "r21asW4AAAAJ",
      "SazwWasAAAAJ",
      "YArRsvEAAAAJ",
      "DEncVcYAAAAJ",
      "icbo4M0AAAAJ",
      "df-THM0AAAAJ",
      "1EW9Jt4AAAAJ",
      "LNXEjT8AAAAJ",
      "1pnp1ZAAAAAJ",
      "sDjp1K8AAAAJ",
      "eTOMoMYAAAAJ",
      "68HhxmAAAAAJ",
      "-QZbHHoAAAAJ",
      "-8QcdvgAAAAJ",
      "ycTTxNUAAAAJ",
      "uCZ7fPUAAAAJ",
      "R6jgG94AAAAJ",
      "lc7OkdAAAAAJ",
      "mDtSdp0AAAAJ",
      "RIeAomMAAAAJ",
      "LNHbZR0AAAAJ",
      "SLISZFAAAAAJ",
      "RJEQriwAAAAJ",
      "2KQlie4AAAAJ",
      "TB6o7YsAAAAJ",
      "knzWGD4AAAAJ",
      "8U7d-_MAAAAJ",
      "jJRiZR8AAAAJ",
      "k9uWzAIAAAAJ",
      "53OPcJ4AAAAJ",
      "_tDXYaYAAAAJ",
      "QsI17JQAAAAJ",
      "nJJ44zoAAAAJ",
      "qsB2vcgAAAAJ",
      "R4EFw_AAAAAJ",
      "tfN6V84AAAAJ",
      "nVsOPtQAAAAJ",
      "o7zbCEsAAAAJ",
      "kUcQkpMAAAAJ",
      "I0nj-TcAAAAJ",
      "FF3Sp4QAAAAJ",
      "5o88MDIAAAAJ",
      "pEDJ-8cAAAAJ",
      "13Puu8AAAAAJ",
      "5f47GEsAAAAJ",
      "K-6ujU4AAAAJ",
      "iwN7GtoAAAAJ",
      "E2Ur1NwAAAAJ",
      "A3GVtGAAAAAJ",
      "Qhe5ua0AAAAJ",
      "1KvNUWgAAAAJ",
      "FyZbyIUAAAAJ",
      "UnDvzw0AAAAJ",
      "X0RVX3AAAAAJ",
      "vkWBb2wAAAAJ",
      "3PJeg1wAAAAJ",
      "J5gGsg0AAAAJ",
      "jW80JWEAAAAJ",
      "d9s3sbQAAAAJ",
      "HH5gtyoAAAAJ",
      "5Uz70IoAAAAJ",
      "wBMRRk0AAAAJ",
      "vtuhhp8AAAAJ",
      "BU6f7L4AAAAJ",
      "9vMpR9UAAAAJ",
      "MzauO7cAAAAJ",
      "7D7IaJ4AAAAJ",
      "yFMX138AAAAJ",
      "RsicLQsAAAAJ",
      "CPuApzoAAAAJ",
      "fopP3AsAAAAJ",
      "57jIWn8AAAAJ",
      "Lt4tmL8AAAAJ",
      "6aWRAPkAAAAJ",
      "N3J70KkAAAAJ",
      "4QZmEqsAAAAJ",
      "cdx_NQIAAAAJ",
      "9aaeCToAAAAJ",
      "D83Vz00AAAAJ",
      "UnEHCNkAAAAJ",
      "Zl9ZzTAAAAAJ",
      "gSLAdnEAAAAJ",
      "QKgg5j4AAAAJ",
      "nQaxVCsAAAAJ",
      "NbVgjv0AAAAJ",
      "ZlNq4_4AAAAJ",
      "7HDE1ZwAAAAJ",
      "RSIlobgAAAAJ",
      "w3KgvQIAAAAJ",
      "D7bpRJ8AAAAJ",
      "-9acvogAAAAJ",
      "aP5VahUAAAAJ",
      "WqF5JigAAAAJ",
      "j4pcHV4AAAAJ",
      "dzyzDRIAAAAJ",
      "wKvaIJgAAAAJ",
      "saWjkLQAAAAJ",
      "hE2mTp4AAAAJ",
      "M3yUD0cAAAAJ",
      "wYDbtFsAAAAJ",
      "jGymlOMAAAAJ",
      "AxzVaI8AAAAJ",
      "MhQPCk8AAAAJ",
      "PnVYoI4AAAAJ",
      "0JH6YbEAAAAJ",
      "sPzla6IAAAAJ",
      "erv7TP0AAAAJ",
      "IyoEsBQAAAAJ",
      "Kq0dhLAAAAAJ",
      "akuWIJQAAAAJ",
      "2o3QdBAAAAAJ",
      "tgm2Y7oAAAAJ",
      "XEgaCScAAAAJ",
      "T1pWaCsAAAAJ",
      "PYrd2GMAAAAJ",
      "yxUduqMAAAAJ",
      "HKGYvu4AAAAJ",
      "q4qDvAoAAAAJ",
      "8kA3eDwAAAAJ",
      "TCYAoF8AAAAJ",
      "izKFQycAAAAJ",
      "wWWEwk0AAAAJ",
      "5KLRGb0AAAAJ",
      "tVPWAKIAAAAJ",
      "k6TEw8kAAAAJ",
      "z5SPCmgAAAAJ",
      "Yw2PquQAAAAJ",
      "n41KN9AAAAAJ",
      "nzS2jrMAAAAJ",
      "edQgLXcAAAAJ",
      "3rF9gtAAAAAJ",
      "ETU-ePAAAAAJ",
      "p9zVBV4AAAAJ",
      "n4bdAtIAAAAJ",
      "ofMZr0IAAAAJ",
      "wMx_Eu4AAAAJ",
      "uxSj18QAAAAJ",
      "lDjk14QAAAAJ",
      "d0TfP8EAAAAJ",
      "4PqxB3gAAAAJ",
      "k7NgVSUAAAAJ",
      "x1cDFYsAAAAJ",
      "ISRNX3gAAAAJ",
      "Ew_nVXEAAAAJ",
      "bRWa8q8AAAAJ",
      "4l2EoB0AAAAJ",
      "S1jUhokAAAAJ",
      "5ErX8dMAAAAJ",
      "eaZS9_YAAAAJ",
      "9GMg6q8AAAAJ",
      "MM4XdKsAAAAJ",
      "GOUpm_oAAAAJ",
      "owqhKD8AAAAJ",
      "-1fU6P0AAAAJ",
      "F4FxpRoAAAAJ",
      "462OoekAAAAJ",
      "0KyeZ2QAAAAJ",
      "6GhZedEAAAAJ",
      "lutJce0AAAAJ",
      "zHXnq0IAAAAJ",
      "nc8HAeIAAAAJ",
      "aWiMKLsAAAAJ",
      "K4bCJYcAAAAJ",
      "pTvhQDQAAAAJ",
      "TKmKZSAAAAAJ",
      "jUCiLN4AAAAJ",
      "FWztzhcAAAAJ",
      "DU-xHpQAAAAJ",
      "pndDsyoAAAAJ",
      "jWWx33IAAAAJ",
      "uglffdcAAAAJ",
      "W7yeGUoAAAAJ",
      "WoSEVJUAAAAJ",
      "PUmV3bwAAAAJ",
      "Y7Rm3DYAAAAJ",
      "qRd8Hh4AAAAJ",
      "Sp6mXKsAAAAJ",
      "pouyVyUAAAAJ",
      "QHZBakwAAAAJ",
      "2BnMsFIAAAAJ",
      "qOC97ysAAAAJ",
      "vEYl-MUAAAAJ",
      "SIxd6jgAAAAJ",
      "I2W13z0AAAAJ",
      "Ooc7UNUAAAAJ",
      "lpswgyIAAAAJ",
      "NUv7u80AAAAJ",
      "FMJePIUAAAAJ",
      "YaEJbvYAAAAJ",
      "2DjuFy8AAAAJ",
      "OVdu5IEAAAAJ",
      "9BGzHdUAAAAJ",
      "-L0XFlMAAAAJ",
      "dTkWR0MAAAAJ",
      "3J4zb7gAAAAJ",
      "IeuLakwAAAAJ",
      "oYlo1ycAAAAJ",
      "2aEdHz0AAAAJ",
      "l7nsfT4AAAAJ",
      "Lz6YRtEAAAAJ",
      "7-TwsxsAAAAJ",
      "bMTBja0AAAAJ",
      "t11U6_sAAAAJ",
      "tsXh_hwAAAAJ",
      "zW32dXsAAAAJ",
      "s9B5sagAAAAJ",
      "96mJbhwAAAAJ",
      "sDHHglIAAAAJ",
      "FF6YBwwAAAAJ",
      "RKd3704AAAAJ",
      "WfS41RAAAAAJ",
      "cdpb5UcAAAAJ",
      "UyZL660AAAAJ",
      "obgiWfUAAAAJ",
      "sCEl8r-n5VEC",
      "IvgxG60AAAAJ",
      "KmlxiiyySHIC",
      "7YSki00AAAAJ",
      "DC7FtVYAAAAJ",
      "gxL7aZQAAAAJ",
      "oF46lMIAAAAJ",
      "MCClSvsAAAAJ",
      "FXw6xXcAAAAJ",
      "kIsmHd4AAAAJ",
      "mII-l2cAAAAJ",
      "pM1yxtsAAAAJ",
      "ACjYGPUAAAAJ",
      "_z41TLwAAAAJ",
      "YULFeN0AAAAJ",
      "eG10MqcAAAAJ",
      "D7WH8ksAAAAJ",
      "C2_ZXdcAAAAJ",
      "uJvw2KUAAAAJ",
      "O27t9j4AAAAJ",
      "8IMaM0QAAAAJ",
      "tFq6hXAAAAAJ",
      "LFyg0tAAAAAJ",
      "OMVTRscAAAAJ",
      "Iq0KSBYAAAAJ",
      "0eR4Lt0AAAAJ",
      "44-qrTIAAAAJ",
      "SqHX4UgAAAAJ",
      "3fvu4fcAAAAJ",
      "rqoFm6sAAAAJ",
      "U66RsYsAAAAJ",
      "HiyW7J4AAAAJ",
      "-3yFcsMAAAAJ",
      "IYUPj9MAAAAJ",
      "bg92wVEAAAAJ",
      "RRzVwKkAAAAJ",
      "PNH24toAAAAJ",
      "I1D9ig8AAAAJ",
      "O7MZStwAAAAJ",
      "_4i-G3YAAAAJ",
      "uMbvldoAAAAJ",
      "-Cy0nZ8AAAAJ",
      "2ItLnFgAAAAJ",
      "eqQQkM4AAAAJ",
      "np0OO24AAAAJ",
      "J8TSTXMAAAAJ",
      "KNQoLcMAAAAJ",
      "kMFnJxgAAAAJ",
      "Plv4gH4AAAAJ",
      "KNiO4pwAAAAJ",
      "bQzoxtsAAAAJ",
      "D-RwB3YAAAAJ",
      "in8fQ10AAAAJ",
      "8mvohP8AAAAJ",
      "9_AUwFUAAAAJ",
      "B9g1lS8AAAAJ",
      "NSbws80AAAAJ",
      "hou2DHoAAAAJ",
      "-qSroKoAAAAJ",
      "d3rRkqcAAAAJ",
      "t8v3JXsAAAAJ",
      "8gEhRVgAAAAJ",
      "UdpacsMAAAAJ",
      "1I0ff2cAAAAJ",
      "L3zNUG4AAAAJ",
      "07IPOvMAAAAJ",
      "2P-Q09UAAAAJ",
      "uj1OljkAAAAJ",
      "1ROPmVQAAAAJ",
      "-KdNGwgAAAAJ",
      "tUrNjFcAAAAJ",
      "S3gQoMgAAAAJ",
      "EWi-CL4AAAAJ",
      "KhAJWroAAAAJ",
      "4BEvaw8AAAAJ",
      "MVUbYCkAAAAJ",
      "hKjmnDUAAAAJ",
      "Av2Iuu0AAAAJ",
      "ftI1lBQAAAAJ",
      "Jq8ZS5kAAAAJ",
      "IjVj4hsAAAAJ",
      "odMFlXUAAAAJ",
      "kUbCuLgAAAAJ",
      "X3JCGVIAAAAJ",
      "xRuVTW4AAAAJ",
      "_WnkXlkAAAAJ",
      "uGkQKUIAAAAJ",
      "tUq_v90AAAAJ",
      "1T2Xh68AAAAJ",
      "cjr90bEAAAAJ",
      "OlpYP3UAAAAJ",
      "vjZrDKQAAAAJ",
      "Py4URJUAAAAJ",
      "YFNi7tsAAAAJ",
      "fZDywBkAAAAJ",
      "NT8lLwEAAAAJ",
      "1QKK-zgAAAAJ",
      "z3IRvDwAAAAJ",
      "Bj50SwkAAAAJ",
      "9rYWg2EAAAAJ",
      "_FZpPv0AAAAJ",
      "cojpd10AAAAJ",
      "rDfyQnIAAAAJ",
      "-VtT7q4AAAAJ",
      "fRwndxUAAAAJ",
      "36ofBJgAAAAJ",
      "Nla9qfUAAAAJ",
      "qL9o1Y0AAAAJ",
      "sua5tGwAAAAJ",
      "iz3e3X8AAAAJ",
      "54wdDqcAAAAJ",
      "hR9rFHgAAAAJ",
      "gLnCTgIAAAAJ",
      "AlTQrFcAAAAJ",
      "yx0pEmYAAAAJ",
      "sJDqACEAAAAJ",
      "JzK8uYAAAAAJ",
      "ytm_89IAAAAJ",
      "KmSuVtgAAAAJ",
      "SI6sQPYAAAAJ",
      "jhPhgf4AAAAJ",
      "0HNGHckAAAAJ",
      "z7l0wOcAAAAJ",
      "6Q6TCkkAAAAJ",
      "SCdhzWoAAAAJ",
      "23LELwEAAAAJ",
      "sktDNcEAAAAJ",
      "1Cv6Sf4AAAAJ",
      "eV2tuR8AAAAJ",
      "LO3pKmwAAAAJ",
      "BENt-uEAAAAJ",
      "J5hwfPwAAAAJ",
      "KUc7JJoAAAAJ",
      "DEtQ_YAAAAAJ",
      "aYHq31IAAAAJ",
      "yOcNQVgAAAAJ",
      "WHelTd0AAAAJ",
      "9rYWAhsAAAAJ",
      "HZPnJ9gAAAAJ",
      "NhJMwocAAAAJ",
      "d4W1UT0AAAAJ",
      "XRsGhZ4AAAAJ",
      "qRXIUuMAAAAJ",
      "tR-p-r8AAAAJ",
      "OttawxUAAAAJ",
      "PVty8PUAAAAJ",
      "sNeVyqoAAAAJ",
      "eIWg8NMAAAAJ",
      "4WEQ8h0AAAAJ",
      "Bh8bGCYAAAAJ",
      "HmbVzpoAAAAJ",
      "jNUBLwMAAAAJ",
      "GwR1fdsAAAAJ",
      "iBOqTdYAAAAJ",
      "1uT7-84AAAAJ",
      "WghUqGkAAAAJ",
      "0TJZPj0AAAAJ",
      "-DSn7-wAAAAJ",
      "J7vQ-QEAAAAJ",
      "On-ONT4AAAAJ",
      "I8kmeZYAAAAJ",
      "dJQf4SYAAAAJ",
      "Qxtj86kAAAAJ",
      "hdMznfMAAAAJ",
      "GvHOmQoAAAAJ",
      "-qS6zoJHb0IC",
      "ExJ1IooAAAAJ",
      "wr9RgmcAAAAJ",
      "MZHW6YMAAAAJ",
      "aJOeGRoAAAAJ",
      "53baCywAAAAJ",
      "h1zSzecAAAAJ",
      "zXQZPnMAAAAJ",
      "8juM0fYAAAAJ",
      "Z8-UfkUAAAAJ",
      "pfGI-KcAAAAJ",
      "bgmagbUAAAAJ",
      "w6hmCEYAAAAJ",
      "WAMYIpQAAAAJ",
      "zZ0-4SUAAAAJ",
      "fcThykUAAAAJ",
      "KGgOhbAAAAAJ",
      "bFNzhmwAAAAJ",
      "-rCpBEsAAAAJ",
      "GMvmr8QAAAAJ",
      "PDwwvrEAAAAJ",
      "kA_rSy4AAAAJ",
      "gnox0EsAAAAJ",
      "KFeN73wAAAAJ",
      "RCi98EAAAAAJ",
      "QdTErIEAAAAJ",
      "L__n1LUAAAAJ",
      "chD5XxkAAAAJ",
      "N5HDmqoAAAAJ",
      "O4_jWCsAAAAJ",
      "Qw72w48AAAAJ",
      "5FwRvZAAAAAJ",
      "hHYRga0AAAAJ",
      "EYo_WkEAAAAJ",
      "8TwcVQcAAAAJ",
      "5hlRYCIAAAAJ",
      "B3ywvIcAAAAJ",
      "CpFoJ1gAAAAJ",
      "5P2jxPQAAAAJ",
      "SO_j4zwAAAAJ",
      "P7ndQrkAAAAJ",
      "9QmGHaYAAAAJ",
      "cmC2pp0AAAAJ",
      "oB0g2IkAAAAJ",
      "DMTuJzAAAAAJ",
      "ntGll74AAAAJ",
      "UNxLPX8AAAAJ",
      "9cHjPDkAAAAJ",
      "8BX3BokAAAAJ",
      "r3NAa9oAAAAJ",
      "XalUZEoAAAAJ",
      "WXOaxKMAAAAJ",
      "GnTX_20AAAAJ",
      "g87CIwgAAAAJ",
      "6eHx7EgAAAAJ",
      "D1LEg-YAAAAJ",
      "m1qAiOUAAAAJ",
      "jbYnJLMAAAAJ",
      "POXzrBYAAAAJ",
      "wnweG9UAAAAJ",
      "R4dvN4oAAAAJ",
      "uTRczaUAAAAJ",
      "aHtfItQAAAAJ",
      "YfPA4YsAAAAJ",
      "5Rp2lKIAAAAJ",
      "6QpFL68AAAAJ",
      "pk-yb_kAAAAJ",
      "Dn_qYK8AAAAJ",
      "SWqd2rgAAAAJ",
      "E_a3VB4AAAAJ",
      "fY69CxIAAAAJ",
      "5tk1PV8AAAAJ",
      "xGI18C0AAAAJ",
      "j54VcVEAAAAJ",
      "bH1k38AAAAAJ",
      "AQ_I-NkAAAAJ",
      "GjCIDGQAAAAJ",
      "tRLUOBIAAAAJ",
      "hH3DA2YAAAAJ",
      "yfsR0k0AAAAJ",
      "LyHzJOMAAAAJ",
      "no_BfYgAAAAJ",
      "HxMQouAAAAAJ",
      "d7IuSpAAAAAJ",
      "CUkAtC4AAAAJ",
      "SKaPm_QAAAAJ",
      "B3QzwVAAAAAJ",
      "T7uctwYAAAAJ",
      "idC8YcsAAAAJ",
      "ThJ-Ju4AAAAJ",
      "MACCA0cAAAAJ",
      "v4UZWmcAAAAJ",
      "tQU8xu0AAAAJ",
      "351ivuQAAAAJ",
      "caAyffEAAAAJ",
      "Lkl8nQYAAAAJ",
      "x0NU7KEAAAAJ",
      "fqDBtzYAAAAJ",
      "rSMPsx4AAAAJ",
      "IAD0fQQAAAAJ",
      "iX-72m8AAAAJ",
      "rsBBj3IAAAAJ",
      "8R35rCwAAAAJ",
      "yXvXtrMAAAAJ",
      "NxBuRgcAAAAJ",
      "BHZT068AAAAJ",
      "8OYE6iEAAAAJ",
      "Dtw3YBoAAAAJ",
      "zX7fPHkAAAAJ",
      "WQXD3uAAAAAJ",
      "G3OMbFSm858C",
      "NjYyuQQAAAAJ",
      "p5LCHHEAAAAJ",
      "j-DQLQgAAAAJ",
      "9pI3MrEAAAAJ",
      "wTGk7TIAAAAJ",
      "244WszUAAAAJ",
      "GWkwfBIAAAAJ",
      "0IzM_20AAAAJ",
      "gI5FMw8AAAAJ",
      "DKfEcuEAAAAJ",
      "Bdlf-Z4AAAAJ",
      "MplR7_cAAAAJ",
      "OSg3D9MAAAAJ",
      "bqx3MAoAAAAJ",
      "jHEvHNYAAAAJ",
      "Hz7KBrIAAAAJ",
      "UuE08jUAAAAJ",
      "5b8D1MgAAAAJ",
      "aUeGl58AAAAJ",
      "gFLW9qcAAAAJ",
      "VEPTSCUAAAAJ",
      "ogXTOZ4AAAAJ",
      "bqKW7NkAAAAJ",
      "MbXKAK8AAAAJ",
      "t5lVb6sAAAAJ",
      "RPWFQlAAAAAJ",
      "pha24HQAAAAJ",
      "E9rg2eEAAAAJ",
      "w7t5xQsAAAAJ",
      "O7q6DkEAAAAJ",
      "Vs-MdPcAAAAJ",
      "7EoDBR0AAAAJ",
      "feURmn4AAAAJ",
      "Zb0am48AAAAJ",
      "dHjYcrgAAAAJ",
      "_9GX96fDWAMC",
      "eH-qW3gAAAAJ",
      "6iPoAXAAAAAJ",
      "vl8imyIAAAAJ",
      "kGOgaowAAAAJ",
      "YtWK2I8AAAAJ",
      "Jtmq_m0AAAAJ",
      "-dnFl2MAAAAJ",
      "QE9pa_cAAAAJ",
      "UsDuS10AAAAJ",
      "0TGDhHsAAAAJ",
      "bKMhN4UAAAAJ",
      "YY7Rql4AAAAJ",
      "BCGgwlEAAAAJ",
      "zStLMKIAAAAJ",
      "50xZTa0AAAAJ",
      "qjgsTnwAAAAJ",
      "zCdh4NEAAAAJ",
      "izeB4QsAAAAJ",
      "wnhU3KoAAAAJ",
      "H4n-cXEAAAAJ",
      "ea6cjVUAAAAJ",
      "2W82D4QAAAAJ",
      "LW8ze_UAAAAJ",
      "O50gXqUAAAAJ",
      "UU3N6-UAAAAJ",
      "ILgZT7MAAAAJ",
      "-xaOIZIAAAAJ",
      "9cBUERoAAAAJ",
      "6ztViH8AAAAJ",
      "SlZavnIAAAAJ",
      "5diMRzQAAAAJ",
      "j-cSRNIAAAAJ",
      "SBKP1acAAAAJ",
      "GtfVLBAAAAAJ",
      "LQR0kNcAAAAJ",
      "H3ExIrEAAAAJ",
      "PfgeYGwAAAAJ",
      "J_XhIsgAAAAJ",
      "ScLUQ-YAAAAJ",
      "5lhsTYwAAAAJ",
      "PjQhSkgAAAAJ",
      "RBX7SrkAAAAJ",
      "c_jPvP4AAAAJ",
      "pdPJFIUAAAAJ",
      "btWJVrgAAAAJ",
      "KA8dgpMAAAAJ",
      "g1I269gAAAAJ",
      "wd6xr6sAAAAJ",
      "1CgET20AAAAJ",
      "R9N6ljUAAAAJ",
      "4QvYJ00AAAAJ",
      "8AXJB5QAAAAJ",
      "yVubPz4AAAAJ",
      "i3wkV_kAAAAJ",
      "tQuRm1AAAAAJ",
      "_DNzXTcAAAAJ",
      "miE8bYkAAAAJ",
      "9r7_pN8AAAAJ",
      "cF6i_goAAAAJ",
      "Y-I1X9QAAAAJ",
      "fZKJdb0AAAAJ",
      "AgqvtZkAAAAJ",
      "h1FDASIAAAAJ",
      "G-xTgkgAAAAJ",
      "7PljKpoAAAAJ",
      "S8D-DqEAAAAJ",
      "gdD2E9QAAAAJ",
      "tqxTaiAAAAAJ",
      "vsAumE0AAAAJ",
      "TJSHa2IAAAAJ",
      "AlpgbIoAAAAJ",
      "VpB8NZ8AAAAJ",
      "n1EE3-8AAAAJ",
      "tQnods8AAAAJ",
      "52f5kGIAAAAJ",
      "WYE8rtcAAAAJ",
      "LLnrH8IAAAAJ",
      "hfmi3QwAAAAJ",
      "MpuRqeQAAAAJ",
      "dHUiyDkAAAAJ",
      "s18-KHUAAAAJ",
      "dCa-pW8AAAAJ",
      "lPM8k54AAAAJ",
      "xA3Jd5gAAAAJ",
      "_s5DZOcAAAAJ",
      "gRxBNZoAAAAJ",
      "13xdkw4AAAAJ",
      "Kt1aSnAAAAAJ",
      "3Tj5lWEAAAAJ",
      "a2KklUoAAAAJ",
      "Mg-vyosAAAAJ",
      "mTqef3oAAAAJ",
      "RUTPdHcAAAAJ",
      "_TgBTNwAAAAJ",
      "wtK4Yh4AAAAJ",
      "P6l5tBcAAAAJ",
      "RZ9pOY4AAAAJ",
      "o6LlkNMAAAAJ",
      "e0nmxyIAAAAJ",
      "t9eduncAAAAJ",
      "wJRAoOsAAAAJ",
      "_4_X3OgAAAAJ",
      "39JcQcEAAAAJ",
      "AaauqDAAAAAJ",
      "9aDxIYcAAAAJ",
      "bQNISbAAAAAJ",
      "PVxHYr4AAAAJ",
      "wvkUbiUAAAAJ",
      "-nzJN7oAAAAJ",
      "KCdL5B0AAAAJ",
      "4Gw0GgEAAAAJ",
      "n0QrdEMAAAAJ",
      "qJBXk9cAAAAJ",
      "n_ts4eYAAAAJ",
      "LOV6_WIAAAAJ",
      "Zhb-VjwAAAAJ",
      "R5QNdhcAAAAJ",
      "EfhUHOQAAAAJ",
      "pneVd2IAAAAJ",
      "ztwMmHEAAAAJ",
      "18fTep8AAAAJ",
      "mM_5lrMAAAAJ",
      "BfmcfEAAAAAJ",
      "6yls9oMAAAAJ",
      "-7FMxqsAAAAJ",
      "0ytii2EAAAAJ",
      "EOlowBUAAAAJ",
      "2gSuGBEAAAAJ",
      "xRmmtzIAAAAJ",
      "aLl3rYoAAAAJ",
      "v6PsQKIAAAAJ",
      "_9pmXcsAAAAJ",
      "qnMs-XYAAAAJ",
      "tBAp1-gAAAAJ",
      "P1-HgxMAAAAJ",
      "SdiAQPQAAAAJ",
      "AaMR6EQAAAAJ",
      "G8dMSvAAAAAJ",
      "0SQP4bwAAAAJ",
      "QY5OAIMAAAAJ",
      "2GKLw94AAAAJ",
      "krvptckAAAAJ",
      "1PEHzesAAAAJ",
      "0ZgdQZ8AAAAJ",
      "nSSZmScAAAAJ",
      "RL7jPuQAAAAJ",
      "slS0dvUAAAAJ",
      "fvwzUnIAAAAJ",
      "zvaeYnUAAAAJ",
      "zTy9cUwAAAAJ",
      "LXqHtF4AAAAJ",
      "i_QJztcAAAAJ",
      "EpidFw8AAAAJ",
      "VMXSblwAAAAJ",
      "nnLiId8AAAAJ",
      "8rU1AaQAAAAJ",
      "leVIam8AAAAJ",
      "5GLvj20AAAAJ",
      "IgO2ThIAAAAJ",
      "l4hK4eEAAAAJ",
      "CKqzOqsAAAAJ",
      "eesxmR0AAAAJ",
      "g_21RKoAAAAJ",
      "TvV_SVwAAAAJ",
      "yvdSr4AAAAAJ",
      "Lh_ZqdcAAAAJ",
      "cKtU3eAAAAAJ",
      "xvOlfw8AAAAJ",
      "00M1AqQAAAAJ",
      "U80atIAAAAAJ",
      "wMjQdBcAAAAJ",
      "Qqtyp-EAAAAJ",
      "rNpUIKAAAAAJ",
      "9om-fCsAAAAJ",
      "CA3Z5zcAAAAJ",
      "o_1YtVoAAAAJ",
      "NbXF7T8AAAAJ",
      "BkGE4AsAAAAJ",
      "wB01auEAAAAJ",
      "m2RVgR0AAAAJ",
      "QLC6sn4AAAAJ",
      "v9-IuzwAAAAJ",
      "Jun8c34AAAAJ",
      "L4CxNO8AAAAJ",
      "B42Mr-sAAAAJ",
      "7w24ptsAAAAJ",
      "NeW9jU8AAAAJ",
      "PBXTVb4AAAAJ",
      "GveGRr0AAAAJ",
      "jDLa-CUAAAAJ",
      "sikKD7UAAAAJ",
      "8qHnRnsAAAAJ",
      "78OLNd4AAAAJ",
      "cLCHds0AAAAJ",
      "M8o8WaQAAAAJ",
      "T04c3fwAAAAJ",
      "xD-wj_0AAAAJ",
      "XCZpOcAAAAAJ",
      "zOKOeG4AAAAJ",
      "zMKzi8kAAAAJ",
      "sLXafasAAAAJ",
      "tokXOxkAAAAJ",
      "bHsjbLwAAAAJ",
      "WfzyRAUAAAAJ",
      "_pPy-pAAAAAJ",
      "Wj3t9l0AAAAJ",
      "i02oEgMAAAAJ",
      "uQZjTq4AAAAJ",
      "umAny5UAAAAJ",
      "Cr3WSpIAAAAJ",
      "6HVq8KMAAAAJ",
      "OtJC70cAAAAJ",
      "vQ1dKQwAAAAJ",
      "kCYbVq0AAAAJ",
      "IkxViPsAAAAJ",
      "GNYqvgQAAAAJ",
      "SNQERVoAAAAJ",
      "DXpZ1lkAAAAJ",
      "6hHbBwwAAAAJ",
      "EcgjIi4AAAAJ",
      "x5wW5WIAAAAJ",
      "i0oFmt0AAAAJ",
      "44ANFF4AAAAJ",
      "tcCGGDsZJUsC",
      "H1d4BS8AAAAJ",
      "uGDQoU0AAAAJ",
      "JrnxAZUAAAAJ",
      "YH7PDvEAAAAJ",
      "jbbtciwAAAAJ",
      "mzZa_yQAAAAJ",
      "B48jbeEAAAAJ",
      "TFx_gLQAAAAJ",
      "Q38iIK4AAAAJ",
      "vDn8bXAAAAAJ",
      "ai8A090AAAAJ",
      "6AA-AAcAAAAJ",
      "wYDYIYkAAAAJ",
      "t0gYEjAAAAAJ",
      "3uClq6kAAAAJ",
      "l5Qki4cAAAAJ",
      "_Q1uzVYAAAAJ",
      "TNr_OWMAAAAJ",
      "yVIXGqYAAAAJ",
      "KGRm0QsAAAAJ",
      "h4i4fh8AAAAJ",
      "Uro_AS0AAAAJ",
      "jgeWbOMAAAAJ",
      "nrEeeY4AAAAJ",
      "IEHo6YcAAAAJ",
      "9zeEI-cAAAAJ",
      "qRnP-p0AAAAJ",
      "MfGgaT0AAAAJ",
      "zgfSvoYAAAAJ",
      "Gzxda70AAAAJ",
      "0NHagNQAAAAJ",
      "elXOB1sAAAAJ",
      "P__ztgcAAAAJ",
      "j5o1jkEAAAAJ",
      "5q_ZMzYAAAAJ",
      "B0KVWJEAAAAJ",
      "JscQvlUAAAAJ",
      "gUO59T8AAAAJ",
      "r90OelAAAAAJ",
      "1ScWJOoAAAAJ",
      "8-nvcSQAAAAJ",
      "6uIhh6MAAAAJ",
      "rynvwScAAAAJ",
      "9ZRcemUAAAAJ",
      "0EWw1z8AAAAJ",
      "kLUQrrYAAAAJ",
      "KnAit3cAAAAJ",
      "ZuWlfPEAAAAJ",
      "kmUgTboAAAAJ",
      "xaFg_NUAAAAJ",
      "rRvt-YAAAAAJ",
      "WJGqLh8AAAAJ",
      "3kDtybgAAAAJ",
      "b4qKr7gAAAAJ",
      "7EWrVYIAAAAJ",
      "PYLHQsYAAAAJ",
      "ZiON80cAAAAJ",
      "4_JVf14AAAAJ",
      "SlkU8ZQAAAAJ",
      "uMNLanIAAAAJ",
      "e1zesfMAAAAJ",
      "PKSWrbwAAAAJ",
      "j8ULfMsAAAAJ",
      "dF8_yxsAAAAJ",
      "Wmr3UIMAAAAJ",
      "_S7LGEEAAAAJ",
      "yVtSOt8AAAAJ",
      "sYza2XwAAAAJ",
      "h2hT0XcAAAAJ",
      "838_NnIAAAAJ",
      "Qogwc7QAAAAJ",
      "MIwNbDcAAAAJ",
      "COEsqLYAAAAJ",
      "_61pvRYAAAAJ",
      "gTWUZlsAAAAJ",
      "narJyMAAAAAJ",
      "GdXOFKoAAAAJ",
      "GlArL6AAAAAJ",
      "GAvF3gUAAAAJ",
      "93hi3QcAAAAJ",
      "dG9MV7oAAAAJ",
      "gxoPfIYAAAAJ",
      "J7H4N_4AAAAJ",
      "fCkoUvEAAAAJ",
      "fXRXgPMAAAAJ",
      "U_8MaDMAAAAJ",
      "UTmj6K4AAAAJ",
      "5hH5bt8AAAAJ",
      "pYasE5oAAAAJ",
      "1Tfui8UAAAAJ",
      "2gpXz3IAAAAJ",
      "bM44mNEAAAAJ",
      "Cl73CgcAAAAJ",
      "ocMf7fQAAAAJ",
      "qvRf9xsAAAAJ",
      "LHkrpqEAAAAJ",
      "ESCWolcAAAAJ",
      "4MB4orsAAAAJ",
      "Xl4E0CsAAAAJ",
      "w68-7AYAAAAJ",
      "Yipk0X4AAAAJ",
      "uGdPyZQAAAAJ",
      "OEJUgwkAAAAJ",
      "L5v2PHAAAAAJ",
      "0_aTa8YAAAAJ",
      "ndv95w0AAAAJ",
      "M5HFiMIAAAAJ",
      "4GTpCxcAAAAJ",
      "EtTJi3oAAAAJ",
      "nhNWrxkAAAAJ",
      "XunnVQoAAAAJ",
      "SOt7sr4AAAAJ",
      "klyIBq8AAAAJ",
      "0VFi-vAAAAAJ",
      "HaN8b2YAAAAJ",
      "ZEnShlcAAAAJ",
      "0OWBle8AAAAJ",
      "XPrjbvoAAAAJ",
      "Rza8c10AAAAJ",
      "MeNbzgIAAAAJ",
      "s1IzhYMAAAAJ",
      "TCg0M_8AAAAJ",
      "rjqOWi4AAAAJ",
      "6VJaD6EAAAAJ",
      "qbjHRA8AAAAJ",
      "D6ZDEUgAAAAJ",
      "YdS6szoAAAAJ",
      "1GPDFqsAAAAJ",
      "laKl8acAAAAJ",
      "asu1aZMAAAAJ",
      "o8TlyGMAAAAJ",
      "8kYedXEAAAAJ",
      "UXNLsZUAAAAJ",
      "S1a25sEAAAAJ",
      "ImpbxLsAAAAJ",
      "CgItEbQAAAAJ",
      "gc62BUIAAAAJ",
      "hyle4iEAAAAJ",
      "iDP84cQAAAAJ",
      "R6jE0VEAAAAJ",
      "iyPP6VYAAAAJ",
      "tGNxOpEAAAAJ",
      "9yRwkr4AAAAJ",
      "2c_x00gAAAAJ",
      "K4t4Rq0AAAAJ",
      "r4gezHUAAAAJ",
      "y80AokkAAAAJ",
      "sUb_eyUAAAAJ",
      "vk37k80AAAAJ",
      "_eLWTEUAAAAJ",
      "sJI2aOYAAAAJ",
      "slFtxbMAAAAJ",
      "XeDtzHEAAAAJ",
      "9mIBxkMAAAAJ",
      "Bl4SRU0AAAAJ",
      "hh5nOn4AAAAJ",
      "iRBUTOAAAAAJ",
      "zC9ANdcAAAAJ",
      "PyuaaWAAAAAJ",
      "FcFAKFEAAAAJ",
      "EMDboA4AAAAJ",
      "Sdz9YPMAAAAJ",
      "im_BJdIAAAAJ",
      "hUh7qCcAAAAJ",
      "h5KkpakAAAAJ",
      "_qY_t5kAAAAJ",
      "dY7OSl0AAAAJ",
      "zc920lAAAAAJ",
      "iyVHKkcAAAAJ",
      "194wSMsAAAAJ",
      "9EFobLUAAAAJ",
      "yQKlLTQAAAAJ",
      "YjTldCMAAAAJ",
      "TkayRqQAAAAJ",
      "m0WCd-4AAAAJ",
      "2wrS35MAAAAJ",
      "u8Q0_xsAAAAJ",
      "vErFKeAAAAAJ",
      "ff0742EAAAAJ",
      "ubaxhUIAAAAJ",
      "xYL6KC0AAAAJ",
      "A8YEQMMAAAAJ",
      "8OVA7ucAAAAJ",
      "RkuzIZMAAAAJ",
      "56urJP0AAAAJ",
      "GStTsxAAAAAJ",
      "7Fxbm0AAAAAJ",
      "NAGHvJIAAAAJ",
      "djheYP0AAAAJ",
      "b8OxVWUAAAAJ",
      "vUM0nAgAAAAJ",
      "DpLFv4gAAAAJ",
      "K7MBJlwAAAAJ",
      "jAKBew4AAAAJ",
      "3-gk0ioAAAAJ",
      "g_aM9xcAAAAJ",
      "RBwpd88AAAAJ",
      "QW_JZnsAAAAJ",
      "INd48rQAAAAJ",
      "aGXkhcwAAAAJ",
      "Qp2pme4AAAAJ",
      "jNQlAkoAAAAJ",
      "GMzzRRUAAAAJ",
      "UpnZAg0AAAAJ",
      "CigslP0AAAAJ",
      "jac_HrgAAAAJ",
      "sioumZAAAAAJ",
      "BzJ_GboAAAAJ",
      "1yB0eLMAAAAJ",
      "0b9YnbYAAAAJ",
      "CIZwXAcAAAAJ",
      "6rl-XhwAAAAJ",
      "HAG5Og4AAAAJ",
      "Wnxq0mgAAAAJ",
      "E5NCCUEAAAAJ",
      "RIBv3lgAAAAJ",
      "pH1PDwYAAAAJ",
      "X53rkecAAAAJ",
      "Kq272_MAAAAJ",
      "EqobCqwAAAAJ",
      "Mz6M9j0AAAAJ",
      "dgeikT8AAAAJ",
      "7hwJ2ckAAAAJ",
      "pL8RApYAAAAJ",
      "t6YzEpgAAAAJ",
      "z9em5msAAAAJ",
      "XoXgt4oAAAAJ",
      "FoGc_e0AAAAJ",
      "8Phz8n4AAAAJ",
      "gjLr_FgAAAAJ",
      "MoYaxfYAAAAJ",
      "UrsQh_0AAAAJ",
      "FSm4igUAAAAJ",
      "yuB-cfoAAAAJ",
      "rMtUkMcAAAAJ",
      "Y8O9N_0AAAAJ",
      "iAG5Mj0AAAAJ",
      "47L65OMAAAAJ",
      "Z-2pv_wAAAAJ",
      "LlK_saMAAAAJ",
      "69JJbWoAAAAJ",
      "S63gb38AAAAJ",
      "Bt4uDWMAAAAJ",
      "vq4lx5YAAAAJ",
      "KzESVKwAAAAJ",
      "CylZPggAAAAJ",
      "7QHvAEYAAAAJ",
      "rpavyzsAAAAJ",
      "OfYf-DMAAAAJ",
      "OVkZUYoAAAAJ",
      "LAuxzv0AAAAJ",
      "E08IHhoAAAAJ",
      "TqUN-LwAAAAJ",
      "ekIw7HQAAAAJ",
      "oIz_CYEAAAAJ",
      "3yT6IX4AAAAJ",
      "78WTKm4AAAAJ",
      "qANkJFwAAAAJ",
      "JfblW3MAAAAJ",
      "rPU7fz0AAAAJ",
      "xQqZt2AAAAAJ",
      "4B-OkFkAAAAJ",
      "N-BBA20AAAAJ",
      "Jd2A44wAAAAJ",
      "5efz6osAAAAJ",
      "MpdsJF0AAAAJ",
      "YsKTazIAAAAJ",
      "JY6hDCoAAAAJ",
      "uL7NxA4AAAAJ",
      "62e5CygAAAAJ",
      "hDLBEhkAAAAJ",
      "MvyO9jAAAAAJ",
      "gXgEgeoAAAAJ",
      "DfXsKZ4AAAAJ",
      "c73wW0kAAAAJ",
      "ep_nM5sAAAAJ",
      "gpLVKmEAAAAJ",
      "DwKuTLwAAAAJ",
      "c7GoaV8AAAAJ",
      "ocPXoIkAAAAJ",
      "DDVtnHEAAAAJ",
      "wR84XY1kACcC",
      "oVsC3XcAAAAJ",
      "MoJFIiQAAAAJ",
      "Id8SJl8AAAAJ",
      "2AT4JE4AAAAJ",
      "ZqLIu1EAAAAJ",
      "e4peJmoAAAAJ",
      "s5_69i0AAAAJ",
      "LK_CV24AAAAJ",
      "k2AHIx8AAAAJ",
      "5n5leq4AAAAJ",
      "l2FS2_IAAAAJ",
      "tJpoCUIAAAAJ",
      "gdUv1PIAAAAJ",
      "MlZq4XwAAAAJ",
      "Bl9FSL0AAAAJ",
      "ny0ZgiQAAAAJ",
      "TGRPKRIAAAAJ",
      "9cCaIAwAAAAJ",
      "bOitqMUAAAAJ",
      "MsuY1TsAAAAJ",
      "7j3itaMAAAAJ",
      "AerHOzUAAAAJ",
      "w0x8vm0AAAAJ",
      "KL4w4bAAAAAJ",
      "Lc9GwgwAAAAJ",
      "uJrcFwYAAAAJ",
      "8J1kJhIAAAAJ",
      "mNwCdqwAAAAJ",
      "JBnyLicAAAAJ",
      "ILDVin4AAAAJ",
      "a5nY-pYAAAAJ",
      "D4NJsXEIh1cJ",
      "ANtAA98AAAAJ",
      "JDhMq3kAAAAJ",
      "9xF7M6wAAAAJ",
      "0Ozzy4IAAAAJ",
      "EnNwKLgAAAAJ",
      "wHlw1L4AAAAJ",
      "lQbIarsAAAAJ",
      "aQeTAr4AAAAJ",
      "LnAus20AAAAJ",
      "T8grPNsAAAAJ",
      "CUDUMSkAAAAJ",
      "UXh1I6UAAAAJ",
      "lEls5I8AAAAJ",
      "BzOqNoQAAAAJ",
      "2HJu9wgAAAAJ",
      "aqSKwDQAAAAJ",
      "aMkW638AAAAJ",
      "OBiA-IAAAAAJ",
      "PEAQZVEAAAAJ",
      "tRJvzU0AAAAJ",
      "wUArfPgAAAAJ",
      "iVLAQysAAAAJ",
      "LtdHRjsAAAAJ",
      "nzA4P0oAAAAJ",
      "dDsbkAoAAAAJ",
      "6F90JHgAAAAJ",
      "UjCHdlEAAAAJ",
      "-BgdY0oAAAAJ",
      "qtLQJRYAAAAJ",
      "FM2DTXwAAAAJ",
      "XeyiyUYAAAAJ",
      "cLPaHcIAAAAJ",
      "HUIAm4UAAAAJ",
      "ijpYJQwAAAAJ",
      "pTTEiHUAAAAJ",
      "NcT-9asAAAAJ",
      "VSI-8CwAAAAJ",
      "DdtAyEIAAAAJ",
      "DWWFQkkAAAAJ",
      "q1HlbIUAAAAJ",
      "-q90a0EAAAAJ",
      "aj84iHAAAAAJ",
      "YP90oGMAAAAJ",
      "hJS2TXwAAAAJ",
      "BMFlkT8AAAAJ",
      "in6eBIwAAAAJ",
      "1GgfFDUAAAAJ",
      "RTbYeUcAAAAJ",
      "00FDOS8AAAAJ",
      "stSUaHAAAAAJ",
      "P2rIVYIAAAAJ",
      "HcyivC0AAAAJ",
      "FuOqWNEAAAAJ",
      "tzbfgcMAAAAJ",
      "emiAAG0AAAAJ",
      "bc0aQ7YAAAAJ",
      "dXzqCT4AAAAJ",
      "PKRe4QwAAAAJ",
      "nCh4qyMAAAAJ",
      "icXJxqwAAAAJ",
      "DNuiPHwAAAAJ",
      "7z8NqmUAAAAJ",
      "_21CagYAAAAJ",
      "DLazAw4AAAAJ",
      "QXgZyjAAAAAJ",
      "daYjNkAAAAAJ",
      "5DfprgMAAAAJ",
      "71L4yYMAAAAJ",
      "ktKXDuMAAAAJ",
      "bMDg-3cAAAAJ",
      "MZqwE-wAAAAJ",
      "1VHwJz0AAAAJ",
      "0Qr2IGwAAAAJ",
      "gV_XNa0AAAAJ",
      "LILR85MAAAAJ",
      "IO8BmHUAAAAJ",
      "0wZN6hEAAAAJ",
      "Tq1gdBUAAAAJ",
      "WzkYR-0AAAAJ",
      "KC6FJ14AAAAJ",
      "aSAS-aAAAAAJ",
      "rPhGUw0AAAAJ",
      "sd0Rw0YAAAAJ",
      "SuWIEE8AAAAJ",
      "6iUjvyMAAAAJ",
      "-lbtnAgAAAAJ",
      "Kce9W-8AAAAJ",
      "yq90c58AAAAJ",
      "ytQV4UcAAAAJ",
      "57XwZeYAAAAJ",
      "cy9mlN0AAAAJ",
      "Z_A0TDgAAAAJ",
      "6Q-289IAAAAJ",
      "zlBSbUAAAAAJ",
      "6T1qA5AAAAAJ",
      "QUJ0kPMAAAAJ",
      "sdw9roIAAAAJ",
      "J1vWqkQAAAAJ",
      "H28xhwQAAAAJ",
      "HuckLq8AAAAJ",
      "SfJ_pOYAAAAJ",
      "FwFFVdIAAAAJ",
      "0v1kYUEAAAAJ",
      "x8dED5cAAAAJ",
      "Tlc4yaMAAAAJ",
      "Rdp-tpgAAAAJ",
      "wfnTS8UAAAAJ",
      "cYoahsBLcjsC",
      "SUAbOcgAAAAJ",
      "91NxdC4AAAAJ",
      "RlaKKWAAAAAJ",
      "ZsgWCyMAAAAJ",
      "0DX2YsQAAAAJ",
      "aYEVCBwAAAAJ",
      "gnBwBZ4AAAAJ",
      "m1eoR-cAAAAJ",
      "UK-VpDoAAAAJ",
      "G-oLZ6wAAAAJ",
      "n-Oret4AAAAJ",
      "WFKit_4AAAAJ",
      "zw1TzeEAAAAJ",
      "r3SJcvoAAAAJ",
      "-d7Ib5UAAAAJ",
      "-hGZC54AAAAJ",
      "0aIhBb0AAAAJ",
      "qlKWTsUAAAAJ",
      "X8H76XIAAAAJ",
      "QIZZA0oAAAAJ",
      "Nav8m8gAAAAJ",
      "AgPS44sAAAAJ",
      "ABKq-ecAAAAJ",
      "mfk62y8AAAAJ",
      "qoIuyMoAAAAJ",
      "FNwI36EAAAAJ",
      "V5gL_H0AAAAJ",
      "abd1LXcAAAAJ",
      "pbhFW1kAAAAJ",
      "5RJ6wXAAAAAJ",
      "H8FJlJoAAAAJ",
      "Az7XqxQAAAAJ",
      "K3ad1CgAAAAJ",
      "oQ6AeyEAAAAJ",
      "LmKtwk8AAAAJ",
      "jIKjjSYAAAAJ",
      "mwpnDOYAAAAJ",
      "239ZfwgAAAAJ",
      "iu8ve8EAAAAJ",
      "nqoOetAAAAAJ",
      "ziP-50wAAAAJ",
      "5ygiTwsAAAAJ",
      "WPe7vWwAAAAJ",
      "FtdDAMoAAAAJ",
      "ZcguQt4AAAAJ",
      "ew0G1PIAAAAJ",
      "oM6Pj3MAAAAJ",
      "jqzSwdsAAAAJ",
      "CRLG9UcAAAAJ",
      "otHomQ8AAAAJ",
      "JlrEuLkAAAAJ",
      "0eQjcEEAAAAJ",
      "uDuLNHkAAAAJ",
      "8zyiGRoAAAAJ",
      "wKjXRn0AAAAJ",
      "YjS546oAAAAJ",
      "okKw87MAAAAJ",
      "ZTkRs84AAAAJ",
      "SMAmWOQAAAAJ",
      "nSZG-vcAAAAJ",
      "2Jw3gv4AAAAJ",
      "aLBeFYcAAAAJ",
      "3XLQbL8AAAAJ",
      "_CNYi6MAAAAJ",
      "AwpU32MAAAAJ",
      "WLk8ZikAAAAJ",
      "5En4XZEAAAAJ",
      "-eVum0sAAAAJ",
      "t4w1jE4AAAAJ",
      "m4fq5VoAAAAJ",
      "ceYJJmYAAAAJ",
      "-V1rJ8wAAAAJ",
      "QwdY5EIAAAAJ",
      "1ypDmDwAAAAJ",
      "yYpm9LoAAAAJ",
      "T_IyfqMAAAAJ",
      "kRdfhVQAAAAJ",
      "CkVvikAAAAAJ",
      "rKyTmpkAAAAJ",
      "DSmxHuMAAAAJ",
      "BMydCgcAAAAJ",
      "eL_y80EAAAAJ",
      "BIO5wVQAAAAJ",
      "SNqm6doAAAAJ",
      "ZZwLZ8UAAAAJ",
      "F3YBJxUAAAAJ",
      "k9TsUVsAAAAJ",
      "rSuG-f4AAAAJ",
      "wCNY8ZYAAAAJ",
      "NE4K0XUAAAAJ",
      "IHPRZuMAAAAJ",
      "WQkBYwQAAAAJ",
      "jre2iwMAAAAJ",
      "0tPCcKEAAAAJ",
      "ciH2ROgAAAAJ",
      "QMFlwLQAAAAJ",
      "F_ASWCUAAAAJ",
      "wR5YWC0AAAAJ",
      "Viv2E9AAAAAJ",
      "phTqe74AAAAJ",
      "lg1fT1kAAAAJ",
      "3Bfgs9cAAAAJ",
      "MgzHAPQAAAAJ",
      "ZRWlokAAAAAJ",
      "p9RsPG4AAAAJ",
      "IoGj8UEAAAAJ",
      "rifOKt4AAAAJ",
      "IC9VJpsAAAAJ",
      "0RLF4vUAAAAJ",
      "S5x4xYUAAAAJ",
      "fbvYwZcAAAAJ",
      "wwW4HRQAAAAJ",
      "n2osZaoAAAAJ",
      "hiGI9v0AAAAJ",
      "de30Rq0AAAAJ",
      "mQIqIVwAAAAJ",
      "dsb5VjkAAAAJ",
      "ZYEgD7wAAAAJ",
      "zxFuDvsAAAAJ",
      "X1zsXTgAAAAJ",
      "x2PfbDEAAAAJ",
      "PBEbCgUAAAAJ",
      "UW3tRn8AAAAJ",
      "2lvIrNAAAAAJ",
      "cPDxYXMAAAAJ",
      "7c2pTZMAAAAJ",
      "tiNiOI4AAAAJ",
      "f4DpFfQAAAAJ",
      "wAKowxMAAAAJ",
      "wo_M4uQAAAAJ",
      "t4rXchwAAAAJ",
      "jLPy8-4AAAAJ",
      "RL61eA0AAAAJ",
      "fsbXdAYAAAAJ",
      "Yxh9WWoAAAAJ",
      "0Knul6gAAAAJ",
      "eEGGCiUAAAAJ",
      "VGBlCk4AAAAJ",
      "KzSKtNUAAAAJ",
      "Ne3wr9oAAAAJ",
      "pKf5LtQAAAAJ",
      "mxYLn8MAAAAJ",
      "--YtdhAAAAAJ",
      "UXYmnbgAAAAJ",
      "tJ_PrzgAAAAJ",
      "m5hqkt0AAAAJ",
      "gTuG8BsAAAAJ",
      "aFDuhV8AAAAJ",
      "lJ_oh2EAAAAJ",
      "LIiCDa0AAAAJ",
      "9i_MgykAAAAJ",
      "xaQuPloAAAAJ",
      "HTfEll0AAAAJ",
      "EbyGwncAAAAJ",
      "FasIlp0AAAAJ",
      "k6-nvDAAAAAJ",
      "ZeJjFQMAAAAJ",
      "QV8hqE4AAAAJ",
      "8AtDeScAAAAJ",
      "kl4jZpAAAAAJ",
      "xpe7bloAAAAJ",
      "UWO1mloAAAAJ",
      "8qNEbiUAAAAJ",
      "ApQt28MAAAAJ",
      "jqWZsC0AAAAJ",
      "Hxic_iwAAAAJ",
      "5kVcNS4AAAAJ",
      "7HoFN1wAAAAJ",
      "4e2pnKYAAAAJ",
      "ldJpvE8AAAAJ",
      "-Txt8vsAAAAJ",
      "5i5vhFQAAAAJ",
      "9RNcFO0AAAAJ",
      "-0T1EtoAAAAJ",
      "Z8vhOxYAAAAJ",
      "oBeXCuQAAAAJ",
      "fqf2tBsAAAAJ",
      "pbb9CG4AAAAJ",
      "qwOPQdIAAAAJ",
      "r1Fn_YsAAAAJ",
      "i7V1kJgAAAAJ",
      "GECP5OIAAAAJ",
      "NcEl9LwAAAAJ",
      "Jv1FrfwAAAAJ",
      "HvI1xmUAAAAJ",
      "8hvFa2AAAAAJ",
      "ZeG4wDgAAAAJ",
      "MgppzFwAAAAJ",
      "lOhHz0gAAAAJ",
      "403nNzMAAAAJ",
      "yy0UFOwAAAAJ",
      "RVl8TE0AAAAJ",
      "TjWwqmwAAAAJ",
      "wtRVnsYAAAAJ",
      "c8yK5XsAAAAJ",
      "ryoyucAAAAAJ",
      "naUbiQ8AAAAJ",
      "01YOPpAAAAAJ",
      "xhKqjpYAAAAJ",
      "FBeJOPgAAAAJ",
      "Q4DTPw4AAAAJ",
      "MqNK0kQAAAAJ",
      "fizPmUgAAAAJ",
      "peqnQjMAAAAJ",
      "T4DF6CAAAAAJ",
      "g65nv5cAAAAJ",
      "lG7aUrkAAAAJ",
      "VatfufAAAAAJ",
      "wN9rBkcAAAAJ",
      "9547Qp4AAAAJ",
      "d5wGxRsAAAAJ",
      "f8sVvG0AAAAJ",
      "GYPCqcYAAAAJ",
      "x2wyjkAAAAAJ",
      "4GpKQUIAAAAJ",
      "Aok9lxwAAAAJ",
      "WkRojboAAAAJ",
      "-CqyjXEAAAAJ",
      "sEMrGicAAAAJ",
      "lfRiJ8YAAAAJ",
      "yz2P_aUAAAAJ",
      "BtwmZfQAAAAJ",
      "SRM4v2cAAAAJ",
      "X57uzqcAAAAJ",
      "tQgvgxkAAAAJ",
      "SCFarTEAAAAJ",
      "rFcdDJEAAAAJ",
      "jdSlREMAAAAJ",
      "OEZ816YAAAAJ",
      "Jc97EyAAAAAJ",
      "0RvAVR4AAAAJ",
      "zfCmRZkAAAAJ",
      "VfYhf2wAAAAJ",
      "AZH_wV0AAAAJ",
      "w3PrbKwAAAAJ",
      "09bl0GIAAAAJ",
      "XDrMB6AAAAAJ",
      "kIx230gAAAAJ",
      "-SlS0mgAAAAJ",
      "-EqbTXoAAAAJ",
      "dy_JBs0AAAAJ",
      "X-s3kzUAAAAJ",
      "8ew3do4AAAAJ",
      "QAdcBnQAAAAJ",
      "RzEnQmgAAAAJ",
      "4EKKyosAAAAJ",
      "48Y9F-YAAAAJ",
      "DSKzTCAAAAAJ",
      "UlpHyKAAAAAJ",
      "8ZpV-lkAAAAJ",
      "FjCbjDYAAAAJ",
      "9FZlpDMAAAAJ",
      "YPzKczYAAAAJ",
      "JlqDXrUAAAAJ",
      "szUb_isAAAAJ",
      "kwe0VEwAAAAJ",
      "bEctTN0AAAAJ",
      "RJeVHPYAAAAJ",
      "M-3cIR0AAAAJ",
      "7PGzs4sAAAAJ",
      "bTdT7hAAAAAJ",
      "_JWhZSAAAAAJ",
      "EL7zNHcAAAAJ",
      "avJO4EcAAAAJ",
      "AfSC-s4AAAAJ",
      "bBQx_5MAAAAJ",
      "XFuk24sAAAAJ",
      "0vZ20kgAAAAJ",
      "XqLiBQMAAAAJ",
      "y1lVpBEAAAAJ",
      "71G11ksAAAAJ",
      "wTTF4yYAAAAJ",
      "OtREFPYAAAAJ",
      "eteU0U4AAAAJ",
      "3qdaPdoAAAAJ",
      "N5QAWfMAAAAJ",
      "52f6rLIAAAAJ",
      "gY1w14YAAAAJ",
      "PCDSl2sAAAAJ",
      "ppaEV-8AAAAJ",
      "vDimc-4AAAAJ",
      "g9d_K0sAAAAJ",
      "4LRxXyIAAAAJ",
      "xuDZ9-sAAAAJ",
      "wEUnFc0AAAAJ",
      "KltleWgAAAAJ",
      "r3q68rcAAAAJ",
      "0cKXP7cAAAAJ",
      "Tpt57v0AAAAJ",
      "jzx6_ZIAAAAJ",
      "8rDNIMsAAAAJ",
      "JETJjHoAAAAJ",
      "yPOT9K0AAAAJ",
      "mIFso2kAAAAJ",
      "7XyGUGkAAAAJ",
      "m7Jr-b4AAAAJ",
      "aLquhd4AAAAJ",
      "bamP5BMAAAAJ",
      "3bL-H00AAAAJ",
      "ho3H9IsAAAAJ",
      "Zo_TuDUAAAAJ",
      "sLYXumkAAAAJ",
      "NMigkG4AAAAJ",
      "XfSFItwAAAAJ",
      "HlLm4LIAAAAJ",
      "VBMuQbsAAAAJ",
      "GGHVmOsAAAAJ",
      "n4kXFdsAAAAJ",
      "oo8QRmIAAAAJ",
      "AZMV2qQAAAAJ",
      "TktX0BAAAAAJ",
      "CQVb2IgAAAAJ",
      "busWvZkAAAAJ",
      "SW_WaQ0AAAAJ",
      "sU6x0E0AAAAJ",
      "W_ZjnTUAAAAJ",
      "jRQtBp0AAAAJ",
      "6V1dbO0AAAAJ",
      "ViBqWZYAAAAJ",
      "ffqbs_0AAAAJ",
      "tXJDPJAAAAAJ",
      "928yXx4AAAAJ",
      "ofoABP8AAAAJ",
      "qxWORNoAAAAJ",
      "ni3EbYgAAAAJ",
      "IGDs4HwAAAAJ",
      "a7drwRMAAAAJ",
      "F3dhs4kAAAAJ",
      "x7cbdTcAAAAJ",
      "YpxRngIAAAAJ",
      "r30eXmkAAAAJ",
      "hubUU3AAAAAJ",
      "GcR_rlkAAAAJ",
      "4HHWesEAAAAJ",
      "TSj_8nYAAAAJ",
      "SqAsppUAAAAJ",
      "I_ZwYZcAAAAJ",
      "BW2Xix4AAAAJ",
      "boebIUcAAAAJ",
      "lvPdFJUAAAAJ",
      "VeRSO8EAAAAJ",
      "XgA70_oAAAAJ",
      "CXPpSu0AAAAJ",
      "DKFiD7cAAAAJ",
      "2WSooDIAAAAJ",
      "b8pLQq0AAAAJ",
      "CeEO6SIAAAAJ",
      "2ZRnqiEAAAAJ",
      "PCJJ8LkAAAAJ",
      "GXhpY9wAAAAJ",
      "w4fhxasAAAAJ",
      "xT19Jc0AAAAJ",
      "h6yXnyEAAAAJ",
      "Xz-fi1cAAAAJ",
      "X2OmK_4AAAAJ",
      "IWPWNxkAAAAJ",
      "RiLCRDwAAAAJ",
      "7UV4ET4AAAAJ",
      "1LyndUsAAAAJ",
      "TWXQyuEAAAAJ",
      "07kG-YsAAAAJ",
      "vEqE_rUAAAAJ",
      "bZNRLNAAAAAJ",
      "g42kJfIAAAAJ",
      "iGgOj5oAAAAJ",
      "IKRu39AAAAAJ",
      "VO62HkEAAAAJ",
      "hlC76YUAAAAJ",
      "bEuH9QIAAAAJ",
      "2jPsTDgAAAAJ",
      "6TGwETYAAAAJ",
      "jTluf5cAAAAJ",
      "kXbo1twAAAAJ",
      "Z_-JBYgAAAAJ",
      "Yfo9_boAAAAJ",
      "0B8uuBkAAAAJ",
      "cMHsYdcAAAAJ",
      "9RyeFYwAAAAJ",
      "rmxKTn4AAAAJ",
      "VBNFtRkAAAAJ",
      "yVnCUg0AAAAJ",
      "YI1EqBoAAAAJ",
      "jmeHpKUAAAAJ",
      "L0BNwUIAAAAJ",
      "au4CYXQAAAAJ",
      "IzqMoZMAAAAJ",
      "aQcYWDMAAAAJ",
      "wurqZikAAAAJ",
      "ZfV1DqMAAAAJ",
      "BFlpS-8AAAAJ",
      "Ilx8WNkAAAAJ",
      "wstakvUAAAAJ",
      "6Ex1MMYAAAAJ",
      "QiQAv48AAAAJ",
      "O5m7WK8AAAAJ",
      "LT9zh4sAAAAJ",
      "UIM7nGwAAAAJ",
      "YkSJ7-8AAAAJ",
      "Xi-B5WIAAAAJ",
      "PMHXcoAAAAAJ",
      "B2U8EUwAAAAJ",
      "mZl2K3AAAAAJ",
      "VjsNXysAAAAJ",
      "tQ5vbOAAAAAJ",
      "nlJCSWcAAAAJ",
      "Nh832fgAAAAJ",
      "u3u16tgAAAAJ",
      "6JZ3R6wAAAAJ",
      "OTk6tAoAAAAJ",
      "iLJcSEsAAAAJ",
      "nShf6cgAAAAJ",
      "xT8PQ0IAAAAJ",
      "i4dDFK8AAAAJ",
      "e7VI_HcAAAAJ",
      "ewj-IFsAAAAJ",
      "Cs75s1MAAAAJ",
      "JEXV__kAAAAJ",
      "QBn7vq8AAAAJ",
      "qXTt3dUAAAAJ",
      "YZYne64AAAAJ",
      "tWBPUHwAAAAJ",
      "NGI_giYAAAAJ",
      "vTWuk1gAAAAJ",
      "_-qBW0UAAAAJ",
      "ejyZTmEAAAAJ",
      "ghfkSasAAAAJ",
      "Pa8qzYQAAAAJ",
      "f4G8d00AAAAJ",
      "_cMw1IUAAAAJ",
      "df3XoJIAAAAJ",
      "4YhNJBEAAAAJ",
      "uDFb6OcAAAAJ",
      "V42yp08AAAAJ",
      "eIdQR5oAAAAJ",
      "EVWYEMQAAAAJ",
      "w3DSGTIAAAAJ",
      "B3FqpjQAAAAJ",
      "eeSqBRoAAAAJ",
      "6d8ODpwAAAAJ",
      "YCPycGAAAAAJ",
      "g2uX6_gAAAAJ",
      "GNzbVIsAAAAJ",
      "FHLTntIAAAAJ",
      "MhDyxdYAAAAJ",
      "kqkq_coAAAAJ",
      "c_mh0i0AAAAJ",
      "vA6ZQ_AAAAAJ",
      "_CEwIJwAAAAJ",
      "9rHwD8wAAAAJ",
      "du74HM4AAAAJ",
      "luv0xMIAAAAJ",
      "R889GIQAAAAJ",
      "i28fU0MAAAAJ",
      "_MEuWIMAAAAJ",
      "xUOx0loAAAAJ",
      "5K1mZq0AAAAJ",
      "t7VnipMAAAAJ",
      "vmHFZM0AAAAJ",
      "f7hypjsAAAAJ",
      "lnCKs0AAAAAJ",
      "MhYrLJAAAAAJ",
      "LRsjX7kAAAAJ",
      "BZfj2c8AAAAJ",
      "1_BWn8IAAAAJ",
      "P2CPNr8AAAAJ",
      "-2wyKzEAAAAJ",
      "QSKXFiYAAAAJ",
      "u512YusAAAAJ",
      "_0aMq28AAAAJ",
      "RGoypN4AAAAJ",
      "WIk2v1QAAAAJ",
      "JEwMX6wAAAAJ",
      "TvdMDhwAAAAJ",
      "XYsMnBsAAAAJ",
      "vOLXDDAAAAAJ",
      "Hs9cVRgAAAAJ",
      "VcmM93MAAAAJ",
      "AEy91GEAAAAJ",
      "w8XocYQAAAAJ",
      "VKI8EhUAAAAJ",
      "t8RKSJsAAAAJ",
      "Nj74Gv4AAAAJ",
      "Kgs3zQoAAAAJ",
      "fb2-dasAAAAJ",
      "GkwzzEAAAAAJ",
      "abx4xHAAAAAJ",
      "aDLGNI0AAAAJ",
      "U5LkFfYAAAAJ",
      "7aabHgsAAAAJ",
      "Lz5YGiQAAAAJ",
      "CqqvouwAAAAJ",
      "VSCSNhMAAAAJ",
      "01je3ewAAAAJ",
      "n44GlFcAAAAJ",
      "ihFmK4cAAAAJ",
      "_X6fpR8AAAAJ",
      "1xqhHuEAAAAJ",
      "Bxgu5DQAAAAJ",
      "7XBJiZsAAAAJ",
      "rN2ny9kAAAAJ",
      "DkUUhXEAAAAJ",
      "0kK7sSAAAAAJ",
      "0fqAIGAAAAAJ",
      "mFbLNZQAAAAJ",
      "2pH8BZwAAAAJ",
      "GTk-bkoAAAAJ",
      "ag_2UqcAAAAJ",
      "FzJ6CXsAAAAJ",
      "vh9KxEIAAAAJ",
      "yaSMILkAAAAJ",
      "zFafsk8AAAAJ",
      "sLVkoTgAAAAJ",
      "B6iZVE0AAAAJ",
      "7MZe4owAAAAJ",
      "4DuiN7AAAAAJ",
      "xdsgpC0AAAAJ",
      "ktwwLjsAAAAJ",
      "2PIkUqgAAAAJ",
      "VhrBelcAAAAJ",
      "YT1DQB8AAAAJ",
      "qFtP1MQAAAAJ",
      "r6YTppEAAAAJ",
      "1gVfqpcAAAAJ",
      "sYncdvUAAAAJ",
      "bZ9oyW8AAAAJ",
      "TkiMCGoAAAAJ",
      "C0ddY2kAAAAJ",
      "9vumoioAAAAJ",
      "K-k47CMAAAAJ",
      "_pv1sEcAAAAJ",
      "dG7KSW0AAAAJ",
      "i2OSovEAAAAJ",
      "P21gHIkAAAAJ",
      "rK5YVA8AAAAJ",
      "Jnei_lEAAAAJ",
      "_RRIYvEAAAAJ",
      "xfgXYZ0AAAAJ",
      "Ksm6fEUAAAAJ",
      "RNiP4hsAAAAJ",
      "0KhH2ioAAAAJ",
      "hNI5rEIAAAAJ",
      "67QZN0gAAAAJ",
      "KKVV2nMAAAAJ",
      "9RAHYd0AAAAJ",
      "rwtM4roAAAAJ",
      "G5M9nYwAAAAJ",
      "jqH6384AAAAJ",
      "onzZ8qUAAAAJ",
      "9YmWGQEAAAAJ",
      "B9jUcIgAAAAJ",
      "VvgVKVYAAAAJ",
      "KfGfDvcAAAAJ",
      "X3FwUngAAAAJ",
      "0k4k1WUAAAAJ",
      "2uG5ut4AAAAJ",
      "A2KHeEgAAAAJ",
      "QLuPP70AAAAJ",
      "8qsuHEoAAAAJ",
      "cEM1a5gAAAAJ",
      "tCUvC4oAAAAJ",
      "dVswVTEAAAAJ",
      "r50jBCUAAAAJ",
      "Q1csT-8AAAAJ",
      "SywbV14AAAAJ",
      "gV4dPToAAAAJ",
      "SwNmwlcAAAAJ",
      "ej9SRrAAAAAJ",
      "bf2ZrFcAAAAJ",
      "TLyT0NwAAAAJ",
      "jFnb_-EAAAAJ",
      "4sgWuPcAAAAJ",
      "mT7ppvwAAAAJ",
      "iRgYMuEAAAAJ",
      "lOGcZowAAAAJ",
      "Ef1hJ8IAAAAJ",
      "lCgSjYAAAAAJ",
      "VECFLiAAAAAJ",
      "UfAyRKEAAAAJ",
      "KqVuUA0AAAAJ",
      "_QlCijoAAAAJ",
      "-mrh5AIAAAAJ",
      "8S5AOggAAAAJ",
      "9vAv0c4AAAAJ",
      "v7G4QvIAAAAJ",
      "M792u2sAAAAJ",
      "auB_CDsAAAAJ",
      "msQ4KT4AAAAJ",
      "NmDY9BMAAAAJ",
      "TrMmYPIAAAAJ",
      "odfHRTcAAAAJ",
      "vqYq3egAAAAJ",
      "r0wOAikAAAAJ",
      "fuVZQsAAAAAJ",
      "PP6LKtYAAAAJ",
      "qF806HcAAAAJ",
      "PvDd3k4AAAAJ",
      "YXJ-_k0AAAAJ",
      "MlFf2igAAAAJ",
      "J-dq_8EAAAAJ",
      "SqFoZNUAAAAJ",
      "hgaAO6QAAAAJ",
      "X7a38bAAAAAJ",
      "mBHPMZUAAAAJ",
      "u8K7nOwAAAAJ",
      "NDhlLv0AAAAJ",
      "RV-JsYEAAAAJ",
      "EYWzxPIAAAAJ",
      "ozaonZMAAAAJ",
      "pDvg7X4AAAAJ",
      "D6h2cTYAAAAJ",
      "gsr-K3ADUvAC",
      "bSU7LYoAAAAJ",
      "2QfPE54AAAAJ",
      "nHhtvqkAAAAJ",
      "ZMzzV7cAAAAJ",
      "-Tpv_CMAAAAJ",
      "9LJgRFAAAAAJ",
      "omHTV3MAAAAJ",
      "d_rxnzAAAAAJ",
      "IMoAPLUAAAAJ",
      "YI1SAjUAAAAJ",
      "7u_uyOsAAAAJ",
      "ejWOgzYAAAAJ",
      "MA6SDuEAAAAJ",
      "0dmJuNkAAAAJ",
      "_u7raRkAAAAJ",
      "ELOVd8sAAAAJ",
      "9_H57VkAAAAJ",
      "SEbcuNoAAAAJ",
      "YF0Hy1sAAAAJ",
      "RQg7790AAAAJ",
      "MUJ51_gAAAAJ",
      "m5dFh6YAAAAJ",
      "jaGNt2sAAAAJ",
      "dok0514AAAAJ",
      "dyYryZYAAAAJ",
      "CSHNLDcAAAAJ",
      "QWPwfsgAAAAJ",
      "Oa4qUz8AAAAJ",
      "04dL0akAAAAJ",
      "nUDR4_gAAAAJ",
      "cCda-zQAAAAJ",
      "nmk3WzgAAAAJ",
      "EtYv_AIAAAAJ",
      "O7p7lRAAAAAJ",
      "uvrIWrUAAAAJ",
      "s1IAWfgAAAAJ",
      "b5TVr_UAAAAJ",
      "iT366TkAAAAJ",
      "_tzVqLEAAAAJ",
      "FFWXLHUAAAAJ",
      "c2Att08AAAAJ",
      "1LgbXjEAAAAJ",
      "EKPoKcQAAAAJ",
      "9fxv1zwAAAAJ",
      "ryE3jpMAAAAJ",
      "9aQUYVQAAAAJ",
      "dxBYu1AAAAAJ",
      "h3qMa1kAAAAJ",
      "FjqLOGsAAAAJ",
      "IVxQvz0AAAAJ",
      "PnUH2KUAAAAJ",
      "TvVmLjUAAAAJ",
      "BaCR90MAAAAJ",
      "gkG4z3IAAAAJ",
      "OtgZrhUAAAAJ",
      "gb2r2ssAAAAJ",
      "30Izy_cAAAAJ",
      "kzS_Xd4AAAAJ",
      "Ks3QdEUAAAAJ",
      "qPP9-msAAAAJ",
      "T_Q-xDkAAAAJ",
      "VqP_wnMAAAAJ",
      "ae1ve-EAAAAJ",
      "bqTPA8kAAAAJ",
      "-4PyWB0AAAAJ",
      "O0VelhkAAAAJ",
      "0gyS3z0AAAAJ",
      "_nHDasEAAAAJ",
      "NBKWzkkAAAAJ",
      "EsoKTawAAAAJ",
      "SJoRNbYAAAAJ",
      "kpQGGFUAAAAJ",
      "Vf0BonwAAAAJ",
      "29FPauoAAAAJ",
      "ox3inugAAAAJ",
      "bhpi3vgAAAAJ",
      "ugSmcnoAAAAJ",
      "qCAslJ8AAAAJ",
      "mtB5szIAAAAJ",
      "hyJ_lk8AAAAJ",
      "3_2o8EgAAAAJ",
      "7H3sBioAAAAJ",
      "gmSwszcAAAAJ",
      "P9ROgN8AAAAJ",
      "WeEK60YAAAAJ",
      "ftEx984AAAAJ",
      "steJe6IAAAAJ",
      "CPQdYCQAAAAJ",
      "6gKEYRgAAAAJ",
      "ayUyj9YAAAAJ",
      "nfXdXswAAAAJ",
      "ykuVSuEAAAAJ",
      "UFokX9EAAAAJ",
      "5dBp2f4AAAAJ",
      "XXUsEjsAAAAJ",
      "GkpvilQAAAAJ",
      "ggLoicQAAAAJ",
      "u4olrOcAAAAJ",
      "RQxKmJMAAAAJ",
      "6CWng3MAAAAJ",
      "C9sg_B8AAAAJ",
      "AIncPrIAAAAJ",
      "KXkVpr4AAAAJ",
      "bslhbWgAAAAJ",
      "sQ8u6h4AAAAJ",
      "QSY7ufMAAAAJ",
      "9MjZO8wAAAAJ",
      "TbN31LMAAAAJ",
      "UCsQ8VgAAAAJ",
      "_8rw_GMAAAAJ",
      "uOyNG_AAAAAJ",
      "VBclY_cAAAAJ",
      "HXCMYLsAAAAJ",
      "KwEOawwAAAAJ",
      "rP3Ed1oAAAAJ",
      "OTFnifoAAAAJ",
      "miDt1j8AAAAJ",
      "RE_wHW0AAAAJ",
      "cIK1hS8AAAAJ",
      "EilVnKwAAAAJ",
      "uHwTzpYAAAAJ",
      "8CVIK-UAAAAJ",
      "BaY_Ie8AAAAJ",
      "G5_VFfkAAAAJ",
      "j7ZI1WUAAAAJ",
      "yd4xmlcAAAAJ",
      "UvFrX04AAAAJ",
      "PynKWyQAAAAJ",
      "AF6kWHUAAAAJ",
      "1_kJPIEAAAAJ",
      "CvwLRSMAAAAJ",
      "pPB_WK0AAAAJ",
      "FX6bV4UAAAAJ",
      "HKk8VjoAAAAJ",
      "vQa7heEAAAAJ",
      "I0HLZAwAAAAJ",
      "F5Ik84MAAAAJ",
      "wldNQHoAAAAJ",
      "iGLS8hMAAAAJ",
      "TiF1WEsAAAAJ",
      "wJR3IY4AAAAJ",
      "mEgZUP8AAAAJ",
      "sCypmFAAAAAJ",
      "yE6LvhMAAAAJ",
      "t4IWpnYAAAAJ",
      "icweOB0AAAAJ",
      "j40pfugAAAAJ",
      "8MFFVgEAAAAJ",
      "2UQAbkEAAAAJ",
      "GbVC5NYAAAAJ",
      "BvxYILIAAAAJ",
      "_iu2AD4AAAAJ",
      "jxQJo9MAAAAJ",
      "fNvryVUAAAAJ",
      "u3-FxUgAAAAJ",
      "ynIWXnUAAAAJ",
      "1Wlj18oAAAAJ",
      "ZYoaQYcAAAAJ",
      "Xz4RAJkAAAAJ",
      "cabvCW8AAAAJ",
      "mPpYLhcAAAAJ",
      "RvbzlYUAAAAJ",
      "V828uG8AAAAJ",
      "98iA_ooAAAAJ",
      "1QlW92QAAAAJ",
      "EtGdFOMAAAAJ",
      "VRR8fGoAAAAJ",
      "fmUkNVcAAAAJ",
      "SFffUYgAAAAJ",
      "fXy1pfcAAAAJ",
      "hzPq7jUAAAAJ",
      "0_1rZqgAAAAJ",
      "Yv-H6F4AAAAJ",
      "TZWVRR8AAAAJ",
      "_egJxfMAAAAJ",
      "X3gGi_0AAAAJ",
      "7TWQgcgAAAAJ",
      "rArDMRMAAAAJ",
      "wSE0nWUAAAAJ",
      "dJoAVvAAAAAJ",
      "U0JhTbAAAAAJ",
      "vspmOX8AAAAJ",
      "7ftnjtEAAAAJ",
      "j-MBXNMAAAAJ",
      "c8wc-6YAAAAJ",
      "YDLkVDoAAAAJ",
      "cnku7dQAAAAJ",
      "gVFnjOcAAAAJ",
      "HwFGzZMAAAAJ",
      "IFINq2QAAAAJ",
      "eWfiq9MAAAAJ",
      "mSK3340AAAAJ",
      "uodw8PQAAAAJ",
      "Ec8g_QwAAAAJ",
      "PRtkZzYAAAAJ",
      "DHSivXEAAAAJ",
      "Jg7O2scAAAAJ",
      "RGtMwTgAAAAJ",
      "O__9HOwAAAAJ",
      "Q1mcglAAAAAJ",
      "10ZeC3MAAAAJ",
      "Du7j3mQAAAAJ",
      "AIy7QHIAAAAJ",
      "lPaISmIAAAAJ",
      "ng9o57kAAAAJ",
      "_WLInT0AAAAJ",
      "22LTQSMAAAAJ",
      "l-xu2w0AAAAJ",
      "iGidFyoAAAAJ",
      "hrqU1KkAAAAJ",
      "-gEuUZIAAAAJ",
      "TV9sa6QAAAAJ",
      "zUHUsuAAAAAJ",
      "vn4dQRIAAAAJ",
      "LTa3GzEAAAAJ",
      "IyyEKyIAAAAJ",
      "NTAsObMAAAAJ",
      "FHOFCuEAAAAJ",
      "2COOamwAAAAJ",
      "QCH7hIEAAAAJ",
      "rE7-N30AAAAJ",
      "Sql50pkAAAAJ",
      "2maWWboAAAAJ",
      "WIAYNzMAAAAJ",
      "_kqpoHIAAAAJ",
      "LUe32ToAAAAJ",
      "VJZj2MsAAAAJ",
      "mu5Y2rYAAAAJ",
      "5n9CN80AAAAJ",
      "a8yv0nEAAAAJ",
      "ZvX1hXcAAAAJ",
      "vfT6-XIAAAAJ",
      "UV0IzT4AAAAJ",
      "KWez2_sAAAAJ",
      "37M48B0AAAAJ",
      "rF2VvOgAAAAJ",
      "q4zv0KYAAAAJ",
      "UwLsYw8AAAAJ",
      "5K1QB_8AAAAJ",
      "JiW8z50AAAAJ",
      "9HoiYnYAAAAJ",
      "CKyX_Y8AAAAJ",
      "Lt945BwAAAAJ",
      "3r-fWJwAAAAJ",
      "9uRDTmUAAAAJ",
      "ykFtI-QAAAAJ",
      "fadRi1YAAAAJ",
      "eZJI5sAAAAAJ",
      "-mh8RQ8AAAAJ",
      "3oe0I0QAAAAJ",
      "LgF3Ds0AAAAJ",
      "G5zYeD8AAAAJ",
      "sow8PQYAAAAJ",
      "4O4oaD0AAAAJ",
      "zm4UbBYAAAAJ",
      "oXasn9EAAAAJ",
      "646vnpUAAAAJ",
      "54urtxYAAAAJ",
      "8bQRH5YAAAAJ",
      "mKzKZfUAAAAJ",
      "yxh9tfEAAAAJ",
      "EkREu_QAAAAJ",
      "xZ8OqxMAAAAJ",
      "H3Uq3FcAAAAJ",
      "hSUP-4cAAAAJ",
      "ZvIdLmYAAAAJ",
      "Qirk2fYAAAAJ",
      "twuEPEEAAAAJ",
      "HbChXx0AAAAJ",
      "yriZqCMAAAAJ",
      "p71ikL4AAAAJ",
      "C7cw4msAAAAJ",
      "Tb0ZrYwAAAAJ",
      "C9rsD2UAAAAJ",
      "3SyxFIAAAAAJ",
      "nHCB2CkAAAAJ",
      "dErAioMAAAAJ",
      "71rMURwAAAAJ",
      "oUK2gu8AAAAJ",
      "IqcCDXkAAAAJ",
      "ILVcer0AAAAJ",
      "_ws9LLgAAAAJ",
      "U-RE8IgAAAAJ",
      "VIPjBSgAAAAJ",
      "ywWy5NIAAAAJ",
      "rk587vcAAAAJ",
      "P_luG3cAAAAJ",
      "p_ALSeoAAAAJ",
      "sQHdOycAAAAJ",
      "Q5J3UXwAAAAJ",
      "238DAAEAAAAJ",
      "wqRhBXMAAAAJ",
      "oclUWQEAAAAJ",
      "V-pBZI8AAAAJ",
      "bOElZi8AAAAJ",
      "yay_v9EAAAAJ",
      "H2JX-RQAAAAJ",
      "Ylp9SPUAAAAJ",
      "DdNAgNwAAAAJ",
      "zWfNZnIAAAAJ",
      "1sC6u3UAAAAJ",
      "LrHm5cgAAAAJ",
      "wbqHAq0AAAAJ",
      "n9K1v-cAAAAJ",
      "OPg56pYAAAAJ",
      "wbJ0vGkAAAAJ",
      "r3A90uAAAAAJ",
      "SlLz8KoAAAAJ",
      "todsDfQAAAAJ",
      "Br80hVMAAAAJ",
      "dGLTaaEAAAAJ",
      "Q8WGJtQAAAAJ",
      "1eBgIWsAAAAJ",
      "9_Hpd5kAAAAJ",
      "BZBkjNYAAAAJ",
      "PPCRqZUAAAAJ",
      "tP5rH0wAAAAJ",
      "ygQznUQAAAAJ",
      "E0iCaa4AAAAJ",
      "BBGlIGQAAAAJ",
      "xCYHonIAAAAJ",
      "ynJ-R00AAAAJ",
      "arjucpEAAAAJ",
      "2g0uKnAAAAAJ",
      "qSNAaCsAAAAJ",
      "j8GFD70AAAAJ",
      "ZTWrzykAAAAJ",
      "SjP9OAoAAAAJ",
      "sV61CtsAAAAJ",
      "DwTxLXAAAAAJ",
      "dh03btIAAAAJ",
      "RZ2KXioAAAAJ",
      "QOf1klMAAAAJ",
      "G2EJz5kAAAAJ",
      "HEozmkMAAAAJ",
      "-_EKVQ0AAAAJ",
      "aKBwXEEAAAAJ",
      "SAemU0sAAAAJ",
      "O8eqJA4AAAAJ",
      "DxoenfgAAAAJ",
      "nUZG1SEAAAAJ",
      "uztQCmMAAAAJ",
      "zc2F3G0AAAAJ",
      "XBk56N0AAAAJ",
      "B8sRETUAAAAJ",
      "xxiTm5EAAAAJ",
      "goCW1d8AAAAJ",
      "UzjHQLcAAAAJ",
      "JUn8PgwAAAAJ",
      "pIwcxfoAAAAJ",
      "zMw7PF8AAAAJ",
      "BUc2uq0AAAAJ",
      "brsVjNcAAAAJ",
      "x9ly9Q0AAAAJ",
      "v0DNZWUAAAAJ",
      "-YP8MJ0AAAAJ",
      "okcbLqoAAAAJ",
      "WPFAXNAAAAAJ",
      "qx_e_9wAAAAJ",
      "ex9BQiIAAAAJ",
      "kqW_-2gAAAAJ",
      "IwBHa3gAAAAJ",
      "LNc2cxUAAAAJ",
      "N7_xhHoAAAAJ",
      "VZIAzPcAAAAJ",
      "Evgx6UkAAAAJ",
      "Wlq5rZEAAAAJ",
      "Es6jE1kAAAAJ",
      "5V7VFi8AAAAJ",
      "N_Z0SDMAAAAJ",
      "8bwdGesAAAAJ",
      "TXTlU3sAAAAJ",
      "16OCMAQAAAAJ",
      "gkCjy_UAAAAJ",
      "X7kZFnoAAAAJ",
      "UNzFsf4AAAAJ",
      "8fFjYbwAAAAJ",
      "fWd88tEAAAAJ",
      "_twaeHkAAAAJ",
      "OZlvV6kAAAAJ",
      "OXtG-isAAAAJ",
      "T6h8tLcAAAAJ",
      "Y2YBgCsAAAAJ",
      "6QQX88UAAAAJ",
      "BFfjA-8AAAAJ",
      "OCdJxC8AAAAJ",
      "ZOF0KysAAAAJ",
      "1cj23VYAAAAJ",
      "UV9LxSEAAAAJ",
      "k4k05hcAAAAJ",
      "7KDSCpQAAAAJ",
      "yAsgeGIAAAAJ",
      "EMADq2wAAAAJ",
      "8y9rrq0AAAAJ",
      "_3O0RcUAAAAJ",
      "YZ8Y-sUAAAAJ",
      "FHiQmOoAAAAJ",
      "5M5nkGAAAAAJ",
      "fXl8n9YAAAAJ",
      "14HASnUAAAAJ",
      "tvgSaXsAAAAJ",
      "-8DNE4UAAAAJ",
      "PlQaW9YAAAAJ",
      "wGG1voYAAAAJ",
      "4B-C50EAAAAJ",
      "LNtKWuIAAAAJ",
      "CUqzFcEAAAAJ",
      "5pJNSzMAAAAJ",
      "4v73L2AAAAAJ",
      "cxYepGkAAAAJ",
      "-gNBIsYAAAAJ",
      "P8NRbbYAAAAJ",
      "E2-uIQYAAAAJ",
      "rQoKPUsAAAAJ",
      "TmuUs30AAAAJ",
      "0IXxNKsAAAAJ",
      "3hYIetoAAAAJ",
      "-rlnZrMAAAAJ",
      "CjRMyA4AAAAJ",
      "ttBdcmsAAAAJ",
      "rmsIyGMAAAAJ",
      "ErvkcKcAAAAJ",
      "-3VoT8cAAAAJ",
      "uxk0GmUAAAAJ",
      "ZXCO3DMAAAAJ",
      "HHd7uewAAAAJ",
      "sqWpn2AAAAAJ",
      "TwMib_QAAAAJ",
      "TBaBNdkAAAAJ",
      "gYj6GRoAAAAJ",
      "LeHa8psAAAAJ",
      "4M6ky2UAAAAJ",
      "IhmK-VkAAAAJ",
      "ZCN03-cAAAAJ",
      "yWJ9BqEAAAAJ",
      "fhaNx_oAAAAJ",
      "SzZRlcMAAAAJ",
      "bI0cfykAAAAJ",
      "a4D08aQAAAAJ",
      "nuwXTh4AAAAJ",
      "IWcGY98AAAAJ",
      "dbggnnAAAAAJ",
      "R0kl_BUAAAAJ",
      "NDyEvlQAAAAJ",
      "U3w720cAAAAJ",
      "Sh5PsUUAAAAJ",
      "mQTedo0AAAAJ",
      "k-DMEhAAAAAJ",
      "jH9i188AAAAJ",
      "UZLC4TYAAAAJ",
      "wwkJvoMAAAAJ",
      "H1v0ztEAAAAJ",
      "arXWx_oAAAAJ",
      "VLft_T4AAAAJ",
      "wziaKmQAAAAJ",
      "zff-8GkAAAAJ",
      "D1uOAWcAAAAJ",
      "3ZLk60QAAAAJ",
      "761-alkAAAAJ",
      "a_dbdxAAAAAJ",
      "tfKeplgAAAAJ",
      "IWwCuGAAAAAJ",
      "364jgpgAAAAJ",
      "cGxq0cMAAAAJ",
      "7cLt5PAAAAAJ",
      "hJjeVsQAAAAJ",
      "7tr3iQkAAAAJ",
      "Ivot3fkAAAAJ",
      "mXJHzYkAAAAJ",
      "aSqr26EAAAAJ",
      "XSUvsTMAAAAJ",
      "tzYolooAAAAJ",
      "6xWhoLoAAAAJ",
      "y0B6gawAAAAJ",
      "dVtzVVAAAAAJ",
      "9y3Kd3cAAAAJ",
      "kMmxbbIAAAAJ",
      "nSpXpqMAAAAJ",
      "wbZc9nUAAAAJ",
      "r1quzEkAAAAJ",
      "XxGyUpAAAAAJ",
      "zK33NPkAAAAJ",
      "7wclGnQAAAAJ",
      "Z43BgdEAAAAJ",
      "M8Hz2NSNe3QC",
      "aMZAyzwAAAAJ",
      "MhXqCRAAAAAJ",
      "ICNU7sAAAAAJ",
      "06OJ1FQAAAAJ",
      "e8kIbEYAAAAJ",
      "ghpLm2cAAAAJ",
      "AqST318AAAAJ",
      "XW6MbmAAAAAJ",
      "7c1B_fIAAAAJ",
      "9XrWuI8AAAAJ",
      "4DFgv64AAAAJ",
      "03n03GEAAAAJ",
      "61k0rBQAAAAJ",
      "sF1vZ0oAAAAJ",
      "1S7VwIcAAAAJ",
      "yTd5KnYAAAAJ",
      "ieDx3WwAAAAJ",
      "gy4UVGcAAAAJ",
      "eZmKjZEAAAAJ",
      "NJ3TiCIAAAAJ",
      "FqNPXeoAAAAJ",
      "keDqjK0AAAAJ",
      "qq3TxtcAAAAJ",
      "tnimPrsAAAAJ",
      "3o1o4ukAAAAJ",
      "I15dUOwAAAAJ",
      "5TZ7f5wAAAAJ",
      "bioUtz4AAAAJ",
      "3nXmUP0AAAAJ",
      "FC9Bt6cAAAAJ",
      "JZIeZ3MAAAAJ",
      "fSXCOfEAAAAJ",
      "beXm1FwAAAAJ",
      "vHTMzPQAAAAJ",
      "s0Fof5IAAAAJ",
      "UNHdIKoAAAAJ",
      "FHtM5MUAAAAJ",
      "oDwLyYUAAAAJ",
      "2E448xEAAAAJ",
      "M9V6y-0AAAAJ",
      "yDZct7UAAAAJ",
      "lJAkLo8AAAAJ",
      "iyD9aw8AAAAJ",
      "Svk4ntYAAAAJ",
      "BexX9vYAAAAJ",
      "Km5y5nIAAAAJ",
      "Olalwx8AAAAJ",
      "r4-NZhwAAAAJ",
      "gGcRkpYAAAAJ",
      "_JhgbioAAAAJ",
      "lECZKZsAAAAJ",
      "qenoZwUAAAAJ",
      "iLOoUqIAAAAJ",
      "qioqafgAAAAJ",
      "yMGBji4AAAAJ",
      "jdcLB8kAAAAJ",
      "7y6i1SQAAAAJ",
      "hEOInHkAAAAJ",
      "kKYbS08AAAAJ",
      "7ZNoHJkAAAAJ",
      "ml-AyBQAAAAJ",
      "i-AStBYAAAAJ",
      "7b5tlJkAAAAJ",
      "qrCVP0YAAAAJ",
      "dyD6nsgAAAAJ",
      "-xQ-C1sAAAAJ",
      "fIoDWp8AAAAJ",
      "VXtCp7MAAAAJ",
      "aAAY3oYAAAAJ",
      "0fA9EQcAAAAJ",
      "Vpr6s3sAAAAJ",
      "mIlaYj0AAAAJ",
      "TAomEzQAAAAJ",
      "g0neHX8AAAAJ",
      "6KkohssAAAAJ",
      "lDfq31wAAAAJ",
      "Koez6qoAAAAJ",
      "CrfsfFSiS0kC",
      "jJ8BLgsAAAAJ",
      "AFf15XkAAAAJ",
      "sbsFpScAAAAJ",
      "LeshmV8AAAAJ",
      "_xyC5igAAAAJ",
      "AERPOfAAAAAJ",
      "ZT1ZkRcAAAAJ",
      "BTn-nikAAAAJ",
      "xIJHTUwAAAAJ",
      "1H4HuCkAAAAJ",
      "oAbEdzUAAAAJ",
      "UztDgakAAAAJ",
      "yqqESloAAAAJ",
      "Actb5ZYAAAAJ",
      "a959F6AAAAAJ",
      "oHv6BrYAAAAJ",
      "1FIyc9kAAAAJ",
      "jZCCpsIAAAAJ",
      "jxpBMwwAAAAJ",
      "XrKLUO0AAAAJ",
      "9wibWOoAAAAJ",
      "wpdabDgAAAAJ",
      "0lO_16kAAAAJ",
      "HqGW4HIAAAAJ",
      "ToU9KBUAAAAJ",
      "jz2Tvk4AAAAJ",
      "fi4HWW8AAAAJ",
      "V-lc8A8AAAAJ",
      "YUHMFMMAAAAJ",
      "qWEImhMAAAAJ",
      "3vKjkoQAAAAJ",
      "pYBdBjkAAAAJ",
      "eZQNcvcAAAAJ",
      "-hexEEAAAAAJ",
      "EzoDsIMAAAAJ",
      "_oZJDPEAAAAJ",
      "lD4Yjn4AAAAJ",
      "6wCEmNYAAAAJ",
      "GLSQo5gAAAAJ",
      "jqHoz9EAAAAJ",
      "euwkGt0AAAAJ",
      "-bp44DoAAAAJ",
      "P1OaUP8AAAAJ",
      "moOv1BsAAAAJ",
      "ddu5MKwAAAAJ",
      "YYJ3aycAAAAJ",
      "OiVOAHMAAAAJ",
      "Jp6Mz1sAAAAJ",
      "5pKdNQkAAAAJ",
      "9RnyW0cAAAAJ",
      "yFLmPsoAAAAJ",
      "hhu_TQsAAAAJ",
      "Q8kbUQEAAAAJ",
      "75q-6ZQAAAAJ",
      "rIoPIFsAAAAJ",
      "iGWgEw8AAAAJ",
      "d8pmohMAAAAJ",
      "jphx5uUAAAAJ",
      "Dy8iau4AAAAJ",
      "NRlzPgIAAAAJ",
      "llcGIZ8AAAAJ",
      "SMn18BwAAAAJ",
      "oz4Ca9AAAAAJ",
      "2hjvDoAAAAAJ",
      "gaqzMHAAAAAJ",
      "iHpqfoQAAAAJ",
      "kwZTvH4AAAAJ",
      "YRPveMcAAAAJ",
      "4Vwt9AEAAAAJ",
      "qR7R2FMAAAAJ",
      "PI30hN8AAAAJ",
      "4v5x0bUAAAAJ",
      "Hl8N_k8AAAAJ",
      "jI3_2koAAAAJ",
      "Hd3kUc4AAAAJ",
      "U_Jw8DUAAAAJ",
      "eLFhiSYAAAAJ",
      "jXfleiEAAAAJ",
      "T_mJiHoAAAAJ",
      "9I4xFcIAAAAJ",
      "Li0F9VAAAAAJ",
      "Gz1YIaUAAAAJ",
      "Dmrm4skAAAAJ",
      "7BM1uyYAAAAJ",
      "UypFDoQAAAAJ",
      "PDu5GC8AAAAJ",
      "2f6t6hYAAAAJ",
      "Ci5YRtAAAAAJ",
      "Q6F3O0sAAAAJ",
      "gMBvzGoAAAAJ",
      "bN_de_QAAAAJ",
      "Mu_8iOEAAAAJ",
      "Iv6ll44AAAAJ",
      "wlxnii4AAAAJ",
      "RU0ZAp4AAAAJ",
      "S6moyNoAAAAJ",
      "vsLT1BIAAAAJ",
      "nHlOHXMAAAAJ",
      "d6vuvHIAAAAJ",
      "3_tE6JgAAAAJ",
      "HzlOQRkAAAAJ",
      "zXhuhtwAAAAJ",
      "GHpxNQIAAAAJ",
      "qa4M89wAAAAJ",
      "3bSbb20AAAAJ",
      "pCe3nQgAAAAJ",
      "WIKDWBQAAAAJ",
      "BMo9cZ4AAAAJ",
      "uMPWVtIAAAAJ",
      "6hPAjdYAAAAJ",
      "OP7F8jEAAAAJ",
      "FY-jB3QAAAAJ",
      "bX__wkYAAAAJ",
      "iQxXG8kAAAAJ",
      "F8_JP6sAAAAJ",
      "CHAajY4AAAAJ",
      "PGZLZFUAAAAJ",
      "CM5qHwQAAAAJ",
      "RatgWlcAAAAJ",
      "Zb0NwBUAAAAJ",
      "lc6CVqEAAAAJ",
      "p_iffpcAAAAJ",
      "7k5QSdoAAAAJ",
      "1_zc1-IAAAAJ",
      "AMFWWyMAAAAJ",
      "sdSjnhwAAAAJ",
      "lWmGADwAAAAJ",
      "hYtGXD0AAAAJ",
      "GhvZjJUAAAAJ",
      "V_VEjLUAAAAJ",
      "ynDHUwkAAAAJ",
      "HEO-wOQAAAAJ",
      "GPusciUAAAAJ",
      "EASHOTUAAAAJ",
      "qQgUtucAAAAJ",
      "XRujzBsAAAAJ",
      "Wel9l1wAAAAJ",
      "7-9jOvEAAAAJ",
      "z3TC8X0AAAAJ",
      "wRw-e8EAAAAJ",
      "YRbB4CgAAAAJ",
      "_kJ-zUYAAAAJ",
      "Sx75CVsAAAAJ",
      "Z5ZeWGMAAAAJ",
      "7vyVxxQAAAAJ",
      "47n-0mwAAAAJ",
      "5cSFXKQAAAAJ",
      "SnQjip0AAAAJ",
      "JzXA6NEAAAAJ",
      "UO7McmEAAAAJ",
      "10RVXDQAAAAJ",
      "M1IgIyMAAAAJ",
      "y5fsjDAAAAAJ",
      "GNiinUoAAAAJ",
      "RjPS_lUAAAAJ",
      "2L_8ynAAAAAJ",
      "XqAe43gAAAAJ",
      "RCvR5HAAAAAJ",
      "JAmTk5gAAAAJ",
      "m_HQ-WQAAAAJ",
      "rAP3wVwAAAAJ",
      "1O83J5MAAAAJ",
      "7EPsnxEAAAAJ",
      "eJwbbXEAAAAJ",
      "W5WbqgoAAAAJ",
      "hBRnEHIAAAAJ",
      "os-DVLkAAAAJ",
      "sI0wlX8AAAAJ",
      "FABZCeAAAAAJ",
      "DZ-fHPgAAAAJ",
      "gvo0nMsAAAAJ",
      "5m-oAesAAAAJ",
      "Y0MyYO0AAAAJ",
      "HQRnt54AAAAJ",
      "Dk0fJHIAAAAJ",
      "koQCVT4AAAAJ",
      "y6wdLA8AAAAJ",
      "mWpu_ooAAAAJ",
      "O9hYMUUAAAAJ",
      "9-iC3BsAAAAJ",
      "o_4HDRwAAAAJ",
      "5o111aIAAAAJ",
      "g9WLzWoAAAAJ",
      "aGvH4yMAAAAJ",
      "rUZN-zQAAAAJ",
      "ZTe13LgAAAAJ",
      "tu39-p8AAAAJ",
      "pYPowr8AAAAJ",
      "nTl5mSwAAAAJ",
      "NAdlsUgAAAAJ",
      "qyMRxowAAAAJ",
      "WuEJs1AAAAAJ",
      "-KN-O0sAAAAJ",
      "MExi4eQAAAAJ",
      "w1_KlvoAAAAJ",
      "PwQHMlwAAAAJ",
      "6vXTtDQAAAAJ",
      "Mo8VdkoAAAAJ",
      "NQgRwKAAAAAJ",
      "6-e-ZBEAAAAJ",
      "pbmjtZsAAAAJ",
      "POlWWAsAAAAJ",
      "_DEJi28AAAAJ",
      "q_n7d6EAAAAJ",
      "9BMXWA8AAAAJ",
      "_cIeQgYAAAAJ",
      "SACXQKYAAAAJ",
      "j7uL6VEAAAAJ",
      "90Yb_90AAAAJ",
      "xNxlvjEAAAAJ",
      "w0OodaEAAAAJ",
      "5JlEyTAAAAAJ",
      "J_1GGJsAAAAJ",
      "a068aTEAAAAJ",
      "znnl0kwAAAAJ",
      "Ns8jBNsAAAAJ",
      "aMUoVMMAAAAJ",
      "8EDHmYkAAAAJ",
      "5EGhZTgAAAAJ",
      "VtbaGhIAAAAJ",
      "ZiEaIpUAAAAJ",
      "CgSBtPYAAAAJ",
      "wcr5g6oAAAAJ",
      "m3DDS00AAAAJ",
      "6rQZU7MAAAAJ",
      "_dVzmiYAAAAJ",
      "d10sXc8AAAAJ",
      "ATkNLcQAAAAJ",
      "2Q1BK6gAAAAJ",
      "FUSSkq0AAAAJ",
      "jV66t1kAAAAJ",
      "r3dW1m0AAAAJ",
      "H4CPLUQAAAAJ",
      "KjOV76MAAAAJ",
      "AYpm7KcAAAAJ",
      "t9PEVrkAAAAJ",
      "_KxkI6UAAAAJ",
      "dASv28sAAAAJ",
      "QEh45NMAAAAJ",
      "miAQ1Q4AAAAJ",
      "YO5XSXwAAAAJ",
      "tGAimhAAAAAJ",
      "1MZF70cAAAAJ",
      "L-ek-X4AAAAJ",
      "sRpY9TIAAAAJ",
      "74Cj5GYAAAAJ",
      "5Zf13ZsAAAAJ",
      "6S-WgLkAAAAJ",
      "KfTWTtAAAAAJ",
      "VBXG4CwAAAAJ",
      "8D_Ggb4AAAAJ",
      "BIwrJuQAAAAJ",
      "Rp5teiwAAAAJ",
      "qVzY4XYAAAAJ",
      "T6PbwPIAAAAJ",
      "Nxmx29UAAAAJ",
      "hI8nho4AAAAJ",
      "GNwyyrsAAAAJ",
      "7KgIMosAAAAJ",
      "XnHdkZUAAAAJ",
      "J1awhoMAAAAJ",
      "VGfczTIAAAAJ",
      "4NUg-zkAAAAJ",
      "pPcNe2EAAAAJ",
      "tQuQ1FwAAAAJ",
      "rY8u8xkAAAAJ",
      "Zp8MeiUAAAAJ",
      "EpA-_qgAAAAJ",
      "hMZMhLoAAAAJ",
      "3xUoKkwAAAAJ",
      "jaNr8IoAAAAJ",
      "CsQTBwsAAAAJ",
      "vzr_L0EAAAAJ",
      "_FeYgnUAAAAJ",
      "SmGZwHYAAAAJ",
      "-Ve9sJ0AAAAJ",
      "y1u15RcAAAAJ",
      "swf47vcAAAAJ",
      "DYUloYkAAAAJ",
      "q3K8X-IAAAAJ",
      "xkH30GgAAAAJ",
      "-fEOFbMAAAAJ",
      "117h3CAAAAAJ",
      "odYttFAAAAAJ",
      "ESRugcEAAAAJ",
      "8qOWtywAAAAJ",
      "weicM8wAAAAJ",
      "CpMjT0YAAAAJ",
      "JY-WzksAAAAJ",
      "2a5XgNAAAAAJ",
      "Y6vuiBUAAAAJ",
      "rSVIHasAAAAJ",
      "HO-fMd8AAAAJ",
      "HeVcLzAAAAAJ",
      "aQmpeAEAAAAJ",
      "-OVm5iMAAAAJ",
      "MHQv5YUAAAAJ",
      "fXxhg5EAAAAJ",
      "cHAnhqcAAAAJ",
      "HsfKE0sAAAAJ",
      "9rAYhr8AAAAJ",
      "cx_Kg8MAAAAJ",
      "mZcPPW4AAAAJ",
      "D37XAbIAAAAJ",
      "F3YYEmMAAAAJ",
      "hIq09eUAAAAJ",
      "hdXvVdgAAAAJ",
      "bW6qGV0AAAAJ",
      "LX2QWBYAAAAJ",
      "w3fqzIYAAAAJ",
      "QYesEdIAAAAJ",
      "yngEYigAAAAJ",
      "e1GAF6sAAAAJ",
      "zwr9wPEAAAAJ",
      "KsocBp8AAAAJ",
      "Wd4ChQ8AAAAJ",
      "Fmq16C4AAAAJ",
      "oVLqz3AAAAAJ",
      "XPFPohcAAAAJ",
      "Rh16nsIAAAAJ",
      "0gkajvEAAAAJ",
      "NcIqQ88AAAAJ",
      "g2nxKt0AAAAJ",
      "fArWdfAAAAAJ",
      "7zp9arUAAAAJ",
      "WsRunnEAAAAJ",
      "Nf48jqcAAAAJ",
      "MMRpEk0AAAAJ",
      "v19p_0oAAAAJ",
      "qdnDZkYAAAAJ",
      "s2Y3qnwAAAAJ",
      "li4mEfcAAAAJ",
      "9IpdcgMAAAAJ",
      "MxeFvewAAAAJ",
      "uFJi3IUAAAAJ",
      "8tpFFEMAAAAJ",
      "_0_p13YAAAAJ",
      "w1srHyIAAAAJ",
      "oZGA-rAAAAAJ",
      "Ual305IAAAAJ",
      "nm3liowAAAAJ",
      "xSavR6cAAAAJ",
      "2F8T0yAAAAAJ",
      "RjJyha8AAAAJ",
      "e-c3R8QAAAAJ",
      "9700p4IAAAAJ",
      "BYSy-9oAAAAJ",
      "BYoq_bwAAAAJ",
      "GhzAXmIAAAAJ",
      "ghdbIsoAAAAJ",
      "Y8ep3h8AAAAJ",
      "lHI7-XoAAAAJ",
      "7jZjfZ8AAAAJ",
      "GseGXPsAAAAJ",
      "VKbBIIoAAAAJ",
      "EemUE4gAAAAJ",
      "7yqJjsgAAAAJ",
      "bg8RrSkAAAAJ",
      "3Yjo-W8AAAAJ",
      "VrFFU84AAAAJ",
      "S9Q7lk4AAAAJ",
      "jMUkLqwAAAAJ",
      "XpscC-EAAAAJ",
      "omfoflQAAAAJ",
      "5f3dXLkAAAAJ",
      "BZGj6sAAAAAJ",
      "ja7P1hQAAAAJ",
      "jk17mo8AAAAJ",
      "vsj2slIAAAAJ",
      "4-AyPLsAAAAJ",
      "45KfCpgAAAAJ",
      "TKUlJukAAAAJ",
      "hMG_gR4AAAAJ",
      "edh9Nv4AAAAJ",
      "AZILAMsAAAAJ",
      "nRKhCa8AAAAJ",
      "1iE2ykkAAAAJ",
      "okx33sUAAAAJ",
      "R_2aiNIAAAAJ",
      "lptAmrMAAAAJ",
      "Hy4JQ2MAAAAJ",
      "Efs3XxQAAAAJ",
      "8SSdKyMAAAAJ",
      "19evEwcAAAAJ",
      "zMspIjIAAAAJ",
      "mc-_DrEAAAAJ",
      "k_9sF90AAAAJ",
      "pWRtbiMAAAAJ",
      "39VDRnoAAAAJ",
      "Q6UMpRYAAAAJ",
      "Xs7cKMwAAAAJ",
      "NRoF0iwAAAAJ",
      "4UvZdF8AAAAJ",
      "t8UduWwAAAAJ",
      "RWV9I_IAAAAJ",
      "eIRG81YAAAAJ",
      "ZIw-AGsAAAAJ",
      "7wuq-7AAAAAJ",
      "LW7uksIAAAAJ",
      "WeIvMTUAAAAJ",
      "dGs2BcIAAAAJ",
      "fDHUk18AAAAJ",
      "Cj-TQ-AAAAAJ",
      "W6bign0AAAAJ",
      "j0_fn9oAAAAJ",
      "z0RoFtcAAAAJ",
      "hgZrGpkAAAAJ",
      "7dQo6WcAAAAJ",
      "xTi3ouAAAAAJ",
      "FVKgcAsAAAAJ",
      "fsqz49kAAAAJ",
      "C8S84g8AAAAJ",
      "qhEK194AAAAJ",
      "xITAf6EAAAAJ",
      "K6ef57QAAAAJ",
      "I7RhPnIAAAAJ",
      "n4YG-zkAAAAJ",
      "3zP4ag0AAAAJ",
      "3TMipekAAAAJ",
      "ckZ7q_gAAAAJ",
      "1ed1sPkAAAAJ",
      "r1TJBr8AAAAJ",
      "H-PvgRsAAAAJ",
      "5SUDRqsAAAAJ",
      "KcPrLhIAAAAJ",
      "0-I8YNgAAAAJ",
      "m0PW6DQAAAAJ",
      "NvBZp6MAAAAJ",
      "1PBvwCgAAAAJ",
      "i5PazXwAAAAJ",
      "1vEw_kgAAAAJ",
      "f3V6gZMAAAAJ",
      "qSQjR4EAAAAJ",
      "xhbf6_oAAAAJ",
      "080Y_lUAAAAJ",
      "jzddqQQAAAAJ",
      "1G4GV2EAAAAJ",
      "hb1bGgUAAAAJ",
      "s9UDcdYAAAAJ",
      "pjPtYgEAAAAJ",
      "kfdwrbYAAAAJ",
      "LcOIFHEAAAAJ",
      "Ssdg9-sAAAAJ",
      "r2Gjhg4AAAAJ",
      "7-2bbBgAAAAJ",
      "UE6z_m8AAAAJ",
      "1LuGqFQAAAAJ",
      "nrSsSrkAAAAJ",
      "6_U35tAAAAAJ",
      "zRQMWrkAAAAJ",
      "2UiIURcAAAAJ",
      "QHSUy3MAAAAJ",
      "Ii7P2QQAAAAJ",
      "s9RsYfcAAAAJ",
      "vyD4QMUAAAAJ",
      "rGS1KaAAAAAJ",
      "SVIdh6AAAAAJ",
      "564o-vIAAAAJ",
      "1nxepREAAAAJ",
      "PsfzbCMAAAAJ",
      "iW_lUIkAAAAJ",
      "s0OErVYAAAAJ",
      "LjTCVxAAAAAJ",
      "6cNoBY4AAAAJ",
      "eECXWqUAAAAJ",
      "yA4rb60AAAAJ",
      "0zrqo3B-66wC",
      "whNDkmMAAAAJ",
      "3Q6vpxYAAAAJ",
      "4wXYfSUAAAAJ",
      "RLOXUngAAAAJ",
      "2r7JwHIAAAAJ",
      "_Fah5fwAAAAJ",
      "axf9B1gAAAAJ",
      "Qyk0paAAAAAJ",
      "OxKLBqwAAAAJ",
      "SZ7-g60AAAAJ",
      "b32YyLIAAAAJ",
      "28p_eLYAAAAJ",
      "pJ8vEo8AAAAJ",
      "rkpVQI4AAAAJ",
      "YPq45Q0AAAAJ",
      "ywv6tDUAAAAJ",
      "oS6gRc4AAAAJ",
      "QMc-grEAAAAJ",
      "jHD1kUsAAAAJ",
      "h0_3SjAAAAAJ",
      "SY8DwiUAAAAJ",
      "reUYd_0AAAAJ",
      "YvHcBcEAAAAJ",
      "cXPscXUAAAAJ",
      "YkeS_SoAAAAJ",
      "DyABVI0AAAAJ",
      "4H4bRkcAAAAJ",
      "0P1J-m8AAAAJ",
      "YayQtGUAAAAJ",
      "3pu8FE0AAAAJ",
      "YfompPIAAAAJ",
      "Yr2yu_sAAAAJ",
      "ohTFQMMAAAAJ",
      "LxsF51oAAAAJ",
      "whu7X_kAAAAJ",
      "4j-x4ckAAAAJ",
      "IDItm6cAAAAJ",
      "MbsEFrYAAAAJ",
      "h6-lPBsAAAAJ",
      "24OOpyEAAAAJ",
      "EY2lqD0AAAAJ",
      "HM_8xZYAAAAJ",
      "H-VmFU4AAAAJ",
      "CU1rungAAAAJ",
      "xk6HHiAAAAAJ",
      "3zhgn8MAAAAJ",
      "2ZYz2SwAAAAJ",
      "1oqm0boAAAAJ",
      "pKuBFaQAAAAJ",
      "HdEjj2MAAAAJ",
      "3Oiv9FwAAAAJ",
      "BGmxwfAAAAAJ",
      "nek5vXMAAAAJ",
      "9Wq1xSUAAAAJ",
      "samruv0AAAAJ",
      "qBy4wKcAAAAJ",
      "YzsCLBoAAAAJ",
      "I6P0SwgAAAAJ",
      "0z0fNxUAAAAJ",
      "JKVR2ksAAAAJ",
      "yKCX2IUAAAAJ",
      "h1r4NG0AAAAJ",
      "9GHrCy4AAAAJ",
      "32w7x1cAAAAJ",
      "l8dX3ssAAAAJ",
      "pkqB2vEAAAAJ",
      "WZfM0qsAAAAJ",
      "ZurKqVkAAAAJ",
      "t2X4Mg8AAAAJ",
      "yQNhFGUAAAAJ",
      "2IXVwTMAAAAJ",
      "GF4pITIAAAAJ",
      "qO3AeDoAAAAJ",
      "5mJDXjoAAAAJ",
      "iVXG-IkAAAAJ",
      "MDDx3Q4AAAAJ",
      "OeULb38AAAAJ",
      "AWKaiasAAAAJ",
      "cTZ7Bg8AAAAJ",
      "Al8dyb4AAAAJ",
      "P1XH4nkAAAAJ",
      "SfBBevUAAAAJ",
      "C-NftTgAAAAJ",
      "6iOJ8foAAAAJ",
      "uOLwGG4AAAAJ",
      "5oa_2lgAAAAJ",
      "JNER_T4AAAAJ",
      "9hQJrpAAAAAJ",
      "10Fx1a4AAAAJ",
      "VgzYS6IAAAAJ",
      "TQw8WLEAAAAJ",
      "axsP38wAAAAJ",
      "se9kni0AAAAJ",
      "8DvzhZMAAAAJ",
      "n6zUuaQAAAAJ",
      "Xr_hCJMAAAAJ",
      "Adug-7cAAAAJ",
      "h-EphF0AAAAJ",
      "Q4oVM7IAAAAJ",
      "3tIEZhAAAAAJ",
      "NCtKHnQAAAAJ",
      "BfDKicQAAAAJ",
      "Z_kok3sAAAAJ",
      "uCoRgGgAAAAJ",
      "zUu0JKYAAAAJ",
      "OaAO-aIAAAAJ",
      "VD5OsIwAAAAJ",
      "nd0G8qEAAAAJ",
      "xWI4K4sAAAAJ",
      "GPJ2qqgAAAAJ",
      "-9AvWrwAAAAJ",
      "sOG3L94AAAAJ",
      "bqL73OkAAAAJ",
      "hxlxVEUAAAAJ",
      "wp1MXzsAAAAJ",
      "S8kPovUAAAAJ",
      "o6W_m00AAAAJ",
      "tbu1jqUAAAAJ",
      "s7ky8QUAAAAJ",
      "LNZ4efwAAAAJ",
      "B88-xMEAAAAJ",
      "RmhQmkwAAAAJ",
      "pmVPj94AAAAJ",
      "1FtOcrMAAAAJ",
      "x3hvdTsAAAAJ",
      "wmx7KVUAAAAJ",
      "bu1SCOuD_CMC",
      "JId76kkAAAAJ",
      "KYHL9aIAAAAJ",
      "bC-gapAAAAAJ",
      "H_6RQ7oAAAAJ",
      "KjfpioYAAAAJ",
      "f5vdXEQAAAAJ",
      "UnrY-40AAAAJ",
      "UWyyLgIAAAAJ",
      "g-_ZXGsAAAAJ",
      "LWmEzL0AAAAJ",
      "PA9La6oAAAAJ",
      "h1XZv94AAAAJ",
      "NR59_v4AAAAJ",
      "ZFGMQsEAAAAJ",
      "If8AWhgAAAAJ",
      "YzxIuqwAAAAJ",
      "4uypulQAAAAJ",
      "fT7XeUEAAAAJ",
      "4TbxnY0AAAAJ",
      "_3_Y0xQAAAAJ",
      "gP9EAWkAAAAJ",
      "08CNqrYAAAAJ",
      "Ga4j7UIAAAAJ",
      "O-oICE8AAAAJ",
      "-hr7rD8AAAAJ",
      "TX6achUAAAAJ",
      "4bl7qAgAAAAJ",
      "H-A5KBYAAAAJ",
      "B4NztA8AAAAJ",
      "4k9lBsoAAAAJ",
      "AGPooMYAAAAJ",
      "gsv5xicAAAAJ",
      "FR8zF_4AAAAJ",
      "0lZoXCUAAAAJ",
      "H7vcwSAAAAAJ",
      "OR5Lx4MAAAAJ",
      "mapNJjcAAAAJ",
      "5w0Y9JUAAAAJ",
      "obpl7GQAAAAJ",
      "DzSgRSoAAAAJ",
      "BGxhOlEAAAAJ",
      "P5eWdgsAAAAJ",
      "uS6-ZOMAAAAJ",
      "OZDGXgwAAAAJ",
      "rXqA5nYAAAAJ",
      "Xlv5PDYAAAAJ",
      "y_sLoXoAAAAJ",
      "WrFQzBIAAAAJ",
      "tCo0KhkAAAAJ",
      "js-mvgoAAAAJ",
      "fF1B7mAAAAAJ",
      "gYXvxhQAAAAJ",
      "ataejQQAAAAJ",
      "djLcGEQAAAAJ",
      "zIS5ibQAAAAJ",
      "7ip1Ih8AAAAJ",
      "WLN3QrAAAAAJ",
      "GGcjtCsAAAAJ",
      "i2oLdaYAAAAJ",
      "wRYM4qgAAAAJ",
      "lXpi86gAAAAJ",
      "dQmvEyUAAAAJ",
      "x9K4md8AAAAJ",
      "GpXyLGwAAAAJ",
      "YYT8-7kAAAAJ",
      "5LubxuUAAAAJ",
      "kwqPtgcAAAAJ",
      "LqBEONAAAAAJ",
      "zpil5xkAAAAJ",
      "18O0OAwAAAAJ",
      "DRt16WsAAAAJ",
      "O0lONMkAAAAJ",
      "Vb3FLmkAAAAJ",
      "Y0FLn-8AAAAJ",
      "Bdy3OD0AAAAJ",
      "IIci8lAAAAAJ",
      "TB5OwW8AAAAJ",
      "_wds938AAAAJ",
      "rUcRJEkAAAAJ",
      "jF4dPZwAAAAJ",
      "MDRALDkAAAAJ",
      "HtNfeKYAAAAJ",
      "xMhGYpgAAAAJ",
      "YBttbLMAAAAJ",
      "mMjWcPAAAAAJ",
      "eqgEprEAAAAJ",
      "RZOjMYMAAAAJ",
      "MiI7lj0AAAAJ",
      "m3f70oYAAAAJ",
      "uIpPgJEAAAAJ",
      "4R7_wW8AAAAJ",
      "FEvVS54AAAAJ",
      "BI8xFr4AAAAJ",
      "_BPdgV0AAAAJ",
      "Lw0H0EwAAAAJ",
      "y-f-MZgAAAAJ",
      "_zSP7YMAAAAJ",
      "6yMIP8AAAAAJ",
      "5cIodxsAAAAJ",
      "xDtTbmQAAAAJ",
      "vEYUIioAAAAJ",
      "_8Egwg8AAAAJ",
      "ySLrpsYAAAAJ",
      "x7b5TJMAAAAJ",
      "yc2mM9IAAAAJ",
      "jHCgT18AAAAJ",
      "Sc7qOfcAAAAJ",
      "skyUvycAAAAJ",
      "e0IRutEAAAAJ",
      "1WYrlLkAAAAJ",
      "b0k2tTgAAAAJ",
      "KCiDjbkAAAAJ",
      "-yZse64AAAAJ",
      "4QnYN1sAAAAJ",
      "e0VXX60AAAAJ",
      "l7Qx0zAAAAAJ",
      "VEkbdjcAAAAJ",
      "3_WYcR4AAAAJ",
      "PaFLL10AAAAJ",
      "quMILWkAAAAJ",
      "1p9NOFEAAAAJ",
      "TeBmXz4AAAAJ",
      "KdX5MN4AAAAJ",
      "HR0uwyIAAAAJ",
      "Dv1K9boAAAAJ",
      "uWNrcTUAAAAJ",
      "aHPX6PsAAAAJ",
      "WBvt5A8AAAAJ",
      "TU_s3xAAAAAJ",
      "pSpRfQ4AAAAJ",
      "5hGRe_QAAAAJ",
      "zDy4jSYAAAAJ",
      "gIH9P-8AAAAJ",
      "SAdQhg4AAAAJ",
      "0KF6ZC8AAAAJ",
      "k8bn6q4AAAAJ",
      "-VgS8AIAAAAJ",
      "Rn7APGIAAAAJ",
      "bp6Ah4EAAAAJ",
      "xCJ8lboAAAAJ",
      "u11FXaoAAAAJ",
      "h8W0ppcAAAAJ",
      "gfUj1FUAAAAJ",
      "OjWXOSsAAAAJ",
      "OPgnjWQAAAAJ",
      "glV_LWsAAAAJ",
      "b4jR5hkAAAAJ",
      "gzQY0s8AAAAJ",
      "zSSrBp4AAAAJ",
      "SNVrOLwAAAAJ",
      "kFXm6DQAAAAJ",
      "E_ejWvYAAAAJ",
      "3Lmd6AMAAAAJ",
      "pnOLBcoAAAAJ",
      "7rNyP1sAAAAJ",
      "sycHskQAAAAJ",
      "vPEmzqYAAAAJ",
      "jPis1roAAAAJ",
      "nc6hvFgAAAAJ",
      "skSqdYsAAAAJ",
      "JmzhiYAAAAAJ",
      "3OQplr0AAAAJ",
      "okjycNEAAAAJ",
      "VUOMP_EAAAAJ",
      "oxyHy1MAAAAJ",
      "RahgPAEAAAAJ",
      "kzoVUPYAAAAJ",
      "ne44BF4AAAAJ",
      "Nf8TQBQAAAAJ",
      "Vkzd7MIAAAAJ",
      "C3KJzwEAAAAJ",
      "TnvQIrYAAAAJ",
      "O-TV6OgAAAAJ",
      "3i8wNscAAAAJ",
      "LFiqVpwAAAAJ",
      "HAf4pEoAAAAJ",
      "mxiO4IkAAAAJ",
      "dgNqguIAAAAJ",
      "oMqNbfsAAAAJ",
      "cCYTVWQAAAAJ",
      "VP48uSEAAAAJ",
      "Wck7gd0AAAAJ",
      "VDyjbagAAAAJ",
      "4v8uJrIAAAAJ",
      "BSORuFoAAAAJ",
      "0qfCL-QAAAAJ",
      "E1CsZLcAAAAJ",
      "Ah6du3EAAAAJ",
      "0MiPsosAAAAJ",
      "wgNML_UAAAAJ",
      "I6x_9IoAAAAJ",
      "3sbdEW4AAAAJ",
      "dJj3vR4AAAAJ",
      "O7bGqjUAAAAJ",
      "pSmh9tkAAAAJ",
      "00roCOMAAAAJ",
      "W2pvAfEAAAAJ",
      "vG5UNEQAAAAJ",
      "Lt9LpLMAAAAJ",
      "6_UmGu0AAAAJ",
      "b8i9J_QAAAAJ",
      "8SZ79v4AAAAJ",
      "1WXpabIAAAAJ",
      "gFwEytkAAAAJ",
      "6POeyBoAAAAJ",
      "NBUWnTYAAAAJ",
      "nbpafUkAAAAJ",
      "u_fAQO4AAAAJ",
      "L-TjbwcAAAAJ",
      "jQeFWdoAAAAJ",
      "abUcBIkAAAAJ",
      "dqVBIjIAAAAJ",
      "f0j0K8QAAAAJ",
      "JApued4AAAAJ",
      "m-om5O8AAAAJ",
      "q-buMEoAAAAJ",
      "_Whqm1IAAAAJ",
      "wRZrrqwAAAAJ",
      "bEcLezcAAAAJ",
      "_GzrRGwAAAAJ",
      "7HCKL10AAAAJ",
      "-xjeTa8AAAAJ",
      "FdNuUb8AAAAJ",
      "vx68rkMAAAAJ",
      "4SDTMIQAAAAJ",
      "XsxZrYYAAAAJ",
      "BCBUDMcAAAAJ",
      "KUG_tG0AAAAJ",
      "0AUIC-8AAAAJ",
      "kDjILRMAAAAJ",
      "_LSLmbYAAAAJ",
      "9XJL-qMAAAAJ",
      "MdbxYu8AAAAJ",
      "m3aJauEAAAAJ",
      "JtPSC9sAAAAJ",
      "hNQoeOYAAAAJ",
      "ZX9LE3QAAAAJ",
      "_TkfqdgAAAAJ",
      "2D06YJAAAAAJ",
      "MlDSA9sAAAAJ",
      "k4Q3TYwAAAAJ",
      "cnPetCkAAAAJ",
      "GLxE-TcAAAAJ",
      "Lf2KB6cAAAAJ",
      "dVpTVwkAAAAJ",
      "wFEJvJUAAAAJ",
      "7_7op_IAAAAJ",
      "rUmKr3AAAAAJ",
      "QS7Z860AAAAJ",
      "67eC0RcAAAAJ",
      "fddAbqsAAAAJ",
      "8200InoAAAAJ",
      "3q-hbWsAAAAJ",
      "cHZ2U6UAAAAJ",
      "edUsNYIAAAAJ",
      "DwUrFHUAAAAJ",
      "T3jkUBwAAAAJ",
      "XG2aNyYAAAAJ",
      "du-k5BYAAAAJ",
      "k8nSlL4AAAAJ",
      "qYYPst0AAAAJ",
      "47sihrsAAAAJ",
      "7Xko5sYAAAAJ",
      "ADMVEmsAAAAJ",
      "r44N6h8AAAAJ",
      "N_rVVG8AAAAJ",
      "eZqFrSsAAAAJ",
      "lueKv2oAAAAJ",
      "B1guGw8AAAAJ",
      "HXXSrNMAAAAJ",
      "y8O77DYAAAAJ",
      "Arn3vCUAAAAJ",
      "ICCMAZ8AAAAJ",
      "j0nK_CsAAAAJ",
      "xdTtK9IAAAAJ",
      "v4JMf6kAAAAJ",
      "9HRLi20AAAAJ",
      "uy8T6BYAAAAJ",
      "hyEds7sAAAAJ",
      "YVrGTe8AAAAJ",
      "9YnPccsAAAAJ",
      "P7LuLZMAAAAJ",
      "Ctp3igcAAAAJ",
      "TjdFs3EAAAAJ",
      "_8gD7Y4AAAAJ",
      "CTT44Y0AAAAJ",
      "HSuy6TQAAAAJ",
      "3HAa8ni1oGUC",
      "u8f4WQ0AAAAJ",
      "pImSVwoAAAAJ",
      "l-Ilg5MAAAAJ",
      "O2gmsKAAAAAJ",
      "64G5UgMAAAAJ",
      "PwdervMAAAAJ",
      "jfu5EP4AAAAJ",
      "GVzdGe8AAAAJ",
      "sUriZlUAAAAJ",
      "rtpoh5wAAAAJ",
      "XHZlMYUAAAAJ",
      "xnQZonMAAAAJ",
      "DZ-WjTIAAAAJ",
      "hGMSFu4AAAAJ",
      "h0R3z64AAAAJ",
      "3rlMzwYAAAAJ",
      "29qQmWIAAAAJ",
      "pViZYwIAAAAJ",
      "8j3t5HsAAAAJ",
      "8VNhGv4AAAAJ",
      "OZ7PjVoAAAAJ",
      "D8dLtRMAAAAJ",
      "GYUuR_sAAAAJ",
      "eJ9qDHMAAAAJ",
      "ZCMRvtIAAAAJ",
      "c0yPSEYAAAAJ",
      "GyRqJIoAAAAJ",
      "0VAe-TQAAAAJ",
      "EM9YhH0AAAAJ",
      "YQcU3NYAAAAJ",
      "yjjrGdgAAAAJ",
      "_ZU4B9AAAAAJ",
      "EAB-RKIAAAAJ",
      "LicjjokAAAAJ",
      "zblQKM8AAAAJ",
      "WN9t4n0AAAAJ",
      "uVgMw8YAAAAJ",
      "i5FMLA4AAAAJ",
      "2IzviGMAAAAJ",
      "Py69D_8AAAAJ",
      "2rzyuRQAAAAJ",
      "ACZeu8cAAAAJ",
      "19Ouf5MAAAAJ",
      "zdn08t8AAAAJ",
      "zP9K32EAAAAJ",
      "vyteiT4AAAAJ",
      "ji0zVjgAAAAJ",
      "e6JywScAAAAJ",
      "GhrKC1gAAAAJ",
      "WRTLuxcAAAAJ",
      "SvuSifMAAAAJ",
      "cpv4vqAAAAAJ",
      "RP4Qx3QAAAAJ",
      "bldHpWIAAAAJ",
      "SuTJ0iMAAAAJ",
      "_ZH86NYAAAAJ",
      "5xYDlvgAAAAJ",
      "D0lL1r0AAAAJ",
      "Smr99uEAAAAJ",
      "hJgT4tYAAAAJ",
      "3ar1DOwAAAAJ",
      "C3-B4nwAAAAJ",
      "HqYIsk4AAAAJ",
      "f1wmyEkAAAAJ",
      "BBKfx4oAAAAJ",
      "e9MgnYYAAAAJ",
      "gWg00ScAAAAJ",
      "xkn_XZgAAAAJ",
      "iCf3SwgAAAAJ",
      "mhmvCgsAAAAJ",
      "mCjP0bAAAAAJ",
      "0zQdH0oAAAAJ",
      "4LWx24UAAAAJ",
      "nicnuy4AAAAJ",
      "TuT3_UwAAAAJ",
      "-SgpaF8AAAAJ",
      "ZNquLr8AAAAJ",
      "SDhzsXUAAAAJ",
      "u4unGhAAAAAJ",
      "xY1GdVgAAAAJ",
      "cXT3p6cAAAAJ",
      "1dPriv4AAAAJ",
      "gnR4zf8AAAAJ",
      "4HTITaMAAAAJ",
      "qEXxyDQAAAAJ",
      "odEM5hMAAAAJ",
      "n-SnMhoAAAAJ",
      "U7svaOMAAAAJ",
      "yV3_PTkAAAAJ",
      "FxU9cG0AAAAJ",
      "v_t_fq8AAAAJ",
      "Bw-WdyUAAAAJ",
      "FiP-TVUAAAAJ",
      "BWDUVOIAAAAJ",
      "nZxJGeUAAAAJ",
      "wvQmuxgAAAAJ",
      "W4Y0jUIAAAAJ",
      "MSCQE-YAAAAJ",
      "5F5LBT8AAAAJ",
      "7kaIUXoAAAAJ",
      "xo7GHUoAAAAJ",
      "QeXHxlIAAAAJ",
      "cxEoVL4AAAAJ",
      "FvRFQZ8AAAAJ",
      "diIore8AAAAJ",
      "b6N0NroAAAAJ",
      "6IQ8pQwAAAAJ",
      "zMLbnN4AAAAJ",
      "feM7-mEAAAAJ",
      "xj666rUAAAAJ",
      "HkVy8voAAAAJ",
      "Mj1QkjkAAAAJ",
      "beVJGycAAAAJ",
      "ZLCLbSQAAAAJ",
      "13yyuCcAAAAJ",
      "qPtFfKAAAAAJ",
      "qcrM7F4AAAAJ",
      "PMh2ysEAAAAJ",
      "JI5QYBwAAAAJ",
      "byA9yI0AAAAJ",
      "2Pxx8QIAAAAJ",
      "LYbs7Q8AAAAJ",
      "AQzIwI4AAAAJ",
      "XK7HXzMAAAAJ",
      "QKOH5iYAAAAJ",
      "sFmN6RkAAAAJ",
      "PzoN2hgAAAAJ",
      "ImQ7ceQAAAAJ",
      "D2EdRScAAAAJ",
      "sm1-TZMAAAAJ",
      "3M9mssIAAAAJ",
      "Y_Ieu7EAAAAJ",
      "Ih7iLuUAAAAJ",
      "Z64LdqQAAAAJ",
      "dkRTvvcAAAAJ",
      "dmDQklMAAAAJ",
      "Hyhp_zUAAAAJ",
      "ySwF8ioAAAAJ",
      "YUrxwrkAAAAJ",
      "Nr6E_rIAAAAJ",
      "gwLessAAAAAJ",
      "HBztuGIAAAAJ",
      "AN6lmmcAAAAJ",
      "jU4IZs4AAAAJ",
      "i1NrG8UAAAAJ",
      "OkOGR_8AAAAJ",
      "bezWXYcAAAAJ",
      "mnAk4HIAAAAJ",
      "hLxJ02wAAAAJ",
      "QX7xv3UAAAAJ",
      "Ai1cvB8AAAAJ",
      "zg9zDcsAAAAJ",
      "Q9DsCL4AAAAJ",
      "Odek140AAAAJ",
      "OpFFE3cAAAAJ",
      "dnMoAsUAAAAJ",
      "R4IDPnoAAAAJ",
      "a5RZKIkAAAAJ",
      "3-9qq6sAAAAJ",
      "6aNMdbsAAAAJ",
      "1KFFbEIAAAAJ",
      "fAWKizAAAAAJ",
      "deCmCVgAAAAJ",
      "1V8AeXYAAAAJ",
      "p6iM9gIAAAAJ",
      "AkJyLCAAAAAJ",
      "px1ffwoAAAAJ",
      "u0rkSl0AAAAJ",
      "6z_XWYcAAAAJ",
      "5NiFWuwAAAAJ",
      "em7o4kwAAAAJ",
      "-9yiQMsAAAAJ",
      "YAHWbtkAAAAJ",
      "PxsyxMsAAAAJ",
      "ufzrGe8AAAAJ",
      "po4ztO4AAAAJ",
      "OGdXlpcAAAAJ",
      "EiwH233ldzsC",
      "2vQRGrYAAAAJ",
      "LXwCIisAAAAJ",
      "8uou2n4AAAAJ",
      "-vsw3Z4AAAAJ",
      "FxEDj4wAAAAJ",
      "umA5NjcAAAAJ",
      "KNdj9HMAAAAJ",
      "ObdsXj8AAAAJ",
      "bdNbTVIAAAAJ",
      "TP-_rb0AAAAJ",
      "bDq7MZMAAAAJ",
      "YYcTN2EAAAAJ",
      "npqoAWwAAAAJ",
      "-lQSzAwAAAAJ",
      "ma7qW2kAAAAJ",
      "e6op8BQAAAAJ",
      "ig8JXwIAAAAJ",
      "vGBcNVAAAAAJ",
      "AgTN6m4AAAAJ",
      "rhZm_NAAAAAJ",
      "r1Zw-VEAAAAJ",
      "aCYoiC8AAAAJ",
      "zjr6n-QAAAAJ",
      "7-B7aQkAAAAJ",
      "hVUVOTIAAAAJ",
      "joR1Z4UAAAAJ",
      "CjOTm_4AAAAJ",
      "mSvrb54AAAAJ",
      "-qV-RYkAAAAJ",
      "8f7XTQIAAAAJ",
      "hR4G6hoAAAAJ",
      "oa78zHUAAAAJ",
      "tMNWtzkAAAAJ",
      "95NLzC4AAAAJ",
      "i7lw4LwAAAAJ",
      "yK7yTiwAAAAJ",
      "cDeKq4YAAAAJ",
      "0aJ--58AAAAJ",
      "8x8FUr8AAAAJ",
      "X7bG7YYAAAAJ",
      "CBUpEcQAAAAJ",
      "YAGjro8AAAAJ",
      "Jr2CK6QAAAAJ",
      "6HwMeesAAAAJ",
      "VINmGpYAAAAJ",
      "VA4ExhYAAAAJ",
      "GgD-B68AAAAJ",
      "mHwonDEAAAAJ",
      "aeGDj-IAAAAJ",
      "20_pofsAAAAJ",
      "hD2WqqcAAAAJ",
      "XpFzyRUAAAAJ",
      "GgQ9GEkAAAAJ",
      "R9MXY8wAAAAJ",
      "5ApCTCoAAAAJ",
      "j_SEFF8AAAAJ",
      "UAwKvEsAAAAJ",
      "LpWGWAwAAAAJ",
      "3jDeUlMAAAAJ",
      "DIKwHRsAAAAJ",
      "Izp-zW0AAAAJ",
      "9lh2gH8AAAAJ",
      "xXQq8AIAAAAJ",
      "M59O9lkAAAAJ",
      "UX-H08cAAAAJ",
      "SM-2GN4AAAAJ",
      "hRB3wSgAAAAJ",
      "oK5EzZsAAAAJ",
      "p9-ohHsAAAAJ",
      "M3WZP7YAAAAJ",
      "ejD_Z3IAAAAJ",
      "LO06dIUAAAAJ",
      "Q-v0BgUAAAAJ",
      "4Z6vo5QAAAAJ",
      "1NXsdH8AAAAJ",
      "-2ATsToAAAAJ",
      "dFNbaFsAAAAJ",
      "rTJTJJ4AAAAJ",
      "VOIlmnoAAAAJ",
      "nzO_5FMAAAAJ",
      "ITJGDKQAAAAJ",
      "iUEcoesAAAAJ",
      "NHIpV98AAAAJ",
      "oX7L_mMAAAAJ",
      "_P954XkAAAAJ",
      "hGM6Go4AAAAJ",
      "9j-6i_oAAAAJ",
      "mldMyOsAAAAJ",
      "5VJ4YPQAAAAJ",
      "1ZT-nZEAAAAJ",
      "AzlUrvUAAAAJ",
      "zVSwZIAAAAAJ",
      "_AZwpCAAAAAJ",
      "QH90248AAAAJ",
      "7N-ethYAAAAJ",
      "MnsxqAcAAAAJ",
      "7ERaCzgAAAAJ",
      "pcfQnOkAAAAJ",
      "n8ysVHUAAAAJ",
      "38fYqeYAAAAJ",
      "q9alvsoAAAAJ",
      "XOfA8ckAAAAJ",
      "dy4WeeIAAAAJ",
      "xbHranwAAAAJ",
      "ajXAb54AAAAJ",
      "cGemfcYAAAAJ",
      "uvaPP80AAAAJ",
      "PM5ZWS4AAAAJ",
      "btk7o4MAAAAJ",
      "4sgEDv8AAAAJ",
      "cMPKe9UAAAAJ",
      "TqblqYcAAAAJ",
      "gf-aMd0AAAAJ",
      "0QtU-NsAAAAJ",
      "YP3gziUAAAAJ",
      "MyTEg-8AAAAJ",
      "nnK-WMMAAAAJ",
      "s_5xXxQXpU0C",
      "GZt32DEAAAAJ",
      "hpItE1QAAAAJ",
      "nCZ2PMcAAAAJ",
      "NUtQyXAAAAAJ",
      "gz1zcR4AAAAJ",
      "wIDVzroAAAAJ",
      "YuFcRF0AAAAJ",
      "sOna0qoAAAAJ",
      "5JE9m1EAAAAJ",
      "Iia81jAAAAAJ",
      "7yobGX4AAAAJ",
      "fNOReswAAAAJ",
      "VfEVlecAAAAJ",
      "yPgtxnkAAAAJ",
      "A4-oSJIAAAAJ",
      "myi68A4AAAAJ",
      "6hB2vJUAAAAJ",
      "MT-S2QMAAAAJ",
      "TaR3dq4AAAAJ",
      "ZQ4iPZUAAAAJ",
      "3y_M1cUAAAAJ",
      "cwXx4EQAAAAJ",
      "faO82gYAAAAJ",
      "cXhAfX0AAAAJ",
      "FJ-huxgAAAAJ",
      "M7wYOSMAAAAJ",
      "W80oBMkAAAAJ",
      "svJIv28AAAAJ",
      "LSvg03gAAAAJ",
      "9c4G6GkAAAAJ",
      "MBiIblMAAAAJ",
      "oBU9w4UAAAAJ",
      "GZkyN4cAAAAJ",
      "_8SObXwAAAAJ",
      "OaE_xMgAAAAJ",
      "XM2WLE8AAAAJ",
      "pfEoUpcAAAAJ",
      "hRV0tY4AAAAJ",
      "lL5jPysAAAAJ",
      "3OKn_UYAAAAJ",
      "CFJHvLcAAAAJ",
      "fds2VpgAAAAJ",
      "1UirFygAAAAJ",
      "mimrFAMAAAAJ",
      "8wGH7wsAAAAJ",
      "F0yiLRIAAAAJ",
      "Daa3WpMAAAAJ",
      "GWyeAskAAAAJ",
      "uQRY6KoAAAAJ",
      "d5Djcl4AAAAJ",
      "4QuRUy8AAAAJ",
      "Jke3O8QAAAAJ",
      "ScqM05wAAAAJ",
      "PRl_gWUAAAAJ",
      "4ME93EEAAAAJ",
      "iAEBIB4AAAAJ",
      "t6exkOAAAAAJ",
      "1AzRLAUAAAAJ",
      "DzI-iPQAAAAJ",
      "staYplUAAAAJ",
      "O4jW7BsAAAAJ",
      "BFWurDEAAAAJ",
      "wc0FCZUAAAAJ",
      "dHU6M_4AAAAJ",
      "SB6_-GAAAAAJ",
      "BNNNS-wAAAAJ",
      "X3ZFZ7AAAAAJ",
      "WUKF2ZwAAAAJ",
      "ow3r9ogAAAAJ",
      "DZ19008AAAAJ",
      "QfxrxDoAAAAJ",
      "bwORIKIAAAAJ",
      "PoZv5KkAAAAJ",
      "V9KyKCwAAAAJ",
      "iBBpnUEAAAAJ",
      "or0oVL0AAAAJ",
      "Q5KT-hEAAAAJ",
      "HK4x3fkAAAAJ",
      "ttJ9AWAAAAAJ",
      "z4JhSBwAAAAJ",
      "q7FiLBkAAAAJ",
      "l78nduAAAAAJ",
      "tqcSvFIAAAAJ",
      "MvYTnPoAAAAJ",
      "BST6b8AAAAAJ",
      "s3McVn8AAAAJ",
      "bkcNcHYAAAAJ",
      "XhyKVFMAAAAJ",
      "38fqeIYAAAAJ",
      "zHCTHbYAAAAJ",
      "cplKIP8AAAAJ",
      "RgIBwboAAAAJ",
      "ilbKQMYAAAAJ",
      "e65kJ08AAAAJ",
      "YmXg5xMAAAAJ",
      "1Lozhc4AAAAJ",
      "Y4TYXDMAAAAJ",
      "E31PR1oAAAAJ",
      "qRXK__gAAAAJ",
      "rupmL3kAAAAJ",
      "CJdblO4AAAAJ",
      "m45LD1kAAAAJ",
      "ajJxXnEAAAAJ",
      "9jfZ5SIAAAAJ",
      "vtwH6GkAAAAJ",
      "afgNSP8AAAAJ",
      "uHFzzkkAAAAJ",
      "tvUH3WMAAAAJ",
      "BaaPAVYAAAAJ",
      "x5iJp8oAAAAJ",
      "D6P3KdMAAAAJ",
      "_tbXjP4AAAAJ",
      "8r2Fiv4AAAAJ",
      "wGNIr6oAAAAJ",
      "Yk3s7HUAAAAJ",
      "2z7iDDUAAAAJ",
      "GzqY7SAAAAAJ",
      "CNuyivcAAAAJ",
      "CYI6cKgAAAAJ",
      "KKQCt30AAAAJ",
      "LBaBtwcAAAAJ",
      "iYN86KEAAAAJ",
      "YoSGjoUAAAAJ",
      "urLZUHwAAAAJ",
      "1VDV6ZEAAAAJ",
      "NNr46G8AAAAJ",
      "KWqO1CgAAAAJ",
      "Uauc4m8AAAAJ",
      "8AkztB0AAAAJ",
      "1FrpQaQAAAAJ",
      "jcewpCIAAAAJ",
      "K2XA5XEAAAAJ",
      "UA3tyKwAAAAJ",
      "duOys3YAAAAJ",
      "IE2DVpIAAAAJ",
      "J3lauQ4AAAAJ",
      "gzn3C3oAAAAJ",
      "Xod5HrAAAAAJ",
      "m8NUgw0AAAAJ",
      "qPlUgrgAAAAJ",
      "vyNLRqgAAAAJ",
      "K3ht_ZUAAAAJ",
      "DsD8SDYAAAAJ",
      "sgBB2sUAAAAJ",
      "0TpaABgAAAAJ",
      "cF2lHxgAAAAJ",
      "FWp7728AAAAJ",
      "0rFlyFgAAAAJ",
      "0fRlG8oAAAAJ",
      "lmDy04wAAAAJ",
      "sTzb6LAAAAAJ",
      "UdaJi94AAAAJ",
      "cUkE7OgAAAAJ",
      "euc0GX4AAAAJ",
      "bSpGhYcAAAAJ",
      "cHN3PVYAAAAJ",
      "jffu6mUAAAAJ",
      "PghQbXMAAAAJ",
      "ygpxbK8AAAAJ",
      "D5eyaLwAAAAJ",
      "j9GCzQUAAAAJ",
      "i_X02A0AAAAJ",
      "NaxShlcAAAAJ",
      "vlgs4G4AAAAJ",
      "I66ZBYwAAAAJ",
      "jaITaUcAAAAJ",
      "DmahiOYAAAAJ",
      "K6-M7A4AAAAJ",
      "09kJn28AAAAJ",
      "rM0Orl0AAAAJ",
      "jQnTUZEAAAAJ",
      "NozmrNYAAAAJ",
      "71ZEsnEAAAAJ",
      "L-lz7CUAAAAJ",
      "REL2gIEAAAAJ",
      "bAPC01sAAAAJ",
      "WvtCacIAAAAJ",
      "Iw9vL9cAAAAJ",
      "-dCETaQAAAAJ",
      "OzfKmBEAAAAJ",
      "ANbGE-UAAAAJ",
      "dio8IesAAAAJ",
      "mSn1TVMAAAAJ",
      "_N2COeAAAAAJ",
      "-6s0HQ4AAAAJ",
      "g66HTn4AAAAJ",
      "DpsEpaoAAAAJ",
      "vPoTuLQAAAAJ",
      "8IjN_vgAAAAJ",
      "BQQjcVAAAAAJ",
      "I1w51gUAAAAJ",
      "P97vI1EAAAAJ",
      "yVy2ZIwAAAAJ",
      "fVuWflQAAAAJ",
      "GnR3Y60AAAAJ",
      "9sHizzsAAAAJ",
      "GIZzv_cAAAAJ",
      "hgUGouQAAAAJ",
      "FY2dQSgAAAAJ",
      "PXMOFVMAAAAJ",
      "itZCog0AAAAJ",
      "ICzsaEsAAAAJ",
      "Lg6yyBEAAAAJ",
      "lKvYBwkAAAAJ",
      "VdmfIeUAAAAJ",
      "EMqQUjoAAAAJ",
      "r6mBY50AAAAJ",
      "FUqUC2oAAAAJ",
      "pDyfiUEAAAAJ",
      "pWJ0SocAAAAJ",
      "9KRGFbYAAAAJ",
      "RohTif4AAAAJ",
      "ahSpJOAAAAAJ",
      "Jok8C54AAAAJ",
      "7t4jbPQAAAAJ",
      "2yaiWZ8AAAAJ",
      "GArEeWQAAAAJ",
      "1TTFBEkAAAAJ",
      "9LcazaMAAAAJ",
      "C6pnolkAAAAJ",
      "a8ZyGisAAAAJ",
      "Fhs-sfkAAAAJ",
      "abyZPXsAAAAJ",
      "Pqd_-nkAAAAJ",
      "NjeM1LsAAAAJ",
      "qPMJxq0AAAAJ",
      "m4QAC_EAAAAJ",
      "uaQdhE4AAAAJ",
      "wVzFBcEAAAAJ",
      "aOklxsQAAAAJ",
      "YGxUJXkAAAAJ",
      "6S09ezcAAAAJ",
      "MyKLYVMAAAAJ",
      "_7fW--oAAAAJ",
      "p4zxPP8AAAAJ",
      "uToGtIwAAAAJ",
      "58GAc80AAAAJ",
      "zbcN_QIAAAAJ",
      "QzTJEdYAAAAJ",
      "qrgWqjYAAAAJ",
      "9GnYJQkAAAAJ",
      "iPJvBGYAAAAJ",
      "utY1nToAAAAJ",
      "hWPIzdkAAAAJ",
      "PTS2AOgAAAAJ",
      "OO-2710AAAAJ",
      "uezRX6QAAAAJ",
      "ixGMcjsAAAAJ",
      "r7gAWagAAAAJ",
      "qg_aiScAAAAJ",
      "4yk44z4AAAAJ",
      "GLtCYtgAAAAJ",
      "krWNpKoAAAAJ",
      "aQUQU10AAAAJ",
      "BOGdPa8AAAAJ",
      "6mgnauMAAAAJ",
      "V0K3gs0AAAAJ",
      "PHi0YEQAAAAJ",
      "YT5NJ24AAAAJ",
      "ct2hw4UAAAAJ",
      "QURZIzUAAAAJ",
      "6vH92bAAAAAJ",
      "IuhidDAAAAAJ",
      "xuSbmssAAAAJ",
      "7oxkHYYAAAAJ",
      "tpoh43QAAAAJ",
      "OFlBL2kAAAAJ",
      "6H0mhLUAAAAJ",
      "UpZmJI0AAAAJ",
      "0XtGoMUAAAAJ",
      "awNOAaYAAAAJ",
      "9Trpw3gAAAAJ",
      "PMd9DyQAAAAJ",
      "6Atez3UAAAAJ",
      "ghZkSV8AAAAJ",
      "Ph-fOwQAAAAJ",
      "rO13CwYAAAAJ",
      "jM1cT4QAAAAJ",
      "EPQZFzwAAAAJ",
      "avQkeJEAAAAJ",
      "eXKdSu0AAAAJ",
      "lyMGnwIAAAAJ",
      "U8dAtsQAAAAJ",
      "2XCryp4AAAAJ",
      "3Bk5C9EAAAAJ",
      "oYAf_hgAAAAJ",
      "Lkrx2SkAAAAJ",
      "PH1aZPsAAAAJ",
      "pf2zAXkAAAAJ",
      "mSj0LUsAAAAJ",
      "kssA7YwAAAAJ",
      "h1-3lSoAAAAJ",
      "gKJ3MfIAAAAJ",
      "wnTOU6AAAAAJ",
      "Dl949GoAAAAJ",
      "Wn8xr_gAAAAJ",
      "JZqo39cAAAAJ",
      "smo705AAAAAJ",
      "XRhKEGMAAAAJ",
      "CZyWk8kAAAAJ",
      "WNqbKzwAAAAJ",
      "KQFUVR8AAAAJ",
      "2eWscBQAAAAJ",
      "199M69AAAAAJ",
      "odQWZoEAAAAJ",
      "wkC9xHMAAAAJ",
      "tyKNvM8AAAAJ",
      "jyaTX64AAAAJ",
      "eJt6cSIAAAAJ",
      "x_7xA0UAAAAJ",
      "0BI-noIAAAAJ",
      "RYLugBwAAAAJ",
      "mYKbo8YAAAAJ",
      "AEr-DWcAAAAJ",
      "PF-RPpEfa-0C",
      "A-4JUL4AAAAJ",
      "EoACFEUAAAAJ",
      "ET6V1LEAAAAJ",
      "pHTgOOIAAAAJ",
      "C6BeHCMAAAAJ",
      "kqVZxpYAAAAJ",
      "tT9mhNMAAAAJ",
      "910z20QAAAAJ",
      "XV30l4MAAAAJ",
      "zjlFcrEAAAAJ",
      "fz7LJPIAAAAJ",
      "laq9cq0AAAAJ",
      "x0NsQm0AAAAJ",
      "owApkWAAAAAJ",
      "IKoa5qAAAAAJ",
      "Bo7Y1j0AAAAJ",
      "KED9FsgAAAAJ",
      "KjYNz88AAAAJ",
      "NirVdpMAAAAJ",
      "dD-3S4QAAAAJ",
      "c4YtO-MAAAAJ",
      "IoEBLNYAAAAJ",
      "p351VxAAAAAJ",
      "FLJ86DwAAAAJ",
      "oRkkQm4AAAAJ",
      "3FwavwMAAAAJ",
      "QpClwb8AAAAJ",
      "_CWxQ1gAAAAJ",
      "2XL6xRgAAAAJ",
      "6QPoYc4AAAAJ",
      "6h1O4AMAAAAJ",
      "bI7KhScAAAAJ",
      "Qf4bw4UAAAAJ",
      "ttbl4FsAAAAJ",
      "tR2Qw0YAAAAJ",
      "Iz9v6dcAAAAJ",
      "SmuY2sMAAAAJ",
      "xXQtID8AAAAJ",
      "is41ryYAAAAJ",
      "Kq0feJIAAAAJ",
      "4cxOltkAAAAJ",
      "KZL-4GEAAAAJ",
      "st_GV1QAAAAJ",
      "CHMpZBIAAAAJ",
      "61hrt1cAAAAJ",
      "-0vALDMAAAAJ",
      "nIEep3cAAAAJ",
      "jeNGFfQAAAAJ",
      "j7Z1Zm8AAAAJ",
      "TM6oPEUAAAAJ",
      "JbBpeE0AAAAJ",
      "EEp82sIAAAAJ",
      "k1tEBf0AAAAJ",
      "Qk8Wh5UAAAAJ",
      "b6zhmt0AAAAJ",
      "E8_P8_wAAAAJ",
      "bxAIuu4AAAAJ",
      "tuBQ_uwAAAAJ",
      "koPRb8UAAAAJ",
      "Uxb6wbkAAAAJ",
      "qKQD-2cAAAAJ",
      "snDpfA0AAAAJ",
      "dwi5wvYAAAAJ",
      "CG04xrsAAAAJ",
      "yn-nyJwAAAAJ",
      "K4w5qYUAAAAJ",
      "8E442bkAAAAJ",
      "BkbnIxkAAAAJ",
      "5Yjb93IAAAAJ",
      "t3A39e8AAAAJ",
      "NJ9c4ygAAAAJ",
      "3nlXVhAAAAAJ",
      "fszzlckAAAAJ",
      "Va50YzkAAAAJ",
      "RJ77s-cAAAAJ",
      "d1O4KssAAAAJ",
      "7JficF8AAAAJ",
      "Q-UjnzEAAAAJ",
      "qLTEaEIAAAAJ",
      "WQnQm0IAAAAJ",
      "_z-DXRIAAAAJ",
      "36qnUD4AAAAJ",
      "lyadgWkAAAAJ",
      "Fa1BONsAAAAJ",
      "B8wslVsAAAAJ",
      "3OdbrfMAAAAJ",
      "z-JV1e8AAAAJ",
      "NWqnXNEAAAAJ",
      "T5GVHawAAAAJ",
      "gYk4eAgAAAAJ",
      "VvdtcWcAAAAJ",
      "OQHNvrEAAAAJ",
      "Wrfc4V8AAAAJ",
      "zX3ba1kAAAAJ",
      "Z03FLwkAAAAJ",
      "jTUvYSAAAAAJ",
      "8LN5NoQAAAAJ",
      "2-P1M2IAAAAJ",
      "jsy-VxMAAAAJ",
      "ZiFn598AAAAJ",
      "cA4CXXoAAAAJ",
      "r7wE4M4AAAAJ",
      "Hd80zWMAAAAJ",
      "OxnSwKkAAAAJ",
      "t9HPFawAAAAJ",
      "u5G_A14AAAAJ",
      "hscMk9AAAAAJ",
      "NiJYYkkAAAAJ",
      "PJQPzgcAAAAJ",
      "zwA5eokAAAAJ",
      "rFB25cgAAAAJ",
      "9xDADY4AAAAJ",
      "dsmssvcAAAAJ",
      "JVpq7SwAAAAJ",
      "Bjpb27sAAAAJ",
      "A8DhSR4AAAAJ",
      "S2OjOvYAAAAJ",
      "ZLpO3XQAAAAJ",
      "A7-xkvcAAAAJ",
      "0xroV7wAAAAJ",
      "br990A8AAAAJ",
      "qxMVu4cAAAAJ",
      "TIpmrtoAAAAJ",
      "BB4R2_gAAAAJ",
      "bXOt49QAAAAJ",
      "ndRmNK8AAAAJ",
      "4Urexvi1sIcC",
      "Ysd-WJgAAAAJ",
      "0o470HsAAAAJ",
      "iq-7vhMAAAAJ",
      "krTnRRUAAAAJ",
      "7PC01c0AAAAJ",
      "R5AmmGwAAAAJ",
      "rpbMOTsAAAAJ",
      "Dg5qUb0AAAAJ",
      "-9Y7xbAAAAAJ",
      "e-fdBdIAAAAJ",
      "uKXVH54AAAAJ",
      "AjkTOkAAAAAJ",
      "BVde3Y0AAAAJ",
      "-pyztDMAAAAJ",
      "wUJ2bXgAAAAJ",
      "T5hu6dsAAAAJ",
      "HLfQbBkAAAAJ",
      "SsEHa6cAAAAJ",
      "nPQEV0YAAAAJ",
      "Ukl64ggAAAAJ",
      "KKLUF8kAAAAJ",
      "lrzfjUQAAAAJ",
      "xSC3VSAAAAAJ",
      "Ke6ex0wAAAAJ",
      "Bs0aA-UAAAAJ",
      "MiHOX3QAAAAJ",
      "i2II0XIAAAAJ",
      "Fks4s-wAAAAJ",
      "opBkPOgAAAAJ",
      "n0pk_jEAAAAJ",
      "si-368wAAAAJ",
      "NGdMpTYAAAAJ",
      "Nr_yTQgAAAAJ",
      "vOYl40wAAAAJ",
      "E_oZZj8AAAAJ",
      "dYwbc9sAAAAJ",
      "ohJ44iMAAAAJ",
      "AtMBDPUAAAAJ",
      "wY1PiLwAAAAJ",
      "-ad5RSQAAAAJ",
      "tsR6sHUAAAAJ",
      "fzSHXS8AAAAJ",
      "-tzn_AsAAAAJ",
      "s6XjtCMAAAAJ",
      "2Vt8ZUAAAAAJ",
      "_zvL7YIAAAAJ",
      "kkirJKcAAAAJ",
      "YMmzWH7gT-oC",
      "E8RwuIIAAAAJ",
      "FdNHp8QAAAAJ",
      "DSEH8XsAAAAJ",
      "fq0DzqoAAAAJ",
      "kBQ4VvEAAAAJ",
      "4QZgrj0AAAAJ",
      "J8_FdjkAAAAJ",
      "aQCRuYQAAAAJ",
      "2EaTkYEAAAAJ",
      "6ZYVPEoAAAAJ",
      "GTmdNU0AAAAJ",
      "VoWkBjUAAAAJ",
      "uebYofUAAAAJ",
      "YZcVsRMAAAAJ",
      "l4ffN_QAAAAJ",
      "qOgSRPQAAAAJ",
      "WsfNeKYAAAAJ",
      "llF8XbMAAAAJ",
      "UfCI-NcAAAAJ",
      "YVfxyeQAAAAJ",
      "dFdEHskAAAAJ",
      "hcAHEDYAAAAJ",
      "hTkUgG0AAAAJ",
      "DplAah0AAAAJ",
      "MTd1890AAAAJ",
      "RAx8zckAAAAJ",
      "oTXlEEwAAAAJ",
      "0P1xwo0AAAAJ",
      "RiiYXH0AAAAJ",
      "W_BvHWoAAAAJ",
      "cC3ZcD8AAAAJ",
      "xPWCLvEAAAAJ",
      "Q-idFOAAAAAJ",
      "JpB-xkUAAAAJ",
      "45uuU3gAAAAJ",
      "oyh-YNwAAAAJ",
      "BGggDBwAAAAJ",
      "1OJiqUQAAAAJ",
      "H0MLFHEAAAAJ",
      "WCUNvnkAAAAJ",
      "ZWC33cYAAAAJ",
      "gLO_20kAAAAJ",
      "mh6kznYAAAAJ",
      "xiiE5rYAAAAJ",
      "US56Kw8AAAAJ",
      "tYE9bLoAAAAJ",
      "SfwUC14AAAAJ",
      "X6t18NkAAAAJ",
      "1RuDJX8AAAAJ",
      "1cVvrLYAAAAJ",
      "7xEd0ZIAAAAJ",
      "RNDrSGYAAAAJ",
      "1rM2RFoAAAAJ",
      "I5jS8ccAAAAJ",
      "5zHUcUEAAAAJ",
      "i5FepLsAAAAJ",
      "hYlbtl8AAAAJ",
      "tjI54N0AAAAJ",
      "DBLgVFQAAAAJ",
      "DFwje0AAAAAJ",
      "5sL0xZ4AAAAJ",
      "MnOal0UAAAAJ",
      "JSFmVQEAAAAJ",
      "v-ab1_kAAAAJ",
      "lgvyqMQAAAAJ",
      "nst5fHgAAAAJ",
      "cvgKxDQAAAAJ",
      "NpccCXwAAAAJ",
      "VdlgOXoAAAAJ",
      "XAveESgAAAAJ",
      "8FfrHw0AAAAJ",
      "1rV69hMAAAAJ",
      "r2v8Jc0AAAAJ",
      "QWzsNMDsvlIC",
      "9DXQi8gAAAAJ",
      "54bOCmQAAAAJ",
      "FQHeASwAAAAJ",
      "oeuqAuQAAAAJ",
      "_1hCq3UAAAAJ",
      "njOmQFsAAAAJ",
      "NIxD36wAAAAJ",
      "HCH-T5UAAAAJ",
      "fpx2AWYAAAAJ",
      "Z-UlU3MAAAAJ",
      "fpT49d8AAAAJ",
      "AdAd4QIAAAAJ",
      "LDb4tb0AAAAJ",
      "NmlzwEMAAAAJ",
      "ZbClz98AAAAJ",
      "2GJDqawAAAAJ",
      "0FuZRPYAAAAJ",
      "WxL13BAAAAAJ",
      "mEEklegAAAAJ",
      "keSzZQIAAAAJ",
      "7N4J31IAAAAJ",
      "lAp-1WEAAAAJ",
      "05_s28EAAAAJ",
      "kaAnZw0AAAAJ",
      "lSJavJUAAAAJ",
      "cItVg2MAAAAJ",
      "FyQAwaEAAAAJ",
      "UQGZX48AAAAJ",
      "FkKFiE8AAAAJ",
      "Pq4Yp_kAAAAJ",
      "tPdzoqYAAAAJ",
      "mvojJ2MAAAAJ",
      "fy2TEm4AAAAJ",
      "Dav2k7cAAAAJ",
      "1kZgyI8AAAAJ",
      "tlhfhLoAAAAJ",
      "UCDMtM0AAAAJ",
      "KilQqKYAAAAJ",
      "qjJg6akAAAAJ",
      "mpZg3FnnHpQC",
      "nnHveQwAAAAJ",
      "MK6zHkYAAAAJ",
      "hI4XguUAAAAJ",
      "A_x6bjQAAAAJ",
      "8vAIQXoAAAAJ",
      "TJWNYtMAAAAJ",
      "eurA6WgAAAAJ",
      "oD8eeUYAAAAJ",
      "vNBuX24AAAAJ",
      "cOkx0_IAAAAJ",
      "mIF9BowAAAAJ",
      "g-WedwYAAAAJ",
      "xSZXqZQAAAAJ",
      "WsRIDokAAAAJ",
      "aXnBRhkAAAAJ",
      "K1CAbGwAAAAJ",
      "qM5jR7YAAAAJ",
      "i9-GzNYAAAAJ",
      "Gdow0U4AAAAJ",
      "x-pMK90AAAAJ",
      "r49_E2cAAAAJ",
      "QqfCvsgAAAAJ",
      "MEk1MWoAAAAJ",
      "3q8ivkoAAAAJ",
      "HxJTHvMAAAAJ",
      "9FSuHUQAAAAJ",
      "xlVG6IUAAAAJ",
      "xB42z10AAAAJ",
      "xe7iyikAAAAJ",
      "tMBYEWAAAAAJ",
      "8Mlyv3oAAAAJ",
      "CALLeYgAAAAJ",
      "oC8YKjUAAAAJ",
      "umOOMzsAAAAJ",
      "nRPjLBQAAAAJ",
      "nPratvEAAAAJ",
      "7Fl-fjIAAAAJ",
      "j7MW4iYAAAAJ",
      "tYgN0GsAAAAJ",
      "7hf-iAEAAAAJ",
      "zyqZgm8AAAAJ",
      "LTL9MjwAAAAJ",
      "H2QWyooAAAAJ",
      "IURWCt4AAAAJ",
      "1h_mxPMAAAAJ",
      "TXHN2DMAAAAJ",
      "e25-lgUAAAAJ",
      "e8aRmAsAAAAJ",
      "CNOqUZoAAAAJ",
      "aO-849gAAAAJ",
      "E20Gzu0AAAAJ",
      "vPOv3boAAAAJ",
      "ugFNit4AAAAJ",
      "twWX2LIAAAAJ",
      "hzkTiowAAAAJ",
      "WgSVkNwAAAAJ",
      "uWfcPkkAAAAJ",
      "NQRw0bQAAAAJ",
      "ogXIdlYAAAAJ",
      "2yAMJ1YAAAAJ",
      "6z4lQzMAAAAJ",
      "Q2U7G6oAAAAJ",
      "5a9ddsQAAAAJ",
      "3Qjt0BUAAAAJ",
      "gLdI4FcAAAAJ",
      "_j5XWygAAAAJ",
      "IyYsKTIAAAAJ",
      "yMXs1WcAAAAJ",
      "nIWUhXAAAAAJ",
      "e1ucbCYAAAAJ",
      "u0eUsYsAAAAJ",
      "TyPF9V4AAAAJ",
      "v-A_7UsAAAAJ",
      "AkffLRcAAAAJ",
      "W4SZGV8AAAAJ",
      "UtBcznsAAAAJ",
      "iBGPazIAAAAJ",
      "15g03MoAAAAJ",
      "udwtIesAAAAJ",
      "DnnCWN0AAAAJ",
      "ljDY868AAAAJ",
      "3OFgQKcAAAAJ",
      "O-vquhwAAAAJ",
      "-PIq1igAAAAJ",
      "_y14JooAAAAJ",
      "km_K9awAAAAJ",
      "xA3RcaUAAAAJ",
      "0VwIiIsAAAAJ",
      "FO8vjQMAAAAJ",
      "GyoKzFwAAAAJ",
      "yqfXEPIAAAAJ",
      "Nomi_U0AAAAJ",
      "AaVPa5kAAAAJ",
      "p2R-FRoAAAAJ",
      "5wiSTtUAAAAJ",
      "JPr5FAUAAAAJ",
      "t70ydxAAAAAJ",
      "JNXWWkIAAAAJ",
      "hOl-5zcAAAAJ",
      "YOVZiJkAAAAJ",
      "rLdfJ1gAAAAJ",
      "S-pd0NwAAAAJ",
      "1rPi_78AAAAJ",
      "q2YhTvAAAAAJ",
      "fOZk6agAAAAJ",
      "6IkG2m0AAAAJ",
      "HxYWiHsAAAAJ",
      "QGc-TQkAAAAJ",
      "cTPU9HcAAAAJ",
      "BIHeNNUAAAAJ",
      "UFo0PcAAAAAJ",
      "kwnwhrgAAAAJ",
      "FGGfkmMAAAAJ",
      "vmLs7E8AAAAJ",
      "rwfHSYgAAAAJ",
      "56EZh6YAAAAJ",
      "mukR7ccAAAAJ",
      "aq4kedwAAAAJ",
      "S21bOvsAAAAJ",
      "nX-_Ou0AAAAJ",
      "CIXmtCQAAAAJ",
      "O2nUrQIAAAAJ",
      "rJMOlVsAAAAJ",
      "E9ZX2lgAAAAJ",
      "nqrkC8IAAAAJ",
      "FnD5B1QAAAAJ",
      "w4XsexUAAAAJ",
      "1ZHcGwIAAAAJ",
      "X3cGY7wAAAAJ",
      "LcARjz0AAAAJ",
      "vvzAfOwAAAAJ",
      "2oy3OXYAAAAJ",
      "pEyaa44AAAAJ",
      "6WiWvr0AAAAJ",
      "VC3Z6dcAAAAJ",
      "eomC7sIAAAAJ",
      "kJ9CX6sAAAAJ",
      "UJb3uKgAAAAJ",
      "W8f0d6oAAAAJ",
      "JbkP8EwAAAAJ",
      "vtegaJgAAAAJ",
      "bruYeAQAAAAJ",
      "cgaU4UkAAAAJ",
      "SAnJ1hIAAAAJ",
      "Im_m9I8AAAAJ",
      "fe-1v0MAAAAJ",
      "TkVHKDgAAAAJ",
      "Slq0rJcAAAAJ",
      "RAiewnEAAAAJ",
      "4lmER2EAAAAJ",
      "sUXvfjUAAAAJ",
      "wvMb3ccAAAAJ",
      "P2Joz5sAAAAJ",
      "FXacC3oAAAAJ",
      "UFlWdvUAAAAJ",
      "UMZrl1cAAAAJ",
      "2yHJIP0AAAAJ",
      "YHjx7qoAAAAJ",
      "kfYJVXEAAAAJ",
      "3yVndk0AAAAJ",
      "EgVWuhAAAAAJ",
      "3kaiBBYAAAAJ",
      "QQ7lOvAAAAAJ",
      "7yn5-VEAAAAJ",
      "1Aa3qxIAAAAJ",
      "6_MJikoAAAAJ",
      "JicYPdAAAAAJ",
      "Wt0ndFIAAAAJ",
      "65bIT4oAAAAJ",
      "YvYBeysAAAAJ",
      "EjOkyc0AAAAJ",
      "ygdQhrIAAAAJ",
      "baF3HKUAAAAJ",
      "iD01qbkAAAAJ",
      "EL-QbZ4AAAAJ",
      "DSKXnkkAAAAJ",
      "eh9yS-QAAAAJ",
      "42MVVPgAAAAJ",
      "x78TL58AAAAJ",
      "Nd6DvD4AAAAJ",
      "O9BRr1UAAAAJ",
      "4VlAkPUAAAAJ",
      "HrrtgKkAAAAJ",
      "pRBbU7wAAAAJ",
      "kV9XRxYAAAAJ",
      "I8A1STcAAAAJ",
      "tlh8i7gAAAAJ",
      "ZP4gfYcAAAAJ",
      "qR4O45oAAAAJ",
      "92M8xv4AAAAJ",
      "XXeNb58AAAAJ",
      "RhOpyXcAAAAJ",
      "2yTeZ58AAAAJ",
      "cePtsyAAAAAJ",
      "Zr7RJT4AAAAJ",
      "01ks8yYAAAAJ",
      "tetdudUAAAAJ",
      "k6fOmQgAAAAJ",
      "cTpyTaIAAAAJ",
      "HjmSOFEAAAAJ",
      "tVjxANMAAAAJ",
      "UxuqG1EAAAAJ",
      "WrLjBYgAAAAJ",
      "mgMzkYMAAAAJ",
      "JC0I3vgAAAAJ",
      "Bw25vHMAAAAJ",
      "4QqjaDgAAAAJ",
      "vACm0-YAAAAJ",
      "SkkDQgMAAAAJ",
      "fTgRyn4AAAAJ",
      "KntSJpQAAAAJ",
      "0mf5NioAAAAJ",
      "uK53FGQAAAAJ",
      "tm5kow8AAAAJ",
      "LVk3xE4AAAAJ",
      "_75LDyMAAAAJ",
      "2opu1SsAAAAJ",
      "j-P28bQAAAAJ",
      "bsyOi1YAAAAJ",
      "bgpBDU4AAAAJ",
      "8LqrW5AAAAAJ",
      "8LDlwEwAAAAJ",
      "Qpfxtc8AAAAJ",
      "rFaxB20AAAAJ",
      "biJiXWoAAAAJ",
      "7l1HdzYAAAAJ",
      "o3PQcYgAAAAJ",
      "gX7rSCcAAAAJ",
      "aPNDep0AAAAJ",
      "-2E52C0AAAAJ",
      "VBkk_NoAAAAJ",
      "t1Xf7NQAAAAJ",
      "eqkBt6EAAAAJ",
      "e7rXLKAAAAAJ",
      "wRXPnP8AAAAJ",
      "n8tK15oAAAAJ",
      "MliblMQAAAAJ",
      "-zaDQ10AAAAJ",
      "c-uQx_0AAAAJ",
      "am5XqsQAAAAJ",
      "l6c85tMAAAAJ",
      "WKO_1VYAAAAJ",
      "lMkTx0EAAAAJ",
      "QBsEFvMAAAAJ",
      "dlytHK4AAAAJ",
      "fMQZybAAAAAJ",
      "ootP9OgAAAAJ",
      "d1oQ8NcAAAAJ",
      "ugH_Wg4AAAAJ",
      "OqAc0T0AAAAJ",
      "mZMaDgEAAAAJ",
      "VA5VktEAAAAJ",
      "8YrBnPsAAAAJ",
      "6GDfcqEAAAAJ",
      "fE3Bs1oAAAAJ",
      "clTKG0QAAAAJ",
      "PxYY_nsAAAAJ",
      "Zrv4oQIAAAAJ",
      "vRM148kAAAAJ",
      "Bm3pH5AAAAAJ",
      "jd1S28YAAAAJ",
      "zmLNe4AAAAAJ",
      "bCuYVE4AAAAJ",
      "lMqmhpwAAAAJ",
      "LY8SM4IAAAAJ",
      "IEcsMPAAAAAJ",
      "c7EMylYAAAAJ",
      "_30hSU8AAAAJ",
      "3svZOGAAAAAJ",
      "jdpFVlgAAAAJ",
      "B0K-DwEAAAAJ",
      "bGXte_4AAAAJ",
      "ibu3FwsAAAAJ",
      "wnK9jX8AAAAJ",
      "uHhsRFgAAAAJ",
      "-4cUri0AAAAJ",
      "rU_-c5oAAAAJ",
      "AdG54z4AAAAJ",
      "XC3nc68AAAAJ",
      "X-VK_5EAAAAJ",
      "06rffEkAAAAJ",
      "wb9DYOEAAAAJ",
      "qmjjxBoAAAAJ",
      "yneRh8EAAAAJ",
      "s5Aqlw4AAAAJ",
      "-NXsLG4AAAAJ",
      "eOLxyqUAAAAJ",
      "hW9fwNYAAAAJ",
      "euruCPEAAAAJ",
      "orqXipgAAAAJ",
      "keIlGm0AAAAJ",
      "rFd-DiAAAAAJ",
      "ep2QZ70AAAAJ",
      "hEUk48QAAAAJ",
      "zyR_DF4AAAAJ",
      "jtrAdywAAAAJ",
      "8qisprwAAAAJ",
      "BnQdO2UAAAAJ",
      "NfJiSMMAAAAJ",
      "nY6P_nwAAAAJ",
      "6wGt7fYAAAAJ",
      "94RFSSsAAAAJ",
      "Nbq6kI0AAAAJ",
      "XZkvOTEAAAAJ",
      "n9fRgvkAAAAJ",
      "WxlqsisAAAAJ",
      "P5g-cYwAAAAJ",
      "o5B39L8AAAAJ",
      "q7nFtUcAAAAJ",
      "job97voAAAAJ",
      "86za4C0AAAAJ",
      "gxnzvbYAAAAJ",
      "BGN4egcAAAAJ",
      "v6YG0YEAAAAJ",
      "P6MosQgAAAAJ",
      "79etgAkAAAAJ",
      "k4SdlbcAAAAJ",
      "HjWpRCIAAAAJ",
      "zp8V7ZMAAAAJ",
      "1CPY1LsAAAAJ",
      "Y2GtJkAAAAAJ",
      "tWcg0ZsAAAAJ",
      "R1eV0ekAAAAJ",
      "LrsjJfwAAAAJ",
      "zyQAdTwAAAAJ",
      "7YWMCDkAAAAJ",
      "sZrw0v0AAAAJ",
      "hKlHPt0AAAAJ",
      "ZBBX5u4AAAAJ",
      "HuZ6F6QAAAAJ",
      "N4sca6EAAAAJ",
      "mV9LQUoAAAAJ",
      "E_82W3EAAAAJ",
      "UZ5wscMAAAAJ",
      "2z3fl5EAAAAJ",
      "VJPRn1oAAAAJ",
      "2dCb2U0AAAAJ",
      "CcruPcoAAAAJ",
      "U0_ab4cAAAAJ",
      "oJESe-cAAAAJ",
      "a7VNhCIAAAAJ",
      "dfsJMOYAAAAJ",
      "-0U84zMAAAAJ",
      "wqVWJNIAAAAJ",
      "1c9oQNMAAAAJ",
      "kW06fgwAAAAJ",
      "Lu7sHfoAAAAJ",
      "BaRpQ_kAAAAJ",
      "wfGiqXEAAAAJ",
      "plQDn_wAAAAJ",
      "D3ita20AAAAJ",
      "T2U5sGIAAAAJ",
      "N0Lv5FUAAAAJ",
      "TxEy3cwAAAAJ",
      "dRc-rTAAAAAJ",
      "DD1MSdMAAAAJ",
      "uVrmjIAAAAAJ",
      "bjdB4K8AAAAJ",
      "xE_pSDAAAAAJ",
      "0CQMPB0AAAAJ",
      "JUpvud8AAAAJ",
      "I2LNwZgAAAAJ",
      "FKUc3vsAAAAJ",
      "ke0k9PkAAAAJ",
      "lYqgwwwAAAAJ",
      "5H0arvkAAAAJ",
      "BDYIAe4AAAAJ",
      "n7Rh7mgAAAAJ",
      "xhU85M4AAAAJ",
      "IVMpLjIAAAAJ",
      "VeXMKBoAAAAJ",
      "9akH-n8AAAAJ",
      "heSjtpgAAAAJ",
      "-UhqXIEAAAAJ",
      "CCV58dgAAAAJ",
      "RGNVBKMAAAAJ",
      "DWPfdT4AAAAJ",
      "zkhHirIAAAAJ",
      "mYyG4p0AAAAJ",
      "GixQBggAAAAJ",
      "quJBh1EAAAAJ",
      "pHSC4Z0AAAAJ",
      "f9iP-80AAAAJ",
      "cX2HlhQAAAAJ",
      "QKFb5pkAAAAJ",
      "T1iIhDEAAAAJ",
      "FmnJtIYAAAAJ",
      "GDabimYAAAAJ",
      "p8ArrV4AAAAJ",
      "_xWMxrQAAAAJ",
      "-j0q9B4AAAAJ",
      "kOWrypIAAAAJ",
      "SMRGdi0AAAAJ",
      "2aqu0VMAAAAJ",
      "OYh64JwAAAAJ",
      "rno2y00AAAAJ",
      "-ILhc-sAAAAJ",
      "v7UAODsAAAAJ",
      "0BQzlisAAAAJ",
      "ABr4UU4AAAAJ",
      "OI7zFmwAAAAJ",
      "pzw1-J4AAAAJ",
      "Tlm978oAAAAJ",
      "9oz-dvgAAAAJ",
      "2Q6fIuAAAAAJ",
      "wgh5X-AAAAAJ",
      "Tpp9ZjoAAAAJ",
      "o67NTxYAAAAJ",
      "zMvBdmQAAAAJ",
      "nXBQn7gAAAAJ",
      "OKjAP7AAAAAJ",
      "BC1Zc78AAAAJ",
      "zCaMimYAAAAJ",
      "5SF-hRsAAAAJ",
      "teS9lHAAAAAJ",
      "7EBwGhIAAAAJ",
      "3yJr9q4AAAAJ",
      "ZE5_-DIAAAAJ",
      "I_YIc0YAAAAJ",
      "grQ_GBgAAAAJ",
      "3bwC_f4AAAAJ",
      "WBCKQMsAAAAJ",
      "5elBSHQAAAAJ",
      "Kpqp274AAAAJ",
      "MNuTR9YAAAAJ",
      "CdEMlrIAAAAJ",
      "mS5k4CYAAAAJ",
      "DmIG_WoAAAAJ",
      "8hpOmVgAAAAJ",
      "t3mQx_kAAAAJ",
      "th3BO8MAAAAJ",
      "3IUE2yQAAAAJ",
      "3mOq4dcAAAAJ",
      "QEqPllIAAAAJ",
      "oqDCDOoAAAAJ",
      "eJAV17IAAAAJ",
      "gVUD47sAAAAJ",
      "rHIz0PoAAAAJ",
      "S4z3uzMAAAAJ",
      "ixp-vqMAAAAJ",
      "fWbf74cAAAAJ",
      "wOYUPpwAAAAJ",
      "D_JpQnAAAAAJ",
      "YAtwLpwAAAAJ",
      "oQsObk0AAAAJ",
      "HO3nVAoAAAAJ",
      "IdSxI0YAAAAJ",
      "fMAg4zEAAAAJ",
      "YQ0GIUwAAAAJ",
      "JvUypEMAAAAJ",
      "xZal_nUAAAAJ",
      "8l9BcBAAAAAJ",
      "UQIBiUcAAAAJ",
      "Ihyz20wAAAAJ",
      "ip9xnysAAAAJ",
      "SxUNhucAAAAJ",
      "XOWZzUcAAAAJ",
      "8W-MW9sAAAAJ",
      "-pgIngUAAAAJ",
      "QFpswmcAAAAJ",
      "h20U9WcAAAAJ",
      "ZasL8IoAAAAJ",
      "ZcULDB0AAAAJ",
      "zdKmnYwAAAAJ",
      "lDmZxTMAAAAJ",
      "ewQrF9cAAAAJ",
      "Vjo4Tg4AAAAJ",
      "Nmty1bkAAAAJ",
      "fGZMMKUAAAAJ",
      "Nmk26z4AAAAJ",
      "Ks1yyXYAAAAJ",
      "UtAdFs8AAAAJ",
      "jUAAhpMAAAAJ",
      "yxWtZLAAAAAJ",
      "_j4M4KEAAAAJ",
      "LUAuzBAAAAAJ",
      "-B5JgjsAAAAJ",
      "OgV3CkYAAAAJ",
      "YJxFe1UAAAAJ",
      "sJIAF-gAAAAJ",
      "-kX87sgAAAAJ",
      "8bVtuOwAAAAJ",
      "RtwBsDYAAAAJ",
      "kV5zQBkAAAAJ",
      "Cul0g2YAAAAJ",
      "GtxZI1MAAAAJ",
      "Cya7Va8AAAAJ",
      "qzIHHMEAAAAJ",
      "p2az0gkAAAAJ",
      "19xIGUUAAAAJ",
      "i16X9rUAAAAJ",
      "UWnwlu4AAAAJ",
      "pqpxh7IAAAAJ",
      "Q8K3FjQAAAAJ",
      "re00xioAAAAJ",
      "Iiut4KYAAAAJ",
      "wCa6nygAAAAJ",
      "0cO2nlMAAAAJ",
      "BAD30S8AAAAJ",
      "s4rghcgAAAAJ",
      "tWI9Pw8AAAAJ",
      "g1n-MOEAAAAJ",
      "KL6_oegAAAAJ",
      "fNfrGMIAAAAJ",
      "lLqnszIAAAAJ",
      "kmeUhO8AAAAJ",
      "LZIPfCkAAAAJ",
      "g5vDxv8AAAAJ",
      "9TbXgQ0AAAAJ",
      "HEY3UzgAAAAJ",
      "nzz6PQMAAAAJ",
      "zeX8KGAAAAAJ",
      "PnyV8dgAAAAJ",
      "xjnef1AAAAAJ",
      "HhotyAoAAAAJ",
      "zT8cqLkAAAAJ",
      "p1XHoeoAAAAJ",
      "SKq6DZcAAAAJ",
      "-JPZ21IAAAAJ",
      "cbTB5-EAAAAJ",
      "AQIwobkAAAAJ",
      "zEUV5a8AAAAJ",
      "WKM_BdYAAAAJ",
      "pRclXR8AAAAJ",
      "yzcxu7oAAAAJ",
      "XI79Mw0AAAAJ",
      "fanhk-gAAAAJ",
      "uKuvN64AAAAJ",
      "K-2OXMIAAAAJ",
      "cbuy0ocAAAAJ",
      "Mkaq4VYAAAAJ",
      "NECavRYAAAAJ",
      "RScZCLEAAAAJ",
      "CbGdL4cAAAAJ",
      "JhIotuYAAAAJ",
      "ItOvQJ4AAAAJ",
      "7soDcboAAAAJ",
      "RUP4S68AAAAJ",
      "I0EoZyQAAAAJ",
      "eZr-ai0AAAAJ",
      "D2boLjwAAAAJ",
      "1hLMcNsAAAAJ",
      "YiUWYl0AAAAJ",
      "2uHyOSIAAAAJ",
      "XM97iScAAAAJ",
      "aZ1Rh50AAAAJ",
      "yOt01wgAAAAJ",
      "_Gl7YvAAAAAJ",
      "yO82m38AAAAJ",
      "jWxX49cAAAAJ",
      "bjNCUt8AAAAJ",
      "feX1fWAAAAAJ",
      "HWFvq_wAAAAJ",
      "RyKtqiQAAAAJ",
      "_SuhcLEAAAAJ",
      "YdiZoJgAAAAJ",
      "mjDKAAoAAAAJ",
      "d5y4iKAAAAAJ",
      "XTqgW-EAAAAJ",
      "cXQciMEAAAAJ",
      "Wx-ul64AAAAJ",
      "AdBqkbIAAAAJ",
      "6YU6_QoAAAAJ",
      "eg6u4X8AAAAJ",
      "WzmDQTMAAAAJ",
      "zmDJrh0AAAAJ",
      "h3XP9JkAAAAJ",
      "UjpbO6IAAAAJ",
      "4Zw1PJ8AAAAJ",
      "R-Cc2h8AAAAJ",
      "e8ZEb4wAAAAJ",
      "qALDmfcAAAAJ",
      "P1jPSzMAAAAJ",
      "CjymsJAAAAAJ",
      "7fONeB0AAAAJ",
      "Tarh6WoAAAAJ",
      "HvJj-pEAAAAJ",
      "2Dab2vkAAAAJ",
      "0FSlSt4AAAAJ",
      "iyEuK8kAAAAJ",
      "lhpoASkAAAAJ",
      "PuTDB5gAAAAJ",
      "xVFrEDwAAAAJ",
      "BbfIggwAAAAJ",
      "NkzyCvUAAAAJ",
      "Ao4gtsYAAAAJ",
      "2eADy_8AAAAJ",
      "kGODZaIAAAAJ",
      "AB0CIBAAAAAJ",
      "P9FclNEAAAAJ",
      "50__r6EAAAAJ",
      "xEm-9oMAAAAJ",
      "t4dSV4YAAAAJ",
      "L1b6JqsAAAAJ",
      "C1skWKgAAAAJ",
      "wNRE148AAAAJ",
      "dilO2p4AAAAJ",
      "ma2bi00AAAAJ",
      "QMkbFp8AAAAJ",
      "ss8KR5gAAAAJ",
      "xR6fOrAAAAAJ",
      "-nsG4ZUAAAAJ",
      "WrJerFMAAAAJ",
      "9SakklgAAAAJ",
      "RTVRTSsAAAAJ",
      "C7zfAI4AAAAJ",
      "WIpCH90AAAAJ",
      "_bs7PqgAAAAJ",
      "iSI9-1oAAAAJ",
      "7unNfcMAAAAJ",
      "loxOHhoAAAAJ",
      "e7V7-gEAAAAJ",
      "uqTfLEgAAAAJ",
      "hyWg3nEAAAAJ",
      "LgAp4-oAAAAJ",
      "MVxcjEoAAAAJ",
      "NjxgmeIAAAAJ",
      "eP2Z3qQAAAAJ",
      "8yGMMwcAAAAJ",
      "fxzlm6IAAAAJ",
      "ONv0HgMAAAAJ",
      "hDGGNYIAAAAJ",
      "Wd8_fOcAAAAJ",
      "VCpSh3gAAAAJ",
      "CiSdOV0AAAAJ",
      "GIejbKQAAAAJ",
      "6MUY5mgAAAAJ",
      "ymzxRhAAAAAJ",
      "RKjEFukAAAAJ",
      "28oeBTgAAAAJ",
      "YDKPDkgAAAAJ",
      "lLMX9hcAAAAJ",
      "nXyv100AAAAJ",
      "d3JgIc8AAAAJ",
      "Bmbkv6sAAAAJ",
      "xIpN5lQAAAAJ",
      "-E3hYj8AAAAJ",
      "f31mvPsAAAAJ",
      "BxlScrEAAAAJ",
      "iFhSTbAAAAAJ",
      "F63BY8kAAAAJ",
      "A7AuNE8AAAAJ",
      "U6Tf0VEAAAAJ",
      "p1tu16UAAAAJ",
      "yaOyQOQAAAAJ",
      "kmoklesAAAAJ",
      "TeuEgRkAAAAJ",
      "rQkl8gIAAAAJ",
      "ehv7qvIAAAAJ",
      "Cmf2HdcAAAAJ",
      "NW5Y82wAAAAJ",
      "GU-vJ5AAAAAJ",
      "I5-0kFQAAAAJ",
      "GcuxcLYAAAAJ",
      "o500TjwAAAAJ",
      "58cKLg4AAAAJ",
      "rgf7oH4AAAAJ",
      "gu2noOcAAAAJ",
      "BN0O9wgAAAAJ",
      "Lvm9Q8QAAAAJ",
      "QehMdGIAAAAJ",
      "lXAUVFcAAAAJ",
      "FiBMfBsAAAAJ",
      "vJkEuTEAAAAJ",
      "5A0Sg-8AAAAJ",
      "LI7rp1QAAAAJ",
      "ZBF2zKMAAAAJ",
      "qX06pRYAAAAJ",
      "JgTAHxkAAAAJ",
      "rvIjH9IAAAAJ",
      "FUOEBDUAAAAJ",
      "UDKpJ0IAAAAJ",
      "8jAftjUAAAAJ",
      "p0L7kOkAAAAJ",
      "Ay-iC-8AAAAJ",
      "3siz6_0AAAAJ",
      "B76dD7YAAAAJ",
      "KynAS2gAAAAJ",
      "rT11mdcAAAAJ",
      "EvUM6UUAAAAJ",
      "PfaeD-8AAAAJ",
      "CQEyVPMAAAAJ",
      "tYazD-8AAAAJ",
      "km6CP8cAAAAJ",
      "tu7wKckAAAAJ",
      "p-PC50wAAAAJ",
      "Ay8t8DEAAAAJ",
      "WLOrHh8AAAAJ",
      "PXm1lPAAAAAJ",
      "IYDJuOAAAAAJ",
      "gckWFYUAAAAJ",
      "3Rlc8EAAAAAJ",
      "7OTD-LEAAAAJ",
      "Hu2Ht28AAAAJ",
      "TDk_NfkAAAAJ",
      "FTWcemsAAAAJ",
      "0iZls38AAAAJ",
      "vX5i2CcAAAAJ",
      "uDVHMCwAAAAJ",
      "GExyiRkAAAAJ",
      "s5-hnX8AAAAJ",
      "sUGrQicAAAAJ",
      "X0EXfT8AAAAJ",
      "MnoNkkcAAAAJ",
      "II-AXHYAAAAJ",
      "OcPVegoAAAAJ",
      "CYkqs5UAAAAJ",
      "6jRu5x4AAAAJ",
      "hISpTpQAAAAJ",
      "SuH4Z2gAAAAJ",
      "9hkEkG0AAAAJ",
      "MA8rI0MAAAAJ",
      "opbZfw0AAAAJ",
      "reEAEWsAAAAJ",
      "BTZBaosAAAAJ",
      "a4HRDBEAAAAJ",
      "of_W1_MAAAAJ",
      "nEsOOx8AAAAJ",
      "XVUCn40AAAAJ",
      "VZCAjz4AAAAJ",
      "3P1gs1sAAAAJ",
      "Cy_VZ3QAAAAJ",
      "0pLOTKcAAAAJ",
      "rA48PN4AAAAJ",
      "1sB4m_wAAAAJ",
      "oWcFfZcAAAAJ",
      "B58vq_cAAAAJ",
      "Kv2Sm7oAAAAJ",
      "BbdF4ysAAAAJ",
      "w2Bt-vwAAAAJ",
      "1aj4dZcAAAAJ",
      "fSgLUqYAAAAJ",
      "x8UpLZUAAAAJ",
      "EyrM4VIAAAAJ",
      "6mD3I24AAAAJ",
      "oj0A7FoAAAAJ",
      "E8aZ_q4AAAAJ",
      "iPI39lEAAAAJ",
      "Qcn2vwUAAAAJ",
      "KzhR_TsAAAAJ",
      "arZclaMAAAAJ",
      "n0Tc-dkAAAAJ",
      "p5uvh2oAAAAJ",
      "JFT_m9kAAAAJ",
      "PjAQATEAAAAJ",
      "HNNL22kAAAAJ",
      "9v86038AAAAJ",
      "yd-4aEIAAAAJ",
      "vEiu33sAAAAJ",
      "YM8BRlUAAAAJ",
      "t5Xsx0IAAAAJ",
      "U2MUXuMAAAAJ",
      "v3w4IYUAAAAJ",
      "bD4hIqcAAAAJ",
      "AdSEuYcAAAAJ",
      "Gqp2GqkAAAAJ",
      "YgoU6w0AAAAJ",
      "jEHm-fUAAAAJ",
      "bEn7ySYAAAAJ",
      "6MfHyuMAAAAJ",
      "LYVNrhMAAAAJ",
      "1LbWyf4AAAAJ",
      "rKv_MJ4AAAAJ",
      "hr81fHoAAAAJ",
      "8fiH7UkAAAAJ",
      "s4Q8hbUAAAAJ",
      "GYksTEEAAAAJ",
      "srP2ANoAAAAJ",
      "TApLOhkAAAAJ",
      "U6AIrqwAAAAJ",
      "vyppxW4AAAAJ",
      "tgtareEAAAAJ",
      "BkDCPiIAAAAJ",
      "biuxbRsAAAAJ",
      "zPPcv9sAAAAJ",
      "8HVTWNkAAAAJ",
      "WJNkMakAAAAJ",
      "sao1OhsAAAAJ",
      "cCUHSdkAAAAJ",
      "JycXWO0AAAAJ",
      "0QDCG8IAAAAJ",
      "PVcaULkAAAAJ",
      "q-06TwoAAAAJ",
      "OxrRSKsAAAAJ",
      "Ry0Bdt8AAAAJ",
      "DRnOvU8AAAAJ",
      "h-sqIigAAAAJ",
      "ixE1z7UAAAAJ",
      "axvGyXoAAAAJ",
      "1XAhYswAAAAJ",
      "wLsZd9wAAAAJ",
      "4fK8bYIAAAAJ",
      "SMSWgw0AAAAJ",
      "2R22h84AAAAJ",
      "Bo-wyrkAAAAJ",
      "pLwOQV4AAAAJ",
      "eyqQt3gAAAAJ",
      "lRUi-A8AAAAJ",
      "23rIjfwAAAAJ",
      "BCxFU0EAAAAJ",
      "ao8r3Q4AAAAJ",
      "KpK7n2EAAAAJ",
      "KFXJQ90AAAAJ",
      "Vz-lz3cAAAAJ",
      "PaEn9KEAAAAJ",
      "cyCp3pIAAAAJ",
      "qWfJbHMAAAAJ",
      "wcOO6hgAAAAJ",
      "hCatCxMAAAAJ",
      "133WpF8AAAAJ",
      "1hqOg28AAAAJ",
      "UE9jz_MAAAAJ",
      "PIq7jcUAAAAJ",
      "lNQmMTMAAAAJ",
      "hbLmvo0AAAAJ",
      "uXNnBTUAAAAJ",
      "d-3sFxQAAAAJ",
      "FXiSi-4AAAAJ",
      "v7EjGHkAAAAJ",
      "eH_c4R4AAAAJ",
      "oy7TshoAAAAJ",
      "axX7PCwAAAAJ",
      "UnuEcZEAAAAJ",
      "_0IIzxgAAAAJ",
      "MeS5d4gAAAAJ",
      "gAKTYtoAAAAJ",
      "MzT5-4kAAAAJ",
      "CBzRa74AAAAJ",
      "xOFOVGMAAAAJ",
      "t1cX3kcAAAAJ",
      "fiDP8AkAAAAJ",
      "UxEw4icAAAAJ",
      "Ajec0lYAAAAJ",
      "Yn-Lm_QAAAAJ",
      "5mSnPlwAAAAJ",
      "8LcYFjEAAAAJ",
      "4EOqqUsAAAAJ",
      "nnCmyBoAAAAJ",
      "9TKjEuQAAAAJ",
      "Ac6n5pQAAAAJ",
      "VJ8Qd6sAAAAJ",
      "5_Fn5CIAAAAJ",
      "h0e2kMQAAAAJ",
      "H4sNIhwAAAAJ",
      "3ACMPEQAAAAJ",
      "2mOtJU4AAAAJ",
      "TZ7xuYAAAAAJ",
      "yjeEP_EAAAAJ",
      "3rq29xkAAAAJ",
      "U_NEZHQAAAAJ",
      "ku59ZJoAAAAJ",
      "xGXNsCMAAAAJ",
      "ZjuMpLoAAAAJ",
      "JzKCTBgAAAAJ",
      "aApop70AAAAJ",
      "JsK4KpMAAAAJ",
      "e4I7ihkAAAAJ",
      "NTozWbQAAAAJ",
      "Q_4d9N0AAAAJ",
      "hSyfNekAAAAJ",
      "f89ndwoAAAAJ",
      "WqJvRZoAAAAJ",
      "3VyGrdwAAAAJ",
      "WA86ONsAAAAJ",
      "JmJfOkMAAAAJ",
      "iGLKl7cAAAAJ",
      "Wx62iOsAAAAJ",
      "5rz6jiUAAAAJ",
      "RNHJqvcAAAAJ",
      "CZiTv0gAAAAJ",
      "yCyrc0MAAAAJ",
      "GUAoEcAAAAAJ",
      "WBS6zncAAAAJ",
      "eAHAxi0AAAAJ",
      "TcXHyvMAAAAJ",
      "T_mPgZIAAAAJ",
      "MkxZCXsAAAAJ",
      "uRlPu-4AAAAJ",
      "CSxgi6AAAAAJ",
      "Rkr2uT8AAAAJ",
      "kcsbLrAAAAAJ",
      "nNVDLb4AAAAJ",
      "s8xc2K4AAAAJ",
      "P7nTj5EAAAAJ",
      "V8RKLEsAAAAJ",
      "eMwEEXUAAAAJ",
      "wWaA2QwAAAAJ",
      "TP0epB8AAAAJ",
      "xHC1VkoAAAAJ",
      "_fxnybwAAAAJ",
      "vXHA_XYAAAAJ",
      "v1rY3BYAAAAJ",
      "ey9AQcEAAAAJ",
      "TKvd_Z4AAAAJ",
      "m1wmXdgAAAAJ",
      "y5uNFK0AAAAJ",
      "3QxoymwAAAAJ",
      "f_sApl4AAAAJ",
      "LVJtdoEAAAAJ",
      "4VpTwzIAAAAJ",
      "hHPeXmYAAAAJ",
      "ppYWVlYAAAAJ",
      "t64GpvUAAAAJ",
      "E2uuNVoAAAAJ",
      "loh93ZkAAAAJ",
      "h-pwCMUAAAAJ",
      "oOhnPUgAAAAJ",
      "jiyonF0AAAAJ",
      "rLepj0gAAAAJ",
      "dSU9MtYAAAAJ",
      "glg1I70AAAAJ",
      "Ytp9oFQAAAAJ",
      "V8NPfyQAAAAJ",
      "rdwkreIAAAAJ",
      "0PUtrrgAAAAJ",
      "9MSArZUAAAAJ",
      "V2Y1L4sAAAAJ",
      "CypbdCkAAAAJ",
      "ld-vt9QAAAAJ",
      "QdnjDj8AAAAJ",
      "eycXl_QAAAAJ",
      "adnTgaAAAAAJ",
      "OrUyRAcAAAAJ",
      "Sx-673sAAAAJ",
      "0Y3a3M4AAAAJ",
      "wUZuAisAAAAJ",
      "STRrPekAAAAJ",
      "SzgX3_MAAAAJ",
      "wy0FA1cAAAAJ",
      "zghjmDgAAAAJ",
      "o37mElYAAAAJ",
      "zQABr7QAAAAJ",
      "eCc_7IgAAAAJ",
      "QJZQgN8AAAAJ",
      "b0ehAgIAAAAJ",
      "KGMaP18AAAAJ",
      "Vv8UdowAAAAJ",
      "0ROQMVcAAAAJ",
      "vHs01IMAAAAJ",
      "c_z5hWEAAAAJ",
      "h3Nsz6YAAAAJ",
      "ND0FM6EAAAAJ",
      "UpZbV44AAAAJ",
      "UuwugFEAAAAJ",
      "jTLiOiMAAAAJ",
      "xUGZX_MAAAAJ",
      "hg3A9TgAAAAJ",
      "gqB4u_wAAAAJ",
      "JcaWZAQAAAAJ",
      "uW8JaBsAAAAJ",
      "9jK5lfsAAAAJ",
      "wlAYZBwAAAAJ",
      "mY6IzuYAAAAJ",
      "iCiUflEAAAAJ",
      "p9-nlRIAAAAJ",
      "ctk2MhUAAAAJ",
      "1Q4R-hIAAAAJ",
      "BAtMB04AAAAJ",
      "iUgCzvgAAAAJ",
      "LCAcHmAAAAAJ",
      "SBTxvCoAAAAJ",
      "nQ7Ij30AAAAJ",
      "_PhjyLoAAAAJ",
      "7CKFg9EAAAAJ",
      "DJon7w4AAAAJ",
      "1M79iLwAAAAJ",
      "hLTZTG4AAAAJ",
      "InxhqXgAAAAJ",
      "L7lMQkQAAAAJ",
      "eFkBvOgAAAAJ",
      "3JfHObUAAAAJ",
      "z8GwuTgAAAAJ",
      "HcL76tsAAAAJ",
      "SaboshYAAAAJ",
      "01Ja8EUAAAAJ",
      "Uly5spMAAAAJ",
      "SnQnQicAAAAJ",
      "Vzr1RukAAAAJ",
      "qCrypnoAAAAJ",
      "hNy1aBgAAAAJ",
      "KG7Na5oAAAAJ",
      "FVTgmOwAAAAJ",
      "D3nUPbYAAAAJ",
      "aXWFB2UdJUUC",
      "wDltOqQAAAAJ",
      "SEDPkrsAAAAJ",
      "J5ZQ-BUAAAAJ",
      "r8NO774AAAAJ",
      "5pKTRxEAAAAJ",
      "n4QjVfoAAAAJ",
      "-tTv7oYAAAAJ",
      "zdAyna8AAAAJ",
      "KSZmI5EAAAAJ",
      "UGZ0jy4AAAAJ",
      "SAEI0jwAAAAJ",
      "Fr9Vhe4AAAAJ",
      "LGo5J4IAAAAJ",
      "DUgsNccAAAAJ",
      "MAs0vOwAAAAJ",
      "8RVWMycAAAAJ",
      "j56HgqYAAAAJ",
      "zGzDpuUAAAAJ",
      "8-p9CLsAAAAJ",
      "EPQuuHMAAAAJ",
      "Lx3Dc9cAAAAJ",
      "sjF5p5wAAAAJ",
      "q0MzO6cAAAAJ",
      "EareJO0AAAAJ",
      "jk0gVL8AAAAJ",
      "OT1uf7kAAAAJ",
      "rldfxOMAAAAJ",
      "piSbEjwAAAAJ",
      "VBz8gZ4AAAAJ",
      "OwT_8sQAAAAJ",
      "TNdMwp0AAAAJ",
      "oCw8EScAAAAJ",
      "haO4sKoAAAAJ",
      "2GcqQgYAAAAJ",
      "gh_fDicAAAAJ",
      "JlX2UTEAAAAJ",
      "Gwb4YkUAAAAJ",
      "NLW1g68AAAAJ",
      "ztpK4iwAAAAJ",
      "99RVk_MAAAAJ",
      "VJlCMGYAAAAJ",
      "j5_DDM0AAAAJ",
      "GuhpBxMAAAAJ",
      "gUEkPQEAAAAJ",
      "j4UuW80AAAAJ",
      "E6ayakEAAAAJ",
      "k_u5ULgAAAAJ",
      "vVvbU7oAAAAJ",
      "afpYZisAAAAJ",
      "a4unsk4AAAAJ",
      "cwKg158AAAAJ",
      "K7Q4GWQAAAAJ",
      "eQ9_vDAAAAAJ",
      "0nPi5YYAAAAJ",
      "mW9BcgsAAAAJ",
      "g3VILNEAAAAJ",
      "UA9Hb2EAAAAJ",
      "IetijcoAAAAJ",
      "ID9QePIAAAAJ",
      "g9bV-_sAAAAJ",
      "TD9RhcgAAAAJ",
      "5sz_jBoAAAAJ",
      "bUGiGKcAAAAJ",
      "tEk4qo8AAAAJ",
      "L_9C4v0AAAAJ",
      "_D_j2aoAAAAJ",
      "JIhJXWUAAAAJ",
      "34bu2-8AAAAJ",
      "22DYUdgAAAAJ",
      "h1NXfKYAAAAJ",
      "lfPTD18AAAAJ",
      "93zBpkAAAAAJ",
      "yuNhi-8AAAAJ",
      "hr1PnUkAAAAJ",
      "88cU_4UAAAAJ",
      "lQn_FEoAAAAJ",
      "KtnTuq8AAAAJ",
      "ZWPqDxEAAAAJ",
      "VRsNu-EAAAAJ",
      "bel5BBcAAAAJ",
      "RhN6jKIAAAAJ",
      "HAgGqScAAAAJ",
      "yhz7sFoAAAAJ",
      "LBJv1gsAAAAJ",
      "sI0DsP8AAAAJ",
      "uErE2UUAAAAJ",
      "ORJ4d3UAAAAJ",
      "19t-gxUAAAAJ",
      "pp848fYAAAAJ",
      "HxZDDzUAAAAJ",
      "F5PJHPcAAAAJ",
      "xd1bW3AAAAAJ",
      "VEUW-qIAAAAJ",
      "HeEBacsAAAAJ",
      "WJlBOwQAAAAJ",
      "nBL0J6kAAAAJ",
      "anc4v98AAAAJ",
      "xQM4BlMAAAAJ",
      "2NHX1bIAAAAJ",
      "0gp5M-kAAAAJ",
      "8cxDHS4AAAAJ",
      "ZRl2aAwAAAAJ",
      "TtAwEMgAAAAJ",
      "eOkGKuUAAAAJ",
      "mOMChFIAAAAJ",
      "N_KDBGcAAAAJ",
      "Ggy4_UcAAAAJ",
      "3qPiYJoAAAAJ",
      "pl-qLQwAAAAJ",
      "8_he8cUAAAAJ",
      "glNJx5zYUbsC",
      "Sm15FXIAAAAJ",
      "VX7d5EQAAAAJ",
      "jWRhmqoAAAAJ",
      "zIv6YN0AAAAJ",
      "yZGlLeMAAAAJ",
      "n6egtH4AAAAJ",
      "cdP5JicAAAAJ",
      "NOZmGq0AAAAJ",
      "6uTDJ9oAAAAJ",
      "QKNeRFsAAAAJ",
      "0O9BbqoAAAAJ",
      "ELiOV2IAAAAJ",
      "8Xt3TnAAAAAJ",
      "GnuEOOgAAAAJ",
      "QGcz9-kAAAAJ",
      "TyyftvAAAAAJ",
      "a-3LnGUAAAAJ",
      "fqkakg8AAAAJ",
      "Cxh2C2oAAAAJ",
      "E-rCbqQAAAAJ",
      "qTnlYokAAAAJ",
      "WDSU0ucAAAAJ",
      "ILkESaUAAAAJ",
      "jQl9RtkAAAAJ",
      "RAt7zSUAAAAJ",
      "pgcjVaYAAAAJ",
      "evrgC2oAAAAJ",
      "Bq1dFNQAAAAJ",
      "WsNt9VoAAAAJ",
      "X08l_4IAAAAJ",
      "rvKJDbIAAAAJ",
      "8iQk0DIAAAAJ",
      "mINzfREAAAAJ",
      "3jS17zQAAAAJ",
      "MYvSvGsAAAAJ",
      "jEzWxQIAAAAJ",
      "WoB6M2cAAAAJ",
      "ZZsEXLAAAAAJ",
      "osxb7aMAAAAJ",
      "1nLn7pcAAAAJ",
      "_VhMIOIAAAAJ",
      "XLJrjN8AAAAJ",
      "3YnlF3UAAAAJ",
      "9ODmYwoAAAAJ",
      "viGDVSkAAAAJ",
      "kNDEuygAAAAJ",
      "zTBFoCoAAAAJ",
      "Bjf-KF8AAAAJ",
      "VgI1d98AAAAJ",
      "g2HE3PsAAAAJ",
      "UhDW6jkAAAAJ",
      "uY4D8-wAAAAJ",
      "0IkkBzQAAAAJ",
      "X71o1ykAAAAJ",
      "Wjs7DOoAAAAJ",
      "NAFriCkAAAAJ",
      "jiTj6toAAAAJ",
      "umm-i20AAAAJ",
      "eLw6g-UAAAAJ",
      "sJKiJQwAAAAJ",
      "DOg4nhoAAAAJ",
      "fFQTJdEAAAAJ",
      "373LKEYAAAAJ",
      "8DeZgKkAAAAJ",
      "0MzVIUsAAAAJ",
      "yatiIigAAAAJ",
      "6U3IGtEAAAAJ",
      "A_grkugAAAAJ",
      "VGga3R4AAAAJ",
      "75x4pdcAAAAJ",
      "_Y_XvN4AAAAJ",
      "YCbFRsAAAAAJ",
      "CXB-29IAAAAJ",
      "-gscDIEAAAAJ",
      "F3yrMeUAAAAJ",
      "QgETxGoAAAAJ",
      "EuCFFwYAAAAJ",
      "0XbUhDUAAAAJ",
      "71P8yv4AAAAJ",
      "ZybgAqkAAAAJ",
      "bBLqsgkAAAAJ",
      "V-HiOnUAAAAJ",
      "_m7uOmUAAAAJ",
      "5LLV29oAAAAJ",
      "80pKMyMAAAAJ",
      "2oB4nAIAAAAJ",
      "RA02NxsAAAAJ",
      "uvyYzagAAAAJ",
      "dlFYlXwAAAAJ",
      "AxGhhfsAAAAJ",
      "6HgpyjMAAAAJ",
      "i4ahyPMAAAAJ",
      "RM0ik8wAAAAJ",
      "Q06Rh6oAAAAJ",
      "FUiFDqUAAAAJ",
      "JBU4ivcAAAAJ",
      "PksdgoUAAAAJ",
      "dPsQR14AAAAJ",
      "-ooGheoAAAAJ",
      "zxzZAi0AAAAJ",
      "9BHYPnUAAAAJ",
      "uy43gzcAAAAJ",
      "VJFrfM0AAAAJ",
      "hcVpBCIAAAAJ",
      "nyicsDgAAAAJ",
      "_zLn05oAAAAJ",
      "2CGNfAEAAAAJ",
      "c0JG32IAAAAJ",
      "Pd4pbaAAAAAJ",
      "f6uvd6kAAAAJ",
      "R2lPbLQAAAAJ",
      "uNsqlqYAAAAJ",
      "kmgzPeQAAAAJ",
      "tbAlI9kAAAAJ",
      "CmQzsisAAAAJ",
      "9rhEuW8AAAAJ",
      "MRCF9PwAAAAJ",
      "YC4WABEAAAAJ",
      "dxwPYhQAAAAJ",
      "GyFb98kAAAAJ",
      "XjWnyM4AAAAJ",
      "g2xwfAMAAAAJ",
      "c1-jq60AAAAJ",
      "McBoXK0AAAAJ",
      "ErDOPbEAAAAJ",
      "OsarV_4AAAAJ",
      "xa-6ZlkAAAAJ",
      "07NrZFIAAAAJ",
      "IGnKP2AAAAAJ",
      "B6OXcFoAAAAJ",
      "EnCwNycAAAAJ",
      "_ogM5zAAAAAJ",
      "PZVd2h8AAAAJ",
      "plt2_DsAAAAJ",
      "HsYH17vSXmQC",
      "sPtFRB8AAAAJ",
      "gicJpX8AAAAJ",
      "ZqGaKSgAAAAJ",
      "z7inLV8AAAAJ",
      "pqP5_PgAAAAJ",
      "WYctQAQAAAAJ",
      "xFlasdQAAAAJ",
      "47EBD1QAAAAJ",
      "5ZTO0uMAAAAJ",
      "h4DSY8MAAAAJ",
      "yE9VDTkAAAAJ",
      "cyp0fCAAAAAJ",
      "DHddutUAAAAJ",
      "Q5yf4F4AAAAJ",
      "TlpsH9cAAAAJ",
      "YdHW1ycAAAAJ",
      "z3t35rcAAAAJ",
      "kc-qetAAAAAJ",
      "SnTMyGUAAAAJ",
      "evReMyEAAAAJ",
      "SRCCuo0AAAAJ",
      "QZrx9MEAAAAJ",
      "vgzrOK4AAAAJ",
      "z28rttMAAAAJ",
      "D_d_d8wAAAAJ",
      "QNnjg7YAAAAJ",
      "EKAynJgAAAAJ",
      "VaLB21wAAAAJ",
      "XgifkSsAAAAJ",
      "pg4JhX0AAAAJ",
      "8HCVx48AAAAJ",
      "hdnpRKsAAAAJ",
      "5waf3bkAAAAJ",
      "AMHNjTIAAAAJ",
      "x-n9rIMAAAAJ",
      "_woZ79YAAAAJ",
      "JEr3qVwAAAAJ",
      "bWwpLA4AAAAJ",
      "GFQzUKoAAAAJ",
      "b15vJuEAAAAJ",
      "u8SnUUgAAAAJ",
      "BFzFy1YAAAAJ",
      "rtfJhO0AAAAJ",
      "Kv9AbjMAAAAJ",
      "c0WCD74AAAAJ",
      "m791iN8AAAAJ",
      "yHDXov0AAAAJ",
      "NxGLVEEAAAAJ",
      "N9t6-RUAAAAJ",
      "FWDKUMUAAAAJ",
      "xF2mhDoAAAAJ",
      "rWZq2nQAAAAJ",
      "TljlLdIAAAAJ",
      "SgST3LkAAAAJ",
      "J7p1Fx4AAAAJ",
      "COuXyKwAAAAJ",
      "gb8sbdcAAAAJ",
      "raAzOHoAAAAJ",
      "HmCZLyoAAAAJ",
      "DJ6mzSUAAAAJ",
      "dztQNeQAAAAJ",
      "PYJlmicAAAAJ",
      "OdLQTz4AAAAJ",
      "cbIxOLYAAAAJ",
      "r493814AAAAJ",
      "93ZjIs0AAAAJ",
      "PsTik-gAAAAJ",
      "ExGkzjQAAAAJ",
      "MIEaoNEAAAAJ",
      "AZeK-REAAAAJ",
      "fpVf9QkAAAAJ",
      "E1c2bVoAAAAJ",
      "EOnaBbUAAAAJ",
      "Mdr6wjUAAAAJ",
      "r2OOH4cAAAAJ",
      "mim8FQkAAAAJ",
      "3hdOFF0AAAAJ",
      "6UHjQQYAAAAJ",
      "AQ8w2uEAAAAJ",
      "jjHAnBUAAAAJ",
      "RGsMgZA4H78C",
      "QQnewdYAAAAJ",
      "KP-DwH0AAAAJ",
      "lBO12XgAAAAJ",
      "4vpQvuwAAAAJ",
      "KmXVOQkAAAAJ",
      "FiTQ7UIAAAAJ",
      "cAy9G6oAAAAJ",
      "7cuwdr8AAAAJ",
      "qCdLtIoAAAAJ",
      "AnSVkUYAAAAJ",
      "T_bLpqYAAAAJ",
      "tipePDkAAAAJ",
      "a0za4V8AAAAJ",
      "-w5DuHgAAAAJ",
      "rNTIQXYAAAAJ",
      "VhxDLwcAAAAJ",
      "LAoMyyoAAAAJ",
      "ROJq4g4AAAAJ",
      "btoec6QAAAAJ",
      "ifK5o2UAAAAJ",
      "jUP4oi8AAAAJ",
      "ODdBJAcAAAAJ",
      "vy5ngwUAAAAJ",
      "7qXxyJkAAAAJ",
      "PgSzKsgAAAAJ",
      "JZ0snAcAAAAJ",
      "ri1sE34AAAAJ",
      "gn3rZ7sAAAAJ",
      "pTcB5WUAAAAJ",
      "k0ZTfQoAAAAJ",
      "HBtozdUAAAAJ",
      "XXiZaA4AAAAJ",
      "-5pzdw4AAAAJ",
      "y2pH4jcAAAAJ",
      "yXdK2wYAAAAJ",
      "jQLg-_UAAAAJ",
      "uRImMPoAAAAJ",
      "Vtzdv-MAAAAJ",
      "BWF8wn4AAAAJ",
      "_BiloKgAAAAJ",
      "-3XaxbkAAAAJ",
      "h60zIiUAAAAJ",
      "3N72KDQAAAAJ",
      "coNUBLoAAAAJ",
      "Ex3pgLAAAAAJ",
      "AOqzUmwAAAAJ",
      "xQAoHP0AAAAJ",
      "rlAIMRMAAAAJ",
      "Gc65LRwAAAAJ",
      "UyD0bLYAAAAJ",
      "-JiwekUAAAAJ",
      "6_cxCKQAAAAJ",
      "_6SjdyMAAAAJ",
      "c8IpF9gAAAAJ",
      "84WzBlYAAAAJ",
      "chv2d8IAAAAJ",
      "l6IizNwAAAAJ",
      "gopF7iMAAAAJ",
      "zYI0rysAAAAJ",
      "gewVBA4AAAAJ",
      "E9NVOBUAAAAJ",
      "yUkK-mgAAAAJ",
      "k1hJzF0AAAAJ",
      "UD87zMYAAAAJ",
      "uDdA-r4AAAAJ",
      "KgZxzjsAAAAJ",
      "IaDc0OcAAAAJ",
      "SUbqiqwAAAAJ",
      "nd8lQQIAAAAJ",
      "bd4gMFAAAAAJ",
      "B_IufdEAAAAJ",
      "sJJamz4AAAAJ",
      "mq-Vzk8AAAAJ",
      "2QbbLJAAAAAJ",
      "qvrqNfwAAAAJ",
      "Fqw9o84AAAAJ",
      "RpqvaTUAAAAJ",
      "RLDbLcUAAAAJ",
      "yyIoQu4AAAAJ",
      "71rdofMAAAAJ",
      "DSdABLMAAAAJ",
      "u7GirtIAAAAJ",
      "DhtAFkwAAAAJ",
      "eQ8ZIG4AAAAJ",
      "0J10RyoAAAAJ",
      "Zcv_mIoAAAAJ",
      "vu5Mw_0AAAAJ",
      "j7zKTIIAAAAJ",
      "ySEpPmYAAAAJ",
      "ccksLFUAAAAJ",
      "83OxU_4AAAAJ",
      "NamIygIAAAAJ",
      "oY7AJUgAAAAJ",
      "UKpinl8AAAAJ",
      "abn9WWMAAAAJ",
      "0mgEF28AAAAJ",
      "iILS6kQAAAAJ",
      "-SWUwoIAAAAJ",
      "IfqsDyYAAAAJ",
      "HHn7118AAAAJ",
      "bysr1zQAAAAJ",
      "tzvqRX4AAAAJ",
      "aQsc6KwAAAAJ",
      "5Cm8L90AAAAJ",
      "7o1I4IkAAAAJ",
      "syUpc-gAAAAJ",
      "o-kMCtAAAAAJ",
      "6UYFl7cAAAAJ",
      "euUV4iUAAAAJ",
      "Z9Pfp6UAAAAJ",
      "xk1gsM8AAAAJ",
      "qimMoFIAAAAJ",
      "BkTebL0AAAAJ",
      "a4bPXeYAAAAJ",
      "X0GMj20AAAAJ",
      "Q0piorUAAAAJ",
      "joagTAoAAAAJ",
      "uXoaU1wAAAAJ",
      "PtwDrzEAAAAJ",
      "_2ofK_kAAAAJ",
      "pZhZndYAAAAJ",
      "dw5f9yIAAAAJ",
      "aNFzP50AAAAJ",
      "Ux677B4AAAAJ",
      "yh7H1fIAAAAJ",
      "IgkGxLsAAAAJ",
      "-oESmhEAAAAJ",
      "qrqim7kAAAAJ",
      "_4EISRwAAAAJ",
      "NCCdqdcAAAAJ",
      "fChTW6MAAAAJ",
      "ltj3BwwAAAAJ",
      "4F9L0-cAAAAJ",
      "k3YaoIEAAAAJ",
      "eQujqDgAAAAJ",
      "tgZPkzkAAAAJ",
      "eBXEZxgAAAAJ",
      "J_xhWIQAAAAJ",
      "N9QGV6YAAAAJ",
      "8JGG3KcAAAAJ",
      "724lKQgAAAAJ",
      "Q4j2laYAAAAJ",
      "QWTkjB8AAAAJ",
      "mPabwyYAAAAJ",
      "KWD-mmoAAAAJ",
      "shkKxnQAAAAJ",
      "GbaikvkAAAAJ",
      "-lKb3XwAAAAJ",
      "cTGO2HoAAAAJ",
      "iH9DuY0AAAAJ",
      "YxkMuYsAAAAJ",
      "jTMUPNkAAAAJ",
      "HnQ2gqMAAAAJ",
      "8hU3dn8AAAAJ",
      "Zi5KiDsAAAAJ",
      "MrI1EV4AAAAJ",
      "A5vhsIYAAAAJ",
      "GskOShAAAAAJ",
      "yILa1y0AAAAJ",
      "bGRVPl8AAAAJ",
      "iojF4S0AAAAJ",
      "bMoauM4AAAAJ",
      "IrixA8MAAAAJ",
      "c4FeOJQAAAAJ",
      "xazEr4oAAAAJ",
      "LLkgMYQAAAAJ",
      "kdi99YAAAAAJ",
      "oQnyyGkAAAAJ",
      "4WLoIRsAAAAJ",
      "vIGcvLsAAAAJ",
      "_4dnp0IAAAAJ",
      "rebEn8oAAAAJ",
      "nV-XGVIAAAAJ",
      "Te3H6mMAAAAJ",
      "rtWKzFwAAAAJ",
      "fE4XXdIAAAAJ",
      "-8rxeRIAAAAJ",
      "wotfaAgAAAAJ",
      "tb2aY4kAAAAJ",
      "f1FwzIsAAAAJ",
      "ruZDm9QAAAAJ",
      "ev8Ilx0AAAAJ",
      "oPV20eMAAAAJ",
      "R9L_AfQAAAAJ",
      "p_P5DAcAAAAJ",
      "I1IiJCAAAAAJ",
      "HXfCKiQAAAAJ",
      "55sPPYMAAAAJ",
      "8ipao8MAAAAJ",
      "t4k2EtkAAAAJ",
      "96ciTVoAAAAJ",
      "6dP660cAAAAJ",
      "6GpZV0YAAAAJ",
      "NaThra4AAAAJ",
      "SZ3_FMQAAAAJ",
      "qq4zSmQAAAAJ",
      "BSrwwfYAAAAJ",
      "EEkwehIAAAAJ",
      "_r4LsycAAAAJ",
      "VWX-GMAAAAAJ",
      "UqiD090AAAAJ",
      "s_YDrrgAAAAJ",
      "zK4uegoAAAAJ",
      "zSZt9K0AAAAJ",
      "fDc1X1YAAAAJ",
      "ym8AZSIAAAAJ",
      "OL6EahoAAAAJ",
      "4D2vsdYAAAAJ",
      "DtV6CrMAAAAJ",
      "ZZGpQG4AAAAJ",
      "H4XGkH0AAAAJ",
      "WXV9HW4AAAAJ",
      "_mMeOTgAAAAJ",
      "TJF5CosAAAAJ",
      "OwA3zyMAAAAJ",
      "TFsE4BIAAAAJ",
      "mWBY8aIAAAAJ",
      "vfPE6hgAAAAJ",
      "ceSzF9YAAAAJ",
      "71a2-WMAAAAJ",
      "A8x07E0AAAAJ",
      "a3133-8AAAAJ",
      "k-0MEIMAAAAJ",
      "ViLZaDsAAAAJ",
      "xG9s8HEAAAAJ",
      "Du51uRIAAAAJ",
      "ZTRGztgAAAAJ",
      "bsDeOEoAAAAJ",
      "WwbRKDUAAAAJ",
      "al5P0bAAAAAJ",
      "asj41ygAAAAJ",
      "6iBz3QgAAAAJ",
      "N_jSE08AAAAJ",
      "aaGW2qwAAAAJ",
      "DLVP3PcAAAAJ",
      "TucFZBUAAAAJ",
      "27eupmsAAAAJ",
      "d1WOhpwAAAAJ",
      "1-pt7zMAAAAJ",
      "KJLJstYAAAAJ",
      "CZaDvPgAAAAJ",
      "1IPn2HgAAAAJ",
      "VEfQf5wAAAAJ",
      "9SITlKwAAAAJ",
      "LE3ctn0AAAAJ",
      "ZcPi_0wAAAAJ",
      "aEd4RLgAAAAJ",
      "sFtxaMkAAAAJ",
      "-d6aNP0AAAAJ",
      "cYkxyg0AAAAJ",
      "Z962IGQAAAAJ",
      "6Z-RC-QAAAAJ",
      "t9ahuxsAAAAJ",
      "uYVc9koAAAAJ",
      "1bYESBYAAAAJ",
      "c4mWQPQAAAAJ",
      "edYZTEEAAAAJ",
      "32gDqAYAAAAJ",
      "z9EcgygAAAAJ",
      "LnB5_AcAAAAJ",
      "1lORpNsAAAAJ",
      "vV4K9eYAAAAJ",
      "TW1vSVUAAAAJ",
      "dj4EiqsAAAAJ",
      "jM6Y0yAAAAAJ",
      "t5KSayQAAAAJ",
      "Vd6RW7cAAAAJ",
      "uIBzJWIAAAAJ",
      "jxrHPD4AAAAJ",
      "JmdnBzcAAAAJ",
      "pchPMh0AAAAJ",
      "Ka0xUQ4AAAAJ",
      "6EgqGRwAAAAJ",
      "6zXsZtEAAAAJ",
      "jeb2t4AAAAAJ",
      "0uTu7fYAAAAJ",
      "8gWTOBAAAAAJ",
      "kCy8JG8AAAAJ",
      "EdROb6UAAAAJ",
      "YKRiYRAAAAAJ",
      "CXJuZ5YAAAAJ",
      "lwlYARMAAAAJ",
      "Lyx4TNIAAAAJ",
      "0RAmmIAAAAAJ",
      "KvRjw-4AAAAJ",
      "JDMpCRAAAAAJ",
      "q0kUpsoAAAAJ",
      "HCHLK5wAAAAJ",
      "NDrCCokAAAAJ",
      "gEM0njwAAAAJ",
      "4ZYEiVEAAAAJ",
      "dK2eepUAAAAJ",
      "556SqtcAAAAJ",
      "iTv2cOgAAAAJ",
      "cx4AaqoAAAAJ",
      "6S0sCwgAAAAJ",
      "-DBwBK4AAAAJ",
      "-YvgZDEAAAAJ",
      "nfHyDeUAAAAJ",
      "q4QmSekAAAAJ",
      "3s52I10AAAAJ",
      "RnoIxUwAAAAJ",
      "urTiL7QAAAAJ",
      "j2yC2GQAAAAJ",
      "lXiXiHAAAAAJ",
      "qDsqFkMAAAAJ",
      "IEPhQd4AAAAJ",
      "BSa0rkwAAAAJ",
      "QKhjs2YAAAAJ",
      "1Kr0r4kAAAAJ",
      "LxmQ8eIAAAAJ",
      "3Ee8qHEAAAAJ",
      "XSforroAAAAJ",
      "zrZu6GkAAAAJ",
      "M9oUY4cAAAAJ",
      "u_H-BTQAAAAJ",
      "zS3z8UgAAAAJ",
      "87nZphcAAAAJ",
      "lv9ZeVUAAAAJ",
      "d-jF4zIAAAAJ",
      "hsxzylEAAAAJ",
      "zF5XNJgAAAAJ",
      "hon00PIAAAAJ",
      "fmsV6nEAAAAJ",
      "JnTrJCQAAAAJ",
      "lH1PdF8AAAAJ",
      "LIJQ_ZYAAAAJ",
      "EOyZV8YAAAAJ",
      "d8gdZR4AAAAJ",
      "NYOJzM4AAAAJ",
      "2uJEkY4AAAAJ",
      "-pu6i_4AAAAJ",
      "CfLHDYgAAAAJ",
      "UcuXmuwAAAAJ",
      "2mYxmokAAAAJ",
      "HvwPRJ0AAAAJ",
      "JArbMQcAAAAJ",
      "uemlfQYAAAAJ",
      "xmp9PZoAAAAJ",
      "_S_1cEEAAAAJ",
      "iQx57VIAAAAJ",
      "ePiPQ2cAAAAJ",
      "nQvPeCAAAAAJ",
      "OQfkwykAAAAJ",
      "SpAotDcAAAAJ",
      "E2kpqtkAAAAJ",
      "1U-VMCIAAAAJ",
      "B7ngg6QAAAAJ",
      "ls_kE0UAAAAJ",
      "2O3IZlkAAAAJ",
      "i4_3daEAAAAJ",
      "WNYs930AAAAJ",
      "-1i9yccAAAAJ",
      "pDIuuVwAAAAJ",
      "-WZcuuwAAAAJ",
      "RqwU8xsAAAAJ",
      "vKDycp8AAAAJ",
      "QLjltcIAAAAJ",
      "EyhHDj4AAAAJ",
      "AgyW_90AAAAJ",
      "O3jMNPkAAAAJ",
      "gnlvP_sAAAAJ",
      "cHDBzPcAAAAJ",
      "kc3snaQAAAAJ",
      "IZrh2CkAAAAJ",
      "E3yOuvEAAAAJ",
      "fb-yr1YAAAAJ",
      "ElqwScwAAAAJ",
      "BE7NiFcAAAAJ",
      "EzQdShoAAAAJ",
      "JR7F__MAAAAJ",
      "xuNJ-d8AAAAJ",
      "MlPFWbgAAAAJ",
      "bRuEhB8AAAAJ",
      "s1UQI6kAAAAJ",
      "ZCa4VDcAAAAJ",
      "0L8vKCwAAAAJ",
      "5EMVIoEAAAAJ",
      "Eta6Y-kAAAAJ",
      "_CuXgYIAAAAJ",
      "tWSGUdoAAAAJ",
      "YOb3xH4AAAAJ",
      "kpcjFekAAAAJ",
      "u7oMoQMAAAAJ",
      "Gkc2UeUAAAAJ",
      "pCj-4VAAAAAJ",
      "Clrvw6kAAAAJ",
      "ez_F5gcAAAAJ",
      "4nw0skIAAAAJ",
      "hW-VFhwAAAAJ",
      "TmWYBeEAAAAJ",
      "9sqduWYAAAAJ",
      "a-yq6EAAAAAJ",
      "dXztgDYAAAAJ",
      "YLh7yrwAAAAJ",
      "2TTqpGQAAAAJ",
      "eFxnUw4AAAAJ",
      "fkDxJxcAAAAJ",
      "AOdxmJYAAAAJ",
      "peIOOn8AAAAJ",
      "g7E_CLwAAAAJ",
      "w5T0phcAAAAJ",
      "Yd4KvooAAAAJ",
      "DGr0fVoAAAAJ",
      "xaOPd1YAAAAJ",
      "uhFQ9WgAAAAJ",
      "pihccVkAAAAJ",
      "O4pBP40AAAAJ",
      "rXyRgbcAAAAJ",
      "pfG0_pEAAAAJ",
      "UyKhhwwAAAAJ",
      "fdGXVd4AAAAJ",
      "B1RixPAAAAAJ",
      "gadgSR4AAAAJ",
      "HHwoC2MAAAAJ",
      "e4_ZXcwAAAAJ",
      "fwKsGokAAAAJ",
      "wAaJqPYAAAAJ",
      "kq2kOfEAAAAJ",
      "_k2LvcEAAAAJ",
      "MRkBwCQAAAAJ",
      "-lnWdScAAAAJ",
      "upz0NPIAAAAJ",
      "F3_yOXUAAAAJ",
      "MTmii2YAAAAJ",
      "OsP7JHAAAAAJ",
      "nUlanA8AAAAJ",
      "QPlFU6oAAAAJ",
      "sDiiVkcAAAAJ",
      "yqt5PeEAAAAJ",
      "irNcfEEAAAAJ",
      "KxUFJmoAAAAJ",
      "WL_xXbQAAAAJ",
      "GwKF9rMAAAAJ",
      "SrHIXjEAAAAJ",
      "PjCDBjIAAAAJ",
      "vJJFv3YAAAAJ",
      "0d59fEcAAAAJ",
      "VVIAoY0AAAAJ",
      "H95HfgIAAAAJ",
      "6ENuGyoAAAAJ",
      "0tLCTHYAAAAJ",
      "caPvMq0AAAAJ",
      "niZiN38AAAAJ",
      "M3XQkq4AAAAJ",
      "SjjIQ24AAAAJ",
      "eVYhlDQAAAAJ",
      "p87Sl34AAAAJ",
      "j9ICsOEAAAAJ",
      "1mDpUSgAAAAJ",
      "rCH4toMAAAAJ",
      "bgI5L7oAAAAJ",
      "6ndk_nAAAAAJ",
      "HQCpSJMAAAAJ",
      "_MjXpXkAAAAJ",
      "5na92fcAAAAJ",
      "J-vrZ58AAAAJ",
      "OGYs810AAAAJ",
      "APiItS4AAAAJ",
      "tVS1jp0AAAAJ",
      "k-o3JBIAAAAJ",
      "IH3HEbkAAAAJ",
      "lPh8l7QAAAAJ",
      "cbm9vaUAAAAJ",
      "yKzSdygAAAAJ",
      "wIE1tY4AAAAJ",
      "DRTIzTsAAAAJ",
      "vQwDZR8AAAAJ",
      "gFAjt2kAAAAJ",
      "RUT0Hf8AAAAJ",
      "_VmflIEAAAAJ",
      "E8Jst30AAAAJ",
      "ewdbG-IAAAAJ",
      "vzfO5TwAAAAJ",
      "vrYHLMgAAAAJ",
      "Sr7jln4AAAAJ",
      "2u8jlxgAAAAJ",
      "NW_lLBUAAAAJ",
      "IpmnLFcAAAAJ",
      "UgK1my4AAAAJ",
      "lb1fNb0AAAAJ",
      "LF-IGAEAAAAJ",
      "foERjnQAAAAJ",
      "k3Oh9D0AAAAJ",
      "fu_wsGUAAAAJ",
      "jpIFgToAAAAJ",
      "D9XHjNAAAAAJ",
      "BwjRbkcAAAAJ",
      "04TuVhEAAAAJ",
      "DgCDBbkAAAAJ",
      "sXtjq8IAAAAJ",
      "Ic4pPAYAAAAJ",
      "3-mdTUAAAAAJ",
      "EPLEf60AAAAJ",
      "4C9Bm9YAAAAJ",
      "xUUEAG4AAAAJ",
      "dcVFn08AAAAJ",
      "6ma-nCYAAAAJ",
      "TPhVfX8AAAAJ",
      "j5N3bKYAAAAJ",
      "K_PU9tQAAAAJ",
      "bpDPt1QAAAAJ",
      "CnBvgwcAAAAJ",
      "FwNaHxQAAAAJ",
      "2ABKu2YAAAAJ",
      "9e0uFr4AAAAJ",
      "0lcJYs8AAAAJ",
      "SyACgDAAAAAJ",
      "siiL_PUAAAAJ",
      "zhxqybUAAAAJ",
      "-mEAM68AAAAJ",
      "BBRkKHUAAAAJ",
      "pcWicN8AAAAJ",
      "5Il-agMAAAAJ",
      "R-z1R84AAAAJ",
      "JmiTDLIAAAAJ",
      "HGXVByQAAAAJ",
      "0n-reRcAAAAJ",
      "sm1q2bYAAAAJ",
      "xsaakpMAAAAJ",
      "Pk-959EAAAAJ",
      "lA7ylt4AAAAJ",
      "wjkaNgcAAAAJ",
      "oMLCZ1sAAAAJ",
      "IxeW3gwAAAAJ",
      "uocljD4AAAAJ",
      "bvDRaVcAAAAJ",
      "Jwnl3v0AAAAJ",
      "ChwmtBkAAAAJ",
      "5xL774wAAAAJ",
      "8M-hWKMAAAAJ",
      "mKLoSgMAAAAJ",
      "GPIB5kUAAAAJ",
      "X22nUYgAAAAJ",
      "cEDjw_wAAAAJ",
      "IMYgXsYAAAAJ",
      "zV5vhUcAAAAJ",
      "eALwl74AAAAJ",
      "jn-B_MoAAAAJ",
      "AJKKzMAAAAAJ",
      "n4k9D7QAAAAJ",
      "MavyE28AAAAJ",
      "00RihbwAAAAJ",
      "7wXWIdUAAAAJ",
      "KS4uI1sAAAAJ",
      "0kV69XQAAAAJ",
      "D9LfKkAe7d0C",
      "MSgWKbYAAAAJ",
      "vlN_kRoAAAAJ",
      "JGS2xjkAAAAJ",
      "pamL_rIAAAAJ",
      "oAD8PrkAAAAJ",
      "MmX7K38AAAAJ",
      "HIcgaZEAAAAJ",
      "gHp0pu4AAAAJ",
      "XMKgrt4AAAAJ",
      "IFljhlMAAAAJ",
      "jeOPodEAAAAJ",
      "gznWHL4AAAAJ",
      "Un10q9gAAAAJ",
      "EOzumJIAAAAJ",
      "whB5QDoAAAAJ",
      "Uva82JYAAAAJ",
      "dvQXYW0AAAAJ",
      "krrh6OUAAAAJ",
      "7vLwm84AAAAJ",
      "qoj5YaYAAAAJ",
      "1cdNGL4AAAAJ",
      "htPVdRMAAAAJ",
      "lWadInsAAAAJ",
      "LIjnUGgAAAAJ",
      "rIAYxaMAAAAJ",
      "vEcgp3AAAAAJ",
      "shLVWDYAAAAJ",
      "oLiBK8cAAAAJ",
      "lyh8wacAAAAJ",
      "dSIEUlEAAAAJ",
      "vxQc2L4AAAAJ",
      "0dR_wD0AAAAJ",
      "Ijfl2tkAAAAJ",
      "TlOMKqMAAAAJ",
      "6TOQpT4AAAAJ",
      "DdFjaEEAAAAJ",
      "726MCb8AAAAJ",
      "dcv4kpIAAAAJ",
      "o_ARklQAAAAJ",
      "tiu7twQAAAAJ",
      "3aYVAZEAAAAJ",
      "v474hP4AAAAJ",
      "ld8AkQEAAAAJ",
      "Q2WSQiEAAAAJ",
      "LZxqcX4AAAAJ",
      "I9VWDKcAAAAJ",
      "XCfZyIkAAAAJ",
      "3m1zllIAAAAJ",
      "dkSYtIIAAAAJ",
      "o-5vyEsAAAAJ",
      "2pp8xosAAAAJ",
      "eov2LfUAAAAJ",
      "pjLCdhIAAAAJ",
      "qqgDCDIAAAAJ",
      "QVBIKh4AAAAJ",
      "ifCcZ5IAAAAJ",
      "YoR3IugAAAAJ",
      "GBJLTN8AAAAJ",
      "O_4qYW4AAAAJ",
      "Sb4o_0IAAAAJ",
      "7Z0Z6VsAAAAJ",
      "yHSi7XkAAAAJ",
      "4wSfAIQAAAAJ",
      "9aG3giMAAAAJ",
      "BA1kFjMAAAAJ",
      "_-KE7lIAAAAJ",
      "-p2WHtgAAAAJ",
      "oD1W8a4AAAAJ",
      "d32BmwcAAAAJ",
      "QZCU3NkAAAAJ",
      "044QzjcAAAAJ",
      "10HcE2QAAAAJ",
      "b4MEVXsAAAAJ",
      "k0b8yXkAAAAJ",
      "4kVLYxIAAAAJ",
      "4JsyJK8AAAAJ",
      "P4G6H7oAAAAJ",
      "2efgcS0AAAAJ",
      "-wpZQY0AAAAJ",
      "teiNc0sAAAAJ",
      "vduyqcMAAAAJ",
      "6ReT2voAAAAJ",
      "jGdqlOwAAAAJ",
      "PGFk9ZgAAAAJ",
      "KLFjg9EAAAAJ",
      "3yPEc4YAAAAJ",
      "LYt_4uIAAAAJ",
      "qYcG-q0AAAAJ",
      "gG5PRvgAAAAJ",
      "z0Y4snAAAAAJ",
      "-mHoWKEAAAAJ",
      "pJ28HA0AAAAJ",
      "vpo0U3QAAAAJ",
      "z7WhDRIAAAAJ",
      "M5zMoh4AAAAJ",
      "5wppdUoAAAAJ",
      "ygFAcZwAAAAJ",
      "dLaR9lgAAAAJ",
      "A4xI6moAAAAJ",
      "sljtWIUAAAAJ",
      "stCljMYAAAAJ",
      "EZ4qNDUAAAAJ",
      "y3MnZUEAAAAJ",
      "5VaXUQsAAAAJ",
      "TQgOjK0AAAAJ",
      "lzfVm_8AAAAJ",
      "F_KIfrsAAAAJ",
      "Eclg4mwAAAAJ",
      "shmr0CQAAAAJ",
      "PGcc-RIAAAAJ",
      "kEOeI2gAAAAJ",
      "uwrwLJcAAAAJ",
      "MwLqCs4AAAAJ",
      "2qLY2QwAAAAJ",
      "MD2-gPcAAAAJ",
      "BYrARP4AAAAJ",
      "pEFsZdYAAAAJ",
      "bh08FeIAAAAJ",
      "9B8PoXUAAAAJ",
      "9R7Gl8YAAAAJ",
      "qvRsU00AAAAJ",
      "VeB3UbcAAAAJ",
      "0uCgFkkAAAAJ",
      "KFTttp0AAAAJ",
      "CPMS_csAAAAJ",
      "-Z7fY00AAAAJ",
      "IYPiRoQAAAAJ",
      "JAp-yScAAAAJ",
      "Z2Kn9ucAAAAJ",
      "_K0GfAoAAAAJ",
      "qWak04oAAAAJ",
      "rRcthW0AAAAJ",
      "hbuu7K8AAAAJ",
      "qIPV_KsAAAAJ",
      "f2x233wAAAAJ",
      "bMZFLZ_V4goC",
      "SxP7_woAAAAJ",
      "tAM57M8AAAAJ",
      "7cU2rQsAAAAJ",
      "q1AewNAAAAAJ",
      "m6NDX0IAAAAJ",
      "51ZIHGIAAAAJ",
      "49_cCT8AAAAJ",
      "0-YNNKUAAAAJ",
      "9MSpWOUAAAAJ",
      "HSlEhqwAAAAJ",
      "70LBhKcAAAAJ",
      "kSvJTg4AAAAJ",
      "bV_IUy8AAAAJ",
      "j4XdW_EAAAAJ",
      "x9qzWg8AAAAJ",
      "kzglGGEAAAAJ",
      "qSGlX6UAAAAJ",
      "EqIVfYcAAAAJ",
      "8ablIzIAAAAJ",
      "PgTO8q4AAAAJ",
      "fKBmhcUAAAAJ",
      "8T5VDv8AAAAJ",
      "LDpxmC8AAAAJ",
      "95mnc80AAAAJ",
      "S7DELUgAAAAJ",
      "-qFe-7wAAAAJ",
      "EBNa5IEAAAAJ",
      "-tEiRFcAAAAJ",
      "JrWUvfEAAAAJ",
      "7vCEi-gAAAAJ",
      "fxYQWPAAAAAJ",
      "DsHKK-AAAAAJ",
      "duSEbnYAAAAJ",
      "vPVX4TIAAAAJ",
      "zykJTC4AAAAJ",
      "bhLQ6oQAAAAJ",
      "XizXVNcAAAAJ",
      "NMIU_S4AAAAJ",
      "SUAT64AAAAAJ",
      "kO_RfY4AAAAJ",
      "R_dIcVwAAAAJ",
      "tM4JMcQAAAAJ",
      "RuDNWj8AAAAJ",
      "XeDv_1IAAAAJ",
      "i38QlUwAAAAJ",
      "6G-l4o0AAAAJ",
      "1bF2s2kAAAAJ",
      "RfSQKrIAAAAJ",
      "A4_gQGgAAAAJ",
      "KNr3vb4AAAAJ",
      "Y3eqab0AAAAJ",
      "WjF1dugAAAAJ",
      "J9PoyoIAAAAJ",
      "FcQ1xcwAAAAJ",
      "8EVs9AEAAAAJ",
      "TqDmo1UAAAAJ",
      "f7jdz5IAAAAJ",
      "hGO6cWYAAAAJ",
      "uPkyCmIAAAAJ",
      "twSIZSEAAAAJ",
      "LHvso9QAAAAJ",
      "dEfp5vQAAAAJ",
      "76crpgsAAAAJ",
      "gd23c7MAAAAJ",
      "Gp90OAUAAAAJ",
      "A7gPbV8AAAAJ",
      "2SvHNeQAAAAJ",
      "OKtm7t4AAAAJ",
      "nf_EnbAAAAAJ",
      "BAAZ_ysAAAAJ",
      "KtSR8_0AAAAJ",
      "aXGTpLgAAAAJ",
      "fdkVqrsAAAAJ",
      "LJnNKXMAAAAJ",
      "OGweeKgAAAAJ",
      "PswI6pYAAAAJ",
      "wjjDKWkAAAAJ",
      "DSiNzkIAAAAJ",
      "6m1ptOgAAAAJ",
      "WXbhp_4AAAAJ",
      "9P9QcckAAAAJ",
      "kJPmYCcAAAAJ",
      "9k20Ie4AAAAJ",
      "jN2Y51YAAAAJ",
      "6Wo3XX4AAAAJ",
      "a0wbKRAAAAAJ",
      "EH4ASmUAAAAJ",
      "3JjcAnoAAAAJ",
      "-YmsnYMAAAAJ",
      "lWqzpFkAAAAJ",
      "REGT0fcAAAAJ",
      "jMSF3ukAAAAJ",
      "n-B0jr4AAAAJ",
      "UZ6kI2AAAAAJ",
      "yQ32avUAAAAJ",
      "XKFJHycAAAAJ",
      "oR9sCGYAAAAJ",
      "8VPkPvUAAAAJ",
      "gOTxTaoAAAAJ",
      "yZ5WqE4AAAAJ",
      "LWVqxRUAAAAJ",
      "QGdSgfoAAAAJ",
      "Z-Qe2UUAAAAJ",
      "7b_ipvgAAAAJ",
      "6XorTkcAAAAJ",
      "9dF2BdMAAAAJ",
      "CLgOCOAAAAAJ",
      "Se7mocgAAAAJ",
      "y_wpkH8AAAAJ",
      "WzEQ9QwAAAAJ",
      "pcLld3wAAAAJ",
      "Izhkp4YAAAAJ",
      "L3wy9QMAAAAJ",
      "7peUPbIAAAAJ",
      "BnxU9TEAAAAJ",
      "v1CRzeAAAAAJ",
      "evVAmhQAAAAJ",
      "c9QnkJMAAAAJ",
      "QiJPlOIAAAAJ",
      "6V6u2g0AAAAJ",
      "XDXw3jQAAAAJ",
      "w8ZDbO8AAAAJ",
      "-VjsrR4AAAAJ",
      "IzwvqPIAAAAJ",
      "sUz6qxwAAAAJ",
      "Yy4QD_AAAAAJ",
      "zMoR8AEAAAAJ",
      "hRggMmIAAAAJ",
      "63WN_bEAAAAJ",
      "ify5zKQAAAAJ",
      "cn_FoswAAAAJ",
      "8jydpnYAAAAJ",
      "6bRXWXEAAAAJ",
      "rwBWbFAAAAAJ",
      "VAgdtpoAAAAJ",
      "Zoiu7FsAAAAJ",
      "fqi186AAAAAJ",
      "ShYqyygAAAAJ",
      "3nYG5BMAAAAJ",
      "bAXsp5wAAAAJ",
      "6p-OvCcAAAAJ",
      "jee2Dy0AAAAJ",
      "66qppJsAAAAJ",
      "lmjR_qMAAAAJ",
      "oH1ScJkAAAAJ",
      "LXSkrXkAAAAJ",
      "1FwhEVYAAAAJ",
      "jLraLTcAAAAJ",
      "p3iJiLIAAAAJ",
      "ZZ61SZwAAAAJ",
      "JDErdKcAAAAJ",
      "y0lN_XsAAAAJ",
      "K2INPyYAAAAJ",
      "o9aFV8cAAAAJ",
      "ViYx9vMAAAAJ",
      "W_L_cZsAAAAJ",
      "x63j7HEAAAAJ",
      "bKwkUO4AAAAJ",
      "wOuOYO4AAAAJ",
      "5FrMEXQAAAAJ",
      "S1x_xqcAAAAJ",
      "pw0LluEAAAAJ",
      "rrPyvsgAAAAJ",
      "62RXlNoAAAAJ",
      "5XdNlE8AAAAJ",
      "CROZP6wWEwEC",
      "ZxXBaswAAAAJ",
      "kkP2ICsAAAAJ",
      "BadZJUsAAAAJ",
      "vNAD0mAAAAAJ",
      "am2ohp0AAAAJ",
      "TaJND9YAAAAJ",
      "ki5hheQAAAAJ",
      "TMPlDbsAAAAJ",
      "sTwMEA8AAAAJ",
      "VQYdApgAAAAJ",
      "1n5ZdOAAAAAJ",
      "vFPjMzYAAAAJ",
      "Vu1OqIsAAAAJ",
      "ypBMJMgAAAAJ",
      "eQpLy20AAAAJ",
      "_ryE-48AAAAJ",
      "QNvkEeoAAAAJ",
      "uDG9sXQAAAAJ",
      "EzCLa-4AAAAJ",
      "Ihs8dwsAAAAJ",
      "4rihlSYAAAAJ",
      "nX9D5AoAAAAJ",
      "RRmQyu8AAAAJ",
      "o6m4948AAAAJ",
      "COrJW_gAAAAJ",
      "eFsEy1YAAAAJ",
      "xegzhJcAAAAJ",
      "h0Al1fcAAAAJ",
      "xXJIsh4AAAAJ",
      "vNUpyxYAAAAJ",
      "swP3h24AAAAJ",
      "OXFjRnEAAAAJ",
      "CCToMygAAAAJ",
      "IMkVH_8AAAAJ",
      "VhnTrugAAAAJ",
      "H_e0wfMAAAAJ",
      "lUnt8X4AAAAJ",
      "LCNVGpcAAAAJ",
      "7Hdu5k4AAAAJ",
      "5JtQbw0AAAAJ",
      "0gEOJSEAAAAJ",
      "iKPWydkAAAAJ",
      "KNcECJQAAAAJ",
      "CSJEObYAAAAJ",
      "17fLjgQAAAAJ",
      "ifNxpgkAAAAJ",
      "s3lQL7YAAAAJ",
      "I3mSZFEAAAAJ",
      "dRShpScAAAAJ",
      "bOQGfFIAAAAJ",
      "FijpZG8AAAAJ",
      "7YZ3sCEAAAAJ",
      "T8RB_40AAAAJ",
      "0Bi5CMgAAAAJ",
      "KkVl2qoAAAAJ",
      "M-1wKzIAAAAJ",
      "ZO3Ek1gAAAAJ",
      "X6UshLwAAAAJ",
      "rqUJfaUAAAAJ",
      "5tVuggUAAAAJ",
      "Px3ZQ08AAAAJ",
      "lsYXBx8AAAAJ",
      "GJaAw1EAAAAJ",
      "V4LXxrQAAAAJ",
      "TN-sNaMAAAAJ",
      "_zo4uhoAAAAJ",
      "0na-wa0AAAAJ",
      "pKEjWnsAAAAJ",
      "lS96SqoAAAAJ",
      "Lum6DhoAAAAJ",
      "AxZIIccAAAAJ",
      "Ya3CmFcAAAAJ",
      "TVfLgPAAAAAJ",
      "e_Y58QEAAAAJ",
      "88xDcnoAAAAJ",
      "NmHgX-wAAAAJ",
      "lelCr80AAAAJ",
      "yjPHHb8AAAAJ",
      "OiVCfscAAAAJ",
      "CRnlLm4AAAAJ",
      "q-KRzawAAAAJ",
      "32rbUtYAAAAJ",
      "SYvhSBcAAAAJ",
      "1O3RPmsAAAAJ",
      "wdbul0gAAAAJ",
      "snHVatUAAAAJ",
      "inYyDE4AAAAJ",
      "aXNBOywAAAAJ",
      "uh7PNBoAAAAJ",
      "lEQ3oDAAAAAJ",
      "KsErEBoAAAAJ",
      "WcXt6YQAAAAJ",
      "3yCig6AAAAAJ",
      "FZOxxvcAAAAJ",
      "9UfZJskAAAAJ",
      "LWlN_BUAAAAJ",
      "wlosgkoAAAAJ",
      "HoPI8pIAAAAJ",
      "frSU5j0AAAAJ",
      "nSI1yM0AAAAJ",
      "B2cTx6MAAAAJ",
      "rXpctjYAAAAJ",
      "JBV4oGQAAAAJ",
      "ajIYB6wAAAAJ",
      "5Xz6xycAAAAJ",
      "9hMb_7IAAAAJ",
      "zfTbkBkAAAAJ",
      "9xbbxGcAAAAJ",
      "7mnKGGEAAAAJ",
      "hIETYPwAAAAJ",
      "U9WUBC4AAAAJ",
      "9gO29eUAAAAJ",
      "miPgny8AAAAJ",
      "56UhAooAAAAJ",
      "gZgQLkgAAAAJ",
      "d4yNzXIAAAAJ",
      "3kKjoMEAAAAJ",
      "vWDTlWoAAAAJ",
      "DVuM2KsAAAAJ",
      "xdxuN98AAAAJ",
      "0Wb80ScAAAAJ",
      "XuQW7ogAAAAJ",
      "46EMhJMAAAAJ",
      "mSw8KfIAAAAJ",
      "V7D7hxMAAAAJ",
      "7Ma_PNAAAAAJ",
      "DMsPWz0AAAAJ",
      "O8CIQXcAAAAJ",
      "tzqeiKYAAAAJ",
      "MobIH6EAAAAJ",
      "I6sTssIAAAAJ",
      "mHbdIAwAAAAJ",
      "yvWIqcQAAAAJ",
      "2sKLll8AAAAJ",
      "BHdSb5AAAAAJ",
      "e3hldDEAAAAJ",
      "sVR8ktkAAAAJ",
      "XtSSJm0AAAAJ",
      "im5aMngAAAAJ",
      "v6HphBcAAAAJ",
      "T0yIjk4AAAAJ",
      "gryqnyAAAAAJ",
      "jfy2IG0AAAAJ",
      "rJjcA_YAAAAJ",
      "qnwjcfAAAAAJ",
      "OGEyrG8AAAAJ",
      "CZiW6c8AAAAJ",
      "EWZ9_SAAAAAJ",
      "NAntFXIAAAAJ",
      "llt18PUAAAAJ",
      "4BHeGQMAAAAJ",
      "XKSNP_EAAAAJ",
      "IBlMTLwAAAAJ",
      "ZP6gGZYAAAAJ",
      "dnZ8udEAAAAJ",
      "M2GyttIAAAAJ",
      "8VkvOEEAAAAJ",
      "Iv5WU4UAAAAJ",
      "elEQEEEAAAAJ",
      "ghuIBIYAAAAJ",
      "rs0a3IQAAAAJ",
      "iyDxq0EAAAAJ",
      "J4SmwaQAAAAJ",
      "fm0h6EkAAAAJ",
      "Ae6siZoAAAAJ",
      "xCA8j6oAAAAJ",
      "hepwvtAAAAAJ",
      "LBi1V04AAAAJ",
      "tE1oVQ4AAAAJ",
      "4U1XK1gAAAAJ",
      "AFgYa68AAAAJ",
      "HBjME2gAAAAJ",
      "ns4fY0sAAAAJ",
      "n5ENv9EAAAAJ",
      "Q8cTLNMAAAAJ",
      "WOsQx6EAAAAJ",
      "zBQxZrcAAAAJ",
      "XcRQkcEAAAAJ",
      "oX-nvpwAAAAJ",
      "scJH01QAAAAJ",
      "09_uzi8AAAAJ",
      "XUQcbFAAAAAJ",
      "q-WSy3AAAAAJ",
      "s2lG0X0AAAAJ",
      "23ZXZvEAAAAJ",
      "eYY2nMYAAAAJ",
      "b957ulAAAAAJ",
      "5Ius69wAAAAJ",
      "Qzss0GEAAAAJ",
      "6aZUUEAAAAAJ",
      "EPfOJwQAAAAJ",
      "gxL1qj8AAAAJ",
      "AZboOI8AAAAJ",
      "voqw10cAAAAJ",
      "g3t0ihoAAAAJ",
      "jktWnL8AAAAJ",
      "664NOb0AAAAJ",
      "E_UlAVQAAAAJ",
      "AlIkUSAAAAAJ",
      "oizZKrsAAAAJ",
      "1KRXBIwAAAAJ",
      "4RpscjwAAAAJ",
      "MFVj4n4AAAAJ",
      "iZ5cY0AAAAAJ",
      "igOOdBAAAAAJ",
      "rQTHsloAAAAJ",
      "206DEM0AAAAJ",
      "oWGEj78AAAAJ",
      "kUe1sZEAAAAJ",
      "uqnNle0AAAAJ",
      "zeK3OSYAAAAJ",
      "s_qd9x0AAAAJ",
      "DNQTSwsAAAAJ",
      "GADXPDcAAAAJ",
      "onJXki0AAAAJ",
      "qjnBu0sAAAAJ",
      "NqZETvUAAAAJ",
      "aHa6fz4AAAAJ",
      "KyPheRMAAAAJ",
      "f8RkRagAAAAJ",
      "7bmQ4FgAAAAJ",
      "5_9v0CIAAAAJ",
      "uwadDKYAAAAJ",
      "OB6vAtkAAAAJ",
      "0Fv4bikAAAAJ",
      "n5vSK6YAAAAJ",
      "BXNelwwAAAAJ",
      "VTGXKrYAAAAJ",
      "I-ANa0QAAAAJ",
      "FTYtHb4AAAAJ",
      "BTEsUk8AAAAJ",
      "SFbKPCEAAAAJ",
      "12uhMdIAAAAJ",
      "z7GCqT4AAAAJ",
      "C5IpcRYAAAAJ",
      "NNJzA7MAAAAJ",
      "vnGywSsAAAAJ",
      "1mJtQD0AAAAJ",
      "1-6y9qoAAAAJ",
      "uyYPun0AAAAJ",
      "sYixPw8AAAAJ",
      "-ZpM8jUAAAAJ",
      "ewGrWyQAAAAJ",
      "knut91AAAAAJ",
      "Dq0Fom8AAAAJ",
      "_qr34PIAAAAJ",
      "Z1OtYmAAAAAJ",
      "FoDWxx8AAAAJ",
      "5weaWuMAAAAJ",
      "w4Pqoc0AAAAJ",
      "7rvNQJoAAAAJ",
      "OAtUvx0AAAAJ",
      "R4DiePwAAAAJ",
      "c-cuO9cAAAAJ",
      "-9geUIIAAAAJ",
      "94yn2j0AAAAJ",
      "_QUUb-gAAAAJ",
      "x04W_mMAAAAJ",
      "Sxi1xgkAAAAJ",
      "Nv2jil0AAAAJ",
      "NlA6rBMAAAAJ",
      "NG5jzCkAAAAJ",
      "dTV6Zj4AAAAJ",
      "4S1Ajs8AAAAJ",
      "vh0_vJ4AAAAJ",
      "eaigsKkAAAAJ",
      "9NkngDMAAAAJ",
      "vMW39p0AAAAJ",
      "B8tFrksAAAAJ",
      "ej68QYkAAAAJ",
      "xBv-PMEAAAAJ",
      "oEfBf3sAAAAJ",
      "WNSPregAAAAJ",
      "3F52RjoAAAAJ",
      "XAhGkq8AAAAJ",
      "bWuZUsoAAAAJ",
      "qKz0qpoAAAAJ",
      "VJuuzLwAAAAJ",
      "fzLxuAIAAAAJ",
      "K6-JprYAAAAJ",
      "NZUdzyIAAAAJ",
      "-2qyBJEAAAAJ",
      "AMReihwAAAAJ",
      "KCv6gOQAAAAJ",
      "tQVe-fAAAAAJ",
      "oDE4I64AAAAJ",
      "ZlqnYZoAAAAJ",
      "lrOLKgQAAAAJ",
      "51it_LkAAAAJ",
      "WFgFAB8AAAAJ",
      "5dGWexcAAAAJ",
      "u66VocEAAAAJ",
      "gr_ZVSQAAAAJ",
      "wFLYIm0AAAAJ",
      "l-la0GQAAAAJ",
      "lNkw3QYAAAAJ",
      "5B5rQPkAAAAJ",
      "AEsPCAUAAAAJ",
      "qfbPQ1YAAAAJ",
      "m5v0PNIAAAAJ",
      "GuU6oA4AAAAJ",
      "IRTtnAIAAAAJ",
      "6NFzfAgAAAAJ",
      "eDHv58AAAAAJ",
      "XUsauXIAAAAJ",
      "fAO6gAYAAAAJ",
      "Z4Y5S2oAAAAJ",
      "cTTbBOsAAAAJ",
      "AC93g9kAAAAJ",
      "uqir0mIAAAAJ",
      "uf0D-uoAAAAJ",
      "so6uzIwAAAAJ",
      "G3eFbR0AAAAJ",
      "_rUcw0EAAAAJ",
      "fBXk3G4AAAAJ",
      "UcGN3MoAAAAJ",
      "zuByMYoAAAAJ",
      "7ShMBcwAAAAJ",
      "lVoOIv4AAAAJ",
      "L8ozqB8AAAAJ",
      "2jOYB6oAAAAJ",
      "tflc42wAAAAJ",
      "ebNrBjYAAAAJ",
      "4MkmgXEAAAAJ",
      "FzwrcoYAAAAJ",
      "7R_id0YAAAAJ",
      "upMvIv4AAAAJ",
      "pXzn2akAAAAJ",
      "ExXP2_AAAAAJ",
      "8oW4qk4AAAAJ",
      "9dXN6cMAAAAJ",
      "zGuKpwQAAAAJ",
      "CJwLwzQAAAAJ",
      "Py54GcEAAAAJ",
      "QPH_lRIAAAAJ",
      "zvBNFb0AAAAJ",
      "owKwr1IAAAAJ",
      "SmGQ48gAAAAJ",
      "IUZ-7_cAAAAJ",
      "lPG5fAIAAAAJ",
      "kh8Qe6YAAAAJ",
      "LC0j4ekAAAAJ",
      "zxeEF2gAAAAJ",
      "AbRFE3IAAAAJ",
      "HOj2qUkAAAAJ",
      "TT-8JRsAAAAJ",
      "c5HeXxsAAAAJ",
      "Z2Mhh2UAAAAJ",
      "ivApfKcAAAAJ",
      "25Ha82sAAAAJ",
      "7VAwhzUAAAAJ",
      "5qh5cc0AAAAJ",
      "u9DNHAoAAAAJ",
      "7SdcAiEAAAAJ",
      "zjl9R-oAAAAJ",
      "ykqoK38AAAAJ",
      "ONNif60AAAAJ",
      "Y28Kt7kAAAAJ",
      "MDeIveMAAAAJ",
      "JHJozAYAAAAJ",
      "yv3sH74AAAAJ",
      "AV6nozIAAAAJ",
      "2sjWX1sAAAAJ",
      "syjQhAMAAAAJ",
      "sdENOQ4AAAAJ",
      "-cL9xWMAAAAJ",
      "uHIYS6UAAAAJ",
      "UtmQJt8AAAAJ",
      "cgBDhqwAAAAJ",
      "I_7PXKEAAAAJ",
      "CzOD0S4AAAAJ",
      "EJXN6tYAAAAJ",
      "P0CpOFwAAAAJ",
      "74zyaaYAAAAJ",
      "2fo_v44AAAAJ",
      "kllQz-YAAAAJ",
      "VQ70NaMAAAAJ",
      "ZvLa1RIAAAAJ",
      "Kia-4B0AAAAJ",
      "prEcE9IAAAAJ",
      "qy87mcIAAAAJ",
      "l_G2vr0AAAAJ",
      "fT30bHMAAAAJ",
      "HQbrO2kAAAAJ",
      "_1basdkAAAAJ",
      "MdORQMcAAAAJ",
      "Gua_MdkAAAAJ",
      "NFeigSoAAAAJ",
      "4jViXZgAAAAJ",
      "jNtH2WUAAAAJ",
      "kNH8zcgAAAAJ",
      "6AyF1U8AAAAJ",
      "cOrfSmIAAAAJ",
      "Qwm6ZOYAAAAJ",
      "rzfe-vsAAAAJ",
      "ItkapK8AAAAJ",
      "k8Ovqo8AAAAJ",
      "hacOX_AAAAAJ",
      "jkm1ipUAAAAJ",
      "QAew4J0AAAAJ",
      "dhmdaoQAAAAJ",
      "cxM-P9UAAAAJ",
      "uVsZydYAAAAJ",
      "Zgk0Z6kAAAAJ",
      "eCXP24kAAAAJ",
      "kdqb_j0AAAAJ",
      "lazJixIAAAAJ",
      "QS5CTxcAAAAJ",
      "Q_kKkIUAAAAJ",
      "p_Ua-sIAAAAJ",
      "eBooFDEAAAAJ",
      "uhwGITAAAAAJ",
      "vNZhd_8AAAAJ",
      "ODr5lMgAAAAJ",
      "LwtwtDgAAAAJ",
      "XI5i5AUAAAAJ",
      "6ZDIdEAAAAAJ",
      "1z6dv-MAAAAJ",
      "0rskDKgAAAAJ",
      "HQDpzBoAAAAJ",
      "LBfy6oMAAAAJ",
      "zvz6LIYAAAAJ",
      "agywNwUAAAAJ",
      "rjnJnEkAAAAJ",
      "N_vPIhoAAAAJ",
      "l1taidEAAAAJ",
      "wFgLdqUAAAAJ",
      "5vVjpBsAAAAJ",
      "cOQW8gkAAAAJ",
      "JgqpX0oAAAAJ",
      "oU0jQIAAAAAJ",
      "K931JfEAAAAJ",
      "WUCu45YAAAAJ",
      "p0sQC6sAAAAJ",
      "U89FHq4AAAAJ",
      "KRQ53ysAAAAJ",
      "aMxXkWkAAAAJ",
      "jk7GqOEAAAAJ",
      "sgsLkM0AAAAJ",
      "5zUqCuUAAAAJ",
      "gD640BwAAAAJ",
      "WHTB3_MAAAAJ",
      "yhli360AAAAJ",
      "jeOFRDsAAAAJ",
      "7_JY8gkAAAAJ",
      "AGnp8NAAAAAJ",
      "mG4imMEAAAAJ",
      "HSx0BgQAAAAJ",
      "1c7hIUIAAAAJ",
      "SQpJmOgAAAAJ",
      "UfbuDH8AAAAJ",
      "j-2RtWUAAAAJ",
      "lc0ARagAAAAJ",
      "T7Wa3GQAAAAJ",
      "W1kXLwYAAAAJ",
      "Y4sk3aMAAAAJ",
      "gM7zfrkAAAAJ",
      "c3PYmxUAAAAJ",
      "E__5Lr0AAAAJ",
      "Bgv4hAUAAAAJ",
      "qYhRbJoAAAAJ",
      "VWEg9YQAAAAJ",
      "_flfbOQAAAAJ",
      "iEFL4-YAAAAJ",
      "zPVItDgAAAAJ",
      "rRCnB0wAAAAJ",
      "aMeteU4AAAAJ",
      "VAiqiv4AAAAJ",
      "A6C3geAAAAAJ",
      "K6RYRTMAAAAJ",
      "FsbND-sAAAAJ",
      "MDfW21AAAAAJ",
      "qnxPT9UAAAAJ",
      "4a6iPeUAAAAJ",
      "3dxS1VYAAAAJ",
      "oREmACAAAAAJ",
      "6h7b0fAAAAAJ",
      "w_GMSlcAAAAJ",
      "DHJjPRAAAAAJ",
      "Uod-_B8AAAAJ",
      "TMuSMXoAAAAJ",
      "5NAFTkAAAAAJ",
      "3f6_I8MAAAAJ",
      "QSVAzVIAAAAJ",
      "9-eaUCMAAAAJ",
      "8vjzfWwAAAAJ",
      "qFmoeNkAAAAJ",
      "ZwnVwKMAAAAJ",
      "68hTs9wAAAAJ",
      "FtMADIMAAAAJ",
      "aCFYAEsAAAAJ",
      "apPMLQ4AAAAJ",
      "WFtyBCwAAAAJ",
      "DXsaMGgAAAAJ",
      "zbRUiLgAAAAJ",
      "Pe39BdUAAAAJ",
      "IkEXPUEAAAAJ",
      "0t_4lhMAAAAJ",
      "ID2aN3QAAAAJ",
      "xVN3UxYAAAAJ",
      "Da-s1FQAAAAJ",
      "NyY8ztoAAAAJ",
      "eWRBqsYAAAAJ",
      "LU1OKMoAAAAJ",
      "Y1XuTkUAAAAJ",
      "QYNU5jMAAAAJ",
      "6lyS2T4AAAAJ",
      "LKv32bgAAAAJ",
      "0iFtFKEAAAAJ",
      "Th4PuGkAAAAJ",
      "gOkjmJcAAAAJ",
      "cPmMoXoAAAAJ",
      "nxNkEiYAAAAJ",
      "ZyA-aKQAAAAJ",
      "35zn-2cAAAAJ",
      "38EC20cAAAAJ",
      "DxyeQ5L6RTkJ",
      "BItCgjYAAAAJ",
      "YdLELsMAAAAJ",
      "MxxZkEcAAAAJ",
      "C6UAIHEAAAAJ",
      "Wm0VZrQAAAAJ",
      "G-x_szsAAAAJ",
      "LuA1j4oAAAAJ",
      "4QIV0FUAAAAJ",
      "nN9bxcIAAAAJ",
      "tkDsIggAAAAJ",
      "5X5c8OkAAAAJ",
      "IVpn1mkAAAAJ",
      "17_nX_kAAAAJ",
      "Mux9-okAAAAJ",
      "I8UXifUAAAAJ",
      "6I7jyygAAAAJ",
      "astFxkwAAAAJ",
      "HylrshMAAAAJ",
      "MVanlR8AAAAJ",
      "-CKm5DEAAAAJ",
      "uXUA1pgAAAAJ",
      "SzemdlUAAAAJ",
      "ZdfkFuAAAAAJ",
      "HU1K_zsAAAAJ",
      "1b2kKWoAAAAJ",
      "VFixSK8AAAAJ",
      "7NpTttkAAAAJ",
      "XKCyZk0AAAAJ",
      "Atc5w-4AAAAJ",
      "4uaSNpYAAAAJ",
      "RNj18KkAAAAJ",
      "7i101rcAAAAJ",
      "IvqCXP4AAAAJ",
      "wsNa_W4AAAAJ",
      "GgJdsl4AAAAJ",
      "Ad6O4-0AAAAJ",
      "lO17d-EAAAAJ",
      "OsGAl50AAAAJ",
      "Uhf4nBkAAAAJ",
      "l7Ra9p8AAAAJ",
      "kukA0LcAAAAJ",
      "VLb_0NYAAAAJ",
      "XEztdZgAAAAJ",
      "B7oP0bIAAAAJ",
      "VYiRfCwAAAAJ",
      "QDuPGHwAAAAJ",
      "xGORWi0AAAAJ",
      "Ee4Peu4AAAAJ",
      "AWNL69MAAAAJ",
      "dGPqP-wAAAAJ",
      "IzXDyR8AAAAJ",
      "afp6_lsAAAAJ",
      "UpCGVSAAAAAJ",
      "bLUllHEAAAAJ",
      "e7abmgkAAAAJ",
      "WEQF9DgAAAAJ",
      "CCP2s2cAAAAJ",
      "QgOASJwAAAAJ",
      "l-BJCdAAAAAJ",
      "M6IjHhoAAAAJ",
      "jjXriQwAAAAJ",
      "WvufSLAAAAAJ",
      "picvdvEAAAAJ",
      "iF1M1sIAAAAJ",
      "FX5CsuYAAAAJ",
      "vMOWEMAAAAAJ",
      "dJRKST0AAAAJ",
      "sOrBUWAAAAAJ",
      "7Mxp9d4AAAAJ",
      "1xEHKjoAAAAJ",
      "K3QJPdMAAAAJ",
      "993eudcAAAAJ",
      "5Ysgg7AAAAAJ",
      "C8qMVQUAAAAJ",
      "izgpKaYAAAAJ",
      "Op4nexcAAAAJ",
      "ItxA4esAAAAJ",
      "MkztWIoAAAAJ",
      "uclqBzgAAAAJ",
      "eF34OvgAAAAJ",
      "Um_KuoYAAAAJ",
      "fIEuk78AAAAJ",
      "rqmw-qQAAAAJ",
      "xxjDmR4AAAAJ",
      "EEre0EcAAAAJ",
      "PogsVkYAAAAJ",
      "2DBmo-wAAAAJ",
      "hwm5E4kAAAAJ",
      "QWK6YXUAAAAJ",
      "HqC4vl8AAAAJ",
      "W5bcaXQAAAAJ",
      "cIlDEugAAAAJ",
      "CFIJZwoAAAAJ",
      "yk6C1SgAAAAJ",
      "cjx8PKUAAAAJ",
      "QYsnk-cAAAAJ",
      "rzwHnAcAAAAJ",
      "x4JAvwMAAAAJ",
      "zNOQUvkAAAAJ",
      "8yg53VQAAAAJ",
      "GYdw0McAAAAJ",
      "S47ydIgAAAAJ",
      "iTEcewwAAAAJ",
      "V3NQnJoAAAAJ",
      "jEANvfgAAAAJ",
      "Hx3iRaMAAAAJ",
      "yqIoH34AAAAJ",
      "JTfD4akAAAAJ",
      "jikMhF4AAAAJ",
      "yhJQnxwAAAAJ",
      "WPYCnqIAAAAJ",
      "BitIg-YAAAAJ",
      "bs5MttgAAAAJ",
      "UZNEAF4AAAAJ",
      "BghVDhgAAAAJ",
      "BwaMMgoAAAAJ",
      "0e49RfgAAAAJ",
      "KssJcIAAAAAJ",
      "ElZ0iNkAAAAJ",
      "usd_zgsAAAAJ",
      "TAAQ1LwAAAAJ",
      "zYzAXcYAAAAJ",
      "vLbYPtwAAAAJ",
      "QmYUuCYAAAAJ",
      "KfxoN50AAAAJ",
      "dqVjyRQAAAAJ",
      "zr9B1YgAAAAJ",
      "Bk5q_pAAAAAJ",
      "rD8a4hQAAAAJ",
      "5_l9dl8AAAAJ",
      "zFsdqo8AAAAJ",
      "VBouyX8AAAAJ",
      "8mA9QpUAAAAJ",
      "vfa1cToAAAAJ",
      "ct4ViZMAAAAJ",
      "6jv2-OYAAAAJ",
      "7JNUMRAAAAAJ",
      "Y_Nmd2sAAAAJ",
      "sQJvy4MAAAAJ",
      "PS-TM94AAAAJ",
      "50baXGgAAAAJ",
      "wm2BrUcAAAAJ",
      "FY_UnPAAAAAJ",
      "Xy8kb5gAAAAJ",
      "_ambxJIAAAAJ",
      "2dvDXjkAAAAJ",
      "WHZiLTIAAAAJ",
      "wxnzyjwAAAAJ",
      "tjT7-uAAAAAJ",
      "Z8I-ydAAAAAJ",
      "6QrCoOoAAAAJ",
      "eAwnN44AAAAJ",
      "pk5cKBUAAAAJ",
      "i2OF1rkAAAAJ",
      "PUz8SCQAAAAJ",
      "_N7091oAAAAJ",
      "ONuIPv0AAAAJ",
      "EYtt2uQAAAAJ",
      "dvoF5_cAAAAJ",
      "UhmcQ7gAAAAJ",
      "57UxFrwAAAAJ",
      "IR0yJB8AAAAJ",
      "tEGxO60AAAAJ",
      "xksqo5gAAAAJ",
      "VVz2wdwAAAAJ",
      "wjRRS3YAAAAJ",
      "F2SAhnQAAAAJ",
      "PtBtfawAAAAJ",
      "FMTai3oAAAAJ",
      "ClSXZ4IAAAAJ",
      "Oo3fRbcAAAAJ",
      "dX4x9z4AAAAJ",
      "I9Db408AAAAJ",
      "68eoKg4AAAAJ",
      "awvsNQYAAAAJ",
      "7BHxn_4AAAAJ",
      "7m2X0GoAAAAJ",
      "SIayDoQAAAAJ",
      "lIKPJ04AAAAJ",
      "CaHuRsgAAAAJ",
      "n1e6LlcAAAAJ",
      "rXYLXJMAAAAJ",
      "SNTbGfIAAAAJ",
      "npq3yLIAAAAJ",
      "R7_-IjUAAAAJ",
      "Craj5M0AAAAJ",
      "OXZC0mQAAAAJ",
      "2uwoiuIAAAAJ",
      "7k_1QFIAAAAJ",
      "07ds-DAAAAAJ",
      "VxAuxMwAAAAJ",
      "Fc-5yRIAAAAJ",
      "RhUcYmQAAAAJ",
      "quJME0oAAAAJ",
      "rRJ9wTJMUB8C",
      "oGqXzKAAAAAJ",
      "Q8iay0gAAAAJ",
      "pVnRW0YAAAAJ",
      "KMcwQtcAAAAJ",
      "Go5BcawAAAAJ",
      "hfqXASoAAAAJ",
      "1F1k4AUAAAAJ",
      "YxBqNw8AAAAJ",
      "W4oOmZEAAAAJ",
      "ghbWy-0AAAAJ",
      "gNMqz_4AAAAJ",
      "yStEfeIAAAAJ",
      "Z6gnDIEAAAAJ",
      "BOAOkNQAAAAJ",
      "e9gUdKwAAAAJ",
      "KGvc3jwAAAAJ",
      "AG51Bv4AAAAJ",
      "4V1nNm4AAAAJ",
      "iH2BZ8UAAAAJ",
      "fzRnjFgAAAAJ",
      "GL9M37YAAAAJ",
      "zzG75zEAAAAJ",
      "2TUruWMAAAAJ",
      "fKESO6sAAAAJ",
      "ZOkQ-PoAAAAJ",
      "NsuX8R8AAAAJ",
      "dEbld0EAAAAJ",
      "k5HsbdcAAAAJ",
      "FehGbqYAAAAJ",
      "1E7m_VsAAAAJ",
      "9jmmp5sAAAAJ",
      "ybjd-fgAAAAJ",
      "GXRermIAAAAJ",
      "s_atrm8AAAAJ",
      "397EbTsAAAAJ",
      "OZ2MxEYAAAAJ",
      "n82TkYwAAAAJ",
      "fQVZ28cAAAAJ",
      "GwGsvm0AAAAJ",
      "ITZ1e7MAAAAJ",
      "VO4oS8UAAAAJ",
      "w0Vl_lsAAAAJ",
      "_bKTUqAAAAAJ",
      "NSWI3OwAAAAJ",
      "GRMMc_MAAAAJ",
      "YCO3WQsAAAAJ",
      "AxFrw0sAAAAJ",
      "wsGvgA8AAAAJ",
      "qmnmdYsAAAAJ",
      "_N44XxAAAAAJ",
      "VFXKWYYAAAAJ",
      "X9AjIugAAAAJ",
      "qB0jk_EAAAAJ",
      "qbTyWP4AAAAJ",
      "jVrqxkYAAAAJ",
      "SQzKCuUAAAAJ",
      "5JserkUAAAAJ",
      "I9r2zF0AAAAJ",
      "-o8kQPwAAAAJ",
      "Y_XwzKQAAAAJ",
      "Q5CBlNcAAAAJ",
      "0h0oV7oAAAAJ",
      "BrWvx00AAAAJ",
      "cLGOIdMAAAAJ",
      "6wwWRdEAAAAJ",
      "8f9jTNcAAAAJ",
      "vIewY1EAAAAJ",
      "dNOBQ1sAAAAJ",
      "YHSRCCsAAAAJ",
      "04TxLAIAAAAJ",
      "9_QWXrsAAAAJ",
      "70lgwYwAAAAJ",
      "3RuMCpcAAAAJ",
      "TqjSyUgAAAAJ",
      "DRA4zoUAAAAJ",
      "vN-is70AAAAJ",
      "F_Go4V4AAAAJ",
      "NLxrmYQAAAAJ",
      "IB_jPZ0AAAAJ",
      "p-PdgdYAAAAJ",
      "yZbch0cAAAAJ",
      "SJctjYgAAAAJ",
      "0OsAngEAAAAJ",
      "7k2LuTkAAAAJ",
      "hqTu-QcAAAAJ",
      "yDXNzfIAAAAJ",
      "uv7g5kMAAAAJ",
      "4WVI4SYAAAAJ",
      "K2hRQgUAAAAJ",
      "PvoHev4AAAAJ",
      "PYtPCHoAAAAJ",
      "TZ9DF0kAAAAJ",
      "qiFEpzIAAAAJ",
      "T4WYN6YAAAAJ",
      "x-G741IAAAAJ",
      "SgNB-ioAAAAJ",
      "3mQFWSYAAAAJ",
      "wTCe1mUAAAAJ",
      "oe3NRPQAAAAJ",
      "6CAfoBgAAAAJ",
      "t_iLVOoAAAAJ",
      "3PuVdYEAAAAJ",
      "MpJ00PUAAAAJ",
      "UmwJklEAAAAJ",
      "3G2EbP4AAAAJ",
      "W8yZCNsAAAAJ",
      "M3BSiiQAAAAJ",
      "aka4LuAAAAAJ",
      "RivxoIcAAAAJ",
      "IjXnDdoAAAAJ",
      "h1VSH6UAAAAJ",
      "vP2to0MAAAAJ",
      "QzqctJgAAAAJ",
      "P0iOgxMAAAAJ",
      "KJoJ8nMAAAAJ",
      "AbyxansAAAAJ",
      "GMVxiYgAAAAJ",
      "Hanjxs8AAAAJ",
      "n1zDCkQAAAAJ",
      "kPxa2w0AAAAJ",
      "qS_ugJAAAAAJ",
      "5O7jjVgAAAAJ",
      "yKGD9ggAAAAJ",
      "3A06cR4AAAAJ",
      "WnFB4iEAAAAJ",
      "ss-IvjMAAAAJ",
      "FmZaK1wAAAAJ",
      "ijmuZ0wAAAAJ",
      "JQcDmB8AAAAJ",
      "O_7MVDIAAAAJ",
      "l0CjtK4AAAAJ",
      "9KRcr3QAAAAJ",
      "vbhA9hwAAAAJ",
      "DZ3S--MAAAAJ",
      "urhvgT0AAAAJ",
      "MnfzuPYAAAAJ",
      "ZQFp_3MAAAAJ",
      "pEKw_vtA1pcC",
      "i0OY_LAAAAAJ",
      "ZlSVieAAAAAJ",
      "LNJMblcAAAAJ",
      "EHSuFcwAAAAJ",
      "nfX25MMAAAAJ",
      "XSgTV7gAAAAJ",
      "htt9T1AAAAAJ",
      "R_bC8bkAAAAJ",
      "a2PXepkAAAAJ",
      "JFEHAwIAAAAJ",
      "Sh1yq5QAAAAJ",
      "lD5J91cAAAAJ",
      "1YEoqJsAAAAJ",
      "3oUgDKQAAAAJ",
      "KoJrMIAAAAAJ",
      "iF01q24AAAAJ",
      "pzQgnrkAAAAJ",
      "W7uYg0UAAAAJ",
      "uaiskTYAAAAJ",
      "0zX2pcwAAAAJ",
      "l8wQ39EAAAAJ",
      "7oD5x5oAAAAJ",
      "ZGpE5cYAAAAJ",
      "Fe-VhGoAAAAJ",
      "mOG0bwsAAAAJ",
      "md3U-GEAAAAJ",
      "hmoy8ssAAAAJ",
      "RryVaLgAAAAJ",
      "LWw60SgAAAAJ",
      "jxBZFwQAAAAJ",
      "43nqWTUAAAAJ",
      "mdPnGScAAAAJ",
      "i5U_SqgAAAAJ",
      "b55hlmIAAAAJ",
      "51I5vxkAAAAJ",
      "1UWlwuEAAAAJ",
      "U_L2uiwAAAAJ",
      "O1LZbI4AAAAJ",
      "crlzbrMAAAAJ",
      "fJQZVyAAAAAJ",
      "CkfQy2gAAAAJ",
      "Pskjj5AAAAAJ",
      "1UU7Rh8AAAAJ",
      "pHblCTAAAAAJ",
      "AIk5YHsAAAAJ",
      "2wG4enAAAAAJ",
      "xqhwEGIAAAAJ",
      "UcWOl8YAAAAJ",
      "ZMLhZJ8AAAAJ",
      "bG5-ZzIAAAAJ",
      "L6xKfHkAAAAJ",
      "22TE5qkAAAAJ",
      "0fJXXaMAAAAJ",
      "h7OHSkoAAAAJ",
      "k2FuJZAAAAAJ",
      "uU2UhGIAAAAJ",
      "0ZsqI4kAAAAJ",
      "M6-o86kAAAAJ",
      "9H75c04AAAAJ",
      "LMtE3FQAAAAJ",
      "iAHjMzQAAAAJ",
      "ZWV0I7cAAAAJ",
      "OqbV4dwAAAAJ",
      "0zZnyMEAAAAJ",
      "7qufP-8AAAAJ",
      "jCNJhFcAAAAJ",
      "MbBntPgAAAAJ",
      "V3kGMXUAAAAJ",
      "KLSUWBAAAAAJ",
      "qvK1_5wAAAAJ",
      "zMH25DoAAAAJ",
      "0kVh58wAAAAJ",
      "Rn_BmTYAAAAJ",
      "O8ALPlkAAAAJ",
      "NiR8zKAAAAAJ",
      "7V7yNeoAAAAJ",
      "GmtZ_jYAAAAJ",
      "bHM8zJkAAAAJ",
      "C_r8d0AAAAAJ",
      "9HiV_AEAAAAJ",
      "ydA8Q5AAAAAJ",
      "t1rjgHgAAAAJ",
      "YYH0BjEAAAAJ",
      "-7oupLAAAAAJ",
      "A3Fw5yMAAAAJ",
      "JrBgRKUAAAAJ",
      "chICXXMAAAAJ",
      "pOd2M64AAAAJ",
      "7620QAMAAAAJ",
      "jyxO2akAAAAJ",
      "LCjW058AAAAJ",
      "rh0ubaUAAAAJ",
      "bzsYmwYAAAAJ",
      "Op-47sgAAAAJ",
      "ww-6D6wAAAAJ",
      "A8h9enQAAAAJ",
      "TLQUwIMAAAAJ",
      "iJENOG8AAAAJ",
      "KlhDpG0AAAAJ",
      "UeltiQ4AAAAJ",
      "O5J1hyMAAAAJ",
      "NmJcIeEAAAAJ",
      "5-pEIw0AAAAJ",
      "WhFGh74AAAAJ",
      "_SVdR44AAAAJ",
      "EMq6KwMAAAAJ",
      "q-O4OlYAAAAJ",
      "-gFCCLMAAAAJ",
      "FiETqWQAAAAJ",
      "hdTDzlQAAAAJ",
      "X1N99wsAAAAJ",
      "9r6119kAAAAJ",
      "FiXHXwgAAAAJ",
      "Lpc8gO4AAAAJ",
      "wsYTsIsAAAAJ",
      "M7EpKqsAAAAJ",
      "ejoWKqsAAAAJ",
      "v8JEPFgAAAAJ",
      "CcqZZqMAAAAJ",
      "4oXBp9UAAAAJ",
      "ELglt8UAAAAJ",
      "eXnKggEAAAAJ",
      "s_3ZE8kAAAAJ",
      "k6-1woQAAAAJ",
      "YVfr3wwAAAAJ",
      "Tiq0XaMAAAAJ",
      "DUNGEAIAAAAJ",
      "I58-jXkAAAAJ",
      "zkc9pukAAAAJ",
      "CLZ9dLoAAAAJ",
      "RNC-GC0AAAAJ",
      "JM9-OOsAAAAJ",
      "HF-1DDwAAAAJ",
      "X4k8oLAAAAAJ",
      "Y-6riI4AAAAJ",
      "E7bRAPkAAAAJ",
      "AH6MwzwAAAAJ",
      "jJfKig8AAAAJ",
      "ZfUyYtEAAAAJ",
      "l9iNFaMAAAAJ",
      "pTEtZCYAAAAJ",
      "175Mu2wAAAAJ",
      "BKfjTj4AAAAJ",
      "rPCzqN4AAAAJ",
      "_e5H8IoAAAAJ",
      "dHDJlo0AAAAJ",
      "RhFhIIgAAAAJ",
      "9cFCY5wAAAAJ",
      "V3rP49wAAAAJ",
      "ECHSnpYAAAAJ",
      "84FUioAAAAAJ",
      "IUqydU0AAAAJ",
      "eghKB-0AAAAJ",
      "vJxuKwgAAAAJ",
      "d3MKMggAAAAJ",
      "SEMSJmcAAAAJ",
      "jkwHy3AAAAAJ",
      "-OGSuAkAAAAJ",
      "7zk-lgMAAAAJ",
      "A_UWzl8AAAAJ",
      "9aFd9dEAAAAJ",
      "ppZN58sAAAAJ",
      "T5DyrYUAAAAJ",
      "l2RQ_S8AAAAJ",
      "IhZxOR4AAAAJ",
      "aM3i_9oAAAAJ",
      "y-RSDYYAAAAJ",
      "SKXmmxIAAAAJ",
      "u0561GMAAAAJ",
      "ft85d8kAAAAJ",
      "cDduRqwAAAAJ",
      "rYFeExcAAAAJ",
      "ljAjAcAAAAAJ",
      "zj6FavAAAAAJ",
      "t-VqN7sAAAAJ",
      "bM4pEGoAAAAJ",
      "8IH6kXQAAAAJ",
      "fz1mq4AAAAAJ",
      "lJbBWhMAAAAJ",
      "Zqz4CQoAAAAJ",
      "eGgZmPgAAAAJ",
      "t3COq84AAAAJ",
      "sp2np4oAAAAJ",
      "czxMUzcAAAAJ",
      "5222Mu8AAAAJ",
      "xrSUChoAAAAJ",
      "NnEMWJsAAAAJ",
      "McgMhW0AAAAJ",
      "8GxAlSUAAAAJ",
      "wmZTE5gAAAAJ",
      "btHLQeQAAAAJ",
      "VghIYWEAAAAJ",
      "MA7j1gkAAAAJ",
      "tf1c4_kAAAAJ",
      "_Pvgwd0AAAAJ",
      "O24CcQQAAAAJ",
      "3srp-NYAAAAJ",
      "5hJNWakAAAAJ",
      "8Ir1WvIAAAAJ",
      "zhQaFaMAAAAJ",
      "dthSEsoAAAAJ",
      "eFVB3ksAAAAJ",
      "a_M5FlgAAAAJ",
      "ZBc_WwYAAAAJ",
      "ZcWO2AEAAAAJ",
      "8vMAKiwAAAAJ",
      "KmHKvzsAAAAJ",
      "qR1zQHQAAAAJ",
      "29B3BAgAAAAJ",
      "c-ZZKpAAAAAJ",
      "WOAlvmoAAAAJ",
      "r5WezOYAAAAJ",
      "6MpBAH4AAAAJ",
      "jInmtEkAAAAJ",
      "CG9yOXoAAAAJ",
      "PeMuphgAAAAJ",
      "1ctl60EAAAAJ",
      "SotYphoAAAAJ",
      "iopH6wIAAAAJ",
      "DGb-sBwAAAAJ",
      "rxxutcgAAAAJ",
      "ZPqZhnAAAAAJ",
      "ahFqdRUAAAAJ",
      "MN9Kfg8AAAAJ",
      "jn5r6TsAAAAJ",
      "R-Cgh08AAAAJ",
      "8TArOy0AAAAJ",
      "1H9CkZgAAAAJ",
      "qzLr75IAAAAJ",
      "xYfYnG4AAAAJ",
      "zjsSMfIAAAAJ",
      "JSkBINwAAAAJ",
      "gWBoNCsAAAAJ",
      "Z7d93ZYAAAAJ",
      "iWq6Tn4AAAAJ",
      "DTNZMGAAAAAJ",
      "74w7FDUAAAAJ",
      "EjG2e0QAAAAJ",
      "aH8AJu4AAAAJ",
      "0v5utcwAAAAJ",
      "OvAOTFkAAAAJ",
      "SvRU8F8AAAAJ",
      "DwHtHE8AAAAJ",
      "t1UaPDgAAAAJ",
      "E3wyDhUAAAAJ",
      "RtNVud4AAAAJ",
      "Mz1fab8AAAAJ",
      "YNGHCrAAAAAJ",
      "wXIOwRoAAAAJ",
      "ffdt7gMAAAAJ",
      "LGx06n8AAAAJ",
      "yV03lm0AAAAJ",
      "9xLaU5MAAAAJ",
      "uX9yGmAAAAAJ",
      "QUmyfogAAAAJ",
      "xX_de_YAAAAJ",
      "huV-_rsAAAAJ",
      "rjfj_8AAAAAJ",
      "Olj9jQgAAAAJ",
      "AUJuK3AAAAAJ",
      "0W9XZ0cAAAAJ",
      "aGpw2rYAAAAJ",
      "mXwpea4AAAAJ",
      "kW-hl3YAAAAJ",
      "XCkp5uEAAAAJ",
      "CM4o-cgAAAAJ",
      "PGodeKsAAAAJ",
      "Pb74Fg4AAAAJ",
      "NYgWyv0AAAAJ",
      "QpmcFjoAAAAJ",
      "nfLC9S0AAAAJ",
      "1OwERREAAAAJ",
      "8O3h4_cAAAAJ",
      "hTxCe4oAAAAJ",
      "4peEKXMAAAAJ",
      "hX0YYUoAAAAJ",
      "OUXS8doAAAAJ",
      "Fl7EBc8AAAAJ",
      "QSTd1oUAAAAJ",
      "l53UPjoAAAAJ",
      "3-lTFAwAAAAJ",
      "jr7gGB4AAAAJ",
      "5kvESDsAAAAJ",
      "uwzBnJwAAAAJ",
      "nsuJs6QAAAAJ",
      "kxqgE9cAAAAJ",
      "05sMX8MAAAAJ",
      "ikn-xhYAAAAJ",
      "T9To2C0AAAAJ",
      "wE5ee_kAAAAJ",
      "r1L_2qkAAAAJ",
      "xGGUwFsAAAAJ",
      "67kghxAAAAAJ",
      "WCqe8yUAAAAJ",
      "GbBRH4EAAAAJ",
      "EguGynAAAAAJ",
      "hFjNgPEAAAAJ",
      "KTYQRzYAAAAJ",
      "8NoMRR0AAAAJ",
      "zZO9qG4AAAAJ",
      "LXu_gVkAAAAJ",
      "m1wGy3gAAAAJ",
      "Td3_kIwAAAAJ",
      "Ca2lQs8AAAAJ",
      "eRcqOkcAAAAJ",
      "XQJN7dsAAAAJ",
      "SWVeT4AAAAAJ",
      "B3C4aY8AAAAJ",
      "UmyrEtcAAAAJ",
      "CYMAfxsAAAAJ",
      "rVsGTeEAAAAJ",
      "tYro5N8AAAAJ",
      "rJotb-YAAAAJ",
      "pdvYP-kAAAAJ",
      "VSsTq14AAAAJ",
      "T94KevkAAAAJ",
      "akrkYU0AAAAJ",
      "8l-mDfQAAAAJ",
      "K757SxgAAAAJ",
      "QRYX59sAAAAJ",
      "MrOv72wAAAAJ",
      "kf8nxJ8AAAAJ",
      "HzfkQy4AAAAJ",
      "36NmvrMAAAAJ",
      "sgva3HcAAAAJ",
      "mDNhPjAAAAAJ",
      "YG6mTEIAAAAJ",
      "lE68S9wAAAAJ",
      "j0_aKI0AAAAJ",
      "Gzo8z-kAAAAJ",
      "yCaVmHIAAAAJ",
      "0IBt8msAAAAJ",
      "q77J4fgAAAAJ",
      "QJ9ThJ0AAAAJ",
      "UphI-hIAAAAJ",
      "CffJDoEAAAAJ",
      "M_NWm1wAAAAJ",
      "uG6vN6QAAAAJ",
      "Ry3K3AMAAAAJ",
      "SZ_vC90AAAAJ",
      "JtHZL24AAAAJ",
      "lXYKgiYAAAAJ",
      "-5_ksIkAAAAJ",
      "Ci-_QYIAAAAJ",
      "J2Z-ChoAAAAJ",
      "kokpiBQAAAAJ",
      "ze5rCdwAAAAJ",
      "8RtQzSQAAAAJ",
      "aPqcyU4AAAAJ",
      "sybphw0AAAAJ",
      "ixBXGEYAAAAJ",
      "q9zQhj8AAAAJ",
      "ZQs5JAIAAAAJ",
      "6-ojl1EAAAAJ",
      "KvX7mJUAAAAJ",
      "_rJCgzIAAAAJ",
      "Rd18rbYAAAAJ",
      "NmP-rOAAAAAJ",
      "gXFy11EAAAAJ",
      "ZpWzifcAAAAJ",
      "nR8UJ3cAAAAJ",
      "0RiypNsAAAAJ",
      "E2z5uYsAAAAJ",
      "0I2qH0oAAAAJ",
      "zqUO0GMAAAAJ",
      "Iz3m3v4AAAAJ",
      "AScNRHUAAAAJ",
      "RfQ6JRcAAAAJ",
      "6U_O28IAAAAJ",
      "hzOgd9MAAAAJ",
      "ribzpr4AAAAJ",
      "Sbpra_AAAAAJ",
      "2YYsi40AAAAJ",
      "RkddXygAAAAJ",
      "uyCsSAEAAAAJ",
      "SXHb84wAAAAJ",
      "SWMKy70AAAAJ",
      "Br8UEzAAAAAJ",
      "cGgZI40AAAAJ",
      "4wcx4HMAAAAJ",
      "twvDiW8AAAAJ",
      "Nmz0IzcAAAAJ",
      "CEt6_mMAAAAJ",
      "hv1LiiEAAAAJ",
      "sR_OzkgAAAAJ",
      "-9ifK0cAAAAJ",
      "qbzezVEAAAAJ",
      "Du5t4FYAAAAJ",
      "MbF6rTEAAAAJ",
      "eQGpfS8AAAAJ",
      "vC8DssQAAAAJ",
      "aCLdkF4AAAAJ",
      "ss7CIgcAAAAJ",
      "xblGvQgAAAAJ",
      "3D-xyjwAAAAJ",
      "7OW6weoAAAAJ",
      "JS72sbsAAAAJ",
      "NfyVi8AAAAAJ",
      "MS1P6hcAAAAJ",
      "ggAIHowAAAAJ",
      "wVazIm8AAAAJ",
      "5V852JcAAAAJ",
      "BO_b2O8AAAAJ",
      "JbhCpzkAAAAJ",
      "7PerW6IAAAAJ",
      "zLjnC5MAAAAJ",
      "XpO6-kEAAAAJ",
      "UbtCA90AAAAJ",
      "3WEijrIAAAAJ",
      "-6ws0MoAAAAJ",
      "CUD7V78AAAAJ",
      "H4rKFc8AAAAJ",
      "GoR_32IAAAAJ",
      "-ndXYyoAAAAJ",
      "MOfaB6oAAAAJ",
      "uND_5REAAAAJ",
      "6qE0tdAAAAAJ",
      "oOwNKsAAAAAJ",
      "XDsMg4YAAAAJ",
      "-sMCAGcAAAAJ",
      "D-CVv_QAAAAJ",
      "yehGhR8AAAAJ",
      "vRI2blsAAAAJ",
      "YuOHpwUAAAAJ",
      "DxQiCiIAAAAJ",
      "SssrcUsAAAAJ",
      "5PBPqeQAAAAJ",
      "DSgKHOQAAAAJ",
      "XY2YaEkAAAAJ",
      "ISomHK0AAAAJ",
      "dM1jSoEAAAAJ",
      "F4JYGjcAAAAJ",
      "xBRQVAcAAAAJ",
      "rGF6-WkAAAAJ",
      "6dr5fLEAAAAJ",
      "xmUDkvQAAAAJ",
      "Wy89g4IAAAAJ",
      "3Br8x_gAAAAJ",
      "wAxr6b8AAAAJ",
      "YLOz1kgAAAAJ",
      "GfcBlpUAAAAJ",
      "mAo_lUwAAAAJ",
      "fpUICd0AAAAJ",
      "5lFDxsMAAAAJ",
      "m0rXqhkAAAAJ",
      "vtxXpVAAAAAJ",
      "E275ukwAAAAJ",
      "wCZbouUAAAAJ",
      "woqUivYAAAAJ",
      "AQcftaEAAAAJ",
      "-S_9ZRcAAAAJ",
      "XEx1fZkAAAAJ",
      "gmI1-UIAAAAJ",
      "l92sxGEAAAAJ",
      "YHmzvmMAAAAJ",
      "4Ma6NAYAAAAJ",
      "4806CYgAAAAJ",
      "IwGLficAAAAJ",
      "oO9-6xEAAAAJ",
      "LNUeOu4AAAAJ",
      "KH3jpkoAAAAJ",
      "P_q1TRgAAAAJ",
      "cCXHHSkAAAAJ",
      "ofcrge8AAAAJ",
      "OpXMNnMAAAAJ",
      "Nn990CkAAAAJ",
      "oBu8kMMAAAAJ",
      "QGU5FrIAAAAJ",
      "A6yjdJAAAAAJ",
      "71IXR1QAAAAJ",
      "e-GEqxoAAAAJ",
      "okf5bmQAAAAJ",
      "VjNg25EAAAAJ",
      "JYaJjE8AAAAJ",
      "2StUgf4AAAAJ",
      "9R-3nvsAAAAJ",
      "Vy16O5UAAAAJ",
      "cNLW5O4AAAAJ",
      "SUNF5HMAAAAJ",
      "sUK_w2QAAAAJ",
      "sb3lPX8AAAAJ",
      "pFlJsUEAAAAJ",
      "cbQB0MMAAAAJ",
      "kTKmpT0AAAAJ",
      "CZ3EC4AAAAAJ",
      "WAleKq0AAAAJ",
      "N_8WC5oAAAAJ",
      "Odh4GSYAAAAJ",
      "RsZBRBQAAAAJ",
      "uDZcR0IAAAAJ",
      "DIBOO50AAAAJ",
      "e5fFIDkAAAAJ",
      "vYougn0AAAAJ",
      "UJcBAgkAAAAJ",
      "HosA8_UAAAAJ",
      "G43gXjIAAAAJ",
      "zr22WkQAAAAJ",
      "JjID4s0AAAAJ",
      "HOngPZAAAAAJ",
      "Pczk-PQAAAAJ",
      "IlgMpNoAAAAJ",
      "xuLKJboAAAAJ",
      "ARmv8N4AAAAJ",
      "6jN5vScAAAAJ",
      "0J0n7sEAAAAJ",
      "gypv57sAAAAJ",
      "k0vrm6kAAAAJ",
      "jFekO3IAAAAJ",
      "JeLy9lMAAAAJ",
      "j1zLfKwAAAAJ",
      "GhPDR9AAAAAJ",
      "IOrQrZcAAAAJ",
      "bOnw_44AAAAJ",
      "6F3ZIeEAAAAJ",
      "VGr54BoAAAAJ",
      "1ViBXywAAAAJ",
      "QOLH_TwAAAAJ",
      "Nuw1Y4oAAAAJ",
      "kzYoaFYAAAAJ",
      "9kzHZssAAAAJ",
      "hon4EsIAAAAJ",
      "AhgjQ2QAAAAJ",
      "j9jEMToAAAAJ",
      "PSh16LsAAAAJ",
      "xsmFT2UAAAAJ",
      "iBeDoRAAAAAJ",
      "LjxqXycAAAAJ",
      "N-gKE0oAAAAJ",
      "qqbRBXEAAAAJ",
      "IQosWycAAAAJ",
      "o29n55IAAAAJ",
      "BFE6IQwAAAAJ",
      "AScYAMYAAAAJ",
      "mm-fpzQAAAAJ",
      "_gH7-4wAAAAJ",
      "wmjk13MAAAAJ",
      "yBl_j4gAAAAJ",
      "qU9WvTgAAAAJ",
      "LjsKfKYAAAAJ",
      "9IWk2PMAAAAJ",
      "YPq3ax4AAAAJ",
      "DL6Gk3AAAAAJ",
      "HhValEMAAAAJ",
      "-ViviVsAAAAJ",
      "kUcBGSgAAAAJ",
      "u5SbAJAAAAAJ",
      "KsGo-_QAAAAJ",
      "SKVnHakAAAAJ",
      "Z_CRrRwAAAAJ",
      "wR_tv-kAAAAJ",
      "xW-IxnwAAAAJ",
      "skcZ-JwAAAAJ",
      "f28F1YUAAAAJ",
      "zkvW8FQAAAAJ",
      "mtejbKYAAAAJ",
      "9c-_E-YAAAAJ",
      "043r6toAAAAJ",
      "C-ZlBWMAAAAJ",
      "gkHA4nEAAAAJ",
      "57gDGpUAAAAJ",
      "spv5CecAAAAJ",
      "Ytks8n0AAAAJ",
      "aa9LMvoAAAAJ",
      "hlWhzU8AAAAJ",
      "CXgQufgAAAAJ",
      "HvjirogAAAAJ",
      "CtRMD1UAAAAJ",
      "aorYJGcAAAAJ",
      "jgqZbREAAAAJ",
      "jzsx52EAAAAJ",
      "G0JugenpCgwC",
      "oajw_bMAAAAJ",
      "sfvCNiEAAAAJ",
      "-K2KHjIAAAAJ",
      "rmAcDNkAAAAJ",
      "0LEOL50AAAAJ",
      "iFYov5EAAAAJ",
      "373HnhYAAAAJ",
      "MzKvJhAAAAAJ",
      "rNcmwggAAAAJ",
      "SW4wc24AAAAJ",
      "eMzW3TwAAAAJ",
      "gfklepYAAAAJ",
      "tX56UKEAAAAJ",
      "YkjjioAAAAAJ",
      "Tom5l8EAAAAJ",
      "CcLMQagAAAAJ",
      "4PMCkasAAAAJ",
      "-TFCgqsAAAAJ",
      "mMANqk8AAAAJ",
      "gcS68oUAAAAJ",
      "DLiKRkgAAAAJ",
      "k5eocA8AAAAJ",
      "WPESKq0AAAAJ",
      "MFoV3lsAAAAJ",
      "wxauPrwAAAAJ",
      "f9_wq_kAAAAJ",
      "GhqD_rwAAAAJ",
      "FqKcLDQAAAAJ",
      "aeKmkoUAAAAJ",
      "k9Hczv4AAAAJ",
      "CBLnYLEAAAAJ",
      "NvIcXEYAAAAJ",
      "IeHKeGYAAAAJ",
      "MiFqJGcAAAAJ",
      "BGONmkIAAAAJ",
      "2zReQdQAAAAJ",
      "lVD0CNEAAAAJ",
      "e378qEIAAAAJ",
      "pP7EjUsAAAAJ",
      "GXJqtYUAAAAJ",
      "MVGcpRsAAAAJ",
      "C4i_vUMAAAAJ",
      "FSj_J7MAAAAJ",
      "03JRmRcAAAAJ",
      "UVuQeJIAAAAJ",
      "y3xgouMAAAAJ",
      "Lr2lbdQAAAAJ",
      "-LJCZMMAAAAJ",
      "ED5iKYYAAAAJ",
      "IkrviqEAAAAJ",
      "LB7sjGwAAAAJ",
      "Qlq7GEQAAAAJ",
      "pa7de7wAAAAJ",
      "D4rBbksAAAAJ",
      "aOO2tOwAAAAJ",
      "N-sME4wAAAAJ",
      "EpdF_GQAAAAJ",
      "y9jYYRkAAAAJ",
      "eQ1uJ6UAAAAJ",
      "BWnXD4IAAAAJ",
      "VQJR8WoAAAAJ",
      "SkH-ZyIAAAAJ",
      "Zq4ioqu5yb8C",
      "zXESohsAAAAJ",
      "4Nzf_IcAAAAJ",
      "mFiX664AAAAJ",
      "MFZC4EgAAAAJ",
      "2BNtbXMAAAAJ",
      "4FM97JgAAAAJ",
      "vf-M8-MAAAAJ",
      "nZ8H4nsAAAAJ",
      "qXi2lyMAAAAJ",
      "IqJ3zskAAAAJ",
      "nP8cwkIAAAAJ",
      "LS6HY-gAAAAJ",
      "gWGQIh4AAAAJ",
      "Ro6enEEAAAAJ",
      "j1okDGUAAAAJ",
      "ynvtzZQAAAAJ",
      "MqWYTj0AAAAJ",
      "czyretsAAAAJ",
      "0y38RJ8AAAAJ",
      "jjEht8wAAAAJ",
      "Vn3L_ioAAAAJ",
      "ipb9-GEAAAAJ",
      "LHTI1W8AAAAJ",
      "wbJxGQ8AAAAJ",
      "0ECOF7cAAAAJ",
      "aHs2JHgAAAAJ",
      "G1WMpcUAAAAJ",
      "J6iSjTcAAAAJ",
      "uK5wa_EAAAAJ",
      "1a-_ns8AAAAJ",
      "UVkOjSAAAAAJ",
      "ZDPCh_EAAAAJ",
      "VPyxd6kAAAAJ",
      "l_XxJ1kAAAAJ",
      "cHia5p0AAAAJ",
      "hHkuxSUAAAAJ",
      "rzhzR-cAAAAJ",
      "p1DZVX8AAAAJ",
      "OzMYwDIAAAAJ",
      "1sqZDWIAAAAJ",
      "VgNDYeYAAAAJ",
      "XtMdGSkAAAAJ",
      "qRp1xZwAAAAJ",
      "SVNNgu4AAAAJ",
      "zTfIpA4AAAAJ",
      "uplepqQAAAAJ",
      "stQ_JksAAAAJ",
      "RlSbIJ4AAAAJ",
      "PqlE63kAAAAJ",
      "AqYyoCMAAAAJ",
      "eUHFqm4AAAAJ",
      "H3LMjtoAAAAJ",
      "-OpGJpYAAAAJ",
      "ZngqplgAAAAJ",
      "p7dCP-kAAAAJ",
      "AscakBgAAAAJ",
      "Jjp8eYUAAAAJ",
      "fftO_HsAAAAJ",
      "6NfC90UAAAAJ",
      "BXGfZq4AAAAJ",
      "Q0iwucYAAAAJ",
      "dKNkD3sAAAAJ",
      "qGWon5kAAAAJ",
      "ASLQHz8AAAAJ",
      "YRWfuEIAAAAJ",
      "daslsUkAAAAJ",
      "jTnQTBoAAAAJ",
      "lGgLAiIAAAAJ",
      "ypaqepYAAAAJ",
      "IT7lx4sAAAAJ",
      "bTG82acAAAAJ",
      "mKia7Y4AAAAJ",
      "6yL0xw8AAAAJ",
      "E02doCkAAAAJ",
      "UZK1i4EAAAAJ",
      "TDxKd6cAAAAJ",
      "qQLlBH4AAAAJ",
      "vjgsd5kAAAAJ",
      "duBlF_YAAAAJ",
      "rjmrrlgAAAAJ",
      "3VZ_E64AAAAJ",
      "NyoUvosAAAAJ",
      "Tqk2bsMAAAAJ",
      "8TkJbjgAAAAJ",
      "1-OBVMMAAAAJ",
      "EfxwV6oAAAAJ",
      "RqOzJR0AAAAJ",
      "OcownLgAAAAJ",
      "9cZUlEYAAAAJ",
      "iS5ADlgAAAAJ",
      "FzSHcngAAAAJ",
      "tUTVVjAAAAAJ",
      "SvKKBy4AAAAJ",
      "W8BMhsgAAAAJ",
      "r9TQ2n4AAAAJ",
      "nEFU7wIAAAAJ",
      "G_vOcFUAAAAJ",
      "tMY31_gAAAAJ",
      "XOJE8OEAAAAJ",
      "MEowyLcAAAAJ",
      "l7HQl-kAAAAJ",
      "V6FaD-UAAAAJ",
      "YgykRA0AAAAJ",
      "fhxshS0AAAAJ",
      "JIJGu30AAAAJ",
      "ncTx_QoAAAAJ",
      "d0npq2oAAAAJ",
      "YCoLskoAAAAJ",
      "dzOd2hgAAAAJ",
      "MzD8rjoAAAAJ",
      "JdRs1sQAAAAJ",
      "Z3dxz9IAAAAJ",
      "TmZ3howAAAAJ",
      "mJB-HiIAAAAJ",
      "N-iYby0AAAAJ",
      "FbkauMAAAAAJ",
      "U9zz4E0AAAAJ",
      "N1Gjo24AAAAJ",
      "3evp9QMAAAAJ",
      "V49BsgMAAAAJ",
      "Ao-FJHwAAAAJ",
      "Hq5VU2EAAAAJ",
      "CmoWrcIAAAAJ",
      "gwUGHwsAAAAJ",
      "fVxqrBkAAAAJ",
      "do7yT8MAAAAJ",
      "RjQ7YnMAAAAJ",
      "iVavvW8AAAAJ",
      "kog9iL0AAAAJ",
      "GlIyobYAAAAJ",
      "GiCqMFkAAAAJ",
      "bMfPYdYAAAAJ",
      "3ZTrRpAAAAAJ",
      "74THEUoAAAAJ",
      "QxbpIMUAAAAJ",
      "o7yFQXUAAAAJ",
      "EC4o-1oAAAAJ",
      "fAxws1sAAAAJ",
      "N4XAItcAAAAJ",
      "M7S3soEAAAAJ",
      "jmERpL4AAAAJ",
      "55G7VxoAAAAJ",
      "K2WfIlsAAAAJ",
      "JnUevM0AAAAJ",
      "MIjWr_8AAAAJ",
      "64y6FZcAAAAJ",
      "c4yK72IAAAAJ",
      "xdCvBg0AAAAJ",
      "M2diIJYAAAAJ",
      "dusV5HMAAAAJ",
      "-N-_kgsAAAAJ",
      "RlNm1d4AAAAJ",
      "i17FWMMAAAAJ",
      "1_f79vUAAAAJ",
      "beiWcokAAAAJ",
      "0qUErHAAAAAJ",
      "AcACRTAAAAAJ",
      "DwdjBUUAAAAJ",
      "5zZjmvEAAAAJ",
      "fHkUYk0AAAAJ",
      "VZi7NssAAAAJ",
      "O8d33mkAAAAJ",
      "68c5HfwAAAAJ",
      "QESJSgMAAAAJ",
      "j3UHaFoAAAAJ",
      "_JFStaIAAAAJ",
      "yiWlY9IAAAAJ",
      "W8VIEZgAAAAJ",
      "lEzcLFwAAAAJ",
      "J8YyZugAAAAJ",
      "31eXgMYAAAAJ",
      "LiwtZz4AAAAJ",
      "lJwPbcUAAAAJ",
      "jjbNzhYAAAAJ",
      "XUhsCZwAAAAJ",
      "AXOiHucAAAAJ",
      "4VJre9IAAAAJ",
      "zJyuMYgAAAAJ",
      "tGK7hLEAAAAJ",
      "MCZpAkEAAAAJ",
      "M1fMGOMAAAAJ",
      "rR96kW0AAAAJ",
      "J8OgouwAAAAJ",
      "ke2MEF0AAAAJ",
      "14LdhrcAAAAJ",
      "aHV3aDMAAAAJ",
      "Lqc4cdAAAAAJ",
      "uXZaVaAAAAAJ",
      "lr1JM5MAAAAJ",
      "LQ5RRNkAAAAJ",
      "SFCOJxMAAAAJ",
      "bVWm69gAAAAJ",
      "XBjhKdoAAAAJ",
      "jHR4dXcAAAAJ",
      "r1cF30oAAAAJ",
      "JYMjWq8AAAAJ",
      "l2E0LR4AAAAJ",
      "24OBED0AAAAJ",
      "UAWfBEoAAAAJ",
      "ZpG_cJwAAAAJ",
      "IYqleYUAAAAJ",
      "SIFRrBIAAAAJ",
      "LR4CHSkAAAAJ",
      "S2Pk9ooAAAAJ",
      "V3UXWuMAAAAJ",
      "yNNIKJsAAAAJ",
      "aH5QOEcAAAAJ",
      "nV-tcHAAAAAJ",
      "YgtBXP0AAAAJ",
      "K2KcQKAAAAAJ",
      "ZsM2sW8AAAAJ",
      "7nuMOqoAAAAJ",
      "BHlY8ewAAAAJ",
      "5akTCHoAAAAJ",
      "JnWSU4oAAAAJ",
      "YQe9pdUAAAAJ",
      "MNqdSZcAAAAJ",
      "TaZaMGkAAAAJ",
      "TGpo3KAAAAAJ",
      "i0n7VXwAAAAJ",
      "aM1rfhEAAAAJ",
      "xOrRvKAAAAAJ",
      "bdHgGgEAAAAJ",
      "BWc6kMsAAAAJ",
      "32RHN4oAAAAJ",
      "qr8Vo9IAAAAJ",
      "_2k-ppwAAAAJ",
      "FXNJRDoAAAAJ",
      "Vj8SG_oAAAAJ",
      "Jwmp358AAAAJ",
      "_9G6V38AAAAJ",
      "-kIVAcAAAAAJ",
      "LeiGXOsAAAAJ",
      "ULRIRdgAAAAJ",
      "QP3QawMAAAAJ",
      "LigYduEAAAAJ",
      "SU0c5P0AAAAJ",
      "pe1ArKwAAAAJ",
      "fvr-J3sAAAAJ",
      "8xSYX9IAAAAJ",
      "PoDj4lsAAAAJ",
      "PtSVy9AAAAAJ",
      "9NvupxcAAAAJ",
      "GU9HgNAAAAAJ",
      "-XZ2HrAAAAAJ",
      "b4Kj6MIAAAAJ",
      "h_q7XhoAAAAJ",
      "kcTK_FAAAAAJ",
      "6Hk7QdkAAAAJ",
      "BFnzsoMAAAAJ",
      "m3eDp7kAAAAJ",
      "xBv5ZfkAAAAJ",
      "7P-gZioAAAAJ",
      "6QWsktwAAAAJ",
      "_U02AlsAAAAJ",
      "iAkcJ2oAAAAJ",
      "2iBYdwEAAAAJ",
      "wKJeOQoAAAAJ",
      "6REa4FcAAAAJ",
      "thZJZaYAAAAJ",
      "8lmWWD0AAAAJ",
      "11JgipcAAAAJ",
      "tRCR72EAAAAJ",
      "i5srt20AAAAJ",
      "6YRoqzQAAAAJ",
      "sDwpLgwAAAAJ",
      "G6txDBYAAAAJ",
      "Ysjk8kkAAAAJ",
      "o5YQMkMAAAAJ",
      "0A3yyk4AAAAJ",
      "BQD1XlcAAAAJ",
      "jq8VoFkAAAAJ",
      "K2BMBtcAAAAJ",
      "89u7qcIAAAAJ",
      "4gWt4fgAAAAJ",
      "EJfvPHYAAAAJ",
      "BaI7l8QAAAAJ",
      "f6JF7BkAAAAJ",
      "a3G23eUAAAAJ",
      "ocIDAto2lksC",
      "GkkMuvQAAAAJ",
      "vKlrdpEAAAAJ",
      "LAl0EukAAAAJ",
      "kXB8FBoAAAAJ",
      "Yd-SGH8AAAAJ",
      "HUi6F7wAAAAJ",
      "tqMGsJwAAAAJ",
      "0VVg_R4AAAAJ",
      "rr8pZoUAAAAJ",
      "Se68XecAAAAJ",
      "cNSbfGQAAAAJ",
      "UWZA0v4AAAAJ",
      "1MSpdmQAAAAJ",
      "AcrgWZIAAAAJ",
      "6NjbexEAAAAJ",
      "Sl_2kHcAAAAJ",
      "clTVC4UAAAAJ",
      "POm0zXkAAAAJ",
      "TR6GqIgAAAAJ",
      "WXXu26AAAAAJ",
      "c7hk0RwAAAAJ",
      "j5bG8TgAAAAJ",
      "1D8C9ZkAAAAJ",
      "2uHUSa8AAAAJ",
      "gdO9Gb0AAAAJ",
      "2J051LYAAAAJ",
      "kg4bCpgAAAAJ",
      "0HuMHFwAAAAJ",
      "3wXH93MAAAAJ",
      "LbYsy_QAAAAJ",
      "BKkK2DoAAAAJ",
      "ciragesAAAAJ",
      "nzEluBwAAAAJ",
      "L8r9ox4AAAAJ",
      "7q_zIE0AAAAJ",
      "tPlneaIAAAAJ",
      "XOnfkHIAAAAJ",
      "dYpPMQEAAAAJ",
      "DP3jcx0AAAAJ",
      "zqRN1ZEAAAAJ",
      "6KQy8zgAAAAJ",
      "SC1L3uAAAAAJ",
      "Kz5C0p0AAAAJ",
      "GfUvUacAAAAJ",
      "PryclcMAAAAJ",
      "QPCr30IAAAAJ",
      "2sPxj90AAAAJ",
      "zvC19mQAAAAJ",
      "bN_1u58AAAAJ",
      "x6zfRbcAAAAJ",
      "tpMNnPwAAAAJ",
      "3jzgrIcAAAAJ",
      "8F1GBF4AAAAJ",
      "jpq33DsAAAAJ",
      "j8svx3IAAAAJ",
      "JEky9g0AAAAJ",
      "zqLpO2QAAAAJ",
      "b2EEZfAAAAAJ",
      "sao65cAAAAAJ",
      "OUv7J6QAAAAJ",
      "MBzLo30AAAAJ",
      "vmAe35UAAAAJ",
      "o42MH0MAAAAJ",
      "2O_ESc4AAAAJ",
      "L4yEk2UAAAAJ",
      "lZ9KLP0AAAAJ",
      "tJlviVYAAAAJ",
      "KMBgMs0AAAAJ",
      "FioDApkAAAAJ",
      "5MeSMfAAAAAJ",
      "nXaOKoYAAAAJ",
      "53OxjmYAAAAJ",
      "2k5j4eMAAAAJ",
      "WAgx2UsAAAAJ",
      "0zKusWIAAAAJ",
      "3LYW1zMAAAAJ",
      "f_fKey0AAAAJ",
      "gdgJQ-wAAAAJ",
      "HMnF6i0AAAAJ",
      "P2mG6rcAAAAJ",
      "GkYIrlIAAAAJ",
      "Ksz7c7YAAAAJ",
      "jo5w-KMAAAAJ",
      "YE9w2BsAAAAJ",
      "nmxbwm4AAAAJ",
      "j4Fshz0AAAAJ",
      "_Lw8tJ8AAAAJ",
      "7MxQd6UAAAAJ",
      "IuKFwTsAAAAJ",
      "jYYYIvsAAAAJ",
      "RNdGVHoAAAAJ",
      "cagVT0AAAAAJ",
      "OcjvsmoAAAAJ",
      "EqJw1-4AAAAJ",
      "fkGRlH0AAAAJ",
      "uJHvcMMAAAAJ",
      "wbIMbL8AAAAJ",
      "fJsSvzkAAAAJ",
      "yJfoD0kAAAAJ",
      "iZwOlgsAAAAJ",
      "TTLOfXIAAAAJ",
      "OYZrsIQAAAAJ",
      "FPRvtUEAAAAJ",
      "KNWTvgEAAAAJ",
      "ZKeyKNgAAAAJ",
      "WjCG3owAAAAJ",
      "KzxURf4AAAAJ",
      "AzcmAtgAAAAJ",
      "ZnT-QpMAAAAJ",
      "0eFZtREAAAAJ",
      "YY_D3XkAAAAJ",
      "8PiZdy4AAAAJ",
      "YU4Ce_MAAAAJ",
      "NIIQFrEAAAAJ",
      "4Bm4gZEAAAAJ",
      "Ba_Ci9UAAAAJ",
      "dS3e-CgAAAAJ",
      "wqHic0AAAAAJ",
      "1qXJQ7cAAAAJ",
      "0CSbRv8AAAAJ",
      "7ICTJmoAAAAJ",
      "V6LJpwgAAAAJ",
      "NkYQr9QAAAAJ",
      "WtO-bN8AAAAJ",
      "v5F-I34AAAAJ",
      "or-t5ZcAAAAJ",
      "0xIrC1cAAAAJ",
      "nQBhQawAAAAJ",
      "lmQkD9UAAAAJ",
      "EMExrOMAAAAJ",
      "iBl-QgEAAAAJ",
      "all0DHsAAAAJ",
      "60HNWsYAAAAJ",
      "ArKKNxwAAAAJ",
      "4D1n8scAAAAJ",
      "jxf3Qv0AAAAJ",
      "Yh0IoBgAAAAJ",
      "2mjUsP8AAAAJ",
      "SGjYdrEAAAAJ",
      "iKlE1A8AAAAJ",
      "OsSiEMEAAAAJ",
      "8j-IC6sAAAAJ",
      "ScmX2AcAAAAJ",
      "K1GoYW8AAAAJ",
      "YK0NLaUAAAAJ",
      "Amg6a3MAAAAJ",
      "-c8JCbUAAAAJ",
      "SfKdzrUAAAAJ",
      "sCTJI-0AAAAJ",
      "EaaOeJwAAAAJ",
      "NfeARS4AAAAJ",
      "j7PrPEUAAAAJ",
      "1Rf6sGcAAAAJ",
      "G1KQAusAAAAJ",
      "ZaJy9J4AAAAJ",
      "7QmCrjcAAAAJ",
      "pOtmLl0AAAAJ",
      "mwzYYPgAAAAJ",
      "9ehX_58AAAAJ",
      "SQqkcdgAAAAJ",
      "wnePPc4AAAAJ",
      "Vwas7kAAAAAJ",
      "RLzWUrwAAAAJ",
      "heTXnBYAAAAJ",
      "j-2_cT0AAAAJ",
      "e6zXN64AAAAJ",
      "FvP33fEAAAAJ",
      "5br3h-UAAAAJ",
      "oTmQCFUAAAAJ",
      "S-J_ItYAAAAJ",
      "FJO1bnsAAAAJ",
      "lEV5F5kAAAAJ",
      "EnEiF7oAAAAJ",
      "FTqutJEAAAAJ",
      "KOBmy0sAAAAJ",
      "zh0Raz8AAAAJ",
      "ebrNfPAAAAAJ",
      "TfWlMTYAAAAJ",
      "kiF6OS4AAAAJ",
      "3G79TTEAAAAJ",
      "TTnfnugAAAAJ",
      "5WT38A0AAAAJ",
      "WlJ69p0AAAAJ",
      "Me9JcfgAAAAJ",
      "di_T0vwAAAAJ",
      "mDLwSZAAAAAJ",
      "-CzfgbwAAAAJ",
      "22oxVYkAAAAJ",
      "I0fbJ6cAAAAJ",
      "dDr8RIgAAAAJ",
      "8JKsHJcAAAAJ",
      "Kzj3HC8AAAAJ",
      "MILCJzAAAAAJ",
      "dvplAJkAAAAJ",
      "SPUjpAwAAAAJ",
      "SEAowdYAAAAJ",
      "78KBaPsAAAAJ",
      "ABPKRkAAAAAJ",
      "u3QYKhkAAAAJ",
      "mpxO5ycAAAAJ",
      "mWS1pY4AAAAJ",
      "MYRUJkUAAAAJ",
      "1aKTzmIAAAAJ",
      "MOitEvkAAAAJ",
      "eC3VWhAAAAAJ",
      "sQ6l4sMAAAAJ",
      "UpZ41EwAAAAJ",
      "T99vQCsAAAAJ",
      "65FCPpwAAAAJ",
      "lfJmfM0AAAAJ",
      "5odGE0wAAAAJ",
      "m-L5Hj0AAAAJ",
      "sgLeMy8AAAAJ",
      "BIGOtyIAAAAJ",
      "5bc-9A4AAAAJ",
      "5Hbi5WYAAAAJ",
      "7wfzKHam13MC",
      "2fWmq-4AAAAJ",
      "yteZM6AAAAAJ",
      "NxGK-wQAAAAJ",
      "EF-SzEUAAAAJ",
      "Zb5wT08AAAAJ",
      "nubwxloAAAAJ",
      "Edh7brQAAAAJ",
      "dEtv5r4AAAAJ",
      "BN2Ze-QAAAAJ",
      "n00Ol9UAAAAJ",
      "PlOGerYAAAAJ",
      "gs5xeKUAAAAJ",
      "ReWNzl4AAAAJ",
      "HOzdZp0AAAAJ",
      "w047VfEAAAAJ",
      "DSZzGh0AAAAJ",
      "F99FuaAAAAAJ",
      "eJVXK_EAAAAJ",
      "p8Ft6RQAAAAJ",
      "J6_5toMAAAAJ",
      "AUuGgYgAAAAJ",
      "pn1-9nIAAAAJ",
      "HzIp5_YAAAAJ",
      "hPhvZI0AAAAJ",
      "3KoL3eQAAAAJ",
      "_cHRq1kAAAAJ",
      "11aRt9oAAAAJ",
      "UDRtJsEAAAAJ",
      "pZ0-BicAAAAJ",
      "Rqy5KDEAAAAJ",
      "5z2rh_oAAAAJ",
      "C0kDOzcAAAAJ",
      "8xaTRNsAAAAJ",
      "OBBqkosAAAAJ",
      "0ZAb3tsAAAAJ",
      "NFCefosAAAAJ",
      "6bJxJIcAAAAJ",
      "uIQ2vHQAAAAJ",
      "LYRkQhMAAAAJ",
      "XboZC1AAAAAJ",
      "RBTNWv4AAAAJ",
      "sFQD3k4AAAAJ",
      "OeuYmWUAAAAJ",
      "mPC6wp4AAAAJ",
      "jgr1-eEAAAAJ",
      "fZinJ_AAAAAJ",
      "j88h_roAAAAJ",
      "QcsE_ZYAAAAJ",
      "X3RNgQMAAAAJ",
      "-_eJqYQAAAAJ",
      "1EPxhywAAAAJ",
      "L9QufAsAAAAJ",
      "4zybTq4AAAAJ",
      "Sg3jtCgAAAAJ",
      "BdwP-3QAAAAJ",
      "gSYxbCYAAAAJ",
      "3TggrEkAAAAJ",
      "uZvvcgUAAAAJ",
      "55swP8AAAAAJ",
      "WeVsE1AAAAAJ",
      "cITeyPkAAAAJ",
      "8hxMm5UAAAAJ",
      "D0pzuNoAAAAJ",
      "yCyR-TsAAAAJ",
      "ygTCc6cAAAAJ",
      "AUhj438AAAAJ",
      "7WntHrAAAAAJ",
      "4ANbX-YAAAAJ",
      "tmK5EPEAAAAJ",
      "-q4nE1kAAAAJ",
      "64zxhRUAAAAJ",
      "6m4wv6gAAAAJ",
      "d97bGd8AAAAJ",
      "GcGVcyoAAAAJ",
      "unUhqcwAAAAJ",
      "BD2lkwIAAAAJ",
      "VTe4SGUAAAAJ",
      "_CYEGnoAAAAJ",
      "_KpeoVgAAAAJ",
      "AbzGfgoAAAAJ",
      "8C2_ZVsAAAAJ",
      "IzLlyzsAAAAJ",
      "yd0R-5MAAAAJ",
      "amJQro0AAAAJ",
      "a3Uhp58AAAAJ",
      "nqDmEHUAAAAJ",
      "ct67_F8AAAAJ",
      "dQ0dT2sAAAAJ",
      "hqNhUCYAAAAJ",
      "ScoZZPsAAAAJ",
      "NpOg5soAAAAJ",
      "pdKcN5gAAAAJ",
      "Gi6ksZoAAAAJ",
      "pkp4VXUAAAAJ",
      "0pOgVVAAAAAJ",
      "GZA3M2AAAAAJ",
      "JMHsqIkAAAAJ",
      "OI6ouhAAAAAJ",
      "3b0l5LEAAAAJ",
      "y0U2EaUAAAAJ",
      "DkYYtGIAAAAJ",
      "WsbgVR4AAAAJ",
      "LW1Kw4EAAAAJ",
      "Eja4Kw4AAAAJ",
      "NqsBRwMAAAAJ",
      "H4Rq5LwAAAAJ",
      "xBH73TYAAAAJ",
      "eiIriYIAAAAJ",
      "fup4pNsAAAAJ",
      "dTue6HQAAAAJ",
      "720Ix7QAAAAJ",
      "RGiCLUgAAAAJ",
      "NMS69lQAAAAJ",
      "2-uoevgAAAAJ",
      "_bIWSJAAAAAJ",
      "HGNZ1fkAAAAJ",
      "RuvHkikAAAAJ",
      "gPKDZtwAAAAJ",
      "y8s4ok0AAAAJ",
      "DFqp8NkAAAAJ",
      "dD7EpwQAAAAJ",
      "PvHFAfIAAAAJ",
      "xrUwjlQAAAAJ",
      "Vu-Zb7EAAAAJ",
      "oNQRPLYAAAAJ",
      "p-h_BvcAAAAJ",
      "Y7aNyh8AAAAJ",
      "ENIyTF8AAAAJ",
      "jG0AYyEAAAAJ",
      "StIHrlMAAAAJ",
      "hlO3qqkAAAAJ",
      "gI55gF0AAAAJ",
      "LfF2zfQAAAAJ",
      "ZisEORUAAAAJ",
      "E0NwK2AAAAAJ",
      "FWJZYMYAAAAJ",
      "fb6FOfsAAAAJ",
      "HmBa_6gAAAAJ",
      "wzifqNkAAAAJ",
      "x5Ig8xMAAAAJ",
      "Ek4hM10AAAAJ",
      "Bp6tvy0AAAAJ",
      "ffwGwU8AAAAJ",
      "0RdaaYsAAAAJ",
      "GD5bzTgAAAAJ",
      "FIBljEYAAAAJ",
      "58Yv3zUAAAAJ",
      "3fa02HAAAAAJ",
      "0Gqc1vIAAAAJ",
      "qg9Gd84AAAAJ",
      "rEL4-fgAAAAJ",
      "6EOl3hAAAAAJ",
      "umFQktIAAAAJ",
      "rTw-pq0AAAAJ",
      "W2DsnAkAAAAJ",
      "u2tgePAAAAAJ",
      "E0A3lSIAAAAJ",
      "RiDZxz8AAAAJ",
      "lsbreWwAAAAJ",
      "lqyGZpQAAAAJ",
      "6nKHDKYAAAAJ",
      "GBU568oAAAAJ",
      "mV7RNZAAAAAJ",
      "RveRRXAAAAAJ",
      "CYfxRVIAAAAJ",
      "BOMboVoAAAAJ",
      "yAWtq6QAAAAJ",
      "700fyvEAAAAJ",
      "9lT6OOEAAAAJ",
      "xlkTND4AAAAJ",
      "7ZXfuAMAAAAJ",
      "gruYQKgAAAAJ",
      "i7eVfzwAAAAJ",
      "Bk5BJ80AAAAJ",
      "zSiDAt4AAAAJ",
      "r0EFvOoAAAAJ",
      "30VwF8YAAAAJ",
      "AYdoj2AAAAAJ",
      "5MdxFjAAAAAJ",
      "uggA5n4AAAAJ",
      "UOv-ce4AAAAJ",
      "siW2DBoAAAAJ",
      "-XCiamcAAAAJ",
      "TlFEW10AAAAJ",
      "6GdwHssAAAAJ",
      "J_5y3HMAAAAJ",
      "1nBmV3cAAAAJ",
      "OJPj4t0AAAAJ",
      "zbXIQMsAAAAJ",
      "TUAzs3sAAAAJ",
      "BTBd5V4AAAAJ",
      "itSa94cAAAAJ",
      "_kKvHOAAAAAJ",
      "RY7cuPAAAAAJ",
      "Jz_PoUQAAAAJ",
      "F6x3R1oAAAAJ",
      "JpSx3EMAAAAJ",
      "-WFwzjoAAAAJ",
      "2sFj-kcAAAAJ",
      "TIKl_foAAAAJ",
      "ehrpcBwAAAAJ",
      "lx-5mjUAAAAJ",
      "MtxwDwoAAAAJ",
      "1gqyKqcAAAAJ",
      "s1_ay2AAAAAJ",
      "xpwMxy8AAAAJ",
      "Zp2LpwUAAAAJ",
      "MGXJkIAAAAAJ",
      "EPO5_f4AAAAJ",
      "cuSWd3cAAAAJ",
      "DCSFMuAAAAAJ",
      "81IhdxgAAAAJ",
      "4_i_4TkAAAAJ",
      "6re6uwMAAAAJ",
      "SmO3044AAAAJ",
      "2P8IbqoAAAAJ",
      "VizsSmEAAAAJ",
      "lTmDo34AAAAJ",
      "3RnBcXAAAAAJ",
      "CVVh3DIAAAAJ",
      "uAsllJMAAAAJ",
      "Hi7ZdhQAAAAJ",
      "KDTyloUAAAAJ",
      "rIK7AMkAAAAJ",
      "AEKT17QAAAAJ",
      "C6GeyOwAAAAJ",
      "DGcTRyEAAAAJ",
      "OHoU9Y4AAAAJ",
      "kmXOOdsAAAAJ",
      "anxumroAAAAJ",
      "ljxAoR8AAAAJ",
      "eyCw9goAAAAJ",
      "CFp3IakAAAAJ",
      "3prQpXgAAAAJ",
      "045mm50AAAAJ",
      "1e6XV-YAAAAJ",
      "Y8-xGncAAAAJ",
      "34FcX8gAAAAJ",
      "Mq89JAcAAAAJ",
      "n8ZpnWMAAAAJ",
      "TwABcRgAAAAJ",
      "9UoNgkYAAAAJ",
      "zXsQ3CkAAAAJ",
      "Rz9p0poAAAAJ",
      "BgQkdsYAAAAJ",
      "5qSIhVkAAAAJ",
      "Xn--pmkAAAAJ",
      "_9n9mi8AAAAJ",
      "YTmGBNsAAAAJ",
      "WNHLjp0AAAAJ",
      "XPiir70AAAAJ",
      "LkoaA0gAAAAJ",
      "XE9SDzgAAAAJ",
      "1c5IZ0QAAAAJ",
      "wIhJS60AAAAJ",
      "wrozdTYAAAAJ",
      "lXCP2cMAAAAJ",
      "LWvgl-8AAAAJ",
      "28sDUWIAAAAJ",
      "iXOzeWUAAAAJ",
      "NZmIA9oAAAAJ",
      "m4rsQCAAAAAJ",
      "Jyqbex4AAAAJ",
      "MNp5hwoAAAAJ",
      "nWboYt0AAAAJ",
      "AjxoEpIAAAAJ",
      "dkW3lTAAAAAJ",
      "ruHs0xMAAAAJ",
      "Mgm8xyAAAAAJ",
      "soanB6MAAAAJ",
      "zmbW4iUAAAAJ",
      "H9xADK0AAAAJ",
      "usJzGjUAAAAJ",
      "XB3_I9cAAAAJ",
      "fuAzo2IAAAAJ",
      "0tWX-EMAAAAJ",
      "Oy8M_4QAAAAJ",
      "lRLvr5EAAAAJ",
      "voxznZAAAAAJ",
      "lyG0vMQAAAAJ",
      "7UCco8IAAAAJ",
      "nxwNAEgAAAAJ",
      "Wj4ZBFIAAAAJ",
      "NbVfqJYAAAAJ",
      "kxAk6AoAAAAJ",
      "Ftz0NHIAAAAJ",
      "txxQb7cAAAAJ",
      "spAJDzYAAAAJ",
      "wOkPYS4AAAAJ",
      "Thz9yCEAAAAJ",
      "NxN3gEsAAAAJ",
      "tAdZoKIAAAAJ",
      "FIpwvjsAAAAJ",
      "fVo3u5wAAAAJ",
      "mnifqeUAAAAJ",
      "z-oSdPoAAAAJ",
      "9pSK04MAAAAJ",
      "DxmHk08AAAAJ",
      "Y5x2ZgQAAAAJ",
      "o8048ZwAAAAJ",
      "Zbo61UMAAAAJ",
      "mFC0wp8AAAAJ",
      "6vBloKgAAAAJ",
      "HfXk1nEAAAAJ",
      "1t-vpJ8AAAAJ",
      "O6NknDYAAAAJ",
      "4yuKD_AAAAAJ",
      "PZJIgZUAAAAJ",
      "SaH2yWMAAAAJ",
      "I_YsXU4AAAAJ",
      "axpNZUAAAAAJ",
      "ho_asq8AAAAJ",
      "hklOXvkAAAAJ",
      "YTO4ex4AAAAJ",
      "3L333oYAAAAJ",
      "21_amyAAAAAJ",
      "nHPGOOgAAAAJ",
      "ETJoidYAAAAJ",
      "PLcCBl4AAAAJ",
      "eG2NHUYAAAAJ",
      "i-g1zC0AAAAJ",
      "6KWZup8AAAAJ",
      "Bphl_fIAAAAJ",
      "iAdho-sAAAAJ",
      "OUpIbcQAAAAJ",
      "jwkE2lgAAAAJ",
      "19qSWk8AAAAJ",
      "hV5D8GYAAAAJ",
      "9I7kD8sAAAAJ",
      "Feoyh4AAAAAJ",
      "DcV-5RAAAAAJ",
      "ogtsTE4AAAAJ",
      "lPU_engAAAAJ",
      "k8Rs4JcAAAAJ",
      "wc1Hbl8AAAAJ",
      "C_AP8XAAAAAJ",
      "vcJ4hAkAAAAJ",
      "nwHfwCIAAAAJ",
      "F2e_jZMAAAAJ",
      "FxdgVLkAAAAJ",
      "WhMzaJwAAAAJ",
      "79k7bGEAAAAJ",
      "qYLOPxoAAAAJ",
      "cZzmemAAAAAJ",
      "Pgor6i8AAAAJ",
      "cyfI_XQAAAAJ",
      "NvKHgzkAAAAJ",
      "UBrbfSwAAAAJ",
      "-PWcE1YAAAAJ",
      "Tw8DY-cAAAAJ",
      "Y-C2u28AAAAJ",
      "GweT9VUAAAAJ",
      "lXBUU7EAAAAJ",
      "hankD2kAAAAJ",
      "zYONEFQAAAAJ",
      "bD8DWiEAAAAJ",
      "aO8KpGcAAAAJ",
      "pW3nxkUAAAAJ",
      "JFEjS1QAAAAJ",
      "j9jhYqQAAAAJ",
      "uW7jWOcAAAAJ",
      "tjjniXEAAAAJ",
      "8tflub4AAAAJ",
      "fDmPEMYAAAAJ",
      "h0a5q3QAAAAJ",
      "AiuGlVQAAAAJ",
      "4C9naMgAAAAJ",
      "zDax7zYAAAAJ",
      "aSJthdEAAAAJ",
      "VFO9h14AAAAJ",
      "_lnL4aQAAAAJ",
      "Sn8fzegAAAAJ",
      "qL2ZsgcAAAAJ",
      "7mGMjnIAAAAJ",
      "PUeKU8kAAAAJ",
      "dDGy3N0AAAAJ",
      "3KF3AIMAAAAJ",
      "LajpoI8AAAAJ",
      "yORoyhsAAAAJ",
      "g2uay50AAAAJ",
      "YB8_6gkAAAAJ",
      "Jzt5uNAAAAAJ",
      "W3lyJF8AAAAJ",
      "-DYvinwAAAAJ",
      "GrDAbaEAAAAJ",
      "dlV-qnUAAAAJ",
      "-P9LwcgAAAAJ",
      "-XGXJbQAAAAJ",
      "AI2f3dkAAAAJ",
      "LjmBUTAAAAAJ",
      "Kv9W_ZYAAAAJ",
      "QAPgF4kAAAAJ",
      "pe6tmKAAAAAJ",
      "bTVBQpcAAAAJ",
      "z7b0sKUAAAAJ",
      "VdBfGdoAAAAJ",
      "NINFXC0AAAAJ",
      "KFnmktMAAAAJ",
      "M0gMbZMAAAAJ",
      "Cybj4ysAAAAJ",
      "16posrQAAAAJ",
      "xiiiSa8AAAAJ",
      "vCuk0SQAAAAJ",
      "PKcjcT4AAAAJ",
      "xVzAml0AAAAJ",
      "TMimDRoAAAAJ",
      "fYarJtcAAAAJ",
      "2bDu3ecAAAAJ",
      "LiH53A8AAAAJ",
      "8ys-38kAAAAJ",
      "0xWltyAAAAAJ",
      "RXsYj9IAAAAJ",
      "Xnk4W5cAAAAJ",
      "6IxWYR0AAAAJ",
      "EFB9ZuwAAAAJ",
      "y3ry4kcAAAAJ",
      "Q7ftcFEAAAAJ",
      "qj3IRU8AAAAJ",
      "3I4iQioAAAAJ",
      "YsXNU78AAAAJ",
      "n8iUBg8AAAAJ",
      "5QC_CV4AAAAJ",
      "d96wNhsAAAAJ",
      "cH0pbIwAAAAJ",
      "P5AJTXcAAAAJ",
      "hma0WFAAAAAJ",
      "cH2eTqAAAAAJ",
      "2aMqJTgAAAAJ",
      "xqyoorYAAAAJ",
      "uWan5l0AAAAJ",
      "q0ZUBN4AAAAJ",
      "VT7peyEAAAAJ",
      "9aw_QGAAAAAJ",
      "BYXqAlwAAAAJ",
      "lD3PMh0AAAAJ",
      "XK_ktwQAAAAJ",
      "BXJ3LwEAAAAJ",
      "K4OcFXUAAAAJ",
      "ZnVZ9xYAAAAJ",
      "V4OPEAgAAAAJ",
      "X5NSuikAAAAJ",
      "QMfeRz0AAAAJ",
      "Hlx9L00AAAAJ",
      "xak5mK4AAAAJ",
      "Bl8GgEcAAAAJ",
      "bQTXRrAAAAAJ",
      "Do8MrDYAAAAJ",
      "iusaOxAAAAAJ",
      "2v1cPRsAAAAJ",
      "8CsZAHUAAAAJ",
      "5b8b5V8AAAAJ",
      "eM916YMAAAAJ",
      "9Pl5k60AAAAJ",
      "h-9pNEkAAAAJ",
      "-D0EgMIAAAAJ",
      "JcZUd5IAAAAJ",
      "JrKoQLgAAAAJ",
      "EzvMOjkAAAAJ",
      "YYUK51oAAAAJ",
      "tWew360AAAAJ",
      "CctaxzYAAAAJ",
      "d3YhiooAAAAJ",
      "FBHC_JYAAAAJ",
      "GQ6xw-oAAAAJ",
      "lg_0u-0AAAAJ",
      "n4eReqMAAAAJ",
      "49ovzE4AAAAJ",
      "Zlpuln8AAAAJ",
      "B6EgtpUAAAAJ",
      "y0LVrtgAAAAJ",
      "P2NN0PAAAAAJ",
      "AEBWEm8AAAAJ",
      "ouSpgSkAAAAJ",
      "fcqBMQgAAAAJ",
      "NSw87QsAAAAJ",
      "Q9va0qQAAAAJ",
      "l7WEDAcAAAAJ",
      "-sGaL8sAAAAJ",
      "OYc22IoAAAAJ",
      "-lONjNgAAAAJ",
      "uxsLx-0AAAAJ",
      "F9kqUXkAAAAJ",
      "QI-eVvkAAAAJ",
      "haahCZ4AAAAJ",
      "3Ir65ZkAAAAJ",
      "Wb_lnjAAAAAJ",
      "DDxFvcIAAAAJ",
      "T8AsZ1sAAAAJ",
      "ji6BSBoAAAAJ",
      "OsoQ-dcAAAAJ",
      "NlnpI7QAAAAJ",
      "KoXUMbsAAAAJ",
      "Tsh90D8AAAAJ",
      "JB1j474AAAAJ",
      "xADN4DUAAAAJ",
      "mnU3HpcAAAAJ",
      "meFUbHIAAAAJ",
      "o_J2CroAAAAJ",
      "BB833ugAAAAJ",
      "dtxmW18AAAAJ",
      "gG7M_pIAAAAJ",
      "ijIHem4AAAAJ",
      "6S9C8XoAAAAJ",
      "AMVmM84AAAAJ",
      "E3NRabsAAAAJ",
      "57QIaiQAAAAJ",
      "QMV3HxMAAAAJ",
      "T3Tt0S8AAAAJ",
      "GN5Mc3UAAAAJ",
      "9qVRm-AAAAAJ",
      "4LAT5WYAAAAJ",
      "4qCGgpsAAAAJ",
      "x275ekUAAAAJ",
      "7aJVFS8AAAAJ",
      "L3KXa3cAAAAJ",
      "3SDKldkAAAAJ",
      "5IMEORsAAAAJ",
      "q7Yn0UwAAAAJ",
      "XrwHHxAAAAAJ",
      "6RWbQjMAAAAJ",
      "gC5ucdsAAAAJ",
      "VuvKPiQAAAAJ",
      "RaScARwAAAAJ",
      "Lh7VfoMAAAAJ",
      "3tNXqMIAAAAJ",
      "9yQ1tQoAAAAJ",
      "WbYQGjcAAAAJ",
      "Djtri0kAAAAJ",
      "lVIk1qIAAAAJ",
      "MAeMisMAAAAJ",
      "9emgsOwAAAAJ",
      "jyk2KYEAAAAJ",
      "QpTmnC4AAAAJ",
      "U_EaAcgAAAAJ",
      "dCheWDEAAAAJ",
      "2zHG0dwAAAAJ",
      "3Y4egcYAAAAJ",
      "jWz4LrAAAAAJ",
      "T2vp1pgAAAAJ",
      "Fg7TcjEAAAAJ",
      "6WYsaqMAAAAJ",
      "7o4wtKEAAAAJ",
      "QwKHApEAAAAJ",
      "IJgXsgwAAAAJ",
      "JdZ8DWwAAAAJ",
      "tvWB_yUAAAAJ",
      "q5O284UAAAAJ",
      "YNi1eSQAAAAJ",
      "fA0rYxMAAAAJ",
      "r2tKnV4AAAAJ",
      "eARXJywAAAAJ",
      "QKtoEnkAAAAJ",
      "xxYMJlUAAAAJ",
      "aAX0au8AAAAJ",
      "hYVMrzsAAAAJ",
      "HPfNU94AAAAJ",
      "DulpV-cAAAAJ",
      "Bz3APTsAAAAJ",
      "vFWw1NoAAAAJ",
      "JL4E0ZoAAAAJ",
      "nqalmtQAAAAJ",
      "5mUoFN0AAAAJ",
      "wyjZbeMAAAAJ",
      "d2gqmrUAAAAJ",
      "q7FfnjgAAAAJ",
      "WQA9GckAAAAJ",
      "BC8TixYAAAAJ",
      "wAFMjfkAAAAJ",
      "Hs3AnAkAAAAJ",
      "BMgUIC0AAAAJ",
      "TwifRtcAAAAJ",
      "-p2OOuQAAAAJ",
      "bn4xHHIAAAAJ",
      "AYPlwA0AAAAJ",
      "f8ByXgEAAAAJ",
      "X11hfvIAAAAJ",
      "xPnkc80AAAAJ",
      "FaOcyfMAAAAJ",
      "kQsnsxIAAAAJ",
      "8fztli4AAAAJ",
      "XG7qH_YAAAAJ",
      "qk0hejcAAAAJ",
      "JepH3ckAAAAJ",
      "qG1LVpQAAAAJ",
      "KIgj3WQAAAAJ",
      "W69x8yYAAAAJ",
      "Ha8rlUgAAAAJ",
      "IOagLnEAAAAJ",
      "MDCu0WEAAAAJ",
      "3_u1jHQAAAAJ",
      "T3hAyLkAAAAJ",
      "nZD_5vsAAAAJ",
      "ZO8UTIUAAAAJ",
      "1KEMrHkAAAAJ",
      "GSHmKZkAAAAJ",
      "Es2BBeYAAAAJ",
      "cZRgwiwAAAAJ",
      "Afa_1z4AAAAJ",
      "D2K-ADYAAAAJ",
      "qUt2HE8AAAAJ",
      "vW3djsoAAAAJ",
      "kosv_k0AAAAJ",
      "vfTpaOAAAAAJ",
      "Uq4lu9YAAAAJ",
      "6FV7CNAAAAAJ",
      "93yNuV0AAAAJ",
      "Uf9gm4oAAAAJ",
      "SLRYlKsAAAAJ",
      "iu-Gqo4AAAAJ",
      "VWCMVn4AAAAJ",
      "B320e3kAAAAJ",
      "HzxnwocAAAAJ",
      "tDWt_MQAAAAJ",
      "eoBHpj4AAAAJ",
      "hdrXRx8AAAAJ",
      "FN2kigYAAAAJ",
      "NCkkQAMAAAAJ",
      "2ftJYXMAAAAJ",
      "H-xtdV4AAAAJ",
      "NLOh3SUAAAAJ",
      "ZwmIw4EAAAAJ",
      "t8YAefAAAAAJ",
      "Ajm0ijIAAAAJ",
      "tsdD0N4AAAAJ",
      "xkIcvmIAAAAJ",
      "UbWVW6sAAAAJ",
      "Br__ds4AAAAJ",
      "RHYFcckAAAAJ",
      "GIle-VwAAAAJ",
      "4NdMn_MAAAAJ",
      "ZbUfUMoAAAAJ",
      "b8cNEHwAAAAJ",
      "TA2fG64AAAAJ",
      "3dYhzNQAAAAJ",
      "6lD1AscAAAAJ",
      "IQ2eTA8AAAAJ",
      "8JeQMMUAAAAJ",
      "BGh9WU4AAAAJ",
      "5jIJb38AAAAJ",
      "Yk6keUoAAAAJ",
      "Z-Wd_x0AAAAJ",
      "6ywZAeEAAAAJ",
      "aOsuqRkAAAAJ",
      "R4Q7jzgAAAAJ",
      "Ja-8AFsAAAAJ",
      "fKV65XQAAAAJ",
      "Jrn-jxQAAAAJ",
      "8UZIqcoAAAAJ",
      "xaYqRfAAAAAJ",
      "UD7d2NEAAAAJ",
      "eETZ8vQAAAAJ",
      "6qWcDTAAAAAJ",
      "-kdBDxYAAAAJ",
      "tk3X1QkAAAAJ",
      "3AJYxmsAAAAJ",
      "_1KUuDQAAAAJ",
      "DfrisKkAAAAJ",
      "2dTrwzAAAAAJ",
      "qk61RmIAAAAJ",
      "0ggsACEAAAAJ",
      "JO59nyUAAAAJ",
      "X3ji--4AAAAJ",
      "ImjOWWEAAAAJ",
      "ncbyhdMAAAAJ",
      "CX8zqPoAAAAJ",
      "JR_KR7MAAAAJ",
      "Ft3sKZ8AAAAJ",
      "soDBSE8AAAAJ",
      "Wk2gAZUAAAAJ",
      "8Qv3HRoAAAAJ",
      "TxdeO-UAAAAJ",
      "qIfpDL0AAAAJ",
      "O8wbTncAAAAJ",
      "IoVlb40AAAAJ",
      "70vJVxcAAAAJ",
      "8U7qLuIAAAAJ",
      "fyf_Vt4AAAAJ",
      "muunN_AAAAAJ",
      "v80j6o0AAAAJ",
      "Sh28erYAAAAJ",
      "lRwkspgAAAAJ",
      "FaJALc0AAAAJ",
      "JjASH4UAAAAJ",
      "HC9-uqsAAAAJ",
      "h8apFZsAAAAJ",
      "8vs5HGYAAAAJ",
      "WlA92lcAAAAJ",
      "9OdMvbAAAAAJ",
      "N_maL_AAAAAJ",
      "9bt2Z5QAAAAJ",
      "zithBbUAAAAJ",
      "Qg7x7M8AAAAJ",
      "FZLHMv8AAAAJ",
      "mSO6jtEAAAAJ",
      "H1JXhMIAAAAJ",
      "QfVWndgAAAAJ",
      "3FsCV_IAAAAJ",
      "NGI_y8IAAAAJ",
      "UvirJPEAAAAJ",
      "vy8xXDQAAAAJ",
      "pCOmQzsAAAAJ",
      "fEhNO7YAAAAJ",
      "ncJWfs0AAAAJ",
      "MFnbrRUAAAAJ",
      "rIdxtXsAAAAJ",
      "ct3WjtoAAAAJ",
      "59O0DBIAAAAJ",
      "0PzT1VoAAAAJ",
      "ThV9ezEAAAAJ",
      "usawh5oAAAAJ",
      "x7viPbgAAAAJ",
      "GlB6wkgAAAAJ",
      "C3NuO-AAAAAJ",
      "VR8nzcUAAAAJ",
      "JKJ99B0AAAAJ",
      "QKslW6EAAAAJ",
      "02hyl6AAAAAJ",
      "qlmK27YAAAAJ",
      "k5NbHlEAAAAJ",
      "Lf3tYKYAAAAJ",
      "qXzIytoAAAAJ",
      "y1aC-CMAAAAJ",
      "tVEF11EAAAAJ",
      "L7fTK1MAAAAJ",
      "l19pn2sAAAAJ",
      "hSaJzr8AAAAJ",
      "PCtRSvUAAAAJ",
      "_X0f2QMAAAAJ",
      "QNRj_g8AAAAJ",
      "1x2nwykAAAAJ",
      "Jlv4MR4AAAAJ",
      "eBtFiuAAAAAJ",
      "qTCXoLQAAAAJ",
      "3chExUsAAAAJ",
      "8eB7Q1kAAAAJ",
      "mGMy_kwAAAAJ",
      "S1YPXrgAAAAJ",
      "WgG-GJkAAAAJ",
      "7jNkTbYAAAAJ",
      "Fvh5mcwAAAAJ",
      "6PJWcFEAAAAJ",
      "54KhKdEAAAAJ",
      "cSN8ZyQAAAAJ",
      "uu7LudIAAAAJ",
      "GvXDNsYAAAAJ",
      "QDmEj4MAAAAJ",
      "KXSlX3sAAAAJ",
      "bo0P2qYAAAAJ",
      "91R66jcAAAAJ",
      "146OneEAAAAJ",
      "50O3v1MAAAAJ",
      "lNVTz20AAAAJ",
      "DqXsbPAAAAAJ",
      "CeioNO4AAAAJ",
      "VWNTaCgAAAAJ",
      "uA0kNBUAAAAJ",
      "DFAzHK8AAAAJ",
      "ZA0KnX0AAAAJ",
      "2oclnIwAAAAJ",
      "zVDNPpvMya0C",
      "oD_Ea7EAAAAJ",
      "FOF_PaEAAAAJ",
      "0pxg5ssAAAAJ",
      "U7HnX4kAAAAJ",
      "Cw7LTkkAAAAJ",
      "sbbRtWwAAAAJ",
      "rYIFql4AAAAJ",
      "OUTSTAYAAAAJ",
      "opVT1qkAAAAJ",
      "DbeHYRcAAAAJ",
      "JSj4f4sAAAAJ",
      "sRId4vsAAAAJ",
      "nkEGpKsAAAAJ",
      "n2S1wyQAAAAJ",
      "pGib_yMAAAAJ",
      "Sou5ih0AAAAJ",
      "NcB2lzcAAAAJ",
      "btkSHDwAAAAJ",
      "jN2DeKcAAAAJ",
      "Ss2KBccAAAAJ",
      "dlzWP0UAAAAJ",
      "8MliTo4AAAAJ",
      "05uQHIgAAAAJ",
      "jTdkr10AAAAJ",
      "gzPWwdIAAAAJ",
      "nUCWRZAAAAAJ",
      "bc_N2-oAAAAJ",
      "ZkBTPkUAAAAJ",
      "GAdPpe0AAAAJ",
      "SUd2LJUAAAAJ",
      "IroP0EwAAAAJ",
      "oirMEUEAAAAJ",
      "zBUwaGkAAAAJ",
      "tgkojSIAAAAJ",
      "OYd3hjYAAAAJ",
      "LurWtuYAAAAJ",
      "kcr8134AAAAJ",
      "Hft2m4wAAAAJ",
      "veCt9kMAAAAJ",
      "gXiGxcMAAAAJ",
      "BF39lMQAAAAJ",
      "elmWdycAAAAJ",
      "u455rGAAAAAJ",
      "EX3OYP4AAAAJ",
      "aUdg4P0AAAAJ",
      "eSgXTkkAAAAJ",
      "bkG57aEAAAAJ",
      "B7xbi_QAAAAJ",
      "np43vMAAAAAJ",
      "2wH43aAAAAAJ",
      "kZQQFE4AAAAJ",
      "KWG3UUMAAAAJ",
      "pwIuivQAAAAJ",
      "8FWkjw8AAAAJ",
      "NcR_PmwAAAAJ",
      "891RunEAAAAJ",
      "sGPW9jAAAAAJ",
      "PHvnX-EAAAAJ",
      "J1tqbNAAAAAJ",
      "w1-xBhoAAAAJ",
      "yREBSy0AAAAJ",
      "qpBtpGsAAAAJ",
      "EIX2jGQAAAAJ",
      "xARSfT4AAAAJ",
      "ROILf3EAAAAJ",
      "nSgKwcMAAAAJ",
      "oPDVmsgAAAAJ",
      "63TLsRcAAAAJ",
      "8HYQ1tgAAAAJ",
      "N9MkuMwAAAAJ",
      "KxmUmKkAAAAJ",
      "klZ2MMcAAAAJ",
      "UgHB5oAAAAAJ",
      "zY_J9IQAAAAJ",
      "Y_NYX7MAAAAJ",
      "c4Gcje4AAAAJ",
      "3xUT1e0AAAAJ",
      "asmcUBEAAAAJ",
      "70I8ZIMAAAAJ",
      "OBUwP_oAAAAJ",
      "Li-BrU4AAAAJ",
      "2o8ORCAAAAAJ",
      "bBFN_qwAAAAJ",
      "SzHPa90AAAAJ",
      "ezllEwMAAAAJ",
      "-SuHe48AAAAJ",
      "9OO7nhUAAAAJ",
      "Yv6wq2kAAAAJ",
      "6C8rf-0AAAAJ",
      "s5hQAPwAAAAJ",
      "vdMXuXgAAAAJ",
      "Y187sPMAAAAJ",
      "Db4BCX8AAAAJ",
      "yABlzrsAAAAJ",
      "nABXo3sAAAAJ",
      "MKSTPN8AAAAJ",
      "SvLPY-QAAAAJ",
      "3D_o3JUAAAAJ",
      "5m5ds6UAAAAJ",
      "6ujRH5UAAAAJ",
      "XFtrWVsAAAAJ",
      "KBRHCEEAAAAJ",
      "0dnObMUAAAAJ",
      "YGnty0AAAAAJ",
      "BYLsgysAAAAJ",
      "P_-O-wcAAAAJ",
      "z2SoXI8AAAAJ",
      "E6vCXjkAAAAJ",
      "TKSjVTUAAAAJ",
      "LSr5-w4AAAAJ",
      "UJ9-UuIAAAAJ",
      "udZSrkYAAAAJ",
      "NuPqqNAAAAAJ",
      "aVg7BRwAAAAJ",
      "DJRhzzYAAAAJ",
      "N0Rq-XAAAAAJ",
      "v6o-fksAAAAJ",
      "ReEG0FwAAAAJ",
      "aIRUO8AAAAAJ",
      "MnnERiQAAAAJ",
      "C7htwEIAAAAJ",
      "97RDUygAAAAJ",
      "H1XVLwsAAAAJ",
      "NIpOwa8AAAAJ",
      "JHNm8PMAAAAJ",
      "-T2Gq-EAAAAJ",
      "7_RHB_gAAAAJ",
      "t2GAVZkAAAAJ",
      "ZK7OfxkAAAAJ",
      "-XEZA0UAAAAJ",
      "7KI2Fa8AAAAJ",
      "-EMkK7QAAAAJ",
      "MYqlcPgAAAAJ",
      "ZgLOSX8AAAAJ",
      "IwSe1-MAAAAJ",
      "5cg_wrUAAAAJ",
      "21W5L1YAAAAJ",
      "0YPGwhgAAAAJ",
      "7BFEwr4AAAAJ",
      "iUe4TdgAAAAJ",
      "IVm1gDgAAAAJ",
      "9s9o-JcAAAAJ",
      "55TAOdgAAAAJ",
      "73D0CgcAAAAJ",
      "P9-oT8AAAAAJ",
      "_vjPh4UAAAAJ",
      "nvR1mBgAAAAJ",
      "vC2vywcAAAAJ",
      "S6H-0RAAAAAJ",
      "oRPEEWIAAAAJ",
      "l2Wb8uQAAAAJ",
      "riuIGwIAAAAJ",
      "0p-CEygAAAAJ",
      "bK3wI10AAAAJ",
      "UQBRs7EAAAAJ",
      "7GSWYLQAAAAJ",
      "77zwH0MAAAAJ",
      "RTkSatQAAAAJ",
      "5ZYeWgcAAAAJ",
      "U5ZZu3IAAAAJ",
      "DNPqaH0AAAAJ",
      "hfVm90AAAAAJ",
      "jW9ts2cAAAAJ",
      "dHec-LkAAAAJ",
      "9-WU64IAAAAJ",
      "FwCqwaoAAAAJ",
      "yGPH-nAAAAAJ",
      "2tt6ZJ0AAAAJ",
      "Bk8FeYwAAAAJ",
      "TGDrPLOkJIIC",
      "CdRAIEkAAAAJ",
      "Fn6xg8EAAAAJ",
      "VaaScNkAAAAJ",
      "aLdQvEAAAAAJ",
      "GdOmgYwAAAAJ",
      "hcmW-W0AAAAJ",
      "Sz01Ye0AAAAJ",
      "NRQftjIAAAAJ",
      "dq3yXjkAAAAJ",
      "_RVvnS4AAAAJ",
      "mNguJ48AAAAJ",
      "2c3HfFAAAAAJ",
      "zofVx00AAAAJ",
      "eyYubf4AAAAJ",
      "jB66t5YAAAAJ",
      "uQnBgK0AAAAJ",
      "VsTyEcQAAAAJ",
      "ebBgMSkAAAAJ",
      "qLtTKNwAAAAJ",
      "1NyT9gQAAAAJ",
      "1i6vsBYAAAAJ",
      "dGuYytYAAAAJ",
      "BEBccCQAAAAJ",
      "hwg8plgAAAAJ",
      "udIzg9QAAAAJ",
      "qNCTLV0AAAAJ",
      "yLQF4mkAAAAJ",
      "u1TctA0AAAAJ",
      "h-JEcQ8AAAAJ",
      "jJz3mXcAAAAJ",
      "xn4tmfQAAAAJ",
      "F36qnN0AAAAJ",
      "WemX9rAAAAAJ",
      "_MsNwIsAAAAJ",
      "qzC5Gh0AAAAJ",
      "vae65B0AAAAJ",
      "5vj1VV8AAAAJ",
      "K1LjZxcAAAAJ",
      "cSGXgEAAAAAJ",
      "Hq28JM0AAAAJ",
      "pzkLOIwAAAAJ",
      "JOD3OtAAAAAJ",
      "F--ov6gAAAAJ",
      "TOZ-J_wAAAAJ",
      "wmDqYvUAAAAJ",
      "Tlt5xsYAAAAJ",
      "dyXX1EgAAAAJ",
      "yqsvxQgAAAAJ",
      "g3mGoAwAAAAJ",
      "WTlgnYkAAAAJ",
      "G77y978AAAAJ",
      "fRwcQToAAAAJ",
      "-ZfwQOkAAAAJ",
      "Wy0bQrwAAAAJ",
      "s4mZnz8AAAAJ",
      "FANRIhwAAAAJ",
      "ROU76KkAAAAJ",
      "xaUJEWAAAAAJ",
      "0ei9XEUAAAAJ",
      "IfEzwZIAAAAJ",
      "WV8GXcsAAAAJ",
      "OeAQ2c0AAAAJ",
      "W56NkyoAAAAJ",
      "nhIirs0AAAAJ",
      "aqgFQqMAAAAJ",
      "0p--0vgAAAAJ",
      "mIlQ2lIAAAAJ",
      "mVkGg80AAAAJ",
      "MR3fFXoAAAAJ",
      "yIkgW-cAAAAJ",
      "-0ASVXUAAAAJ",
      "sNMowOIAAAAJ",
      "N7kzlPoAAAAJ",
      "7joKYcAAAAAJ",
      "uVTR_eoAAAAJ",
      "sgH6VuwAAAAJ",
      "f_gNVb8AAAAJ",
      "M75dilYAAAAJ",
      "wYpNpTEAAAAJ",
      "7Ek7pqgAAAAJ",
      "PDIstVQAAAAJ",
      "FeOUaQYAAAAJ",
      "AFGPpWoAAAAJ",
      "R1YK5BsAAAAJ",
      "ysE-XbUAAAAJ",
      "FAv6Nd8AAAAJ",
      "60ITZUkAAAAJ",
      "95hBTe8AAAAJ",
      "nj49RCAAAAAJ",
      "g-hQdY8AAAAJ",
      "M5YT8IoAAAAJ",
      "1KaPl5wAAAAJ",
      "tDgCcOEAAAAJ",
      "xdwK2NsAAAAJ",
      "tRPd-vQAAAAJ",
      "GrpsKVsAAAAJ",
      "-3zYIjQAAAAJ",
      "EKNrHzQAAAAJ",
      "3MzhkFIAAAAJ",
      "IWDmHggAAAAJ",
      "f1feDTMAAAAJ",
      "K0kaNvkAAAAJ",
      "kM95eWgAAAAJ",
      "wb-DKCIAAAAJ",
      "5v0elikAAAAJ",
      "3UZwE6sAAAAJ",
      "IaNhZ9AAAAAJ",
      "vHi84IsAAAAJ",
      "6bQxCusAAAAJ",
      "NQeu1oAAAAAJ",
      "V_VpLksAAAAJ",
      "XWhajuQAAAAJ",
      "zRkcvqgAAAAJ",
      "CwazDKgAAAAJ",
      "N5MghGIAAAAJ",
      "JJWWPjsAAAAJ",
      "1MceCxsAAAAJ",
      "hNsmH54AAAAJ",
      "Ycos9pAAAAAJ",
      "PgqC5SYAAAAJ",
      "qkIp7AEAAAAJ",
      "q33fP9sAAAAJ",
      "lHSilFcAAAAJ",
      "l3yJjKIAAAAJ",
      "lcOacs8AAAAJ",
      "xWdb5R8AAAAJ",
      "sT_qeloAAAAJ",
      "Tq0P7eoAAAAJ",
      "kb4ubhcAAAAJ",
      "bYvl2kwAAAAJ",
      "0g31OfAAAAAJ",
      "HpQGq54AAAAJ",
      "L766PJkAAAAJ",
      "WuWWdKcAAAAJ",
      "4Cqm82UAAAAJ",
      "kWEH634AAAAJ",
      "mbB3MRIAAAAJ",
      "tBbUAfsAAAAJ",
      "6KWxpxkAAAAJ",
      "uOfp1TEAAAAJ",
      "GMZYUyQAAAAJ",
      "BqtGVowAAAAJ",
      "ijtcJ1sAAAAJ",
      "y-nUzMwAAAAJ",
      "qU-JFvMAAAAJ",
      "wD_hj9QAAAAJ",
      "IDF-ar0AAAAJ",
      "YtUDgPIAAAAJ",
      "nUTqrPkAAAAJ",
      "SM9v2HMAAAAJ",
      "_ZAnS78AAAAJ",
      "4hbbNREAAAAJ",
      "D1okUccAAAAJ",
      "Ancx9LMAAAAJ",
      "8B9EaL8AAAAJ",
      "OZk7X80AAAAJ",
      "PsKlNzUAAAAJ",
      "EV3kaHYAAAAJ",
      "rvW4j38AAAAJ",
      "a_z5a5wAAAAJ",
      "IS4VSXAAAAAJ",
      "_DSRMYIAAAAJ",
      "7ezIRWQAAAAJ",
      "NcaZT3wAAAAJ",
      "M8wm74gAAAAJ",
      "SfN31P4AAAAJ",
      "foTQUXwAAAAJ",
      "u1CHA2sAAAAJ",
      "TMawhM4AAAAJ",
      "vHd2qAkAAAAJ",
      "BEHcR-IAAAAJ",
      "K6J_DvgAAAAJ",
      "l2IhA2IAAAAJ",
      "aZALISYAAAAJ",
      "IcW1vJEAAAAJ",
      "qrNPFTQAAAAJ",
      "Yn59qc4AAAAJ",
      "2GCPK34AAAAJ",
      "mw9kXD8AAAAJ",
      "ikq9m9QAAAAJ",
      "sX31JjwAAAAJ",
      "xPqd-FMAAAAJ",
      "DnxrVXgAAAAJ",
      "E894cQoAAAAJ",
      "NGqfK2wAAAAJ",
      "jH79pJkAAAAJ",
      "wTppKvQAAAAJ",
      "xGbDr7YAAAAJ",
      "U8QXoYkAAAAJ",
      "XYpPTpQAAAAJ",
      "dGj1KOsAAAAJ",
      "SeGmqkIAAAAJ",
      "P4nfoKYAAAAJ",
      "Xtgj8q0AAAAJ",
      "GP64q_kAAAAJ",
      "LQSNuf0AAAAJ",
      "fAVYK4wAAAAJ",
      "njAD34UAAAAJ",
      "pw_0Z_UAAAAJ",
      "VEGtG7YAAAAJ",
      "xfskSZEAAAAJ",
      "S_6zsEwAAAAJ",
      "ndOMZXMAAAAJ",
      "e5lxgjIAAAAJ",
      "WXd3dDwAAAAJ",
      "LuQA_vcAAAAJ",
      "1FiIlQsAAAAJ",
      "WeyLqFUAAAAJ",
      "1B0l7U8AAAAJ",
      "UhC0_gwAAAAJ",
      "rftklyIAAAAJ",
      "c646VbAAAAAJ",
      "EWJYRncAAAAJ",
      "W1a8vwIAAAAJ",
      "J8E8GQYAAAAJ",
      "cjRV2IsAAAAJ",
      "1WSaBBsAAAAJ",
      "pfqzHqUAAAAJ",
      "hlLuENoAAAAJ",
      "jyF9UHAAAAAJ",
      "hqGaEUoAAAAJ",
      "kALYnggAAAAJ",
      "R0bnqaAAAAAJ",
      "nHE4ylYAAAAJ",
      "M0OhM1UAAAAJ",
      "XaFT1o4AAAAJ",
      "psiQDeAAAAAJ",
      "OEivUAQAAAAJ",
      "nCFeUqYAAAAJ",
      "UcZbFroAAAAJ",
      "90FJPJUAAAAJ",
      "aajhzaQAAAAJ",
      "meTZPLgAAAAJ",
      "9D4aG8AAAAAJ",
      "WmH1GQoAAAAJ",
      "62ElavIAAAAJ",
      "oFIvUSQAAAAJ",
      "TW7U1W0AAAAJ",
      "8sKIuAcAAAAJ",
      "JIUz890AAAAJ",
      "pWvrysEAAAAJ",
      "k2ZQE1IAAAAJ",
      "Rcjr4UYAAAAJ",
      "KqtBi6MAAAAJ",
      "DqKSB-kAAAAJ",
      "PK57vrQAAAAJ",
      "uDLRZQMAAAAJ",
      "ZgqVLuMAAAAJ",
      "-QopmQoAAAAJ",
      "s1PgoeUAAAAJ",
      "GdQtWNQAAAAJ",
      "kroHjvEAAAAJ",
      "PnaHFhUAAAAJ",
      "eJsW6W8AAAAJ",
      "ih3MdzUAAAAJ",
      "ekic9BkAAAAJ",
      "qlwIFJsAAAAJ",
      "ojKsx6AAAAAJ",
      "taqlL_cAAAAJ",
      "C7UqPnoAAAAJ",
      "Qt2d3BoAAAAJ",
      "92bmh84AAAAJ",
      "RdvLNP4AAAAJ",
      "oejm5IUAAAAJ",
      "Bx9WGD6lBFEC",
      "J4Kj7EIAAAAJ",
      "dYu68U8AAAAJ",
      "aenlXyEAAAAJ",
      "nxd3mDcAAAAJ",
      "Q-dQhygAAAAJ",
      "DwXLsT8AAAAJ",
      "ZyaLOy4AAAAJ",
      "5S1kGcAAAAAJ",
      "RfyLl28AAAAJ",
      "Rr643xYAAAAJ",
      "Et-LI74AAAAJ",
      "jM23vRsKxuIC",
      "sPTruxEAAAAJ",
      "CSzbLwUAAAAJ",
      "j6eVlwsAAAAJ",
      "N0x7TRcAAAAJ",
      "myYVVuYAAAAJ",
      "bfec5vAAAAAJ",
      "xViwZ0QAAAAJ",
      "IRyM3b8AAAAJ",
      "P28bgJMAAAAJ",
      "UsqNPH4AAAAJ",
      "XeEA6r8AAAAJ",
      "hYi6i9sAAAAJ",
      "V64dmUAAAAAJ",
      "F9kSTM0AAAAJ",
      "ieyW4WQAAAAJ",
      "v7kFHRoAAAAJ",
      "uUuq67cAAAAJ",
      "kSnFGqkAAAAJ",
      "dpLLZIAAAAAJ",
      "4SlTNbAAAAAJ",
      "oVxK8g0AAAAJ",
      "TxKNCSoAAAAJ",
      "yFEHsv4AAAAJ",
      "IZC7zeUAAAAJ",
      "6pR07RQAAAAJ",
      "1hXyfIkAAAAJ",
      "dXBtN0cAAAAJ",
      "mhpaapIAAAAJ",
      "OcbAkXwAAAAJ",
      "v84tWxsAAAAJ",
      "Mfrpm_IAAAAJ",
      "eGIw04UAAAAJ",
      "Bri9R_4AAAAJ",
      "zBdo-BoAAAAJ",
      "RZueBXQAAAAJ",
      "w4yTWwoAAAAJ",
      "1YjIvioAAAAJ",
      "DQOT0OMAAAAJ",
      "68y3nvYAAAAJ",
      "XO8T-Y4AAAAJ",
      "iSFDVj4AAAAJ",
      "AjKdHVMAAAAJ",
      "L9ztLe8AAAAJ",
      "1RGui4wAAAAJ",
      "R71GD9MAAAAJ",
      "bOlnJwcAAAAJ",
      "QmP0ggQAAAAJ",
      "7e456ToAAAAJ",
      "1JQDH_AAAAAJ",
      "9dAjSlYAAAAJ",
      "DCP9rQgAAAAJ",
      "LDur_VYAAAAJ",
      "xBJ-7n4AAAAJ",
      "MtqfTRYAAAAJ",
      "B88-PigAAAAJ",
      "lWzkIg4AAAAJ",
      "0JA37SgAAAAJ",
      "iWmtv7gAAAAJ",
      "DSfv69oAAAAJ",
      "rQ0Zl50AAAAJ",
      "uH5WA4oAAAAJ",
      "1e_R-xoAAAAJ",
      "7SgUlggAAAAJ",
      "UMKkDVwAAAAJ",
      "N1yNDnQAAAAJ",
      "QxLpghAAAAAJ",
      "R41MlbcAAAAJ",
      "0ZXfitAAAAAJ",
      "TiDGyF4AAAAJ",
      "roFM8XsAAAAJ",
      "ptAR7tUAAAAJ",
      "JHwivywAAAAJ",
      "BiCxWC0AAAAJ",
      "VxpypngAAAAJ",
      "NfvUWXgAAAAJ",
      "OKZC1CYAAAAJ",
      "NvjazjgAAAAJ",
      "1UEU5PEAAAAJ",
      "fNl-ZkIAAAAJ",
      "MyPTNBgAAAAJ",
      "bYMpSOMAAAAJ",
      "7CH_3FwAAAAJ",
      "wMcK4TQAAAAJ",
      "4gVbilMMp-AC",
      "8Qu_gAMAAAAJ",
      "uvZ63bMAAAAJ",
      "niCbywQAAAAJ",
      "TfInmkIAAAAJ",
      "Ixg9n-EAAAAJ",
      "DgLEyZgAAAAJ",
      "SgbbTp4AAAAJ",
      "s2Ibok8AAAAJ",
      "kwTTDPMAAAAJ",
      "6CTPn44AAAAJ",
      "6KgM0OkAAAAJ",
      "VseAjdcAAAAJ",
      "B_FTboQAAAAJ",
      "pvyI8GkAAAAJ",
      "LaLilZ8AAAAJ",
      "MrWIWNwAAAAJ",
      "YTQnGJsAAAAJ",
      "kFyna0YAAAAJ",
      "xPSkgtIAAAAJ",
      "e38fTZQAAAAJ",
      "kddKBCsAAAAJ",
      "nb8wjsoAAAAJ",
      "M1aIpoIAAAAJ",
      "-Yge2L0AAAAJ",
      "q3AmlWMAAAAJ",
      "Kbi2t9sAAAAJ",
      "LnhCGNMAAAAJ",
      "XaYJrgoAAAAJ",
      "jb__2PIAAAAJ",
      "bh-uRFMAAAAJ",
      "n01L0mEAAAAJ",
      "LPAZlL8AAAAJ",
      "MOgfm8oAAAAJ",
      "b4NaZMoAAAAJ",
      "1jgwWYAAAAAJ",
      "KA4xjHMAAAAJ",
      "YHxZLlwAAAAJ",
      "a58cNycAAAAJ",
      "UKqIqRsAAAAJ",
      "YaBPvxAAAAAJ",
      "J6LkBeUAAAAJ",
      "xf1T870AAAAJ",
      "DvbPrWYAAAAJ",
      "O5jENBMAAAAJ",
      "HcB81j4AAAAJ",
      "VNSzxhUAAAAJ",
      "pyBSGjgAAAAJ",
      "ARmXjpcAAAAJ",
      "R5q_E8wAAAAJ",
      "3Zb5Y2YAAAAJ",
      "-fPI9LgAAAAJ",
      "5Qp_0TUAAAAJ",
      "ZPmHxbsAAAAJ",
      "GnpHmO8AAAAJ",
      "Mtho-7EAAAAJ",
      "NqkgsjoAAAAJ",
      "Ize17HEAAAAJ",
      "EaYZfmoAAAAJ",
      "TJEUdh4AAAAJ",
      "ubAcojQAAAAJ",
      "g6MislAAAAAJ",
      "dNHNpxoAAAAJ",
      "Jz1O6loAAAAJ",
      "hhm6ZzUAAAAJ",
      "ZQ1Bbb8AAAAJ",
      "f1lspM0AAAAJ",
      "VOf45S0AAAAJ",
      "-aNI9zwAAAAJ",
      "hkCVqYkAAAAJ",
      "xOWBOKQAAAAJ",
      "xlOEqOEAAAAJ",
      "j4DDmQ0AAAAJ",
      "VIu8KZfWuM0C",
      "jYCidWgAAAAJ",
      "C-5j7CQAAAAJ",
      "aKkIMogAAAAJ",
      "BEFl4j0AAAAJ",
      "QXyvv94AAAAJ",
      "vrqzitkAAAAJ",
      "9LcxwsMAAAAJ",
      "1HO5UacAAAAJ",
      "OVRxQj8AAAAJ",
      "yj2b7pgAAAAJ",
      "0w0Dy34AAAAJ",
      "OI0HSa0AAAAJ",
      "XD_01h8AAAAJ",
      "-x3wvW8AAAAJ",
      "DTthB48AAAAJ",
      "AiH3_CkAAAAJ",
      "r8Zh-jwAAAAJ",
      "feURfe4AAAAJ",
      "QZW0vl8AAAAJ",
      "52T2LYoAAAAJ",
      "vPnu7C4AAAAJ",
      "dbWhFN4AAAAJ",
      "D6nN2NcAAAAJ",
      "5KZ-7BAAAAAJ",
      "GI5Dse8AAAAJ",
      "b7JHXbgAAAAJ",
      "IdkhB44AAAAJ",
      "V8GEfeAAAAAJ",
      "25HL3QcAAAAJ",
      "NrOA9QoAAAAJ",
      "ra1iQ8cAAAAJ",
      "qcyG7rwAAAAJ",
      "K29Sv1EAAAAJ",
      "iGgf9KwAAAAJ",
      "2z2camUAAAAJ",
      "jplQac8AAAAJ",
      "tmZ8MaAAAAAJ",
      "f7upZyAAAAAJ",
      "Zdl00bEAAAAJ",
      "jPD85m0AAAAJ",
      "s4I2aDgAAAAJ",
      "AYaHBAQAAAAJ",
      "kbZqRLkAAAAJ",
      "9tI89HMAAAAJ",
      "56vtsXMAAAAJ",
      "JpoFnJQAAAAJ",
      "zl0AOEgAAAAJ",
      "CQ39OowAAAAJ",
      "K-KlWSsAAAAJ",
      "hfZRGpgAAAAJ",
      "TXqPY5IAAAAJ",
      "2DzkuhQAAAAJ",
      "H8yqlRYAAAAJ",
      "ucSLToQAAAAJ",
      "FuGllAwAAAAJ",
      "PRhJB5EAAAAJ",
      "XZrEn1sAAAAJ",
      "TJVj26YAAAAJ",
      "8ihSLrwAAAAJ",
      "b7w97acAAAAJ",
      "RUWfW-kAAAAJ",
      "QJu--ysAAAAJ",
      "K4_TvQQAAAAJ",
      "Zjshth4AAAAJ",
      "ovgLRIIAAAAJ",
      "YqKbGXAAAAAJ",
      "6vQmgzcAAAAJ",
      "v8PeLGgAAAAJ",
      "mXtH1UYAAAAJ",
      "fhLHgd8AAAAJ",
      "orVoz4IAAAAJ",
      "Xy1QFMAAAAAJ",
      "H02tLFMAAAAJ",
      "8iCb2TwAAAAJ",
      "UoATnWEAAAAJ",
      "AGaoCGAAAAAJ",
      "OvKEnVwAAAAJ",
      "OnVgcOkAAAAJ",
      "bHn29ScAAAAJ",
      "-xA1_OAAAAAJ",
      "QQHXl9sAAAAJ",
      "Y04UhM4AAAAJ",
      "sYTUOu8AAAAJ",
      "2ylcZSsAAAAJ",
      "5rjfy4AAAAAJ",
      "-ki9u4sAAAAJ",
      "dqN-sYkAAAAJ",
      "WDB4HqIAAAAJ",
      "fWVzdOcAAAAJ",
      "fDW6YA0AAAAJ",
      "dB4mKx4AAAAJ",
      "sbBPoc0AAAAJ",
      "XlqTD2UAAAAJ",
      "JQ939pQAAAAJ",
      "XT3E7RoAAAAJ",
      "kFduPiIAAAAJ",
      "t4rgICIAAAAJ",
      "8Ut6gTcAAAAJ",
      "urQ9fNgAAAAJ",
      "1zmDOdwAAAAJ",
      "6_oL_9IAAAAJ",
      "_fVZiToAAAAJ",
      "FTe6HDoAAAAJ",
      "5HACNJ0AAAAJ",
      "9HCmTcwAAAAJ",
      "odOmEY0AAAAJ",
      "pxSj9JkAAAAJ",
      "-novlhIAAAAJ",
      "E5GfpA4AAAAJ",
      "a_OQrYoAAAAJ",
      "__CwaPMAAAAJ",
      "p1HAb2QAAAAJ",
      "gMOBKfUAAAAJ",
      "VMihW8oAAAAJ",
      "iOLC30YAAAAJ",
      "zO6kmIAAAAAJ",
      "XbjOzyQAAAAJ",
      "2xjjS3oAAAAJ",
      "R-7TkKkAAAAJ",
      "vZkXCcsAAAAJ",
      "6mxddyMAAAAJ",
      "j3CEIuEAAAAJ",
      "AVDkgFIAAAAJ",
      "5ReVSa8AAAAJ",
      "uHDiAKQAAAAJ",
      "wFkXSlYAAAAJ",
      "GazEl1wAAAAJ",
      "U_IVY50AAAAJ",
      "Ml_vQ8MAAAAJ",
      "VUi7eM8AAAAJ",
      "hWzXZUMAAAAJ",
      "auA1nNAAAAAJ",
      "57BFBY0AAAAJ",
      "24Ke6Q8AAAAJ",
      "9huOSj4AAAAJ",
      "yE4WT_0AAAAJ",
      "o3nJb1EAAAAJ",
      "MV8KGT0AAAAJ",
      "kV4N4zoAAAAJ",
      "0P35aLUAAAAJ",
      "5qo8bOkAAAAJ",
      "xhUvqK8AAAAJ",
      "w_wosd4AAAAJ",
      "Zldo9CAAAAAJ",
      "Ecy6lXwAAAAJ",
      "vZHanWgAAAAJ",
      "Dxiw1K8AAAAJ",
      "dYt8FGcAAAAJ",
      "gO-31VYAAAAJ",
      "K__JmtcAAAAJ",
      "puDkuLoAAAAJ",
      "B3Xd8-kAAAAJ",
      "OENNEBIAAAAJ",
      "5vSCuk0AAAAJ",
      "haCXENgAAAAJ",
      "d7fUTNIAAAAJ",
      "DiBVENwAAAAJ",
      "YOrLGyAAAAAJ",
      "GW9vw8UAAAAJ",
      "MU5tFcQAAAAJ",
      "SupjsEUAAAAJ",
      "guJ_kBQAAAAJ",
      "UvNbBnEAAAAJ",
      "kQ-axIUAAAAJ",
      "1zCDX_UAAAAJ",
      "_M5OBVkAAAAJ",
      "Mf9VHRcAAAAJ",
      "xByATywAAAAJ",
      "34eszXwAAAAJ",
      "oQ5FSggAAAAJ",
      "acmtRMAAAAAJ",
      "Sd8mmE0AAAAJ",
      "mE1vlGEAAAAJ",
      "7U_OA0oAAAAJ",
      "HMyXWb4AAAAJ",
      "PGyMqU0AAAAJ",
      "g_zaiVIAAAAJ",
      "kjMNMLkAAAAJ",
      "fVcFAiIAAAAJ",
      "OV1Y3FUAAAAJ",
      "nxXheggAAAAJ",
      "1ir6WUEAAAAJ",
      "Oa3Aze8AAAAJ",
      "zP0S_ikAAAAJ",
      "DzeJ67UAAAAJ",
      "-6cOYcYAAAAJ",
      "nuyBlicAAAAJ",
      "NzLGjWoAAAAJ",
      "XcQ9WqMAAAAJ",
      "YR1EmaAAAAAJ",
      "Om4Lag0AAAAJ",
      "6cuNVagAAAAJ",
      "b-GJ3QIAAAAJ",
      "CRWJFnwAAAAJ",
      "rEjgIskAAAAJ",
      "ApKpgeMAAAAJ",
      "Tw2m5kUAAAAJ",
      "AOGTQn0AAAAJ",
      "dI-eZ3sAAAAJ",
      "MV7LPnEAAAAJ",
      "-KzSL30AAAAJ",
      "IuMFxFUAAAAJ",
      "jUt50EcAAAAJ",
      "fE3FSqIAAAAJ",
      "ZoW-xfcAAAAJ",
      "AfLwLQ0AAAAJ",
      "L8HAaJYAAAAJ",
      "k5FaRwcAAAAJ",
      "bKlSszcAAAAJ",
      "Dfzm6hsAAAAJ",
      "RdPknzsAAAAJ",
      "dlm2DaAAAAAJ",
      "UB5EoOEAAAAJ",
      "7LcGErsAAAAJ",
      "RrYw5jkAAAAJ",
      "wP0IgaAAAAAJ",
      "fMgMCaoAAAAJ",
      "1TV1xrMAAAAJ",
      "jUtYwE0AAAAJ",
      "7nVGYfgAAAAJ",
      "p_837e0AAAAJ",
      "VeTSl0wAAAAJ",
      "G9DVxcQAAAAJ",
      "aCQjyp0AAAAJ",
      "Ih29F_QAAAAJ",
      "uOIgTt8AAAAJ",
      "_92oJ8IAAAAJ",
      "S8Ov5d8AAAAJ",
      "_Wb6s7cAAAAJ",
      "eJISgYQAAAAJ",
      "jrazNCQAAAAJ",
      "r2nw6DIAAAAJ",
      "G0LfNJcAAAAJ",
      "0b_e2eAAAAAJ",
      "c_E3E4kAAAAJ",
      "9gV4DRsAAAAJ",
      "APgaFK0AAAAJ",
      "9e7BtYsAAAAJ",
      "BsOkXDsAAAAJ",
      "Vz8AQ6oAAAAJ",
      "FMDCrXMAAAAJ",
      "1wLVDP4AAAAJ",
      "4-ccLwEAAAAJ",
      "5nn3fN0AAAAJ",
      "-hW6cvgAAAAJ",
      "D1EmzeoAAAAJ",
      "HF2G3LAAAAAJ",
      "mqpjAt4AAAAJ",
      "S9xCl8EAAAAJ",
      "ADxG8S4AAAAJ",
      "0dIBL4AAAAAJ",
      "dMjagUIAAAAJ",
      "NKtRqvYAAAAJ",
      "hbriwLcAAAAJ",
      "CdJ2xRIAAAAJ",
      "8t3Ex0QAAAAJ",
      "l7GidmgAAAAJ",
      "zIjCVzAAAAAJ",
      "KyNwquYAAAAJ",
      "1TDqUuwAAAAJ",
      "DO3quJYAAAAJ",
      "MKRyHXsAAAAJ",
      "FpaKuysAAAAJ",
      "L82mYv8AAAAJ",
      "aXdjxb4AAAAJ",
      "Oz9MLlEAAAAJ",
      "HPoaHyQAAAAJ",
      "1TqAq5AAAAAJ",
      "x_OUOncAAAAJ",
      "Hz4oXAYAAAAJ",
      "C3s1jqIAAAAJ",
      "Q93u3c0AAAAJ",
      "vYRgxJ8AAAAJ",
      "mQf5cE0AAAAJ",
      "lT3YoNkAAAAJ",
      "b-o1o7cAAAAJ",
      "4eloUCwAAAAJ",
      "iIFHZ1UAAAAJ",
      "Wbwt1JgAAAAJ",
      "YrihYtsAAAAJ",
      "46MDvXcAAAAJ",
      "UqtDdZUAAAAJ",
      "Zrs0wpEAAAAJ",
      "NEBWPbsAAAAJ",
      "GQdnFXQAAAAJ",
      "N2M9RPoAAAAJ",
      "iwBPvPIAAAAJ",
      "BgOXDogAAAAJ",
      "pxFyKAIAAAAJ",
      "5XqE3bQAAAAJ",
      "agcYx2YAAAAJ",
      "TOzQO_UAAAAJ",
      "E9ITYW0AAAAJ",
      "Njlo7WAAAAAJ",
      "6THqxEoAAAAJ",
      "ZzJO3UkAAAAJ",
      "AP_Yd6wAAAAJ",
      "oQyYH9kAAAAJ",
      "RikRyq4AAAAJ",
      "73IbXtsAAAAJ",
      "xDNZlnMAAAAJ",
      "jabdPAwAAAAJ",
      "fKcFF-gAAAAJ",
      "SgGIYH0AAAAJ",
      "nkTd_BIAAAAJ",
      "p7mehDEAAAAJ",
      "5bQjLz4AAAAJ",
      "PR2DwYYAAAAJ",
      "oE6XwXsAAAAJ",
      "mrMYnBEAAAAJ",
      "rIh5OqoAAAAJ",
      "-ihQeTYAAAAJ",
      "lmsiq6oAAAAJ",
      "S7YR2MEAAAAJ",
      "nkmDOPgAAAAJ",
      "fDvQyegAAAAJ",
      "rZ0mlMYAAAAJ",
      "0DD8EREAAAAJ",
      "qWrXkPwAAAAJ",
      "-oy5DaIAAAAJ",
      "NzjKoWIAAAAJ",
      "nBwaXUsAAAAJ",
      "GnDGqKQAAAAJ",
      "XjltJv8AAAAJ",
      "_Uzh_ucAAAAJ",
      "m8m9nD0AAAAJ",
      "d3UtiX8AAAAJ",
      "vcGuNDYAAAAJ",
      "vIqWvgwAAAAJ",
      "YkWi5xoAAAAJ",
      "8TIMnwEAAAAJ",
      "7agkJogAAAAJ",
      "ZN0NeWMAAAAJ",
      "Yu_0vEEAAAAJ",
      "ZlE1X8IAAAAJ",
      "j98IWfoAAAAJ",
      "eXqOR10AAAAJ",
      "dJg1TUEAAAAJ",
      "eLZ_clAAAAAJ",
      "_kOUMXoAAAAJ",
      "3Q5zpJwAAAAJ",
      "1H2H7XAAAAAJ",
      "WaGlwJ4AAAAJ",
      "eO2xkdMAAAAJ",
      "IolN_okAAAAJ",
      "IuOS8TkAAAAJ",
      "lL3KYmMAAAAJ",
      "83HL5FwAAAAJ",
      "dB6ftCcAAAAJ",
      "CulluAgAAAAJ",
      "QIRWZf8AAAAJ",
      "V9JYPP0AAAAJ",
      "fHsIRb0AAAAJ",
      "9RlvgLEAAAAJ",
      "ZaJEZpYAAAAJ",
      "T1RxzcUAAAAJ",
      "qAWS07wAAAAJ",
      "AkEXTbIAAAAJ",
      "l0Bj7U8AAAAJ",
      "1r8HluQAAAAJ",
      "khZgnWYAAAAJ",
      "ny7iUz4AAAAJ",
      "AFD2rD4AAAAJ",
      "TaF4L4EAAAAJ",
      "0qxCVx8AAAAJ",
      "NILVLIAAAAAJ",
      "WMHRQ-8AAAAJ",
      "WxZ_6nsAAAAJ",
      "66s6LkAAAAAJ",
      "DdCAbWwAAAAJ",
      "umivlPQAAAAJ",
      "-GduGkcAAAAJ",
      "6oqV3v8AAAAJ",
      "HXowq5YAAAAJ",
      "PmrXZ8oAAAAJ",
      "8PUwH9gAAAAJ",
      "WBeDvikAAAAJ",
      "ax3nTU8AAAAJ",
      "iSL1cKsAAAAJ",
      "ZZP1cXYAAAAJ",
      "_A7rrswAAAAJ",
      "jkDd-3QAAAAJ",
      "wctJ37UAAAAJ",
      "Km0qjY8AAAAJ",
      "2trZ2IYAAAAJ",
      "nh5a4LQAAAAJ",
      "D2VLt-8AAAAJ",
      "2s9_ZWgAAAAJ",
      "nM77MX0AAAAJ",
      "OpAiiOAAAAAJ",
      "5gi3Pm0AAAAJ",
      "MeZLMbkAAAAJ",
      "rbGxNYwAAAAJ",
      "UetM7FgAAAAJ",
      "nq7tuDkAAAAJ",
      "8NamuusAAAAJ",
      "r31_fYQAAAAJ",
      "MY1FRYUAAAAJ",
      "cPcOoY4AAAAJ",
      "aN4IwM4AAAAJ",
      "lS0tvhoAAAAJ",
      "U6BRIM4AAAAJ",
      "YtAIQ34AAAAJ",
      "GN_9dYIAAAAJ",
      "6vghMS0AAAAJ",
      "X6fRNfUAAAAJ",
      "DaDmjMMAAAAJ",
      "_JjIgGcAAAAJ",
      "U8qAL-0AAAAJ",
      "xgQd1qgAAAAJ",
      "OqUlGZwAAAAJ",
      "1ytghtEAAAAJ",
      "OWDai70AAAAJ",
      "QwL4z2UAAAAJ",
      "SC9wV2kAAAAJ",
      "v3VmgekAAAAJ",
      "1pMBYn8AAAAJ",
      "WH2KmRgAAAAJ",
      "O-29z5AAAAAJ",
      "FZuNgqIAAAAJ",
      "orxu07YAAAAJ",
      "FH9nKOAAAAAJ",
      "x34kIOIAAAAJ",
      "Vt1j3kEAAAAJ",
      "By1xdxEAAAAJ",
      "0J6vYkEAAAAJ",
      "tu9gL58AAAAJ",
      "STHWcmIAAAAJ",
      "n4pWU_0AAAAJ",
      "lLqTCtUAAAAJ",
      "rHF25YEAAAAJ",
      "2IEoTWwAAAAJ",
      "YYRnhTkAAAAJ",
      "4aqK_74AAAAJ",
      "cVHKEaoAAAAJ",
      "k8Px6S8AAAAJ",
      "Wdo9AyQAAAAJ",
      "T8LkBTYAAAAJ",
      "zSdOp4EAAAAJ",
      "SHQikPwAAAAJ",
      "-zlRjYcAAAAJ",
      "CMIgrCgAAAAJ",
      "LQLq8eEAAAAJ",
      "WlWma8EAAAAJ",
      "Uo0aIHAAAAAJ",
      "t2eNzb8AAAAJ",
      "M7edePUAAAAJ",
      "0ret4cUAAAAJ",
      "CRclm5cAAAAJ",
      "zVAYbpYAAAAJ",
      "UJcm1MoAAAAJ",
      "Oj-2ZNEAAAAJ",
      "HuQF6AsAAAAJ",
      "1qmAFhsAAAAJ",
      "FLcpd34AAAAJ",
      "U0ZjG84AAAAJ",
      "r4ldy4AAAAAJ",
      "f1hBi5wAAAAJ",
      "fXPO6U0AAAAJ",
      "wmpvU_YAAAAJ",
      "U0egIsIAAAAJ",
      "-BO7TXUAAAAJ",
      "gZGtgS4AAAAJ",
      "hwQtFB0AAAAJ",
      "y_4JsmcAAAAJ",
      "d_OCVbEAAAAJ",
      "01II9NsAAAAJ",
      "6sWGL5wAAAAJ",
      "2hjbResAAAAJ",
      "wBu1J2MAAAAJ",
      "WmFoofMAAAAJ",
      "1CLaPMEAAAAJ",
      "FBVwO5wAAAAJ",
      "_-5PSgQAAAAJ",
      "UPvWSMYAAAAJ",
      "7cqQFSoAAAAJ",
      "11tt6p4AAAAJ",
      "9CW-7GAAAAAJ",
      "grsfoH8AAAAJ",
      "KbVFiKYAAAAJ",
      "EP_omZQAAAAJ",
      "tW21GGYAAAAJ",
      "0DpK1EMAAAAJ",
      "oC7EgKQAAAAJ",
      "8MJh6JcAAAAJ",
      "x9K3GqkAAAAJ",
      "h8u3ll8AAAAJ",
      "GNBB3JQAAAAJ",
      "1GjHPkcAAAAJ",
      "O9djN1AAAAAJ",
      "fiM8AFsAAAAJ",
      "7cNE8rkAAAAJ",
      "Ag_6KEgAAAAJ",
      "wwswAvEAAAAJ",
      "sIfE5HIAAAAJ",
      "KVPQoQgAAAAJ",
      "KBHW5wsAAAAJ",
      "N5rG_E0AAAAJ",
      "ZNE6TqsAAAAJ",
      "HqTUx7YAAAAJ",
      "bniKGtgAAAAJ",
      "pPaf4pkAAAAJ",
      "QdlhnBMAAAAJ",
      "CKXeqHoAAAAJ",
      "l_pScqkAAAAJ",
      "EWY1qlkAAAAJ",
      "dNRKN3wAAAAJ",
      "MoX2ERkAAAAJ",
      "8sGC5D4AAAAJ",
      "4dPt9-4AAAAJ",
      "yp4Gk3kAAAAJ",
      "l7X99s0AAAAJ",
      "b-JF-UIAAAAJ",
      "bkALdvsAAAAJ",
      "hczHVxEAAAAJ",
      "avud6aAAAAAJ",
      "5Ec8ENMAAAAJ",
      "V8fBl-0AAAAJ",
      "9b64ixMAAAAJ",
      "whdanWAAAAAJ",
      "nQjxbScAAAAJ",
      "IKUm624AAAAJ",
      "t3l8q6gAAAAJ",
      "v3JsjMYAAAAJ",
      "lm55cKIAAAAJ",
      "UliV3XQAAAAJ",
      "A20BZnQAAAAJ",
      "klWjaQIAAAAJ",
      "NACSmGwAAAAJ",
      "SvmrjK4AAAAJ",
      "a8Y2OJMAAAAJ",
      "tKSxEgQAAAAJ",
      "szP4pC0AAAAJ",
      "1rDKD9kAAAAJ",
      "yV_Ws-QAAAAJ",
      "kXkHRK4AAAAJ",
      "mZM5KHIAAAAJ",
      "dvz7WRQAAAAJ",
      "gOUeu2IAAAAJ",
      "P2VyO-YAAAAJ",
      "WS2-qlAAAAAJ",
      "OejqtPoAAAAJ",
      "4vJ6wLMAAAAJ",
      "LlfHFqUAAAAJ",
      "FkufKDgAAAAJ",
      "EhCg54EAAAAJ",
      "bYI7VMwAAAAJ",
      "iZpSjEYAAAAJ",
      "QHVdvtUAAAAJ",
      "wHHgs8UAAAAJ",
      "pAiIxxkAAAAJ",
      "YvjuUugAAAAJ",
      "tjb2UccAAAAJ",
      "cZBq_9MAAAAJ",
      "pS-idGwAAAAJ",
      "STftvjoAAAAJ",
      "EpLo4l4AAAAJ",
      "xBX234cAAAAJ",
      "fbVyT0QAAAAJ",
      "RG9pwnUAAAAJ",
      "4HLUnhIAAAAJ",
      "x5QTK9YAAAAJ",
      "k9IJYg8AAAAJ",
      "bIUsRBQAAAAJ",
      "jHgmQEIAAAAJ",
      "AjX6hisAAAAJ",
      "cI0dYX4AAAAJ",
      "wQU1dJAAAAAJ",
      "Y3wdd8oAAAAJ",
      "ErkEIHkAAAAJ",
      "dzP4uYEAAAAJ",
      "T645IqsAAAAJ",
      "M4AKMC4AAAAJ",
      "KG0pbOYAAAAJ",
      "gX8LBfgAAAAJ",
      "9IRFiEQAAAAJ",
      "q9g_OlwAAAAJ",
      "lsFo_DcAAAAJ",
      "_b_LTjMAAAAJ",
      "5mnT2ocAAAAJ",
      "4kOdChQAAAAJ",
      "0M99MEYAAAAJ",
      "L_m67ywAAAAJ",
      "kc_fImQAAAAJ",
      "EIw2QBsAAAAJ",
      "C7dO_UgAAAAJ",
      "EysbmrUAAAAJ",
      "E42NyKUAAAAJ",
      "h6eAkFwAAAAJ",
      "23sOkXYAAAAJ",
      "02nHF0gAAAAJ",
      "aC55XVgAAAAJ",
      "Nq0dVMcAAAAJ",
      "w-xdg4sAAAAJ",
      "GkXqbmMAAAAJ",
      "Ut6nPD8AAAAJ",
      "5QYHMpsAAAAJ",
      "PgGOyOUAAAAJ",
      "PYZ_Xb0AAAAJ",
      "IyGPTacAAAAJ",
      "GX-PtukAAAAJ",
      "xt3XLjcAAAAJ",
      "sCuACdkAAAAJ",
      "ABSaf6IAAAAJ",
      "qULx8g8AAAAJ",
      "rWg9lSsAAAAJ",
      "dfScyQgAAAAJ",
      "fwVWk9UAAAAJ",
      "Khb7qw8AAAAJ",
      "ujDhg2sAAAAJ",
      "vN2ALVYAAAAJ",
      "ZLyJRxoAAAAJ",
      "Ik6TGDAAAAAJ",
      "v5TPCXFtkUgC",
      "siuZCjUAAAAJ",
      "YnJVsp4AAAAJ",
      "vCHNxFcAAAAJ",
      "15GNzKcAAAAJ",
      "m9I8jgcAAAAJ",
      "quhI7uQAAAAJ",
      "w6RxCIkAAAAJ",
      "l8RaE9YAAAAJ",
      "N_YNMIMAAAAJ",
      "vyX6kpwAAAAJ",
      "1azFZ6cAAAAJ",
      "rJ-biB0AAAAJ",
      "es9clvEAAAAJ",
      "1OSj0wkAAAAJ",
      "ErVxNWkAAAAJ",
      "pIoPb7sAAAAJ",
      "h6jljQQAAAAJ",
      "-1iyBukAAAAJ",
      "zZNKHdEAAAAJ",
      "eF5vfBAAAAAJ",
      "1UNlyTcAAAAJ",
      "6SDclmEAAAAJ",
      "3WJN5csAAAAJ",
      "bYjKaowAAAAJ",
      "gqkpV2kAAAAJ",
      "7QmEsOwAAAAJ",
      "jfOVNcUAAAAJ",
      "IJ1yaGsAAAAJ",
      "QSQuvHYAAAAJ",
      "GaYmpIgAAAAJ",
      "VzkoqhIAAAAJ",
      "AVT2-U4AAAAJ",
      "Dzh5C9EAAAAJ",
      "9r_f1w4AAAAJ",
      "5c30hccAAAAJ",
      "LltfiXgAAAAJ",
      "8h3AFugAAAAJ",
      "oO53gjEAAAAJ",
      "IFZY5fMAAAAJ",
      "TyfMgeQAAAAJ",
      "V3JjNJ0AAAAJ",
      "ozaKHIIAAAAJ",
      "Kv2pL8YAAAAJ",
      "V358UyMAAAAJ",
      "WYTugmIAAAAJ",
      "GqZBmfgAAAAJ",
      "68V-nNAAAAAJ",
      "37lzFAoAAAAJ",
      "dgBh0UMAAAAJ",
      "t5zdD_IAAAAJ",
      "4gE_vYgAAAAJ",
      "78Z4ctAAAAAJ",
      "hYKcn9sAAAAJ",
      "vNcBx1sAAAAJ",
      "5t2myD8AAAAJ",
      "rxg0zB4AAAAJ",
      "f0Wc8tkAAAAJ",
      "w19KkekAAAAJ",
      "LVPkbeYAAAAJ",
      "Ouu9Zv0AAAAJ",
      "4fN_h5QAAAAJ",
      "U7yzfCkAAAAJ",
      "P-md_yYAAAAJ",
      "juUEPSAAAAAJ",
      "yhGqdMgAAAAJ",
      "IzhtPq4AAAAJ",
      "d0KQ9z0AAAAJ",
      "V7aWNcoAAAAJ",
      "2m-p8FcAAAAJ",
      "eP6FHFAAAAAJ",
      "Q21P3fsAAAAJ",
      "CPye2b4AAAAJ",
      "nKSXus4AAAAJ",
      "hy-qH-cAAAAJ",
      "Ml6RzmEAAAAJ",
      "18exh0MAAAAJ",
      "zUJus70AAAAJ",
      "wHAYz5wAAAAJ",
      "VzJAvWEAAAAJ",
      "0oIAvO8AAAAJ",
      "PBvgcC8AAAAJ",
      "XnUZEcoAAAAJ",
      "WQ0PktMAAAAJ",
      "02FGPmwAAAAJ",
      "q__pgY9AkUQJ",
      "egq785sAAAAJ",
      "YTokrfkAAAAJ",
      "3pyzQQ8AAAAJ",
      "-A4wqWEAAAAJ",
      "9W1jAhEAAAAJ",
      "2YKaNDIAAAAJ",
      "4MrZ9zMAAAAJ",
      "H8FOdHwAAAAJ",
      "AU5d1KUAAAAJ",
      "zaF8UJcAAAAJ",
      "4g-njrYAAAAJ",
      "8twuSywAAAAJ",
      "VN0X-PcAAAAJ",
      "-GnCn1MAAAAJ",
      "vKAKE1gAAAAJ",
      "LIG-4BcAAAAJ",
      "3HSzhHoAAAAJ",
      "VSc-eTAAAAAJ",
      "l9Or8EMAAAAJ",
      "_PZKLYUAAAAJ",
      "Gwrwxa0AAAAJ",
      "F_MI0pcAAAAJ",
      "BU79wO4AAAAJ",
      "6Wg-hF4AAAAJ",
      "KQaf5-wAAAAJ",
      "wJ8seI8AAAAJ",
      "5u4IlBYAAAAJ",
      "dWKDuxcAAAAJ",
      "mWhnaCkAAAAJ",
      "Mp1C17IAAAAJ",
      "Ji-VV2cAAAAJ",
      "Gv4kyjQAAAAJ",
      "oeg_NN4AAAAJ",
      "oH7drVcAAAAJ",
      "T2UHRgoAAAAJ",
      "bqP_zxYAAAAJ",
      "gbY_w1IAAAAJ",
      "Arl0IwUAAAAJ",
      "G0x9hZkAAAAJ",
      "bZVkVvoAAAAJ",
      "a-ifJKsAAAAJ",
      "U9EvD0wAAAAJ",
      "3_002c0AAAAJ",
      "YgSxvV4AAAAJ",
      "UY7CtEwAAAAJ",
      "-84M1m0AAAAJ",
      "VZ6S70MAAAAJ",
      "WhEIQD0AAAAJ",
      "cAwC5EQAAAAJ",
      "H8tlV-oAAAAJ",
      "tjNPA04AAAAJ",
      "4Fw2ma4AAAAJ",
      "vOur3Q4AAAAJ",
      "yhpAb1YAAAAJ",
      "SDavuPAAAAAJ",
      "9g4PcV8AAAAJ",
      "rQ68pVwAAAAJ",
      "vK0-CDcAAAAJ",
      "Za7uka8AAAAJ",
      "Cz-Q_IsAAAAJ",
      "1JvIQ8EAAAAJ",
      "_Ic8wQ4AAAAJ",
      "jhyC8TsAAAAJ",
      "7ov4UekAAAAJ",
      "xkLdn4gAAAAJ",
      "neGbgzYAAAAJ",
      "568MtVQAAAAJ",
      "2BTuWpgAAAAJ",
      "dGKi9Q4AAAAJ",
      "okLwXk0AAAAJ",
      "0iktJ5sAAAAJ",
      "OeDgxpgAAAAJ",
      "pihC5CkAAAAJ",
      "5GavKiQAAAAJ",
      "rM7Dm0wAAAAJ",
      "KFQERBwAAAAJ",
      "b_RBE3EAAAAJ",
      "_3bbpWoAAAAJ",
      "lZKlDFcAAAAJ",
      "8hIYYuEAAAAJ",
      "4sontAIAAAAJ",
      "dVZuASAAAAAJ",
      "MYsIXF4AAAAJ",
      "WYkBdO0AAAAJ",
      "dHboSOoAAAAJ",
      "ATj2IF4AAAAJ",
      "k1eaag4AAAAJ",
      "DWERCmsAAAAJ",
      "qlwwdfEAAAAJ",
      "GL3GjBYAAAAJ",
      "VbNwxKYAAAAJ",
      "Mx8MbWYAAAAJ",
      "HYHTg_0AAAAJ",
      "gaiImbAAAAAJ",
      "eSPY7nMAAAAJ",
      "PDgp6OkAAAAJ",
      "Wewcpo4AAAAJ",
      "K-g2p4cAAAAJ",
      "h3SuftsAAAAJ",
      "vlDYiZoAAAAJ",
      "9QR0uE4AAAAJ",
      "4XMv5IoAAAAJ",
      "FGZ1CJsAAAAJ",
      "_TgGqhsAAAAJ",
      "v8QhiOwAAAAJ",
      "8xkg8pIAAAAJ",
      "m9vu99gAAAAJ",
      "BDmtLHsAAAAJ",
      "_7x84lgAAAAJ",
      "wYMTld8AAAAJ",
      "IQSbom0AAAAJ",
      "nRQi4O8AAAAJ",
      "T0qnS1oAAAAJ",
      "fDtoo50AAAAJ",
      "Q0YEc-QAAAAJ",
      "jEdhxGMAAAAJ",
      "UZIKgasAAAAJ",
      "hUWfaL0AAAAJ",
      "ZGmFXNsAAAAJ",
      "IAeKTGsAAAAJ",
      "54yrQIkAAAAJ",
      "8S0L-q8AAAAJ",
      "KhnebkgAAAAJ",
      "L4axvLoAAAAJ",
      "AMb1WywAAAAJ",
      "il-F8YYAAAAJ",
      "-y6SIhQAAAAJ",
      "9PVf18oAAAAJ",
      "P2oSOR0AAAAJ",
      "wh_eLqQAAAAJ",
      "rLI9DmoAAAAJ",
      "n2ohF50AAAAJ",
      "PTeSCbIAAAAJ",
      "B-4cOBMAAAAJ",
      "5z1iJjoAAAAJ",
      "2FbkAzYAAAAJ",
      "KZpZTTQAAAAJ",
      "xW33QlMAAAAJ",
      "7IwA14gAAAAJ",
      "KFhCWUcAAAAJ",
      "BpJTboUAAAAJ",
      "unQVOJkAAAAJ",
      "1bG8fLEAAAAJ",
      "Z_WrhK8AAAAJ",
      "MRYnqOEAAAAJ",
      "NC16W1kAAAAJ",
      "5NtH-JcAAAAJ",
      "mW2Jtu0AAAAJ",
      "8kHXJhAAAAAJ",
      "fgRMGc4AAAAJ",
      "RFcbxjoAAAAJ",
      "M-X3Q-UAAAAJ",
      "-gJkPHIAAAAJ",
      "mN6_BKAAAAAJ",
      "FfXcEGMAAAAJ",
      "eln2A94AAAAJ",
      "JWmiQR0AAAAJ",
      "0iieFBwAAAAJ",
      "6_i63vgAAAAJ",
      "0gJQCIgAAAAJ",
      "6FWSv1EAAAAJ",
      "1Oofk3YAAAAJ",
      "azE-Yq0AAAAJ",
      "6PnL3BgAAAAJ",
      "HvVqBmkAAAAJ",
      "1c1TsZ8AAAAJ",
      "HB6mzf0AAAAJ",
      "vhP-tlcAAAAJ",
      "m9UbvIkAAAAJ",
      "ivUi2T0AAAAJ",
      "9UAk6Y0AAAAJ",
      "duIUwpwAAAAJ",
      "w3GjGqoAAAAJ",
      "x942ipYAAAAJ",
      "Q10gid0AAAAJ",
      "QQVlcOUAAAAJ",
      "ijH0-a8AAAAJ",
      "YH1v2uYAAAAJ",
      "KNWPax8AAAAJ",
      "ARo4eW0AAAAJ",
      "NFWFaGAAAAAJ",
      "UeG5w08AAAAJ",
      "2B_o_MIAAAAJ",
      "ejsX7D0AAAAJ",
      "UKIdPdYAAAAJ",
      "z-KILD8AAAAJ",
      "jm6S_kEAAAAJ",
      "XnhYW0MAAAAJ",
      "tmKKPjkAAAAJ",
      "ysMAhlwAAAAJ",
      "i86O0SAAAAAJ",
      "BD8llAEAAAAJ",
      "WOrTFE0AAAAJ",
      "djRMREYAAAAJ",
      "3BMRzr8AAAAJ",
      "6ArMETUAAAAJ",
      "Fv9ag1YAAAAJ",
      "vgfGtykAAAAJ",
      "1Uk-ZIAAAAAJ",
      "6gd_QS0AAAAJ",
      "2_gFWe4AAAAJ",
      "2IvwHucAAAAJ",
      "Xc4IOBEAAAAJ",
      "DLzuuVoAAAAJ",
      "LfcroyAAAAAJ",
      "pUB0nnwhGVAC",
      "CHO-UV8AAAAJ",
      "tbxCHJgAAAAJ",
      "ilSYpW0AAAAJ",
      "gZ-RhocAAAAJ",
      "M93Auk4AAAAJ",
      "qArWV_wAAAAJ",
      "bDrXQPUAAAAJ",
      "ktqbPscAAAAJ",
      "7qTg_1kAAAAJ",
      "mQnBkmoAAAAJ",
      "BPFqibsAAAAJ",
      "WufbXzIAAAAJ",
      "LaPb8-YAAAAJ",
      "HriWXcEAAAAJ",
      "hwqQOpUAAAAJ",
      "0cAcheMAAAAJ",
      "8_lfEOsAAAAJ",
      "lWrAwrwAAAAJ",
      "eWbZJlMAAAAJ",
      "0wIdMGEAAAAJ",
      "Bmuft6wAAAAJ",
      "x7iwG1UAAAAJ"
    ]
  },
  "summary": {
    "total_authors": 12336,
    "input_authors_count": 14,
    "direct_co_authors_count": 604,
    "second_level_co_authors_count": 12275,
    "authors_with_abstracts": 610,
    "total_abstracts": 1781
  }
}