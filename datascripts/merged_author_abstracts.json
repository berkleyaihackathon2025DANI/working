{
  "input_authors": [
    "j8g1fe8AAAAJ",
    "8m8taGEAAAAJ",
    "AhgjQ2QAAAAJ",
    "ZNYYv18AAAAJ",
    "ai5ebQkAAAAJ",
    "NoTPL0wAAAAJ",
    "WcpiFUQAAAAJ",
    "ugMdl90AAAAJ",
    "nicnuy4AAAAJ",
    "bLH3dWgAAAAJ",
    "NvKHgzkAAAAJ",
    "nP1F-QsAAAAJ",
    "dJ8MMFoAAAAJ",
    "nje5fjEAAAAJ",
    "9lmyivIAAAAJ",
    "NDHbbuAAAAAJ",
    "8R35rCwAAAAJ",
    "bh-uRFMAAAAJ",
    "a4unsk4AAAAJ",
    "84WzBlYAAAAJ",
    "a_dbdxAAAAAJ",
    "aO8KpGcAAAAJ",
    "LKv32bgAAAAJ",
    "vtwH6GkAAAAJ",
    "B96GkdgAAAAJ",
    "_pv1sEcAAAAJ",
    "Wi25oKoAAAAJ",
    "B847xq8AAAAJ",
    "_tNCgxMAAAAJ",
    "UgHB5oAAAAAJ"
  ],
  "all_authors": [
    "Mk7BuSwAAAAJ",
    "KWhGcA4AAAAJ",
    "nQE56v0AAAAJ",
    "bLH3dWgAAAAJ",
    "_5PRunQAAAAJ",
    "DCRTLJ8AAAAJ",
    "Zbvss7Sjr2sC",
    "NDHbbuAAAAAJ",
    "VizEaQEAAAAJ",
    "SlZavnIAAAAJ",
    "tsNsOJ4AAAAJ",
    "_vJSGrkAAAAJ",
    "zmyHfb8AAAAJ",
    "tVZggyIAAAAJ",
    "UtRiqWQAAAAJ",
    "7V1AORUAAAAJ",
    "VN-UCMgAAAAJ",
    "ziBaxi0AAAAJ",
    "pbhFW1kAAAAJ",
    "DoJvepkAAAAJ",
    "-4JbzIoAAAAJ",
    "nicnuy4AAAAJ",
    "Q5_G4oQAAAAJ",
    "Y-o1GEQAAAAJ",
    "Dkeu8BMAAAAJ",
    "IJgXsgwAAAAJ",
    "wIdzoc8AAAAJ",
    "_2LKKpsAAAAJ",
    "3QooCT0AAAAJ",
    "ZrCk8RwAAAAJ",
    "_2_v4bsAAAAJ",
    "FOafMIgAAAAJ",
    "lbMG9IcAAAAJ",
    "8m8taGEAAAAJ",
    "EtDeLfYAAAAJ",
    "b-53G6MAAAAJ",
    "SdXw4U4AAAAJ",
    "PznKxuwAAAAJ",
    "2kMKbisAAAAJ",
    "_dBDJygAAAAJ",
    "p8E6WqMAAAAJ",
    "ugMdl90AAAAJ",
    "sNW9iscAAAAJ",
    "uBFV6SUAAAAJ",
    "7w2WVgIAAAAJ",
    "mbcRJ2sAAAAJ",
    "wg421oQAAAAJ",
    "XCkp5uEAAAAJ",
    "alxMRnQAAAAJ",
    "kqTlJ1MAAAAJ",
    "ylh95x4AAAAJ",
    "ORaHXn8AAAAJ",
    "dJ8MMFoAAAAJ",
    "GsDdaaYAAAAJ",
    "UGgGMrIAAAAJ",
    "7KnIsvQAAAAJ",
    "i3-ENjQAAAAJ",
    "sEAoh3MAAAAJ",
    "o2cUkz4AAAAJ",
    "oz19xXsAAAAJ",
    "4arkOLcAAAAJ",
    "MtBYJ7MAAAAJ",
    "-2OhI8YAAAAJ",
    "Ya8eTsYAAAAJ",
    "Ah0UP2kAAAAJ",
    "GP64q_kAAAAJ",
    "aCb48bUAAAAJ",
    "Mw84b5sAAAAJ",
    "r_tMTzEAAAAJ",
    "9lmyivIAAAAJ",
    "drakQU4AAAAJ",
    "J-uRiRAAAAAJ",
    "ABnl2_MAAAAJ",
    "TrrbXhIAAAAJ",
    "TkL_VtoAAAAJ",
    "wRUKAMMAAAAJ",
    "x19iFT0AAAAJ",
    "DVk7EKAAAAAJ",
    "0uzKezgAAAAJ",
    "QflOmB4AAAAJ",
    "sZf6F1cAAAAJ",
    "4p5ooX4AAAAJ",
    "tRCNWC4AAAAJ",
    "fXhxN3AAAAAJ",
    "aCNJzKEAAAAJ",
    "WcpiFUQAAAAJ",
    "tJ3oJEkAAAAJ",
    "UbOaNlUAAAAJ",
    "7qTg_1kAAAAJ",
    "PFQE6v8AAAAJ",
    "2hjzVM8AAAAJ",
    "FBtKFBQAAAAJ",
    "J2KWqAoAAAAJ",
    "NoTPL0wAAAAJ",
    "glDysGkAAAAJ",
    "s7gOlh8AAAAJ",
    "Yokdc8IAAAAJ",
    "qIg8KFYAAAAJ",
    "8dHy9FAAAAAJ",
    "BnaRir8AAAAJ",
    "TN09YMcAAAAJ",
    "6xr9l5EAAAAJ",
    "nP1F-QsAAAAJ",
    "PMwlwE0AAAAJ",
    "j8g1fe8AAAAJ",
    "cY-UP0oAAAAJ",
    "rYBIFu8AAAAJ",
    "AhgjQ2QAAAAJ",
    "zb2kBYgAAAAJ",
    "ai5ebQkAAAAJ",
    "D2dgzzQAAAAJ",
    "Qs2N8fMAAAAJ",
    "v7a8-e0AAAAJ",
    "kxg88EcAAAAJ",
    "tiM51yoAAAAJ",
    "valGGiQAAAAJ",
    "GxXX_ekAAAAJ",
    "ZD6J9JIAAAAJ",
    "RWGj7esAAAAJ",
    "3ENogOkAAAAJ",
    "-f4kLIoAAAAJ",
    "kwqPtgcAAAAJ",
    "AZqd0b4AAAAJ",
    "nje5fjEAAAAJ",
    "GrBOKEsAAAAJ",
    "yr_ubo0AAAAJ",
    "_9E4gkoAAAAJ",
    "XMVtscAAAAAJ",
    "8BwddWMAAAAJ",
    "U73rXq8AAAAJ",
    "EV0ft6UAAAAJ",
    "in-6RDsAAAAJ",
    "AroaLZIAAAAJ",
    "NvKHgzkAAAAJ",
    "tDIJwxsAAAAJ",
    "ZNYYv18AAAAJ",
    "e9gUdKwAAAAJ",
    "3yT6IX4AAAAJ",
    "p0sQC6sAAAAJ",
    "-zaDQ10AAAAJ",
    "euc0GX4AAAAJ",
    "ZvX1hXcAAAAJ",
    "0lZoXCUAAAAJ",
    "4mVPFQ8AAAAJ",
    "YAHWbtkAAAAJ",
    "-ltRSM0AAAAJ",
    "xRmmtzIAAAAJ",
    "DwdjBUUAAAAJ",
    "mqpjAt4AAAAJ",
    "Nn990CkAAAAJ",
    "L-diWvQAAAAJ",
    "uFJi3IUAAAAJ",
    "yy0UFOwAAAAJ",
    "07qshUgAAAAJ",
    "BgQkdsYAAAAJ",
    "GUAoEcAAAAAJ",
    "ZaJEZpYAAAAJ",
    "eWRBqsYAAAAJ",
    "4Z6vo5QAAAAJ",
    "VecEj6kAAAAJ",
    "d97bGd8AAAAJ",
    "Ch9iRwQAAAAJ",
    "GHpxNQIAAAAJ",
    "lH1PdF8AAAAJ",
    "rIjeeRsAAAAJ",
    "kiFd6A8AAAAJ",
    "T9To2C0AAAAJ",
    "yDVn5LEAAAAJ",
    "84WzBlYAAAAJ",
    "ADkiClQAAAAJ",
    "a4unsk4AAAAJ",
    "65FCPpwAAAAJ",
    "MN9Kfg8AAAAJ",
    "-XCiamcAAAAJ",
    "4bl7qAgAAAAJ",
    "nABXo3sAAAAJ",
    "wSstCv0AAAAJ",
    "OFlBL2kAAAAJ",
    "MzKvJhAAAAAJ",
    "UfbuDH8AAAAJ",
    "8R35rCwAAAAJ",
    "LKv32bgAAAAJ",
    "23ZXZvEAAAAJ",
    "iyDxq0EAAAAJ",
    "y-8unsgAAAAJ",
    "0mgEF28AAAAJ",
    "OP6ejqgAAAAJ",
    "AEsPCAUAAAAJ",
    "94RFSSsAAAAJ",
    "VjsNXysAAAAJ",
    "FwxfQosAAAAJ",
    "aO8KpGcAAAAJ",
    "3kDtybgAAAAJ",
    "df-THM0AAAAJ",
    "_PZKLYUAAAAJ",
    "Op-47sgAAAAJ",
    "pvyI8GkAAAAJ",
    "on2DUKoAAAAJ",
    "k-nF0qgAAAAJ",
    "pouyVyUAAAAJ",
    "aC55XVgAAAAJ",
    "H3LMjtoAAAAJ",
    "1wLVDP4AAAAJ",
    "APgaFK0AAAAJ",
    "gYiCq88AAAAJ",
    "KgZxzjsAAAAJ",
    "b8OxVWUAAAAJ",
    "-gJkPHIAAAAJ",
    "Q-v0BgUAAAAJ",
    "5VaXUQsAAAAJ",
    "ijmuZ0wAAAAJ",
    "x04W_mMAAAAJ",
    "B96GkdgAAAAJ",
    "DZ3S--MAAAAJ",
    "-5_ksIkAAAAJ",
    "Dtw3YBoAAAAJ",
    "K3QJPdMAAAAJ",
    "opbZfw0AAAAJ",
    "nTiSnwUAAAAJ",
    "vfPE6hgAAAAJ",
    "8O8MQEUAAAAJ",
    "XCZpOcAAAAAJ",
    "LfcroyAAAAAJ",
    "bh-uRFMAAAAJ",
    "QWzsNMDsvlIC",
    "VT7peyEAAAAJ",
    "9xDADY4AAAAJ",
    "W8VIEZgAAAAJ",
    "eurA6WgAAAAJ",
    "odFQXSYAAAAJ",
    "SqFoZNUAAAAJ",
    "UnEHCNkAAAAJ",
    "DcV-5RAAAAAJ",
    "CgItEbQAAAAJ",
    "8fztli4AAAAJ",
    "Vzr1RukAAAAJ",
    "a5nY-pYAAAAJ",
    "QXyvv94AAAAJ",
    "Wi25oKoAAAAJ",
    "vN-is70AAAAJ",
    "7OTD-LEAAAAJ",
    "SaboshYAAAAJ",
    "62e5CygAAAAJ",
    "6-e-ZBEAAAAJ",
    "fNOReswAAAAJ",
    "P4nfoKYAAAAJ",
    "CzOD0S4AAAAJ",
    "_1hCq3UAAAAJ",
    "mnU3HpcAAAAJ",
    "ID9QePIAAAAJ",
    "iVLAQysAAAAJ",
    "PS-TM94AAAAJ",
    "vtwH6GkAAAAJ",
    "LUe32ToAAAAJ",
    "Hyhp_zUAAAAJ",
    "NDyEvlQAAAAJ",
    "jERkdhIAAAAJ",
    "DRnOvU8AAAAJ",
    "bZ9oyW8AAAAJ",
    "gRxBNZoAAAAJ",
    "mu5Y2rYAAAAJ",
    "a_dbdxAAAAAJ",
    "1O83J5MAAAAJ",
    "itSa94cAAAAJ",
    "2oy3OXYAAAAJ",
    "8-p9CLsAAAAJ",
    "6dskOSUAAAAJ",
    "B7oP0bIAAAAJ",
    "IcaU830AAAAJ",
    "7t4jbPQAAAAJ",
    "X-Sd3-8AAAAJ",
    "_pv1sEcAAAAJ",
    "O43_7KUAAAAJ",
    "r44N6h8AAAAJ",
    "0bwP0i4AAAAJ",
    "B8wslVsAAAAJ",
    "zS3z8UgAAAAJ",
    "3XLQbL8AAAAJ",
    "FFWXLHUAAAAJ",
    "tsXh_hwAAAAJ",
    "DpLFv4gAAAAJ",
    "gzpWXPcAAAAJ",
    "HBztuGIAAAAJ",
    "l-la0GQAAAAJ",
    "bLUllHEAAAAJ",
    "YLOz1kgAAAAJ",
    "yxUduqMAAAAJ",
    "m_HQ-WQAAAAJ",
    "7GSWYLQAAAAJ",
    "zBUwaGkAAAAJ",
    "_tNCgxMAAAAJ",
    "BsOkXDsAAAAJ",
    "IB_jPZ0AAAAJ",
    "DYUloYkAAAAJ",
    "UAwKvEsAAAAJ",
    "xOWBOKQAAAAJ",
    "czyretsAAAAJ",
    "CpMjT0YAAAAJ",
    "hdTDzlQAAAAJ",
    "kppa2vgAAAAJ",
    "I1EvjZsAAAAJ",
    "UgHB5oAAAAAJ",
    "NSWI3OwAAAAJ",
    "fftO_HsAAAAJ",
    "d5y4iKAAAAAJ",
    "pzw1-J4AAAAJ",
    "EMDboA4AAAAJ",
    "4zybTq4AAAAJ",
    "RLvsC94AAAAJ",
    "zX3ba1kAAAAJ",
    "B847xq8AAAAJ",
    "5pKTRxEAAAAJ",
    "9yRwkr4AAAAJ"
  ],
  "author_names": {
    "Mk7BuSwAAAAJ": "Liukang Xu",
    "KWhGcA4AAAAJ": "Edoardo Charbon",
    "nQE56v0AAAAJ": "Hyun Woo \"Chris\" Lee",
    "bLH3dWgAAAAJ": "Hannah S Stuart",
    "_5PRunQAAAAJ": "Daniel S Karp",
    "DCRTLJ8AAAAJ": "Shameek Ganguly",
    "Zbvss7Sjr2sC": "John Laudun",
    "NDHbbuAAAAAJ": "Avideh ZAKHOR",
    "VizEaQEAAAAJ": "Kate Munden-Dixon",
    "tsNsOJ4AAAAJ": "Jianbo Gao",
    "_vJSGrkAAAAJ": "Glenn Ballard",
    "zmyHfb8AAAAJ": "Matthew L. Jockers",
    "tVZggyIAAAAJ": "Gerald Brantner",
    "UtRiqWQAAAAJ": "Abdalla Odeh",
    "7V1AORUAAAAJ": "Lauri Koskela",
    "VN-UCMgAAAAJ": "Kathryn De Master",
    "ziBaxi0AAAAJ": "Roberto Passerone",
    "pbhFW1kAAAAJ": "Marco Di Natale",
    "DoJvepkAAAAJ": "Sebastian D. Lee",
    "-4JbzIoAAAAJ": "Farook Hamzeh",
    "nicnuy4AAAAJ": "Richard IVRY",
    "Q5_G4oQAAAAJ": "Mark SANDBERG",
    "Y-o1GEQAAAAJ": "Jungpyo Lee",
    "Dkeu8BMAAAAJ": "Gil Sadka",
    "IJgXsgwAAAAJ": "Edward A. LEE",
    "wIdzoc8AAAAJ": "Thais da C. L. Alves",
    "_2LKKpsAAAAJ": "Cynthia C.Y. Tsao",
    "3QooCT0AAAAJ": "Dr.-Ing. Fatos Elezi",
    "ZrCk8RwAAAAJ": "Federico Castillo",
    "_2_v4bsAAAAJ": "Kenneth Walsh",
    "FOafMIgAAAAJ": "Lianhong Gu",
    "lbMG9IcAAAAJ": "Adam J Calo",
    "8m8taGEAAAAJ": "Masayoshi Tomizuka",
    "EtDeLfYAAAAJ": "Christine Rosen",
    "b-53G6MAAAAJ": "Sara Beckman",
    "SdXw4U4AAAAJ": "Daniel Aukes",
    "PznKxuwAAAAJ": "behnam shahbazi",
    "2kMKbisAAAAJ": "Christopher Bacon",
    "_dBDJygAAAAJ": "Ren-Jye Dzeng",
    "p8E6WqMAAAAJ": "Abhijit Davare",
    "ugMdl90AAAAJ": "Rushin Contractor",
    "sNW9iscAAAAJ": "Dominic Melville",
    "uBFV6SUAAAAJ": "David Mimno",
    "7w2WVgIAAAAJ": "Laura Katherine Treers",
    "mbcRJ2sAAAAJ": "Catherine M. Crespi",
    "wg421oQAAAAJ": "Christian R Voolstra",
    "XCkp5uEAAAAJ": "Markus Reichstein",
    "alxMRnQAAAAJ": "Adam Frandson",
    "kqTlJ1MAAAAJ": "Maywa Montenegro de Wit",
    "ylh95x4AAAAJ": "Don A. Moore",
    "ORaHXn8AAAAJ": "SALLIE YEA",
    "dJ8MMFoAAAAJ": "Dennis BALDOCCHI",
    "GsDdaaYAAAAJ": "Pierluigi Nuzzo",
    "UGgGMrIAAAAJ": "Mehdi Maasoumy",
    "7KnIsvQAAAAJ": "Gernot Hickethier",
    "i3-ENjQAAAAJ": "Erin Chang",
    "sEAoh3MAAAAJ": "Luca Carloni",
    "o2cUkz4AAAAJ": "Tiziano Villa",
    "oz19xXsAAAAJ": "Heike E. Daldrup-Link",
    "4arkOLcAAAAJ": "Oussama Khatib",
    "MtBYJ7MAAAAJ": "Panos N. Patatoukas",
    "-2OhI8YAAAAJ": "Edward Sargent",
    "Ya8eTsYAAAAJ": "Patrick Baur",
    "Ah0UP2kAAAAJ": "Carlos T. Formoso",
    "GP64q_kAAAAJ": "Jan Rabaey",
    "aCb48bUAAAAJ": "Wayne Landsman",
    "Mw84b5sAAAAJ": "Matteo Detto",
    "r_tMTzEAAAAJ": "Jeff McMullin",
    "9lmyivIAAAAJ": "Timothy Tangherlini",
    "drakQU4AAAAJ": "TAE MYUNG HUH",
    "J-uRiRAAAAAJ": "Alper Demir",
    "ABnl2_MAAAAJ": "Monica Li",
    "TrrbXhIAAAAJ": "Peter Leonard",
    "TkL_VtoAAAAJ": "Timothy Bowles",
    "wRUKAMMAAAAJ": "Khaled Nabil Salama",
    "x19iFT0AAAAJ": "Haibo Zeng",
    "DVk7EKAAAAAJ": "Daniel E. O'Leary",
    "0uzKezgAAAAJ": "Pierrette Zouein",
    "QflOmB4AAAAJ": "Jin Xie",
    "sZf6F1cAAAAJ": "Luca Benvenuti",
    "4p5ooX4AAAAJ": "Youngryel Ryu (\ub958\uc601\ub82c)",
    "tRCNWC4AAAAJ": "Luciano Lavagno",
    "fXhxN3AAAAAJ": "Paz Arroyo",
    "aCNJzKEAAAAJ": "Tilden P Meyers",
    "WcpiFUQAAAAJ": "Hannes Bajohr",
    "tJ3oJEkAAAAJ": "Dara O'Rourke",
    "UbOaNlUAAAAJ": "Kristen Parrish",
    "7qTg_1kAAAAJ": "Dario Papale",
    "PFQE6v8AAAAJ": "Pavan Holur",
    "2hjzVM8AAAAJ": "Gregory A. Howell",
    "FBtKFBQAAAAJ": "Bozidar Stojadinovic",
    "J2KWqAoAAAAJ": "Beverly E Law",
    "NoTPL0wAAAAJ": "Iris D. Tommelein, NAC",
    "glDysGkAAAAJ": "Florian Fuchs",
    "s7gOlh8AAAAJ": "Mark D'Esposito",
    "Yokdc8IAAAAJ": "Vincent Creuze",
    "qIg8KFYAAAAJ": "Mark Cutkosky",
    "8dHy9FAAAAAJ": "Scott Joslin",
    "BnaRir8AAAAJ": "Xiyang Yeh",
    "TN09YMcAAAAJ": "Qi Zhu",
    "6xr9l5EAAAAJ": "Hicham Fenniri",
    "nP1F-QsAAAAJ": "Alastair Iles, Professor of Sustainability Transitions",
    "PMwlwE0AAAAJ": "Alessandro Pinto",
    "j8g1fe8AAAAJ": "John F. Hartwig",
    "cY-UP0oAAAAJ": "Mary Barth",
    "rYBIFu8AAAAJ": "Raymond Levitt",
    "AhgjQ2QAAAAJ": "Alberto Sangiovanni Vincentelli",
    "zb2kBYgAAAAJ": "Lulu Qian",
    "ai5ebQkAAAAJ": "Carmine Emanuele Cella",
    "D2dgzzQAAAAJ": "Ehsan Ebrahimzadeh",
    "Qs2N8fMAAAAJ": "Jianghong Rao",
    "v7a8-e0AAAAJ": "Claire Kremen",
    "kxg88EcAAAAJ": "Christy Getz",
    "tiM51yoAAAAJ": "Rieke Trim\u00e7ev",
    "valGGiQAAAAJ": "DAVID CHONG",
    "GxXX_ekAAAAJ": "Christopher Armstrong",
    "ZD6J9JIAAAAJ": "Sunil Khatri",
    "RWGj7esAAAAJ": "Carlo Fischione",
    "3ENogOkAAAAJ": "Shufei Lei",
    "-f4kLIoAAAAJ": "garrett graddy-lovelace",
    "kwqPtgcAAAAJ": "Robert J. Full",
    "AZqd0b4AAAAJ": "Clark Miller",
    "nje5fjEAAAAJ": "Yaniv Konchitchki",
    "GrBOKEsAAAAJ": "Vwani Roychowdhury",
    "yr_ubo0AAAAJ": "Eli Bartov",
    "_9E4gkoAAAAJ": "Maria Domenica Di Benedetto",
    "XMVtscAAAAAJ": "Yuri Gloumakov",
    "8BwddWMAAAAJ": "Mark L. DeFond",
    "U73rXq8AAAAJ": "Ryan E. Galt",
    "EV0ft6UAAAAJ": "Andrew McPherson",
    "in-6RDsAAAAJ": "Shana Kelley",
    "AroaLZIAAAAJ": "Stephen Epstein",
    "NvKHgzkAAAAJ": "Raluca Ada Popa",
    "tDIJwxsAAAAJ": "Kenzo Esquivel",
    "ZNYYv18AAAAJ": "Grigory Tikhomirov",
    "e9gUdKwAAAAJ": "Xin Wang",
    "3yT6IX4AAAAJ": "Adrian L Harris",
    "p0sQC6sAAAAJ": "Michael Franklin",
    "-zaDQ10AAAAJ": "Mark van der Laan",
    "euc0GX4AAAAJ": "Karthik Narasimhan",
    "ZvX1hXcAAAAJ": "Nived Rajaraman",
    "0lZoXCUAAAAJ": "Mohammad Mahdian",
    "4mVPFQ8AAAAJ": "Dylan Hadfield-Menell",
    "YAHWbtkAAAAJ": "Jennifer Chayes",
    "-ltRSM0AAAAJ": "Evan Shelhamer",
    "xRmmtzIAAAAJ": "Thomas Courtade",
    "DwdjBUUAAAAJ": "Alvin Wan",
    "mqpjAt4AAAAJ": "Judy Hoffman",
    "Nn990CkAAAAJ": "Pang Wei Koh",
    "L-diWvQAAAAJ": "Deepti Gurdasani",
    "uFJi3IUAAAAJ": "Joseph Hellerstein",
    "yy0UFOwAAAAJ": "Karol Hausman",
    "07qshUgAAAAJ": "Pravesh K. Kothari",
    "BgQkdsYAAAAJ": "Paria Rashidinejad",
    "GUAoEcAAAAAJ": "Scott Shenker",
    "ZaJEZpYAAAAJ": "Dorsa Sadigh",
    "eWRBqsYAAAAJ": "Alicia Curth",
    "4Z6vo5QAAAAJ": "John Hopcroft",
    "VecEj6kAAAAJ": "Gopala K. Anumanchipalli",
    "d97bGd8AAAAJ": "Alexei A. Efros",
    "Ch9iRwQAAAAJ": "Aditi Raghunathan",
    "GHpxNQIAAAAJ": "Anna Rohrbach",
    "lH1PdF8AAAAJ": "Stefano Soatto",
    "rIjeeRsAAAAJ": "Tom Hartvigsen",
    "kiFd6A8AAAAJ": "Jinsung Yoon",
    "T9To2C0AAAAJ": "Justin Fu",
    "yDVn5LEAAAAJ": "Hanlin Zhu",
    "84WzBlYAAAAJ": "Dawn Song",
    "ADkiClQAAAAJ": "Yevgen Chebotar",
    "a4unsk4AAAAJ": "Adam Yala",
    "65FCPpwAAAAJ": "Moshe Tennenholtz",
    "MN9Kfg8AAAAJ": "Zachary C. Lipton",
    "-XCiamcAAAAJ": "Fisher Yu",
    "4bl7qAgAAAAJ": "Nathan Ratliff",
    "nABXo3sAAAAJ": "Eric Tzeng",
    "wSstCv0AAAAJ": "Hongyang Zhang",
    "OFlBL2kAAAAJ": "Frederik Ebert",
    "MzKvJhAAAAAJ": "Steven Basart",
    "UfbuDH8AAAAJ": "Jeff Donahue",
    "8R35rCwAAAAJ": "Sergey Levine",
    "LKv32bgAAAAJ": "Jacob Steinhardt",
    "23ZXZvEAAAAJ": "James Zou",
    "iyDxq0EAAAAJ": "Banghua Zhu",
    "y-8unsgAAAAJ": "Marek Biskup",
    "0mgEF28AAAAJ": "Yuandong Tian",
    "OP6ejqgAAAAJ": "Kartik Venkat",
    "AEsPCAUAAAAJ": "Deepak Pathak",
    "94RFSSsAAAAJ": "Daniel Crankshaw",
    "VjsNXysAAAAJ": "Jur van den Berg",
    "FwxfQosAAAAJ": "Xue Bin Peng",
    "aO8KpGcAAAAJ": "Jiantao Jiao",
    "3kDtybgAAAAJ": "Marcus Rohrbach",
    "df-THM0AAAAJ": "Tianhao Wu",
    "_PZKLYUAAAAJ": "Amin Saberi",
    "Op-47sgAAAAJ": "Evan Frick",
    "pvyI8GkAAAAJ": "Lisa Anne M Hendricks",
    "on2DUKoAAAAJ": "David Ouyang",
    "k-nF0qgAAAAJ": "Kevin S Hughes",
    "pouyVyUAAAAJ": "Percy Liang",
    "aC55XVgAAAAJ": "Rong Tang",
    "H3LMjtoAAAAJ": "Danny Bickson",
    "1wLVDP4AAAAJ": "Abhishek Gupta",
    "APgaFK0AAAAJ": "Louis-Philippe Morency",
    "gYiCq88AAAAJ": "Sergio Guadarrama",
    "KgZxzjsAAAAJ": "Shankar Sastry",
    "b8OxVWUAAAAJ": "Vikram Sreekanti",
    "-gJkPHIAAAAJ": "George Tucker",
    "Q-v0BgUAAAAJ": "Anthony Philippakis",
    "5VaXUQsAAAAJ": "Tianhe Yu",
    "ijmuZ0wAAAAJ": "Sergey Karayev",
    "x04W_mMAAAAJ": "Ilya Sutskever",
    "B96GkdgAAAAJ": "Joseph E. Gonzalez",
    "DZ3S--MAAAAJ": "Mihaela van der Schaar",
    "-5_ksIkAAAAJ": "Claire Tomlin",
    "Dtw3YBoAAAAJ": "Andrew Ilyas",
    "K3QJPdMAAAAJ": "Bichen Wu",
    "opbZfw0AAAAJ": "Vahab Mirrokni",
    "nTiSnwUAAAAJ": "Tsachy Weissman",
    "vfPE6hgAAAAJ": "Chelsea Finn",
    "8O8MQEUAAAAJ": "Henry Cohn",
    "XCZpOcAAAAAJ": "Wojciech Zaremba",
    "LfcroyAAAAAJ": "David Sontag",
    "bh-uRFMAAAAJ": "Trevor Darrell",
    "QWzsNMDsvlIC": "Gordon Slade",
    "VT7peyEAAAAJ": "Tuomas Haarnoja",
    "9xDADY4AAAAJ": "Kate Saenko",
    "W8VIEZgAAAAJ": "Ross Girshick",
    "eurA6WgAAAAJ": "Sandy H Huang",
    "odFQXSYAAAAJ": "Rohin Shah",
    "SqFoZNUAAAAJ": "Noam Berger",
    "UnEHCNkAAAAJ": "Michael Brautbar",
    "DcV-5RAAAAAJ": "Kannan Ramchandran",
    "CgItEbQAAAAJ": "Gregory Valiant",
    "8fztli4AAAAJ": "Ken Goldberg",
    "Vzr1RukAAAAJ": "Igor Mordatch",
    "a5nY-pYAAAAJ": "Alexandre Bayen",
    "QXyvv94AAAAJ": "Michael Mahoney",
    "Wi25oKoAAAAJ": "Xiaoyu (Rayne) Zheng",
    "vN-is70AAAAJ": "Ion Stoica",
    "7OTD-LEAAAAJ": "Zhuang Liu",
    "SaboshYAAAAJ": "Ankur Dave",
    "62e5CygAAAAJ": "Andreea Bobu",
    "6-e-ZBEAAAAJ": "Dario Amodei",
    "fNOReswAAAAJ": "Riccardo Zecchina",
    "P4nfoKYAAAAJ": "Alex `Sandy' Pentland",
    "CzOD0S4AAAAJ": "Travis Ian Zack",
    "_1hCq3UAAAAJ": "Nicole Immorlica",
    "mnU3HpcAAAAJ": "Ioana Bica",
    "ID9QePIAAAAJ": "Kurt Keutzer",
    "iVLAQysAAAAJ": "Jonathan Ho",
    "PS-TM94AAAAJ": "Mohsen Bayati",
    "vtwH6GkAAAAJ": "Pieter Abbeel",
    "LUe32ToAAAAJ": "Andrea Bajcsy",
    "Hyhp_zUAAAAJ": "Jodi Forlizzi",
    "NDyEvlQAAAAJ": "Atul J. Butte",
    "jERkdhIAAAAJ": "Gregory Kahn",
    "DRnOvU8AAAAJ": "Benjamin Eysenbach",
    "bZ9oyW8AAAAJ": "Yaodong Yu",
    "gRxBNZoAAAAJ": "Adam Tauman Kalai",
    "mu5Y2rYAAAAJ": "Yangqing Jia",
    "a_dbdxAAAAAJ": "Benjamin Recht",
    "1O83J5MAAAAJ": "Aurick Zhou",
    "itSa94cAAAAJ": "John Schulman",
    "2oy3OXYAAAAJ": "Stuart Russell",
    "8-p9CLsAAAAJ": "Alex X. Lee",
    "6dskOSUAAAAJ": "Christopher Olah",
    "B7oP0bIAAAAJ": "Paul Christiano",
    "IcaU830AAAAJ": "Richard Liaw",
    "7t4jbPQAAAAJ": "J. Andrew Bagnell",
    "X-Sd3-8AAAAJ": "Kush Bhatia",
    "_pv1sEcAAAAJ": "Ahmed M. Alaa",
    "O43_7KUAAAAJ": "Jivat Neet Kaur",
    "SlZavnIAAAAJ": "Sanjit A. Seshia",
    "r44N6h8AAAAJ": "Brendan Lucier",
    "0bwP0i4AAAAJ": "Lars van der Laan",
    "B8wslVsAAAAJ": "Shixiang Shane Gu",
    "zS3z8UgAAAAJ": "Remco van der Hofstad",
    "3XLQbL8AAAAJ": "Laurent El Ghaoui",
    "FFWXLHUAAAAJ": "Philipp Moritz",
    "tsXh_hwAAAAJ": "Smitha Milli",
    "DpLFv4gAAAAJ": "Carlos Guestrin",
    "gzpWXPcAAAAJ": "Marie-Laure Charpignon",
    "HBztuGIAAAAJ": "Rein Houthooft",
    "l-la0GQAAAAJ": "Julian Ibarz",
    "bLUllHEAAAAJ": "Adam Coates",
    "YLOz1kgAAAAJ": "Greg Shakhnarovich",
    "yxUduqMAAAAJ": "Michael I. Jordan",
    "m_HQ-WQAAAAJ": "Alfredo Braunstein",
    "7GSWYLQAAAAJ": "Siddharth Reddy",
    "zBUwaGkAAAAJ": "Aviral Kumar",
    "_tNCgxMAAAAJ": "Anil Aswani",
    "BsOkXDsAAAAJ": "Ashvin Nair",
    "IB_jPZ0AAAAJ": "Cong Ma",
    "DYUloYkAAAAJ": "Carlo Baldassi",
    "UAwKvEsAAAAJ": "Thomas L. Griffiths",
    "xOWBOKQAAAAJ": "Sachin Patil",
    "czyretsAAAAJ": "Dan Hendrycks",
    "CpMjT0YAAAAJ": "Daniel Kang",
    "hdTDzlQAAAAJ": "Yanjun Han",
    "kppa2vgAAAAJ": "Aviv Tamar",
    "I1EvjZsAAAAJ": "Matei Zaharia",
    "UgHB5oAAAAAJ": "Anca D Dragan",
    "NSWI3OwAAAAJ": "Quan Vuong",
    "fftO_HsAAAAJ": "Brijen Thananjeyan",
    "d5y4iKAAAAAJ": "Dhruv Shah",
    "pzw1-J4AAAAJ": "Inioluwa Deborah Raji",
    "EMDboA4AAAAJ": "Yan Duan",
    "4zybTq4AAAAJ": "Jerry Li",
    "RLvsC94AAAAJ": "Tom B Brown",
    "zX3ba1kAAAAJ": "Moses Charikar",
    "B847xq8AAAAJ": "Christian Borgs",
    "5pKTRxEAAAAJ": "Eric Xing",
    "9yRwkr4AAAAJ": "Fernanda C. G. Polubriaginof, MD PhD"
  },
  "co_authors": {
    "j8g1fe8AAAAJ": [],
    "8m8taGEAAAAJ": [],
    "AhgjQ2QAAAAJ": [
      "tRCNWC4AAAAJ",
      "o2cUkz4AAAAJ",
      "SlZavnIAAAAJ",
      "sEAoh3MAAAAJ",
      "ziBaxi0AAAAJ",
      "GsDdaaYAAAAJ",
      "pbhFW1kAAAAJ",
      "_9E4gkoAAAAJ",
      "IJgXsgwAAAAJ",
      "KWhGcA4AAAAJ",
      "GP64q_kAAAAJ",
      "sZf6F1cAAAAJ",
      "ZD6J9JIAAAAJ",
      "TN09YMcAAAAJ",
      "UGgGMrIAAAAJ",
      "PMwlwE0AAAAJ",
      "x19iFT0AAAAJ",
      "p8E6WqMAAAAJ",
      "J-uRiRAAAAAJ",
      "RWGj7esAAAAJ"
    ],
    "ZNYYv18AAAAJ": [
      "Qs2N8fMAAAAJ",
      "zb2kBYgAAAAJ",
      "oz19xXsAAAAJ",
      "in-6RDsAAAAJ",
      "6xr9l5EAAAAJ",
      "-2OhI8YAAAAJ"
    ],
    "ai5ebQkAAAAJ": [],
    "NoTPL0wAAAAJ": [
      "_vJSGrkAAAAJ",
      "7V1AORUAAAAJ",
      "fXhxN3AAAAAJ",
      "2hjzVM8AAAAJ",
      "0uzKezgAAAAJ",
      "_2_v4bsAAAAJ",
      "alxMRnQAAAAJ",
      "-4JbzIoAAAAJ",
      "3QooCT0AAAAJ",
      "rYBIFu8AAAAJ",
      "Ah0UP2kAAAAJ",
      "UbOaNlUAAAAJ",
      "wIdzoc8AAAAJ",
      "_dBDJygAAAAJ",
      "_2LKKpsAAAAJ",
      "UtRiqWQAAAAJ",
      "b-53G6MAAAAJ",
      "FBtKFBQAAAAJ",
      "nQE56v0AAAAJ",
      "7KnIsvQAAAAJ"
    ],
    "WcpiFUQAAAAJ": [
      "glDysGkAAAAJ",
      "tiM51yoAAAAJ"
    ],
    "ugMdl90AAAAJ": [],
    "nicnuy4AAAAJ": [
      "s7gOlh8AAAAJ"
    ],
    "bLH3dWgAAAAJ": [
      "qIg8KFYAAAAJ",
      "drakQU4AAAAJ",
      "4arkOLcAAAAJ",
      "ABnl2_MAAAAJ",
      "EV0ft6UAAAAJ",
      "7w2WVgIAAAAJ",
      "Yokdc8IAAAAJ",
      "BnaRir8AAAAJ",
      "wg421oQAAAAJ",
      "wRUKAMMAAAAJ",
      "tVZggyIAAAAJ",
      "SdXw4U4AAAAJ",
      "Y-o1GEQAAAAJ",
      "kwqPtgcAAAAJ",
      "XMVtscAAAAAJ",
      "DoJvepkAAAAJ",
      "8m8taGEAAAAJ",
      "DCRTLJ8AAAAJ",
      "sNW9iscAAAAJ",
      "i3-ENjQAAAAJ"
    ],
    "NvKHgzkAAAAJ": [],
    "nP1F-QsAAAAJ": [
      "v7a8-e0AAAAJ",
      "kqTlJ1MAAAAJ",
      "Ya8eTsYAAAAJ",
      "lbMG9IcAAAAJ",
      "TkL_VtoAAAAJ",
      "2kMKbisAAAAJ",
      "tDIJwxsAAAAJ",
      "_5PRunQAAAAJ",
      "U73rXq8AAAAJ",
      "AZqd0b4AAAAJ",
      "kxg88EcAAAAJ",
      "VizEaQEAAAAJ",
      "VN-UCMgAAAAJ",
      "ZrCk8RwAAAAJ",
      "EtDeLfYAAAAJ",
      "3ENogOkAAAAJ",
      "-f4kLIoAAAAJ",
      "tJ3oJEkAAAAJ"
    ],
    "dJ8MMFoAAAAJ": [
      "J2KWqAoAAAAJ",
      "aCNJzKEAAAAJ",
      "7qTg_1kAAAAJ",
      "Mk7BuSwAAAAJ",
      "XCkp5uEAAAAJ",
      "4p5ooX4AAAAJ",
      "FOafMIgAAAAJ",
      "Mw84b5sAAAAJ"
    ],
    "nje5fjEAAAAJ": [
      "MtBYJ7MAAAAJ",
      "aCb48bUAAAAJ",
      "DVk7EKAAAAAJ",
      "cY-UP0oAAAAJ",
      "8BwddWMAAAAJ",
      "yr_ubo0AAAAJ",
      "8dHy9FAAAAAJ",
      "r_tMTzEAAAAJ",
      "Dkeu8BMAAAAJ",
      "QflOmB4AAAAJ",
      "GxXX_ekAAAAJ",
      "ylh95x4AAAAJ"
    ],
    "9lmyivIAAAAJ": [
      "GrBOKEsAAAAJ",
      "PFQE6v8AAAAJ",
      "D2dgzzQAAAAJ",
      "PznKxuwAAAAJ",
      "TrrbXhIAAAAJ",
      "ORaHXn8AAAAJ",
      "mbcRJ2sAAAAJ",
      "Zbvss7Sjr2sC",
      "tsNsOJ4AAAAJ",
      "zmyHfb8AAAAJ",
      "valGGiQAAAAJ",
      "uBFV6SUAAAAJ",
      "AroaLZIAAAAJ",
      "Q5_G4oQAAAAJ"
    ],
    "NDHbbuAAAAAJ": [],
    "8R35rCwAAAAJ": [
      "vfPE6hgAAAAJ",
      "vtwH6GkAAAAJ",
      "zBUwaGkAAAAJ",
      "1wLVDP4AAAAJ",
      "yy0UFOwAAAAJ",
      "DRnOvU8AAAAJ",
      "B8wslVsAAAAJ",
      "-gJkPHIAAAAJ",
      "ADkiClQAAAAJ",
      "T9To2C0AAAAJ",
      "l-la0GQAAAAJ",
      "1O83J5MAAAAJ",
      "5VaXUQsAAAAJ",
      "FwxfQosAAAAJ",
      "VT7peyEAAAAJ",
      "bh-uRFMAAAAJ",
      "NSWI3OwAAAAJ",
      "d5y4iKAAAAAJ",
      "BsOkXDsAAAAJ",
      "OFlBL2kAAAAJ"
    ],
    "bh-uRFMAAAAJ": [
      "9xDADY4AAAAJ",
      "UfbuDH8AAAAJ",
      "-ltRSM0AAAAJ",
      "mqpjAt4AAAAJ",
      "W8VIEZgAAAAJ",
      "P4nfoKYAAAAJ",
      "GHpxNQIAAAAJ",
      "mu5Y2rYAAAAJ",
      "3kDtybgAAAAJ",
      "nABXo3sAAAAJ",
      "pvyI8GkAAAAJ",
      "d97bGd8AAAAJ",
      "AEsPCAUAAAAJ",
      "-XCiamcAAAAJ",
      "vtwH6GkAAAAJ",
      "7OTD-LEAAAAJ",
      "gYiCq88AAAAJ",
      "ijmuZ0wAAAAJ",
      "APgaFK0AAAAJ",
      "YLOz1kgAAAAJ"
    ],
    "a4unsk4AAAAJ": [
      "k-nF0qgAAAAJ",
      "aC55XVgAAAAJ",
      "euc0GX4AAAAJ",
      "9yRwkr4AAAAJ"
    ],
    "84WzBlYAAAAJ": [],
    "a_dbdxAAAAAJ": [],
    "aO8KpGcAAAAJ": [
      "iyDxq0EAAAAJ",
      "nTiSnwUAAAAJ",
      "yxUduqMAAAAJ",
      "hdTDzlQAAAAJ",
      "OP6ejqgAAAAJ",
      "DcV-5RAAAAAJ",
      "yDVn5LEAAAAJ",
      "2oy3OXYAAAAJ",
      "df-THM0AAAAJ",
      "5pKTRxEAAAAJ",
      "wSstCv0AAAAJ",
      "BgQkdsYAAAAJ",
      "IB_jPZ0AAAAJ",
      "ZvX1hXcAAAAJ",
      "bZ9oyW8AAAAJ",
      "3XLQbL8AAAAJ",
      "0mgEF28AAAAJ",
      "xRmmtzIAAAAJ",
      "Op-47sgAAAAJ",
      "LKv32bgAAAAJ"
    ],
    "LKv32bgAAAAJ": [
      "czyretsAAAAJ",
      "84WzBlYAAAAJ",
      "MzKvJhAAAAAJ",
      "pouyVyUAAAAJ",
      "6dskOSUAAAAJ",
      "itSa94cAAAAJ",
      "6-e-ZBEAAAAJ",
      "Ch9iRwQAAAAJ",
      "B7oP0bIAAAAJ",
      "CgItEbQAAAAJ",
      "MN9Kfg8AAAAJ",
      "Nn990CkAAAAJ",
      "zX3ba1kAAAAJ",
      "4zybTq4AAAAJ",
      "CpMjT0YAAAAJ",
      "RLvsC94AAAAJ",
      "Dtw3YBoAAAAJ",
      "07qshUgAAAAJ",
      "iyDxq0EAAAAJ",
      "aO8KpGcAAAAJ"
    ],
    "vtwH6GkAAAAJ": [
      "8R35rCwAAAAJ",
      "itSa94cAAAAJ",
      "8fztli4AAAAJ",
      "EMDboA4AAAAJ",
      "Vzr1RukAAAAJ",
      "iVLAQysAAAAJ",
      "bh-uRFMAAAAJ",
      "xOWBOKQAAAAJ",
      "kppa2vgAAAAJ",
      "HBztuGIAAAAJ",
      "XCZpOcAAAAAJ",
      "2oy3OXYAAAAJ",
      "x04W_mMAAAAJ",
      "8-p9CLsAAAAJ",
      "a5nY-pYAAAAJ",
      "jERkdhIAAAAJ",
      "FFWXLHUAAAAJ",
      "VjsNXysAAAAJ",
      "4mVPFQ8AAAAJ",
      "bLUllHEAAAAJ"
    ],
    "B96GkdgAAAAJ": [
      "vN-is70AAAAJ",
      "8fztli4AAAAJ",
      "uFJi3IUAAAAJ",
      "bh-uRFMAAAAJ",
      "p0sQC6sAAAAJ",
      "ID9QePIAAAAJ",
      "yxUduqMAAAAJ",
      "I1EvjZsAAAAJ",
      "e9gUdKwAAAAJ",
      "DpLFv4gAAAAJ",
      "DwdjBUUAAAAJ",
      "SaboshYAAAAJ",
      "fftO_HsAAAAJ",
      "94RFSSsAAAAJ",
      "b8OxVWUAAAAJ",
      "GUAoEcAAAAAJ",
      "QXyvv94AAAAJ",
      "K3QJPdMAAAAJ",
      "H3LMjtoAAAAJ",
      "IcaU830AAAAJ"
    ],
    "_pv1sEcAAAAJ": [
      "DZ3S--MAAAAJ",
      "kiFd6A8AAAAJ",
      "mnU3HpcAAAAJ",
      "NDyEvlQAAAAJ",
      "Q-v0BgUAAAAJ",
      "LfcroyAAAAAJ",
      "3yT6IX4AAAAJ",
      "rIjeeRsAAAAJ",
      "L-diWvQAAAAJ",
      "-zaDQ10AAAAJ",
      "0bwP0i4AAAAJ",
      "eWRBqsYAAAAJ",
      "CzOD0S4AAAAJ",
      "gzpWXPcAAAAJ",
      "on2DUKoAAAAJ",
      "pzw1-J4AAAAJ",
      "23ZXZvEAAAAJ",
      "VecEj6kAAAAJ",
      "yxUduqMAAAAJ",
      "O43_7KUAAAAJ"
    ],
    "Wi25oKoAAAAJ": [],
    "B847xq8AAAAJ": [
      "YAHWbtkAAAAJ",
      "_PZKLYUAAAAJ",
      "0lZoXCUAAAAJ",
      "fNOReswAAAAJ",
      "gRxBNZoAAAAJ",
      "_1hCq3UAAAAJ",
      "SqFoZNUAAAAJ",
      "UnEHCNkAAAAJ",
      "opbZfw0AAAAJ",
      "8O8MQEUAAAAJ",
      "zS3z8UgAAAAJ",
      "r44N6h8AAAAJ",
      "4Z6vo5QAAAAJ",
      "QWzsNMDsvlIC",
      "PS-TM94AAAAJ",
      "DYUloYkAAAAJ",
      "m_HQ-WQAAAAJ",
      "65FCPpwAAAAJ",
      "lH1PdF8AAAAJ",
      "y-8unsgAAAAJ"
    ],
    "_tNCgxMAAAAJ": [],
    "UgHB5oAAAAAJ": [
      "vtwH6GkAAAAJ",
      "2oy3OXYAAAAJ",
      "8R35rCwAAAAJ",
      "4mVPFQ8AAAAJ",
      "LUe32ToAAAAJ",
      "KgZxzjsAAAAJ",
      "7GSWYLQAAAAJ",
      "tsXh_hwAAAAJ",
      "-5_ksIkAAAAJ",
      "odFQXSYAAAAJ",
      "ZaJEZpYAAAAJ",
      "SlZavnIAAAAJ",
      "62e5CygAAAAJ",
      "eurA6WgAAAAJ",
      "UAwKvEsAAAAJ",
      "X-Sd3-8AAAAJ",
      "8fztli4AAAAJ",
      "Hyhp_zUAAAAJ",
      "4bl7qAgAAAAJ",
      "7t4jbPQAAAAJ"
    ]
  },
  "author_abstracts": {
    "Mk7BuSwAAAAJ": [
      {
        "title": "Sensitivity of growth of roots versus leaves to water stress: biophysical analysis and relation to water transport",
        "abstract": "Water transport is an integral part of the process of growth by cell expansion and accounts for most of the increase in cell volume characterizing growth. Under water deficiency, growth is readily inhibited and growth of roots is favoured over that of leaves. The mechanisms underlying this differential response are examined in terms of Lockhart's equations and water transport. For roots, when water potential (\u03a8) is suddenly reduced, osmotic adjustment occurs rapidly to allow partial turgor recovery and re\u2010establishment of \u03a8 gradient for water uptake, and the loosening ability of the cell wall increases as indicated by a rapid decline in yield\u2010threshold turgor. These adjustments permit roots to resume growth under low \u03a8. In contrast, in leaves under reductions in \u03a8 of similar magnitude, osmotic adjustment occurs slowly and wall loosening ability either does not increase substantially or actually decreases, leading to \u2026",
        "year": 2000,
        "authors": "Theodore C Hsiao and Liu\u2010Kang Xu"
      },
      {
        "title": "Evaluation of remote sensing based terrestrial productivity from MODIS using regional tower eddy flux network observations",
        "abstract": "The Moderate Resolution Spectroradiometer (MODIS) sensor has provided near real-time estimates of gross primary production (GPP) since March 2000. We compare four years (2000 to 2003) of satellite-based calculations of GPP with tower eddy CO2 flux-based estimates across diverse land cover types and climate regimes. We examine the potential error contributions from meteorology, leaf area index (LAI)/fPAR, and land cover. The error between annual GPP computed from NASA's Data Assimilation Office's (DAO) and tower-based meteorology is 28%, indicating that NASA's DAO global meteorology plays an important role in the accuracy of the GPP algorithm. Approximately 62% of MOD15-based estimates of LAI were within the estimates based on field optical measurements, although remaining values overestimated site values. Land cover presented the fewest errors, with most errors within the forest \u2026",
        "year": 2006,
        "authors": "Faith Ann Heinsch and Maosheng Zhao and Steven W Running and John S Kimball and Ramakrishna R Nemani and Kenneth J Davis and Paul V Bolstad and Bruce D Cook and Ankur R Desai and Daniel M Ricciuto and Beverly E Law and Walt C Oechel and Hyojung Kwon and Hongyan Luo and Steven C Wofsy and Allison L Dunn and J William Munger and Dennis D Baldocchi and Liukang Xu and David Y Hollinger and Andrew D Richardson and Paul C Stoy and Mario BS Siqueira and Russell K Monson and Sean P Burns and Lawrence B Flanagan"
      },
      {
        "title": "Seasonal variation in carbon dioxide exchange over a Mediterranean annual grassland in California",
        "abstract": "Understanding how environmental variables affect the processes that regulate the carbon flux over grassland is critical for large-scale modeling research, since grasslands comprise almost one-third of the earth\u2019s natural vegetation. To address this issue, fluxes of CO2 (Fc, flux toward the surface is negative) were measured over a Mediterranean, annual grassland in California, USA for 2 years with the eddy covariance method. To interpret the biotic and abiotic factors that modulate Fc over the course of a year we decomposed net ecosystem CO2 exchange into its constituent components, ecosystem respiration (Reco) and gross primary production (GPP). Daytime Reco was extrapolated from the relationship between temperature and nighttime Fc under high turbulent conditions. Then, GPP was estimated by subtracting daytime values of Fc from daytime estimates of Reco. Results show that most of carbon exchange \u2026",
        "year": 2004,
        "authors": "Liukang Xu and Dennis D Baldocchi"
      }
    ],
    "KWhGcA4AAAAJ": [
      {
        "title": "Cryo-CMOS circuits and systems for quantum computing applications",
        "abstract": "A fault-tolerant quantum computer with millions of quantum bits (qubits) requires massive yet very precise control electronics for the manipulation and readout of individual qubits. CMOS operating at cryogenic temperatures down to 4 K (cryo-CMOS) allows for closer system integration, thus promising a scalable solution to enable future quantum computers. In this paper, a cryogenic control system is proposed, along with the required specifications, for the interface of the classical electronics with the quantum processor. To prove the advantages of such a system, the functionality of key circuit blocks is experimentally demonstrated. The characteristic properties of cryo-CMOS are exploited to design a noise-canceling low-noise amplifier for spin-qubit RF-reflectometry readout and a class-F2,3 digitally controlled oscillator required to manipulate the state of qubits.",
        "year": 2017,
        "authors": "Bishnu Patra and Rosario M Incandela and Jeroen PG Van Dijk and Harald AR Homulle and Lin Song and Mina Shahmohammadi and Robert Bogdan Staszewski and Andrei Vladimirescu and Masoud Babaie and Fabio Sebastiano and Edoardo Charbon"
      },
      {
        "title": "Design and characterization of a CMOS 3-D image sensor based on single photon avalanche diodes",
        "abstract": "The design and characterization of an imaging system is presented for depth information capture of arbitrary three-dimensional (3-D) objects. The core of the system is an array of 32 /spl times/ 32 rangefinding pixels that independently measure the time-of-flight of a ray of light as it is reflected back from the objects in a scene. A single cone of pulsed laser light illuminates the scene, thus no complex mechanical scanning or expensive optical equipment are needed. Millimetric depth accuracies can be reached thanks to the rangefinder's optical detectors that enable picosecond time discrimination. The detectors, based on a single photon avalanche diode operating in Geiger mode, utilize avalanche multiplication to enhance light detection. On-pixel high-speed electrical amplification can therefore be eliminated, thus greatly simplifying the array and potentially reducing its power dissipation. Optical power requirements \u2026",
        "year": 2005,
        "authors": "Cristiano Niclass and Alexis Rochas and P-A Besse and Edoardo Charbon"
      },
      {
        "title": "Single-photon avalanche diode imagers in biophotonics: review and outlook",
        "abstract": "Single-photon avalanche diode (SPAD) arrays are solid-state detectors that offer imaging capabilities at the level of individual photons, with unparalleled photon counting and time-resolved performance. This fascinating technology has progressed at a very fast pace in the past 15 years, since its inception in standard CMOS technology in 2003. A host of architectures have been investigated, ranging from simpler implementations, based solely on off-chip data processing, to progressively \u201csmarter\u201d sensors including on-chip, or even pixel level, time-stamping and processing capabilities. As the technology has matured, a range of biophotonics applications have been explored, including (endoscopic) FLIM, (multibeam multiphoton) FLIM-FRET, SPIM-FCS, super-resolution microscopy, time-resolved Raman spectroscopy, NIROT and PET. We will review some representative sensors and their corresponding applications \u2026",
        "year": 2019,
        "authors": "Claudio Bruschini and Harald Homulle and Ivan Michel Antolovic and Samuel Burri and Edoardo Charbon"
      }
    ],
    "nQE56v0AAAAJ": [
      {
        "title": "Alignment between lean principles and practices and worker safety behavior",
        "abstract": "Alignment and synergy between the areas of lean construction and safety management are expected because all near misses and injury incidents represent waste from the lean perspective. This paper describes a research study of lean and safety principles and practices with regards to worker behavior and safety practices. Specifically, the study aimed to investigate the extent of alignment between lean construction principles/practices and worker behaviors associated with construction safety. To conduct the study, the researchers used a multistep process involving a comprehensive literature review, document content analyses by an expert panel, and a survey of industry practitioners knowledgeable about lean construction. The findings support the perspective that many similarities exist between the application and impacts of lean and safety principles and practices. Lean practitioners surveyed believe that \u2026",
        "year": 2016,
        "authors": "John A Gambatese and Catarina Pestana and Hyun Woo Lee"
      },
      {
        "title": "Evidence-driven sound detection for prenotification and identification of construction safety hazards and accidents",
        "abstract": "As the construction industry experiences a high rate of casualties and significant economic loss associated with accidents, safety has always been a primary concern. In response, several studies have attempted to develop new approaches and state-of-the-art technology for conducting autonomous safety surveillance of construction work zones such as vision-based monitoring. The current and proposed methods including human inspection, however, are limited to consistent and real-time monitoring and rapid event recognition of construction safety issues. In addition, the health and safety risks inherent in construction projects make it challenging for construction workers to be aware of possible safety risks and hazards according to daily planned work activities. To address the urgent demand of the industry to improve worker safety, this study involves the development of an audio-based event detection system to \u2026",
        "year": 2020,
        "authors": "Yong-Cheol Lee and Moeid Shariatfar and Abbas Rashidi and Hyun Woo Lee"
      },
      {
        "title": "Improving construction work zone safety using technology: a systematic review of applicable technologies",
        "abstract": "Once considered conventional, the construction industry is gradually increasing its reliance on innovations such as the application of technologies in safety management. Given the growing literature on technology applications in safety management and the varying opinions on the utility of applied technologies, a systematic review that streamlines findings from past studies is indispensable to construction stakeholders. Although a number of review studies are available in the building construction sector, the level of fragmentation and uniqueness within the construction industry necessitates a review study specifically targeting the heavy civil sector. In response, the present study applies a three-step approach to identify and review articles pertinent to the safety of highway construction work zones. The factors considered include the number of publications per year, publication locations, and technology types. In \u2026",
        "year": 2020,
        "authors": "Chukwuma Nnaji and John Gambatese and Hyun Woo Lee and Fan Zhang"
      }
    ],
    "bLH3dWgAAAAJ": [
      {
        "title": "Ocean One: A Robotic Avatar for Oceanic Discovery",
        "abstract": "The promise of oceanic discovery has long intrigued scientists and explorers, whether with the idea of studying underwater ecology and climate change or with the hope of uncovering natural resources and historic secrets buried deep in archaeological sites. This quest to explore the oceans requires skilled human access, yet much of the oceans are inaccessible to human divers; nearly ninetenths of the ocean floor is at 1 km or deeper [1]. Accessing these depths is imperative since factors such as pollution and deep-sea trawling threaten ecology and archaeological sites. While remotely operated vehicles (ROVs) are inadequate for the task, a robotic avatar could go where humans cannot and still embody human intelligence and intentions through immersive interfaces.",
        "year": 2016,
        "authors": "Oussama Khatib and Xiyang Yeh and Gerald Brantner and Brian Soe and Boyeon Kim and Shameek Ganguly and Hannah Stuart and Shiquan Wang and Mark Cutkosky and Aaron Edsinger and Phillip Mullins and Mitchell Barham and Christian R. Voolstra and Khaled Nabil Salama and Michel L\u2019Hour and Vincent Creuze"
      },
      {
        "title": "Design and testing of a selectively compliant underactuated hand",
        "abstract": "Motivated by the requirements of mobile manipulation, a compliant underactuated hand, capable of locking individual joints, has been developed. Locking is accomplished with electrostatic brakes in the joints and significantly increases the maximum pullout forces for power grasps. In addition, by locking and unlocking joints, the hand can adopt configurations and grasp sequences that would otherwise require a fully actuated solution. Other features of the hand include an integrated sensing suite that uses a common transduction technology on flexible printed circuits for tactile and proprioceptive sensing. The hand is analyzed using a three-dimensional rigid body analysis package with efficient simulation of compliant mechanisms and contacts with friction. This package allows one to evaluate design tradeoffs among link lengths, required tendon tensions, spring stiffnesses and braking requirements to grasp and \u2026",
        "year": 2014,
        "authors": "Daniel M Aukes and Barrett Heyneman and John Ulmen and Hannah Stuart and Mark R Cutkosky and Susan Kim and Pablo Garcia and Aaron Edsinger"
      },
      {
        "title": "The ocean one hands: An adaptive design for robust marine manipulation",
        "abstract": "Underactuated, compliant, tendon-driven robotic hands are suited for deep-sea exploration. The robust Ocean One hand design utilizes elastic finger joints and a spring transmission to achieve a variety of pinch and wrap grasps. Compliance in the fingers and transmission determines the degree of load-sharing among contacts and the hands\u2019 ability to secure irregularly shaped objects. However, it can also decrease external grasp stiffness and acquisition reliability. SimGrasp, a flexible dynamic hand simulator, enables parametric studies of the hand for acquisition and pull-out tests with varying transmission spring rates. In the present application, we take advantage of achieving different stiffnesses by reversing the direction of tendon windup using a torsional spring-loaded winch. With this provision, the hand can be relatively soft for handling delicate objects and stiff for tasks requiring strength. Two hands were field \u2026",
        "year": 2017,
        "authors": "Hannah Stuart and Shiquan Wang and Oussama Khatib and Mark R Cutkosky"
      }
    ],
    "_5PRunQAAAAJ": [
      {
        "title": "Essential biodiversity variables",
        "abstract": "Reducing the rate of biodiversity loss and averting dangerous biodiversity change are international goals, reasserted by the Aichi Targets for 2020 by Parties to the United Nations (UN) Convention on Biological Diversity (CBD) after failure to meet the 2010 target (, ). However, there is no global, harmonized observation system for delivering regular, timely data on biodiversity change . With the first plenary meeting of the Intergovernmental Science-Policy Platform on Biodiversity and Ecosystem Services (IPBES) soon under way, partners from the Group on Earth Observations Biodiversity Observation Network (GEO BON)  are developing\u2014and seeking consensus around\u2014Essential Biodiversity Variables (EBVs) that could form the basis of monitoring programs worldwide.",
        "year": 2013,
        "authors": "Henrique Miguel Pereira and Simon Ferrier and M Walters and Gary N Geller and RHG Jongman and Robert J Scholes and Michael William Bruford and N Brummitt and SHM Butchart and AC Cardoso and NC Coops and E Dulloo and DP Faith and J Freyhof and RD Gregory and C Heip and R H\u00f6ft and G Hurtt and W Jetz and DS Karp and MA McGeoch and D Obura and Y Onoda and N Pettorelli and B Reyers and R Sayre and JPW Scharlemann and SN Stuart and E Turak and M Walpole and M Wegmann"
      },
      {
        "title": "A global synthesis reveals biodiversity-mediated benefits for crop production",
        "abstract": "Human land use threatens global biodiversity and compromises multiple ecosystem functions critical to food production. Whether crop yield\u2013related ecosystem services can be maintained by a few dominant species or rely on high richness remains unclear. Using a global database from 89 studies (with 1475 locations), we partition the relative importance of species richness, abundance, and dominance for pollination; biological pest control; and final yields in the context of ongoing land-use change. Pollinator and enemy richness directly supported ecosystem services in addition to and independent of abundance and dominance. Up to 50% of the negative effects of landscape simplification on ecosystem services was due to richness losses of service-providing organisms, with negative consequences for crop yields. Maintaining the biodiversity of ecosystem service providers is therefore vital to sustain the flow of key \u2026",
        "year": 2019,
        "authors": "Matteo Dainese and Emily A Martin and Marcelo A Aizen and Matthias Albrecht and Ignasi Bartomeus and Riccardo Bommarco and Luisa G Carvalheiro and Rebecca Chaplin-Kramer and Vesna Gagic and Lucas A Garibaldi and Jaboury Ghazoul and Heather Grab and Mattias Jonsson and Daniel S Karp and Christina M Kennedy and David Kleijn and Claire Kremen and Douglas A Landis and Deborah K Letourneau and Lorenzo Marini and Katja Poveda and Romina Rader and Henrik G Smith and Teja Tscharntke and Georg KS Andersson and Isabelle Badenhausser and Svenja Baensch and Antonio Diego M Bezerra and Felix JJA Bianchi and Virginie Boreux and Vincent Bretagnolle and Berta Caballero-Lopez and Pablo Cavigliasso and Aleksandar \u0106etkovi\u0107 and Natacha P Chacoff and Alice Classen and Sarah Cusser and Felipe D da Silva E Silva and G Arjen De Groot and Jan H Dudenh\u00f6ffer and Johan Ekroos and Thijs Fijen and Pierre Franck and Breno M Freitas and Michael PD Garratt and Claudio Gratton and Juliana Hip\u00f3lito and Andrea Holzschuh and Lauren Hunt and Aaron L Iverson and Shalene Jha and Tamar Keasar and Tania N Kim and Miriam Kishinevsky and Bj\u00f6rn K Klatt and Alexandra-Maria Klein and Kristin M Krewenka and Smitha Krishnan and Ashley E Larsen and Claire Lavigne and Heidi Liere and Bea Maas and Rachel E Mallinger and Eliana Martinez Pachon and Alejandra Mart\u00ednez-Salinas and Timothy D Meehan and Matthew GE Mitchell and Gonzalo AR Molina and Maike Nesper and Lovisa Nilsson and Megan E O'rourke and Marcell K Peters and Milan Ple\u0107a\u0161 and Simon G Potts and Davi de L Ramos and Jay A Rosenheim and Maj Rundl\u00f6f and Adrien Rusch and Agust\u00edn S\u00e1ez and Jeroen Scheper and Matthias Schleuning and Julia M Schmack and Amber R Sciligo and Colleen Seymour and Dara A Stanley and Rebecca Stewart and Jane C Stout and Louis Sutter and Mayura B Takada and Hisatomo Taki and Giovanni Tamburini and Matthias Tschumi and Blandina F Viana and Catrin Westphal and Bryony K Willcox and Stephen D Wratten and Akira Yoshioka and Carlos Zaragoza-Trello and Wei Zhang and Yi Zou and Ingolf Steffan-Dewenter"
      },
      {
        "title": "Crop pests and predators exhibit inconsistent responses to surrounding landscape composition",
        "abstract": "The idea that noncrop habitat enhances pest control and represents a win\u2013win opportunity to conserve biodiversity and bolster yields has emerged as an agroecological paradigm. However, while noncrop habitat in landscapes surrounding farms sometimes benefits pest predators, natural enemy responses remain heterogeneous across studies and effects on pests are inconclusive. The observed heterogeneity in species responses to noncrop habitat may be biological in origin or could result from variation in how habitat and biocontrol are measured. Here, we use a pest-control database encompassing 132 studies and 6,759 sites worldwide to model natural enemy and pest abundances, predation rates, and crop damage as a function of landscape composition. Our results showed that although landscape composition explained significant variation within studies, pest and enemy abundances, predation rates \u2026",
        "year": 2018,
        "authors": "Daniel S Karp and Rebecca Chaplin-Kramer and Timothy D Meehan and Emily A Martin and Fabrice DeClerck and Heather Grab and Claudio Gratton and Lauren Hunt and Ashley E Larsen and Alejandra Mart\u00ednez-Salinas and Megan E O\u2019rourke and Adrien Rusch and Katja Poveda and Mattias Jonsson and Jay A Rosenheim and Nancy A Schellhorn and Teja Tscharntke and Stephen D Wratten and Wei Zhang and Aaron L Iverson and Lynn S Adler and Matthias Albrecht and Audrey Alignier and Gina M Angelella and Muhammad Zubair Anjum and Jacques Avelino and P\u00e9ter Bat\u00e1ry and Johannes M Baveco and Felix JJA Bianchi and Klaus Birkhofer and Eric W Bohnenblust and Riccardo Bommarco and Michael J Brewer and Berta Caballero-L\u00f3pez and Yves Carri\u00e8re and Lu\u00edsa G Carvalheiro and Luis Cayuela and Mary Centrella and Aleksandar \u0106etkovi\u0107 and Dominic Charles Henri and Ariane Chabert and Alejandro C Costamagna and Aldo De la Mora and Joop De Kraker and Nicolas Desneux and Eva Diehl and Tim Diek\u00f6tter and Carsten F Dormann and James O Eckberg and Martin H Entling and Daniela Fiedler and Pierre Franck and FJ Frank van Veen and Thomas Frank and Vesna Gagic and Michael PD Garratt and Awraris Getachew and David J Gonthier and Peter B Goodell and Ignazio Graziosi and Russell L Groves and Geoff M Gurr and Zachary Hajian-Forooshani and George E Heimpel and John D Herrmann and Anders S Huseth and Diego J Incl\u00e1n and Adam J Ingrao and Phirun Iv and Katja Jacot and Gregg A Johnson and Laura Jones and Marina Kaiser and Joe M Kaser and Tamar Keasar and Tania N Kim and Miriam Kishinevsky and Douglas A Landis and Blas Lavandero and Claire Lavigne and Anne Le Ralec and Debissa Lemessa and Deborah K Letourneau and Heidi Liere and Yanhui Lu and Yael Lubin and Tim Luttermoser and Bea Maas and Kevi Mace and Filipe Madeira and Viktoria Mader and Anne Marie Cortesero and Lorenzo Marini and Eliana Martinez and Holly M Martinson and Philippe Menozzi and Matthew GE Mitchell and Tadashi Miyashita and Gonzalo AR Molina and Marco A Molina-Montenegro and Matthew E O\u2019Neal and Itai Opatovsky and Sebaastian Ortiz-Martinez and Michael Nash and \u00d6rjan \u00d6stman and Annie Ouin and Damie Pak and Daniel Paredes and Soroush Parsa and Hazel Parry and Ricardo Perez-Alvarez and David J Perovi\u0107 and Julie A Peterson and Sandrine Petit and Stacy M Philpott and Manuel Plantegenest and Milan Ple\u0107a\u0161 and Therese Pluess and Xavier Pons and Simon G Potts and Richard F Pywell and David W Ragsdale and Tatyana A Rand and Lucie Raymond and Beno\u00eet Ricci and Chris Sargent and Jean-Pierre Sarthou and Julia Saulais and Jessica Sch\u00e4ckermann and Nick P Schmidt and Gudrun Schneider and Christof Sch\u00fcepp and Frances S Sivakoff and Henrik G Smith and Kaitlin Stack Whitney and Sonja Stutz and Zsofia Szendrei and Mayura B Takada and Hisatomo Taki and Giovanni Tamburini and Linda J Thomson and Yann Tricault and Noelline Tsafack and Matthias Tschumi and Muriel Valantin-Morison and Mai Van Trinh and Wopke Van Der Werf and Kerri T Vierling and Ben P Werling and Jennifer B Wickens"
      }
    ],
    "DCRTLJ8AAAAJ": [
      {
        "title": "Ocean one: A robotic avatar for oceanic discovery",
        "abstract": "The promise of oceanic discovery has long intrigued scientists and explorers, whether with the idea of studying underwater ecology and climate change or with the hope of uncovering natural resources and historic secrets buried deep in archaeological sites. This quest to explore the oceans requires skilled human access, yet much of the oceans are inaccessible to human divers; nearly ninetenths of the ocean floor is at 1 km or deeper [1]. Accessing these depths is imperative since factors such as pollution and deep-sea trawling threaten ecology and archaeological sites. While remotely operated vehicles (ROVs) are inadequate for the task, a robotic avatar could go where humans cannot and still embody human intelligence and intentions through immersive interfaces.",
        "year": 2016,
        "authors": "Oussama Khatib and Xiyang Yeh and Gerald Brantner and Brian Soe and Boyeon Kim and Shameek Ganguly and Hannah Stuart and Shiquan Wang and Mark Cutkosky and Aaron Edsinger and Phillip Mullins and Mitchell Barham and Christian R Voolstra and Khaled Nabil Salama and Michel l'Hour and Vincent Creuze"
      },
      {
        "title": "Achieving haptic perception in forceps\u2019 manipulator using pneumatic artificial muscle",
        "abstract": "Many minimally invasive surgical procedures are now performed using teleoperated robotic systems. However, such commercially available systems do not provide significant force feedback to the surgeon. This reduces surgeon's dexterity and increases tissue trauma when performing the operation. In this paper, a compact and lightweight forceps' manipulator using pneumatic artificial muscles (PAMs) for minimally invasive surgery is presented, which allows for the perception of manipulation force without the usage of the force sensor. The main advantage of this concept is that no force sensor has to be integrated into surgical instruments and inserted into the patient's body. Rather, a disturbance observer is integrated into the slave-side controller for the estimation of the external force acting at the forcep's tip. This approach reduces costs and stabilizability demands for forceps' manipulator while enables haptic \u2026",
        "year": 2011,
        "authors": "Hongbing Li and Kenji Kawashima and Kotaro Tadano and Shameek Ganguly and Sumire Nakano"
      },
      {
        "title": "Control of pneumatic artificial muscle system through experimental modelling",
        "abstract": "This paper deals with position control of a single degree of freedom (sdof) manipulator actuated by Pneumatic Artificial Muscle (PAM) actuator. Though the compliance characteristics of these actuators are desirable, their inherent non-linearities due to compressibility of air and non-linear load\u2013contraction characteristics make them difficult to model and design of controller becomes very complex. To overcome this, a novel method is hereby proposed to establish an accurate empirical model for the system. The quasi-static characteristics of the PAM are first modelled followed by the dynamic characteristics through spectral analysis. For cost competitiveness, the present work incorporates inexpensive on\u2013off switching valves operated using a novel model based proportional pressure regulator developed using a modified PWM algorithm. Finally, a conventional PID position controller is extended using the empirical \u2026",
        "year": 2012,
        "authors": "Shameek Ganguly and Akash Garg and Akshay Pasricha and SKa Dwivedy"
      }
    ],
    "Zbvss7Sjr2sC": [
      {
        "title": "A multiscale theory for the dynamical evolution of sentiment in novels",
        "abstract": "Recent work in literary sentiment analysis has suggested that shifts in emotional valence may serve as a reliable proxy for plot movement in novels. The raw sentiment time series of a novel can now be extracted using a variety of different methods, and after extraction, filtering is commonly used to smooth the irregular sentiment time series. Using an adaptive filter, which is among the most effective in determining trends of a signal, reducing noise, and performing fractal and multifractal analysis, we show that the energy of the smoothed sentiment signals decays with the smoothing parameter as a power-law, characterized by a Hurst parameter H of 1/2 <; H <; 1, which signifies long-range correlations. We further show that a smoothed sentiment arc corresponds to the sentiment of fast playing mode or sentiment retained in one's memory, and that for a novel to be both captivating and rich, H has to be larger than 1/2 but \u2026",
        "year": 2016,
        "authors": "Jianbo Gao and Matthew L Jockers and John Laudun and Timothy Tangherlini"
      },
      {
        "title": "Computing folklore studies: Mapping over a century of scholarly production through topics",
        "abstract": "Folklorists, like most practitioners in a field, understand the history of their discipline through a combination of their own reading and the consensus inherited from their graduate training and professional interactions. Disciplinary history, an effectively oral form of communication, codifies quickly. Highly contingent and random processes become widely understood as historically inevitable. In this preliminary report on a larger project examining the application of computational methodologies in the service of intellectual history, we explore the use of topic modeling as a way to understand the ebb and flow of topics and paradigms within a domain. Using JSTOR\u2019s Data for Research application programming interface to access the contents of 6,778 articles from three folklore studies journals (Journal of American Folklore, Western Folklore, Journal of Folklore Research), we used one form of topic modeling, Latent \u2026",
        "year": 2013,
        "authors": "John Laudun and Jonathan Goodwin"
      },
      {
        "title": "Reading Hurston Writing",
        "abstract": "Professor of English at the University of Louisiana-Lafayette. He indicates that he owes a number of debts in the development of this essay, chief among which is to Susan Gubar, of the Indiana University Department of English, for her encouragement in seeing the essay through multiple drafts. He would also like to thank Frederick McElroy and John McCluskey of lU's Afro-American Studies department for their guidance as Laudun embarked upon revisions as well as upon his career, the Twentieth Century Literature Conference held annually at the University of Louisville, and the anonymous and demanding reader for AAR whose comments reminded Laudun of the essay's essential point, something sometimes lost, he reports, in multiple drafts over several years.",
        "year": 2004,
        "authors": "John Laudun"
      }
    ],
    "NDHbbuAAAAAJ": [
      {
        "title": "Multirate 3-D subband coding of video",
        "abstract": "We propose a full color video compression strategy, based on 3-D subband coding with camera pan compensation, to generate a single embedded bit stream supporting multiple decoder display formats and a wide, finely gradated range of bit rates. An experimental implementation of our algorithm produces a single bit stream, from which suitable subsets are extracted to be compatible with many decoder frame sizes and frame rates and to satisfy transmission bandwidth constraints ranging from several tens of kilobits per second to several megabits per second. Reconstructed video quality from any of these bit stream subsets is often found to exceed that obtained from an MPEG-1 implementation, operated with equivalent bit rate constraints, in both perceptual quality and mean squared error. In addition, when restricted to 2-D, the algorithm produces some of the best results available in still image compression.<>",
        "year": 1994,
        "authors": "David Taubman and Avideh Zakhor"
      },
      {
        "title": "Iterative procedures for reduction of blocking effects in transform image coding",
        "abstract": "The authors propose an iterative block reduction technique based on the theory of a projection onto convex sets. The idea is to impose a number of constraints on the coded image in such a way as to restore it to its original artifact-free form. One such constraint can be derived by exploiting the fact that the transform-coded image suffering from blocking effects contains high-frequency vertical and horizontal artifacts corresponding to vertical and horizontal discontinuities across boundaries of neighboring blocks. Another constraint has to be with the quantization intervals of the transform coefficients. Specifically, the decision levels associated with transform coefficient quantizers can be used as lower and upper bounds on transform coefficients, which in turn define boundaries of the convex set for projection. A few examples of the proposed approach are presented.<>",
        "year": 2002,
        "authors": "Avideh Zakhor"
      },
      {
        "title": "Applications of video-content analysis and retrieval",
        "abstract": "Managing multimedia data requires more than collecting the data into storage archives and delivering it via networks to homes or offices. We survey technologies and applications for video-content analysis and retrieval. We also give specific examples.",
        "year": 2002,
        "authors": "Nevenka Dimitrova and Hong-Jiang Zhang and Behzad Shahraray and Ibrahim Sezan and Thomas Huang and Avideh Zakhor"
      }
    ],
    "VizEaQEAAAAJ": [
      {
        "title": "Transitioning to sustainable agriculture requires growing and sustaining an ecologically skilled workforce",
        "abstract": "In the face of rapidly advancing climate change, biodiversity loss, and water scarcity, it is clear that global agriculture must swiftly and decisively shift toward sustainability. Fortunately, farmers and researchers have developed a thoroughly studied pathway to this transition: agroecological farming systems that mimic natural ecosystems, creating tightly coupled cycles of energy, water, and nutrients. A critical and underappreciated feature of agroecological systems is that they replace fossil fuel- and chemical -intensive management with knowledge-intensive management. Hence, the greatest sustainability challenge for agriculture may well be that of replacing non-renewable resources with ecologically-skilled people, and doing so in ways that create and support desirable rural livelihoods. Yet over the past century, US agriculture has been trending in the opposite direction, rapidly replacing knowledgeable people with non-renewable resources and eroding rural economies in the process. Below, we suggest how US policy could pivot to enable and support the ecologically skilled workforce needed to achieve food security in the face of climate change.",
        "year": 2019,
        "authors": "Liz Carlisle and Maywa Montenegro de Wit and Marcia S DeLonge and Alastair Iles and Adam Calo and Christy Getz and Joanna Ory and Katherine Munden-Dixon and Ryan Galt and Brett Melone and Reggie Knox and Daniel Press"
      },
      {
        "title": "Securing the future of US agriculture: The case for investing in new entry sustainable farmers",
        "abstract": "Sustainable agriculture is among the most urgently needed work in the United States, for at least three reasons: we face an environmental crisis, a health crisis, and a rural economic crisis. Addressing these pressing crises through sustainability transition will require growing our agricultural workforce: both because the current farm population is aging, and because sustainable agriculture is knowledge-intensive work that substitutes experiential knowledge of farm ecosystems for harmful industrial inputs. Given its social value, sustainable agriculture ought to be a welcoming profession. But at present, US agriculture is decidedly unwelcoming for nearly all who work in it \u2013 and it puts new entry and sustainable farmers at a distinct disadvantage. In this paper, we first examine why it is so hard to enter and succeed in sustainable farming. We find that new entrants struggle to gain critical access, assets, and assistance \u2026",
        "year": 2019,
        "authors": "Liz Carlisle and Maywa Montenegro De Wit and Marcia S DeLonge and Adam Calo and Christy Getz and Joanna Ory and Katherine Munden-Dixon and Ryan Galt and Brett Melone and Reggie Knox and Alastair Iles and Daniel Press"
      },
      {
        "title": "Food policy councils and local governments: Creating effective collaboration for food systems change",
        "abstract": "Drawing data from comparative case studies of 10 California food policy councils (FPCs), this paper describes the nature of the relationships between local governments and FPCs and examines how these relationships support policy-related activities and food systems change. We focus our comparisons on distinct organizational structures, resource flows, and policy activities. All but one of the 10 councils is organized as a multisector community collaborative, rather than as an independent nonprofit organization or a government advisory body. Each includes local government personnel as members and most depend on government resources for their operations, including meeting spaces, facilitation, information, and/or direct funding. All 10 councils feature regular meetings at which information is shared to build awareness, relationships, and trust, all of which can indirectly shape policy agendas and initiatives. This policy relevant work is feasible even for small councils with few resources. FPC leaders can also seize opportunities by considering the stages of the policy process they hope to influence, the types of policy issues they wish to address, the time frame it may take to realize different types of policy goals, and the degree to which they will seek incremental or more fundamental changes. We find that structural autonomy\u2014being organized outside of the government while maintaining strong collaborations with the government\u2014helps food policy councils retain their independence while promoting more inclusive policy making processes that link community members to the government.",
        "year": 2018,
        "authors": "Clare Gupta and Dave Campbell and Kate Munden-Dixon and Jennifer Sowerwine and Shosha Capps and Gail Feenstra and Julia Van Soelen Kim"
      }
    ],
    "tsNsOJ4AAAAJ": [
      {
        "title": "Detecting dynamical changes in time series using the permutation entropy",
        "abstract": "Timely detection of unusual and/or unexpected events in natural and man-made systems has deep scientific and practical relevance. We show that the recently proposed conceptually simple and easily calculated measure of permutation entropy can be effectively used to detect qualitative and quantitative dynamical changes. We illustrate our results on two model systems as well as on clinically characterized brain wave data from epileptic patients.",
        "year": 2004,
        "authors": "Yinhe Cao Cao and Wen-wen Tung and J. B. Gao and V.A. Protopopescu and L. M. Hively"
      },
      {
        "title": "Multiscale analysis of complex time series: integration of chaos and random fractal theory, and beyond",
        "abstract": "The only integrative approach to chaos and random fractal theory Chaos and random fractal theory are two of the most important theories developed for data analysis. Until now, there has been no single book that encompasses all of the basic concepts necessary for researchers to fully understand the ever-expanding literature and apply novel methods to effectively solve their signal processing problems. Multiscale Analysis of Complex Time Series fills this pressing need by presenting chaos and random fractal theory in a unified manner. Adopting a data-driven approach, the book covers: DNA sequence analysis EEG analysis Heart rate variability analysis Neural information processing Network traffic modeling Economic time series analysis And more Additionally, the book illustrates almost every concept presented through applications and a dedicated Web site is available with source codes written in various languages, including Java, Fortran, C, and MATLAB, together with some simulated and experimental data. The only modern treatment of signal processing with chaos and random fractals unified, this is an essential book for researchers and graduate students in electrical engineering, computer science, bioengineering, and many other fields.",
        "year": 2007,
        "authors": "Jianbo Gao and Yinhe Cao and Wen-wen Tung and Jing Hu"
      },
      {
        "title": "Denoising nonlinear time series by adaptive filtering and wavelet shrinkage: a comparison",
        "abstract": " Time series measured in real world is often nonlinear, even chaotic. To effectively extract desired information from measured time series, it is important to preprocess data to reduce noise. In this Letter, we propose an adaptive denoising algorithm. Using chaotic Lorenz data and calculating root-mean-square-error, Lyapunov exponent, and correlation dimension, we show that our adaptive algorithm more effectively reduces noise in the chaotic Lorenz system than wavelet denoising with three different thresholding choices. We further analyze an electroencephalogram (EEG) signal in sleep apnea and show that the adaptive algorithm again more effectively reduces the Electrocardiogram (ECG) and other types of noise contaminated in EEG than wavelet approaches. ",
        "year": 2009,
        "authors": "Jianbo Gao and Hussain Sultan and Jing Hu and Wen-Wen Tung"
      }
    ],
    "_vJSGrkAAAAJ": [
      {
        "title": "The last planner system of production control",
        "abstract": "Project controls have traditionally been focused on after-the-fact detection of variances. This thesis proposes a control system, the Last Planner system, that causes the realization of plans, and thus supplements project management\u2019s concern for management of contracts with the management of production.  The Last Planner system has previously been successfully applied by firms with direct responsibility for production management; e.g., specialty contractors. This thesis extends system application to those coordinating specialists, both in design and construction, through a series of case studies, one of which also explores the limits of unilateral implementation by specialists.  In addition to the extended application, two questions drive this research. The first question is 1) What can be done by way of tools provided and improved implementation of the Last Planner system of production control to increase plan reliability above the 70% PPC level? Previous research revealed substantial improvement in productivity for those who improved plan reliability to the 70% level, consequently there is reason to hope for further improvement, possibly in all performance dimensions, especially with application across an entire project rather than limited to individual specialty firms. That question is explored in three case studies, the last of which achieved the 90% target.   The second question is 2) How/Can Last Planner be successfully applied to increase plan reliability during design processes. That question is explored in an extensive case study, which significantly contributes to understanding the design process from the perspective of active control, but \u2026",
        "year": 2000,
        "authors": "Herman Glenn Ballard"
      },
      {
        "title": "Shielding production: Essential step in production control",
        "abstract": "Effective production control systems are structured around the assignment as the unit of analysis. The quality of work assignments in production units such as construction crews and engineering squads is the key to production control and for determining production unit productivity. Research has revealed that the quality of assignments can be substantially improved by forming and selecting them to meet soundness, sequence, and size criteria. Quality assignments shield production units from work flow uncertainty, enabling those units to improve their own productivity, and also improve the productivity of the production units downstream. The associated reduction in task duration can shorten projects. Further reduction of project duration comes from shortening the buffers previously needed to accommodate flow uncertainty.",
        "year": 1998,
        "authors": "Glenn Ballard and Gregory Howell"
      },
      {
        "title": "The lean project delivery system: An update",
        "abstract": "The Lean Project Delivery System emerged in 2000 from theoretical and practical investigations, and is in process of on-going development through experimentation in many parts of the world. In recent years, experiments have focused on the definition and design phase of projects, applying concepts and methods drawn from the Toyota Product Development System, most especially target costing and set based design. These have been adapted for use in the construction industry and integrated with computer modeling and relational forms of contract. Although by no means a finished work, the Lean Project Delivery System has developed sufficiently to warrant an updated description and presentation to industry and academia, incorporating processes and practices that have emerged since earlier publications.",
        "year": 2008,
        "authors": "Glenn Ballard"
      }
    ],
    "zmyHfb8AAAAJ": [
      {
        "title": "Macroanalysis: Digital methods and literary history",
        "abstract": "In this volume, Matthew L. Jockers introduces readers to large-scale literary computing and the revolutionary potential of macroanalysis--a new approach to the study of the literary record designed for probing the digital-textual world as it exists today, in digital form and in large quantities. Using computational analysis to retrieve key words, phrases, and linguistic patterns across thousands of texts in digital libraries, researchers can draw conclusions based on quantifiable evidence regarding how literary trends are employed over time, across periods, within regions, or within demographic groups, as well as how cultural, historical, and societal linkages may bind individual authors, texts, and genres into an aggregate literary culture. Moving beyond the limitations of literary interpretation based on the\" close-reading\" of individual works, Jockers describes how this new method of studying large collections of digital material can help us to better understand and contextualize the individual works within those collections.",
        "year": 2013,
        "authors": "Matthew L Jockers"
      },
      {
        "title": "Text analysis with R",
        "abstract": "There is a tradition in the teaching of programming languages in which students write a script to print out (to their screen) the words hello world. Though this book is about programming in R, this is not a programming book. Instead this text is designed to get you familiar with the R environment while engaging with, exploring, and even addressing some real text analysis questions. If you are like us, you probably launched R and started typing in commands a few hours ago. Maybe you got stuck, hit the wall, and are now turning to this book for a little shove in the right direction. If you are like us, you probably headed to the index first and tried to find some function name or keyword (such as frequency list or count word occurrences) to get you rolling. You are ready to jump in and start working, and if you\u2019ve ever done any coding before, you may be wondering (maybe dreading) if this is going to be another one of those \u2026",
        "year": 2020,
        "authors": "Matthew L Jockers and Rosamond Thalken"
      },
      {
        "title": "Significant themes in 19th-century literature",
        "abstract": "External factors such as author gender, author nationality, and date of publication can affect both the choice of literary themes in novels and the expression of those themes, but the extent of this association is difficult to quantify. In this work, we apply statistical methods to identify and extract hundreds of topics (themes) from a corpus of 19th-century British, Irish, and American fiction. We use these topics as a measurable, data-driven proxy for literary themes and assess how external factors may predict fluctuations in the use of themes and the individual word choices within themes. We use topics not only to measure these associations but also to evaluate whether this evidence is statistically significant.",
        "year": 2013,
        "authors": "Matthew L Jockers and David Mimno"
      }
    ],
    "tVZggyIAAAAJ": [
      {
        "title": "Ocean one: A robotic avatar for oceanic discovery",
        "abstract": "The promise of oceanic discovery has long intrigued scientists and explorers, whether with the idea of studying underwater ecology and climate change or with the hope of uncovering natural resources and historic secrets buried deep in archaeological sites. This quest to explore the oceans requires skilled human access, yet much of the oceans are inaccessible to human divers; nearly ninetenths of the ocean floor is at 1 km or deeper [1]. Accessing these depths is imperative since factors such as pollution and deep-sea trawling threaten ecology and archaeological sites. While remotely operated vehicles (ROVs) are inadequate for the task, a robotic avatar could go where humans cannot and still embody human intelligence and intentions through immersive interfaces.",
        "year": 2016,
        "authors": "Oussama Khatib and Xiyang Yeh and Gerald Brantner and Brian Soe and Boyeon Kim and Shameek Ganguly and Hannah Stuart and Shiquan Wang and Mark Cutkosky and Aaron Edsinger and Phillip Mullins and Mitchell Barham and Christian R Voolstra and Khaled Nabil Salama and Michel L'Hour and Vincent Creuze"
      },
      {
        "title": "Controlling Ocean One: Human\u2013robot collaboration for deep\u2010sea manipulation",
        "abstract": "Deploying robots to explore venues that are inaccessible to humans, or simply inhospitable, has been a longstanding ambition of scientists, engineers, and explorers across numerous fields. The deep sea exemplifies an environment that is largely uncharted and denies human presence. Central to exploration is the capacity to deliver dexterous robotic manipulation to this unstructured environment. Unmanned underwater vehicles (UUVs) are successful in providing passive solutions for observation and mapping but currently are far from capable of delivering human\u2010level dexterity. The ones providing manipulation typically are UUVs coupled with position\u2010controlled hydraulic arms using disjoint controllers for navigation and manipulation that require expert operators. Ocean One is a humanoid underwater robot designed specifically for underwater manipulation. In this paper, we present Ocean One's control \u2026",
        "year": 2021,
        "authors": "Gerald Brantner and Oussama Khatib"
      },
      {
        "title": "Haptic fMRI: Combining functional neuroimaging with haptics for studying the brain's motor control representation",
        "abstract": "A challenging problem in motor control neuroimaging studies is the inability to perform complex human motor tasks given the Magnetic Resonance Imaging (MRI) scanner's disruptive magnetic fields and confined workspace. In this paper, we propose a novel experimental platform that combines Functional MRI (fMRI) neuroimaging, haptic virtual simulation environments, and an fMRI-compatible haptic device for real-time haptic interaction across the scanner workspace (above torso ~ .65\u00d7.40\u00d7.20m<;sup>3<;/sup>). We implement this Haptic fMRI platform with a novel haptic device, the Haptic fMRI Interface (HFI), and demonstrate its suitability for motor neuroimaging studies. HFI has three degrees-of-freedom (DOF), uses electromagnetic motors to enable high-fidelity haptic rendering (>350Hz), integrates radio frequency (RF) shields to prevent electromagnetic interference with fMRI (temporal SNR >100), and is \u2026",
        "year": 2013,
        "authors": "Samir Menon and Gerald Brantner and Chris Aholt and Kendrick Kay and Oussama Khatib"
      }
    ],
    "UtRiqWQAAAAJ": [
      {
        "title": "Causes of construction delay: traditional contracts",
        "abstract": "Many projects experience extensive delays and thereby exceed initial time and cost estimates. In addition to imparting the economic feasibility of capital projects, extensive delays provide a fertile ground for costly disputes and claims. This paper presents the findings of a survey aimed at identifying the most important causes of delays in construction projects with traditional type contracts from the viewpoint of construction contractors and consultants. Results of the survey indicate that contractors and consultants agreed that owner interference, inadequate contractor experience, financing and payments, labor productivity, slow decision making, improper planning, and subcontractors are among the top ten most important factors. It is hoped that these findings will guide efforts to improve the performance of the construction industry, and will be useful to international engineering and construction firms seeking a share in \u2026",
        "year": 2002,
        "authors": "Abdalla M Odeh and Hussien T Battaineh"
      },
      {
        "title": "Economic costs of traffic accidents in Jordan",
        "abstract": "The objectives of this study were to estimate the economic costs of traffic accidents in Jordan during the year of 1996 and to derive unit accident costs for various accident severity levels. The related data were acquired from different sources, including traffic police records, insurance companies, private hospitals and medical centers. In this study, a framework for applying unit casualty class costs, unit property damage cost, as well as police activities and insurance administration costs to accidents of various severity levels was suggested. The loss-of-output, the loss quality of life, the community and family losses, the temporary and permanent losses, and hospitalization and medical treatment costs were estimated in computing the unit cost for fatalities or injuries of different casualty classes. The vehicle repair cost, detention period cost, and public and private costs were accounted for in estimating the unit cost of \u2026",
        "year": 1999,
        "authors": "Hashem R Al-Masaeid and Adel A Al-Mashakbeh and Abdalla M Qudah"
      },
      {
        "title": "Knowledge-based assembly of simulation networks using construction designs, plans, and methods",
        "abstract": "An object-oriented and interactive computer system is presented that integrates project- and process-level planning. This system, named CIPROS, realistically models construction processes by matching resource properties with design component properties and operation durations. It uses a modular representation to create discrete event simulation networks and to relate simulation output to the design and construction plan of the facility to be built. CIPROS users must identify and describe attributes of components to be constructed, based on the facility's design drawings and specifications, and they must develop a CPM plan. They must also select a construction method to perform each activity by retrieving the appropriate elemental simulation network from a library of networks that represent such methods. CIPROS then pieces the networks together based on sequential relationships from the plan and property \u2026",
        "year": 1994,
        "authors": "Iris D Tommelein and Robert I Carr and Abdalla M Odeh"
      }
    ],
    "7V1AORUAAAAJ": [
      {
        "title": "Application of the new production philosophy to construction",
        "abstract": "5. Results: Construction should adopt the new production philosophy. In manufacturing, the new production philosophy improves competitiveness by identifying and eliminating waste (non value-adding) activities. Traditionally, construction is viewed and modeled only as a series of conversion (value-adding) activities. For example, waste activities such as waiting, storing inventory, moving material, and inspection are not generally modeled by Critical Path Models (CPM) or other control tools. Construction has traditionally tried to improve competitiveness by making conversions incrementally more efficient. But judging from the manufacturing experience, construction could realize dramatic improvements simply by identifying and eliminating non conversion (non value-adding) activities. In other words, actual construction should be viewed as flow processes (consisting of both waste and conversion activities), not just conversion processes. As demonstrated previously by the manufacturing industry's experience, adoption of the new production philosophy",
        "year": 1992,
        "authors": "Lauri Koskela"
      },
      {
        "title": "An exploration towards a production theory and its application to construction",
        "abstract": "This thesis endeavors to answer to two specific questions. Is it possible to formulate a theory of production? Does such a theory add to our understanding and lead to improved performance when applied to construction? The answer to the first question is sought by reviewing the history of production thinking both from the scientific and the industrial points of view. Historical analysis reveals that three different conceptualizations of production have been used in practice and conceptually advanced in the 20th century. In the first conceptualization, production is viewed as a transformation of inputs to outputs. Production management equates to decomposing the total transformation into elementary transformations, tasks, and carrying out the tasks as efficiently as possible. The second conceptualization views production as a flow, where, in addition to transformation, there are waiting, inspection and moving stages. Production management equates to minimizing the share of non-transformation stages of the production flow, especially by reducing variability. The third conceptualization views production as a means for the fulfillment of the customer needs. Production management equates to translating these needs accurately into a design solution and then producing products that conform to the specified design. It is argued that all these conceptualizations are necessary, and they should be utilized simultaneously. The resulting transformation-flow-value generation model of production is called the TFV theory of production. It is noteworthy that this same new conceptualization also applies to product design and development, as revealed by a historical \u2026",
        "year": 2000,
        "authors": "Lauri Koskela"
      },
      {
        "title": "The four roles of supply chain management in construction",
        "abstract": "It is argued that due to construction peculiarities, supply chain management has four specific roles in construction. Practical initiatives in each role to advance the construction supply chain are analysed. The present status of construction supply chains is investigated by means of case studies and a comparison with previous research. Three main conclusions are drawn regarding the present status. Firstly, even in normal situations the construction supply chain has a large quantity of waste and problems. Secondly, most of these are caused in another stage of the construction supply chain than when detected. Thirdly, waste and problems are largely caused by obsolete, myopic control of the construction supply chain. These results concur with the findings made on make-to-order supply chains in general. Finally, the subjective and objective limitations of the four roles are analysed, this being based on empirical \u2026",
        "year": 2000,
        "authors": "Ruben Vrijhoef and Lauri Koskela"
      }
    ],
    "VN-UCMgAAAAJ": [
      {
        "title": "Tasting food, tasting sustainability: Defining the attributes of an alternative food system with competent, ordinary people",
        "abstract": "Initiatives intended to create alternatives to the conventional, industrialized, global food system are now emerging. Conceptual framings of alternative food systems have been based principally on the reflections of academics and policy specialists rather than on the views of the producers and eaters who constitute the bulk of the food localization movement. At a conference hosted by the Michael Fields Agricultural Institute, we explored the attributes of food system sustainability with 125 persons representing a broad cross section of the alternative farm/food community. Dividing into five discussion groups, participants were asked what the characteristics of a sustainable food system would be. From their statements we abstracted a set of attributes. Participants envisioned a sustainable food system as relational, proximate, diverse, ecologically sustainable, economically sustaining, just/ethical, sacred, knowledgeable \u2026",
        "year": 2000,
        "authors": "Jack Kloppenburg Jr and Sharon Lezberg and Kathryn De Master and George W Stevenson and John Hendrickson"
      },
      {
        "title": "New rural livelihoods or museums of production? Quality food initiatives in practice",
        "abstract": "In recent years, the European Union\u2019s stated commitment to the principle of multifunctionality within its Common Agricultural Policy has fostered a resurgence of interest in recovering and protecting the heritage and traditions associated with local agricultural products. In spite of, or perhaps because of, the growing political and economic salience of heritage-based initiatives, however, we argue that it is important to interrogate the meanings and assumptions that underlie notions of heritage and tradition. In this paper, we use case study research from France and Poland to explore the potential contradictions associated with heritage-based food systems. While quality initiatives create essential spaces for maintaining rural livelihoods in the face of the homogenizing trends in the global agro-food system, particularly for regions where traditional agriculture has been economically marginalized, they also have the \u2026",
        "year": 2011,
        "authors": "Sarah Bowen and Kathryn De Master"
      },
      {
        "title": "A devil's bargain: Rural environmental injustices and hydraulic fracturing on Pennsylvania's farms",
        "abstract": "Rural Pennsylvania, the epicenter of the Marcellus Shale region, hosts the most prolific unconventional natural gas extraction and production activity in the US. Farmers of small and midsized operations in Marcellus counties depend increasingly on incomes from booming natural gas operations, while the industry needs their land to access energy resources. These farmers thus bridge two economic sectors\u2014unconventional natural gas production and agriculture. Related dynamics rapidly transform the social, economic, and environmental landscapes for Pennsylvania's rural communities. We ask: What, if any, are the environmental justice implications of the unconventional natural gas industry's presence in rural agricultural spaces, particularly for farmers with small and midsized operations? Presenting findings from 42 in-depth interviews, participant observation, and archival analysis, we show how farmers benefit \u2026",
        "year": 2016,
        "authors": "Stephanie A Malin and Kathryn Teigen DeMaster"
      }
    ],
    "ziBaxi0AAAAJ": [
      {
        "title": "Taming Dr. Frankenstein: Contract-based design for cyber-physical systems",
        "abstract": "Cyber-physical systems combine a cyber side (computing and networking) with a physical side (mechanical, electrical, and chemical processes). In many cases, the cyber component controls the physical side using sensors and actuators that observe the physical system and actuate the controls. Such systems present the biggest challenges as well as the biggest opportunities in several large industries, including electronics, energy, automotive, defense and aerospace, telecommunications, instrumentation, industrial automation.Engineers today do successfully design cyber-physical systems in a variety of industries. Unfortunately, the development of systems is costly, and development schedules are difficult to stick to. The complexity of cyber-physical systems, and particularly the increased performance that is offered from interconnecting what in the past have been separate systems, increases the design and \u2026",
        "year": 2012,
        "authors": "Alberto Sangiovanni-Vincentelli and Werner Damm and Roberto Passerone"
      },
      {
        "title": "Contracts for system design",
        "abstract": "Recently, contract-based design has been proposed as an \u201corthogonal\u201d approach that complements system design methodologies proposed so far to cope with the complexity of system design. Contract-based design provides a rigorous scaffolding for verification, analysis, abstraction/refinement, and even synthesis. A number of results have been obtained in this domain but a unified treatment of the topic that can help put contract-based design in perspective was missing. This monograph intends to provide such a treatment where contracts are precisely defined and characterized so that they can be used in design methodologies with no ambiguity. In particular, this monograph identifies the essence of complex system design using contracts through a mathematical \u201cmeta-theory\u201d, where all the properties of the methodology are derived from a very abstract and generic notion of contract. We show that the meta-theory provides deep and illuminating links with existing contract and interface theories, as well as guidelines for designing new theories. Our study encompasses contracts for both software and systems, with emphasis on the latter. We illustrate the use of contracts with two examples: requirement engineering for a parking garage management, and the development of contracts for timing and scheduling in the context of the AUTOSAR methodology in use in the automotive sector.",
        "year": 2018,
        "authors": "Albert Benveniste and Beno\u00eet Caillaud and Dejan Nickovic and Roberto Passerone and Jean-Baptiste Raclet and Philipp Reinkemeier and Alberto Sangiovanni-Vincentelli and Werner Damm and Thomas A Henzinger and Kim G Larsen"
      },
      {
        "title": "Multiple viewpoint contract-based specification and design",
        "abstract": "We present the mathematical foundations and the design methodology of the contract-based model developed in the framework of the SPEEDS project. SPEEDS aims at developing methods and tools to support \u201cspeculative design\u201d, a design methodology in which distributed designers develop different aspects of the overall system, in a concurrent but controlled way. Our generic mathematical model of contract supports this style of development. This is achieved by focusing on behaviors, by supporting the notion of \u201crich component\u201d where diverse (functional and non-functional) aspects of the system can be considered and combined, by representing rich components via their set of associated contracts, and by formalizing the whole process of component composition.",
        "year": 2008,
        "authors": "Albert Benveniste and Beno\u00eet Caillaud and Alberto Ferrari and Leonardo Mangeruca and Roberto Passerone and Christos Sofronis"
      }
    ],
    "pbhFW1kAAAAJ": [
      {
        "title": "Implications of classical scheduling results for real-time systems",
        "abstract": "Knowledge of complexity, fundamental limits and performance bounds-well known for many scheduling problems-helps real time designers choose a good design and algorithm and avoid poor ones. The scheduling problem has so many dimensions that it has no accepted taxonomy. We divide scheduling theory between uniprocessor and multiprocessor results. In the uniprocessor section, we begin with independent tasks and then consider shared resources and overload. In the multiprocessor section, we divide the work between static and dynamic algorithms.<>",
        "year": 1995,
        "authors": "John A Stankovic and Marco Spuri and Marco Di Natale and Giorgio C Buttazzo"
      },
      {
        "title": "Understanding and using the controller area network communication protocol: theory and practice",
        "abstract": "This book to offers a hands-on guide to designing, analyzing and debugging a communication infrastructure based on the Controller Area Network (CAN) bus. Although the CAN bus standard is well established and currently used in most automotive systems, as well as avionics, medical systems and other devices, its features are not fully understood by most developers, who tend to misuse the network. This results in lost opportunities for better efficiency and performance. These authors offer a comprehensive range of architectural solutions and domains of analysis. It also provides formal models and analytical results, with thorough discussion of their applicability, so that it serves as an invaluable reference for researchers and students, as well as practicing engineers.",
        "year": 2012,
        "authors": "Marco Di Natale and Haibo Zeng and Paolo Giusto and Arkadeb Ghosal"
      },
      {
        "title": "Minimizing memory utilization of real-time task sets in single and multi-processor systems-on-a-chip",
        "abstract": "The research on real-time software systems has produced algorithms that allow to effectively schedule system resources while guaranteeing the deadlines of the application and to group tasks in a very short number of non-preemptive sets which require much less RAM memory for stack. Unfortunately, up to now the research focus has been on time guarantees rather than the optimization of RAM usage. Furthermore, these techniques do not apply to multiprocessor architectures which are likely to be widely used in future microcontrollers. This paper presents a fast and simple algorithm for sharing resources in multiprocessor systems, together with an innovative procedure for assigning preemption thresholds to tasks. This allows to guarantee the schedulability of hard real-time task sets while minimizing RAM usage. The experimental part shows the effectiveness of a simulated annealing-based tool that allows to find \u2026",
        "year": 2001,
        "authors": "Paolo Gai and Giuseppe Lipari and Marco Di Natale"
      }
    ],
    "DoJvepkAAAAJ": [
      {
        "title": "Design considerations for 3D printed, soft, multimaterial resistive sensors for soft robotics",
        "abstract": "Sensor design for soft robots is a challenging problem because of the wide range of design parameters (e.g., geometry, material, actuation type, etc.) critical to their function. While conventional rigid sensors work effectively for soft robotics in specific situations, sensors that are directly integrated into the bodies of soft robots could help improve both their exteroceptive and interoceptive capabilities. To address this challenge, we designed sensors that can be co-fabricated with soft robot bodies using commercial 3D printers, without additional modification. We describe an approach to the design and fabrication of compliant, resistive soft sensors using a Connex3 Objet350 multimaterial printer and investigated an analytical comparison to sensors of similar geometries. The sensors consist of layers of commercial photopolymers with varying conductivities. We characterized the conductivity of TangoPlus, TangoBlackPlus, VeroClear, and Support705 materials under various conditions and demonstrate applications in which we can take advantage of these embedded sensors.",
        "year": 2019,
        "authors": "Benjamin Shih and Caleb Christianson and Kyle Gillespie and Sebastian D Lee and Jason Mayeda and Zhaoyuan Huo and Michael T Tolley"
      },
      {
        "title": "Ultrafast, Programmable, and Electronics\u2010Free Soft Robots Enabled by Snapping Metacaps",
        "abstract": "Soft robots offer a myriad of potential because of their intrinsically compliant bodies, enabling safe interactions with humans and adaptability to unpredictable environments. However, most of them have limited actuation speeds, require complex control systems, and lack sensing capabilities. To address these challenges, herein, a class of metacaps is geometrically designed by introducing an array of ribs to a spherical cap with programmable bistabilities and snapping behaviors, enabling several unprecedented soft robotic functionalities. Specifically, a centimeter\u2010sized, sensor\u2010less metacap gripper is demonstrated that can grasp objects in 3.75\u2009ms upon physical contact or pneumatic actuation with tunable behaviors that have little dependence on the rate of input. The grippers can be readily integrated into a robotic platform for practical applications. The metacap can further enable propelling of a swimming robot \u2026",
        "year": 2023,
        "authors": "Lishuai Jin and Yueying Yang and Bryan O Torres Maldonado and Sebastian David Lee and Nadia Figueroa and Robert J Full and Shu Yang"
      },
      {
        "title": "Haptic search with the smart suction cup on adversarial objects",
        "abstract": "Suction cups are an important gripper type in industrial robot applications, and the prior literature focuses on using vision-based planners to improve grasping success in these tasks. Vision-based planners can fail due to adversarial objects or lose generalizability for unseen scenarios, without retraining learned algorithms. In this article, we propose haptic exploration to improve suction cup grasping when visual grasp planners fail. We present the smart suction cup, an end effector that utilizes internal flow measurements for tactile sensing. We show that model-based haptic search methods, guided by these flow measurements, improve grasping success by up to 2.5\u00d7 as compared with using only a vision planner during a bin-picking task. In characterizing the smart suction cup on both geometric edges and curves, we find that flow rate can accurately predict the ideal motion direction even with large postural errors \u2026",
        "year": 2023,
        "authors": "Jungpyo Lee and Sebastian D Lee and Tae Myung Huh and Hannah S Stuart"
      }
    ],
    "-4JbzIoAAAAJ": [
      {
        "title": "3D concrete printing: machine design, mix proportioning, and mix comparison between different machine setups",
        "abstract": "As a novel construction method, 3D concrete printing offers several merits for the construction industry by reducing project time, cost, and defects while improving design flexibility and environmentally friendly aspects. Using this method, a predesigned building element can be built in 2D layers on top of each other, the repetition of which results in the construction of a 3D object. The contribution of this chapter to science is in presenting a framework for addressing the various design and operational constraints of 3D concrete printing, which will aid in further development of this construction method. The chapter discusses two main aspects: (1) the design of a 3D printing machine and nozzle on one hand; and (2) the design of the concrete mix to be used. Two 3D concrete machine and nozzle setups are introduced with the corresponding concrete mixes. Experimental results reveal the optimal concrete mix for each \u2026",
        "year": 2019,
        "authors": "Zeina Malaeb and Fatima AlSakka and Farook Hamzeh"
      },
      {
        "title": "Rethinking Lookahead Planning to Optimize Construction Workflow",
        "abstract": "Research Question How to improve lookahead planning practices in the construction industry to increase the reliability of production planning? Purpose To assess the performance of lookahead planning, advise a standardized practice to support a strong linkage between Lookahead planning and activity execution, and improve the reliability of production planning. Research Design/Method This study employs case study analysis, industry interviews, and an industry survey to assess the current implementation of lookahead planning on construction projects in North America, South America, and Europe. Findings The study findings indicate the existence of non-compliance with Last Planner\u00ae System rules, inadequate lookahead planning and standardized practices, sluggish identification and removal of constraints, and absence of analysis for plan failures. Limitations The authors\u2019 active role on the projects used as case studies may constitute a limitation to the research methods and tools used. The industry survey may have not covered all companies applying the Last Planner System. The suggested framework should be custom tailored to different projects to cater for size, culture, etc. Implications This research provides a framework for applying the Last Planner System rules during lookahead planning. It aims at increasing the success of the making activities ready, designing operations, and ultimately improving PPC. Value for practitioners: The study presents to industry practitioners applying the Last Planner System a standardized framework for implementing lookahead planning on construction projects. The paper also highlights the use of \u2026",
        "year": 2012,
        "authors": "Farook R. Hamzeh and Glenn Ballard and Iris D Tommelein"
      }
    ],
    "nicnuy4AAAAJ": [
      {
        "title": "Timing functions of the cerebellum",
        "abstract": "This study investigated the effects of different types of neurological deficits on timing functions. The performance of Parkinson, cerebellar, cortical, and peripheral neuropathy patients was compared to age-matched control subjects on two separate measures of timing functions. The first task involved the production of timed intervals in which the subjects attempted to maintain a simple rhythm. The second task measured the subjects' perceptual ability to discriminate between small differences in the duration of two intervals.The primacy of the cerebellum in timing functions was demonstrated by the finding that these were the only patients who showed a deficit in both the production and perception of timing tasks. The cerebellar group was found to have increased variability in performing rhythmic tapping and they were less accurate than the other groups in making perceptual discriminations regarding small differences \u2026",
        "year": 1989,
        "authors": "Richard B Ivry and Steven W Keele"
      },
      {
        "title": "Attention and structure in sequence learning.",
        "abstract": "In this study we investigated the role of attention, sequence structure, and effector specificity in learning a structured sequence of actions. Experiment 1 demonstrated that simple structured sequences can be learned in the presence of attentional distraction. The learning is unaffected by variation in distractor task difficulty, and subjects appear unaware of the structure. The structured sequence knowledge transfers from finger production to arm production (Experiment 2), suggesting that sequence specification resides in an effector-independent system. Experiments 3 and 4 demonstrated that only structures with at least some unique associations (eg, any association in Structure 15243\u2026 or 4 to 3 in Structure 143132\u2026) can be learned under attentional distraction. Structures with all items repeated in different orders in different parts of the structure (eg, Sequence 132312\u2026) require attention for learning. Such structures \u2026",
        "year": 1990,
        "authors": "Asher Cohen and Richard I Ivry and Steven W Keele"
      },
      {
        "title": "Consensus paper: roles of the cerebellum in motor control\u2014the diversity of ideas on cerebellar involvement in movement",
        "abstract": "Considerable progress has been made in developing models of cerebellar function in sensorimotor control, as well as in identifying key problems that are the focus of current investigation. In this consensus paper, we discuss the literature on the role of the cerebellar circuitry in motor control, bringing together a range of different viewpoints. The following topics are covered: oculomotor control, classical conditioning (evidence in animals and in humans), cerebellar control of motor speech, control of grip forces, control of voluntary limb movements, timing, sensorimotor synchronization, control of corticomotor excitability, control of movement-related sensory data acquisition, cerebro-cerebellar interaction in visuokinesthetic perception of hand movement, functional neuroimaging studies, and magnetoencephalographic mapping of cortico-cerebellar dynamics. While the field has yet to reach a consensus on the \u2026",
        "year": 2012,
        "authors": "Mario Manto and James M Bower and Adriana Bastos Conforto and Jos\u00e9 M Delgado-Garc\u00eda and Suzete Nascimento Farias Da Guarda and Marcus Gerwig and Christophe Habas and Nobuhiro Hagura and Richard B Ivry and Peter Mari\u00ebn and Marco Molinari and Eiichi Naito and Dennis A Nowak and Nordeyn Oulad Ben Taib and Denis Pelisson and Claudia D Tesche and Caroline Tilikete and Dagmar Timmann"
      }
    ],
    "Q5_G4oQAAAAJ": [
      {
        "title": "Living pictures, missing persons: Mannequins, museums, and modernity",
        "abstract": "In the late nineteenth century, Scandinavian urban dwellers developed a passion for a new, utterly modern sort of visual spectacle: objects and effigies brought to life in astonishingly detailed, realistic scenes. The period 1880-1910 was the popular high point of mannequin display in Europe. Living Pictures, Missing Persons explores this phenomenon as it unfolded with the rise of wax museums and folk museums in the largest cities of Denmark, Sweden, and Norway. Mark Sandberg asks: Why did modernity generate a cultural fascination with the idea of effigy? He shows that the idea of effigy is also a portal to understanding other aspects of visual entertainment in that period, including the widespread interest in illusionistic scenes and tableaux, in the\" portability\" of sights, spaces, and entire milieus. Sandberg investigates this transformation of visual culture outside the usual test cases of the largest European metropolises. He argues that Scandinavian spectators desired an unusual degree of authenticity--a cultural preference for naturalism that made its way beyond theater to popular forms of museum display. The Scandinavian wax museums and folk-ethnographic displays of the era helped pre-cinematic spectators work out the social implications of both voyeuristic and immersive display techniques. This careful study thus anticipates some of the central paradoxes of twentieth-century visual culture--but in a time when the mannequin and the physical relic reigned supreme, and in a place where the contrast between tradition and modernity was a high-stakes game.",
        "year": 2003,
        "authors": "Mark B Sandberg"
      },
      {
        "title": "Ibsen's Houses: Architectural Metaphor and the Modern Uncanny",
        "abstract": "Henrik Ibsen's plays came at a pivotal moment in late nineteenth-century European modernity. They engaged his public through a strategic use of metaphors of house and home, which resonated with experiences of displacement, philosophical homelessness, and exile. The most famous of these metaphors-embodied by the titles of his plays A Doll's House, Pillars of Society, and The Master Builder-have entered into mainstream Western thought in ways that mask the full force of the reversals Ibsen performed on notions of architectural space. Analyzing literary and performance-related reception materials from Ibsen's lifetime, Mark B. Sandberg concentrates on the interior dramas of the playwright's prose-play cycle, drawing also on his selected poems. Sandberg's close readings of texts and cultural commentary present the immediate context of the plays, provide new perspectives on them for international readers, and reveal how Ibsen became a master of the modern uncanny.",
        "year": 2015,
        "authors": "Mark B Sandberg"
      },
      {
        "title": "Effigy and narrative: looking into the nineteenth-century folk museum",
        "abstract": "The visual objects of a museum resemble the scattered bones on the battlefield of Ezekiel's vision. Pour a living, coherent idea into these soulless, often anonymous objects; sort them, order them, group them around their centers;... in this way let the meaningless receive its meaning, let the apparently worthless find an ingenious use, and the scattered bones wiU arrange themselves into figures; ethnographic objects in their unsurveyable mass will gather themselves into types, and the visitor wiU leave the collection with a total impression of a people now living and breathing in the provinces, in the fatherland, in the Scandinavian North.",
        "year": 1995,
        "authors": "Mark B Sandberg"
      }
    ],
    "Y-o1GEQAAAAJ": [
      {
        "title": "Ultrasonic Neuromodulation via Astrocytic TRPA1",
        "abstract": "Low-intensity, low-frequency ultrasound (LILFU) is the next-generation, non-invasive brain stimulation technology for treating various neurological and psychiatric disorders. However, the underlying cellular and molecular mechanism of LILFU-induced neuromodulation has remained unknown. Here, we report that LILFU-induced neuromodulation is initiated by opening of TRPA1 channels in astrocytes. The Ca2+ entry through TRPA1 causes a release of gliotransmitters including glutamate through Best1 channels in astrocytes. The released glutamate activates NMDA receptors in neighboring neurons to elicit action potential firing. Our results reveal an unprecedented mechanism of LILFU-induced neuromodulation, involving TRPA1 as a unique sensor for LILFU and glutamate-releasing Best1 as a mediator of glia-neuron interaction. These discoveries should prove to be useful for optimization of human brain \u2026",
        "year": 2019,
        "authors": "Soo-Jin Oh and Jung Moo Lee and Hyun-Bum Kim and Jungpyo Lee and Sungmin Han and Jin Young Bae and Gyu-Sang Hong and Wuhyun Koh and Jea Kwon and Eun-Sang Hwang and Dong Ho Woo and Inchan Youn and Il-Joo Cho and Yong Chul Bae and Sungon Lee and Jae Wan Shim and Ji-Ho Park and C Justin Lee"
      },
      {
        "title": "Amorphous phosphorus-incorporated cobalt molybdenum sulfide on carbon cloth: an efficient and stable electrocatalyst for enhanced overall water splitting over entire pH values",
        "abstract": "The development of economical, proficient, and highly stable catalysts to substitute the expensive noble metal electrodes for electrocatalytic water-splitting applications is exceedingly desirable. In this context, the most fascinating and challenging approach is the rational design of a nanocomposite encompassing multiple components with unique functionalities. Herein, we describe the fabrication of a strongly catalytic and superb durable phosphorus-incorporated cobalt molybdenum sulfide electrocatalyst grown on carbon cloth (P-CoMoS/CC). The hybrid material exhibited excellent activity for hydrogen and oxygen evolution reactions over a wide range of pH (1\u201314) with extremely high stability (\u223c90% retention of the initial current density) after 24 h of electrolysis. Importantly, when P-CoMoS/CC was used as both cathode and anode for overall water splitting, a very low cell voltage of 1.54 V is required to attain the \u2026",
        "year": 2017,
        "authors": "Chaiti Ray and Su Chan Lee and Kalimuthu Vijaya Sankar and Bingjun Jin and Jungpyo Lee and Jong Hyeok Park and Seong Chan Jun"
      },
      {
        "title": "Facile approach to synthesize highly fluorescent multicolor emissive carbon dots via surface functionalization for cellular imaging",
        "abstract": "Luminescent nanomaterials are encouraging scaffolds for diverse applications such as chemical sensors and biosensors, imaging, drug delivery, diagnostics, catalysis, energy, photonics, medicine, and so on. Carbon dots (CDs) are a new class of luminescent carbonaceous nanomaterial that have appeared recently and reaped tremendous scientific interest. Herein, we have exploited a simple approach to prepare tuneable and highly fluorescent CDs via surface functionalization. The successful synthesis of CDs is manifested from several investigations like high-resolution transmission electron microscopy (HRTEM), X-ray diffraction (XRD), Fourier transform infrared spectroscopy (FTIR) and X-ray photoelectron spectroscopy (XPS). The CDs exhibit excellent water solubility and with increasing nitrogen content fluorescence quantum yield increases whereas cell toxicity decreases. The CD synthesized at high \u2026",
        "year": 2018,
        "authors": "Aniruddha Kundu and Jungpyo Lee and Byeongho Park and Chaiti Ray and K Vijaya Sankar and Wook Sung Kim and Soo Hyun Lee and Il-Joo Cho and Seong Chan Jun"
      }
    ],
    "Dkeu8BMAAAAJ": [
      {
        "title": "Is financial reporting shaped by equity markets or by debt markets? An international study of timeliness and conservatism",
        "abstract": "We hypothesize debt markets\u2014not equity markets\u2014are the primary influence on \u201cassociation\u201d metrics studied since Ball and Brown (1968 J Account Res 6:159\u2013178). Debt markets demand high scores on timeliness, conservatism and Lev\u2019s (1989 J Account Res 27(supplement):153\u2013192) R 2, because debt covenants utilize reported numbers. Equity markets do not rate financial reporting consistently with these metrics, because (among other things) they control for the total information incorporated in prices. Single-country studies shed little light on debt versus equity influences, in part because within-country firms operate under a homogeneous reporting regime. International data are consistent with our hypothesis. This is a fundamental issue in accounting.",
        "year": 2008,
        "authors": "Ray Ball and Ashok Robin and Gil Sadka"
      },
      {
        "title": "Liquidity and the post-earnings-announcement drift",
        "abstract": "The post-earnings-announcement drift is a longstanding anomaly that conflicts                     with market efficiency. This study documents that the post-earnings-announcement                     drift occurs mainly in highly illiquid stocks. A trading strategy that goes long                     high-earnings-surprise stocks and short low-earnings-surprise stocks provides a                     monthly value-weighted return of 0.04 percent in the most liquid stocks and 2.43                     percent in the most illiquid stocks. The illiquid stocks have high trading costs                     and high market impact costs. By using a multitude of estimates, the study finds                     that transaction costs account for 70\u2013100 percent of the paper profits                     from a long\u2013short strategy designed to exploit the earnings momentum                     anomaly. ",
        "year": 2009,
        "authors": "Tarun Chordia and Amit Goyal and Gil Sadka and Ronnie Sadka and Lakshmanan Shivakumar"
      },
      {
        "title": "Aggregate earnings and asset prices",
        "abstract": "A principal\u2010components analysis demonstrates that common earnings factors explain a substantial portion of firm\u2010level earnings variation, implying earnings shocks have substantial systematic components and are not almost fully diversifiable as prior literature has concluded. Furthermore, the principal components of earnings and returns are highly correlated, implying aggregate earnings risks and return risks are related. In contrast to previous studies, the correlation we report between the systematic components of earnings and returns is stable over time. We also show that the earnings factors are priced, in the sense that the sensitivities of securities' returns to the earnings factors explain a significant portion of the cross\u2010sectional variation in returns, even controlling for return risk. This suggests earnings performance is an underlying source of priced risk. Our evidence that the information sets of returns and \u2026",
        "year": 2009,
        "authors": "Ray Ball and Gil Sadka and Ronnie Sadka"
      }
    ],
    "IJgXsgwAAAAJ": [
      {
        "title": "Cyber physical systems: Design challenges",
        "abstract": "Cyber-Physical Systems (CPS) are integrations of computation and physical processes. Embedded computers and networks monitor and control the physical processes, usually with feedback loops where physical processes affect computations and vice versa. The economic and societal potential of such systems is vastly greater than what has been realized, and major investments are being made worldwide to develop the technology. There are considerable challenges, particularly because the physical components of such systems introduce safety and reliability requirements qualitatively different from those in general- purpose computing. Moreover, physical components are qualitatively different from object-oriented software components. Standard abstractions based on method calls and threads do not work. This paper examines the challenges in designing such systems, and in particular raises the question of \u2026",
        "year": 2008,
        "authors": "Edward A Lee"
      },
      {
        "title": "Synchronous data flow",
        "abstract": "Data flow is a natural paradigm for describing DSP applications for concurrent implementation on parallel hardware. Data flow programs for signal processing are directed graphs where each node represents a function and each arc represents a signal path. Synchronous data flow (SDF) is a special case of data flow (either atomic or large grain) in which the number of data samples produced or consumed by each node on each invocation is specified a priori. Nodes can be scheduled statically (at compile time) onto single or parallel programmable processors so the run-time overhead usually associated with data flow evaporates. Multiple sample rates within the same system are easily and naturally handled. Conditions for correctness of SDF graph are explained and scheduling algorithms are described for homogeneous parallel processors sharing memory. A preliminary SDF software system for automatically \u2026",
        "year": 1987,
        "authors": "Edward A Lee and David G Messerschmitt"
      },
      {
        "title": "Scientific workflow management and the Kepler system",
        "abstract": "Many scientific disciplines are now data and information driven, and new scientific knowledge is often gained by scientists putting together data analysis and knowledge discovery \u2018pipelines\u2019. A related trend is that more and more scientific communities realize the benefits of sharing their data and computational services, and are thus contributing to a distributed data and computational community infrastructure (a.k.a. \u2018the Grid\u2019). However, this infrastructure is only a means to an end and ideally scientists should not be too concerned with its existence. The goal is for scientists to focus on development and use of what we call scientific workflows. These are networks of analytical steps that may involve, e.g., database access and querying steps, data analysis and mining steps, and many other steps including computationally intensive jobs on high\u2010performance cluster computers. In this paper we describe characteristics \u2026",
        "year": 2006,
        "authors": "Bertram Lud\u00e4scher and Ilkay Altintas and Chad Berkley and Dan Higgins and Efrat Jaeger and Matthew Jones and Edward A Lee and Jing Tao and Yang Zhao"
      }
    ],
    "wIdzoc8AAAAJ": [
      {
        "title": "Exploring lean construction practice, research, and education",
        "abstract": "The purpose of this paper is to investigate the history of dissemination and use of lean concepts in construction and potential challenges for continued use, as application of lean concepts transitions from a small group of first adopters to an industry\u2010wide community.Using insights obtained from a meeting with industry practitioners, literature review, and published cases in which different approaches were used to disseminate lean production/construction, evidence is presented that supports these challenges.The authors identify three challenges facing lean construction (LC) practitioners, researchers, and educators. One challenge is lean has many meanings (whether denoted or connoted) when applied to construction. Another challenge is to have academics constantly working with industry practitioners to keep working on the adaptation of concepts/systems \u2026",
        "year": 2012,
        "authors": "Tha\u00eds da CL Alves and Colin Milberg and Kenneth D Walsh"
      },
      {
        "title": "Visual management in Brazilian construction companies: taxonomy and guidelines for implementation",
        "abstract": "Visual management (VM) is the managerial strategy of consciously integrating visual tools in workspaces with the aim of increasing transparency on construction sites. Several VM tools and approaches that had been originally developed in the manufacturing context were implemented in construction. However, research on the application of VM in construction as a managerial strategy is scarce. This paper aims to investigate and classify the types of visual devices that can be used in construction sites through multiple case studies carried out in nine construction companies actively implementing VM. It also discusses strategies for the implementation of VM in construction. The main contributions of this investigation are: (1) a VM tools taxonomy that can be used to identify VM application opportunities, providing a basis for evaluating the level of VM implementation in construction; and (2) identification of critical factors \u2026",
        "year": 2015,
        "authors": "Algan Tezel and Lauri Koskela and Patricia Tzortzopoulos and Carlos Formoso and Thais Alves"
      }
    ],
    "_2LKKpsAAAAJ": [
      {
        "title": "Work structuring to achieve integrated product\u2013process design",
        "abstract": "This paper presents \u201cwork structuring,\u201d a term used to describe the effort of integrating product and process design throughout the project development process. To illustrate current work structuring practice, we describe a case study involving the installation of door frames into walls in a prison. We analyze why various problems existed. To improve the work structuring effort, we apply the \u201cfive whys\u201d to develop local and global fixes for the system of precast walls and door frames. The five whys is a technique to elicit alternative ways of structuring work without being constrained by contractual agreements, traditions, or trade boundaries. We discuss the importance of dimensional tolerances in construction and how these affect the handoff of work from one group of workers to the next. We argue that these constraints and tolerance management practices are so embedded that project participants can miss opportunities \u2026",
        "year": 2004,
        "authors": "Cynthia CY Tsao and Iris D Tommelein and Eric S Swanlund and Gregory A Howell"
      },
      {
        "title": "Case study for work structuring: installation of metal door frames",
        "abstract": "Work structuring means developing a project\u2019s process design while trying to align engineering design, supply chain, resource allocation, and assembly efforts. The goal of work structuring is to make work flow more reliable and quick while delivering value to the customer. Current work structuring practices are driven by contracts, the history of trades, and the traditions of craft. As a result, they rarely consider alternatives for making the construction process more efficient. To illustrate current practice and the opportunities provided by work structuring, this case study discusses the installation of metal door frames at a prison project. Because the project is a correctional facility, the door frame installation process involves a special grouting procedure which makes the installation process less routine. Those involved recognized the difficulty of the situation but better solutions were impeded by normal practice. This case study thus provided the opportunity to illustrate how one may come up with alternative ways to perform the work without being constrained by contractual agreements and trade boundaries. By doing so, we illustrate what work structuring means. Local and global fixes for the system comprising walls and doors are explored. In addition, we discuss the importance of dimensional tolerances in construction and how these affect the handoff of work chunks from one production unit to the next.",
        "year": 2000,
        "authors": "Cynthia CY Tsao and Iris D Tommelein and Eric Swanlund and Gregory A Howell"
      },
      {
        "title": "Lean construction\u20132000 to 2006",
        "abstract": "Construction management research in the early 1990s called for Architecture-Engineering-Construction (AEC) researchers and practitioners to investigate how the theory, principles, and techniques associated with the Toyota Production System (TPS) can be abstracted and applied to the planning and management of AEC projects. Since then, the International Group for Lean Construction (IGLC) has become a focal point for showcasing research efforts in this regard. Contributors to IGLC proceedings include academics, practitioners, and consultants covering a range of project types, project phases, and countries. By analyzing the keywords listed by IGLC papers from 2000 to 2006, we hope to identify major research areas to provide a perspective as to what Lean Construction means in 2006. We will also make recommendations for future research and identify strategies for streamlining the IGLC community\u2019s efforts in categorizing papers for fellow researchers.",
        "year": 2007,
        "authors": "Thais da CL Alves and Cynthia CY Tsao"
      }
    ],
    "3QooCT0AAAAJ": [
      {
        "title": "Towards recursive plan-do-check-act cycles for continuous improvement",
        "abstract": "Continuous improvement is a cornerstone of successful management approaches such as Lean Production, Total Quality Management, and Six Sigma. Its implementation in complex organizational contexts requires a systemic perspective. This paper presents one such perspective on continuous improvement and its implementation methods, such as the Plan-Do-Check-Act (PDCA) cycle, based on the Viable System Model (ViSM1). With its underlying cybernetic principles, the ViSM provides a theoretical basis for recursive application of PDCA cycles throughout an organization, both in a top-down- and bottom-up manner. This model can therefore serve as a foundation for implementation support of continuous improvement in complex organizational contexts.",
        "year": 2014,
        "authors": "Michael Timo Schmidt and Fatos Elezi and Iris D Tommelein and Udo Lindemann"
      },
      {
        "title": "Management Cybernetics as a Theoretical Basis for Lean Construction Thinking.",
        "abstract": "Question: Management cybernetics claims that any successful organization responds to its laws. As there are numerous successful enterprises that use lean thinking as a management philosophy, including increasing numbers of construction companies, does this claim hold and if so, do these laws offer the opportunity to sharpen understanding of Lean Construction practices? Purpose: The purpose of this paper is to explore the use of management cybernetics\u2014specifically Stafford Beer\u2019s Viable Systems Model\u2014as a theoretical basis for Lean Construction thinking.Research Method: Review, analyze, and compare literature on management cybernetics and Lean Construction. Develop an example to illustrate such use. Findings: Through a theoretical approach of describing lean thinking rules from the perspective of management cybernetics, we were able to show that following this argumentation, the Lean \u2026",
        "year": 2015,
        "authors": "Tobias Steinhaeusser and Fatos Elezi and Iris D Tommelein and Udo Lindemann"
      },
      {
        "title": "Using a systemic perspective to support engineering change management",
        "abstract": "Engineering change management (ECM) is an important enabler for the overall success of engineering projects. Engineering changes (ECs) occur because engineering projects are exposed to internal and external dynamic influences. The implementation of ECM supports project managers involved in coordinating EC processes, which results in more efficient operations. There are, however, many challenges related to ECM because of the need for internal and external stakeholders to collaborate during the EC process. Many existing approaches that support ECM adopt a reductionistic perspective. This paper takes a novel approach by adopting a systemic perspective. The self-organizing nature of complex systems is of particular interest because efficient ECM is a learning process that requires constant adaptation on different organizational levels. This paper describes how self-organization can be incorporated \u2026",
        "year": 2015,
        "authors": "Julian Wilberg and Fatos Elezi and Iris D Tommelein and Udo Lindemann"
      }
    ],
    "ZrCk8RwAAAAJ": [
      {
        "title": "16. The deadly combination of heat and humidity in India and Pakistan in summer 2015",
        "abstract": "EXPLAINING EXTREME EVENTS OF 2015 Page 1 Special Supplement to the Bullefin of \nthe American Meteorological Society Vol. 97, No. 12, December 2016 EXPLAINING \nEXTREME EVENTS OF 2015 From A Climate Perspective Page 2 EXPLAINING EXTREME \nEVENTS OF 2015 FROM A CLIMATE PERSPECTIVE Editors Stephanie C. Herring, Andrew \nHoell, Martin P. Hoerling, James P. Kossin, Carl J. Schreck III, and Peter A. Stott Special \nSupplement to the Bulletin of the American Meteorological Society Vol. 97, No. 12, \nDecember 2016 AMERICAN METEOROLOGICAL SOCIETY Page 3 HOW TO CITE THIS \nDOCUMENT \n__________________________________________________________________________________________ \nCiting the complete report: Herring, SC, A. Hoell, MP Hoerling, JP Kossin, CJ Schreck III, \nand PA Stott, Eds., 2016: Explaining Extreme Events of 2015 from a Climate Perspective. \u2026",
        "year": 2016,
        "authors": "Michael Wehner and D\u00e1ith\u00ed Stone and Hari Krishnan and Krishna AchutaRao and Federico Castillo"
      },
      {
        "title": "Individual and institutional responses to the drought: the case of California agriculture",
        "abstract": "Drought is one of the biggest and devastating events that mankind has witnessed throughout the world. The determination of the drought onset or end, as well as its severity, is difficult. It is a gradual phenomenon, its impact can, nevertheless, be devastating. The drought\u2019s impacts are dependent not only on the duration, intensity, and geographical extent, but also on the demands by human activities, flexibility of the region's water storage and supply, and the institutions of the delivery system. They evolve over time and are influenced by the interactions between supply and demand. Drought events and adaptation throughout the world have been documented in Yevjevich et al.(1983), Wilhite et al.(1987), and Wilhite (1993).A comparative study of drought policies (Wilhite, 1986) suggests that governments often respond to drought through crisis management rather than preplanned programs. A National Research \u2026",
        "year": 2002,
        "authors": "David Zilberman and Ariel Dinar and Neal MacDougall and Madhu Khanna and Cheril Brown and Frederico Castillo"
      },
      {
        "title": "Narrow and brittle or broad and nimble? Comparing adaptive capacity in simplifying and diversifying farming systems",
        "abstract": "Humanity faces a triple threat of climate change, biodiversity loss, and global food insecurity. In response, increasing the general adaptive capacity of farming systems is essential. We identify two divergent strategies for building adaptive capacity. Simplifying processes seek to narrowly maximize production by shifting the basis of agricultural production toward centralized control of socially and ecologically homogenized systems. Diversifying processes cultivate social-ecological complexity in order to provide multiple ecosystem services, maintain management flexibility, and promote coordinated adaptation across levels. Through five primarily United States focused cases of distinct agricultural challenges\u2014foodborne pathogens, drought, marginal lands, labor availability, and land access and tenure\u2014we compare simplifying and diversifying responses to assess how these pathways differentially enhance or degrade the adaptive capacity of farming systems in the context of the triple threat. These cases show that diversifying processes can weave a form of broad and nimble adaptive capacity that is fundamentally distinct from the narrow and brittle adaptive capacity produced through simplification. We find that while there are structural limitations and tradeoffs to diversifying processes, adaptive capacity can be facilitated by empowering people and enhancing ecosystem functionality to proactively distribute resources and knowledge where needed and to nimbly respond to changing circumstances. Our cases suggest that, in order to garner the most adaptive benefits from diversification, farming systems should balance the pursuit of multiple goals \u2026",
        "year": 2021,
        "authors": "Margiana Petersen-Rockney and Patrick Baur and Aidee Guzman and S Franz Bender and Adam Calo and Federico Castillo and Kathryn De Master and Antoinette Dumont and Kenzo Esquivel and Claire Kremen and James LaChance and Maria Mooshammer and Joanna Ory and Mindy J Price and Yvonne Socolar and Paige Stanley and Alastair Iles and Timothy Bowles"
      }
    ],
    "_2_v4bsAAAAJ": [
      {
        "title": "Soil\u2013water characteristic curve variability",
        "abstract": "The most widely-used constitutive relations for unsaturated soils use matric soil suction as a state variable. The soil-water characteristic curve (SWCC), the relationship between soil suction and some measure of the water content, can be measured or predicted based on soil index properties such as the grain-size distribution (GSD) function. Estimation based on index properties is highly desirable due to its simplicity and low cost and would be the path of choice to the SWCC, provided the accuracy of the estimate were adequate. Whether measured or estimated, there is variability and uncertainty associated with the SWCC that in turn will directly impact any model for the unsaturated soil behavior that makes use of this relationship. The variability in the SWCC associated with direct suction measurements as well as the variability associated with the prediction of the SWCC based on GSD was investigated. Three \u2026",
        "year": 2000,
        "authors": "Claudia E Zapata and William N Houston and Sandra L Houston and Kenneth D Walsh"
      },
      {
        "title": "Value stream analysis of a re-engineered construction supply chain",
        "abstract": "A case study is presented that documents the most common configuration of the supply chain for pipe supports used in power plants in the USA. This supply chain, like many others in construction, has numerous inefficiencies, many of which occur at the interfaces between processes, disciplines or organizations. Recognizing and understanding such inefficiencies, their causes and potential remedies provides a basis for process re-engineering. The study describes how today's industry practices are changing to yield shorter supply chain lead times. To model the mechanisms that drive those changes, data are presented from industry practice in the form of value stream maps that span organizational disciplines and company boundaries. Metrics commonly used in lean construction are introduced to gauge system performance. A current state map documents how work flows throughout the design, procurement and \u2026",
        "year": 2003,
        "authors": "Roberto Arbulu and Iris Tommelein and Kenneth Walsh and James Hershauer"
      },
      {
        "title": "Exploring lean construction practice, research, and education",
        "abstract": "The purpose of this paper is to investigate the history of dissemination and use of lean concepts in construction and potential challenges for continued use, as application of lean concepts transitions from a small group of first adopters to an industry\u2010wide community.Using insights obtained from a meeting with industry practitioners, literature review, and published cases in which different approaches were used to disseminate lean production/construction, evidence is presented that supports these challenges.The authors identify three challenges facing lean construction (LC) practitioners, researchers, and educators. One challenge is lean has many meanings (whether denoted or connoted) when applied to construction. Another challenge is to have academics constantly working with industry practitioners to keep working on the adaptation of concepts/systems \u2026",
        "year": 2012,
        "authors": "Tha\u00eds da C and Colin Milberg and Kenneth D Walsh"
      }
    ],
    "FOafMIgAAAAJ": [
      {
        "title": "FLUXNET: A new tool to study the temporal and spatial variability of ecosystem-scale carbon dioxide, water vapor, and energy flux densities",
        "abstract": "FLUXNET is a global network of micrometeorological flux measurement sites that measure the exchanges of carbon dioxide, water vapor, and energy between the biosphere and atmosphere. At present over 140 sites are operating on a long-term and continuous basis. Vegetation under study includes temperate conifer and broadleaved (deciduous and evergreen) forests, tropical and boreal forests, crops, grasslands, chaparral, wetlands, and tundra. Sites exist on five continents and their latitudinal distribution ranges from 70\u00b0N to 30\u00b0S.             FLUXNET has several primary functions. First, it provides infrastructure for compiling, archiving, and distributing carbon, water, and energy flux measurement, and meteorological, plant, and soil data to the science community. (Data and site information are available online at the FLUXNET Web site,             http://www-eosdis.ornl.gov/FLUXNET/             .) Second, the \u2026",
        "year": 2001,
        "authors": "Dennis Baldocchi and Eva Falge and Lianhong Gu and Richard Olson and David Hollinger and Steve Running and Peter Anthoni and Ch Bernhofer and Kenneth Davis and Robert Evans and Jose Fuentes and Allen Goldstein and Gabriel Katul and Beverly Law and Xuhui Lee and Yadvinder Malhi and Tilden Meyers and William Munger and Walt Oechel and Kyaw Tha Paw U and Kim Pilegaard and Hans Peter Schmid and Riccardo Valentini and Shashi Verma and Timo Vesala and Kell Wilson and Steve Wofsy"
      },
      {
        "title": "Environmental controls over carbon dioxide and water vapor exchange of terrestrial vegetation",
        "abstract": "The objective of this research was to compare seasonal and annual estimates of CO2 and water vapor exchange across sites in forests, grasslands, crops, and tundra that are part of an international network called FLUXNET, and to investigating the responses of vegetation to environmental variables. FLUXNETs goals are to understand the mechanisms controlling the exchanges of CO2, water vapor and energy across a spectrum of time and space scales, and to provide information for modeling of carbon and water cycling across regions and the globe. At a subset of sites, net carbon uptake (net ecosystem exchange, the net of photosynthesis and respiration) was greater under diffuse than under direct radiation conditions, perhaps because of a more efficient distribution of non-saturating light conditions for photosynthesis, lower vapor pressure deficit limitation to photosynthesis, and lower respiration associated \u2026",
        "year": 2002,
        "authors": "Beverly E Law and Eva Falge and Lianhong Gu and Dennis D Baldocchi and Peter Bakwin and Paul Berbigier and Kenneth Davis and A Johannes Dolman and M Falk and JD Fuentes and A Goldstein and A Granier and A Grelle and D Hollinger and IA Janssens and P Jarvis and NO Jensen and G Katul and Y Mahli and G Matteucci and T Meyers and R Monson and W Munger and W Oechel and R Olson and K Pilegaard and H Thorgeirsson and R Valentini and S Verma and T Vesala and K Wilson and S Wofsy"
      },
      {
        "title": "Advantages of diffuse radiation for terrestrial ecosystem productivity",
        "abstract": "Clouds and aerosols alter the proportion of diffuse radiation in global solar radiation reaching the Earth's surface. It is known that diffuse and direct beam radiation differ in the way they transfer through plant canopies and affect the summation of nonlinear processes like photosynthesis differently than what would occur at the leaf scale. We compared the relative efficiencies of canopy photosynthesis to diffuse and direct photosynthetically active radiation (PAR) for a Scots pine forest, an aspen forest, a mixed deciduous forest, a tallgrass prairie and a winter wheat crop. The comparison was based on the seasonal patterns of the parameters that define the canopy photosynthetic responses to diffuse PAR and those that define the responses to direct PAR. These parameters were inferred from half\u2010hourly tower CO2 flux measurements. We found that: (1) diffuse radiation results in higher light use efficiencies by plant \u2026",
        "year": 2002,
        "authors": "Lianhong Gu and Dennis Baldocchi and Shashi B Verma and TA Black and Timo Vesala and Eva M Falge and Pete R Dowty"
      }
    ],
    "lbMG9IcAAAAJ": [
      {
        "title": "Transitioning to sustainable agriculture requires growing and sustaining an ecologically skilled workforce",
        "abstract": "In the face of rapidly advancing climate change, biodiversity loss, and water scarcity, it is clear that global agriculture must swiftly and decisively shift toward sustainability. Fortunately, farmers and researchers have developed a thoroughly studied pathway to this transition: agroecological farming systems that mimic natural ecosystems, creating tightly coupled cycles of energy, water, and nutrients. A critical and underappreciated feature of agroecological systems is that they replace fossil fuel- and chemical -intensive management with knowledge-intensive management. Hence, the greatest sustainability challenge for agriculture may well be that of replacing non-renewable resources with ecologically-skilled people, and doing so in ways that create and support desirable rural livelihoods. Yet over the past century, US agriculture has been trending in the opposite direction, rapidly replacing knowledgeable people with non-renewable resources and eroding rural economies in the process. Below, we suggest how US policy could pivot to enable and support the ecologically skilled workforce needed to achieve food security in the face of climate change.",
        "year": 2019,
        "authors": "Liz Carlisle and Maywa Montenegro de Wit and Marcia S DeLonge and Alastair Iles and Adam Calo and Christy Getz and Joanna Ory and Katherine Munden-Dixon and Ryan Galt and Brett Melone and Reggie Knox and Daniel Press"
      },
      {
        "title": "Securing the future of US agriculture: The case for investing in new entry sustainable farmers",
        "abstract": "Sustainable agriculture is among the most urgently needed work in the United States, for at least three reasons: we face an environmental crisis, a health crisis, and a rural economic crisis. Addressing these pressing crises through sustainability transition will require growing our agricultural workforce: both because the current farm population is aging, and because sustainable agriculture is knowledge-intensive work that substitutes experiential knowledge of farm ecosystems for harmful industrial inputs. Given its social value, sustainable agriculture ought to be a welcoming profession. But at present, US agriculture is decidedly unwelcoming for nearly all who work in it \u2013 and it puts new entry and sustainable farmers at a distinct disadvantage. In this paper, we first examine why it is so hard to enter and succeed in sustainable farming. We find that new entrants struggle to gain critical access, assets, and assistance \u2026",
        "year": 2019,
        "authors": "Liz Carlisle and Maywa Montenegro De Wit and Marcia S DeLonge and Adam Calo and Christy Getz and Joanna Ory and Katherine Munden-Dixon and Ryan Galt and Brett Melone and Reggie Knox and Alastair Iles and Daniel Press"
      },
      {
        "title": "Narrow and brittle or broad and nimble? Comparing adaptive capacity in simplifying and diversifying farming systems",
        "abstract": "Humanity faces a triple threat of climate change, biodiversity loss, and global food insecurity. In response, increasing the general adaptive capacity of farming systems is essential. We identify two divergent strategies for building adaptive capacity. Simplifying processes seek to narrowly maximize production by shifting the basis of agricultural production toward centralized control of socially and ecologically homogenized systems. Diversifying processes cultivate social-ecological complexity in order to provide multiple ecosystem services, maintain management flexibility, and promote coordinated adaptation across levels. Through five primarily United States focused cases of distinct agricultural challenges\u2014foodborne pathogens, drought, marginal lands, labor availability, and land access and tenure\u2014we compare simplifying and diversifying responses to assess how these pathways differentially enhance or degrade the adaptive capacity of farming systems in the context of the triple threat. These cases show that diversifying processes can weave a form of broad and nimble adaptive capacity that is fundamentally distinct from the narrow and brittle adaptive capacity produced through simplification. We find that while there are structural limitations and tradeoffs to diversifying processes, adaptive capacity can be facilitated by empowering people and enhancing ecosystem functionality to proactively distribute resources and knowledge where needed and to nimbly respond to changing circumstances. Our cases suggest that, in order to garner the most adaptive benefits from diversification, farming systems should balance the pursuit of multiple goals \u2026",
        "year": 2021,
        "authors": "Margiana Petersen-Rockney and Patrick Baur and Aidee Guzman and S Franz Bender and Adam Calo and Federico Castillo and Kathryn De Master and Antoinette Dumont and Kenzo Esquivel and Claire Kremen and James LaChance and Maria Mooshammer and Joanna Ory and Mindy J Price and Yvonne Socolar and Paige Stanley and Alastair Iles and Timothy Bowles"
      }
    ],
    "8m8taGEAAAAJ": [
      {
        "title": "Zero phase error tracking algorithm for digital control",
        "abstract": "A digital feedforward control algorithm for tracking desired time varying signals is presented. The feedforward controller cancels all the closed-loop poles and cancellable closed-loop zeros. For uncancellable zeros, which include zeros outside the unit circle, the feedforward controller cancels the phase shift induced by them. The phase cancellation assures that the frequency response between the desired output and actual output exhibits zero phase shift for all the frequencies. The algorithm is particularly suited to the general motion control problems including robotic arms and positioning tables. A typical motion control problem is used to show the effectiveness of the proposed feedforward controller.",
        "year": 1987,
        "authors": "Masayoshi Tomizuka"
      },
      {
        "title": "Sparse r-cnn: End-to-end object detection with learnable proposals",
        "abstract": "We present Sparse R-CNN, a purely sparse method for object detection in images. Existing works on object detection heavily rely on dense object candidates, such as k anchor boxes pre-defined on all grids of image feature map of size HxW. In our method, however, a fixed sparse set of learned object proposals, total length of N, are provided to object recognition head to perform classification and location. By eliminating HWk (up to hundreds of thousands) hand-designed object candidates to N (eg 100) learnable proposals, Sparse R-CNN completely avoids all efforts related to object candidates design and many-to-one label assignment. More importantly, final predictions are directly output without non-maximum suppression post-procedure. Sparse R-CNN demonstrates accuracy, run-time and training convergence performance on par with the well-established detector baselines on the challenging COCO dataset, eg, achieving 45.0 AP in standard 3x training schedule and running at 22 fps using ResNet-50 FPN model. We hope our work could inspire re-thinking the convention of dense prior in object detectors. The code is available at: https://github. com/PeizeSun/SparseR-CNN.",
        "year": 2021,
        "authors": "Peize Sun and Rufeng Zhang and Yi Jiang and Tao Kong and Chenfeng Xu and Wei Zhan and Masayoshi Tomizuka and Lei Li and Zehuan Yuan and Changhu Wang and Ping Luo"
      },
      {
        "title": "Fuzzy gain scheduling of PID controllers",
        "abstract": "This paper describes the development of a fuzzy gain scheduling scheme of PID controllers for process control. Fuzzy rules and reasoning are utilized online to determine the controller parameters based on the error signal and its first difference. Simulation results demonstrate that better control performance can be achieved in comparison with Ziegler-Nichols controllers and Kitamori's PID controllers.<>",
        "year": 1993,
        "authors": "Zhen-Yu Zhao and Masayoshi Tomizuka and Satoru Isaka"
      }
    ],
    "EtDeLfYAAAAJ": [
      {
        "title": "The limits of power: Great fires and the process of city growth in America",
        "abstract": "Chicago, Boston, and Baltimore all suffered terrible fires in the late nineteenth or early twentieth century. Residents of these cities agreed that the destruction caused by the fires provided them with a special opportunity to improve their inadequately built cities. This book examines these rebuildings, using each to examine in close detail the process of city growth. The massive population growth and economic expansion of the nineteenth century necessitated that every aspect of the urban environment be redeveloped. Yet, at virtually every stage of city growth, the achievement of environmental adaptation lagged significantly behind the need for change. The innovative features of this book will make it useful to all readers interested in city growth. By drawing on several fields of the social sciences, the author develops a conceptual framework for explaining the barriers to environmental improvement; and through the historical narrative, the usefulness of this framework is demonstrated.",
        "year": 2003,
        "authors": "Christine Meisner Rosen"
      },
      {
        "title": "Product recovery with some byte: an overview of management challenges and environmental consequences in reverse manufacturing for the computer industry",
        "abstract": "Estimates vary about the rate at which end-of-life computer products have been piling up, but the total population of spent computers is likely to reach into the hundreds of millions. To tackle this mounting solid and hazardous waste problem, policy and business entrepreneurs are promoting product recovery as an environmentally preferable alternative to disposal, and product recovery infrastructure and strategy has begun to develop in recent decades. However, despite some real and theoretical developments in the field, current literature lacks an overall description of the recovery process capable of capturing the essence of end-of-life management challenges for complex, rapidly obsolete, high-tech products like computers and electronics. The absence of this broad frame of reference presents a problem for managers trying to integrate environmentally sound choices into planning and management. Using case \u2026",
        "year": 2003,
        "authors": "Charles David White and Eric Masanet and Christine Meisner Rosen and Sara L Beckman"
      },
      {
        "title": "Environmental strategy and competitive advantage: an introduction.",
        "abstract": "The purpose of this CMR symposium on\" Environmental Strategy and Competitive Advantage\" is to call attention to a major transition tak-ing place in business: a change in the character of corporate environmental management. Until quite recently, most people assumed that business was, by its very nature, pitted in a war with regulators and environmentalists. Managers took it for granted that environmental protection was peripheral to\u2014or worse, a major threat to\u2014the challenge of maximizing corporate advantage in the increasingly competitive global market place. They believed that improving a firm's environmental performance was a matter of regulatory compliance, an activity that added nothing but economic cost and legal and political complications to the corporate bottom line.Today, at the dawn of the 21st century, this set of assumptions is giving way. A new generation of leading-edge managers is starting to recognize that superior environmental performance can confer competitive advantage, rather than undercut it. These managers see that it is in their company's strategic interest to institute environmental management systems that help them reduce waste and manage environmental risk effectively, because this increases efficiency, cutting costs as well as protecting against environmental liabilities. More importantly, they are realizing that it is in their firm's strategic self-interest to identify and find ways to embrace the business opportunities inherent in taking a constructive approach to solving society's mounting environmental problems. To turn environmental problems into strategic opportunities, the managers who are furthest along this \u2026",
        "year": 2001,
        "authors": "Christine Meisner Rosen"
      }
    ],
    "b-53G6MAAAAJ": [
      {
        "title": "The persistence and transfer of learning in industrial settings",
        "abstract": "The persistence of learning within organizations and the transfer of learning across organizations are examined on data collected from multiple organizations. Results indicate that knowledge acquired through production depreciates rapidly. The conventional measure of learning, cumulative output, significantly overstates the persistence of learning. There is some evidence that learning transfers across organizations: organizations beginning production later are more productive than those with early start dates. Once organizations begin production, however, they do not appear to benefit from learning in other organizations. The implications of the results for a theory of organizational learning are discussed. Managerial implications are described.",
        "year": 1990,
        "authors": "Linda Argote and Sara L Beckman and Dennis Epple"
      },
      {
        "title": "Innovation as a learning process: Embedding design thinking",
        "abstract": "The history of academic understanding of the design process\u2014developed in a field often referred to as design theories and methods\u2014displays both a need to make design thinking explicit and a need to embrace the many disciplines that are engaged in some way in design. 10 In the early to mid-1960s, the complexities of developing technologies that might transform human lives\u2014such as the first operational nuclear power station and supersonic flight\u2014caused academics and practitioners alike to seek some structure for the design process. Designers at that time realized that, compared to the scientists who were creating the new technologies, their processes for embedding those technologies in usable artifacts were less rigorous and explicit. 11 Further, as they were increasingly forced to work across disciplinary boundaries, they found a need to be more precise in describing their processes to the others with \u2026",
        "year": 2007,
        "authors": "Sara L Beckman and Michael Barry"
      },
      {
        "title": "Managing product definition in high-technology industries: A pilot study",
        "abstract": "Recent research on product design and development processes suggests that the management and organization of the early stages of the process affect product success or failure in the marketplace.'According to Gupta and Wilemon, the early phases of development projects critically influence the length of time needed to bring a product to market-a robust and well-understood\" product definition\" is associated with a shorter development cycle. 2 Eisenhardt'and Gomory,'among others, argue that shorter development cycles contribute to competitive success by facilitating the insertion of new component technologies into products and accelerating the incorporation of improvements based on learning in production or in use. In addition, shorter development cycles may allow a firm to create greater product variety and a broader product\" family.\" Other empirical studies of new product development emphasize the \u2026",
        "year": 1994,
        "authors": "Glenn Bacon and Sara Beckman and David Mowery and Edith Wilson"
      }
    ],
    "SdXw4U4AAAAJ": [
      {
        "title": "Self-folding origami: shape memory composites activated by uniform heating",
        "abstract": "Self-folding is an approach used frequently in nature for the efficient fabrication of structures, but is seldom used in engineered systems. Here, self-folding origami are presented, which consist of shape memory composites that are activated with uniform heating in an oven. These composites are rapidly fabricated using inexpensive materials and tools. The folding mechanism based on the in-plane contraction of a sheet of shape memory polymer is modeled, and parameters for the design of composites that self-fold into target shapes are characterized. Four self-folding shapes are demonstrated: a cube, an icosahedron, a flower, and a Miura pattern; each of which is activated in an oven in less than 4 min. Self-sealing is also investigated using hot melt adhesive, and the resulting structures are found to bear up to twice the load of unsealed structures.",
        "year": 2014,
        "authors": "Michael T Tolley and Samuel M Felton and Shuhei Miyashita and Daniel Aukes and Daniela Rus and Robert J Wood"
      },
      {
        "title": "Design and testing of a selectively compliant underactuated hand",
        "abstract": "Motivated by the requirements of mobile manipulation, a compliant underactuated hand, capable of locking individual joints, has been developed. Locking is accomplished with electrostatic brakes in the joints and significantly increases the maximum pullout forces for power grasps. In addition, by locking and unlocking joints, the hand can adopt configurations and grasp sequences that would otherwise require a fully actuated solution. Other features of the hand include an integrated sensing suite that uses a common transduction technology on flexible printed circuits for tactile and proprioceptive sensing. The hand is analyzed using a three-dimensional rigid body analysis package with efficient simulation of compliant mechanisms and contacts with friction. This package allows one to evaluate design tradeoffs among link lengths, required tendon tensions, spring stiffnesses and braking requirements to grasp and \u2026",
        "year": 2014,
        "authors": "Daniel M Aukes and Barrett Heyneman and John Ulmen and Hannah Stuart and Mark R Cutkosky and Susan Kim and Pablo Garcia and Aaron Edsinger"
      },
      {
        "title": "Highly stretchable self-sensing actuator based on conductive photothermally-responsive hydrogel",
        "abstract": "Soft robots built with active soft materials have been increasingly attractive. Despite tremendous efforts in soft sensors and actuators, it remains extremely challenging to construct intelligent soft materials that simultaneously actuate and sense their own motions, resembling living organisms\u2019 neuromuscular behaviors. This work presents a soft robotic strategy that couples actuation and strain-sensing into a single homogeneous material, composed of an interpenetrating double-network of a nanostructured thermo-responsive hydrogel poly(N-isopropylacrylamide) (PNIPAAm) and a light-absorbing, electrically conductive polymer polypyrrole (PPy). This design grants the material both photo/thermal-responsiveness and piezoresistive-responsiveness, enabling remotely-triggered actuation and local strain-sensing. This self-sensing actuating soft material demonstrated ultra-high stretchability (210%) and large volume \u2026",
        "year": 2021,
        "authors": "Chiao-Yueh Lo and Yusen Zhao and Cheolgyu Kim and Yousif Alsaid and Roozbeh Khodambashi and Matthew Peet and Rebecca Fisher and Hamid Marvi and Spring Berman and Daniel Aukes and Ximin He"
      }
    ],
    "PznKxuwAAAAJ": [
      {
        "title": "An automated pipeline for the discovery of conspiracy and conspiracy theory narrative frameworks: Bridgegate, Pizzagate and storytelling on the web",
        "abstract": "Although a great deal of attention has been paid to how conspiracy theories circulate on social media, and the deleterious effect that they, and their factual counterpart conspiracies, have on political institutions, there has been little computational work done on describing their narrative structures. Predicating our work on narrative theory, we present an automated pipeline for the discovery and description of the generative narrative frameworks of conspiracy theories that circulate on social media, and actual conspiracies reported in the news media. We base this work on two separate comprehensive repositories of blog posts and news articles describing the well-known conspiracy theory Pizzagate from 2016, and the New Jersey political conspiracy Bridgegate from 2013. Inspired by the qualitative narrative theory of Greimas, we formulate a graphical generative machine learning model where nodes represent actors/actants, and multi-edges and self-loops among nodes capture context-specific relationships. Posts and news items are viewed as samples of subgraphs of the hidden narrative framework network. The problem of reconstructing the underlying narrative structure is then posed as a latent model estimation problem. To derive the narrative frameworks in our target corpora, we automatically extract and aggregate the actants (people, places, objects) and their relationships from the posts and articles. We capture context specific actants and interactant relationships by developing a system of supernodes and subnodes. We use these to construct an actant-relationship network, which constitutes the underlying generative narrative framework for \u2026",
        "year": 2020,
        "authors": "Timothy R Tangherlini and Shadi Shahsavari and Behnam Shahbazi and Ehsan Ebrahimzadeh and Vwani Roychowdhury"
      },
      {
        "title": "Recognition of nutrition intake using time-frequency decomposition in a wearable necklace using a piezoelectric sensor",
        "abstract": "Food intake levels, hydration, ingestion rate, and dietary choices are all factors known to impact the risk of obesity. This paper presents a novel wearable system in the form of a necklace, which aggregates data from an embedded piezoelectric sensor capable of detecting skin motion in the lower trachea during ingestion. The skin motion produces an output voltage with varying frequencies over time. As a result, we propose an algorithm based on time-frequency decomposition, spectrogram analysis of piezoelectric sensor signals, to accurately distinguish between food types, such as liquid and solid, hot and cold drinks, and hard and soft foods. The necklace transmits data to a smartphone, which performs the processing of the signals, classifies the food type, and provides visual feedback to the user to assist the user in monitoring their eating habits over time. We compare our spectrogram analysis with other time \u2026",
        "year": 2015,
        "authors": "Nabil Alshurafa and Haik Kalantarian and Mohammad Pourhomayoun and Jason J Liu and Shruti Sarin and Behnam Shahbazi and Majid Sarrafzadeh"
      },
      {
        "title": "An automated pipeline for character and relationship extraction from readers literary book reviews on goodreads. com",
        "abstract": "Reader reviews of literary fiction on social media, especially those in persistent, dedicated forums, create and are in turn driven by underlying narrative frameworks. In their comments about a novel, readers generally include only a subset of characters and their relationships, thus offering a limited perspective on that work. Yet in aggregate, these reviews capture an underlying narrative framework comprised of different actants (people, places, things), their roles, and interactions that we label the \u201cconsensus narrative framework\u201d. We represent this framework in the form of an actant-relationship story graph. Extracting this graph is a challenging computational problem, which we pose as a latent graphical model estimation problem. Posts and reviews are viewed as samples of sub graphs/networks of the hidden narrative framework. Inspired by the qualitative narrative theory of Greimas, we formulate a graphical \u2026",
        "year": 2020,
        "authors": "Shadi Shahsavari and Ehsan Ebrahimzadeh and Behnam Shahbazi and Misagh Falahi and Pavan Holur and Roja Bandari and Timothy R. Tangherlini and Vwani Roychowdhury"
      }
    ],
    "2kMKbisAAAAJ": [
      {
        "title": "Confronting the coffee crisis: can fair trade, organic, and specialty coffees reduce small-scale farmer vulnerability in northern Nicaragua?",
        "abstract": "This paper links changing global coffee markets to opportunities and vulnerabilities for sustaining small-scale farmer livelihoods in northern Nicaragua. Changing governance structures, corporate concentration, oversupply, interchangeable commodity grade beans, and low farm gate prices characterize the crisis in conventional coffee markets. In contrast, certified Fair Trade and organic are two alternative forms of specialty coffee trade and production that may offer opportunities for small-scale producers. A research team surveyed 228 farmers to measure the impact of sales on organic and Fair Trade markets. The results suggest that participation in organic and Fair Trade networks reduces farmers\u2019 livelihood vulnerability.",
        "year": 2005,
        "authors": "Christopher Bacon"
      },
      {
        "title": "Diversified farming systems: an agroecological, systems-based alternative to modern industrial agriculture",
        "abstract": "This Special Issue on Diversified Farming Systems is motivated by a desire to understand how agriculture designed according to whole systems, agroecological principles can contribute to creating a more sustainable, socially just, and secure global food system. We first define Diversified Farming Systems (DFS) as farming practices and landscapes that intentionally include functional biodiversity at multiple spatial and/or temporal scales in order to maintain ecosystem services that provide critical inputs to agriculture, such as soil fertility, pest and disease control, water use efficiency, and pollination. We explore to what extent DFS overlap or are differentiated from existing concepts such as sustainable, multifunctional, organic or ecoagriculture. DFS are components of social-ecological systems that depend on certain combinations of traditional and contemporary knowledge, cultures, practices, and governance \u2026",
        "year": 2012,
        "authors": "Claire Kremen and Alastair Iles and Christopher Bacon"
      },
      {
        "title": "Agroecology as a transdisciplinary, participatory, and action-oriented approach",
        "abstract": "This article traces multiple directions in the evolution of agroecology, from its early emphasis on ecological processes in agricultural systems, to its emergence as a multidimensional approach focusing on broader agro-food systems. This review is timely, as agroecology is being increasingly applied within a diversity of scientific-, policy-, and farmer-based initiatives. We contrast different agroecological perspectives or \u201cagroecologies\u201d and discuss the characteristics of an agroecology characterized by a transdisciplinary, participatory and action-oriented approach. Our final discussion describes the contents of the special issue, and states our goal for this compilation, which is to encourage future work that embraces an agroecological approach grounded in transdisciplinarity, participation, and transformative action.",
        "year": 2013,
        "authors": "V Ernesto M\u00e9ndez and Christopher M Bacon and Roseann Cohen"
      }
    ],
    "_dBDJygAAAAJ": [
      {
        "title": "Construction safety training via e-Learning: Learning effectiveness and user satisfaction",
        "abstract": "In Taiwan, promoting knowledge of \u201cLabor Safety\u201d which relates to life and work right is very important. Safety training and learning effectiveness become essential issues of adult learning. To reduce the costs of educational training, enterprises have also started to aggressively introduce e-learning education training. Unlike the construction industry, few studies have investigated the effectiveness of e-learning and conventional learning. This study tested the effectiveness of the safety education to prevent falls by different learning modes used to assess safety behavior and learning effectiveness during the education training period. According to the average pass rate, satisfaction degree of course and total number of unsafe behavior, the e-learning mode improves learning effectiveness. Additionally, when the e-learning mode is introduced in the construction safety education training, the labor can use the teaching \u2026",
        "year": 2010,
        "authors": "Chun-Ling Ho and Ren-Jye Dzeng"
      },
      {
        "title": "A study of ontology-based risk management framework of construction projects through project life cycle",
        "abstract": "The process knowledge assets make a substantial contribution to the risk management (RM) for contractors in the construction phase. To effectively reuse these assets, knowledge extraction becomes a significant research area. This paper was designed to explore an approach to conduct knowledge extraction by establishing project risk ontology. Specifically, the study proposed the ontology-based risk management (ORM) framework to enhance the RM performance by improving the RM workflow and knowledge reuse. The ORM framework facilitated the identification, analysis, and response of project risks. This study validated the ORM framework through a case demonstration. Through the implementation and application, the results demonstrated that the ORM framework was able to apply to the RM workflow for contractors, and more importantly, it greatly increased the effectiveness of project RM.",
        "year": 2009,
        "authors": "H Ping Tserng and Samuel YL Yin and Ren-Jye Dzeng and B Wou and MD Tsai and WY Chen"
      },
      {
        "title": "Using eye-tracker to compare search patterns between experienced and novice workers for site hazard identification",
        "abstract": "The construction industry accounts for a high number of accidents. Although identifying hazards prior to commencing construction is widely employed to prevent accidents, it typically fails because of insufficient safety experience. The experience helps in training novice inspectors, although extracting and describing tacit knowledge explicitly is difficult. This study created a digital building construction site, and designed a hazard-identification experiment involving four workplaces featuring obvious and unobvious hazards (e.g., falls, collapses, and electric shocks), and an eye-tracker was used to compare the search patterns of the experienced and novice workers. The results indicated that experience assisted the experienced workers in assessing both obvious (p < 0.001) and unobvious hazards (p = 0.004) significantly faster than the novice workers could; however, it did not improve the accuracy with which they \u2026",
        "year": 2016,
        "authors": "Ren-Jye Dzeng and Chin-Teng Lin and Yi-Cho Fang"
      }
    ],
    "p8E6WqMAAAAJ": [
      {
        "title": "Period optimization for hard real-time distributed automotive systems",
        "abstract": "The complexity and physical distribution of modern active-safety automotive applications requires the use of distributed architectures. These architectures consist of multiple electronic control units (ECUs) connected with standardized buses. The most common configuration features periodic activation of tasks and messages coupled with run-time priority-based scheduling. The correct deployment of applications on such architectures requires end-to-end latency deadlines to be met. This is challenging since deadlines must be enforced across a set of ECUs and buses, each of which supports multiple functionality. The need for accommodating legacy tasks and messages further complicates the scenario.In this work, we automatically assign task and message periods for distributed automotive systems. This is accomplished by leveraging schedulability analysis within a convex optimization framework to \u2026",
        "year": 2007,
        "authors": "Abhijit Davare and Qi Zhu and Marco Di Natale and Claudio Pinello and Sri Kanajan and Alberto Sangiovanni-Vincentelli"
      },
      {
        "title": "Minimization of dynamic and static power through joint assignment of threshold voltages and sizing optimization",
        "abstract": "We describe an optimization strategy for minimizing total power consumption using dual threshold voltage (Vth) technology. Significant power savings are possible by simultaneous assignment of Vth with gate sizing. We propose an efficient algorithm based on linear programming that jointly performs Vth assignment and gate sizing to minimize total power under delay constraints. First, linear programming assigns the optimal amounts of slack to gates based on power-delay sensitivity. Then, an optimal gate configuration, in terms of Vth and transistor sizes, is selected by an exhaustive local search. Benchmark results for the algorithm show 32% reduction in power consumption on average, compared to sizing only power minimization. There is up to a 57% reduction for some circuits. The flow can be extended to dual supply voltage libraries to yield further power savings.",
        "year": 2003,
        "authors": "David Nguyen and Abhijit Davare and Michael Orshansky and David Chinnery and Brandon Thompson and Kurt Keutzer"
      },
      {
        "title": "A next-generation design framework for platform-based design",
        "abstract": "The platform-based design methodology [1] is based on the usage of formal modeling techniques, clearly defined abstraction levels and the separation of concerns to enable an effective design process. The METROPOLIS framework embodies the platform-based design methodology and has been applied to a number of case studies across multiple domains. Based on these experiences, we have identified three key features that need to be enhanced: heterogeneous IP import, orthogonalization of performance from behavior, and design space exploration. The next generation METRO II framework incorporates these advanced features. The main concepts underlying METRO II are described in this paper and illustrated with a small example.",
        "year": 2007,
        "authors": "Abhijit Davare and Douglas Densmore and Trevor Meyerowitz and Alessandro Pinto and Alberto Sangiovanni-Vincentelli and Guang Yang and Haibo Zeng and Qi Zhu"
      }
    ],
    "ugMdl90AAAAJ": [
      {
        "title": "Scalable single-mode surface-emitting laser via open-Dirac singularities",
        "abstract": "Single-aperture cavities are a key component of lasers that are instrumental for the amplification and emission of a single light mode. However, the appearance of high-order transverse modes as the size of the cavities increases has frustrated efforts to scale-up cavities while preserving single-mode operation since the invention of the laser six decades ago, , , , , , \u2013. A suitable physical mechanism that allows single-mode lasing irrespective of the cavity size\u2014a \u2018scale invariant\u2019 cavity or laser\u2014has not been identified yet. Here we propose and demonstrate experimentally that open-Dirac electromagnetic cavities with linear dispersion\u2014which in our devices are realized by a truncated photonic crystal arranged in a hexagonal pattern\u2014exhibit unconventional scaling of losses in reciprocal space, leading to single-mode lasing that is maintained as the cavity is scaled up in size. The physical origin of this phenomenon lies \u2026",
        "year": 2022,
        "authors": "Rushin Contractor and Wanwoo Noh and Walid Redjem and Wayesh Qarony and Emma Martin and Scott Dhuey and Adam Schwartzberg and Boubacar Kant\u00e9"
      },
      {
        "title": "Differentiating and quantifying exosome secretion from a single cell using quasi-bound states in the continuum",
        "abstract": "One of the key challenges in biology is to understand how individual cells process information and respond to perturbations. However, most of the existing single-cell analysis methods can only provide a glimpse of cell properties at specific time points and are unable to provide cell secretion and protein analysis at single-cell resolution. To address the limits of existing methods and to accelerate discoveries from single-cell studies, we propose and experimentally demonstrate a new sensor based on bound states in the continuum to quantify exosome secretion from a single cell. Our optical sensors demonstrate high-sensitivity refractive index detection. Because of the strong overlap between the medium supporting the mode and the analytes, such an optical cavity has a figure of merit of 677 and sensitivity of 440 nm/RIU. Such results facilitate technological progress for highly conducive optical sensors for different \u2026",
        "year": 2020,
        "authors": "Abdoulaye Ndao and Liyi Hsu and Wei Cai and Jeongho Ha and Junhee Park and Rushin Contractor and Yuhwa Lo and Boubacar Kant\u00e9"
      },
      {
        "title": "Ultra-broadband, polarization-independent, wide-angle absorption in impedance-matched metamaterials with anti-reflective moth-eye surfaces",
        "abstract": "We computationally study periodic impedance-matched metal-dielectric metamaterials and the advantage of imprinting moth-eye surfaces on them. Impedance-matched metamaterials are known to act as strong, polarization-independent, broadband absorbers. However, in the infrared region far from the metal\u2019s plasma frequency, the reflection from metal layers dominates over the absorption. Using anti-reflective moth-eye surfaces we show that it is possible to obtain absorption independent of polarization or incidence angle, over an exceptionally broad frequency range from 400 nm to 6 \u03bcm.",
        "year": 2018,
        "authors": "Rushin Contractor and Giuseppe D\u2019Aguanno and Curtis Menyuk"
      }
    ],
    "sNW9iscAAAAJ": [
      {
        "title": "Milliscale Features Increase Friction of Soft Skin in Lubricated Contact",
        "abstract": "Real world environments, such as kitchens, present objects covered in viscous fluids: soap, oil, water, etc. Understanding and designing for slippery and submerged contact, where fluid lubrication is present, is a continuing challenge in the robotics community. Contact area, bending stiffness, and the presence of a viscous fluid affect friction. This work focuses on milliscale features (3 to 20 mm in size) of soft urethane skin on smooth, flat surfaces. We characterize the friction of soft skins, with varying size, and therefore bending stiffness, of cylindrical features, all with the same nominal contact area. In addition, a new method of frustrated total internal reflection with dye is introduced to visualize lubricated contact. We find that a small number of milliscale fingertip features maximizes friction force in the presence of lubrication, as compared both to un-patterned and many-featured skin designs. This holds true for a robotic \u2026",
        "year": 2020,
        "authors": "Monica S Li and Dominic Melville and Ethan Chung and Hannah S Stuart"
      },
      {
        "title": "Tactile sensing based on fingertip suction flow for submerged dexterous manipulation",
        "abstract": "The ocean is a harsh and unstructured environment for robotic systems; high ambient pressures, saltwater corrosion and low-light conditions demand machines with robust electrical and mechanical parts that are able to sense and respond to the environment. Prior work shows that the addition of gentle suction flow to the hands of underwater robots can aid in the handling of objects during mobile manipulation tasks. The current paper explores using this suction flow mechanism as a new modality for tactile sensing; by monitoring orifice occlusion we can get a sense of how objects make contact in the hand. The electronics required for this sensor can be located remotely from the hand and the signal is insensitive to large changes in ambient pressure associated with diving depth. In this study, suction is applied to the fingertips of a two-fingered compliant gripper and suction-based tactile sensing is monitored while an \u2026",
        "year": 2020,
        "authors": "Philippe Nadeau and Michael Abbott and Dominic Melville and Hannah S Stuart"
      }
    ],
    "uBFV6SUAAAAJ": [
      {
        "title": "Optimizing semantic coherence in topic models",
        "abstract": "Latent variable models have the potential to add value to large document collections by discovering interpretable, low-dimensional subspaces. In order for people to use such models, however, they must trust them. Unfortunately, typical dimensionality reduction methods for text, such as latent Dirichlet allocation, often produce low-dimensional subspaces (topics) that are obviously flawed to human domain experts. The contributions of this paper are threefold:(1) An analysis of the ways in which topics can be flawed;(2) an automated evaluation metric for identifying such topics that does not rely on human annotators or reference collections outside the training data;(3) a novel statistical topic model based on this metric that significantly improves topic quality in a large-scale document collection from the National Institutes of Health (NIH).",
        "year": 2011,
        "authors": "David Mimno and Hanna Wallach and Edmund Talley and Miriam Leenders and Andrew McCallum"
      },
      {
        "title": "Evaluation methods for topic models",
        "abstract": "A natural evaluation metric for statistical topic models is the probability of held-out documents given a trained model. While exact computation of this probability is intractable, several estimators for this probability have been used in the topic modeling literature, including the harmonic mean method and empirical likelihood method. In this paper, we demonstrate experimentally that commonly-used methods are unlikely to accurately estimate the probability of held-out documents, and propose two alternative methods that are both accurate and efficient.",
        "year": 2009,
        "authors": "Hanna M Wallach and Iain Murray and Ruslan Salakhutdinov and David Mimno"
      },
      {
        "title": "Rethinking LDA: Why priors matter",
        "abstract": "Implementations of topic models typically use symmetric Dirichlet priors with fixed concentration parameters, with the implicit assumption that such smoothing parameters\" have little practical effect. In this paper, we explore several classes of structured priors for topic models. We find that an asymmetric Dirichlet prior over the document-topic distributions has substantial advantages over a symmetric prior, while an asymmetric prior over the topic-word distributions provides no real benefit. Approximation of this prior structure through simple, efficient hyperparameter optimization steps is sufficient to achieve these performance gains. The prior structure we advocate substantially increases the robustness of topic models to variations in the number of topics and to the highly skewed word frequency distributions common in natural language. Since this prior structure can be implemented using efficient algorithms that add negligible cost beyond standard inference techniques, we recommend it as a new standard for topic modeling.\"",
        "year": 2009,
        "authors": "Hanna Wallach and David Mimno and Andrew McCallum"
      }
    ],
    "7w2WVgIAAAAJ": [
      {
        "title": "Bio-inspired geotechnical engineering: principles, current work, opportunities and challenges",
        "abstract": "A broad diversity of biological organisms and systems interact with soil in ways that facilitate their growth and survival. These interactions are made possible by strategies that enable organisms to accomplish functions that can be analogous to those required in geotechnical engineering systems. Examples include anchorage in soft and weak ground, penetration into hard and stiff subsurface materials and movement in loose sand. Since the biological strategies have been \u2018vetted\u2019 by the process of natural selection, and the functions they accomplish are governed by the same physical laws in both the natural and engineered environments, they represent a unique source of principles and design ideas for addressing geotechnical challenges. Prior to implementation as engineering solutions, however, the differences in spatial and temporal scales and material properties between the biological environment and \u2026",
        "year": 2022,
        "authors": "Alejandro Martinez and Jason Dejong and Idil Akin and Ali Aleali and Chloe Arson and Jared Atkinson and Paola Bandini and Tugce Baser and Rodrigo Borela and Ross Boulanger and Matthew Burrall and Yuyan Chen and Clint Collins and Douglas Cortes and Sheng Dai and Theodore DeJong and Emanuela Del Dottore and Kelly Dorgan and Richard Fragaszy and J David Frost and Robert Full and Majid Ghayoomi and Daniel I Goldman and Nicholas Gravish and Ivan L Guzman and James Hambleton and Elliot Hawkes and Michael Helms and David Hu and Lin Huang and Sichuan Huang and Christopher Hunt and Duncan Irschick and Hai Thomas Lin and Bret Lingwall and Alen Marr and Barbara Mazzolai and Benjamin McInroe and Tejas Murthy and Kyle O'hara and Marianne Porter and Salah Sadek and Marcelo Sanchez and Carlos Santamarina and Lisheng Shao and James Sharp and Hannah Stuart and Hans Henning Stutz and Adam Summers and Julian Tao and Michael Tolley and Laura Treers and Kurtis Turnbull and Rogelio Valdes and Leon Van Paassen and Gioacchino Viggiani and Daniel Wilson and Wei Wu and Xiong Yu and Junxing Zheng"
      },
      {
        "title": "Granular resistive force theory implementation for three-dimensional trajectories",
        "abstract": "Modelling interaction forces as bodies intrude into granular media is a longstanding challenge in the design and control of machines that navigate and manipulate these highly complex materials. Granular Resistive Force Theory, or RFT, is a flexible, reduced-order model for predicting intrusion forces on bodies in granular media. 2D RFT describes the forces on a plate whose velocity and normal vectors lie in the same vertical plane. We introduce a 3D RFT method that projects the total velocity vector into two scenarios that can already be described by 2D RFT, which allows us to extend the model into 3D with minimal additional experimental characterization. We then superimpose these independently calculated forces, weighted by experimentally fit scaling factors, to determine the total force on the plate. When applied to discretized convex hulls, this method performs force estimates of arbitrary trajectories in 3D \u2026",
        "year": 2021,
        "authors": "Laura K Treers and Cyndia Cao and Hannah S Stuart"
      },
      {
        "title": "Design and control of lightweight supernumerary robotic limbs for sitting/standing assistance",
        "abstract": "We present a new, lightweight prototype of the Supernumerary Robotic Limbs (SRL), a wearable robot that augments its user by providing two extra robotic legs. We then showcase the robot\u2019s assistive capabilities by developing and implementing a control strategy that supports the user during sitting and standing motions. The reduced mass and volume of the robot are enabled by innovative design choices including advanced materials, efficient joint structure, and high-performance pneumatic actuation. The assistive control strategy is tailored to each individual based on their motion preferences, and allows the SRL to support users without getting in the way of their movements. The proposed assistive strategy is implemented and validated in experiments with the physical SRL prototype.",
        "year": 2017,
        "authors": "Laura Treers and Roger Lo and Michael Cheung and Aymeric Guy and Jacob Guggenheim and Federico Parietti and Harry Asada"
      }
    ],
    "mbcRJ2sAAAAJ": [
      {
        "title": "Selenium for preventing cancer",
        "abstract": "BackgroundThis review is the third update of the Cochrane review\" Selenium for preventing cancer\". Selenium is a naturally occurring element with both nutritional and toxicological properties. Higher selenium exposure and selenium supplements have been suggested to protect against several types of cancer.Objectives",
        "year": 2018,
        "authors": "Marco Vinceti and Tommaso Filippini and Cinzia Del Giovane and Gabriele Dennert and Marcel Zwahlen and Maree Brinkman and Maurice PA Zeegers and Markus Horneber and Roberto D'Amico and Catherine M Crespi"
      },
      {
        "title": "Mindfulness meditation for younger breast cancer survivors: a randomized controlled trial",
        "abstract": "Premenopausal women diagnosed with breast cancer are at risk for psychological and behavioral disturbances after cancer treatment. Targeted interventions are needed to address the needs of this vulnerable group.This randomized trial provided the first evaluation of a brief, mindfulness\u2010based intervention for younger breast cancer survivors designed to reduce stress, depression, and inflammatory activity. Women diagnosed with early stage breast cancer at or before age 50 who had completed cancer treatment were randomly assigned to a 6\u2010week Mindful Awareness Practices (MAPS) intervention group (n\u2009=\u200939) or to a wait\u2010list control group (n\u2009=\u200932). Participants completed questionnaires before and after the intervention to assess stress and depressive symptoms (primary outcomes) as well as physical symptoms, cancer\u2010related distress, and positive outcomes. Blood samples \u2026",
        "year": 2015,
        "authors": "Julienne E Bower and Alexandra D Crosswell and Annette L Stanton and Catherine M Crespi and Diana Winston and Jesusa Arevalo and Jeffrey Ma and Steve W Cole and Patricia A Ganz"
      },
      {
        "title": "Pooled analysis of recent studies on magnetic fields and childhood leukaemia",
        "abstract": "Background:Previous pooled analyses have reported an association between magnetic fields and childhood leukaemia. We present a pooled analysis based on primary data from studies on residential magnetic fields and childhood leukaemia published after 2000.Methods:Seven studies with a total of 10 865 cases and 12 853 controls were included. The main analysis focused on 24-h magnetic field measurements or calculated fields in residences.Results:In the combined results, risk increased with increase in exposure, but the estimates were imprecise. The odds ratios for exposure categories of 0.1\u20130.2 \u03bcT, 0.2\u20130.3 \u03bcT and\u2a7e 0.3 \u03bcT, compared with< 0.1 \u03bcT, were 1.07 (95% CI 0.81\u20131.41), 1.16 (0.69\u20131.93) and 1.44 (0.88\u20132.36), respectively. Without the most influential study from Brazil, the odds ratios increased somewhat. An increasing trend was also suggested by a nonparametric analysis conducted using a \u2026",
        "year": 2010,
        "authors": "Leeka Kheifets and Anders Ahlbom and Catherine M Crespi and Gerald Draper and Jun Hagihara and Raymond M Lowenthal and Gabor Mezei and Sona Oksuzyan and Joachim Sch\u00fcz and John Swanson and Andrea Tittarelli and Marco Vinceti and V Wunsch Filho"
      }
    ],
    "wg421oQAAAAJ": [
      {
        "title": "Systematic revision of Symbiodiniaceae highlights the antiquity and diversity of coral endosymbionts",
        "abstract": "The advent of molecular data has transformed the science of organizing and studying life on Earth. Genetics-based evidence provides fundamental insights into the diversity, ecology, and origins of many biological systems, including the mutualisms between metazoan hosts and their micro-algal partners. A well-known example is the dinoflagellate endosymbionts (\"zooxanthellae\") that power the growth of stony corals and coral reef ecosystems. Once assumed to encompass a single panmictic species, genetic evidence has revealed a divergent and rich diversity within the zooxanthella genus Symbiodinium. Despite decades of reporting on the significance of this diversity, the formal systematics of these eukaryotic microbes have not kept pace, and a major revision is long overdue. With the consideration of molecular, morphological, physiological, and ecological data, we propose that evolutionarily divergent \u2026",
        "year": 2018,
        "authors": "Todd C LaJeunesse and John Everett Parkinson and Paul W Gabrielson and Hae Jin Jeong and James Davis Reimer and Christian R Voolstra and Scott R Santos"
      },
      {
        "title": "Bacterial community dynamics are linked to patterns of coral heat tolerance",
        "abstract": "Ocean warming threatens corals and the coral reef ecosystem. Nevertheless, corals can be adapted to their thermal environment and inherit heat tolerance across generations. In addition, the diverse microbes that associate with corals have the capacity for more rapid change, potentially aiding the adaptation of long-lived corals. Here, we show that the microbiome of reef corals is different across thermally variable habitats and changes over time when corals are reciprocally transplanted. Exposing these corals to thermal bleaching conditions changes the microbiome for heat-sensitive corals, but not for heat-tolerant corals growing in habitats with natural high heat extremes. Importantly, particular bacterial taxa predict the coral host response in a short-term heat stress experiment. Such associations could result from parallel responses of the coral and the microbial community to living at high natural temperatures. A \u2026",
        "year": 2017,
        "authors": "Maren Ziegler and Francois O Seneca and Lauren K Yum and Stephen R Palumbi and Christian R Voolstra"
      },
      {
        "title": "Nitrogen cycling in corals: the key to understanding holobiont functioning?",
        "abstract": "Corals are animals that form close mutualistic associations with endosymbiotic photosynthetic algae of the genus Symbiodinium. Together they provide the calcium carbonate framework of coral reef ecosystems. The importance of the microbiome (i.e., bacteria, archaea, fungi, and viruses) to holobiont functioning has only recently been recognized. Given that growth and density of Symbiodinium within the coral host is highly dependent on nitrogen availability, nitrogen-cycling microbes may be of fundamental importance to the stability of the coral\u2013algae symbiosis and holobiont functioning, in particular under nutrient-enriched and -depleted scenarios. We summarize what is known about nitrogen cycling in corals and conclude that disturbance of microbial nitrogen cycling may be tightly linked to coral bleaching and disease.",
        "year": 2015,
        "authors": "Nils R\u00e4decker and Claudia Pogoreutz and Christian R Voolstra and J\u00f6rg Wiedenmann and Christian Wild"
      }
    ],
    "XCkp5uEAAAAJ": [
      {
        "title": "Europe-wide reduction in primary productivity caused by the heat and drought in 2003",
        "abstract": "Future climate warming is expected to enhance plant growth in temperate ecosystems and to increase carbon sequestration,. But although severe regional heatwaves may become more frequent in a changing climate,, their impact on terrestrial carbon cycling is unclear. Here we report measurements of ecosystem carbon dioxide fluxes, remotely sensed radiation absorbed by plants, and country-level crop yields taken during the European heatwave in 2003. We use a terrestrial biosphere simulation model to assess continental-scale changes in primary productivity during 2003, and their consequences for the net carbon balance. We estimate a 30 per cent reduction in gross primary productivity over Europe, which resulted in a strong anomalous net source of carbon dioxide (0.5\u2009Pg\u2009C\u2009yr-1) to the atmosphere and reversed the effect of four years of net ecosystem carbon sequestration. Our results suggest that \u2026",
        "year": 2005,
        "authors": "Ph Ciais and Markus Reichstein and Nicolas Viovy and Andr\u00e9 Granier and J\u00e9r\u00f4me Og\u00e9e and Vincent Allard and Marc Aubinet and Nina Buchmann and Chr Bernhofer and Arnaud Carrara and Fdr Chevallier and Nathalie De Noblet and Andrew D Friend and Pierre Friedlingstein and Thomas Gr\u00fcnwald and Bernard Heinesch and Petri Keronen and Alexander Knohl and Gerhard Krinner and Denis Loustau and Giovanni Manca and Giorgio Matteucci and Franco Miglietta and Jean-Marc Ourcival and Dario Papale and Kim Pilegaard and Serge Rambal and G\u00fcnther Seufert and Jean-Fran\u00e7ois Soussana and Mar\u00eda Jos\u00e9 Sanz and Ernst-Detlef Schulze and Timo Vesala and Riccardo Valentini"
      },
      {
        "title": "Deep learning and process understanding for data-driven Earth system science",
        "abstract": "Machine learning approaches are increasingly used to extract patterns and insights from the ever-increasing stream of geospatial data, but current approaches may not be optimal when system behaviour is dominated by spatial or temporal context. Here, rather than amending classical machine learning, we argue that these contextual cues should be used as part of deep learning (an approach that is able to extract spatio-temporal features automatically) to gain further process understanding of Earth system science problems, improving the predictive ability of seasonal forecasting and modelling of long-range spatial connections across multiple timescales, for example. The next step will be a hybrid modelling approach, coupling physical process models with the versatility of data-driven machine learning.",
        "year": 2019,
        "authors": "Markus Reichstein and Gustau Camps-Valls and Bjorn Stevens and Martin Jung and Joachim Denzler and Nuno Carvalhais and F Prabhat"
      },
      {
        "title": "On the separation of net ecosystem exchange into assimilation and ecosystem respiration: review and improved algorithm",
        "abstract": "This paper discusses the advantages and disadvantages of the different methods that separate net ecosystem exchange (NEE) into its major components, gross ecosystem carbon uptake (GEP) and ecosystem respiration (Reco). In particular, we analyse the effect of the extrapolation of night\u2010time values of ecosystem respiration into the daytime; this is usually done with a temperature response function that is derived from long\u2010term data sets. For this analysis, we used 16 one\u2010year\u2010long data sets of carbon dioxide exchange measurements from European and US\u2010American eddy covariance networks. These sites span from the boreal to Mediterranean climates, and include deciduous and evergreen forest, scrubland and crop ecosystems.We show that the temperature sensitivity of Reco, derived from long\u2010term (annual) data sets, does not reflect the short\u2010term temperature sensitivity that is effective when \u2026",
        "year": 2005,
        "authors": "Markus Reichstein and Eva Falge and Dennis Baldocchi and Dario Papale and Marc Aubinet and Paul Berbigier and Christian Bernhofer and Nina Buchmann and Tagir Gilmanov and Andre Granier and Thomas Gr\u00fcnwald and Katka Havrankova and Hannu Ilvesniemi and Dalibor Janous and Alexander Knohl and Tuomas Laurila and Annalea Lohila and Denis Loustau and Giorgio Matteucci and Tilden Meyers and Franco Miglietta and Jean\u2010Marc Ourcival and Jukka Pumpanen and Serge Rambal and Eyal Rotenberg and Maria Sanz and John Tenhunen and G\u00fcnther Seufert and Francesco Vaccari and Timo Vesala and Dan Yakir and Riccardo Valentini"
      }
    ],
    "alxMRnQAAAAJ": [
      {
        "title": "Takt time planning for construction of exterior cladding",
        "abstract": "This paper presents the concept and steps taken, as well as a case study on production scheduling, to implement the use of Takt time. It starts with an overview of traditional construction scheduling and contrasts that with the use of production scheduling using Takt time. It then presents a process for Takt time scheduling and illustrates its application by means of a case study. Takt time was used to drive installation of the exterior cladding system on a healthcare facility in Sacramento, California. Thanks to the use of a production schedule with a four-day Takt, the traditional construction schedule of 11 months for partial completion of the exteriors was reduced to 5.5 months. This case study illustrates the successful development and application of Takt time, challenges, benefits, and lessons learned.",
        "year": 2013,
        "authors": "Adam Frandson and Klas Berghede and Iris D Tommelein"
      },
      {
        "title": "Comparison between location based management and takt time planning",
        "abstract": "Construction planning methods may or may not explicitly model space as a resource. This paper compares two methods that do. The first method is used in the Location Based Management System (LBMS). The second method is Takt Time Planning (TTP). Both are iterative design methods for planning and controlling construction work, both focus on creating a balanced production schedule with a predictable timing of work while also preventing spatial interference between trades, but they differ in how they achieve these goals. The contribution of this paper is to (1) highlight the similarities and differences between these two methods and (2) describe a proposal for future exploratory research to evaluate the systems using common metrics.",
        "year": 2015,
        "authors": "Adam G Frandson and Olli Sepp\u00e4nen and Iris D Tommelein"
      },
      {
        "title": "Takt-time planning and the last planner",
        "abstract": "Introduction of the Last Planner\u2122 System helped to improve predictability and overall productivity in the construction industry. In manufacturing, the use of takttime resulting in production to a set beat, has long been a center piece in leveling work flow and optimizing production lines. This paper will explore how we successfully merge the rigorous and more pre-determined structure of takt-time planning with the fluid, more interactive and responsive Last Planner\u2122 System. The paper will use the Cathedral Hill Hospital Project as an example of takt-time planning in use and describe how the production team can work together with Last Planners to make sure that the structure and alignment from the takt-time plan also improve and simplify the Last Planner\u2019s ability to plan their work successfully. We are especially interested in the dynamics around worker buy-in and the notion of manageable \u2018chunks\u2019 of work to improve the ability for workers to plan successfully.",
        "year": 2014,
        "authors": "Adam Frandson and Klas Berghede and Iris D Tommelein"
      }
    ],
    "kqTlJ1MAAAAJ": [
      {
        "title": "Examining multi-functionality for crop yield and ecosystem services in five systems of agroecological intensification",
        "abstract": "Agroecological intensification (AEI) integrates ecological principles and biodiversity management into farming systems with the aims of increasing farm productivity, reducing dependency on external inputs, and sustaining or enhancing ecosystem services. This review develops an analytic framework to characterize the fulfilment of these objectives by documenting the co-occurrence of positive, neutral, and negative outcomes for crop yield and nine regulating ecosystem services. We provide an illustrative examination of the framework, evaluating evidence for yield and ecosystem service outcomes across five AEI systems: conservation agriculture, holistic grazing management, organic agriculture, precision agriculture, and system of rice intensification (SRI). We reviewed 104 studies containing 245 individual comparisons between AEI and contrasting farming systems. In three of the five AEI systems, conservation \u2026",
        "year": 2017,
        "authors": "Kelly Garbach and Jeffrey C Milder and Fabrice AJ DeClerck and Maywa Montenegro de Wit and Laura Driscoll and Barbara Gemmill-Herren"
      },
      {
        "title": "Sovereignty at what scale? An inquiry into multiple dimensions of food sovereignty",
        "abstract": "Food sovereignty has struggled to make inroads into changing the structures and processes underlying the corporate food regime. One reason is that scale is still underspecified in the politics, strategies, and theories of food sovereignty. We suggest that much can be learned from examining the multiple dimensions of scale inherent in ongoing food sovereignty struggles. A gap exists between these in vivo experiments and the maturing academic theory of scale. The concept of \u2018sovereignty\u2019 can be opened up to reveal that movements, peoples, and communities, for example, are creating multiple sovereignties and are exercising sovereignty in more relational ways. Relational scale can aid movements and scholars to map and evaluate how spatial and temporal processes at and among various levels work to reinforce dominant agri-food systems but could also be reconfigured to support progressive alternatives \u2026",
        "year": 2018,
        "authors": "Alastair Iles and Maywa Montenegro De Wit"
      },
      {
        "title": "Transitioning to sustainable agriculture requires growing and sustaining an ecologically skilled workforce",
        "abstract": "In the face of rapidly advancing climate change, biodiversity loss, and water scarcity, it is clear that global agriculture must swiftly and decisively shift toward sustainability. Fortunately, farmers and researchers have developed a thoroughly studied pathway to this transition: agroecological farming systems that mimic natural ecosystems, creating tightly coupled cycles of energy, water, and nutrients. A critical and underappreciated feature of agroecological systems is that they replace fossil fuel- and chemical -intensive management with knowledge-intensive management. Hence, the greatest sustainability challenge for agriculture may well be that of replacing non-renewable resources with ecologically-skilled people, and doing so in ways that create and support desirable rural livelihoods. Yet over the past century, US agriculture has been trending in the opposite direction, rapidly replacing knowledgeable people with non-renewable resources and eroding rural economies in the process. Below, we suggest how US policy could pivot to enable and support the ecologically skilled workforce needed to achieve food security in the face of climate change.",
        "year": 2019,
        "authors": "Liz Carlisle and Maywa Montenegro de Wit and Marcia S DeLonge and Alastair Iles and Adam Calo and Christy Getz and Joanna Ory and Katherine Munden-Dixon and Ryan Galt and Brett Melone and Reggie Knox and Daniel Press"
      }
    ],
    "ylh95x4AAAAJ": [
      {
        "title": "Judgment in managerial decision making",
        "abstract": "Behavioral decision research provides many important insights into managerial behavior. From negotiation to investment decisions, the authors weave behavioral decision research into the organizational realm by examining judgment in a variety of managerial contexts. Embedded with the latest research and theories, Managerial Decision Making 8th Edition gives students the opportunity to understand their own decision-making tendencies, learn strategies for overcoming cognitive biases, and become better decision makers.",
        "year": 2012,
        "authors": "Max H Bazerman and Don A Moore"
      },
      {
        "title": "The trouble with overconfidence.",
        "abstract": "The authors present a reconciliation of 3 distinct ways in which the research literature has defined overconfidence:(a) overestimation of one's actual performance,(b) overplacement of one's performance relative to others, and (c) excessive precision in one's beliefs. Experimental evidence shows that reversals of the first 2 (apparent underconfidence), when they occur, tend to be on different types of tasks. On difficult tasks, people overestimate their actual performances but also mistakenly believe that they are worse than others; on easy tasks, people underestimate their actual performances but mistakenly believe they are better than others. The authors offer a straightforward theory that can explain these inconsistencies. Overprecision appears to be more persistent than either of the other 2 types of overconfidence, but its presence reduces the magnitude of both overestimation and overplacement.",
        "year": 2008,
        "authors": "Don A Moore and Paul J Healy"
      },
      {
        "title": "Redefine statistical significance",
        "abstract": "The lack of reproducibility of scientific studies has caused growing concern over the credibility of claims of new discoveries based on \u2018statistically significant\u2019findings. There has been much progress toward documenting and addressing several causes of this lack of reproducibility (for example, multiple testing, P-hacking, publication bias and under-powered studies). However, we believe that a leading cause of non-reproducibility has not yet been adequately addressed: statistical standards of evidence for claiming new discoveries in many fields of science are simply too low. Associating statistically significant findings with P< 0.05 results in a high rate of false positives even in the absence of other experimental, procedural and reporting problems.For fields where the threshold for defining statistical significance for new discoveries is P< 0.05, we propose a change to P< 0.005. This simple step would immediately \u2026",
        "year": 2018,
        "authors": "Daniel J Benjamin and James O Berger and Magnus Johannesson and Brian A Nosek and E-J Wagenmakers and Richard Berk and Kenneth A Bollen and Bj\u00f6rn Brembs and Lawrence Brown and Colin Camerer and David Cesarini and Christopher D Chambers and Merlise Clyde and Thomas D Cook and Paul De Boeck and Zoltan Dienes and Anna Dreber and Kenny Easwaran and Charles Efferson and Ernst Fehr and Fiona Fidler and Andy P Field and Malcolm Forster and Edward I George and Richard Gonzalez and Steven Goodman and Edwin Green and Donald P Green and Anthony G Greenwald and Jarrod D Hadfield and Larry V Hedges and Leonhard Held and Teck Hua Ho and Herbert Hoijtink and Daniel J Hruschka and Kosuke Imai and Guido Imbens and John Ioannidis and Minjeong Jeon and James Holland Jones and Michael Kirchler and David Laibson and John List and Roderick Little and Arthur Lupia and Edouard Machery and Scott E Maxwell and Michael McCarthy and Don A Moore and Stephen L Morgan and Marcus Munaf\u00f3 and Shinichi Nakagawa and Brendan Nyhan and Timothy H Parker and Luis Pericchi and Marco Perugini and Jeff Rouder and Judith Rousseau and Victoria Savalei and Felix D Sch\u00f6nbrodt and Thomas Sellke and Betsy Sinclair and Dustin Tingley and Trisha Van Zandt and Simine Vazire and Duncan J Watts and Christopher Winship and Robert L Wolpert and Yu Xie and Cristobal Young and Jonathan Zinman and Valen E Johnson"
      }
    ],
    "ORaHXn8AAAAJ": [
      {
        "title": "Geographies of friendships",
        "abstract": "Friendships are an important part of what makes us, and our geographies of various kinds, human. We consider how geographers can contribute to efforts to afford friendship greater prominence in the social sciences. The main part of the article considers three strands of work on friendship that push the boundaries of research in human geography: (1) geographies of affect/emotion and the ontological construction of the human; (2) children\u2019s and young people\u2019s geographies and the (re)production of social ordering; and (3) geographies of mobility and transnationalism in a world of increased human spatial movement and social relations at a distance.",
        "year": 2012,
        "authors": "Tim Bunnell and Sallie Yea and Linda Peake and Tracey Skelton and Monica Smith"
      },
      {
        "title": "Contentious Kwangju: the May 18 uprising in Korea's past and present",
        "abstract": "One of the largest political protests in contemporary Korean history, the May 1980 Kwangju Uprising still exerts a profound, often contested, influence in Korean society. Through a deft combination of personal reflections and academic analysis, Contentious Kwangju offers a comprehensive examination of the multiple, shifting meanings of this seminal event and explains how the memory of Kwangju has affected Korean life from politics to culture. In keeping with the book's title, the essays offer competing interpretations of the Kwangju Uprising, yet together provide the most thorough English-language treatment to date of the multifaceted, sweeping significance of this seminal event.",
        "year": 2003,
        "authors": "Gi-Wook Shin and Kyung Moon Hwang"
      },
      {
        "title": "Introduction",
        "abstract": "The theme of KAIZEN as an approach and philosophy of continuous improvement is still valid in the second decade of the twenty-first century. An example is the considerable papers that were presented at the Production Operation Management Conference POMS 2022 held online, including that to be held in Nara, Japan on the topic of KAIZEN. Quantitative empirical articles, case studies, qualitative studies, and even some theoretical ones continue to be presented. From another aspect, in the practical arena, in virtually every social network in the world, the term KAIZEN appears in different forms of training, seminars, conferences, and webinars. In simple terms, it is a concept that is still valid and widespread to this day.Organizations are probably experiencing one of the most turbulent environments they could experience in recent years. The global coronavirus disease 2019 (COVID-19) has resulted in COVID-19 \u2026",
        "year": 2023,
        "authors": "Manuel F Su\u00e1rez-Barraza"
      }
    ],
    "dJ8MMFoAAAAJ": [
      {
        "title": "FLUXNET: A new tool to study the temporal and spatial variability of ecosystem-scale carbon dioxide, water vapor, and energy flux densities",
        "abstract": "FLUXNET is a global network of micrometeorological flux measurement sites that measure the exchanges of carbon dioxide, water vapor, and energy between the biosphere and atmosphere. At present over 140 sites are operating on a long-term and continuous basis. Vegetation under study includes temperate conifer and broadleaved (deciduous and evergreen) forests, tropical and boreal forests, crops, grasslands, chaparral, wetlands, and tundra. Sites exist on five continents and their latitudinal distribution ranges from 70\u00b0N to 30\u00b0S.             FLUXNET has several primary functions. First, it provides infrastructure for compiling, archiving, and distributing carbon, water, and energy flux measurement, and meteorological, plant, and soil data to the science community. (Data and site information are available online at the FLUXNET Web site,             http://www-eosdis.ornl.gov/FLUXNET/             .) Second, the \u2026",
        "year": 2001,
        "authors": "Dennis Baldocchi and Eva Falge and Lianhong Gu and Richard Olson and David Hollinger and Steve Running and Peter Anthoni and Ch Bernhofer and Kenneth Davis and Robert Evans and Jose Fuentes and Allen Goldstein and Gabriel Katul and Beverly Law and Xuhui Lee and Yadvinder Malhi and Tilden Meyers and William Munger and Walt Oechel and Kyaw Tha Paw U and Kim Pilegaard and Hans Peter Schmid and Riccardo Valentini and Shashi Verma and Timo Vesala and Kell Wilson and Steve Wofsy"
      },
      {
        "title": "On the separation of net ecosystem exchange into assimilation and ecosystem respiration: review and improved algorithm",
        "abstract": "This paper discusses the advantages and disadvantages of the different methods that separate net ecosystem exchange (NEE) into its major components, gross ecosystem carbon uptake (GEP) and ecosystem respiration (Reco). In particular, we analyse the effect of the extrapolation of night\u2010time values of ecosystem respiration into the daytime; this is usually done with a temperature response function that is derived from long\u2010term data sets. For this analysis, we used 16 one\u2010year\u2010long data sets of carbon dioxide exchange measurements from European and US\u2010American eddy covariance networks. These sites span from the boreal to Mediterranean climates, and include deciduous and evergreen forest, scrubland and crop ecosystems.We show that the temperature sensitivity of Reco, derived from long\u2010term (annual) data sets, does not reflect the short\u2010term temperature sensitivity that is effective when \u2026",
        "year": 2005,
        "authors": "Markus Reichstein and Eva Falge and Dennis Baldocchi and Dario Papale and Marc Aubinet and Paul Berbigier and Christian Bernhofer and Nina Buchmann and Tagir Gilmanov and Andre Granier and Thomas Gr\u00fcnwald and Katka Havrankova and Hannu Ilvesniemi and Dalibor Janous and Alexander Knohl and Tuomas Laurila and Annalea Lohila and Denis Loustau and Giorgio Matteucci and Tilden Meyers and Franco Miglietta and Jean\u2010Marc Ourcival and Jukka Pumpanen and Serge Rambal and Eyal Rotenberg and Maria Sanz and John Tenhunen and G\u00fcnther Seufert and Francesco Vaccari and Timo Vesala and Dan Yakir and Riccardo Valentini"
      },
      {
        "title": "Assessing the eddy covariance technique for evaluating carbon dioxide exchange rates of ecosystems: past, present and future",
        "abstract": "The eddy covariance technique ascertains the exchange rate of CO2 across the interface between the atmosphere and a plant canopy by measuring the covariance between fluctuations in vertical wind velocity and CO2 mixing ratio. Two decades ago, the method was employed to study CO2 exchange of agricultural crops under ideal conditions during short field campaigns. During the past decade the eddy covariance method has emerged as an important tool for evaluating fluxes of carbon dioxide between terrestrial ecosystems and the atmosphere over the course of a year, and more. At present, the method is being applied in a nearly continuous mode to study carbon dioxide and water vapor exchange at over a hundred and eighty field sites, worldwide. The objective of this review is to assess the eddy covariance method as it is being applied by the global change community on increasingly longer time scales \u2026",
        "year": 2003,
        "authors": "Dennis D Baldocchi"
      }
    ],
    "GsDdaaYAAAAJ": [
      {
        "title": "Noise analysis of regenerative comparators for reconfigurable ADC architectures",
        "abstract": "The need for highly integrable and programmable analog-to-digital converters (ADCs) is pushing towards the use of dynamic regenerative comparators to maximize speed, power efficiency and reconfigurability. Comparator thermal noise is, however, a limiting factor for the achievable resolution of several ADC architectures with scaled supply voltages. While mismatch in these comparators can be compensated for by calibration, noise can irreparably hinder performance and is less straightforward to be accounted for at design time. This paper presents a method to estimate the input referred noise in fully dynamic regenerative comparators leveraging a reference architecture. A time-domain analysis is proposed that accounts for the time varying nature of the circuit exploiting some basic results from the solution of stochastic differential equations. The resulting symbolic expressions allow focusing designers' attention \u2026",
        "year": 2008,
        "authors": "Pierluigi Nuzzo and Fernando De Bernardinis and Pierangelo Terreni and Geert Van der Plas"
      },
      {
        "title": "Secure state estimation for cyber-physical systems under sensor attacks: A satisfiability modulo theory approach",
        "abstract": "Secure state estimation is the problem of estimating the state of a dynamical system from a set of noisy and adversarially corrupted measurements. Intrinsically a combinatorial problem, secure state estimation has been traditionally addressed either by brute force search, suffering from scalability issues, or via convex relaxations, using algorithms that can terminate in polynomial time but are not necessarily sound. In this paper, we present a novel algorithm that uses a satisfiability modulo theory approach to harness the complexity of secure state estimation. We leverage results from formal methods over real numbers to provide guarantees on the soundness and completeness of our algorithm. Moreover, we discuss its scalability properties, by providing upper bounds on the runtime performance. Numerical simulations support our arguments by showing an order of magnitude decrease in execution time with respect to \u2026",
        "year": 2017,
        "authors": "Yasser Shoukry and Pierluigi Nuzzo and Alberto Puggelli and Alberto L Sangiovanni-Vincentelli and Sanjit A Seshia and Paulo Tabuada"
      },
      {
        "title": "An 820\u03bcW 9b 40MS/s noise-tolerant dynamic-SAR ADC in 90nm digital CMOS",
        "abstract": "Current trends in analog/mixed-signal design for battery-powered devices demand the adoption of cheap and power-efficient ADCs. SAR architectures have been recently demonstrated as able to achieve high power efficiency in the moderate-resolution/medium- bandwidth range in Craninckx, J. and Van der Plas, G., (2007). However, when the comparator determines in first instance the overall performance, as in most SAR ADCs, comparator thermal noise can limit the maximum achievable resolution. More than 1 and 2 ENOB reductions are observed in Craninckx, J. and Van der Plas, G., (2007) and Kuttner, F., (2002), respectively, because of thermal noise, and degradations could be even worse with scaled supply voltages and the extensive use of dynamic regenerative latches without pre-amplification. Unlike mismatch, random noise cannot be compensated by calibration and would finally demand a quadratic \u2026",
        "year": 2008,
        "authors": "Vito Giannini and Pierluigi Nuzzo and Vincenzo Chironi and Andrea Baschirotto and Geert Van der Plas and Jan Craninckx"
      }
    ],
    "UGgGMrIAAAAJ": [
      {
        "title": "Model predictive control from signal temporal logic specifications: A case study",
        "abstract": "This paper describes current work on framing the model predictive control (MPC) of cyber-physical systems as synthesis from signal temporal logic (STL) specifications. We provide a case study using a simplified power grid model with uncertain demand and generation; the model-predictive control problem here is that of the ancillary service power flow from the buildings. We show how various relevant constraints can be captured using STL formulas, and incorporated into an MPC framework. We also provide preliminary simulation results to illustrate the promise of the proposed approach.",
        "year": 2014,
        "authors": "Vasumathi Raman and Mehdi Maasoumy and Alexandre Donz\u00e9"
      },
      {
        "title": "Handling model uncertainty in model predictive control for energy efficient buildings",
        "abstract": "Model uncertainty is a significant challenge to more widespread use of model predictive controllers (MPC) for optimizing building energy consumption. This paper presents two methodologies to handle model uncertainty for building MPC. First, we propose a modeling framework for online estimation of states and unknown parameters leading to a parameter-adaptive building (PAB) model. Second, we propose a robust model predictive control (RMPC) formulation to make a building controller robust to model uncertainties. The results from these two approaches are compared with those from a nominal MPC and a common building rule based control (RBC). The results are then used to develop a methodology for selecting a controller type (i.e. RMPC, MPC, or RBC) as a function of building model uncertainty. RMPC is found to be the superior controller for the cases with an intermediate level of model uncertainty (30 \u2026",
        "year": 2014,
        "authors": "Mehdi Maasoumy and M Razmara and Mahdi Shahbakhti and A Sangiovanni Vincentelli"
      },
      {
        "title": "Total and peak energy consumption minimization of building HVAC systems using model predictive control",
        "abstract": "This article addresses the challenge of realizing the building automation and control system using a distributed network of embedded computers. A specification methodology and design space exploration framework are proposed to raise the level of abstraction at which building control systems are designed, to reduce design effort, and to lower implementation cost.",
        "year": 2012,
        "authors": "Mehdi Maasoumy and Alberto Sangiovanni-Vincentelli"
      }
    ],
    "7KnIsvQAAAAJ": [
      {
        "title": "SOCIAL NETWORK ANALYSIS OF INFORMATION FLOW IN AN IPD-PROJECT DESIGN ORGANIZATION",
        "abstract": "Lean Construction recommends concurrent development of product and process by bringing Last Planners into the design phase. While this approach offers opportunities to reduce downstream waste and improve value generation, it increases coordination complexity during design due to the increased number of participants in the design team. In large projects, this increased number of participants can demand a multiteam structure with roles and mechanisms to coordinate the work between teams. In a case study we document the coordination mechanisms of a design organization on a large-scale construction project, being delivered under an Integrated Project Delivery (IPD) type contract, the Integrated Form of Agreement (IFOA). We conduct a Social Network Analysis (SNA) of information flow between people on the project, who work in a big-room environment. Analysis of this IPD-based social network with indices of degree centrality, betweenness centrality, and clustering, yields the following results:(1) the Chief Engineer and leaders of cross-functional teams play key roles in the coordination between teams,(2) people take on coordination jobs, even if it is not part of their formal role, and (3) IPD projects foster cross-functional collaboration. We conclude the paper with managerial recommendations for the efficient and effective coordination of IPD-based design project organizations and ideas for future research.",
        "year": 2013,
        "authors": "Gernot Hickethier and Iris D Tommelein and Baris Lostuvali"
      },
      {
        "title": "USE OF MODULARIZATION IN DESIGN AS A STRATEGY TO REDUCE COMPONENT VARIETY IN ONE-OFF PROJECTS",
        "abstract": "Standardization of work as an essential principle of lean management aims to improve the production process in construction. This paper describes a design strategy which aims to reduce the variety of building components, where this variety affects productivity negatively. The design strategy is based on modularization and standardization. We first review the roots of modularization and standardization, and distinguish the two concepts from each other. Then, we describe the design strategy, which is based on structuring of a building model and defining \u201cmodules\u201d. The modeling strategy is implemented in two interrelated steps:(1) modularization, and (2) standardization.(1) The process of modularization defines' chunks' in the building\u2019s model and the interfaces between them.(2) The process of standardization aligns the structure of the modules to reduce the variety of components. Creation of these standardized modules during design improves application of standardized work and pre-fabrication. We present the described design strategy in two case studies: The first case study presents an example of implementing the design methodology, and the second case study describes the results of the design methodology in reducing the variety of the components. We conclude that modularization improves the potential for standardization in one-off projects, but it should be applied (1) early in design and (2) in an integrated team to identify customer value trade-offs.",
        "year": 2013,
        "authors": "Ahlam Mohamad and Gernot Hickethier and Volkmar Hovestadt and Fritz Gehbauer"
      },
      {
        "title": "Reducing rework in design by comparing structural complexity using a Multi Domain Matrix",
        "abstract": "Complexity in design causes iteration which can be value-adding or wasteful. Wasteful iteration, called rework, may stem from inefficient information flow in design. This paper focuses on the structural complexity of information flow, and on the identification of root causes of the resulting rework. We propose that one can identify root causes for rework in the design phase of a project by (1) making actual information flow transparent and by (2) comparing actual information flow to planned information flow. After identifying misalignments between actual-and planned information flow, one can find their root causes, and then address those causes in order to reduce rework in design. We use a Multi Domain Matrix to deduce actual (\u2018As is\u2019) and planned (\u2018Should\u2019) information flow and then apply the Delta-Design Structure Matrix to compare the structures of the \u2018Should-\u2019with the \u2018As is\u2019 perspective. The proposed hypotheses,\u201cComparing structural complexity between the \u2018Should-\u2019and the \u2018As is\u2019 perspective helps to identify misalignments\u201d and \u201cReduction of misalignments between actualand planned information flow reduces rework in design\u201d were tested during the detailed design phase of a project. The Multi Domain Matrix and Design Structure Matrix were successfully applied: comparison of structural complexity aided in making actual information flow transparent and in reducing rework.",
        "year": 2012,
        "authors": "Gernot Hickethier and Iris D Tommelein and Fritz Gehbauer"
      }
    ],
    "i3-ENjQAAAAJ": [
      {
        "title": "Immune genes are primed for robust transcription by proximal long noncoding RNAs located in nuclear compartments",
        "abstract": "Accumulation of trimethylation of histone H3 at lysine 4 (H3K4me3) on immune-related gene promoters underlies robust transcription during trained immunity. However, the molecular basis for this remains unknown. Here we show three-dimensional chromatin topology enables immune genes to engage in chromosomal contacts with a subset of long noncoding RNAs (lncRNAs) we have defined as immune gene\u2013priming lncRNAs (IPLs). We show that the prototypical IPL, UMLILO, acts in cis to direct the WD repeat-containing protein 5 (WDR5)\u2013mixed lineage leukemia protein 1 (MLL1) complex across the chemokine promoters, facilitating their H3K4me3 epigenetic priming. This mechanism is shared amongst several trained immune genes. Training mediated by \u03b2-glucan epigenetically reprograms immune genes by upregulating IPLs in manner dependent on nuclear factor of activated T cells. The murine \u2026",
        "year": 2019,
        "authors": "Stephanie Fanucchi and Ezio T Fok and Emiliano Dalla and Youtaro Shibayama and Kathleen B\u00f6rner and Erin Y Chang and Stoyan Stoychev and Maxim Imakaev and Dirk Grimm and Kevin C Wang and Guoliang Li and Wing-Kin Sung and Musa M Mhlanga"
      },
      {
        "title": "The antifibrotic adipose-derived stromal cell: Grafted fat enriched with CD74+ adipose-derived stromal cells reduces chronic radiation-induced skin fibrosis",
        "abstract": "Fat grafting can reduce radiation-induced fibrosis. Improved outcomes are found when fat grafts are enriched with adipose-derived stromal cells (ASCs), implicating ASCs as key drivers of soft tissue regeneration. We have identified a subpopulation of ASCs positive for CD74 with enhanced antifibrotic effects. Compared to CD74\u2212 and unsorted (US) ASCs, CD74+ ASCs have increased expression of hepatocyte growth factor, fibroblast growth factor 2, and transforming growth factor \u03b23 (TGF-\u03b23) and decreased levels of TGF-\u03b21. Dermal fibroblasts incubated with conditioned media from CD74+ ASCs produced less collagen upon stimulation, compared to fibroblasts incubated with media from CD74\u2212 or US ASCs. Upon transplantation, fat grafts enriched with CD74+ ASCs reduced the stiffness, dermal thickness, and collagen content of overlying skin, and decreased the relative proportions of more fibrotic dermal \u2026",
        "year": 2020,
        "authors": "Mimi R Borrelli and Ronak A Patel and Sandeep Adem and Nestor M Diaz Deleon and Abra H Shen and Jan Sokol and Sara Yen and Erin Y Chang and Rahim Nazerali and Dung Nguyen and Arash Momeni and Kevin C Wang and Michael T Longaker and Derrick C Wan"
      },
      {
        "title": "Honey bee Royalactin unlocks conserved pluripotency pathway in mammals",
        "abstract": "Royal jelly is the queen-maker for the honey bee Apis mellifera, and has cross-species effects on longevity, fertility, and regeneration in mammals. Despite this knowledge, how royal jelly or its components exert their myriad effects has remained poorly understood. Using mouse embryonic stem cells as a platform, here we report that through its major protein component Royalactin, royal jelly can maintain pluripotency by activating a ground-state pluripotency-like gene network. We further identify Regina, a mammalian structural analog of Royalactin that also induces a naive-like state in mouse embryonic stem cells. This reveals an important innate program for stem cell self-renewal with broad implications in understanding the molecular regulation of stem cell fate across species.",
        "year": 2018,
        "authors": "Derrick C Wan and Stefanie L Morgan and Andrew L Spencley and Natasha Mariano and Erin Y Chang and Gautam Shankar and Yunhai Luo and Ted H Li and Dana Huh and Star K Huynh and Jasmine M Garcia and Cole M Dovey and Jennifer Lumb and Ling Liu and Katharine V Brown and Abel Bermudez and Richard Luong and Hong Zeng and Victoria L Mascetti and Sharon J Pitteri and Jordon Wang and Hua Tu and Marco Quarta and Vittorio Sebastiano and Roel Nusse and Thomas A Rando and Jan E Carette and J Fernando Bazan and Kevin C Wang"
      }
    ],
    "sEAoh3MAAAAJ": [
      {
        "title": "Photonic networks-on-chip for future generations of chip multiprocessors",
        "abstract": "The design and performance of next-generation chip multiprocessors (CMPs) will be bound by the limited amount of power that can be dissipated on a single die. We present photonic networks-on-chip (NoC) as a solution to reduce the impact of intra-chip and off-chip communication on the overall power budget. A photonic interconnection network can deliver higher bandwidth and lower latencies with significantly lower power dissipation. We explain why on-chip photonic communication has recently become a feasible opportunity and explore the challenges that need to be addressed to realize its implementation. We introduce a novel hybrid micro-architecture for NoCs combining a broadband photonic circuit-switched network with an electronic overlay packet-switched control network. We address the critical design issues including: topology, routing algorithms, deadlock avoidance, and path-setup/tear-down \u2026",
        "year": 2008,
        "authors": "Assaf Shacham and Keren Bergman and Luca P Carloni"
      },
      {
        "title": "Theory of latency-insensitive design",
        "abstract": "The theory of latency-insensitive design is presented as the foundation of a new correct-by-construction methodology to design complex systems by assembling intellectual property components. Latency-insensitive designs are synchronous distributed systems and are realized by composing functional modules that exchange data on communication channels according to an appropriate protocol. The protocol works on the assumption that the modules are stallable, a weak condition to ask them to obey. The goal of the protocol is to guarantee that latency-insensitive designs composed of functionally correct modules behave correctly independently of the channel latencies. This allows us to increase the robustness of a design implementation because any delay variations of a channel can be \"recovered\" by changing the channel latency while the overall system functionality remains unaffected. As a consequence, an \u2026",
        "year": 2002,
        "authors": "Luca P Carloni and Kenneth L McMillan and Alberto L Sangiovanni-Vincentelli"
      },
      {
        "title": "On the design of a photonic network-on-chip",
        "abstract": "Recent remarkable advances in nanoscale silicon-photonic integrated circuitry specifically compatible with CMOS fabrication have generated new opportunities for leveraging the unique capabilities of optical technologies in the on-chip communications infrastructure. Based on these nano-photonic building blocks, we consider a photonic network-on-chip architecture designed to exploit the enormous transmission bandwidths, low latencies, and low power dissipation enabled by data exchange in the optical domain. The novel architectural approach employs a broadband photonic circuit-switched network driven in a distributed fashion by an electronic overlay control network which is also used for independent exchange of short messages. We address the critical network design issues for insertion in chip multiprocessors (CMP) applications, including topology, routing algorithms, path-setup and tear-down \u2026",
        "year": 2007,
        "authors": "Assaf Shacham and Keren Bergman and Luca P Carloni"
      }
    ],
    "o2cUkz4AAAAJ": [
      {
        "title": "VIS: A system for verification and synthesis",
        "abstract": "VIS (Verification Interacting with Synthesis) is a tool that integrates the verification, simulation, and synthesis of finite-state hardware systems. It uses a Verilog front end and supports fair CTL model checking, language emptiness checking, combinational and sequential equivalence checking, cycle-based simulation, and hierarchical synthesis. We designed VIS to maximize performance by using state-of-the-art algorithms, and to provide a solid platform for future research in formal verification. VIS improves upon existing verification tools by:1. providing a better programming environment, 2. providing new capabilities, mad 3.~ mproving performance.",
        "year": 1996,
        "authors": "Robert K Brayton and Gary D Hachtel and Alberto Sangiovanni-Vincentelli and Fabio Somenzi and Adnan Aziz and Szu -Tsung Cheng and Stephen Edwards and Sunil Khatri and Yuji Kukimoto and Abelardo Pardo and Shaz Qadeer and Rajeev K Ranjan and Shaker Sarwary and Thomas R Staple and Gitanjali Swamy and Tiziano Villa"
      },
      {
        "title": "NOVA: State assignment of finite state machines for optimal two-level logic implementations",
        "abstract": "The problem of encoding the states of a synchronous Finite State Machine (FSM), so that the area of a two-level implementation of the combinational logic is minimized, is addressed. As in previous approaches, the problem is reduced to the solution of the combinatorial optimization problems defined by the translation of the cover obtained by a multiple-valued logic minimization or by a symbolic minimization into a compatible Boolean representation. In this paper we present algorithms for their solution, based on a new theoretical framework that offers advantages over previous approaches to develop effective heuristics. The algorithms are part of NOVA, a program for optimal encoding of control logic. Final areas averaging 20% less than other state assignment programs and 30% less than the best random solutions have been obtained. Literal counts averaging 30% less than the best random solutions have been \u2026",
        "year": 1989,
        "authors": "Tiziano Villa and Alberto Sangiovanni-Vincentelli"
      },
      {
        "title": "Multi-valued decision diagrams: theory and applications",
        "abstract": "Multi-valued decision diagrams : Theory and Applications | CiNii Research CiNii \u56fd\u7acb\u60c5\u5831\u5b66\n\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u8a73\u7d30\u3078\u79fb\u52d5 \u691c\u7d22\u30d5\u30a9\u30fc\u30e0\u3078\u79fb\u52d5 \u8ad6\u6587\u30fb\u30c7\u30fc\u30bf\u3092\u3055\u304c\u3059 \u5927\u5b66\n\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 English \u691c\u7d22 \u30bf\u30a4\u30c8\u30eb \u4eba\u7269/\u56e3\u4f53\u540d \u6240\u5c5e\u6a5f\u95a2 ISSN DOI \n\u671f\u9593 ~ \u672c\u6587\u30ea\u30f3\u30af \u672c\u6587\u30ea\u30f3\u30af\u3042\u308a \u30c7\u30fc\u30bf\u30bd\u30fc\u30b9 JaLC IRDB Crossref DataCite NDL\u30b5\u30fc\u30c1 NDL\u30c7\u30b8\u30b3\u30ec\n(\u65e7NII-ELS) RUDA JDCat NINJAL CiNii Articles CiNii Books DBpedia Nikkei BP KAKEN \nIntegbio MDR PubMed LSDB Archive \u6975\u5730\u7814ADS \u6975\u5730\u7814\u5b66\u8853DB OpenAIRE \u516c\u5171\u30c7\u30fc\u30bf\u30ab\u30bf\u30ed\u30b0 \n\u30e0\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8\u578b\u7814\u7a76\u958b\u767a\u4e8b\u696d \u3059\u3079\u3066 \u7814\u7a76\u30c7\u30fc\u30bf \u8ad6\u6587 \u672c \u535a\u58eb\u8ad6\u6587 \u30d7\u30ed\u30b8\u30a7\u30af\u30c8 [2024\u5e7412\u67089\u65e5\n\u66f4\u65b0]CiNii Dissertations\u53ca\u3073CiNii Books\u306eCiNii Research\u3078\u306e\u7d71\u5408\u306b\u3064\u3044\u3066 CiNii Research\u81ea\u52d5\n\u7ffb\u8a33\u6a5f\u80fd(\u8a66\u884c\u7248)\u3092CiNii Labs\u306b\u3066\u516c\u958b\u3057\u307e\u3057\u305f \u65e5\u7d4cBP\u793e\u63d0\u4f9b\u30c7\u30fc\u30bf\u306e\u66f4\u65b0\u505c\u6b62\u53ca\u3073\u524a\u9664\n\u306b\u3064\u3044\u3066 \u300c\u7814\u7a76\u30c7\u30fc\u30bf\u300d\u300c\u6839\u62e0\u30c7\u30fc\u30bf\u300d\u306e\u53ce\u9332\u306b\u3064\u3044\u3066 Multi-valued decision diagrams : Theory and \u2026",
        "year": 1998,
        "authors": "Timothy Kam and Tiziano Villa and Robert Brayton and Alberto Sangiovanni-Vincentelli"
      }
    ],
    "oz19xXsAAAAJ": [
      {
        "title": "Iron oxide nanoparticles inhibit tumour growth by inducing pro-inflammatory macrophage polarization in tumour tissues",
        "abstract": "Until now, the Food and Drug Administration (FDA)-approved iron supplement ferumoxytol and other iron oxide nanoparticles have been used for treating iron deficiency, as contrast agents for magnetic resonance imaging and as drug carriers. Here, we show an intrinsic therapeutic effect of ferumoxytol on the growth of early mammary cancers, and lung cancer metastases in liver and lungs. In vitro, adenocarcinoma cells co-incubated with ferumoxytol and macrophages showed increased caspase-3 activity. Macrophages exposed to ferumoxytol displayed increased mRNA associated with pro-inflammatory Th1-type responses. In vivo, ferumoxytol significantly inhibited growth of subcutaneous adenocarcinomas in mice. In addition, intravenous ferumoxytol treatment before intravenous tumour cell challenge prevented development of liver metastasis. Fluorescence-activated cell sorting (FACS) and histopathology \u2026",
        "year": 2016,
        "authors": "Saeid Zanganeh and Gregor Hutter and Ryan Spitler and Olga Lenkov and Morteza Mahmoudi and Aubie Shaw and Jukka Sakari Pajarinen and Hossein Nejadnik and Stuart Goodman and Michael Moseley and Lisa Marie Coussens and Heike Elisabeth Daldrup-Link"
      },
      {
        "title": "Glioblastoma multiforme (GBM): An overview of current therapies and mechanisms of resistance",
        "abstract": "Glioblastoma multiforme (GBM) is a WHO grade IV glioma and the most common malignant, primary brain tumor with a 5-year survival of 7.2%. Its highly infiltrative nature, genetic heterogeneity, and protection by the blood brain barrier (BBB) have posed great treatment challenges. The standard treatment for GBMs is surgical resection followed by chemoradiotherapy. The robust DNA repair and self-renewing capabilities of glioblastoma cells and glioma initiating cells (GICs), respectively, promote resistance against all current treatment modalities. Thus, durable GBM management will require the invention of innovative treatment strategies. In this review, we will describe biological and molecular targets for GBM therapy, the current status of pharmacologic therapy, prominent mechanisms of resistance, and new treatment approaches. To date, medical imaging is primarily used to determine the location, size and \u2026",
        "year": 2021,
        "authors": "Wei Wu and Jessica L Klockow and Michael Zhang and Famyrah Lafortune and Edwin Chang and Linchun Jin and Yang Wu and Heike E Daldrup-Link"
      },
      {
        "title": "Whole-body MR imaging for detection of bone metastases in children and young adults: comparison with skeletal scintigraphy and FDG PET",
        "abstract": "OBJECTIVE. The purpose of this study was to compare the diagnostic  accuracy of whole-body MR imaging, skeletal scintigraphy, and  18F-fluorodeoxyglucose (FDG) positron emission tomography (PET) for the  detection of bone metastases in children.SUBJECTS AND METHODS. Thirty-nine children and young adults who were  2-19 years old and who had Ewing's sarcoma, osteosarcoma, lymphoma,  rhabdomyosarcoma, melanoma, and Langerhans' cell histiocytosis underwent  whole-body spin-echo MR imaging, skeletal scintigraphy, and FDG PET for the  initial staging of bone marrow metastases. The number and location of bone and  bone marrow lesions diagnosed with each imaging modality were correlated with  biopsy and clinical follow-up as the standard of reference.RESULTS. Twenty-one patients exhibited 51 bone metastases.  Sensitivities for the detection of bone metastases were 90% for FDG \u2026",
        "year": 2001,
        "authors": "Heike E Daldrup-Link and Christiane Franzius and Thomas M Link and Daniela Laukamp and Joachim Sciuk and Heribert Ju\u0308rgens and Otmar Schober and Ernst J Rummeny"
      }
    ],
    "4arkOLcAAAAJ": [
      {
        "title": "Real-time obstacle avoidance for manipulators and mobile robots",
        "abstract": "This paper presents a unique real-time obstacle avoidance approach for manipulators and mobile robots based on the artificial potential field concept. Collision avoidance, tradi tionally considered a high level planning problem, can be effectively distributed between different levels of control, al lowing real-time robot operations in a complex environment. This method has been extended to moving obstacles by using a time-varying artificial patential field. We have applied this obstacle avoidance scheme to robot arm mechanisms and have used a new approach to the general problem of real-time manipulator control. We reformulated the manipulator con trol problem as direct control of manipulator motion in oper ational space\u2014the space in which the task is originally described\u2014rather than as control of the task's corresponding joint space motion obtained only after geometric and kine matic transformation. Outside \u2026",
        "year": 1986,
        "authors": "Oussama Khatib"
      },
      {
        "title": "Springer handbook of robotics",
        "abstract": "The second edition of this handbook provides a state-of-the-art overview on the various aspects in the rapidly developing field of robotics. Reaching for the human frontier, robotics is vigorously engaged in the growing challenges of new emerging domains. Interacting, exploring, and working with humans, the new generation of robots will increasingly touch people and their lives. The credible prospect of practical robots among humans is the result of the scientific endeavour of a half a century of robotic developments that established robotics as a modern scientific discipline. The ongoing vibrant expansion and strong growth of the field during the last decade has fueled this second edition of the Springer Handbook of Robotics.The first edition of the handbook soon became a landmark in robotics publishing and won the American Association of Publishers PROSE Award for Excellence in Physical Sciences & \u2026",
        "year": 2008,
        "authors": "Bruno Siciliano and Oussama Khatib and Torsten Kr\u00f6ger"
      },
      {
        "title": "A unified approach for motion and force control of robot manipulators: The operational space formulation",
        "abstract": "A framework for the analysis and control of manipulator systems with respect to the dynamic behavior of their end-effectors is developed. First, issues related to the description of end-effector tasks that involve constrained motion and active force control are discussed. The fundamentals of the operational space formulation are then presented, and the unified approach for motion and force control is developed. The extension of this formulation to redundant manipulator systems is also presented, constructing the end-effector equations of motion and describing their behavior with respect to joint forces. These results are used in the development of a new and systematic approach for dealing with the problems arising at kinematic singularities. At a singular configuration, the manipulator is treated as a mechanism that is redundant with respect to the motion of the end-effector in the subspace of operational space \u2026",
        "year": 2003,
        "authors": "Oussama Khatib"
      }
    ],
    "MtBYJ7MAAAAJ": [
      {
        "title": "Customer-base concentration: Implications for firm performance and capital markets: 2011 American accounting association competitive manuscript award winner",
        "abstract": "This study investigates whether and how customer-base concentration affects supplier firm fundamentals and stock market valuation. I compile a comprehensive sample of supply chain relationships and develop a measure (CC) to capture the extent to which a supplier's customer base is concentrated. In contrast to the conventional view of customer-base concentration as an impediment to supplier firm performance, I document a positive contemporaneous association between CC and accounting rates of return, suggesting that efficiencies accrue to suppliers with concentrated customer bases. Consistent with a cause-and-effect link between customer-base concentration and supplier firm performance, analysis of intertemporal changes demonstrates that CC increases predict efficiency gains in the form of reduced operating expenses per dollar of sales and enhanced asset utilization. Using stock returns tests, I \u2026",
        "year": 2012,
        "authors": "Panos N Patatoukas"
      },
      {
        "title": "Accounting earnings and gross domestic product",
        "abstract": "We document that aggregate accounting earnings growth is an incrementally significant leading indicator of growth in nominal Gross Domestic Product (GDP). Professional macro forecasters, however, do not fully incorporate the predictive content embedded in publicly available accounting earnings data. As a result, future nominal GDP growth forecast errors are predictable based on accounting earnings data that are available to professional macro forecasters in real time.",
        "year": 2014,
        "authors": "Yaniv Konchitchki and Panos N Patatoukas"
      },
      {
        "title": "More evidence of bias in the differential timeliness measure of conditional conservatism",
        "abstract": "Despite the conceptual appeal and popularity of the differential timeliness (DT) measure of conditional conservatism proposed in Basu (1997), Dietrich et al.(2007) and Givoly et al.(2007) have identified considerable biases associated with that measure. We renew their call to avoid using the DT measure because it is affected unexpectedly by two empirical regularities\u2014namely, scale is negatively related to (1) deflated mean earnings and (2) variance of stock returns. Even though these regularities are unrelated to conditional conservatism, their joint effect is substantial and pervasive. More importantly, prior findings regarding time-series and cross-sectional variation in differential timeliness are confounded by corresponding variation in these regularities.",
        "year": 2011,
        "authors": "Panos N Patatoukas and Jacob K Thomas"
      }
    ],
    "-2OhI8YAAAAJ": [
      {
        "title": "Low trap-state density and long carrier diffusion in organolead trihalide perovskite single crystals",
        "abstract": "The fundamental properties and ultimate performance limits of organolead trihalide MAPbX3 (MA = CH3NH3+; X = Br\u2013 or I\u2013) perovskites remain obscured by extensive disorder in polycrystalline MAPbX3 films. We report an antisolvent vapor-assisted crystallization approach that enables us to create sizable crack-free MAPbX3 single crystals with volumes exceeding 100 cubic millimeters. These large single crystals enabled a detailed characterization of their optical and charge transport characteristics. We observed exceptionally low trap-state densities on the order of 109 to 1010 per cubic centimeter in MAPbX3 single crystals (comparable to the best photovoltaic-quality silicon) and charge carrier diffusion lengths exceeding 10 micrometers. These results were validated with density functional theory calculations.",
        "year": 2015,
        "authors": "Dong Shi and Valerio Adinolfi and Riccardo Comin and Mingjian Yuan and Erkki Alarousu and Andrei Buin and Yin Chen and Sjoerd Hoogland and Alexander Rothenberger and Khabiboulakh Katsiev and Yaroslav Losovyj and Xin Zhang and Peter A Dowben and Omar F Mohammed and Edward H Sargent and Osman M Bakr"
      },
      {
        "title": "Perovskite light-emitting diodes with external quantum efficiency exceeding 20 per cent",
        "abstract": "Metal halide perovskite materials are an emerging class of solution-processable semiconductors with considerable potential for use in optoelectronic devices, \u2013. For example, light-emitting diodes (LEDs) based on these materials could see application in flat-panel displays and solid-state lighting, owing to their potential to be made at low cost via facile solution processing, and could provide tunable colours and narrow emission line widths at high photoluminescence quantum yields, , , \u2013. However, the highest reported external quantum efficiencies of green- and red-light-emitting perovskite LEDs are around 14 per cent, and 12 per cent, respectively\u2014still well behind the performance of organic LEDs, \u2013 and inorganic quantum dot LEDs. Here we describe visible-light-emitting perovskite LEDs that surpass the quantum efficiency milestone of 20 per cent. This achievement stems from a new strategy for managing the \u2026",
        "year": 2018,
        "authors": "Kebin Lin and Jun Xing and Li Na Quan and F Pelayo Garc\u00eda de Arquer and Xiwen Gong and Jianxun Lu and Liqiang Xie and Weijie Zhao and Di Zhang and Chuanzhong Yan and Wenqiang Li and Xinyi Liu and Yan Lu and Jeffrey Kirman and Edward H Sargent and Qihua Xiong and Zhanhua Wei"
      },
      {
        "title": "What would it take for renewably powered electrosynthesis to displace petrochemical processes?",
        "abstract": "As the world continues to transition toward carbon emissions\u2013free energy technologies, there remains a need to also reduce the carbon emissions of the chemical production industry. Today many of the world\u2019s chemicals are produced from fossil fuel\u2013derived feedstocks. Electrochemical conversion of carbon dioxide (CO2) into chemical feedstocks offers a way to turn waste emissions into valuable products, closing the carbon loop. When coupled to renewable sources of electricity, these products can be made with a net negative carbon emissions footprint, helping to sequester CO2 into usable goods. Research and development into electrocatalytic materials for CO2 reduction has intensified in recent years, with advances in selectivity, efficiency, and reaction rate progressing toward practical implementation. A variety of chemical products can be made from CO2, such as alcohols, oxygenates \u2026",
        "year": 2019,
        "authors": "Phil De Luna and Christopher Hahn and Drew Higgins and Shaffiq A Jaffer and Thomas F Jaramillo and Edward H Sargent"
      }
    ],
    "Ya8eTsYAAAAJ": [
      {
        "title": "Narrow and brittle or broad and nimble? Comparing adaptive capacity in simplifying and diversifying farming systems",
        "abstract": "Humanity faces a triple threat of climate change, biodiversity loss, and global food insecurity. In response, increasing the general adaptive capacity of farming systems is essential. We identify two divergent strategies for building adaptive capacity. Simplifying processes seek to narrowly maximize production by shifting the basis of agricultural production toward centralized control of socially and ecologically homogenized systems. Diversifying processes cultivate social-ecological complexity in order to provide multiple ecosystem services, maintain management flexibility, and promote coordinated adaptation across levels. Through five primarily United States focused cases of distinct agricultural challenges\u2014foodborne pathogens, drought, marginal lands, labor availability, and land access and tenure\u2014we compare simplifying and diversifying responses to assess how these pathways differentially enhance or degrade the adaptive capacity of farming systems in the context of the triple threat. These cases show that diversifying processes can weave a form of broad and nimble adaptive capacity that is fundamentally distinct from the narrow and brittle adaptive capacity produced through simplification. We find that while there are structural limitations and tradeoffs to diversifying processes, adaptive capacity can be facilitated by empowering people and enhancing ecosystem functionality to proactively distribute resources and knowledge where needed and to nimbly respond to changing circumstances. Our cases suggest that, in order to garner the most adaptive benefits from diversification, farming systems should balance the pursuit of multiple goals \u2026",
        "year": 2021,
        "authors": "Margiana Petersen-Rockney and Patrick Baur and Aidee Guzman and S Franz Bender and Adam Calo and Federico Castillo and Kathryn De Master and Antoinette Dumont and Kenzo Esquivel and Claire Kremen and James LaChance and Maria Mooshammer and Joanna Ory and Mindy J Price and Yvonne Socolar and Paige Stanley and Alastair Iles and Timothy Bowles"
      },
      {
        "title": "When farmers are pulled in too many directions: comparing institutional drivers of food safety and environmental sustainability in California agriculture",
        "abstract": "Aspirations to farm \u2018better\u2019 may fall short in practice due to constraints outside of farmers\u2019 control. Yet farmers face proliferating pressures to adopt practices that align with various societal visions of better agriculture. What happens when the accumulation of external pressures overwhelms farm management capacity? Or, worse, when different visions of better agriculture pull farmers toward conflicting management paradigms? This article addresses these questions by comparing the institutional manifestations of two distinct societal obligations placed on California fruit and vegetable farmers: to practice sustainable agriculture and to ensure food safety. Drawing on the concept of constrained choice, I define and utilize a framework for comparison comprising five types of institutions that shape farm management decisions: rules and standards, market and supply chain forces, legal liability, social networks and norms \u2026",
        "year": 2020,
        "authors": "Patrick Baur"
      },
      {
        "title": "The unintended ecological and social impacts of food safety regulations in California's Central Coast region",
        "abstract": "In 2006, a multistate Escherichia coli O157:H7 outbreak linked to spinach grown in California's Central Coast region caused public concerns, catalyzing far-reaching reforms in vegetable production. Industry and government pressured growers to adopt costly new measures to improve food safety, many of which targeted wildlife as a disease vector. In response, many growers fenced fields, lined field edges with wildlife traps and poison, and removed remaining adjacent habitat. Although the efficacy of these and other practices for mitigating pathogen risk have not been thoroughly evaluated, their widespread adoption has substantial consequences for rural livelihoods, biodiversity, and ecological processes. Today, as federal regulators are poised to set mandatory standards for on-farm food safety throughout the United States, major gaps persist in understanding the relationships between farming systems and \u2026",
        "year": 2015,
        "authors": "Daniel S Karp and Patrick Baur and Edward R Atwill and Kathryn De Master and Sasha Gennet and Alastair Iles and Joanna L Nelson and Amber R Sciligo and Claire Kremen"
      }
    ],
    "Ah0UP2kAAAAJ": [
      {
        "title": "Material waste in building industry: main causes and prevention",
        "abstract": "Material waste has been recognized as a major problem in the construction industry that has important implications both for the efficiency industry and for the environmental impact of construction projects. Moreover, waste measurement plays an important role in the management of production systems since it is an effective way to assess their performance, allowing areas of potential improvement to be pointed out. This paper describes the main results of two research studies carried out in Brazil that investigated the occurrence of material waste at 74 building sites located in different regions of that country. Some typical figures for the waste of some key construction materials are provided, and the main causes of waste in the sector are discussed. The results indicate that the waste of materials in the Brazilian building industry is fairly high and that a large variability in waste incidence is found across different projects \u2026",
        "year": 2002,
        "authors": "Carlos T Formoso and Lucio Soibelman and Claudia De Cesare and Eduardo L Isatto"
      },
      {
        "title": "Method for waste control in the building industry",
        "abstract": "The paper presents the preliminary results of an ongoing research project which aims to develop a method for controlling waste on building sites. The main focus of the method is to establish waste control procedures as part of site management on a routine basis, using a pull learning approach and emphasising the principle of process transparency by using qualitative and quantitative data collection techniques. The study also intends to make some contributions for the consolidation of the Lean Construction theory, through the application of some of its principles in practice.",
        "year": 1999,
        "authors": "Carlos Torres Formoso and Eduardo Lu\u00eds Isatto and Ercilia Hitomi Hirota"
      },
      {
        "title": "Site logistics planning and control for engineer-to-order prefabricated building systems using BIM 4D modeling",
        "abstract": "There has been a growing demand for engineer-to-order (ETO) prefabricated building systems, in which a unique product must fulfill the requirements of specific clients. Although industrialized building systems can potentially simplify the production process, there is usually a high level of complexity in ETO production systems, such as uncertainty in client demands, short lead-time, overlapping between project stages, and resources that are shared among different projects. In this context, logistics management plays a key role in terms of achieving project goals related to cost, time and safety. This research work proposes the combined use of principles from the Lean Production Philosophy and Building Information Modeling (BIM), as a mechanism to cope with the complexity involved in those types of projects. Although these can be regarded as two separate approaches for improving the performance of production \u2026",
        "year": 2019,
        "authors": "Rafaela Bortolini and Carlos Torres Formoso and Daniela D Viana"
      }
    ],
    "GP64q_kAAAAJ": [
      {
        "title": "Digital integrated circuits",
        "abstract": "\u201cLa densit\u00e0 di componenti \u00e8 raddoppiata ogni anno. Sicuramente, a breve termine ci si pu\u00f2 attendere che questo ritmo continui, o addirittura acceleri. Nel lungo periodo, la velocit\u00e0 \u00e8 meno prevedibile, sebbene non vi sia alcuna ragione per credere che questo ritmo non debba rimanere circa costante per almeno dieci anni. Ci\u00f2 significa che nel 1975, il numero di componenti per circuito integrato sar\u00e0 65.000\u201d",
        "year": 2002,
        "authors": "Jan M Rabaey and Anantha Chandrakasan and Borivoje Nikolic"
      },
      {
        "title": "A study of low level vibrations as a power source for wireless sensor nodes",
        "abstract": "Advances in low power VLSI design, along with the potentially low duty cycle of wireless sensor nodes open up the possibility of powering small wireless computing devices from scavenged ambient power. A broad review of potential power scavenging technologies and conventional energy sources is first presented. Low-level vibrations occurring in common household and office environments as a potential power source are studied in depth. The goal of this paper is not to suggest that the conversion of vibrations is the best or most versatile method to scavenge ambient power, but to study its potential as a viable power source for applications where vibrations are present. Different conversion mechanisms are investigated and evaluated leading to specific optimized designs for both capacitive MicroElectroMechancial Systems (MEMS) and piezoelectric converters. Simulations show that the potential power density \u2026",
        "year": 2003,
        "authors": "Shad Roundy and Paul K Wright and Jan Rabaey"
      },
      {
        "title": "Energy aware routing for low energy ad hoc sensor networks",
        "abstract": "The recent interest in sensor networks has led to a number of routing schemes that use the limited resources available at sensor nodes more efficiently. These schemes typically try to find the minimum energy path to optimize energy usage at a node. In this paper we take the view that always using lowest energy paths may not be optimal from the point of view of network lifetime and long-term connectivity. To optimize these measures, we propose a new scheme called energy aware routing that uses sub-optimal paths occasionally to provide substantial gains. Simulation results are also presented that show increase in network lifetimes of up to 40% over comparable schemes like directed diffusion routing. Nodes also burn energy in a more equitable way across the network ensuring a more graceful degradation of service with time.",
        "year": 2002,
        "authors": "Rahul C Shah and Jan M Rabaey"
      }
    ],
    "aCb48bUAAAAJ": [
      {
        "title": "International accounting standards and accounting quality",
        "abstract": "We examine whether application of International Accounting Standards (IAS) is associated with higher accounting quality. The application of IAS reflects combined effects of features of the financial reporting system, including standards, their interpretation, enforcement, and litigation. We find that firms applying IAS from 21 countries generally evidence less earnings management, more timely loss recognition, and more value relevance of accounting amounts than do matched sample firms applying non\u2010U.S. domestic standards. Differences in accounting quality between the two groups of firms in the period before the IAS firms adopt IAS do not account for the postadoption differences. Firms applying IAS generally evidence an improvement in accounting quality between the pre\u2010 and postadoption periods. Although we cannot be sure our findings are attributable to the change in the financial reporting system rather \u2026",
        "year": 2008,
        "authors": "Mary E Barth and Wayne R Landsman and Mark H Lang"
      },
      {
        "title": "The relevance of the value relevance literature for financial accounting standard setting: another view",
        "abstract": "This paper explains that value relevance research assesses how well accounting amounts reflect information used by equity investors, and provides insights into questions of interest to standard setters. A primary focus of financial statements is equity investment. Other uses of financial statement information, such as contracting, do not diminish the importance of value relevance research. Value relevance questions can be addressed using extant valuation models. Value relevance studies address econometric issues that otherwise could limit inferences, and can accommodate and be used to study the implications of accounting conservatism.",
        "year": 2001,
        "authors": "Mary E Barth and William H Beaver and Wayne R Landsman"
      },
      {
        "title": "Relative valuation roles of equity book value and net income as a function of financial health",
        "abstract": "This study tests predictions that pricing multiples on and incremental explanatory power of equity book value (net income) increase (decrease) as financial health decreases. Tests using a sample of 396 bankrupt firms and tests using a larger, pooled sample both yield inferences consistent with predictions. Findings are robust to inclusion of controls for industry, size, return-on-equity, and volatility of equity returns. Equity book value and net income multiples and incremental explanatory power vary predictably across three illustrative industries, selected based on the likely extent of unrecognized intangible assets.",
        "year": 1998,
        "authors": "Mary E Barth and William H Beaver and Wayne R Landsman"
      }
    ],
    "Mw84b5sAAAAJ": [
      {
        "title": "CTFS\u2010Forest GEO: a worldwide network monitoring forests in an era of global change",
        "abstract": "Global change is impacting forests worldwide, threatening biodiversity and ecosystem services including climate regulation. Understanding how forests respond is critical to forest conservation and climate protection. This review describes an international network of 59 long\u2010term forest dynamics research sites (CTFS\u2010ForestGEO) useful for characterizing forest responses to global change. Within very large plots (median size 25 ha), all stems \u22651 cm diameter are identified to species, mapped, and regularly recensused according to standardized protocols. CTFS\u2010ForestGEO spans 25\u00b0S\u201361\u00b0N latitude, is generally representative of the range of bioclimatic, edaphic, and topographic conditions experienced by forests worldwide, and is the only forest monitoring network that applies a standardized protocol to each of the world's major forest biomes. Supplementary standardized measurements at subsets of the sites \u2026",
        "year": 2015,
        "authors": "Kristina J Anderson\u2010Teixeira and Stuart J Davies and Amy C Bennett and Erika B Gonzalez\u2010Akre and Helene C Muller\u2010Landau and S Joseph Wright and Kamariah Abu Salim and Ang\u00e9lica M Almeyda Zambrano and Alfonso Alonso and Jennifer L Baltzer and Yves Basset and Norman A Bourg and Eben N Broadbent and Warren Y Brockelman and Sarayudh Bunyavejchewin and David FRP Burslem and Nathalie Butt and Min Cao and Dairon Cardenas and George B Chuyong and Keith Clay and Susan Cordell and Handanakere S Dattaraja and Xiaobao Deng and Matteo Detto and Xiaojun Du and Alvaro Duque and David L Erikson and Corneille EN Ewango and Gunter A Fischer and Christine Fletcher and Robin B Foster and Christian P Giardina and Gregory S Gilbert and Nimal Gunatilleke and Savitri Gunatilleke and Zhanqing Hao and William W Hargrove and Terese B Hart and Billy CH Hau and Fangliang He and Forrest M Hoffman and Robert W Howe and Stephen P Hubbell and Faith M Inman\u2010Narahari and Patrick A Jansen and Mingxi Jiang and Daniel J Johnson and Mamoru Kanzaki and Abdul Rahman Kassim and David Kenfack and Staline Kibet and Margaret F Kinnaird and Lisa Korte and Kamil Kral and Jitendra Kumar and Andrew J Larson and Yide Li and Xiankun Li and Shirong Liu and Shawn KY Lum and James A Lutz and Keping Ma and Damian M Maddalena and Jean\u2010Remy Makana and Yadvinder Malhi and Toby Marthews and Rafizah Mat Serudin and Sean M McMahon and William J McShea and Herv\u00e9 R Memiaghe and Xiangcheng Mi and Takashi Mizuno and Michael Morecroft and Jonathan A Myers and Vojtech Novotny and Alexandre A de Oliveira and Perry S Ong and David A Orwig and Rebecca Ostertag and Jan Den Ouden and Geoffrey G Parker and Richard P Phillips and Lawren Sack and Moses N Sainge and Weiguo Sang and Kriangsak Sri\u2010ngernyuang and Raman Sukumar and I\u2010Fang Sun and Witchaphart Sungpalee and Hebbalalu Sathyanarayana Suresh and Sylvester Tan and Sean C Thomas and Duncan W Thomas and Jill Thompson and Benjamin L Turner and Maria Uriarte and Renato Valencia and Marta I Vallejo and Alberto Vicentini and Tom\u00e1\u0161 Vr\u0161ka and Xihua Wang and Xugao Wang and George Weiblen and Amy Wolf and Han Xu and Sandra Yap and Jess Zimmerman"
      },
      {
        "title": "Consequences of defaunation for a tropical tree community",
        "abstract": "Hunting affects a considerably greater area of the tropical forest biome than deforestation and logging combined. Often even large remote protected areas are depleted of a substantial proportion of their vertebrate fauna. However, understanding of the long\u2010term ecological consequences of defaunation in tropical forests remains poor. Using tree census data from a large\u2010scale plot monitored over a 15\u2010year period since the approximate onset of intense hunting, we provide a comprehensive assessment of the immediate consequences of defaunation for a tropical tree community. Our data strongly suggest that over\u2010hunting has engendered pervasive changes in tree population spatial structure and dynamics, leading to a consistent decline in local tree diversity over time. However, we do not find any support for suggestions that over\u2010hunting reduces above\u2010ground biomass or biomass accumulation rate in this forest \u2026",
        "year": 2013,
        "authors": "Rhett D Harrison and Sylvester Tan and Joshua B Plotkin and Ferry Slik and Matteo Detto and Tania Brenes and Akira Itoh and Stuart J Davies"
      },
      {
        "title": "Tree carbon allocation explains forest drought\u2010kill and recovery patterns",
        "abstract": "The mechanisms governing tree drought mortality and recovery remain a subject of inquiry and active debate given their role in the terrestrial carbon cycle and their concomitant impact on climate change. Counter\u2010intuitively, many trees do not die during the drought itself. Indeed, observations globally have documented that trees often grow for several years after drought before mortality. A combination of meta\u2010analysis and tree physiological models demonstrate that optimal carbon allocation after drought explains observed patterns of delayed tree mortality and provides a predictive recovery framework. Specifically, post\u2010drought, trees attempt to repair water transport tissue and achieve positive carbon balance through regrowing drought\u2010damaged xylem. Furthermore, the number of years of xylem regrowth required to recover function increases with tree size, explaining why drought mortality increases with size \u2026",
        "year": 2018,
        "authors": "AT Trugman and M Detto and MK Bartlett and D Medvigy and WRL Anderegg and C Schwalm and B Schaffer and Stephen Wilson Pacala"
      }
    ],
    "r_tMTzEAAAAJ": [
      {
        "title": "Entropy-balanced accruals",
        "abstract": "This study assesses whether the accrual-generating process is adequately described by a linear model with respect to a range of underlying determinants examined by prior literature. We document substantial departures from linearity across the distributions of accrual determinants, including measures of size, performance, and growth. To incorporate non-linear relations, we employ a recently developed multivariate matching approach (entropy balancing) to adjust for determinants in place of relying on a linear model. Entropy balancing identifies weights for the control sample to equalize the distribution of determinants across treatment and control samples. In simulations drawing random samples from deciles where a linear model displays poor fit, we find that entropy balancing significantly improves accrual model specification by reducing coefficient bias relative to linear and propensity-score matched models \u2026",
        "year": 2020,
        "authors": "Jeff L McMullin and Bryce Schonberger"
      },
      {
        "title": "When good balance goes bad: A discussion of common pitfalls when using entropy balancing",
        "abstract": "For many accounting research questions, empirical researchers cannot randomly assign observations to treatment conditions or identify a quasi-experimental setting. In these cases, entropy balancing  is an increasingly popular statistical method for identifying a control sample that is nearly identical to the treated sample with respect to observable covariates. In this paper, we compare entropy balancing's approach of reweighting control sample observations to ordinary least squares and propensity score matching. We demonstrate that researchers applying entropy balancing in empirical settings involving panel data with features common in accounting research may encounter implementation issues that render the resulting estimates sensitive to relatively minor changes in the control sample or the research design. Using the setting of estimating the Big-N audit fee premium, we empirically demonstrate these \u2026",
        "year": 2022,
        "authors": "Jeff McMullin and Bryce Schonberger"
      },
      {
        "title": "Economic consequences of risk and ability disclosures: evidence from crowdfunding",
        "abstract": "We exploit the introduction of a\" risks and challenges\"(RC) section on the crowdfunding website Kickstarter. com to study the role of disclosure in markets characterized by severe information asymmetries and agency frictions. Although the RC section contains voluntary and unaudited disclosures, after its addition projects with already observably risky characteristics attract fewer backers and are less likely to be funded, and project creators who respond to the prompt to discuss risks and abilities increase their non-risk disclosures and use a financing structure that accommodates greater risk. Risky projects attract relatively more backers and funding when project creators respond to the prompt, consistent with increased disclosure mitigating market frictions. Our findings suggest that crowdfunders change the types of projects they support and that project creators modify their disclosures and financing structure when prompted to consider risks.",
        "year": 2018,
        "authors": "Joshua Madsen and Jeff L McMullin"
      }
    ],
    "9lmyivIAAAAJ": [
      {
        "title": "Conspiracy in the time of corona: automatic detection of emerging COVID-19 conspiracy theories in social media and the news",
        "abstract": "Rumors and conspiracy theories thrive in environments of low confidence and low trust. Consequently, it is not surprising that ones related to the COVID-19 pandemic are proliferating given the lack of scientific consensus on the virus\u2019s spread and containment, or on the long-term social and economic ramifications of the pandemic. Among the stories currently circulating in US-focused social media forums are ones suggesting that the 5G telecommunication network activates the virus, that the pandemic is a hoax perpetrated by a global cabal, that the virus is a bio-weapon released deliberately by the Chinese, or that Bill Gates is using it as cover to launch a broad vaccination program to facilitate a global surveillance regime. While some may be quick to dismiss these stories as having little impact on real-world behavior, recent events including the destruction of cell phone towers, racially fueled attacks against Asian \u2026",
        "year": 2020,
        "authors": "Shadi Shahsavari and Pavan Holur and Tianyi Wang and Timothy R Tangherlini and Vwani Roychowdhury"
      },
      {
        "title": "\" It happened not too far from here...\": a survey of legend theory and characterization",
        "abstract": "One of the main concerns of folklorist developing new classificatory systems a tions (Hand 1965; Bodker 1965: 253-261 titled\" The Legend and the Sparrow\" L ings of these attempts and proposed that examining the obstacles to deriving a ch legend (D6gh 1975: 188). Both the cong Society for Folk Narrative Research and ferences on contemporary legend held headway in addressing the concerns Deg goals of this paper are to provide a his legend scholarship that has laid the grou sions and to develop a characterization o a synthesis of previous scholarship in a the range of the genre but rather explai the folk legend.",
        "year": 1990,
        "authors": "Timothy R Tangherlini"
      },
      {
        "title": "An automated pipeline for the discovery of conspiracy and conspiracy theory narrative frameworks: Bridgegate, Pizzagate and storytelling on the web",
        "abstract": "Although a great deal of attention has been paid to how conspiracy theories circulate on social media, and the deleterious effect that they, and their factual counterpart conspiracies, have on political institutions, there has been little computational work done on describing their narrative structures. Predicating our work on narrative theory, we present an automated pipeline for the discovery and description of the generative narrative frameworks of conspiracy theories that circulate on social media, and actual conspiracies reported in the news media. We base this work on two separate comprehensive repositories of blog posts and news articles describing the well-known conspiracy theory Pizzagate from 2016, and the New Jersey political conspiracy Bridgegate from 2013. Inspired by the qualitative narrative theory of Greimas, we formulate a graphical generative machine learning model where nodes represent actors/actants, and multi-edges and self-loops among nodes capture context-specific relationships. Posts and news items are viewed as samples of subgraphs of the hidden narrative framework network. The problem of reconstructing the underlying narrative structure is then posed as a latent model estimation problem. To derive the narrative frameworks in our target corpora, we automatically extract and aggregate the actants (people, places, objects) and their relationships from the posts and articles. We capture context specific actants and interactant relationships by developing a system of supernodes and subnodes. We use these to construct an actant-relationship network, which constitutes the underlying generative narrative framework for \u2026",
        "year": 2020,
        "authors": "Timothy R Tangherlini and Shadi Shahsavari and Behnam Shahbazi and Ehsan Ebrahimzadeh and Vwani Roychowdhury"
      }
    ],
    "drakQU4AAAAJ": [
      {
        "title": "Design of a variable-stiffness flapping mechanism for maximizing the thrust of a bio-inspired underwater robot",
        "abstract": "Compliance can increase the thrust generated by the fin of a bio-inspired underwater vehicle. To improve the performance of a compliant fin, the compliance should change with the operating conditions; a fin should become stiffer as the oscillating frequency increases. This paper presents a novel variable-stiffness flapping (VaSF) mechanism that can change its stiffness to maximize the thrust of a bio-inspired underwater robot. The mechanism is designed on the basis of an endoskeleton structure, composed of compliant and rigid segments alternately connected in series. To determine the attachment point of tendons, the anatomy of a dolphin's fluke is considered. Two tendons run through the mechanism to adjust the stiffness. The fluke becomes stiffer when the tendons are pulled to compress the structure. The thrust generated by a prototype mechanism is measured under different conditions to show that the thrust \u2026",
        "year": 2014,
        "authors": "Yong-Jai Park and Tae Myung Huh and Daegeun Park and Kyu-Jin Cho"
      },
      {
        "title": "Integrated ground reaction force sensing and terrain classification for small legged robots",
        "abstract": "We present the design and implementation of a miniature tactile sensing array for ground reaction force measurements in small legged robots. Dynamic ground pressure data from the sensors were collected using a small two-legged runner and used to train a support vector machine (SVM) terrain classifier. Results show that tactile sensing data, in combination with information about the motor torque and robot gait, are sufficient to distinguish among hard, slippery, grassy and granular terrain types with>90% accuracy in a single stride. The most useful classifier features include stride frequency, peak motor torque, and peak and average tactile sensor readings.",
        "year": 2016,
        "authors": "X Alice Wu and Tae Myung Huh and Rudranarayan Mukherjee and Mark Cutkosky"
      },
      {
        "title": "Tactile sensing and terrain-based gait control for small legged robots",
        "abstract": "For small legged robots, ground contact interactions significantly affect the dynamics and locomotion performance. In this article, we designed thin, robust capacitive tactile sensors and applied them to the feet of a small hexapod with C-shaped rotating legs. The sensors measure contact forces as the robot traverses different types of terrain including hard surfaces with high or low friction, sand, and grass. Different gaits perform best on different types of terrain. Useful measured parameters include the magnitude and timing of the peak normal forces, in combination with the leg rotational velocity. The measured parameters were used in a support vector machine classifier to identify terrain types with 82.5% accuracy. Based on gait performance studies, we implemented a terrain-based gait control using real-time terrain classifications. A surface transitioning test shows 17.1% increase in body speed and 13.2 \u2026",
        "year": 2019,
        "authors": "X Alice Wu and Tae Myung Huh and Aaron Sabin and Srinivasan A Suresh and Mark R Cutkosky"
      }
    ],
    "J-uRiRAAAAAJ": [
      {
        "title": "Phase noise in oscillators: A unifying theory and numerical methods for characterization",
        "abstract": "Phase noise is a topic of theoretical and practical interest in electronic circuits, as well as in other fields such as optics. Although progress has been made in understanding the phenomenon, there still remain significant gaps, both in its fundamental theory and in numerical techniques for its characterisation. In this paper, we develop a solid foundation for phase noise that is valid for any oscillator, regardless of operating mechanism. We establish novel results about the dynamics of stable nonlinear oscillators in the presence of perturbations, both deterministic and random. We obtain an exact, nonlinear equation for phase error, which we solve without approximations for random perturbations. This leads us to a precise characterisation of timing jitter and spectral dispersion, for computing which we develop efficient numerical methods. We demonstrate our techniques on practical electrical oscillators, and obtain good \u2026",
        "year": 2000,
        "authors": "Alper Demir and Amit Mehrotra and Jaijeet Roychowdhury"
      },
      {
        "title": "Phase noise and timing jitter in oscillators with colored-noise sources",
        "abstract": "Phase noise or timing jitter in oscillators is of major concern in wireless and optical communications, being a major contributor to the bit-error rate of communication systems, and creating synchronization problems in other clocked and sampled-data systems. This paper presents the theory and practical characterization of phase noise in oscillators due to colored, as opposed to white, noise sources. Shot and thermal noise sources in oscillators can be modeled as white-noise sources for all practical purposes. The characterization of phase noise in oscillators due to shot and thermal noise sources is covered by a recently developed theory of phase noise due to white-noise sources. The extension of this theory and the practical characterization techniques to noise sources in oscillators, which have a colored spectral density, e.g., 1/f noise, is crucial for practical applications. In this paper, we first derive a stochastic \u2026",
        "year": 2003,
        "authors": "Alper Demir"
      }
    ],
    "ABnl2_MAAAAJ": [
      {
        "title": "What you saw is what you will hear: Two new illusions with audiovisual postdictive effects",
        "abstract": "Neuroscience investigations are most often focused on the prediction of future perception or decisions based on prior brain states or stimulus presentations. However, the brain can also process information retroactively, such that later stimuli impact conscious percepts of the stimuli that have already occurred (called \u201cpostdiction\u201d). Postdictive effects have thus far been mostly unimodal (such as apparent motion), and the models for postdiction have accordingly been limited to early sensory regions of one modality. We have discovered two related multimodal illusions in which audition instigates postdictive changes in visual perception. In the first illusion (called the \u201cIllusory Audiovisual Rabbit\u201d), the location of an illusory flash is influenced by an auditory beep-flash pair that follows the perceived illusory flash. In the second illusion (called the \u201cInvisible Audiovisual Rabbit\u201d), a beep-flash pair following a real flash suppresses the perception of the earlier flash. Thus, we showed experimentally that these two effects are influenced significantly by postdiction. The audiovisual rabbit illusions indicate that postdiction can bridge the senses, uncovering a relatively-neglected yet critical type of neural processing underlying perceptual awareness. Furthermore, these two new illusions broaden the Double Flash Illusion, in which a single real flash is doubled by two sounds. Whereas the double flash indicated that audition can create an illusory flash, these rabbit illusions expand audition\u2019s influence on vision to the suppression of a real flash and the relocation of an illusory flash. These new additions to auditory-visual interactions indicate a spatio-temporally fine \u2026",
        "year": 2018,
        "authors": "Noelle RB Stiles and Monica Li and Carmel A Levitan and Yukiyasu Kamitani and Shinsuke Shimojo"
      },
      {
        "title": "A multi-chamber smart suction cup for adaptive gripping and haptic exploration",
        "abstract": "We present a novel robot end-effector for gripping and haptic exploration. Tactile sensing through suction flow monitoring is achieved with a new suction cup design that contains multiple chambers for air flow. Each chamber connects with its own remote pressure transducer, which enables both absolute and differential pressure measures between chambers. By changing the overall vacuum applied to this smart suction cup, it can perform different functions such as gentle haptic exploration (low pressure) and monitoring breaks in the seal during strong astrictive gripping (high pressure). Haptic exploration of surfaces through sliding and palpation can guide the selection of suction grasp locations and help to identify the local surface geometry. During suction gripping, a trained LSTM network can localize breaks in the suction seal between four quadrants with up to 97% accuracy and detects breaks in the suction seal \u2026",
        "year": 2021,
        "authors": "Tae Myung Huh and Kate Sanders and Michael Danielczuk and Monica Li and Yunliang Chen and Ken Goldberg and Hannah S Stuart"
      },
      {
        "title": "Milliscale features increase friction of soft skin in lubricated contact",
        "abstract": "Real world environments, such as kitchens, present objects covered in viscous fluids: soap, oil, water, etc. Understanding and designing for slippery and submerged contact, where fluid lubrication is present, is a continuing challenge in the robotics community. Contact area, bending stiffness, and the presence of a viscous fluid affect friction. This work focuses on milliscale features (3 to 20 mm in size) of soft urethane skin on smooth, flat surfaces. We characterize the friction of soft skins, with varying size, and therefore bending stiffness, of cylindrical features, all with the same nominal contact area. In addition, a new method of frustrated total internal reflection with dye is introduced to visualize lubricated contact. We find that a small number of milliscale fingertip features maximizes friction force in the presence of lubrication, as compared both to un-patterned and many-featured skin designs. This holds true for a robotic \u2026",
        "year": 2020,
        "authors": "Monica S Li and Dominic Melville and Ethan Chung and Hannah S Stuart"
      }
    ],
    "TrrbXhIAAAAJ": [
      {
        "title": "Trawling in the sea of the great unread: Sub-corpus topic modeling and humanities research",
        "abstract": "Given a small, well-understood corpus that is of interest to a Humanities scholar, we propose sub-corpus topic modeling (STM) as a tool for discovering meaningful passages in a larger collection of less well-understood texts. STM allows Humanities scholars to discover unknown passages from the vast sea of works that Moretti calls the \u201cgreat unread\u201d and to significantly increase the researcher's ability to discuss aspects of influence and the development of intellectual movements across a broader swath of the literary landscape. In this article, we test three typical Humanities research problems: in the first, a researcher wants to find text passages that exhibit similarities to a collection of influential non literary texts from a single author (here, Darwin); in the second, a researcher wants to discover literary passages related to a well understood corpus of literary texts (here, emblematic texts from the Modern Breakthrough \u2026",
        "year": 2013,
        "authors": "Timothy R Tangherlini and Peter Leonard"
      },
      {
        "title": "Mining large datasets for the humanities",
        "abstract": "This paper considers how libraries can support humanities scholars in working with large digitized collections of cultural material. Although disciplines such as corpus linguistics have already made extensive use of these collections, fields such as literature, history, and cultural studies stand at the threshold of new opportunity.   Libraries can play an important role in helping these scholars make sense of big cultural data. In part, this is because many humanities graduate programs neither consider data skills a prerequisite, nor train their students in data analysis methods.  As the \u2018laboratory for the humanities,\u2019 libraries are uniquely suited to host new forms of collaborative exploration of big data by humanists. But in order to do this successfully, libraries must consider three challenges:  1) How to evolve technical infrastructure to support the analysis, not just the presentation, of digitized artifacts.  2) How to work with data that may fall under both copyright and licensing restrictions.  3) How to serve as trusted partners with disciplines that have evolved thoughtful critiques of quantitative and algorithmic methodologies.",
        "year": 2014,
        "authors": "Peter Leonard"
      },
      {
        "title": "Det Etniske Gennembrud - Multicultural Literature in Denmark",
        "abstract": "The critic Lars Bukdahl, writing in Weekendavisen, suggested that \u201c\u00e6rligt talt kunne Berlingske og Gyldendal godt aflyse deres konkurrence om nydansk litteratur og bare give Maja Lee f\u00f8rstepr\u00e6mien.\u201d 3 But even in the intimate scale of Denmark\u2019s literary world, certain lines had to be drawn, as editor Wissing noted:\u201cN\u00e5r vi kr\u00e6ver anden b\u00e5de etnisk og kulturel baggrund, s\u00e5 udelukker det bl. a. koreanske adoptivb\u00f8rn\u2026\u201d 4 It\u2019s hard to know whether Wissing was referring to Langvad specifically, or if the category of adoptive children as a whole was seen as too \u201cintegrated\u201d to be able to supply the ethnic difference that Nye Stemmer promised.What, then, can we learn from the volume that resulted from this competition? Unlike the reception of the Swedish author Jonas Khemiri\u2019s first novel, Ett \u00f6ga r\u00f6tt, in 2003, none of the works in Nye Stemmer seems to have heralded a new way of writing about identity.\u201cHvis man forventer, at den nydanske litteratur, der nu er p\u00e5 vej, vil v\u00e6re skr\u00e6mmende og enormt fremmedartet, s\u00e5 bliver man, at d\u00f8mme efter disse bidrag, skuffet,\u201d noted reviewer and editor Christian B. Korsgaard.\u201cDe var bare stille og roligt godt lavet.\u201d 5 Some contributions, such as Nassrin el Halawani\u2019s \u201cDen et niske lov,\u201d took their cues from Langvad\u2019s re-appropriation of legalistic language to describe the iron-clad laws of ethnic performance in Danish society:\u201cParagraf 3: \u00c9n gang etnisk, altid etnisk/Paragraf 3a: Ingen kan tage den etniskes borgerrettigheder som etnisk fra den etniske/Paragraf 3b: Den etniske kan ikke frasige sig sin etnicitet.\u201d This similarity between El Halawani\u2019s and Langvad\u2019s style suggests that",
        "year": 2008,
        "authors": "Peter Leonard"
      }
    ],
    "TkL_VtoAAAAJ": [
      {
        "title": "Soil enzyme activities, microbial communities, and carbon and nitrogen availability in organic agroecosystems across an intensively-managed agricultural landscape",
        "abstract": "Variability in the activity and composition of soil microbial communities may have important implications for the suite of microbially-derived ecosystem functions upon which agricultural systems rely, particularly organic agriculture. An on-farm approach was used to investigate microbial communities and soil carbon (C) and nitrogen (N) availability on 13 organically-managed fields growing Roma-type tomatoes, but differing in nutrient management, across an intensively-managed agricultural landscape in the Central Valley of California. Soil physicochemical characteristics, potential activities of nine soil enzymes involved in C, N, phosphorus (P), and sulfur (S) cycling, and fatty acid methyl esters (FAMEs) were measured during the growing season and evaluated with multivariate approaches. Soil texture and pH in the 0\u201315 cm surface layer were similar across the 13 fields, but there was a three-fold range of soil C \u2026",
        "year": 2014,
        "authors": "L.E. Bowles and T.M. and Acosta-Martinez and V. and Calderon and F. and and Jackson"
      },
      {
        "title": "Long-term evidence shows that crop-rotation diversification increases agricultural resilience to adverse growing conditions in North America",
        "abstract": "A grand challenge facing humanity is how to produce food for a growing population in the face of a changing climate and environmental degradation. Although empirical evidence remains sparse, management strategies that increase environmental sustainability, such as increasing agroecosystem diversity through crop rotations, may also increase resilience to weather extremes without sacrificing yields. We used multilevel regression analyses of long-term crop yield datasets across a continental precipitation gradient to assess how temporal crop diversification affects maize yields in intensively managed grain systems. More diverse rotations increased maize yields over time and across all growing conditions (28.1% on average), including in favorable conditions (22.6%). Notably, more diverse rotations also showed positive effects on yield under unfavorable conditions, whereby yield losses were reduced by 14.0 \u2026",
        "year": 2020,
        "authors": "Timothy M Bowles and Maria Mooshammer and Yvonne Socolar and Francisco Calder\u00f3n and Michel A Cavigelli and Steve W Culman and William Deen and Craig F Drury and Axel Garcia y Garcia and Am\u00e9lie CM Gaudin and W Scott Harkcom and R Michael Lehman and Shannon L Osborne and G Philip Robertson and Jonathan Salerno and Marty R Schmer and Jeffrey Strock and A Stuart Grandy"
      },
      {
        "title": "Comparison of permanganate\u2010oxidizable carbon and mineralizable carbon for assessment of organic matter stabilization and mineralization",
        "abstract": " Core Ideas POXC and mineralizable C were evaluated across diverse agroecosystems. The two are related but differentially influenced by management practices. POXC better reflected SOM stabilizing practices. Mineralizable C reflected SOM mineralizing practices. Both predicted agronomic performance better than other soil C fractions. Permanganate\u2010oxidizable C (POXC) and mineralizable C (as determined by short\u2010term aerobic incubation of rewetted soil) are measures of active organic matter that may provide early indication of soil C stabilization and mineralization processes. To date, the relationship between these two promising active organic matter tests has not been comprehensively evaluated, and little is known about their functional role in the soil ecosystem. Here, we examined the relationship between POXC and mineralizable C across a wide range of soil types, management histories, and \u2026",
        "year": 2016,
        "authors": "Tunsisa T Hurisso and Steve W Culman and William R Horwath and Jordon Wade and Deandra Cass and Joshua W Beniston and Timothy M Bowles and A Stuart Grandy and Alan J Franzluebbers and Meagan E Schipanski and Shawn T Lucas and Carmen M Ugarte"
      }
    ],
    "wRUKAMMAAAAJ": [
      {
        "title": "Memristor-based memory: The sneak paths problem and solutions",
        "abstract": "In this paper, we investigate the read operation of memristor-based memories. We analyze the sneak paths problem and provide a noise margin metric to compare the various solutions proposed in the literature. We also analyze the power consumption associated with these solutions. Moreover, we study the effect of the aspect ratio of the memory array on the sneak paths. Finally, we introduce a new technique for solving the sneak paths problem by gating the memory cell using a three-terminal memistor device.",
        "year": 2013,
        "authors": "Mohammed Affan Zidan and Hossam Aly Hassan Fahmy and Muhammad Mustafa Hussain and Khaled Nabil Salama"
      },
      {
        "title": "Biofunctionalized two-dimensional Ti3C2 MXenes for ultrasensitive detection of cancer biomarker",
        "abstract": "In this work, ultrathin Ti3C2-MXene nanosheets were synthesized by minimally intensive layer delamination methods, and uniformly functionalized with aminosilane (f-Ti3C2-MXene) to provide a covalent binding for the immobilized bio-receptor (anti-CEA) for label free, ultrasensitive detection of cancer biomarker (carcinoembryonic antigen, CEA). The effect of different redox probes on the electrochemical behavior of f-Ti3C2-MXene was investigated and found that hexaammineruthenium ([Ru(NH3)6]3+) is the preferable redox probe for biosensing. The fabricated biofunctionalized Ti3C2-MXene exhibits a linear detection range of 0.0001\u20132000\u202fng\u202fmL\u22121 with sensitivity of 37.9\u202f\u00b5A\u202fng\u22121 mL\u202fcm\u22122 per decade. The wider linear detection range of our f-Ti3C2-MXene is not only higher than previously reported pristine 2D nanomaterials, but is even comparable to other hybrid 2D nanomaterials. We believe that this \u2026",
        "year": 2018,
        "authors": "Saurabh Kumar and Yongjiu Lei and Niman H Alshareef and MA Quevedo-Lopez and Khaled N Salama"
      },
      {
        "title": "A MXene\u2010based wearable biosensor system for high\u2010performance in vitro perspiration analysis",
        "abstract": "Wearable electrochemical biosensors for sweat analysis present a promising means for noninvasive biomarker monitoring. However, sweat\u2010based sensing still poses several challenges, including easy degradation of enzymes and biomaterials with repeated testing, limited detection range and sensitivity of enzyme\u2010based biosensors caused by oxygen deficiency in sweat, and poor shelf life of sensors using all\u2010in\u2010one working electrodes patterned by traditional techniques (e.g., electrodeposition and screen printing). Herein, a stretchable, wearable, and modular multifunctional biosensor is developed, incorporating a novel MXene/Prussian blue (Ti3C2Tx/PB) composite designed for durable and sensitive detection of biomarkers (e.g., glucose and lactate) in sweat. A unique modular design enables a simple exchange of the specific sensing electrode to target the desired analytes. Furthermore, an implemented solid \u2026",
        "year": 2019,
        "authors": "Yongjiu Lei and Wenli Zhao and Yizhou Zhang and Qiu Jiang and Jr\u2010Hau He and Antje J Baeumner and Otto S Wolfbeis and Zhong Lin Wang and Khaled N Salama and Husam N Alshareef"
      }
    ],
    "x19iFT0AAAAJ": [
      {
        "title": "Understanding and using the controller area network communication protocol: theory and practice",
        "abstract": "This book to offers a hands-on guide to designing, analyzing and debugging a communication infrastructure based on the Controller Area Network (CAN) bus. Although the CAN bus standard is well established and currently used in most automotive systems, as well as avionics, medical systems and other devices, its features are not fully understood by most developers, who tend to misuse the network. This results in lost opportunities for better efficiency and performance. These authors offer a comprehensive range of architectural solutions and domains of analysis. It also provides formal models and analytical results, with thorough discussion of their applicability, so that it serves as an invaluable reference for researchers and students, as well as practicing engineers.",
        "year": 2012,
        "authors": "Marco Di Natale and Haibo Zeng and Paolo Giusto and Arkadeb Ghosal"
      },
      {
        "title": "Two-stage energy management for office buildings with workplace EV charging and renewable energy",
        "abstract": "Workplace electric vehicle (EV) charging is now supported by more and more companies to encourage EV adoption. In the meantime, renewable energies are becoming an important power source. To participate in the day-ahead power market, decisions have to be made before knowing the actual power demand. This paper addresses the challenges of energy scheduling in office buildings integrated with photovoltaic systems and workplace EV charging. It proposes to leverage day-ahead power market and time-of-use electricity, and uses stochastic programming to address the uncertainties in EV charging demand. Two computationally efficient control algorithms, stochastic programming and load forecasting for energy management with two stages (SPLET) and sample average approximation-based SPLET, are proposed. Both algorithms contain two stages: day-ahead scheduling and real-time operation. First \u2026",
        "year": 2017,
        "authors": "Di Wu and Haibo Zeng and Chao Lu and Benoit Boulet"
      },
      {
        "title": "A next-generation design framework for platform-based design",
        "abstract": "The platform-based design methodology [1] is based on the usage of formal modeling techniques, clearly defined abstraction levels and the separation of concerns to enable an effective design process. The METROPOLIS framework embodies the platform-based design methodology and has been applied to a number of case studies across multiple domains. Based on these experiences, we have identified three key features that need to be enhanced: heterogeneous IP import, orthogonalization of performance from behavior, and design space exploration. The next generation METRO II framework incorporates these advanced features. The main concepts underlying METRO II are described in this paper and illustrated with a small example.",
        "year": 2007,
        "authors": "Abhijit Davare and Douglas Densmore and Trevor Meyerowitz and Alessandro Pinto and Alberto Sangiovanni-Vincentelli and Guang Yang and Haibo Zeng and Qi Zhu"
      }
    ],
    "DVk7EKAAAAAJ": [
      {
        "title": "Enterprise resource planning systems: systems, life cycle, electronic commerce, and risk",
        "abstract": "Enterprise Resource Planning Systems can provide the foundation for a wide range of e-commerce based processes including web-based ordering and order tracing, inventory management, and built-to-order goods. This book examines the pros and cons of ERP systems, explains how they work, and highlights their role at the heart of e-commerce. The author begins by explaining the background to ERP systems and goes on to discuss specific systems and their capabilities. He then focuses on the ERP life cycle, from initial implementation through to the time when the system goes live. After covering the use of ERP in e-commerce, he concludes by discussing the risks associated with the adoption of ERP systems. The book contains several detailed case-studies and will be an invaluable guide to managers and consultants working with ERP systems. It will also be a useful reference for MBA students taking courses in information systems management.",
        "year": 2000,
        "authors": "Daniel E O'Leary"
      },
      {
        "title": "Artificial Intelligence and Big Data",
        "abstract": "AI Innovation in Industry is a new department for IEEE Intelligent Systems, and this paper examines some of the basic concerns and uses of AI for big data (AI has been used in several different ways to facilitate capturing and structuring big data, and it has been used to analyze big data for key insights).",
        "year": 2013,
        "authors": "Daniel E O'Leary"
      },
      {
        "title": "Enterprise knowledge management",
        "abstract": "Many enterprises downsize to adapt to more competitive environments, but unless they have captured the knowledge of their employees, downsizing can result in a loss of critical information. Similarly, as employees leave, organizations are likely to lose access to large quantities of critical knowledge. As companies expand internationally, geographic barriers can affect knowledge exchange and prevent easy access to information. These and other forces are pushing enterprises to explore better methods for knowledge management. Enterprise knowledge management entails formally managing knowledge resources, typically by using advanced information technology. KM is formal in that knowledge is classified and categorized according to a prespecified, but evolving, ontology into structured and semistructured data and knowledge bases. The overriding purpose of enterprise KM is to make knowledge accessible \u2026",
        "year": 1998,
        "authors": "Daniel E O'Leary"
      }
    ],
    "0uzKezgAAAAJ": [
      {
        "title": "Dynamic layout planning using a hybrid incremental solution method",
        "abstract": "Efficiently using site space to accommodate resources throughout the duration of a construction project is a critical problem. It is termed the \u201cdynamic layout planning\u201d problem. Solving it involves creating a sequence of layouts that span the entire project duration, given resources, the timing of their presence on site, their changing demand for space over time, constraints on their location, and costs for their relocation. A dynamic layout construction procedure is presented here. Construction resources, represented as rectangles, are subjected to two-dimensional geometric constraints on relative locations. The objective is to allow site space to all resources so that no spatial conflicts arise, while keeping distance-based adjacency and relocation costs minimal. The solution is constructed stepwise for consecutive time frames. For each resource, selected heuristically one at a time, constraint satisfaction is used to compute \u2026",
        "year": 1999,
        "authors": "PP Zouein and ID Tommelein"
      },
      {
        "title": "Interactive dynamic layout planning",
        "abstract": "The layout of temporary facilities on a construction site necessarily changes over time, so the term dynamic layout is used to describe a sequence of layouts spanning the entire duration of construction of a project. Many layout changes are dictated by the construction schedule. In the MovePlan model, which is presented here, the activity schedule is therefore augmented with data needed to construct layouts, i.e., resources required to perform activities, and their dimensions. This augmented schedule can drive the dynamic layout process, including the positioning of temporary facilities on site and the movement of materials and equipment. Conservative modeling assumptions were made in order to keep computational costs low, so that the MovePlan implementation would run on a microcomputer and thus be readily field\u2010usable. The MovePlan prototype system provides a graphical interactive interface with \u2026",
        "year": 1993,
        "authors": "ID Tommelein and PP Zouein"
      },
      {
        "title": "Genetic algorithm for solving site layout problem with unequal-size and constrained facilities",
        "abstract": "This paper presents an investigation of the applicability of a genetic approach for solving the construction site layout problem. This problem involves coordinating the use of limited site space to accommodate temporary facilities so that transportation cost of materials is minimized. The layout problem considered in this paper is characterized by affinity weights used to model transportation costs between facilities and by geometric constraints that limit their relative positions on site. The proposed genetic algorithm generates an initial population of layouts through a sequence of mutation operations and evolves the layouts of this population through a sequence of genetic operations aiming at finding an optimal layout. The paper concludes with examples illustrating the strength and limitations of the proposed algorithm in the cases of (1) loosely versus tightly constrained layouts with equal levels of interaction between \u2026",
        "year": 2002,
        "authors": "PP Zouein and H Harmanani and A Hajar"
      }
    ],
    "QflOmB4AAAAJ": [
      {
        "title": "The Anticompetitive Effects of Common Ownership: The Case of Paragraph IV Generic Entry",
        "abstract": "Brand-name pharmaceutical companies often file lawsuits against generic drug manufacturers that challenge the monopoly status of patent-protected drugs. Institutional horizontal shareholdings, measured by the generic shareholders' ownership in the brand-name company relative to their ownership in the generic manufacturer, are significantly positively associated with the likelihood that the two parties enter into a settlement agreement in which the brand pays the generic manufacturer to stay out of the market.",
        "year": 2020,
        "authors": "Jin Xie and Joseph Gerakos"
      },
      {
        "title": "Punish one, teach a hundred: The sobering effect of punishment on the unpunished",
        "abstract": "Direct experience of a peer\u2019s punishment might make non-punished peers reassess the probability and consequences of facing punishment and hence induce a change in their behavior. We test this mechanism in a setting, China, in which we observe the reactions to the same peer\u2019s punishment by listed firms with different incentives to react\u2013state-owned enterprises (SOEs) and non-SOEs. After observing peers punished for wrongdoing in loan guarantees to related parties, SOEs\u2013which are less disciplined by traditional governance mechanisms than non-SOEs\u2013cut their loan guarantees. SOEs whose CEOs have stronger career concerns react more than other SOEs to the same punishment events, a result that systematic differences between SOEs and non-SOEs cannot drive. SOEs react more to events with higher press coverage even if information about all events is publicly available. After peers\u2019 punishments, SOEs also increase their board independence, reduce inefficient investment, increase total factor productivity, and experience positive cumulative abnormal returns. The bank debt and investment of related parties that benefited from tunneling drop after listed peers\u2019 punishments. Strategic punishments could be a cost-effective governance mechanism when other forms of governance are ineffective.",
        "year": 2019,
        "authors": "Francesco D'Acunto and Michael Weber and Jin Xie"
      },
      {
        "title": "Trust and Contracts: Empirical Evidence",
        "abstract": "Trust between parties should drive contract design: if parties were suspicious about each others' reaction to unplanned events, they might agree to pay higher costs of negotiation ex ante to complete contracts. Using a unique sample of U.S. consulting contracts and a negative shock to trust between shareholders/managers (principals) and consultants (agents) staggered across space and over time, we find that lower trust increases contract completeness. Not only the complexity but also the verifiable states of the world covered by contracts increase after trust drops. The results hold for several novel text-analysis-based measures of contract completeness and do not arise in falsification tests. At the clause level, we find that non-compete agreements, confidentiality, indemnification, and termination rules are the most likely clauses added to contracts after a negative shock to trust and these additions are not driven by new boilerplate contract templates. These clauses are those whose presence should be sensitive to the mutual trust between principals and agents.",
        "year": 2020,
        "authors": "Francesco D'Acunto and Jin Xie and Jiaquan Yao"
      }
    ],
    "sZf6F1cAAAAJ": [
      {
        "title": "A tutorial on the positive realization problem",
        "abstract": "This paper is a tutorial on the positive realization problem, that is the problem of finding a positive state-space representation of a given transfer function and characterizing existence and minimality of such representation. This problem goes back to the 1950s and was first related to the identifiability problem for hidden Markov models, then to the determination of internal structures for compartmental systems and later embedded in the more general framework of positive systems theory. Within this framework, developing some ideas sprang in the 1960s, during the 1980s, the positive realization problem was reformulated in terms of a geometric condition which was recently exploited as a tool for finding the solution to the existence problem and providing partial answers to the minimality problem. In this paper, the reader is carried through the key ideas which have proved to be useful in order to tackle this problem. In \u2026",
        "year": 2004,
        "authors": "Luca Benvenuti and Lorenzo Farina"
      },
      {
        "title": "Automotive engine control and hybrid systems: Challenges and opportunities",
        "abstract": "The design of engine control systems has been traditionally carried out using a mix of heuristic techniques validated by simulation and prototyping using approximate average-value models. However, the ever increasing demands on passengers' comfort, safety, emissions, and fuel consumption imposed by car manufacturers and regulations call for more robust techniques and the use of cycle-accurate models. We argue that these models must be hybrid because of the combination of time-domain and event-based behaviors. We present a hybrid model of the engine in which both continuous and discrete time-domain as well as event-based phenomena are modeled in a separate but integrated manner. Based on this model, we formalize the specification of the overall engine control by defining a number of hybrid control problems. To cope with the difficulties arising in the design of hybrid controllers, a design \u2026",
        "year": 2002,
        "authors": "Andrea Balluchi and Luca Benvenuti and Maria Domenica Di Benedetto and Claudio Pinello and Alberto L Sangiovanni-Vincentelli"
      },
      {
        "title": "Nonnegative realization of a linear system with nonnegative impulse response",
        "abstract": "Let H(z) be a rational transfer function, with associated nonnegative impulse response sequence. The paper considers the question: When does there exist a triple A/spl isin/R/sup N/spl times/N/, b/spl isin/R/sup N/, c/spl isin/R/sup N/ with all nonnegative entries H(z)=c'(zI-A)/sup -1/b? An essentially complete characterization is given of the H(z) allowing such a realization, in terms of the location of the pole or poles of H(z) with maximum modulus.",
        "year": 2002,
        "authors": "Brian DO Anderson and Manfred Deistler and Lorenzo Farina and Luca Benvenuti"
      }
    ],
    "4p5ooX4AAAAJ": [
      {
        "title": "Climate change, phenology, and phenological control of vegetation feedbacks to the climate system",
        "abstract": "Vegetation phenology is highly sensitive to climate change. Phenology also controls many feedbacks of vegetation to the climate system by influencing the seasonality of albedo, surface roughness length, canopy conductance, and fluxes of water, energy, CO2 and biogenic volatile organic compounds. In this review, we first discuss the environmental drivers of phenology, and the impacts of climate change on phenology, in different biomes. We then examine the vegetation-climate feedbacks that are mediated by phenology, and assess the potential impact on these feedbacks of shifts in phenology driven by climate change. We finish with an overview of phenological modeling and we suggest ways in which models might be improved using existing data sets. Several key weaknesses in our current understanding emerge from this analysis. First, we need a better understanding of the drivers of phenology, particularly \u2026",
        "year": 2013,
        "authors": "Andrew D Richardson and Trevor F Keenan and Mirco Migliavacca and Youngryel Ryu and Oliver Sonnentag and Michael Toomey"
      },
      {
        "title": "Increased atmospheric vapor pressure deficit reduces global vegetation growth",
        "abstract": "Atmospheric vapor pressure deficit (VPD) is a critical variable in determining plant photosynthesis. Synthesis of four global climate datasets reveals a sharp increase of VPD after the late 1990s. In response, the vegetation greening trend indicated by a satellite-derived vegetation index (GIMMS3g), which was evident before the late 1990s, was subsequently stalled or reversed. Terrestrial gross primary production derived from two satellite-based models (revised EC-LUE and MODIS) exhibits persistent and widespread decreases after the late 1990s due to increased VPD, which offset the positive CO2 fertilization effect. Six Earth system models have consistently projected continuous increases of VPD throughout the current century. Our results highlight that the impacts of VPD on vegetation growth should be adequately considered to assess ecosystem responses to future climate conditions.",
        "year": 2019,
        "authors": "Wenping Yuan and Yi Zheng and Shilong Piao and Philippe Ciais and Danica Lombardozzi and Yingping Wang and Youngryel Ryu and Guixing Chen and Wenjie Dong and Zhongming Hu and Atul K Jain and Chongya Jiang and Etsushi Kato and Shihua Li and Sebastian Lienert and Shuguang Liu and Julia EMS Nabel and Zhangcai Qin and Timothy Quine and Stephen Sitch and William K Smith and Fan Wang and Chaoyang Wu and Zhiqiang Xiao and Song Yang"
      },
      {
        "title": "Optical vegetation indices for monitoring terrestrial ecosystems globally",
        "abstract": "Vegetation indices (VIs), which describe remotely sensed vegetation properties such as photosynthetic activity and canopy structure, are widely used to study vegetation dynamics across scales. However, VI-based results can vary between indices, sensors, quality control measures, compositing algorithms, and atmospheric and sun\u2013target\u2013sensor geometry corrections. These variations make it difficult to draw robust conclusions about ecosystem change and highlight the need for consistent VI application and verification. In this Technical Review, we summarize the history and ecological applications of VIs and the linkages and inconsistencies between them. VIs have been used since the early 1970s and have evolved rapidly with the emergence of new satellite sensors with more spectral channels, new scientific demands and advances in spectroscopy. When choosing VIs, the spectral sensitivity and features of VIs \u2026",
        "year": 2022,
        "authors": "Yelu Zeng and Dalei Hao and Alfredo Huete and Benjamin Dechant and Joe Berry and Jing M Chen and Joanna Joiner and Christian Frankenberg and Ben Bond-Lamberty and Youngryel Ryu and Jingfeng Xiao and Ghassem R Asrar and Min Chen"
      }
    ],
    "tRCNWC4AAAAJ": [
      {
        "title": "SIS: A system for sequential circuit synthesis",
        "abstract": "SIS : A system for sequential circuit synthesis | CiNii Research CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\n\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u8a73\u7d30\u3078\u79fb\u52d5 \u691c\u7d22\u30d5\u30a9\u30fc\u30e0\u3078\u79fb\u52d5 \u8ad6\u6587\u30fb\u30c7\u30fc\u30bf\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\n\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 English \u691c\u7d22 \u30bf\u30a4\u30c8\u30eb \u4eba\u7269/\u56e3\u4f53\u540d \u6240\u5c5e\u6a5f\u95a2 ISSN DOI \u671f\u9593 ~ \n\u672c\u6587\u30ea\u30f3\u30af \u672c\u6587\u30ea\u30f3\u30af\u3042\u308a \u30c7\u30fc\u30bf\u30bd\u30fc\u30b9 JaLC IRDB Crossref DataCite NDL\u30b5\u30fc\u30c1 NDL\u30c7\u30b8\u30b3\u30ec(\u65e7\nNII-ELS) RUDA JDCat NINJAL CiNii Articles CiNii Books DBpedia Nikkei BP KAKEN Integbio \nMDR PubMed LSDB Archive \u6975\u5730\u7814ADS \u6975\u5730\u7814\u5b66\u8853DB OpenAIRE \u516c\u5171\u30c7\u30fc\u30bf\u30ab\u30bf\u30ed\u30b0 \u30e0\u30fc\u30f3\n\u30b7\u30e7\u30c3\u30c8\u578b\u7814\u7a76\u958b\u767a\u4e8b\u696d \u3059\u3079\u3066 \u7814\u7a76\u30c7\u30fc\u30bf \u8ad6\u6587 \u672c \u535a\u58eb\u8ad6\u6587 \u30d7\u30ed\u30b8\u30a7\u30af\u30c8 [2024\u5e7412\u67089\u65e5\u66f4\u65b0\n]CiNii Dissertations\u53ca\u3073CiNii Books\u306eCiNii Research\u3078\u306e\u7d71\u5408\u306b\u3064\u3044\u3066 CiNii Research\u81ea\u52d5\n\u7ffb\u8a33\u6a5f\u80fd(\u8a66\u884c\u7248)\u3092CiNii Labs\u306b\u3066\u516c\u958b\u3057\u307e\u3057\u305f \u65e5\u7d4cBP\u793e\u63d0\u4f9b\u30c7\u30fc\u30bf\u306e\u66f4\u65b0\u505c\u6b62\u53ca\u3073\u524a\u9664\u306b\u3064\u3044\u3066 \nSIS : A system for sequential circuit synthesis \u88ab\u5f15\u7528\u6587\u732e1\u4ef6 SENTOVICH ME \u53ce\u9332\u520a\u884c\u7269 \u2026",
        "year": 1992,
        "authors": "ME Sentovich"
      },
      {
        "title": "Hardware-software co-design of embedded systems: the POLIS approach",
        "abstract": "Embedded systems are informally defined as a collection of programmable parts surrounded by ASICs and other standard components, that interact continuously with an environment through sensors and actuators. The programmable parts include micro-controllers and Digital Signal Processors (DSPs). Embedded systems are often used in life-critical situations, where reliability and safety are more important criteria than performance. Today, embedded systems are designed with an ad hoc approach that is heavily based on earlier experience with similar products and on manual design. Use of higher-level languages such as C helps structure the design somewhat, but with increasing complexity it is not sufficient. Formal verification and automatic synthesis of implementations are the surest ways to guarantee safety. Thus, the POLIS system which is a co-design environment for embedded systems is based on a formal model of computation. POLIS was initiated in 1988 as a research project at the University of California at Berkeley and, over the years, grew into a full design methodology with a software system supporting it. Hardware-Software Co-Design of Embedded Systems: The POLIS Approach is intended to give a complete overview of the POLIS system including its formal and algorithmic aspects. Hardware-Software Co-Design of Embedded Systems: The POLIS Approach will be of interest to embedded system designers (automotive electronics, consumer electronics and telecommunications), micro-controller designers, CAD developers and students.",
        "year": 2012,
        "authors": "Felice Balarin and Paolo Giusto and Attila Jurecska and Claudio Passerone and Ellen Sentovich and Bassam Tabbara and Massimiliano Chiodo and Harry Hsieh and Luciano Lavagno and Alberto Sangiovanni-Vincentelli and Kei Suzuki"
      },
      {
        "title": "Design of embedded systems: Formal models, validation, and synthesis",
        "abstract": "This paper addresses the design of reactive real-time embedded systems. Such systems are often heterogeneous in implementation technologies and design styles, for example by combining hardware application-specific integrated circuits (ASICs) with embedded software. The concurrent design process for such embedded systems involves solving the specification, validation, and synthesis problems. We review the variety of approaches to these problems that have been taken.",
        "year": 2002,
        "authors": "Stephen Edwards and Luciano Lavagno and Edward A Lee and Alberto Sangiovanni-Vincentelli"
      }
    ],
    "fXhxN3AAAAAJ": [
      {
        "title": "Comparing AHP and CBA as decision methods to resolve the choosing problem in detailed design",
        "abstract": "Multicriteria decision-making (MCDM) methods can help designers address the choosing problem in building detailed design. Many, however, appear to assume that all methods are equivalent. This paper argues that differences between MCDM methods matter. The first contribution of this paper is differentiating between the analytical hierarchy process (AHP) and choosing by advantages (CBA) by comparing them through an example. The second contribution is explaining why CBA is superior to AHP for this context. In summary, CBA (1) provides a more context-based analysis than AHP, (2) does not incorporate conflicting judgments for weighing factors as AHP does, (3) does not assume linear trade-offs between factors as AHP does, (4) does not assume that factors have zero as a natural scale as AHP does, (5) focuses on differentiating between alternatives more than AHP, (6) maintains the result of the decision \u2026",
        "year": 2015,
        "authors": "P Arroyo and ID Tommelein and G Ballard"
      },
      {
        "title": "Selecting appropriate wastewater treatment technologies using a choosing-by-advantages approach",
        "abstract": "Selecting the most sustainable wastewater treatment (WWT) technology among possible alternatives is a very complex task because the choice must integrate economic, environmental, and social criteria. Traditionally, several multi-criteria decision-making approaches have been applied, with the most often used being the analytical hierarchical process (AHP). However, AHP allows users to offset poor environmental and/or social performance with low cost. To overcome this limitation, our study examines a choosing-by-advantages (CBA) approach to rank seven WWT technologies for secondary WWT. CBA results were compared with results obtained by using the AHP approach. The rankings of WWT alternatives differed, depending on whether the CBA or AHP approach was used, which highlights the importance of the method used to support decision-making processes, particularly ones that rely on subjective \u2026",
        "year": 2018,
        "authors": "Paz Arroyo and Mar\u00eda Molinos-Senante"
      },
      {
        "title": "Choosing by advantages: A case study for selecting an HVAC system for a net zero energy museum",
        "abstract": "Choosing a building system is not an easy task, especially when designers are concerned about the social and environmental impacts of their choices, as in the case of a net zero energy (NZE) building. In addition, economic constraints are commonly misunderstood so that all too often decisions are based on what is cheaper upfront and do not take the life-cycle cost into account. Moreover, the interaction with increasing numbers of stakeholders makes decision-making even more complex. While decisions can be supported by decision-making methods, in practice many are made without a formal method or discussion, which often generates conflict and waste in the design process. Few designers know how to incorporate social, environmental and economical factors when making a decision. This research fills the literature gap and provides practical advice for practitioners by demonstrating the application of a \u2026",
        "year": 2016,
        "authors": "Paz Arroyo and Iris D Tommelein and Glenn Ballard and Peter Rumsey"
      }
    ],
    "aCNJzKEAAAAJ": [
      {
        "title": "FLUXNET: A new tool to study the temporal and spatial variability of ecosystem-scale carbon dioxide, water vapor, and energy flux densities",
        "abstract": "FLUXNET is a global network of micrometeorological flux measurement sites that measure the exchanges of carbon dioxide, water vapor, and energy between the biosphere and atmosphere. At present over 140 sites are operating on a long-term and continuous basis. Vegetation under study includes temperate conifer and broadleaved (deciduous and evergreen) forests, tropical and boreal forests, crops, grasslands, chaparral, wetlands, and tundra. Sites exist on five continents and their latitudinal distribution ranges from 70\u00b0N to 30\u00b0S.             FLUXNET has several primary functions. First, it provides infrastructure for compiling, archiving, and distributing carbon, water, and energy flux measurement, and meteorological, plant, and soil data to the science community. (Data and site information are available online at the FLUXNET Web site,             http://www-eosdis.ornl.gov/FLUXNET/             .) Second, the \u2026",
        "year": 2001,
        "authors": "Dennis Baldocchi and Eva Falge and Lianhong Gu and Richard Olson and David Hollinger and Steve Running and Peter Anthoni and Ch Bernhofer and Kenneth Davis and Robert Evans and Jose Fuentes and Allen Goldstein and Gabriel Katul and Beverly Law and Xuhui Lee and Yadvinder Malhi and Tilden Meyers and William Munger and Walt Oechel and Kyaw Tha Paw U and Kim Pilegaard and Hans Peter Schmid and Riccardo Valentini and Shashi Verma and Timo Vesala and Kell Wilson and Steve Wofsy"
      },
      {
        "title": "On the separation of net ecosystem exchange into assimilation and ecosystem respiration: review and improved algorithm",
        "abstract": "This paper discusses the advantages and disadvantages of the different methods that separate net ecosystem exchange (NEE) into its major components, gross ecosystem carbon uptake (GEP) and ecosystem respiration (Reco). In particular, we analyse the effect of the extrapolation of night\u2010time values of ecosystem respiration into the daytime; this is usually done with a temperature response function that is derived from long\u2010term data sets. For this analysis, we used 16 one\u2010year\u2010long data sets of carbon dioxide exchange measurements from European and US\u2010American eddy covariance networks. These sites span from the boreal to Mediterranean climates, and include deciduous and evergreen forest, scrubland and crop ecosystems.We show that the temperature sensitivity of Reco, derived from long\u2010term (annual) data sets, does not reflect the short\u2010term temperature sensitivity that is effective when \u2026",
        "year": 2005,
        "authors": "Markus Reichstein and Eva Falge and Dennis Baldocchi and Dario Papale and Marc Aubinet and Paul Berbigier and Christian Bernhofer and Nina Buchmann and Tagir Gilmanov and Andre Granier and Thomas Gr\u00fcnwald and Katka Havrankova and Hannu Ilvesniemi and Dalibor Janous and Alexander Knohl and Tuomas Laurila and Annalea Lohila and Denis Loustau and Giorgio Matteucci and Tilden Meyers and Franco Miglietta and Jean\u2010Marc Ourcival and Jukka Pumpanen and Serge Rambal and Eyal Rotenberg and Maria Sanz and John Tenhunen and G\u00fcnther Seufert and Francesco Vaccari and Timo Vesala and Dan Yakir and Riccardo Valentini"
      },
      {
        "title": "Gap filling strategies for defensible annual sums of net ecosystem exchange",
        "abstract": "Heightened awareness of global change issues within both science and political communities has increased interest in using the global network of eddy covariance flux towers to more fully understand the impacts of natural and anthropogenic phenomena on the global carbon balance. Comparisons of net ecosystem exchange (FNEE) responses are being made among biome types, phenology patterns, and stress conditions. The comparisons are usually performed on annual sums of FNEE; however, the average data coverage during a year is only 65%. Therefore, robust and consistent gap filling methods are required. We review several methods of gap filling and apply them to data sets available from the EUROFLUX and AmeriFlux databases. The methods are based on mean diurnal variation (MDV), look-up tables (LookUp), and nonlinear regressions (Regr.), and the impact of different gap filling methods on the \u2026",
        "year": 2001,
        "authors": "Eva Falge and Dennis Baldocchi and Richard Olson and Peter Anthoni and Marc Aubinet and Christian Bernhofer and George Burba and Reinhart Ceulemans and Robert Clement and Han Dolman and Andr\u00e9 Granier and Patrick Gross and Thomas Gr\u00fcnwald and David Hollinger and Niels-Otto Jensen and Gabriel Katul and Petri Keronen and Andrew Kowalski and Chun Ta Lai and Beverley E Law and Tilden Meyers and John Moncrieff and Eddy Moors and J William Munger and Kim Pilegaard and \u00dcllar Rannik and Corinna Rebmann and Andrew Suyker and John Tenhunen and Kevin Tu and Shashi Verma and Timo Vesala and Kell Wilson and Steve Wofsy"
      }
    ],
    "WcpiFUQAAAAJ": [
      {
        "title": "Publishing as artistic practice",
        "abstract": "Critique d\u2019art - Actualit\u00e9 internationale de la litt\u00e9rature critique sur l\u2019art contemporain Navigation \n\u2013 Plan du site Critique d\u2019art Actualit\u00e9 internationale de la litt\u00e9rature critique sur l\u2019art contemporain \nAccueilNotes de lectureLivres collectifs2016Publishing as Artistic Practice Chercher Sommaire \n- Document pr\u00e9c\u00e9dent - Document suivant Livres collectifs 2016 Publishing as Artistic Practice \nPublishing as Artistic Practice Berlin : Sternberg Press, 2016, 304p. ill. 24 x 16cm, eng Index \nISBN : 9783956791772. _ 22,00 \u20ac Sous la dir. d\u2019Annette Gilbert Notice bibliographique \npubli\u00e9e le 21 octobre 2016 Lire l'article de Lilian Froger Publication le 30 novembre 2017 \nSommaire - Document pr\u00e9c\u00e9dent - Document suivant Notes de lecture Toutes les notes de \nlecture en ligne Livres par auteur Livres collectifs Catalogues monographiques Catalogues \ncollectifs Cr\u00e9ations de revues Index par auteurs par sujets : artistes/auteurs par \u00e9diteurs \u2026",
        "year": 2016,
        "authors": "Annette Gilbert and Hannes Bajohr and Paul Benzon and K Antranik Cassem and Bernhard Cella and Leo Findeisen and Hanna Kuusela and Antoine Lefebvre and Matt Longabucco and Alessandro Ludovico and Lucas W Melkane and Anne Moeglin-Delcroix and Aur\u00e9lie Noury and Valentina Parisi and Michalis Pichler and Anna-Sophie Springer and Alexander Starre and Nick Thurston and Rachel Valinsky and Eva Weinmayr and Vadim Zakharov"
      },
      {
        "title": "Keine Quallen: Anthropoz\u00e4n und Negative Anthropologie",
        "abstract": "August 2016 endlich die offizielle Empfehlung vor, in ihre erdgeschichtliche Periodisierung eine neue geologische Epoche einzuf\u00fchren, in der der Einfluss des Menschen im Erdstratum ablesbar geworden ist. Zuletzt hatte sich abgezeichnet, dass ihr Beginn wohl auf die j\u00fcngste Vergangenheit festgesetzt werden w\u00fcrde\u2013etwa auf die great acceleration, die industrielle Beschleunigung der Nachkriegszeit (Zalasiewicz et al. 2017) oder auf das Jahr 1945, genauer, auf den 16. Juli: Mit dem ersten Atombombentest in der W\u00fcste New Mexicos w\u00e4re der Mensch, eine Spezies, die nur 0, 01 Prozent irdischen Lebens ausmacht, zu einem geologischen Faktor geworden, dessen Existenz sich auch noch Jahrmillionen sp\u00e4ter chrono stratigrafisch identifizieren lie\u00dfe (Waters et al. 2015). Bislang aber ist das Anthropoz\u00e4n noch kein formalisierter Bestandteil des geologischen Begriffsarsenals. Stattdessen, und zum \u00c4rger vieler \u2026",
        "year": 2020,
        "authors": "Hannes Bajohr"
      }
    ],
    "tJ3oJEkAAAAJ": [
      {
        "title": "Outsourcing regulation: Analyzing nongovernmental systems of labor standards and monitoring",
        "abstract": " A range of new nongovernmental systems for advancing labor standards and enforcement have emerged over the last 5 years. This article comparatively assesses these multistakeholder systems of codes of conduct and monitoring, discusses their underlying models of regulation, and proposes a set of criteria for evaluating their effectiveness, including their legitimacy, rigor, accountability, and complementarity. Critical issues are raised about the transparency of existing initiatives, independence of monitors, convergence of standards, and dynamics among nongovernmental regulation, unions, and state enforcement. The article concludes by arguing that with increased transparency, improved technical capacities, and new mechanisms of accountability to workers and consumers, nongovernmental monitoring could complement existing state regulatory systems. ",
        "year": 2003,
        "authors": "Dara O'Rourke"
      },
      {
        "title": "Just oil? The distribution of environmental and social impacts of oil production and consumption",
        "abstract": "This review presents existing data and research on the global distribution of the impacts of oil production and consumption. The review describes and analyzes the environmental, social, and health impacts of oil extraction, transport, refining, and consumption, with a particular focus on the distribution of these burdens among socioeconomic and ethnic groups, communities, countries, and ecosystems. An environmental justice framework is used to analyze the processes influencing the distribution of harmful effects from oil production and use. A critical evaluation of current research and recommendations for future data collection and analysis on the distributional and procedural impacts of oil production and consumption conclude the review.",
        "year": 2003,
        "authors": "Dara O'Rourke and Sarah Connolly"
      },
      {
        "title": "Multi-stakeholder regulation: privatizing or socializing global labor standards?",
        "abstract": "This paper evaluates leading non-governmental labor regulation initiatives in the United States and Europe. It comparatively assesses the codes of conduct and monitoring systems within these initiatives, discusses their different models of regulation, and proposes criteria for evaluating their effectiveness. It identifies critical factors which appear to support more effective non-governmental regulation, such as substantive participation of local stakeholders; public transparency of methods and findings; and mechanisms that bring market pressures to bear on multi-national corporations, and simultaneously support processes of multi-stakeholder problem solving within factories and global supply chains.",
        "year": 2006,
        "authors": "Dara O\u2019rourke"
      }
    ],
    "UbOaNlUAAAAJ": [
      {
        "title": "Making design decisions using choosing by advantages",
        "abstract": "Choosing By Advantages (CBA) is a sound system to make decisions using welldefined vocabulary to ensure clarity and transparency in the decision-making process. Making sound design decisions aids in successful implementation of set-based design. This paper explores the use of CBA to select a design for steel reinforcement, aka. rebar, in a beam-column joint. CBA, in conjunction with set-based design, allows the engineer to explicitly consider multiple design alternatives that meet various \u2018must\u2019and \u2018want\u2019criteria. The factors and criteria developed to evaluate the design alternatives reflect the values of the various project team members involved in rebar design and construction. Because decision-making is subjective, it is important to document why and on what basis decisions are made so they can be revisited at a later time on that project, should new considerations or facts become available, and on future projects. Decision-makers using CBA list the attributes and advantages (the beneficial difference between two alternatives) of each alternative and then assign a degree of importance to each advantage relative to the one that is least preferred. The example presented herein shows that team member values may conflict, but including all perspectives in the CBA table enriches the decision-making process and cultivates a shared understanding among project team members.",
        "year": 2009,
        "authors": "Kristen Parrish and ID Tommelein"
      },
      {
        "title": "Transforming BIM to BEM: Generation of building geometry for the NASA Ames sustainability base BIM",
        "abstract": "Typical processes of whole Building Energy simulation Model (BEM) generation are subjective, labor intensive, time intensive and error prone. Essentially, these typical processes reproduce already existing data, ie building models already created by the architect. Accordingly, Lawrence Berkeley National Laboratory (LBNL) developed a semi-automated process that enables reproducible conversions of Building Information Model (BIM) representations of building geometry into a format required by building energy modeling (BEM) tools. This is a generic process that may be applied to all building energy modeling tools but to date has only been used for EnergyPlus.This report describes and demonstrates each stage in the semi-automated process for building geometry using the recently constructed NASA Ames Sustainability Base throughout. This example uses ArchiCAD (Graphisoft, 2012) as the originating CAD tool and EnergyPlus as the concluding whole building energy simulation tool. It is important to note that the process is also applicable for professionals that use other CAD tools such as Revit (\u201cRevit Architecture,\u201d 2012) and DProfiler (Beck Technology, 2012) and can be extended to provide geometry definitions for BEM tools other than EnergyPlus. Geometry Simplification Tool (GST) was used during the NASA Ames project and was the enabling software that facilitated semi-automated data transformations. GST has now been superseded by Space Boundary Tool (SBT-1) and will be referred to as SBT-1 throughout this report.",
        "year": 2013,
        "authors": "James T O'Donnell"
      },
      {
        "title": "Development of a project scope definition and assessment tool for small industrial construction projects",
        "abstract": "Front-end planning is arguably the most impactful activity in the management of construction projects. Small projects oftentimes have minimal planning completed prior to the start of the design and construction, much to the detriment of the project success. This paper summarizes the research efforts to develop a front-end planning tool specifically for small projects, namely the project definition rating index for small industrial projects (PDRI-SIP). A set of 41 specific elements relevant to the planning of SIPs was developed. Five separate workshops were held in which 65 industry professionals evaluated and prioritized the proposed elements. The tool was validated by more than 50 completed and ongoing SIPs. Statistical analysis showed that projects with better scope definition had significantly improved cost and schedule performance than projects with lesser scope definition. Comparison of front-end planning \u2026",
        "year": 2017,
        "authors": "Wesley Collins and Kristen Parrish and G Edward Gibson Jr"
      }
    ],
    "7qTg_1kAAAAJ": [
      {
        "title": "Europe-wide reduction in primary productivity caused by the heat and drought in 2003",
        "abstract": "Future climate warming is expected to enhance plant growth in temperate ecosystems and to increase carbon sequestration,. But although severe regional heatwaves may become more frequent in a changing climate,, their impact on terrestrial carbon cycling is unclear. Here we report measurements of ecosystem carbon dioxide fluxes, remotely sensed radiation absorbed by plants, and country-level crop yields taken during the European heatwave in 2003. We use a terrestrial biosphere simulation model to assess continental-scale changes in primary productivity during 2003, and their consequences for the net carbon balance. We estimate a 30 per cent reduction in gross primary productivity over Europe, which resulted in a strong anomalous net source of carbon dioxide (0.5\u2009Pg\u2009C\u2009yr-1) to the atmosphere and reversed the effect of four years of net ecosystem carbon sequestration. Our results suggest that \u2026",
        "year": 2005,
        "authors": "Ph Ciais and Markus Reichstein and Nicolas Viovy and Andr\u00e9 Granier and J\u00e9r\u00f4me Og\u00e9e and Vincent Allard and Marc Aubinet and Nina Buchmann and Chr Bernhofer and Arnaud Carrara and Fdr Chevallier and Nathalie De Noblet and Andrew D Friend and Pierre Friedlingstein and Thomas Gr\u00fcnwald and Bernard Heinesch and Petri Keronen and Alexander Knohl and Gerhard Krinner and Denis Loustau and Giovanni Manca and Giorgio Matteucci and Franco Miglietta and Jean-Marc Ourcival and Dario Papale and Kim Pilegaard and Serge Rambal and G\u00fcnther Seufert and Jean-Fran\u00e7ois Soussana and Mar\u00eda Jos\u00e9 Sanz and Ernst-Detlef Schulze and Timo Vesala and Riccardo Valentini"
      },
      {
        "title": "On the separation of net ecosystem exchange into assimilation and ecosystem respiration: review and improved algorithm",
        "abstract": "This paper discusses the advantages and disadvantages of the different methods that separate net ecosystem exchange (NEE) into its major components, gross ecosystem carbon uptake (GEP) and ecosystem respiration (Reco). In particular, we analyse the effect of the extrapolation of night\u2010time values of ecosystem respiration into the daytime; this is usually done with a temperature response function that is derived from long\u2010term data sets. For this analysis, we used 16 one\u2010year\u2010long data sets of carbon dioxide exchange measurements from European and US\u2010American eddy covariance networks. These sites span from the boreal to Mediterranean climates, and include deciduous and evergreen forest, scrubland and crop ecosystems.We show that the temperature sensitivity of Reco, derived from long\u2010term (annual) data sets, does not reflect the short\u2010term temperature sensitivity that is effective when \u2026",
        "year": 2005,
        "authors": "Markus Reichstein and Eva Falge and Dennis Baldocchi and Dario Papale and Marc Aubinet and Paul Berbigier and Christian Bernhofer and Nina Buchmann and Tagir Gilmanov and Andre Granier and Thomas Gr\u00fcnwald and Katka Havrankova and Hannu Ilvesniemi and Dalibor Janous and Alexander Knohl and Tuomas Laurila and Annalea Lohila and Denis Loustau and Giorgio Matteucci and Tilden Meyers and Franco Miglietta and Jean\u2010Marc Ourcival and Jukka Pumpanen and Serge Rambal and Eyal Rotenberg and Maria Sanz and John Tenhunen and G\u00fcnther Seufert and Francesco Vaccari and Timo Vesala and Dan Yakir and Riccardo Valentini"
      },
      {
        "title": "Terrestrial gross carbon dioxide uptake: global distribution and covariation with climate",
        "abstract": "Terrestrial gross primary production (GPP) is the largest global CO2 flux driving several ecosystem functions. We provide an observation-based estimate of this flux at 123 \u00b1 8 petagrams of carbon per year (Pg C year\u22121) using eddy covariance flux data and various diagnostic models. Tropical forests and savannahs account for 60%. GPP over 40% of the vegetated land is associated with precipitation. State-of-the-art process-oriented biosphere models used for climate predictions exhibit a large between-model variation of GPP\u2019s latitudinal patterns and show higher spatial correlations between GPP and precipitation, suggesting the existence of missing processes or feedback mechanisms which attenuate the vegetation response to climate. Our estimates of spatially distributed GPP and its covariation with climate can help improve coupled climate\u2013carbon cycle process models.",
        "year": 2010,
        "authors": "Christian Beer and Markus Reichstein and Enrico Tomelleri and Philippe Ciais and Martin Jung and Nuno Carvalhais and Christian R\u00f6denbeck and M Altaf Arain and Dennis Baldocchi and Gordon B Bonan and Alberte Bondeau and Alessandro Cescatti and Gitta Lasslop and Anders Lindroth and Mark Lomas and Sebastiaan Luyssaert and Hank Margolis and Keith W Oleson and Olivier Roupsard and Elmar Veenendaal and Nicolas Viovy and Christopher Williams and F Ian Woodward and Dario Papale"
      }
    ],
    "PFQE6v8AAAAJ": [
      {
        "title": "Conspiracy in the time of corona: automatic detection of emerging COVID-19 conspiracy theories in social media and the news",
        "abstract": "Rumors and conspiracy theories thrive in environments of low confidence and low trust. Consequently, it is not surprising that ones related to the COVID-19 pandemic are proliferating given the lack of scientific consensus on the virus\u2019s spread and containment, or on the long-term social and economic ramifications of the pandemic. Among the stories currently circulating in US-focused social media forums are ones suggesting that the 5G telecommunication network activates the virus, that the pandemic is a hoax perpetrated by a global cabal, that the virus is a bio-weapon released deliberately by the Chinese, or that Bill Gates is using it as cover to launch a broad vaccination program to facilitate a global surveillance regime. While some may be quick to dismiss these stories as having little impact on real-world behavior, recent events including the destruction of cell phone towers, racially fueled attacks against Asian \u2026",
        "year": 2020,
        "authors": "Shadi Shahsavari and Pavan Holur and Tianyi Wang and Timothy R Tangherlini and Vwani Roychowdhury"
      },
      {
        "title": "An automated pipeline for character and relationship extraction from readers literary book reviews on goodreads. com",
        "abstract": "Reader reviews of literary fiction on social media, especially those in persistent, dedicated forums, create and are in turn driven by underlying narrative frameworks. In their comments about a novel, readers generally include only a subset of characters and their relationships, thus offering a limited perspective on that work. Yet in aggregate, these reviews capture an underlying narrative framework comprised of different actants (people, places, things), their roles, and interactions that we label the \u201cconsensus narrative framework\u201d. We represent this framework in the form of an actant-relationship story graph. Extracting this graph is a challenging computational problem, which we pose as a latent graphical model estimation problem. Posts and reviews are viewed as samples of sub graphs/networks of the hidden narrative framework. Inspired by the qualitative narrative theory of Greimas, we formulate a graphical \u2026",
        "year": 2020,
        "authors": "Shadi Shahsavari and Ehsan Ebrahimzadeh and Behnam Shahbazi and Misagh Falahi and Pavan Holur and Roja Bandari and Timothy R. Tangherlini and Vwani Roychowdhury"
      }
    ],
    "2hjzVM8AAAAJ": [
      {
        "title": "Productivity improvement in construction",
        "abstract": "Productivity improvement in construction | CiNii Research CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\n\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u8a73\u7d30\u3078\u79fb\u52d5 \u691c\u7d22\u30d5\u30a9\u30fc\u30e0\u3078\u79fb\u52d5 \u8ad6\u6587\u30fb\u30c7\u30fc\u30bf\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \n\u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 English \u691c\u7d22 \u30bf\u30a4\u30c8\u30eb \u4eba\u7269/\u56e3\u4f53\u540d \u6240\u5c5e\u6a5f\u95a2 ISSN DOI \u671f\u9593 ~ \u672c\u6587\u30ea\u30f3\u30af \n\u672c\u6587\u30ea\u30f3\u30af\u3042\u308a \u30c7\u30fc\u30bf\u30bd\u30fc\u30b9 JaLC IRDB Crossref DataCite NDL NDL-Digital RUDA JDCat NINJAL \nCiNii Articles CiNii Books CiNii Dissertations DBpedia Nikkei BP KAKEN Integbio MDR PubMed \nLSDB Archive \u6975\u5730\u7814ADS \u6975\u5730\u7814\u5b66\u8853DB \u516c\u5171\u30c7\u30fc\u30bf\u30ab\u30bf\u30ed\u30b0 \u30e0\u30fc\u30f3\u30b7\u30e7\u30c3\u30c8\u578b\u7814\u7a76\u958b\u767a\u4e8b\u696d \n\u3059\u3079\u3066 \u7814\u7a76\u30c7\u30fc\u30bf \u8ad6\u6587 \u672c \u535a\u58eb\u8ad6\u6587 \u30d7\u30ed\u30b8\u30a7\u30af\u30c8 [2023\u5e7410\u670831\u65e5\u63b2\u8f09]CiNii Dissertations\u53ca\u3073\nCiNii Books\u306eCiNii Research\u3078\u306e\u7d71\u5408\u306b\u3064\u3044\u3066 \u65b0\u300c\u56fd\u7acb\u56fd\u4f1a\u56f3\u66f8\u9928\u30b5\u30fc\u30c1\u300d\u516c\u958b\u306b\u3088\u308b\nCiNii\u30b5\u30fc\u30d3\u30b9\u3078\u306e\u5f71\u97ff\u306b\u3064\u3044\u3066 Productivity improvement in construction Web Site CiNii \u6240\u8535\u9928 \n3\u9928 Oglesby, Clarkson Hill Parker, Henry W. Howell, Gregory A. \u66f8\u8a8c\u4e8b\u9805 \u30bf\u30a4\u30c8\u30eb \"Productivity \u2026",
        "year": 1989,
        "authors": "Clarkson Hill Oglesby and Henry W Parker and Gregory A Howell"
      },
      {
        "title": "The underlying theory of project management is obsolete",
        "abstract": "In prior literature, it has been generally seen that there is no explicit theory of project management. We contend that it is possible to precisely point out the underlying theoretical foundation of project management as espoused in the PMBOK Guide by PMI and mostly applied in practice. This foundation can be divided into a theory of project and a theory of management. We link theories to the body of knowledge by comparing prescriptions derived from theory to prescriptions presented in the PMBOK. Secondly, we show, by a comparison to competing theories and by an analysis of anomalies (deviations from assumptions or outcomes as implied in the body of knowledge) observed in project management practice, that this foundation is obsolete and has to be substituted by a wider and more powerful theoretical foundation.",
        "year": 2002,
        "authors": "Lauri J Koskela and Gregory Howell"
      },
      {
        "title": "What is lean construction-1999",
        "abstract": "The origins of lean production are reviewed and a claim made that it is a new form of production management, that is neither mass nor craft. Then the applicability of lean production in construction is considered and nature of lean construction discussed in comparison with current practice.",
        "year": 1999,
        "authors": "Gregory A Howell"
      }
    ],
    "FBtKFBQAAAAJ": [
      {
        "title": "Probabilistic seismic demand model for California highway bridges",
        "abstract": "A performance-based seismic design method enables designers to evaluate a graduated suite of performance levels for a structure in a given hazard environment. The Pacific Earthquake Engineering Research Center is developing a framework for performance-based seismic design. One component of this framework is a probabilistic seismic demand model for a class of structures in an urban region with a well-defined seismic hazard exposure. A probabilistic seismic demand model relates ground motion intensity measures to structural demand measures. It is formulated by statistically analyzing the results of a suite of nonlinear time-history analyses of typical structures under expected earthquakes in the urban region. An example of a probabilistic seismic demand model for typical highway bridges in California is presented. It was formulated using a portfolio of 80 recorded ground motions and a portfolio of 108 \u2026",
        "year": 2001,
        "authors": "Kevin Mackie and Bo\u017eidar Stojadinovi\u0107"
      },
      {
        "title": "Shear strength of normal and high-strength fiber reinforced concrete beams without stirrups",
        "abstract": "Shear Strength of Normal and High-Strength Fiber Reinforced Concrete Beams without Stirrups \nSearch Subscribe to Email \u200b\u25bc Membership Membership In today\u2019s market, it is imperative to \nbe knowledgeable and have an edge over the competition. ACI members have it\u2026they are \nengaged, informed, and stay up to date by taking advantage of benefits that ACI membership \nprovides them. Read more about membership Types of Membership Individual Student \nYoung Professional Organizational Sustaining ACI MEMBERSHIP Enjoy the benefits of an \nACI Membership Learn More Become an ACI Member Member Directory Sustaining Members \nHonors and Awards Career Center About ACI The American Concrete Institute Founded in \n1904 and headquartered in Farmington Hills, Michigan, USA, the American Concrete Institute \nis a leading authority and resource worldwide for the development, dissemination, and \u2026",
        "year": 1999,
        "authors": "Madhusudan Khuntia and Bozidar Stojadinovic and Subhash C Goel"
      }
    ],
    "J2KWqAoAAAAJ": [
      {
        "title": "FLUXNET: a new tool to study the temporal and spatial variability of ecosystem-scale carbon dioxide, water vapor, and energy flux densities",
        "abstract": "FLUXNET is a global network of micrometeorological flux measurement sites that measure the exchanges of carbon dioxide, water vapor, and energy between the biosphere and atmosphere. At present over 140 sites are operating on a long-term and continuous basis. Vegetation under study includes temperate conifer and broadleaved (deciduous and evergreen) forests, tropical and boreal forests, crops, grasslands, chaparral, wetlands, and tundra. Sites exist on five continents and their latitudinal distribution ranges from 70\u00b0N to 30\u00b0S.             FLUXNET has several primary functions. First, it provides infrastructure for compiling, archiving, and distributing carbon, water, and energy flux measurement, and meteorological, plant, and soil data to the science community. (Data and site information are available online at the FLUXNET Web site,             http://www-eosdis.ornl.gov/FLUXNET/             .) Second, the \u2026",
        "year": 2001,
        "authors": "Dennis Baldocchi and Eva Falge and Lianhong Gu and Richard Olson and David Hollinger and Steve Running and Peter Anthoni and Ch Bernhofer and Kenneth Davis and Robert Evans and Jose Fuentes and Allen Goldstein and Gabriel Katul and Beverly Law and Xuhui Lee and Yadvinder Malhi and Tilden Meyers and William Munger and Walt Oechel and KT Paw and Kim Pilegaard and HP Schmid and Riccardo Valentini and Shashi Verma and Timo Vesala and Kell Wilson and Steve Wofsy"
      },
      {
        "title": "Energy balance closure at FLUXNET sites",
        "abstract": "A comprehensive evaluation of energy balance closure is performed across 22 sites and 50 site-years in FLUXNET, a network of eddy covariance sites measuring long-term carbon and energy fluxes in contrasting ecosystems and climates. Energy balance closure was evaluated by statistical regression of turbulent energy fluxes (sensible and latent heat (LE)) against available energy (net radiation, less the energy stored) and by solving for the energy balance ratio, the ratio of turbulent energy fluxes to available energy. These methods indicate a general lack of closure at most sites, with a mean imbalance in the order of 20%. The imbalance was prevalent in all measured vegetation types and in climates ranging from Mediterranean to temperate and arctic. There were no clear differences between sites using open and closed path infrared gas analyzers. At a majority of sites closure improved with turbulent intensity \u2026",
        "year": 2002,
        "authors": "Kell Wilson and Allen Goldstein and Eva Falge and Marc Aubinet and Dennis Baldocchi and Paul Berbigier and Christian Bernhofer and Reinhart Ceulemans and Han Dolman and Chris Field and Achim Grelle and Andreas Ibrom and BE Law and Andy Kowalski and Tilden Meyers and John Moncrieff and Russ Monson"
      },
      {
        "title": "Recent decline in the global land evapotranspiration trend due to limited moisture supply",
        "abstract": "More than half of the solar energy absorbed by land surfaces is currently used to evaporate water. Climate change is expected to intensify the hydrological cycle and to alter evapotranspiration, with implications for ecosystem services and feedback to regional and global climate. Evapotranspiration changes may already be under way, but direct observational constraints are lacking at the global scale. Until such evidence is available, changes in the water cycle on land\u2014a key diagnostic criterion of the effects of climate change and variability\u2014remain uncertain. Here we provide a data-driven estimate of global land evapotranspiration from 1982 to 2008, compiled using a global monitoring network, meteorological and remote-sensing observations, and a machine-learning algorithm. In addition, we have assessed evapotranspiration variations over the same time period using an ensemble of process-based land \u2026",
        "year": 2010,
        "authors": "Martin Jung and Markus Reichstein and Philippe Ciais and Sonia I Seneviratne and Justin Sheffield and Michael L Goulden and Gordon Bonan and Alessandro Cescatti and Jiquan Chen and Richard De Jeu and A Johannes Dolman and Werner Eugster and Dieter Gerten and Damiano Gianelle and Nadine Gobron and Jens Heinke and John Kimball and Beverly E Law and Leonardo Montagnani and Qiaozhen Mu and Brigitte Mueller and Keith Oleson and Dario Papale and Andrew D Richardson and Olivier Roupsard and Steve Running and Enrico Tomelleri and Nicolas Viovy and Ulrich Weber and Christopher Williams and Eric Wood and S\u00f6nke Zaehle and Ke Zhang"
      }
    ],
    "NoTPL0wAAAAJ": [
      {
        "title": "The foundations of lean construction",
        "abstract": "Editorial comment Building designers are often criticized for producing fanciful or elaborate schemes with scant regard for the problems that will be faced by the contractors who have to build them. Fortunately the determination of architects, often with the support of visionary engineers, has allowed building design to evolve and made possible the realization of such landmark projects as the Guggenheim Museum in Bilbao, Sydney Opera House and the Hong Kong and Shanghai Bank.",
        "year": 2007,
        "authors": "Lauri Koskela and Greg Howell and Glenn Ballard and Iris Tommelein"
      },
      {
        "title": "Pull-driven scheduling for pipe-spool installation: Simulation of lean construction technique",
        "abstract": "Many construction processes include installation of unique materials in specific locations in the facility being built; materials and locations must match before installation can take place. Mismatches due to delay and uncertainty in supplying materials or completing prerequisite work at those locations hamper field productivity. This is illustrated here using a model of a materials-management process with a matching problem that typifies fast-track process-plant projects. The uniqueness of materials and locations combined with the unpredictability in duration and variation in execution quality of various steps in the supply chain allow for different ways to sequence material delivery and work area completion. Several alternatives are described. Their impact on process execution is illustrated by means of probabilistic process models. One model reflects a total lack of coordination between delivery and work area \u2026",
        "year": 1998,
        "authors": "Iris D Tommelein"
      },
      {
        "title": "Parade game: Impact of work flow variability on trade performance",
        "abstract": "The Parade Game illustrates the impact work flow variability has on the performance of construction trades and their successors. The game consists of simulating a construction process in which resources produced by one trade are prerequisite to work performed by the next trade. Production-level detail, describing resources being passed from one trade to the next, illustrates that throughput will be reduced, project completion delayed, and waste increased by variations in flow. The game shows that it is possible to reduce waste and shorten project duration by reducing the variability in work flow between trades. Basic production management concepts are thus applied to construction management. They highlight two shortcomings of using the critical-path method for field-level planning: The critical-path method makes modeling the dependence of ongoing activities between trades or with operations unwieldy and it \u2026",
        "year": 1999,
        "authors": "Iris D Tommelein and David R Riley and Greg A Howell"
      }
    ],
    "glDysGkAAAAJ": [
      {
        "title": "History, Metaphors, Fables: A Hans Blumenberg Reader",
        "abstract": "History, Metaphors, Fables collects the central writings by Hans Blumenberg and covers topics such as on the philosophy of language, metaphor theory, non-conceptuality, aesthetics, politics, and literary studies. This landmark volume demonstrates Blumenberg's intellectual breadth and gives an overview of his thematic and stylistic range over four decades. Blumenberg's early philosophy of technology becomes tangible, as does his critique of linguistic perfectibility and conceptual thought, his theory of history as successive concepts of reality\", his anthropology, or his studies of literature. History, Metaphors, Fables allows readers to discover a master thinker whose role in the German intellectual post-war scene can hardly be overestimated.",
        "year": 2020,
        "authors": "Joe Paul Kroll and Florian Fuchs and Hannes Bajohr and Hans Blumenberg"
      },
      {
        "title": "Novella",
        "abstract": "Given its brevity, the novella has been newly rediscovered as \u201cthe original# Longread,\u201d 1 an appellation that fits neatly into its centuries-long genealogy. Before there were hashtags, the novella has been described as many things: an anecdote retold, the sister of drama, a short novel, a story readable in a single sitting, an unprecedented incident, or simply as a piece of news. Curiously, these alternative titles point to no common feature, except one: novellas seem to be defined with respect to other genres. This is perhaps most true of the rapprochement of the novella and the short novel, which has proven so intuitive that its comparative nature is often forgotten and \u201cnovella\u201d used interchangeably with \u201cshort novel.\u201d On the contrary, a novella and a novel, however long or short, are very different things. What helps these and other false equations cohere is that novellas have gained their specific features, including the \u2026",
        "year": 2019,
        "authors": "Florian Fuchs"
      },
      {
        "title": "Civic Storytelling: The Rise of Short Forms and the Agency of Literature",
        "abstract": "A deep history of storytelling as a civic agency, recalibrating literature\u2019s political role for the twenty-first century Why did short narrative forms like the novella, fable, and fairy tale suddenly emerge around 1800 as genres symptomatic of literature\u2019s role in life and society? In order to explain their rapid ascent to such importance, Florian Fuchs identifies an essential role of literature, a role traditionally performed within classical civic discourse of storytelling, by looking at new or updated forms of this civic practice in modernity. Fuchs's focus in this groundbreaking book is on the fate of topical speech, on what is exchanged between participants in argument or conversation as opposed to rhetorical speech, which emanates from and ensures political authority. He shows how after the decline of the Ars topica in the eighteenth century, various forms of literary speech took up the role of topical speech that Aristotle had originally identified. Thus, his book outlines a genealogy of various literary short forms\u2014from fable, fairy tale, and novella to twenty-first century video storytelling\u2014that attempted on both\" high\" and\" low\" levels of culture to exercise again the social function of topical speech. Some of the specific texts analyzed include the novellas of Theodor Storm and the novella-like lettre de cachet, proverbial fictions of Gustave Flaubert and Gottfried Keller, the fairy tale as rediscovered by Vladimir Propp and Walter Benjamin, the epiphanies of James Joyce, and the video narratives of Hito Steyerl.",
        "year": 2023,
        "authors": "Florian Fuchs"
      }
    ],
    "s7gOlh8AAAAJ": [
      {
        "title": "Persistent activity in the prefrontal cortex during working memory",
        "abstract": "The dorsolateral prefrontal cortex (DLPFC) plays a crucial role in working memory. Notably, persistent activity in the DLPFC is often observed during the retention interval of delayed response tasks. The code carried by the persistent activity remains unclear, however. We critically evaluate how well recent findings from functional magnetic resonance imaging studies are compatible with current models of the role of the DLFPC in working memory. These new findings suggest that the DLPFC aids in the maintenance of information by directing attention to internal representations of sensory stimuli and motor plans that are stored in more posterior regions.",
        "year": 2003,
        "authors": "Clayton E Curtis and Mark D'Esposito"
      },
      {
        "title": "Role of left inferior prefrontal cortex in retrieval of semantic knowledge: a reevaluation",
        "abstract": "A number of neuroimaging findings have been interpreted as evidence that the left inferior frontal gyrus (IFG) subserves retrieval of semantic knowledge. We provide a fundamentally different interpretation, that it is not retrieval of semantic knowledge per se that is associated with left IFG activity but rather selection of information among competing alternatives from semantic memory. Selection demands were varied across three semantic tasks in a single group of subjects. Functional magnetic resonance imaging signal in overlapping regions of left IFG was dependent on selection demands in all three tasks. In addition, the degree of semantic processing was varied independently of selection demands in one of the tasks. The absence of left IFG activity for this comparison counters the argument that the effects of selection can be attributed solely to variations in degree of semantic retrieval. Our findings suggest that it is \u2026",
        "year": 1997,
        "authors": "Sharon L Thompson-Schill and Mark D\u2019Esposito and Geoffrey K Aguirre and Martha J Farah"
      },
      {
        "title": "The neural basis of the central executive system of working memory",
        "abstract": "WORKING memory refers to a system for temporary storage and manipulation of information in the brain, a function critical for a wide range of cognitive operations. It has been proposed that working memory includes a central executive system (CES) to control attention and information flow to and from verbal and spatial short-term memory buffers1. Although the prefrontal cortex is activated during both verbal and spatial passive working memory tasks2\u20138, the brain regions involved in the CES component of working memory have not been identified. We have used functional magnetic resonance imaging (fMRI) to examine brain activation during the concurrent performance of two tasks, which is expected to engage the CES. Activation of the prefrontal cortex was observed when both tasks are performed together, but not when they are performed separately. These results support the view that the prefrontal cortex is \u2026",
        "year": 1995,
        "authors": "Mark D'esposito and John A Detre and David C Alsop and Robert K Shin and Scott Atlas and Murray Grossman"
      }
    ],
    "Yokdc8IAAAAJ": [
      {
        "title": "Ocean one: A robotic avatar for oceanic discovery",
        "abstract": "The promise of oceanic discovery has long intrigued scientists and explorers, whether with the idea of studying underwater ecology and climate change or with the hope of uncovering natural resources and historic secrets buried deep in archaeological sites. This quest to explore the oceans requires skilled human access, yet much of the oceans are inaccessible to human divers; nearly ninetenths of the ocean floor is at 1 km or deeper [1]. Accessing these depths is imperative since factors such as pollution and deep-sea trawling threaten ecology and archaeological sites. While remotely operated vehicles (ROVs) are inadequate for the task, a robotic avatar could go where humans cannot and still embody human intelligence and intentions through immersive interfaces.",
        "year": 2016,
        "authors": "Oussama Khatib and Xiyang Yeh and Gerald Brantner and Brian Soe and Boyeon Kim and Shameek Ganguly and Hannah Stuart and Shiquan Wang and Mark Cutkosky and Aaron Edsinger and Phillip Mullins and Mitchell Barham and Christian R Voolstra and Khaled Nabil Salama and Michel l'Hour and Vincent Creuze"
      },
      {
        "title": "AQUALOC: An underwater dataset for visual\u2013inertial\u2013pressure localization",
        "abstract": "We present a new dataset, dedicated to the development of simultaneous localization and mapping methods for underwater vehicles navigating close to the seabed. The data sequences composing this dataset are recorded in three different environments: a harbor at a depth of a few meters, a first archeological site at a depth of 270 meters, and a second site at a depth of 380 meters. The data acquisition is performed using remotely operated vehicles equipped with a monocular monochromatic camera, a low-cost inertial measurement unit, a pressure sensor, and a computing unit, all embedded in a single enclosure. The sensors\u2019 measurements are recorded synchronously on the computing unit and 17 sequences have been created from all the acquired data. These sequences are made available in the form of ROS bags and as raw data. For each sequence, a trajectory has also been computed offline using a \u2026",
        "year": 2019,
        "authors": "Maxime Ferrera and Vincent Creuze and Julien Moras and Pauline Trouv\u00e9-Peloux"
      },
      {
        "title": "Adaptive disturbance observer for trajectory tracking control of underwater vehicles",
        "abstract": "Complex and highly coupled dynamics, time-variance, unpredictable disturbances and lack of knowledge of hydrodynamic parameters, complicate the control of underwater vehicles. This paper deals with the adaptive disturbance observer design for the robust trajectory tracking problem for underwater vehicles in presence of unknown external disturbances and parametric uncertainties. First, the dynamics of the vehicle is transformed into the so-called regular form. Then, based on the Extended State Observer technique and High Order Sliding Modes Control, a disturbance observer is proposed. Furthermore, the gains of the observer are automatically adjusted by the introduction of an adaption law. The stability of the whole controller/observer scheme is proven using Lyapunov\u2019s arguments. The adaptive disturbance observer aims to improve the Backstepping and nonlinear PD controllers. Real-Time experiments \u2026",
        "year": 2020,
        "authors": "Jesus Guerrero and J Torres and Vincent Creuze and Ahmed Chemori"
      }
    ],
    "qIg8KFYAAAAJ": [
      {
        "title": "On grasp choice, grasp models, and the design of hands for manufacturing tasks.",
        "abstract": "Current analytical models of grasping and manipulation with robotic hands contain simplifications and assumptions that limit their application to manufacturing environments. Ta evaluate these models, a study was undertaken of the grasps used by machinists in a small batch manufacturing operation. Based on the study, a taxonomy of grasps was constructed. An expert system also was developed to clarify the issues involved in human grasp choice. Comparisons of the grasp taxonomy, the expert system and grasp quality measures derived from the analytic models reveal that the analytic measures are useful for describing grasps in manufacturing tasks, despite the limitations in the models. In addition, the grasp taxonomy provides insights for the design of versatile robotic hands for manufacturing.",
        "year": 1989,
        "authors": "Mark R Cutkosky"
      },
      {
        "title": "PACT: An experiment in integrating concurrent engineering systems",
        "abstract": "The Palo Alto Collaborative Testbed (PACT), a concurrent engineering infrastructure that encompasses multiple sites, subsystems, and disciplines, is discussed. The PACT systems include NVisage, a distributed knowledge-based integration environment for design tools; DME (Device Modeling Environment), a model formulation and simulation environment; Next-Cut, a mechanical design and process planning system; and Designworld, a digital electronics design, simulation, assembly, and testing system. The motivations for PACT and the significance of the approach for concurrent engineering is discussed. Initial experiments in distributed simulation and incremental redesign are reviewed, and PACT's agent-based architecture and lessons learned from the PACT experiments are described.< >",
        "year": 1993,
        "authors": "Mark R.  Cutkosky and Robert S.  Engelmore and Richard E Fikes and Michael R.  Genesereth and Thomas R.  Gruber and William S.  Mark and Jay M.  Tenenbaum and Jay C.  Weber"
      },
      {
        "title": "Smooth vertical surface climbing with directional adhesion",
        "abstract": " Stickybot is a bioinspired robot that climbs smooth vertical surfaces such as glass, plastic, and ceramic tile at 4 cm/s. The robot employs several design principles adapted from the gecko including a hierarchy of compliant structures, directional adhesion, and control of tangential contact forces to achieve control of adhesion. We describe the design and fabrication methods used to create underactuated, multimaterial structures that conform to surfaces over a range of length scales from centimeters to micrometers. At the finest scale, the undersides of Stickybot's toes are covered with arrays of small, angled polymer stalks. Like the directional adhesive structures used by geckos, they readily adhere when pulled tangentially from the tips of the toes toward the ankles; when pulled in the opposite direction, they release. Working in combination with the compliant structures and directional adhesion is a force control strategy \u2026",
        "year": 2008,
        "authors": "Sangbae Kim and Matthew Spenko and Salomon Trujillo and Barrett Heyneman and Daniel Santos and Mark R Cutkosky"
      }
    ],
    "8dHy9FAAAAAJ": [
      {
        "title": "Risk premiums in dynamic term structure models with unspanned macro risks",
        "abstract": "This paper quantifies how variation in economic activity and inflation in the United States influences the market prices of level, slope, and curvature risks in Treasury markets. We develop a novel arbitrage\u2010free dynamic term structure model in which bond investment decisions are influenced by output and inflation risks that are unspanned by (imperfectly correlated with) information about the shape of the yield curve. Our model reveals that, between 1985 and 2007, these risks accounted for a large portion of the variation in forward terms premiums, and there was pronounced cyclical variation in the market prices of level and slope risks.",
        "year": 2014,
        "authors": "Scott Joslin and Marcel Priebsch and Kenneth Singleton"
      },
      {
        "title": "A new perspective on Gaussian dynamic term structure models",
        "abstract": "In any canonical Gaussian dynamic term structure model (GDTSM), the conditional forecasts of the pricing factors are invariant to the imposition of no-arbitrage restrictions. This invariance is maintained even in the presence of a variety of restrictions on the factor structure of bond yields. To establish these results, we develop a novel canonical GDTSM in which the pricing factors are observable portfolios of yields. For our normalization, standard maximum likelihood algorithms converge to the global optimum almost instantaneously. We present empirical estimates and out-of-sample forecasts for several GDTSMs using data on U.S. Treasury bond yields.",
        "year": 2011,
        "authors": "Scott Joslin and Kenneth J Singleton and Haoxiang Zhu"
      },
      {
        "title": "Rare disasters and risk sharing with heterogeneous beliefs",
        "abstract": "Risks of rare economic disasters can have a large impact on asset prices. At the same time, difficulties in inference regarding both the likelihood and severity of disasters, as well as agency problems, can lead to significant disagreements among investors about disaster risk. We show that such disagreements generate strong risk-sharing motives, such that just a small number of optimists in the economy will significantly reduce the disaster risk premium. Our model highlights the \u201clatent\u201d nature of disaster risk. The disaster risk premium will likely be low and smooth during normal times but increases dramatically when the risk-sharing capacity of the optimists is reduced, e.g., following a disaster. The model also helps reconcile the difference in the amount of disaster risk implied by financial markets and international macroeconomic data, and provides caution to the approach of extracting disaster probabilities from \u2026",
        "year": 2012,
        "authors": "Hui Chen and Scott Joslin and Ngoc-Khanh Tran"
      }
    ],
    "BnaRir8AAAAJ": [
      {
        "title": "Ocean one: A robotic avatar for oceanic discovery",
        "abstract": "The promise of oceanic discovery has long intrigued scientists and explorers, whether with the idea of studying underwater ecology and climate change or with the hope of uncovering natural resources and historic secrets buried deep in archaeological sites. This quest to explore the oceans requires skilled human access, yet much of the oceans are inaccessible to human divers; nearly ninetenths of the ocean floor is at 1 km or deeper [1]. Accessing these depths is imperative since factors such as pollution and deep-sea trawling threaten ecology and archaeological sites. While remotely operated vehicles (ROVs) are inadequate for the task, a robotic avatar could go where humans cannot and still embody human intelligence and intentions through immersive interfaces.",
        "year": 2016,
        "authors": "Oussama Khatib and Xiyang Yeh and Gerald Brantner and Brian Soe and Boyeon Kim and Shameek Ganguly and Hannah Stuart and Shiquan Wang and Mark Cutkosky and Aaron Edsinger and Phillip Mullins and Mitchell Barham and Christian R Voolstra and Khaled Nabil Salama and Michel l'Hour and Vincent Creuze"
      },
      {
        "title": "Variable radius pulley design methodology for pneumatic artificial muscle-based antagonistic actuation systems",
        "abstract": "There is a growing interest in utilizing pneumatic artificial muscles (PAMs) as actuators for human-friendly robots. However, several performance drawbacks prevent the widespread use of PAMs. Although many approaches have been proposed to overcome the low control bandwidth of PAMs, some limitations of PAMs such as restricted workspace and torque capacity remain to be addressed. This paper analyzes the limitations of conventional circular pulley joints and subsequently proposes a design methodology to synthesize a pair of variable radius pulleys to improve joint torque capacity over a large workspace. Experimental results show that newly synthesized variable radius pulleys significantly improve position tracking performance in the enlarged workspace.",
        "year": 2011,
        "authors": "Dongjun Shin and Xiyang Yeh and Oussama Khatib"
      },
      {
        "title": "Circular pulley versus variable radius pulley: Optimal design methodologies and dynamic characteristics analysis",
        "abstract": "Human-centered robotics has received growing interest in low-impedance actuations. In particular, pneumatic artificial muscles (PAMs) provide compliance and high force-to-weight ratio, which allow for safe actuation. However, several performance drawbacks prevent PAMs from being more pervasive. Although many approaches have been proposed to overcome the low control bandwidth of PAMs, some limitations of PAMs, such as restricted workspace and torque capacity, remain to be addressed. This paper analyzes the characteristics and limitations of PAMs-driven joints and subsequently provides an optimization strategy for circular pulleys (CPs) in order to improve joint torque capacity over a large workspace. In addition to CPs, this paper proposes a design methodology to synthesize a pair of variable radius pulleys (VRPs) for further improvement. Simulation and experimental results show that newly \u2026",
        "year": 2013,
        "authors": "Dongjun Shin and Xiyang Yeh and Oussama Khatib"
      }
    ],
    "TN09YMcAAAAJ": [
      {
        "title": "Deep reinforcement learning for building HVAC control",
        "abstract": "Buildings account for nearly 40% of the total energy consumption in the United States, about half of which is used by the HVAC (heating, ventilation, and air conditioning) system. Intelligent scheduling of building HVAC systems has the potential to significantly reduce the energy cost. However, the traditional rule-based and model-based strategies are often inefficient in practice, due to the complexity in building thermal dynamics and heterogeneous environment disturbances. In this work, we develop a data-driven approach that leverages the deep reinforcement learning (DRL) technique, to intelligently learn the effective strategy for operating the building HVAC systems. We evaluate the performance of our DRL algorithm through simulations using the widely-adopted EnergyPlus tool. Experiments demonstrate that our DRL-based algorithm is more effective in energy cost reduction compared with the traditional rule \u2026",
        "year": 2017,
        "authors": "Tianshu Wei and Yanzhi Wang and Qi Zhu"
      },
      {
        "title": "Addressing class imbalance in federated learning",
        "abstract": "Federated learning (FL) is a promising approach for training decentralized data located on local client devices while improving efficiency and privacy. However, the distribution and quantity of the training data on the clients' side may lead to significant challenges such as class imbalance and non-IID (non-independent and identically distributed) data, which could greatly impact the performance of the common model. While much effort has been devoted to helping FL models converge when encountering non-IID data, the imbalance issue has not been sufficiently addressed. In particular, as FL training is executed by exchanging gradients in an encrypted form, the training data is not completely observable to either clients or server, and previous methods for class imbalance do not perform well for FL. Therefore, it is crucial to design new methods for detecting class imbalance in FL and mitigating its impact. In this work, we propose a monitoring scheme that can infer the composition of training data for each FL round, and design a new loss function--Ratio Loss to mitigate the impact of the imbalance. Our experiments demonstrate the importance of acknowledging class imbalance and taking measures as early as possible in FL training, and the effectiveness of our method in mitigating the impact. Our method is shown to significantly outperform previous methods, while maintaining client privacy.",
        "year": 2021,
        "authors": "Lixu Wang and Shichao Xu and Xiao Wang and Qi Zhu"
      },
      {
        "title": "Period optimization for hard real-time distributed automotive systems",
        "abstract": "The complexity and physical distribution of modern active-safety automotive applications requires the use of distributed architectures. These architectures consist of multiple electronic control units (ECUs) connected with standardized buses. The most common configuration features periodic activation of tasks and messages coupled with run-time priority-based scheduling. The correct deployment of applications on such architectures requires end-to-end latency deadlines to be met. This is challenging since deadlines must be enforced across a set of ECUs and buses, each of which supports multiple functionality. The need for accommodating legacy tasks and messages further complicates the scenario.In this work, we automatically assign task and message periods for distributed automotive systems. This is accomplished by leveraging schedulability analysis within a convex optimization framework to \u2026",
        "year": 2007,
        "authors": "Abhijit Davare and Qi Zhu and Marco Di Natale and Claudio Pinello and Sri Kanajan and Alberto Sangiovanni-Vincentelli"
      }
    ],
    "6xr9l5EAAAAJ": [
      {
        "title": "Nanotechnology-based drug delivery systems",
        "abstract": "Nanoparticles hold tremendous potential as an effective drug delivery system. In this review we discussed recent developments in nanotechnology for drug delivery. To overcome the problems of gene and drug delivery, nanotechnology has gained interest in recent years. Nanosystems with different compositions and biological properties have been extensively investigated for drug and gene delivery applications. To achieve efficient drug delivery it is important to understand the interactions of nanomaterials with the biological environment, targeting cell-surface receptors, drug release, multiple drug administration, stability of therapeutic agents and molecular mechanisms of cell signalling involved in pathobiology of the disease under consideration. Several anti-cancer drugs including paclitaxel, doxorubicin, 5-fluorouracil and dexamethasone have been successfully formulated using nanomaterials \u2026",
        "year": 2007,
        "authors": "Sarabjeet Singh Suri and Hicham Fenniri and Baljit Singh"
      },
      {
        "title": "Helical rosette nanotubes: design, self-assembly, and characterization",
        "abstract": "Organic, 1 inorganic, 2 and surfactant-derived3 discrete tubular architectures have been the subject of intense investigation in the fields of materials science, nanotechnology, molecular electronic and photonic devices, sensor and artificial channel systems. Here we present evidence in support of a modus operandi for the hierarchical self-assembly of organic nanotubes from selfassembled supermacrocycles (rosettes) 3f, g, 4 of low-molecular weight synthetic modules, under physiological conditions. For a system based on hydrogen bonds to self-assemble in water one has to balance the enthalpic loss (H-bonds) with a consequent entropic gain (stacking interactions and hydrophobic effect). If preorganized, ionic H-bonds could also add to the enthalpic term. Nature has ingeniously taken advantage of these design principles to compartmentalize the cell (membranes), and to create thermodynamically favorable \u2026",
        "year": 2001,
        "authors": "Hicham Fenniri and Packiarajan Mathivanan and Kenrick L Vidale and Debra M Sherman and Klaas Hallenga and Karl V Wood and Joseph G Stowell"
      },
      {
        "title": "Helical rosette nanotubes with tunable chiroptical properties",
        "abstract": "On the basis of transmission electron microscopy (TEM), dynamic light scattering (DLS), small-angle X-ray scattering (SAXS), and circular dichroism (CD) studies, compound 1 was shown to exist mainly in two states:\u2009 (a) At high concentration (\u22651 mM, in methanol), 1 undergoes hierarchical self-assembly to generate rosette nanotubes with \u223c4 nm diameter and a concentration-dependent hydrodynamic radius in the range 10\u2212100 nm. Under these conditions, addition of a chiral amino acid promoter (l-Ala), that binds to the crown ether moiety of 1 via electrostatic interactions, promotes a rapid transition (k0 \u2248 0.48 s-1, for [1] = 0.046 mM, [l-Ala] = 2.8 mM) from racemic to chiral rosette nanotubes with predefined helicities as indicated by the resulting induced circular dichroism (ICD). (b) At low concentration (\u22640.04 mM, in methanol), 1 exists mainly in a nonassembled state as shown by TEM and DLS. Addition of l-Ala \u2026",
        "year": 2002,
        "authors": "Hicham Fenniri and Bo-Liang Deng and Alexander E Ribbe"
      }
    ],
    "nP1F-QsAAAAJ": [
      {
        "title": "Diversified farming systems: an agroecological, systems-based alternative to modern industrial agriculture",
        "abstract": "This Special Issue on Diversified Farming Systems is motivated by a desire to understand how agriculture designed according to whole systems, agroecological principles can contribute to creating a more sustainable, socially just, and secure global food system. We first define Diversified Farming Systems (DFS) as farming practices and landscapes that intentionally include functional biodiversity at multiple spatial and/or temporal scales in order to maintain ecosystem services that provide critical inputs to agriculture, such as soil fertility, pest and disease control, water use efficiency, and pollination. We explore to what extent DFS overlap or are differentiated from existing concepts such as sustainable, multifunctional, organic or ecoagriculture. DFS are components of social-ecological systems that depend on certain combinations of traditional and contemporary knowledge, cultures, practices, and governance \u2026",
        "year": 2012,
        "authors": "Claire Kremen and Alastair Iles and Christopher Bacon"
      },
      {
        "title": "The social dimensions of energy transitions",
        "abstract": "The future of energy systems is one of the central policy challenges facing industrial countries. This challenge is complex and multifaceted. Energy systems are among the largest human enterprises, comprising 9 of the 12 most heavily capitalized companies in the world. They form the heart of the technological arrangements around which contemporary industrial economies are organized. Efforts to transform energy systems involve changes, therefore, not only to energy technologies and prices but also to the broader social and economic assemblages that are built around energy production and consumption. Yet energy planning and policy rarely account for these broader dimensions of energy change. Two recent US energy reports illustrate this trend: the US National Academy of Engineering\u2019s study, America\u2019s Energy Future, and the US Department of Energy\u2019s recent review of its programs (NAE, 2009; DOE \u2026",
        "year": 2013,
        "authors": "Clark A Miller and Alastair Iles and Christopher F Jones"
      },
      {
        "title": "Expanding bioplastics production: sustainable business innovation in the chemical industry",
        "abstract": "The case of bioplastics illustrates how business models can link producers and customers through the development of new technologies and products. Chemical companies have assumed that reducing costs, increasing yields, and developing better feedstock supplies will guarantee the success of bioplastics in the market, yet a number of unconventional hurdles exist. Companies need to build markets for bioplastics and to assure customers that bioplastics are indeed sustainably made. We contend that companies are most able to develop business models that bring bioplastics to market effectively when they develop and mobilize their \u201cdynamic capabilities\u201d around sustainability. DuPont, BASF, and Braskem have identified new market opportunities for bioplastics, designed distinctive types of business models to seize these opportunities, and devised ways to create increased value by communicating performance \u2026",
        "year": 2013,
        "authors": "Alastair Iles and Abigail N Martin"
      }
    ],
    "PMwlwE0AAAAJ": [
      {
        "title": "Languages and tools for hybrid systems design",
        "abstract": "The explosive growth of embedded electronics is bringing information and control systems of increasing complexity to every aspects of our lives. The most challenging designs are safety-critical systems, such as transportation systems (eg, airplanes, cars, and trains), industrial plants and health care monitoring. The difficulties reside in accommodating constraints both on functionality and implementation. The correct behavior must be guaranteed under diverse states of the environment and potential failures; implementation has to meet cost, size, and power consumption requirements. The design is therefore subject to extensive mathematical analysis and simulation. However, traditional models of information systems do not interface well to the continuous evolving nature of the environment in which these devices operate. Thus, in practice, different mathematical representations have to be mixed to analyze the overall behavior of the system. Hybrid systems are a particular class of mixed models that focus on the combination of discrete and continuous subsystems. There is a wealth of tools and languages that have been proposed over the years to handle hybrid systems. However, each tool makes different assumptions on the environment, resulting in somewhat different notions of hybrid system. This makes it difficult to share information among tools. Thus, the community cannot maximally leverage the substantial amount of work that has been directed to this important topic. In this paper, we review and compare hybrid system tools by highlighting their differences in terms of their underlying semantics, expressive power and mathematical \u2026",
        "year": 2006,
        "authors": "Luca P Carloni and Roberto Passerone and Alessandro Pinto and Alberto L Sangiovanni-Vincentelli"
      },
      {
        "title": "Efficient synthesis of networks on chip",
        "abstract": "We propose an efficient heuristic for the constraint-driven communication synthesis (CDCS) of on-chip communication networks. The complexity of the synthesis problems comes from the number of constraints that have to be considered. We propose to cluster constraints to reduce the number that needs to be considered by the optimization algorithm. Then a quadratic programming approach is used to solve the communication synthesis problem with the clustered constraints. We provide an analytical model that justifies our choice of the clustering cost function and we discuss a set of experiments showing the effectiveness of the overall approach with respect to the exact algorithm.",
        "year": 2003,
        "authors": "Alessandro Pinto and Luca P Carloni and Alberto L Sangiovanni-Vincentelli"
      },
      {
        "title": "A next-generation design framework for platform-based design",
        "abstract": "The platform-based design methodology [1] is based on the usage of formal modeling techniques, clearly defined abstraction levels and the separation of concerns to enable an effective design process. The METROPOLIS framework embodies the platform-based design methodology and has been applied to a number of case studies across multiple domains. Based on these experiences, we have identified three key features that need to be enhanced: heterogeneous IP import, orthogonalization of performance from behavior, and design space exploration. The next generation METRO II framework incorporates these advanced features. The main concepts underlying METRO II are described in this paper and illustrated with a small example.",
        "year": 2007,
        "authors": "Abhijit Davare and Douglas Densmore and Trevor Meyerowitz and Alessandro Pinto and Alberto Sangiovanni-Vincentelli and Guang Yang and Haibo Zeng and Qi Zhu"
      }
    ],
    "j8g1fe8AAAAJ": [
      {
        "title": "C\u2212 H activation for the construction of C\u2212 B bonds",
        "abstract": "A long-standing challenge in synthetic chemistry is the direct, selective functionalization of alkyl, alkenyl, and aryl CH bonds. Much research has been devoted to the selective oxidation of alkyl CH bonds, but the development of a catalyst for the conversion of methane to methanol, for example, remains an important, unsolved problem in catalysis. 1 Several groups have made great progress toward selective conversions of aryl CH bonds to CC, CO, CN, and CX (X) F, Cl, Br, and I) bonds, 2, 3 and several groups have made progress toward the conversion of alkyl CH bonds to CC, CO, and CdC bonds. 4, 5 In contrast, the direct conversion of CH bonds to CB bonds is a more recently developed class of metal-catalyzed CH bond functionalization. Significant progress has been made toward the development of systems that catalyze such borylation reactions of CH bonds in alkanes, alkenes, and arenes in high yields \u2026",
        "year": 2010,
        "authors": "Ibraheem AI Mkhalid and Jonathan H Barnard and Todd B Marder and Jaclyn M Murphy and John F Hartwig"
      },
      {
        "title": "Organotransition metal chemistry: from bonding to catalysis",
        "abstract": "Organotransition metal chemistry : from bonding to catalysis | CiNii Research CiNii \u56fd\u7acb\u60c5\u5831\u5b66\n\u7814\u7a76\u6240 \u5b66\u8853\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u8a73\u7d30\u3078\u79fb\u52d5 \u691c\u7d22\u30d5\u30a9\u30fc\u30e0\u3078\u79fb\u52d5 \u8ad6\u6587\u30fb\u30c7\u30fc\u30bf\u3092\u3055\u304c\u3059 \u5927\u5b66\n\u56f3\u66f8\u9928\u306e\u672c\u3092\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 English \u691c\u7d22 \u30bf\u30a4\u30c8\u30eb \u4eba\u7269/\u56e3\u4f53\u540d \u6240\u5c5e\u6a5f\u95a2 ISSN \nDOI \u671f\u9593 ~ \u672c\u6587\u30ea\u30f3\u30af \u672c\u6587\u30ea\u30f3\u30af\u3042\u308a \u30c7\u30fc\u30bf\u30bd\u30fc\u30b9 JaLC IRDB Crossref DataCite NDL NDL-Digital \nRUDA JDCat NINJAL CiNii Articles CiNii Books CiNii Dissertations DBpedia Nikkei BP KAKEN \nIntegbio MDR PubMed LSDB Archive \u6975\u5730\u7814ADS \u6975\u5730\u7814\u5b66\u8853DB \u516c\u5171\u30c7\u30fc\u30bf\u30ab\u30bf\u30ed\u30b0 \u30e0\u30fc\u30f3\n\u30b7\u30e7\u30c3\u30c8\u578b\u7814\u7a76\u958b\u767a\u4e8b\u696d \u3059\u3079\u3066 \u7814\u7a76\u30c7\u30fc\u30bf \u8ad6\u6587 \u672c \u535a\u58eb\u8ad6\u6587 \u30d7\u30ed\u30b8\u30a7\u30af\u30c8 [2024\u5e747\u67082\u65e5\u66f4\u65b0]CiNii \nDissertations\u53ca\u3073CiNii Books\u306eCiNii Research\u3078\u306e\u7d71\u5408\u306b\u3064\u3044\u3066 \u65b0\u300c\u56fd\u7acb\u56fd\u4f1a\u56f3\u66f8\u9928\u30b5\u30fc\u30c1\n\u300d\u516c\u958b\u306b\u3088\u308bCiNii\u30b5\u30fc\u30d3\u30b9\u3078\u306e\u5f71\u97ff\u306b\u3064\u3044\u3066 \u5b9f\u9a13\u7684\u30b5\u30fc\u30d3\u30b9\u516c\u958b\u30b5\u30a4\u30c8\u3067\u3042\u308bCiNii Labs\u3092\u516c\u958b\u3057\u307e\n\u3057\u305f. Organotransition metal chemistry : from bonding to catalysis Web Site CiNii \u6240\u8535\u9928 43\u2026",
        "year": 2010,
        "authors": "John Frederick Hartwig"
      },
      {
        "title": "Transition metal catalyzed synthesis of arylamines and aryl ethers from aryl halides and triflates: Scope and mechanism",
        "abstract": "Oxidative addition and reductive elimination are the central steps in new palladium\u2010catalyzed chemistry that forms C\u2013N and C\u2013O bonds in arylamines and ethers. In the potential mechanism shown on the right the amine is formed by reductive elimination from a four\u2010coordinate, 16\u2010electron amido aryl complex. The use of a chelating ligand such as 1,1\u2032\u2010bis(diphenylphosphanyl)ferrocene (DPPF) reduces the occurrence of the competing \u03b2\u2010hydrogen elimination. X=Br, I; R, R\u2032=alkyl, aryl.",
        "year": 1998,
        "authors": "John F Hartwig"
      }
    ],
    "cY-UP0oAAAAJ": [
      {
        "title": "International accounting standards and accounting quality",
        "abstract": "We examine whether application of International Accounting Standards (IAS) is associated with higher accounting quality. The application of IAS reflects combined effects of features of the financial reporting system, including standards, their interpretation, enforcement, and litigation. We find that firms applying IAS from 21 countries generally evidence less earnings management, more timely loss recognition, and more value relevance of accounting amounts than do matched sample firms applying non\u2010U.S. domestic standards. Differences in accounting quality between the two groups of firms in the period before the IAS firms adopt IAS do not account for the postadoption differences. Firms applying IAS generally evidence an improvement in accounting quality between the pre\u2010 and postadoption periods. Although we cannot be sure our findings are attributable to the change in the financial reporting system rather \u2026",
        "year": 2008,
        "authors": "Mary E Barth and Wayne R Landsman and Mark H Lang"
      },
      {
        "title": "The relevance of the value relevance literature for financial accounting standard setting: another view",
        "abstract": "This paper explains that value relevance research assesses how well accounting amounts reflect information used by equity investors, and provides insights into questions of interest to standard setters. A primary focus of financial statements is equity investment. Other uses of financial statement information, such as contracting, do not diminish the importance of value relevance research. Value relevance questions can be addressed using extant valuation models. Value relevance studies address econometric issues that otherwise could limit inferences, and can accommodate and be used to study the implications of accounting conservatism.",
        "year": 2001,
        "authors": "Mary E Barth and William H Beaver and Wayne R Landsman"
      },
      {
        "title": "Market reaction to the adoption of IFRS in Europe",
        "abstract": " ABSTRACT: This study examines European stock market reactions to 16 events associated with the adoption of International Financial Reporting Standards (IFRS) in Europe. European IFRS adoption represented a major milestone toward financial reporting convergence yet spurred controversy reaching the highest levels of government. We find an incrementally positive reaction for firms with lower quality pre\u2010adoption information, which is more pronounced for banks, and with higher pre\u2010adoption information asymmetry, consistent with investors expecting net information quality benefits from IFRS adoption. We find an incrementally negative reaction for firms domiciled in code law countries, consistent with investors' concerns over enforcement of IFRS in those countries. Finally, we find a positive reaction to IFRS adoption events for firms with high\u2010quality pre\u2010adoption information, consistent with investors \u2026",
        "year": 2010,
        "authors": "Christopher S Armstrong and Mary E Barth and Alan D Jagolinzer and Edward J Riedl"
      }
    ],
    "rYBIFu8AAAAJ": [
      {
        "title": "Construction safety management",
        "abstract": "Designing safety into every facet of your construction organizationisn t just sensible, it s also profitable.... Featuring provensafety management methods gathered from fifteen years or researchat Stanford University and used by the most successful constructionmanagers in the industry, Construction Safety Management is acomprehensive blueprint for CEOs, job-site managers, foremen, safety professionals, and owners on safely managing constructionwork at every level and phase of a project. Incorporating thesemanagement practices and policies into a practical format ofreal-life case studies and summary action steps, this new updatedSecond Edition offers each member of the construction managementteam specific advice on effectively upgrading an organization stotal safety performance, including:* Building a corporate culture of zero accidents* Planning for high project performance* Establishing accountability for safety* Eliminating drugs and alcohol from the job site* Maintaining a communications safety net* Achieving the dual goal of safety and productivity* Maintaining effective crews* Measuring safety performance* Monitoring contractors for safety This new edition also reviews key requirements of the ComprehensiveSafety and Health Reform Act of 1993 and discusses the potential ofemerging management techniques and computing technologies forconstruction safety management, including Total Quality Management, partnering, robotics, automated process control, artificialintelligence, and expert systems.\" The Second Edition is even better than the first. The informationis timely but what s even more important, the techniques work!\" \u2026",
        "year": 1993,
        "authors": "Raymond Elliot Levitt and Nancy Morse Samelson"
      },
      {
        "title": "The virtual design team: A computational model of project organizations",
        "abstract": "Large scale and multidisciplinary engineering projects (e.g., design of a hospital building) are often complex. They usually involve many interdependent activities and require intensive coordination among actors (i.e., designers) to deal with activity interdependencies. To make such projects more effective and efficient, one needs to understand how coordination requirements are generated and what coordination mechanisms should be applied for given project situations. Our research on the Virtual Design Team (VDT) attempts to develop a computational model of project organizations to analyze how activity interdependencies raise coordination needs and how organization design and communication tools change team coordination capacity and project performance. The VDT model is built based on contingency theory (Galbraith, 1977) and our observations about collaborative and multidisciplinary work in \u2026",
        "year": 1996,
        "authors": "Yan Jin and Raymond E Levitt"
      },
      {
        "title": "Interpersonal trust in cross-functional, geographically distributed work: A longitudinal study",
        "abstract": "With increasing globalization and the proliferation of communication technologies, more people are working in cross-functional, geographically distributed teams. Although trust is clearly an important ingredient in these collaborations, little is known about the challenges this new work and social environment creates for the development of trust. Different disciplinary perspectives, different regional or national cultures, and the lack of face-to-face interaction when working at a distance raise significant barriers to developing trust between distant co-workers. We, therefore, posit that traditional models of trust need to be adapted to describe the development of trust between cross-functional, geographically distributed partners. To test our hypotheses, we conducted a longitudinal study of architecture, engineering and construction management students engaged in designing and planning a $5 million construction project in \u2026",
        "year": 2004,
        "authors": "Roxanne Zolin and Pamela J Hinds and Renate Fruchter and Raymond E Levitt"
      }
    ],
    "AhgjQ2QAAAAJ": [
      {
        "title": "Logic minimization algorithms for VLSI synthesis",
        "abstract": "The roots of the project which culminates with the writing of this book can be traced to the work on logic synthesis started in 1979 at the IBM Watson Research Center and at University of California, Berkeley. During the preliminary phases of these projects, the impor tance of logic minimization for the synthesis of area and performance effective circuits clearly emerged. In 1980, Richard Newton stirred our interest by pointing out new heuristic algorithms for two-level logic minimization and the potential for improving upon existing approaches. In the summer of 1981, the authors organized and participated in a seminar on logic manipulation at IBM Research. One of the goals of the seminar was to study the literature on logic minimization and to look at heuristic algorithms from a fundamental and comparative point of view. The fruits of this investigation were surprisingly abundant: it was apparent from an initial implementation of recursive logic minimiza tion (ESPRESSO-I) that, if we merged our new results into a two-level minimization program, an important step forward in automatic logic synthesis could result. ESPRESSO-II was born and an APL implemen tation was created in the summer of 1982. The results of preliminary tests on a fairly large set of industrial examples were good enough to justify the publication of our algorithms. It is hoped that the strength and speed of our minimizer warrant its Italian name, which denotes both express delivery and a specially-brewed black coffee.",
        "year": 1984,
        "authors": "Robert King Brayton"
      },
      {
        "title": "SIS: A system for sequential circuit synthesis",
        "abstract": "SIS : A system for sequential circuit synthesis | CiNii Research CiNii \u56fd\u7acb\u60c5\u5831\u5b66\u7814\u7a76\u6240 \u5b66\u8853\n\u60c5\u5831\u30ca\u30d3\u30b2\u30fc\u30bf[\u30b5\u30a4\u30cb\u30a3] \u8a73\u7d30\u3078\u79fb\u52d5 \u691c\u7d22\u30d5\u30a9\u30fc\u30e0\u3078\u79fb\u52d5 \u8ad6\u6587\u30fb\u30c7\u30fc\u30bf\u3092\u3055\u304c\u3059 \u5927\u5b66\u56f3\u66f8\u9928\u306e\u672c\u3092\n\u3055\u304c\u3059 \u65e5\u672c\u306e\u535a\u58eb\u8ad6\u6587\u3092\u3055\u304c\u3059 English \u691c\u7d22 \u30bf\u30a4\u30c8\u30eb \u4eba\u7269/\u56e3\u4f53\u540d \u6240\u5c5e\u6a5f\u95a2 ISSN DOI \u671f\u9593 ~ \n\u672c\u6587\u30ea\u30f3\u30af \u672c\u6587\u30ea\u30f3\u30af\u3042\u308a \u30c7\u30fc\u30bf\u30bd\u30fc\u30b9 JaLC IRDB Crossref DataCite NDL\u30b5\u30fc\u30c1 NDL\u30c7\u30b8\u30b3\u30ec(\u65e7\nNII-ELS) RUDA JDCat NINJAL CiNii Articles CiNii Books DBpedia Nikkei BP KAKEN Integbio \nMDR PubMed LSDB Archive \u6975\u5730\u7814ADS \u6975\u5730\u7814\u5b66\u8853DB OpenAIRE \u516c\u5171\u30c7\u30fc\u30bf\u30ab\u30bf\u30ed\u30b0 \u30e0\u30fc\u30f3\n\u30b7\u30e7\u30c3\u30c8\u578b\u7814\u7a76\u958b\u767a\u4e8b\u696d \u3059\u3079\u3066 \u7814\u7a76\u30c7\u30fc\u30bf \u8ad6\u6587 \u672c \u535a\u58eb\u8ad6\u6587 \u30d7\u30ed\u30b8\u30a7\u30af\u30c8 [2024\u5e7412\u67089\u65e5\u66f4\u65b0\n]CiNii Dissertations\u53ca\u3073CiNii Books\u306eCiNii Research\u3078\u306e\u7d71\u5408\u306b\u3064\u3044\u3066 CiNii Research\u81ea\u52d5\n\u7ffb\u8a33\u6a5f\u80fd(\u8a66\u884c\u7248)\u3092CiNii Labs\u306b\u3066\u516c\u958b\u3057\u307e\u3057\u305f \u65e5\u7d4cBP\u793e\u63d0\u4f9b\u30c7\u30fc\u30bf\u306e\u66f4\u65b0\u505c\u6b62\u53ca\u3073\u524a\u9664\u306b\u3064\u3044\u3066 \nSIS : A system for sequential circuit synthesis \u88ab\u5f15\u7528\u6587\u732e1\u4ef6 SENTOVICH ME \u53ce\u9332\u520a\u884c\u7269 \u2026",
        "year": 1992,
        "authors": "ME Sentovich"
      },
      {
        "title": "MIS: A multiple-level logic optimization system",
        "abstract": "MIS is both an interactive and a batch-oriented multilevel logic synthesis and minimization system. MIS starts from the combinational logic extracted, typically, from a high-level description of a macrocell. It produces a multilevel set of optimized logic equations preserving the input-output behavior. The system includes both fast and slower (but more optimal) versions of algorithms for minimizing the area, and global timing optimization algorithms to meet system-level timing constraints. This paper provides an overview of the system and a description of the algorithms used. Included are some examples illustrating an input language used for specifying logic and don't-cares. Parts on an industrial chip have been re-synthesized using MIS with favorable results as compared to equivalent manual designs.",
        "year": 2004,
        "authors": "Robert K Brayton and Richard Rudell and Alberto Sangiovanni-Vincentelli and Albert R Wang"
      }
    ],
    "zb2kBYgAAAAJ": [
      {
        "title": "Scaling up digital circuit computation with DNA strand displacement cascades",
        "abstract": "To construct sophisticated biochemical circuits from scratch, one needs to understand how simple the building blocks can be and how robustly such circuits can scale up. Using a simple DNA reaction mechanism based on a reversible strand displacement process, we experimentally demonstrated several digital logic circuits, culminating in a four-bit square-root circuit that comprises 130 DNA strands. These multilayer circuits include thresholding and catalysis within every logical operation to perform digital signal restoration, which enables fast and reliable function in large circuits with roughly constant switching time and linear signal propagation delays. The design naturally incorporates other crucial elements for large-scale circuitry, such as general debugging tools, parallel circuit preparation, and an abstraction hierarchy supported by an automated circuit compiler.",
        "year": 2011,
        "authors": "Lulu Qian and Erik Winfree"
      },
      {
        "title": "Neural network computation with DNA strand displacement cascades",
        "abstract": "The impressive capabilities of the mammalian brain\u2014ranging from perception, pattern recognition and memory formation to decision making and motor activity control\u2014have inspired their re-creation in a wide range of artificial intelligence systems for applications such as face recognition, anomaly detection, medical diagnosis and robotic vehicle control. Yet before neuron-based brains evolved, complex biomolecular circuits provided individual cells with the \u2018intelligent\u2019 behaviour required for survival. However, the study of how molecules can \u2018think\u2019 has not produced an equal variety of computational models and applications of artificial chemical systems. Although biomolecular systems have been hypothesized to carry out neural-network-like computations in vivo,, and the synthesis of artificial chemical analogues has been proposed theoretically,,,,, experimental work,,, has so far fallen short of fully implementing \u2026",
        "year": 2011,
        "authors": "Lulu Qian and Erik Winfree and Jehoshua Bruck"
      },
      {
        "title": "A cargo-sorting DNA robot",
        "abstract": "Since the 1980s, the design and synthesis of molecular machines has been identified as a grand challenge for molecular engineering. Robots are an important type of molecular machine that automatically carry out complex nanomechanical tasks. DNA molecules are excellent materials for building molecular robots, because their geometric, thermodynamic, and kinetic properties are well understood and highly programmable. So far, the development of DNA robots has been limited to simple functions. Most DNA robots were designed to perform a single function: walking in a controlled direction. A few demonstrations included a second function combined with walking (for example, picking up nanoparticles or choosing a path at a junction). However, these relatively more complex functions were also more difficult to control, and the complexity of the tasks was limited to what the robot can perform \u2026",
        "year": 2017,
        "authors": "Anupama J Thubagere and Wei Li and Robert F Johnson and Zibo Chen and Shayan Doroudi and Yae Lim Lee and Gregory Izatt and Sarah Wittman and Niranjan Srinivas and Damien Woods and Erik Winfree and Lulu Qian"
      }
    ],
    "ai5ebQkAAAAJ": [
      {
        "title": "Kymatio: Scattering transforms in python",
        "abstract": "The wavelet scattering transform is an invariant and stable signal representation suitable for many signal processing and machine learning applications. We present the Kymatio software package, an easy-to-use, high-performance Python implementation of the scattering transform in 1D, 2D, and 3D that is compatible with modern deep learning frameworks, including PyTorch and TensorFlow/Keras. The transforms are implemented on both CPUs and GPUs, the latter offering a significant speedup over the former. The package also has a small memory footprint. Source code, documentation, and examples are available under a BSD license at https://www.kymat.io.",
        "year": 2020,
        "authors": "Mathieu Andreux and Tom\u00e1s Angles and Georgios Exarchakis and Roberto Leonarduzzi and Gaspar Rochette and Louis Thiry and John Zarka and St\u00e9phane Mallat and Joakim And\u00e9n and Eugene Belilovsky and Joan Bruna and Vincent Lostanlen and Muawiz Chaudhary and Matthew J Hirn and Edouard Oyallon and Sixin Zhang and Carmine Cella and Michael Eickenberg"
      },
      {
        "title": "Deep convolutional networks on the pitch spiral for musical instrument recognition",
        "abstract": "Musical performance combines a wide range of pitches, nuances, and expressive techniques. Audio-based classification of musical instruments thus requires to build signal representations that are invariant to such transformations. This article investigates the construction of learned convolutional architectures for instrument recognition, given a limited amount of annotated training data. In this context, we benchmark three different weight sharing strategies for deep convolutional networks in the time-frequency domain: temporal kernels; time-frequency kernels; and a linear combination of time-frequency kernels which are one octave apart, akin to a Shepard pitch spiral. We provide an acoustical interpretation of these strategies within the source-filter framework of quasi-harmonic sounds with a fixed spectral envelope, which are archetypal of musical notes. The best classification accuracy is obtained by hybridizing all three convolutional layers into a single deep learning architecture.",
        "year": 2016,
        "authors": "Vincent Lostanlen and Carmine-Emanuele Cella"
      },
      {
        "title": "OrchideaSOL: a dataset of extended instrumental techniques for computer-aided orchestration",
        "abstract": "This paper introduces OrchideaSOL, a free dataset of samples of extended instrumental playing techniques, designed to be used as default dataset for the Orchidea framework for target-based computer-aided orchestration. OrchideaSOL is a reduced and modified subset of Studio On Line, or SOL for short, a dataset developed at Ircam between 1996 and 1998. We motivate the reasons behind OrchideaSOL and describe the differences between the original SOL and our dataset. We will also show the work done in improving the dynamic ranges of orchestral families and other aspects of the data.",
        "year": 2020,
        "authors": "Carmine Emanuele Cella and Daniele Ghisi and Vincent Lostanlen and Fabien L\u00e9vy and Joshua Fineberg and Yan Maresz"
      }
    ],
    "D2dgzzQAAAAJ": [
      {
        "title": "An automated pipeline for the discovery of conspiracy and conspiracy theory narrative frameworks: Bridgegate, Pizzagate and storytelling on the web",
        "abstract": "Although a great deal of attention has been paid to how conspiracy theories circulate on social media, and the deleterious effect that they, and their factual counterpart conspiracies, have on political institutions, there has been little computational work done on describing their narrative structures. Predicating our work on narrative theory, we present an automated pipeline for the discovery and description of the generative narrative frameworks of conspiracy theories that circulate on social media, and actual conspiracies reported in the news media. We base this work on two separate comprehensive repositories of blog posts and news articles describing the well-known conspiracy theory Pizzagate from 2016, and the New Jersey political conspiracy Bridgegate from 2013. Inspired by the qualitative narrative theory of Greimas, we formulate a graphical generative machine learning model where nodes represent actors/actants, and multi-edges and self-loops among nodes capture context-specific relationships. Posts and news items are viewed as samples of subgraphs of the hidden narrative framework network. The problem of reconstructing the underlying narrative structure is then posed as a latent model estimation problem. To derive the narrative frameworks in our target corpora, we automatically extract and aggregate the actants (people, places, objects) and their relationships from the posts and articles. We capture context specific actants and interactant relationships by developing a system of supernodes and subnodes. We use these to construct an actant-relationship network, which constitutes the underlying generative narrative framework for \u2026",
        "year": 2020,
        "authors": "Timothy R Tangherlini and Shadi Shahsavari and Behnam Shahbazi and Ehsan Ebrahimzadeh and Vwani Roychowdhury"
      },
      {
        "title": "\u201cMommy blogs\u201d and the vaccination exemption narrative: results from a machine-learning approach for story aggregation on parenting social media sites",
        "abstract": "Background: Social media offer an unprecedented opportunity to explore how people talk about health care at a very large scale. Numerous studies have shown the importance of websites with user forums for people seeking information related to health. Parents turn to some of these sites, colloquially referred to as \u201cmommy blogs,\u201d to share concerns about children\u2019s health care, including vaccination. Although substantial work has considered the role of social media, particularly Twitter, in discussions of vaccination and other health care\u2013related issues, there has been little work on describing the underlying structure of these discussions and the role of persuasive storytelling, particularly on sites with no limits on post length. Understanding the role of persuasive storytelling at Internet scale provides useful insight into how people discuss vaccinations, including exemption-seeking behavior, which has been tied to a recent diminution of herd immunity in some communities.Objective: To develop an automated and scalable machine-learning method for story aggregation on social media sites dedicated to discussions of parenting. We wanted to discover the aggregate narrative frameworks to which individuals, through their exchange of experiences and commentary, contribute over time in a particular topic domain. We also wanted to characterize temporal trends in these narrative frameworks on the sites over the study period.Methods: To ensure that our data capture long-term discussions and not short-term reactions to recent events, we developed a dataset of 1.99 million posts contributed by 40,056 users and viewed 20.12 million times indexed from \u2026",
        "year": 2016,
        "authors": "Timothy R Tangherlini and Vwani Roychowdhury and Beth Glenn and Catherine M Crespi and Roja Bandari and Akshay Wadia and Misagh Falahi and Ehsan Ebrahimzadeh and Roshan Bastani"
      },
      {
        "title": "An automated pipeline for character and relationship extraction from readers literary book reviews on goodreads. com",
        "abstract": "Reader reviews of literary fiction on social media, especially those in persistent, dedicated forums, create and are in turn driven by underlying narrative frameworks. In their comments about a novel, readers generally include only a subset of characters and their relationships, thus offering a limited perspective on that work. Yet in aggregate, these reviews capture an underlying narrative framework comprised of different actants (people, places, things), their roles, and interactions that we label the \u201cconsensus narrative framework\u201d. We represent this framework in the form of an actant-relationship story graph. Extracting this graph is a challenging computational problem, which we pose as a latent graphical model estimation problem. Posts and reviews are viewed as samples of sub graphs/networks of the hidden narrative framework. Inspired by the qualitative narrative theory of Greimas, we formulate a graphical \u2026",
        "year": 2020,
        "authors": "Shadi Shahsavari and Ehsan Ebrahimzadeh and Behnam Shahbazi and Misagh Falahi and Pavan Holur and Roja Bandari and Timothy R. Tangherlini and Vwani Roychowdhury"
      }
    ],
    "Qs2N8fMAAAAJ": [
      {
        "title": "Semiconducting polymer nanoparticles as photoacoustic molecular imaging probes in living mice",
        "abstract": "Photoacoustic imaging holds great promise for the visualization of physiology and pathology at the molecular level with deep tissue penetration and fine spatial resolution. To fully utilize this potential, photoacoustic molecular imaging probes have to be developed. Here, we introduce near-infrared light absorbing semiconducting polymer nanoparticles as a new class of contrast agents for photoacoustic molecular imaging. These nanoparticles can produce a stronger signal than the commonly used single-walled carbon nanotubes and gold nanorods on a per mass basis, permitting whole-body lymph-node photoacoustic mapping in living mice at a low systemic injection mass. Furthermore, the semiconducting polymer nanoparticles possess high structural flexibility, narrow photoacoustic spectral profiles and strong resistance to photodegradation and oxidation, enabling the development of the first near-infrared \u2026",
        "year": 2014,
        "authors": "Kanyi Pu and Adam J Shuhendler and Jesse V Jokerst and Jianguo Mei and Sanjiv S Gambhir and Zhenan Bao and Jianghong Rao"
      },
      {
        "title": "Self-illuminating quantum dot conjugates for in vivo imaging",
        "abstract": "Fluorescent semiconductor quantum dots hold great potential for molecular imaging in vivo,,,,. However, the utility of existing quantum dots for in vivo imaging is limited because they require excitation from external illumination sources to fluoresce, which results in a strong autofluorescence background and a paucity of excitation light at nonsuperficial locations. Here we present quantum dot conjugates that luminesce by bioluminescence resonance energy transfer in the absence of external excitation. The conjugates are prepared by coupling carboxylate-presenting quantum dots to a mutant of the bioluminescent protein Renilla reniformis luciferase. We show that the conjugates emit long-wavelength (from red to near-infrared) bioluminescent light in cells and in animals, even in deep tissues, and are suitable for multiplexed in vivo imaging. Compared with existing quantum dots, self-illuminating quantum dot \u2026",
        "year": 2006,
        "authors": "Min-Kyung So and Chenjie Xu and Andreas M Loening and Sanjiv S Gambhir and Jianghong Rao"
      },
      {
        "title": "Fluorescence imaging in vivo: recent advances",
        "abstract": "In vivo fluorescence imaging uses a sensitive camera to detect fluorescence emission from fluorophores in whole-body living small animals. To overcome the photon attenuation in living tissue, fluorophores with long emission at the near-infrared (NIR) region are generally preferred, including widely used small indocarbocyanine dyes. The list of NIR probes continues to grow with the recent addition of fluorescent organic, inorganic and biological nanoparticles. Recent advances in imaging strategies and reporter techniques for in vivo fluorescence imaging include novel approaches to improve the specificity and affinity of the probes and to modulate and amplify the signal at target sites for enhanced sensitivity. Further emerging developments are aiming to achieve high-resolution, multimodality and lifetime-based in vivo fluorescence imaging.",
        "year": 2007,
        "authors": "Jianghong Rao and Anca Dragulescu-Andrasi and Hequan Yao"
      }
    ],
    "v7a8-e0AAAAJ": [
      {
        "title": "Importance of pollinators in changing landscapes for world crops",
        "abstract": "The extent of our reliance on animal pollination for world crop production for human food has not previously been evaluated and the previous estimates for countries or continents have seldom used primary data. In this review, we expand the previous estimates using novel primary data from 200 countries and found that fruit, vegetable or seed production from 87 of the leading global food crops is dependent upon animal pollination, while 28 crops do not rely upon animal pollination. However, global production volumes give a contrasting perspective, since 60% of global production comes from crops that do not depend on animal pollination, 35% from crops that depend on pollinators, and 5% are unevaluated. Using all crops traded on the world market and setting aside crops that are solely passively self-pollinated, wind-pollinated or parthenocarpic, we then evaluated the level of dependence on animal-mediated \u2026",
        "year": 2007,
        "authors": "Alexandra-Maria Klein and Bernard E Vaissi\u00e8re and James H Cane and Ingolf Steffan-Dewenter and Saul A Cunningham and Claire Kremen and Teja Tscharntke"
      },
      {
        "title": "Global pollinator declines: trends, impacts and drivers",
        "abstract": "Pollinators are a key component of global biodiversity, providing vital ecosystem services to crops and wild plants. There is clear evidence of recent declines in both wild and domesticated pollinators, and parallel declines in the plants that rely upon them. Here we describe the nature and extent of reported declines, and review the potential drivers of pollinator loss, including habitat loss and fragmentation, agrochemicals, pathogens, alien species, climate change and the interactions between them. Pollinator declines can result in loss of pollination services which have important negative ecological and economic impacts that could significantly affect the maintenance of wild plant diversity, wider ecosystem stability, crop production, food security and human welfare.",
        "year": 2010,
        "authors": "Simon G Potts and Jacobus C Biesmeijer and Claire Kremen and Peter Neumann and Oliver Schweiger and William E Kunin"
      },
      {
        "title": "Wild pollinators enhance fruit set of crops regardless of honey bee abundance",
        "abstract": "The diversity and abundance of wild insect pollinators have declined in many agricultural landscapes. Whether such declines reduce crop yields, or are mitigated by managed pollinators such as honey bees, is unclear. We found universally positive associations of fruit set with flower visitation by wild insects in 41 crop systems worldwide. In contrast, fruit set increased significantly with flower visitation by honey bees in only 14% of the systems surveyed. Overall, wild insects pollinated crops more effectively; an increase in wild insect visitation enhanced fruit set by twice as much as an equivalent increase in honey bee visitation. Visitation by wild insects and honey bees promoted fruit set independently, so pollination by managed honey bees supplemented, rather than substituted for, pollination by wild insects. Our results suggest that new practices for integrated management of both honey bees and diverse wild \u2026",
        "year": 2013,
        "authors": "Lucas A Garibaldi and Ingolf Steffan-Dewenter and Rachael Winfree and Marcelo A Aizen and Riccardo Bommarco and Saul A Cunningham and Claire Kremen and Lu\u00edsa G Carvalheiro and Lawrence D Harder and Ohad Afik and Ignasi Bartomeus and Faye Benjamin and Virginie Boreux and Daniel Cariveau and Natacha P Chacoff and Jan H Dudenh\u00f6ffer and Breno M Freitas and Jaboury Ghazoul and Sarah Greenleaf and Juliana Hip\u00f3lito and Andrea Holzschuh and Brad Howlett and Rufus Isaacs and Steven K Javorek and Christina M Kennedy and Kristin M Krewenka and Smitha Krishnan and Yael Mandelik and Margaret M Mayfield and Iris Motzke and Theodore Munyuli and Brian A Nault and Mark Otieno and Jessica Petersen and Gideon Pisanty and Simon G Potts and Romina Rader and Taylor H Ricketts and Maj Rundl\u00f6f and Colleen L Seymour and Christof Sch\u00fcepp and Hajnalka Szentgy\u00f6rgyi and Hisatomo Taki and Teja Tscharntke and Carlos H Vergara and Blandina F Viana and Thomas C Wanger and Catrin Westphal and Neal Williams and Alexandra M Klein"
      }
    ],
    "kxg88EcAAAAJ": [
      {
        "title": "From farm to table: The organic vegetable commodity chain of Northern California",
        "abstract": "The social basis for a democratic food policy lies in movements for employment and incomes, for safe and nutritious food, for environmentally sensitive agriculture (includmg treatment of animals) and for democratic participation... Democratic principles... emphasize proximity and seasonality-sensitivity to place and time. This means the use and development of technologies and markets to facilitate local enterprises in every possible link of agrofood chains. What is increasingly clear is that healthy food and environmentally sound agriculture must be rooted in local economies.(Friedmann 1993, p. 55)",
        "year": 1997,
        "authors": "Daniel Buck and Christina Getz and Julie Guthman"
      },
      {
        "title": "Social sustainability, farm labor, and organic agriculture: Findings from an exploratory analysis",
        "abstract": "Much of the attention by social scientists to the rapidly growing organic agriculture sector focuses on the benefits it provides to consumers (in the form of pesticide-free foods) and to farmers (in the form of price premiums). By contrast, there has been little discussion or research about the implications of the boom in organic agriculture for farmworkers on organic farms. In this paper, we ask the question: From the perspective of organic farmers, does \u201ccertified organic\u201d agriculture encompass a commitment to \u201csustainability\u201d that prioritizes social goals? Specifically, we aim to broaden our understanding of the relationship between social sustainability and organic agriculture by drawing attention to issues affecting farmworkers, whose labor and contribution tends to elude most discussions of organic agriculture. We present findings from a survey of organic farmers in California about the possible incorporation of \u2026",
        "year": 2006,
        "authors": "Aimee Shreck and Christy Getz and Gail Feenstra"
      },
      {
        "title": "The social dimensions of sustainability and change in diversified farming systems",
        "abstract": "Agricultural systems are embedded in wider social-ecological processes that must be considered in any complete discussion of sustainable agriculture. Just as climatic profiles will influence the future viability of crops, institutions, i.e., governance agreements, rural household and community norms, local associations, markets, and agricultural ministries, to name but a few, create the conditions that foster sustainable food systems. Because discussions of agricultural sustainability often overlook the full range of social dimensions, we propose a dual focus on a broad set of criteria, i.e., human health, labor, democratic participation, resiliency, biological and cultural diversity, equity, and ethics, to assess social outcomes, and on institutions that could support diversified farming systems (DFS). A comparative analysis of case studies from California\u2019s Central Valley, Mesoamerican coffee agroforestry systems, and \u2026",
        "year": 2012,
        "authors": "Christopher M Bacon and Christy Getz and Sibella Kraus and Maywa Montenegro and Kaelin Holland"
      }
    ],
    "tiM51yoAAAAJ": [
      {
        "title": "Entangled memory: Toward a third wave in memory studies",
        "abstract": "This essay takes up the call for a \u201cthird phase\u201d in memory studies and makes theoretical and methodological suggestions for its further development. Starting from an understanding of memory that centers on memory's temporality, its relation to language, and its quality as a social action, the essay puts forward the concept of \u201centangled memory.\u201d On a theoretical level, it brings to the fore the entangledness of acts of remembering. In a synchronic perspective, memory's entangledness is presented as twofold. Every act of remembering inscribes an individual in multiple social frames. This polyphony entails the simultaneous existence of concurrent interpretations of the past. In a diachronic perspective, memory is entangled in the dynamic relation between single acts of remembering and changing mnemonic patterns. Memory scholars therefore uncover boundless cross\u2010referential configurations. Wishing to enhance \u2026",
        "year": 2014,
        "authors": "Gregor Feindt and F\u00e9lix Krawatzek and Daniela Mehler and Friedemann Pestel and Rieke Trim\u00e7ev"
      },
      {
        "title": "Historicizing Strong Metaphors: A Challenge for Conceptual History",
        "abstract": "The debate between metaphor theorists and conceptual historians has been intensifying in recent years. This article takes this debate beyond the bias toward Blumenberg's metaphorology, and starts from the interaction view of metaphor as formulated by Max Black. The article opens with a theoretical framework that reformulates Black's notions of metaphorical resonance and emphasis. It adapts them to the requirements of Conceptual History, and adds a third, historical criterion for metaphoricity. It then applies these suggestions to the history of the metaphor play/game/Spiel/jeu within twentieth-century political thought. Here, the focus lies on the role this metaphor plays in the conceptual relations between the ideas of political order, conflict, and immanence.",
        "year": 2012,
        "authors": "Rieke Sch\u00e4fer"
      }
    ],
    "valGGiQAAAAJ": [
      {
        "title": "A real-time platform for contextualized conspiracy theory analysis",
        "abstract": "As the U.S. Capitol riots of January 6, 2021 attest, conspiracy theories can lead to civil unrest. Many \"netizens\" of the radical online fora that host these conversations are not themselves radicalized. However, the limited in-line context necessary to evaluate their legitimacy, along with readers\u2019 predisposition to believe stories that reinforce their existing worldviews, can create interpretations of real-world events that conflict with fact. Recent work proposes automated computational methods to reconstruct the missing contexts of conspiracy theories. While such work has successfully exposed several recent conspiracy theories, a robust real-time system that builds on this success at scale is needed. This paper presents one such implementation with: (a) A plug-and-play module for adding and removing heterogeneous text sources, (b) A scalable infrastructure that caters to the constantly expanding knowledge space, (c \u2026",
        "year": 2021,
        "authors": "David Chong and Erl Lee and Matthew Fan and Pavan Holur and Shadi Shahsavari and Timothy Tangherlini and Vwani Roychowdhury"
      },
      {
        "title": "My side, your side and the evidence: Discovering aligned actor groups and the narratives they weave",
        "abstract": "News reports about emerging issues often include several conflicting story lines. Individual stories can be conceptualized as samples from an underlying mixture of competing narratives. The automated identification of these distinct narratives from unstructured text is a fundamental yet difficult task in Computational Linguistics since narratives are often intertwined and only implicitly conveyed in text. In this paper, we consider a more feasible proxy task: Identify the distinct sets of aligned story actors responsible for sustaining the issue-specific narratives. Discovering aligned actors, and the groups these alignments create, brings us closer to estimating the narrative that each group represents. With the help of Large Language Models (LLM), we address this task by:(i) Introducing a corpus of text segments rich in narrative content associated with six different current issues;(ii) Introducing a novel two-step graph-based framework that (a) identifies alignments between actors (INCANT) and (b) extracts aligned actor groups using the network structure (TAMPA). Amazon Mechanical Turk evaluations demonstrate the effectiveness of our framework. Across domains, alignment relationships from INCANT are accurate (macro F1>= 0.75) and actor groups from TAMPA are preferred over 2 non-trivial baseline models (ACC>= 0.75).",
        "year": 2023,
        "authors": "Pavan Holur and David Chong and Timothy Tangherlini and Vwani Roychowdhury"
      },
      {
        "title": "Creating an AI Observer: Generative Semantic Workspaces",
        "abstract": "An experienced human Observer reading a document -- such as a crime report -- creates a succinct plot-like $\\textit{``Working Memory''}$ comprising different actors, their prototypical roles and states at any point, their evolution over time based on their interactions, and even a map of missing Semantic parts anticipating them in the future. $\\textit{An equivalent AI Observer currently does not exist}$. We introduce the $\\textbf{[G]}$enerative $\\textbf{[S]}$emantic $\\textbf{[W]}$orkspace (GSW) -- comprising an $\\textit{``Operator''}$ and a $\\textit{``Reconciler''}$ -- that leverages advancements in LLMs to create a generative-style Semantic framework, as opposed to a traditionally predefined set of lexicon labels. Given a text segment $C_n$ that describes an ongoing situation, the $\\textit{Operator}$ instantiates actor-centric Semantic maps (termed ``Workspace instance'' $\\mathcal{W}_n$). The $\\textit{Reconciler}$ resolves differences between $\\mathcal{W}_n$ and a ``Working memory'' $\\mathcal{M}_n^*$ to generate the updated $\\mathcal{M}_{n+1}^*$. GSW outperforms well-known baselines on several tasks ($\\sim 94\\%$ vs. FST, GLEN, BertSRL - multi-sentence Semantics extraction, $\\sim 15\\%$ vs. NLI-BERT, $\\sim 35\\%$ vs. QA). By mirroring the real Observer, GSW provides the first step towards Spatial Computing assistants capable of understanding individual intentions and predicting future behavior.",
        "year": 2024,
        "authors": "Pavan Holur and Shreyas Rajesh and David Chong and Vwani Roychowdhury"
      }
    ],
    "GxXX_ekAAAAJ": [
      {
        "title": "The role of information and financial reporting in corporate governance and debt contracting",
        "abstract": "We review recent literature on the role of financial reporting transparency in reducing governance-related agency conflicts among managers, directors, and shareholders, as well as in reducing agency conflicts between shareholders and creditors, and offer researchers some suggested avenues for future research. Key themes include the endogenous nature of debt contracts and governance mechanisms with respect to information asymmetry between contracting parties, the heterogeneous nature of the informational demands of contracting parties, and the heterogeneous nature of the resulting governance and debt contracts. We also emphasize the role of a commitment to financial reporting transparency in facilitating informal multiperiod contracts among managers, directors, shareholders, and creditors.",
        "year": 2010,
        "authors": "Christopher S Armstrong and Wayne R Guay and Joseph P Weber"
      },
      {
        "title": "Market reaction to the adoption of IFRS in Europe",
        "abstract": " ABSTRACT: This study examines European stock market reactions to 16 events associated with the adoption of International Financial Reporting Standards (IFRS) in Europe. European IFRS adoption represented a major milestone toward financial reporting convergence yet spurred controversy reaching the highest levels of government. We find an incrementally positive reaction for firms with lower quality pre\u2010adoption information, which is more pronounced for banks, and with higher pre\u2010adoption information asymmetry, consistent with investors expecting net information quality benefits from IFRS adoption. We find an incrementally negative reaction for firms domiciled in code law countries, consistent with investors' concerns over enforcement of IFRS in those countries. Finally, we find a positive reaction to IFRS adoption events for firms with high\u2010quality pre\u2010adoption information, consistent with investors \u2026",
        "year": 2010,
        "authors": "Christopher S Armstrong and Mary E Barth and Alan D Jagolinzer and Edward J Riedl"
      },
      {
        "title": "Corporate governance, incentives, and tax avoidance",
        "abstract": "We examine the link between corporate governance, managerial incentives, and corporate tax avoidance. Similar to other investment opportunities that involve risky expected cash flows, unresolved agency problems may lead managers to engage in more or less corporate tax avoidance than shareholders would otherwise prefer. Consistent with the mixed results reported in prior studies, we find no relation between various corporate governance mechanisms and tax avoidance at the conditional mean and median of the tax avoidance distribution. However, using quantile regression, we find a positive relation between board independence and financial sophistication for low levels of tax avoidance, but a negative relation for high levels of tax avoidance. These results indicate that these governance attributes have a stronger relation with more extreme levels of tax avoidance, which are more likely to be symptomatic \u2026",
        "year": 2015,
        "authors": "Christopher S Armstrong and Jennifer L Blouin and Alan D Jagolinzer and David F Larcker"
      }
    ],
    "ZD6J9JIAAAAJ": [
      {
        "title": "VIS: A system for verification and synthesis",
        "abstract": "VIS (Verification Interacting with Synthesis) is a tool that integrates the verification, simulation, and synthesis of finite-state hardware systems. It uses a Verilog front end and supports fair CTL model checking, language emptiness checking, combinational and sequential equivalence checking, cycle-based simulation, and hierarchical synthesis. We designed VIS to maximize performance by using state-of-the-art algorithms, and to provide a solid platform for future research in formal verification. VIS improves upon existing verification tools by:1. providing a better programming environment, 2. providing new capabilities, mad 3.~ mproving performance.",
        "year": 1996,
        "authors": "Robert K Brayton and Gary D Hachtel and Alberto Sangiovanni-Vincentelli and Fabio Somenzi and Adnan Aziz and Szu -Tsung Cheng and Stephen Edwards and Sunil Khatri and Yuji Kukimoto and Abelardo Pardo and Shaz Qadeer and Rajeev K Ranjan and Shaker Sarwary and Thomas R Staple and Gitanjali Swamy and Tiziano Villa"
      },
      {
        "title": "Analysis and avoidance of cross-talk in on-chip buses",
        "abstract": "We present techniques to analyze and alleviate cross-talk in on-chip buses. With rapidly shrinking process feature sizes, wire delay is becoming a large fraction of the overall delay of a circuit. Additionally, the increasing cross-coupling capacitances between wires on the same metal layer create a situation where the delay of a wire is strongly dependent on the electrical state of its neighboring wires. The delay of a wire can vary widely depending on whether its neighbors perform a like or unlike transition. This effect is acute for long on-chip buses. In this work, we classify cross-talk interactions between the wires of an on-chip bus. We present encoding techniques which can help a designer trade off cross-talk against area overhead. Our experimental results show that the proposed techniques result in reduced delay variation due to cross-talk. As a result, the overall delay of a bus actually decreases even after the use \u2026",
        "year": 2001,
        "authors": "Chunjie Duan and Anup Tirumala and Sunil P Khatri"
      },
      {
        "title": "Towards acceleration of fault simulation using graphics processing units",
        "abstract": "In this paper, we explore the implementation of fault simulation on a Graphics Processing Unit (GPU). In particular, we implement a fault simulator that exploits thread level parallelism. Fault simulation is inherently parallelizable, and the large number of threads that can be computed in parallel on a GPU results in a natural fit for the problem of fault simulation. Our implementation fault-simulates all the gates in a particular level of a circuit, including good and faulty circuit simulations, for all patterns, in parallel. Since GPUs have an extremely large memory bandwidth, we implement each of our fault simulation threads (which execute in parallel with no data dependencies) using memory lookup. Fault injection is also done along with gate evaluation, with each thread using a different fault injection mask. All threads compute identical instructions, but on different data, as required by the Single Instruction Multiple Data \u2026",
        "year": 2008,
        "authors": "Kanupriya Gulati and Sunil P Khatri"
      }
    ],
    "RWGj7esAAAAJ": [
      {
        "title": "Wireless network design for control systems: A survey",
        "abstract": "Wireless networked control systems (WNCSs) are composed of spatially distributed sensors, actuators, and controllers communicating through wireless networks instead of conventional point-to-point wired connections. Due to their main benefits in the reduction of deployment and maintenance costs, large flexibility and possible enhancement of safety, WNCS are becoming a fundamental infrastructure technology for critical control systems in automotive electrical systems, avionics control systems, building management systems, and industrial automation systems. The main challenge in WNCS is to jointly design the communication and control systems considering their tight interaction to improve the control performance and the network lifetime. In this survey, we make an exhaustive review of the literature on wireless network design and optimization for WNCS. First, we discuss what we call the critical interactive \u2026",
        "year": 2017,
        "authors": "Pangun Park and Sinem Coleri Ergen and Carlo Fischione and Chenyang Lu and Karl Henrik Johansson"
      },
      {
        "title": "A survey of enabling technologies for network localization, tracking, and navigation",
        "abstract": "Location information for events, assets, and individuals, mostly focusing on two dimensions so far, has triggered a multitude of applications across different verticals, such as consumer, networking, industrial, health care, public safety, and emergency response use cases. To fully exploit the potential of location awareness and enable new advanced location-based services, localization algorithms need to be combined with complementary technologies including accurate height estimation, i.e., three dimensional location, reliable user mobility classification, and efficient indoor mapping solutions. This survey provides a comprehensive review of such enabling technologies. In particular, we present cellular localization systems including recent results on 5G localization, and solutions based on wireless local area networks, highlighting those that are capable of computing 3D location in multi-floor indoor environments \u2026",
        "year": 2018,
        "authors": "Christos Laoudias and Adriano Moreira and Sunwoo Kim and Sangwoo Lee and Lauri Wirola and Carlo Fischione"
      },
      {
        "title": "Millimeter wave cellular networks: A MAC layer perspective",
        "abstract": "The millimeter-wave (mmWave) frequency band is seen as a key enabler of multigigabit wireless access in future cellular networks. In order to overcome the propagation challenges, mmWave systems use a large number of antenna elements both at the base station and at the user equipment, which leads to high directivity gains, fully directional communications, and possible noise-limited operations. The fundamental differences between mmWave networks and traditional ones challenge the classical design constraints, objectives, and available degrees of freedom. This paper addresses the implications that highly directional communication has on the design of an efficient medium access control (MAC) layer. The paper discusses key MAC layer issues, such as synchronization, random access, handover, channelization, interference management, scheduling, and association. This paper provides an integrated \u2026",
        "year": 2015,
        "authors": "Hossein Shokri-Ghadikolaei and Carlo Fischione and Gabor Fodor and Petar Popovski and Michele Zorzi"
      }
    ],
    "3ENogOkAAAAJ": [
      {
        "title": "Citizen science in the age of neogeography: Utilizing volunteered geographic information for environmental monitoring",
        "abstract": "The interface between neogeography and citizen science has great potential for environmental monitoring, but this nexus has been explored less often than each subject individually. In this article we review the emerging role of volunteered geographic information in citizen science and present a case study of an integrated tool set that engages multiple types of users (from targeted citizen-based observation networks, expert-driven focused monitoring, and opportunistic crowdsourcing efforts) in monitoring a forest disease in the western United States. We first introduce the overall challenge of data collection in environmental monitoring projects and then discuss the literature surrounding an emergent integration of citizen science and volunteered geographical information. We next explore how these methods characterize and underpin knowledge discovery and how multimodal interaction is supported so that a large \u2026",
        "year": 2012,
        "authors": "John Patrick Connors and Shufei Lei and Maggi Kelly"
      },
      {
        "title": "Information-delivery system and method and applications employing same",
        "abstract": "BACKGROUND0001 Embodiments of the present invention are related in general to information-delivery systems and more spe cifically to information-delivery systems and methods for providing information about an entity, such as a product, brand, company, investment, and so on. 0002. When shopping for a product, a user often researches the product before purchase. Various factors may be considered. Thus, delivering product information to the user may influence the user's choice. Product information may be delivered to the consumer via advertising, product labeling, price tags, websites, and so on. Unfortunately, the product information is often limited to product features, capabilities, and price. This information is sometimes useful to a user but may not provide all the information a user desires.",
        "year": 2008,
        "authors": "Dara O'rourke and Kelly Bryant and Graham Bullock and Alastair Iles and Hye Y Kim and Shufei Lei"
      },
      {
        "title": "Expanding the table: the web as a tool for participatory adaptive management in California forests",
        "abstract": "Participatory adaptive management is widely promoted as the new paradigm in public lands management. It is grounded in two underlying principles \u2013 that management experiments and diverse sources of information should be used to continually refine management in complex ecological systems, and that the public must be included throughout the adaptive management process. Access to scientific results and exchange of information is at the core of both of these principles. The recent proliferation of Internet communities and web-based participation tools raises the question of how the Internet might help facilitate information exchange in participatory adaptive management. Using a case study approach, the role of web technologies in facilitating the flow of transparent and useful information was examined in a participatory adaptive management project focused on Forest Service vegetation management \u2026",
        "year": 2012,
        "authors": "Maggi Kelly and Shasta Ferranto and Shufei Lei and Ken-ichi Ueda and Lynn Huntsinger"
      }
    ],
    "-f4kLIoAAAAJ": [
      {
        "title": "Regarding biocultural heritage: In situ political ecology of agricultural biodiversity in the Peruvian Andes",
        "abstract": "This paper emerges from and aims to contribute to conversations on agricultural biodiversity loss, value, and renewal. Standard international responses to the crisis of agrobiodiversity erosion focus mostly on ex situ preservation of germplasm, with little financial and strategic support for in situ cultivation. Yet, one agrarian collective in the Peruvian Andes\u2014the Parque de la Papa (Parque)\u2014has repatriated a thousand native potatoes from the gene bank in Lima so as to catalyze in situ regeneration of lost agricultural biodiversity in the region. Drawing on participant action research and observation, this paper engages with the projects underway at the Parque\u2014as well as \u201cindigenous biocultural heritage\u201d (IBCH), the original action-framework guiding the Parque\u2019s work. IBCH grounds the ecology of successful crop diversity within the Andean cosmovisi\u00f3n, or worldview\u2014which is included, but marginalized, in \u2026",
        "year": 2013,
        "authors": "T Garrett Graddy"
      },
      {
        "title": "From supply management to agricultural subsidies\u2014and back again? The US Farm Bill & agrarian (in) viability",
        "abstract": "Farm subsidies have become increasingly maligned in agricultural policy debates, but the merits of subsidies are a distraction from deeper political, economic, and ecological problems in agriculture. Drawing on a history of the U.S. Farm Bill, this paper argues that a fixation on farm subsidies ignores why they came into being, and more generally glosses over the imperative for modern states to intervene into agricultural economies. Karl Polanyi's 'double movement' framework is used to situate the rise and fall of agricultural supply management within food regime theory. In the second, or surplus food regime, the U.S. government wielded excess commodities as geopolitical tools\u2014even as domestic farm policy labored to contain overproduction, and thus support agrarian viability. In the subsequent corporate food regime, \u201cfree market\u201d agriculture displaces and discredits supply management, even as massive \u2026",
        "year": 2017,
        "authors": "Garrett Graddy-Lovelace and Adam Diamond"
      },
      {
        "title": "New opportunities, new challenges: Harnessing Cuba\u2019s advances in agroecology and sustainable agriculture in the context of changing relations with the United States",
        "abstract": "Cuba\u2019s transition to agroecology is perhaps as widely known as it is misunderstood. In response to the economic crisis of the early 1990s, the Cuban agricultural sector largely departed from the industrial model of food production that it had previously pursued. The subsequent transition towards an agroecological model has been a dynamic and uneven process, elevating Cuba on the world stage as a global leader in sustainable agriculture while at the same time producing unique challenges for Cuban farmers, policy makers, researchers and academics. This article synthesizes and updates contemporary literature on the Cuban agricultural system, paying attention to both successes and shortcomings of agroecology in Cuba to date. In particular, it situates these literatures alongside contributions from academics and practitioners alike, bringing a number of data sets, experiences, and perspectives into \u2026",
        "year": 2018,
        "authors": "Margarita Fernandez and Justine Williams and Galia Figueroa and Garrett Graddy-Lovelace and Mario Machado and Luis Vazquez and Nilda Perez and Leidy Casimiro and Graciela Romero and Fernando Funes-Aguilar"
      }
    ],
    "kwqPtgcAAAAJ": [
      {
        "title": "Adhesive force of a single gecko foot-hair",
        "abstract": "Geckos are exceptional in their ability to climb rapidly up smooth vertical surfaces,,. Microscopy has shown that a gecko's foot has nearly five hundred thousand keratinous hairs or setae. Each 30\u2013130\u2009\u00b5m long seta is only one-tenth the diameter of a human hair and contains hundreds of projections terminating in 0.2\u20130.5\u2009\u00b5m spatula-shaped structures,. After nearly a century of anatomical description,,,, here we report the first direct measurements of single setal force by using a two-dimensional micro-electro-mechanical systems force sensor and a wire as a force gauge. Measurements revealed that a seta is ten times more effective at adhesion than predicted from maximal estimates on whole animals. Adhesive force values support the hypothesis that individual seta operate by van der Waals forces,. The gecko's peculiar behaviour of toe uncurling and peeling led us to discover two aspects of setal function which \u2026",
        "year": 2000,
        "authors": "Kellar Autumn and Yiching A Liang and S Tonia Hsieh and Wolfgang Zesch and Wai Pang Chan and Thomas W Kenny and Ronald Fearing and Robert J Full"
      },
      {
        "title": "Evidence for van der Waals adhesion in gecko setae",
        "abstract": "Geckos have evolved one of the most versatile and effective adhesives known. The mechanism of dry adhesion in the millions of setae on the toes of geckos has been the focus of scientific study for over a century. We provide the first direct experimental evidence for dry adhesion of gecko setae by van der Waals forces, and reject the use of mechanisms relying on high surface polarity, including capillary adhesion. The toes of live Tokay geckos were highly hydrophobic, and adhered equally well to strongly hydrophobic and strongly hydrophilic, polarizable surfaces. Adhesion of a single isolated gecko seta was equally effective on the hydrophobic and hydrophilic surfaces of a microelectro-mechanical systems force sensor. A van der Waals mechanism implies that the remarkable adhesive properties of gecko setae are merely a result of the size and shape of the tips, and are not strongly affected by surface chemistry \u2026",
        "year": 2002,
        "authors": "Kellar Autumn and Metin Sitti and Yiching A Liang and Anne M Peattie and Wendy R Hansen and Simon Sponberg and Thomas W Kenny and Ronald Fearing and Jacob N Israelachvili and Robert J Full"
      },
      {
        "title": "How animals move: an integrative view",
        "abstract": "Recent advances in integrative studies of locomotion have revealed several general principles. Energy storage and exchange mechanisms discovered in walking and running bipeds apply to multilegged locomotion and even to flying and swimming. Nonpropulsive lateral forces can be sizable, but they may benefit stability, maneuverability, or other criteria that become apparent in natural environments. Locomotor control systems combine rapid mechanical preflexes with multimodal sensory feedback and feedforward commands. Muscles have a surprising variety of functions in locomotion, serving as motors, brakes, springs, and struts. Integrative approaches reveal not only how each component within a locomotor system operates but how they function as a collective whole.",
        "year": 2000,
        "authors": "Michael H Dickinson and Claire T Farley and Robert J Full and MAR Koehl and Rodger Kram and Steven Lehman"
      }
    ],
    "AZqd0b4AAAAJ": [
      {
        "title": "Science and decisionmaking",
        "abstract": "Science and Decisionmaking University of Amsterdam University of Amsterdam UvA Terms of \nuse Contact UvA-DARE (Digital Academic Repository) Home Advanced Search Browse My \nselection Search UvA-DARE item 1 out of 1 return to search results Author S. Jasanoff B. Wynne \nF. Buttel F. Charvolin P. Edwards A. Elzinga P. Haas C. Kwa WH Lambright M. Lynch C. Miller \nYear 1998 host editors E. Malone S. Rayner Title Science and Decisionmaking Book title Human \nChoice and Climate Change, Vol 1: The Societal Framework Pages (from-to) 1-87 Publisher \nOhio: Battelle Press Document type Chapter Faculty Faculty of Science (FNWI) Language \nUndefined/Unknown Persistent Identifier https://hdl.handle.net/11245/1.141789 \nDisclaimer/Complaints regulations If you believe that digital publication of certain material \ninfringes any of your rights or (privacy) interests, please let the Library know, stating your reasons. \u2026",
        "year": 1998,
        "authors": "Sheila Jasanoff and Brian Wynne and F Buttel and Florian Charvolin and P Edwards and Aant Elzinga and P Haas and Chunglin Kwa and W Henry Lambright and Michael Lynch and C Miller"
      },
      {
        "title": "Hybrid management: boundary organizations, science policy, and environmental governance in the climate regime",
        "abstract": "The theory of boundary organizations was developed to address an important group of institutions in American society neglected by scholarship in science studies and political science. The long-term stability of scientific and political institutions in the United States has enabled a new class of institutions to grow and thrive as mediators between the two. As originally developed, this structural feature of these new institutions\u2014that is, their location on the boundary between science and politics\u2014dominated theoretical frame-works for explaining their behavior. Applying the theory of boundary organizations to international society requires a refocusing of some of the theory\u2019s central features, however. In this article, I introduce a new framework\u2014hybrid management\u2014to explain the activities of boundary organizations in the more complex, contingent, and contested settings of global politics. I develop the framework of \u2026",
        "year": 2001,
        "authors": "Clark Miller"
      },
      {
        "title": "Climate science and the making of a global political order",
        "abstract": "Clark A. Miller are states willing to cede authority to experts and expert knowledge in global decisions? What normative principles will guide global procedural and distributive choices? Who will have the right to speak to those principles, and how will those rights be managed in practice? These questions, familiar from ongoing debates within a variety of new international organizations, demonstrate just how destabilizing the new global politics can be to an existing political order founded on the primacy of nation-states. 3Where does the power come from to call into question such entrenched political settlements? Part of the answer, I propose, is that existing normative and organizational frameworks for making public policy choices are now seen as inadequate for solving the kinds of problems humanity faces\u2013problems that are conceived as explicitly global in scope. Faced with an array of challenges that seem to \u2026",
        "year": 2004,
        "authors": "Clark A Miller"
      }
    ],
    "nje5fjEAAAAJ": [
      {
        "title": "Cost of capital and earnings transparency",
        "abstract": "We provide evidence that firms with more transparent earnings enjoy a lower cost of capital. We base our earnings transparency measure on the extent to which earnings and change in earnings covary contemporaneously with returns. We find a significant negative relation between our transparency measure and subsequent excess and portfolio mean returns, and expected cost of capital, even after controlling for previously documented determinants of cost of capital.",
        "year": 2013,
        "authors": "Mary E Barth and Yaniv Konchitchki and Wayne R Landsman"
      },
      {
        "title": "Accounting earnings and gross domestic product",
        "abstract": "We document that aggregate accounting earnings growth is an incrementally significant leading indicator of growth in nominal Gross Domestic Product (GDP). Professional macro forecasters, however, do not fully incorporate the predictive content embedded in publicly available accounting earnings data. As a result, future nominal GDP growth forecast errors are predictable based on accounting earnings data that are available to professional macro forecasters in real time.",
        "year": 2014,
        "authors": "Yaniv Konchitchki and Panos N Patatoukas"
      },
      {
        "title": "Event study methodologies in information systems research",
        "abstract": "Event studies are based on the theoretical framework of efficient capital markets and the notion that security prices include all information available to the market. As a result, announcements made by firms provide to market participants information that can be impounded into the market price. This paper investigates the use of event studies in information systems and accounting information systems research using a three-pronged approach. First, this paper provides a comprehensive survey of research that uses event study methodologies, where the events are announcements made by firms about issues related to information systems, e.g., announcements of the adoption of enterprise resource planning systems and of the effect of security breaches in firms' information systems. Second, this paper summarizes event study methodologies used in prior research, along with some of the key parameters and concerns \u2026",
        "year": 2011,
        "authors": "Yaniv Konchitchki and Daniel E O'Leary"
      }
    ],
    "GrBOKEsAAAAJ": [
      {
        "title": "Electron-spin-resonance transistors for quantum computing in silicon-germanium heterostructures",
        "abstract": "We apply the full power of modern electronic band-structure engineering and epitaxial heterostructures to design a transistor that can sense and control a single-donor electron spin. Spin-resonance transistors may form the technological basis for quantum information processing. One-and two-qubit operations are performed by applying a gate bias. The bias electric field pulls the electron wave function away from the dopant ion into layers of different alloy composition. Owing to the variation of the g factor (Si: g= 1.998, Ge: g= 1.563), this displacement changes the spin Zeeman energy, allowing single-qubit operations. By displacing the electron even further, the overlap with neighboring qubits is affected, which allows two-qubit operations. Certain silicon-germanium alloys allow a qubit spacing as large as 200 nm, which is well within the capabilities of current lithographic techniques. We discuss manufacturing \u2026",
        "year": 2000,
        "authors": "Rutger Vrijen and Eli Yablonovitch and Kang Wang and Hong Wen Jiang and Alex Balandin and Vwani Roychowdhury and Tal Mor and David DiVincenzo"
      },
      {
        "title": "Network component analysis: reconstruction of regulatory signals in biological systems",
        "abstract": "High-dimensional data sets generated by high-throughput technologies, such as DNA microarray, are often the outputs of complex networked systems driven by hidden regulatory signals. Traditional statistical methods for computing low-dimensional or hidden representations of these data sets, such as principal component analysis and independent component analysis, ignore the underlying network structures and provide decompositions based purely on a priori statistical constraints on the computed component signals. The resulting decomposition thus provides a phenomenological model for the observed data and does not necessarily contain physically or biologically meaningful signals. Here, we develop a method, called network component analysis, for uncovering hidden regulatory signals from outputs of networked systems, when only a partial knowledge of the underlying network topology is available. The \u2026",
        "year": 2003,
        "authors": "James C Liao and Riccardo Boscolo and Young-Lyeol Yang and Linh My Tran and Chiara Sabatti and Vwani P Roychowdhury"
      },
      {
        "title": "A new proof for the existence of mutually unbiased bases",
        "abstract": "We develop a strong connection between maximally commuting bases of orthogonal unitary matrices and mutually unbiased bases. A necessary condition of the existence of mutually unbiased bases for any finite dimension is obtained. Then a constructive proof of the existence of mutually unbiased bases for dimensions that are powers of primes is presented. It is also proved that in any dimension d  the number of mutually unbiased bases is at most d+1 . An explicit representation of mutually unbiased observables in terms of Pauli matrices are provided for d=2 m  .",
        "year": 2002,
        "authors": "Bandyopadhyay and Boykin and Roychowdhury and Vatan"
      }
    ],
    "yr_ubo0AAAAJ": [
      {
        "title": "The rewards to meeting or beating earnings expectations",
        "abstract": "This paper finds that firms that meet or beat current analysts\u2019 earnings expectations (MBE) enjoy a higher return over the quarter than firms with similar quarterly earnings forecast errors that fail to meet these expectations. Further, such a premium to MBE, although somewhat smaller, exists in the cases where MBE is likely to have been achieved through earnings or expectations management. The findings also indicate that the premium to MBE is a leading indicator of future performance. This premium and its predictive ability are only marginally affected by whether the MBE is genuine or the result of earnings or expectations management.",
        "year": 2002,
        "authors": "Eli Bartov and Dan Givoly and Carla Hayn"
      },
      {
        "title": "Discretionary accruals models and audit qualifications",
        "abstract": "The primary goal of this study is to evaluate the ability of the Cross-sectional Jones Model and the Cross-sectional Modified Jones Model to detect earnings management vis-\u00e0-vis their time-series counterparts by examining the association between discretionary accruals and audit qualifications. These two cross-sectional models have not been formally evaluated by prior research, and their use may offer certain advantages to investors and researchers over their time-series counterparts. A sample of 173 distinct firms with qualified audit reports and a matched-pair control sample with clean audit reports are used. Only the two cross-sectional models are consistently able to detect earnings management. One limitation of this study is that its findings merely indicate the superiority of the cross-sectional models vis-\u00e0-vis their time-series counterparts in an audit qualification setting, not validate either the former or the latter.",
        "year": 2001,
        "authors": "E Bartov and F Gul and J Tsui"
      },
      {
        "title": "The timing of asset sales and earnings manipulation",
        "abstract": "This study presents an empirical examination of whether managers manipulate earnings through the timing of income recognition from disposal of long-lived assets and investments (hereafter assets). Since managers can often choose the period during which an asset will be sold, and since the principle of acquisition cost underlying the accounting valuation of assets implies that changes in the market value of an asset between acquisition and sale are reported in the period of sale, it follows that there are opportunities for managers to manipulate earnings through the timing of asset sales at relatively low cost. Two common explanations for earnings manipulations are examined: the earnings-smoothing and the debt-equity hypotheses.1 The earnings-smoothing hypothesis predicts that earnings are manipulated to reduce fluctuations around some level that is considered normal for the firm (see, e.g., Ronen and \u2026",
        "year": 1993,
        "authors": "Eli Bartov"
      }
    ],
    "_9E4gkoAAAAJ": [
      {
        "title": "Design of observers for hybrid systems",
        "abstract": "A methodology for the design of dynamical observers for hybrid plants is proposed. The hybrid observer consists of two parts: a location observer and a continuous observer. The former identifies the current location of the hybrid plant, while the latter produces an estimate of the evolution of the continuous state of the hybrid plant. A synthesis procedure is offered when a set of properties on the hybrid plant is satisfied. The synthesized hybrid observer identifies the current location of the plant after a finite number of steps and converges exponentially to the continuous state.",
        "year": 2002,
        "authors": "Andrea Balluchi and Luca Benvenuti and Maria D Di Benedetto and Alberto L Sangiovanni-Vincentelli"
      },
      {
        "title": "Automotive engine control and hybrid systems: Challenges and opportunities",
        "abstract": "The design of engine control systems has been traditionally carried out using a mix of heuristic techniques validated by simulation and prototyping using approximate average-value models. However, the ever increasing demands on passengers' comfort, safety, emissions, and fuel consumption imposed by car manufacturers and regulations call for more robust techniques and the use of cycle-accurate models. We argue that these models must be hybrid because of the combination of time-domain and event-based behaviors. We present a hybrid model of the engine in which both continuous and discrete time-domain as well as event-based phenomena are modeled in a separate but integrated manner. Based on this model, we formalize the specification of the overall engine control by defining a number of hybrid control problems. To cope with the difficulties arising in the design of hybrid controllers, a design \u2026",
        "year": 2002,
        "authors": "Andrea Balluchi and Luca Benvenuti and Maria Domenica Di Benedetto and Claudio Pinello and Alberto L Sangiovanni-Vincentelli"
      },
      {
        "title": "Hamiltonian adaptive control of spacecraft",
        "abstract": "A new approach to the accurate attitude tracking control of rigid spacecraft handling large loads of unknown mass properties is proposed. The method, based on the construction of a physically motivated Lyapunov-like function, is inspired by the adaptive robot control algorithm of J.J.E. Slotine and W. Li (Int. J. Robot. Res., vol.6, no.3, 1987), and presents similar advantages over techniques based on inverse dynamics in terms of simplicity, easier approach to robustness issues, and adaptive capabilities. The approach is illustrated in simulations.< >",
        "year": 1990,
        "authors": "J-E Slotine and MD Di Benedetto"
      }
    ],
    "XMVtscAAAAAJ": [
      {
        "title": "Dimensionality reduction and motion clustering during activities of daily living: Three-, four-, and seven-degree-of-freedom arm movements",
        "abstract": "This paper is the first in a two-part series analyzing human arm and hand motion during a wide range of unstructured tasks. The wide variety of motions performed by the human arm during daily tasks makes it desirable to find representative subsets to reduce the dimensionality of these movements for a variety of applications, including the design and control of robotic and prosthetic devices. This paper presents a novel method and the results of an extensive human subjects study to obtain representative arm joint angle trajectories that span naturalistic motions during Activities of Daily Living (ADLs). In particular, we seek to identify sets of useful motion trajectories of the upper limb that are functions of a single variable, allowing, for instance, an entire prosthetic or robotic arm to be controlled with a single input from a user, along with a means to select between motions for different tasks. Data driven approaches are \u2026",
        "year": 2020,
        "authors": "Yuri Gloumakov and Adam J Spiers and Aaron M Dollar"
      },
      {
        "title": "Examining the impact of wrist mobility on reaching motion compensation across a discretely sampled workspace",
        "abstract": "This paper presents an effort to characterize the impact of wrist mobility on reaching motion compensation over an evenly sampled planar workspace. When the degrees of freedom of the arm are limited due to injury or amputation, the behavior of other joints is modified to achieve the same motion goals. Though several past studies have measured motion compensation for simulated activities of daily living, the results tend to be specific to one spatial configuration of user and objects. Conversely, this paper aims to understand how motions and compensation vary when the same task (reaching-and-grasping) is conducted at a variety of locations across in the workspace. This high-resolution sampling enables spatial patterns of unimpaired and impaired movement to be identified. To achieve this, joint angles and Cartesian trajectories of the upper body were recorded as able-bodied participants reached and grasped \u2026",
        "year": 2018,
        "authors": "Adam J Spiers and Yuri Gloumakov and Aaron M Dollar"
      },
      {
        "title": "Trajectory control\u2013an effective strategy for controlling multi-DOF upper limb prosthetic devices",
        "abstract": "Despite great innovations in upper-extremity prosthetic hardware in recent decades, controlling a multiple joint upper limb prosthesis such as an elbow/wrist/hand system is still an open clinical challenge, in large part due to an insufficient number of control inputs available to users. While simultaneous control is in its early stages, the common control approach is sequential control, in which joints and grasps are driven one at a time. In this paper, we introduce and evaluate a concept we call  trajectory control , that builds upon this approach, in which motions of the wrist, elbow, and shoulder DOFs (and subsets of them) are coupled into predefined sets of coordinated trajectories; to be selected by the user and driven with a single input variable. These trajectories were designed based on an earlier motion study of activities of daily life obtained from human demonstrations. We experimentally evaluate the efficacy of our \u2026",
        "year": 2022,
        "authors": "Yuri Gloumakov and Joao Bimbo and Aaron M Dollar"
      }
    ],
    "8BwddWMAAAAJ": [
      {
        "title": "The Effect of Audit Quality on Earnings Management*",
        "abstract": "This study examines the relation between audit quality and earnings management. Consistent with prior research, we treat audit quality as a dichotomous variable and assume that Big Six auditors are of higher quality than non\u2010Big Six auditors. Earnings management is captured by discretionary accruals that are estimated using a cross\u2010sectional version of the Jones 1991 model. Prior literature suggests that auditors are more likely to object to management's accounting choices that increase earnings (as opposed to decrease earnings) and that auditors are more likely to be sued when they are associated with financial statements that overstate earnings (as compared to understate earnings). Therefore, we hypothesize that clients of non\u2010Big Six auditors report discretionary accruals that increase income relatively more than the discretionary accruals reported by clients of Big Six auditors. This hypothesis is \u2026",
        "year": 1998,
        "authors": "Connie L Becker and Mark L DeFond and James Jiambalvo and KR Subramanyam"
      },
      {
        "title": "Debt covenant violation and manipulation of accruals",
        "abstract": "This paper examines the abnormal accruals of a sample of 94 firms that reported debt covenant violations in annual reports. We expect debt covenant restrictions to influence accounting choices in the year preceding and the year of violation. Time-series and cross-sectional models are used to estimate \u2018normal\u2019 accruals. In the year prior to violation, both models indicate that \u2018abnormal\u2019 total and working capital accruals are significantly positive. In the year of violation, there is evidence of positive abnormal working capital accruals after controlling for management changes and auditor going concern qualifications.",
        "year": 1994,
        "authors": "Mark L DeFond and James Jiambalvo"
      },
      {
        "title": "A review of archival auditing research",
        "abstract": "We define higher audit quality as greater assurance of high financial reporting quality. Researchers use many proxies for audit quality, with little guidance on choosing among them. We provide a framework for systematically evaluating their unique strengths and weaknesses. Because it is inextricably intertwined with financial reporting quality, audit quality also depends on firms\u2019 innate characteristics and financial reporting systems. Our review of the models commonly used to disentangle these constructs suggests the need for better conceptual guidance. Finally, we urge more research on the role of auditor and client competency in driving audit quality.",
        "year": 2014,
        "authors": "Mark DeFond and Jieying Zhang"
      }
    ],
    "U73rXq8AAAAJ": [
      {
        "title": "Agroecology: A review from a global-change perspective",
        "abstract": "This review by a multidisciplinary team maps key components and emerging connections within the intellectual landscape of agroecology. We attempt to extend and preview agroecology as a discipline in which agriculture can be conceptualized within the context of global change and studied as a coupled system involving a wide range of social and natural processes. This intrinsic coupling, combined with powerful emerging drivers of change, presents challenges for the practice of agroecology and agriculture itself, as well as providing the framework for some of the most innovative research areas and the greatest potential for innovation for a sustainable future in agriculture. The objective of this review is to identify forward-looking scientific questions to enhance the relevance of agroecology for the key challenges of mitigating environmental impacts of agriculture while dramatically increasing global food production \u2026",
        "year": 2011,
        "authors": "Thomas P Tomich and Sonja Brodt and Howard Ferris and Ryan Galt and William R Horwath and Ermias Kebreab and Johan HJ Leveau and Daniel Liptzin and Mark Lubell and Pierre Merel and Richard Michelmore and Todd Rosenstock and Kate Scow and Johan Six and Neal Williams and Louie Yang"
      },
      {
        "title": "The moral economy is a double-edged sword: explaining farmer earnings and self-exploitation in Community Supported Agriculture",
        "abstract": "In this article I develop a political economic understanding of community-supported agriculture (CSA). I first develop the relevance of three concepts\u2014economic rents, self-exploitation, and social embeddedness\u2014to CSA and then introduce a framework that relates CSA farmers\u2019 earnings to the average rate of profit, economic rents, and self-exploitation. I then examine qualitative and quantitative data from a study of 54 CSAs in California\u2019s Central Valley and surrounding foothills to explain the wide range of farmers\u2019 earnings in relation to the characteristics of production of CSAs, the social embeddedness of CSAs, and the farmers\u2019 motivations and rationalities. Qualitative data from interviews are used to interpret the results of an ordinary least squares regression analysis showing that (1) farmers\u2019 age, number of employees, and type of CSA strongly shape farmers\u2019 earnings; (2) the moral economy of CSA cuts both \u2026",
        "year": 2013,
        "authors": "Ryan E Galt"
      },
      {
        "title": "Globalization and multi-spatial trends in the coverage of protected-area conservation (1980\u20132000)",
        "abstract": "This study is focused on the global expansion of protected-area coverage that occurred during the 1980\u20132000 period. We examine the multi-scale patterning of four of the basic facets of this expansion: i) estimated increases at the world-regional and country-level scales of total protected-area coverage; ii) transboundary protected areas; iii) conservation corridor projects; and iv) type of conservation management. Geospatial patterning of protectedarea designations is a reflection of the priorities of global conservation organizations and the globalization of post- Cold War political and economic arrangements. Local and national-level factors (political leadership and infrastructure) as well as international relations such as multilateral and bilateral aid combine with these globalization processes to impact the extent, type, and location of protected-area designations. We conclude that the interaction of these factors led \u2026",
        "year": 2004,
        "authors": "Karl S Zimmerer and Ryan E Galt and Margaret V Buck"
      }
    ],
    "EV0ft6UAAAAJ": [
      {
        "title": "Motor-augmented wrist-driven orthosis: Flexible grasp assistance for people with spinal cord injury",
        "abstract": "This paper presents the design of a motor-augmented wrist-driven orthosis (MWDO) for improved grasp articulation for people with C6-C7 spinal cord injuries. Based on the traditional passive, wrist-driven orthotic (WDO) mechanism, the MWDO allows for both body-powered and motorized actuation of the grasping output thus enabling more flexible and dexterous operation. Here, the associated control scheme enables active decoupling of wrist and finger articulation, which can be useful during certain phases of manipulation tasks. An additional modification to the traditional WDO is the integration of a magnetic latch at the Distal Interphalangeal (DIP) joint allowing for improved pinching. These abilities are demonstrated with common activities of daily living (ADL).",
        "year": 2020,
        "authors": "Andrew IW McPherson and Vatsal V Patel and Phillip R Downey and Ahmed Abbas Alvi and Michael E Abbott and Hannah S Stuart"
      },
      {
        "title": "Modulating wrist-hand kinematics in motorized-assisted grasping with c5-6 spinal cord injury",
        "abstract": "Loss of hand function severely impacts the independence of people with spinal cord injuries (SCI) between C5 and C7. To achieve limited grasps or strengthen grip around small objects, these individuals commonly employ a compensatory technique to passively induce finger flexion by extending their wrist. Passive body-powered devices using wrist-driven actuation have been developed to assist this function, in addition to advancements in active robotic devices aimed at finger articulation for dexterous manipulation. Nevertheless, neither passive nor active devices see wide adoption and retention in the long-term. Here we present an unconventional system for combining aspects of both passive and active actuation and show that actively modulating the relationship between passive wrist and finger movement can impact both performance and kinematic metrics of upper body compensation. This study comprises \u2026",
        "year": 2023,
        "authors": "Erin Y Chang and Andrew IW McPherson and Ryan C Adolf and Yuri Gloumakov and Hannah S Stuart"
      },
      {
        "title": "Tenodesis grasp emulator: Kinematic assessment of wrist-driven orthotic control",
        "abstract": "Wrist-driven orthotics have been designed to assist people with C6-7 spinal cord injury, however, the kinematic constraint imposed by such a control strategy can impede mobility and lead to abnormal body motion. This study characterizes body compensation using the novel Tenodesis Grasp Emulator, an adaptor orthotic that allows for the investigation of tenodesis grasping in subjects with unimpaired hand function. Subjects perform a series of grasp-and-release tasks in order to compare normal (test control) and constrained wrist-driven modes, showing significant compensation as a result of the constraint. A motor-augmented mode is also compared against traditional wrist-driven operation, to explore the potential role of hybrid human-robot control. We find that both the passive wrist-driven and motor-augmented modes fulfill different roles throughout various tasks tested. Thus, we conclude that a flexible control \u2026",
        "year": 2022,
        "authors": "Erin Y Chang and Raghid Mardini and Andrew IW McPherson and Yuri Gloumakov and Hannah S Stuart"
      }
    ],
    "in-6RDsAAAAJ": [
      {
        "title": "Enhanced electrocatalytic CO2 reduction via field-induced reagent concentration",
        "abstract": "Electrochemical reduction of carbon dioxide (CO2) to carbon monoxide (CO) is the first step in the synthesis of more complex carbon-based fuels and feedstocks using renewable electricity,,,,,,. Unfortunately, the reaction suffers from slow kinetics, owing to the low local concentration of CO2 surrounding typical CO2 reduction reaction catalysts. Alkali metal cations are known to overcome this limitation through non-covalent interactions with adsorbed reagent species,, but the effect is restricted by the solubility of relevant salts. Large applied electrode potentials can also enhance CO2 adsorption, but this comes at the cost of increased hydrogen (H2) evolution. Here we report that nanostructured electrodes produce, at low applied overpotentials, local high electric fields that concentrate electrolyte cations, which in turn leads to a high local concentration of CO2 close to the active CO2 reduction reaction surface \u2026",
        "year": 2016,
        "authors": "Min Liu and Yuanjie Pang and Bo Zhang and Phil De Luna and Oleksandr Voznyy and Jixian Xu and Xueli Zheng and Cao Thang Dinh and Fengjia Fan and Changhong Cao and F Pelayo Garc\u00eda De Arquer and Tina Saberi Safaei and Adam Mepham and Anna Klinkova and Eugenia Kumacheva and Tobin Filleter and David Sinton and Shana O Kelley and Edward H Sargent"
      },
      {
        "title": "What should we make with CO2 and how can we make it?",
        "abstract": "In this forward-looking Perspective, we discuss the current state of technology and the economics of electrocatalytic transformation of CO2 into various chemical fuels. Our analysis finds that short-chain simple building-block molecules currently present the most economically compelling targets. Making an optimistic prediction of technology advancement in the future, we propose the gradual rise of photocatalytic, CO2 polymerization, biohybrid, and molecular machine technologies to augment and enhance already practical electrocatalytic CO2 conversion methods.",
        "year": 2018,
        "authors": "Oleksandr S Bushuyev and Phil De Luna and Cao Thang Dinh and Ling Tao and Genevieve Saur and Jao van de Lagemaat and Shana O Kelley and Edward H Sargent"
      },
      {
        "title": "Electron transfer between bases in double helical DNA",
        "abstract": "Fluorescent analogs of adenine that selectively oxidize guanine were used to investigate photoinduced electron transfer through the DNA \u03c0-stack as a function of reactant stacking and energetics. Small variations in these factors led to profound changes in the kinetics and distance dependences of DNA-mediated electron-transfer reactions. Values of \u03b2, a parameter reflecting the dependence of electron transfer on distance, ranged from 0.1 to 1.0 per angstrom. Strong stacking interactions result in the fastest electron-transfer kinetics. Electrons are thus transported preferentially through an intrastrand rather than interstrand pathway. Reactant energetics also modulate the distance dependence of DNA-mediated charge transport. These studies may resolve the range of disparate results previously reported, and paradigms must now be developed to describe these properties of the DNA \u03c0-stack, which can range from \u2026",
        "year": 1999,
        "authors": "Shana O Kelley and Jacqueline K Barton"
      }
    ],
    "AroaLZIAAAAJ": [
      {
        "title": "Multiple exposures: Korean bodies and the transnational imagination",
        "abstract": "Since the turn of the millennium, emphasis on bodil perfection has become increasingl central to the media industries of South Korea (henceforth Korea), and a focus on ideal bodies has permeated popular discourse more generall. 1 Although ie s on ph sical appearance built on longstanding notions of its importance in announcing status continue to be informed ba patriarchal order, a palpabl intensif ing commodification of the bod in Korea's media-saturated, consumer capitalist culture is gi ing rise to ne er concepts of corporeal self-discipline and reconfiguring not onl of ho \u02bbbeaut\u2019, \u02bbmasculinit\u2019and \u02bbfemininit\u2019are represented, but ho the modern national self is understood.While Connell (2005) has argued that multiple \u201cmasculinities\u201d are produced in relation to \u201cfemininities,\u201d she also asserts that mechanics of power create hegemonic ersions of masculinit and femininit. Such paradigms of gender performance are disseminated in manifold modes from e er da discourse to literar and screen narrati e, but in this article we focus on the \u201cscopic regime\u201d(Metz 1982) that creates ideal masculine and feminine bod t pes through the reproduction of images in a ariet of isual genres and texts. Further, following Debord (1995: 7) we examine social relations as mediated b images: in Korea transcultural, gendered practices of the bod ha e intersected with the imperati es of a globall oriented nationalism, neoliberal policies emphasizing self-care (Rose 2001), and",
        "year": 2012,
        "authors": "Stephen Epstein and Rachael M Joo"
      },
      {
        "title": "Girls\u2019 generation? Gender,(dis) empowerment, and K-pop",
        "abstract": "The hottest phrase in Korea nowadays is undeniably'girl group.'But girl group fever is more than just a trend: it's symbolic of a cultural era that is embracing the expulsion of authoritarian ideology.\" So reads the content blurb for a story on the rise of girl groups in the March 2010 issue of Korea, a public relations magazine published under the auspices of the Korean Culture and Information Service. Nonetheless, despite official, top-down promotion and cheerful assertions that this phenomenon is a liberating pop movement, a reading of the lyrics and visual codes of the music videos of popular contemporary Korea girl groups raises serious questions about the empowering nature of\" Girl Group Fever.\" In this paper, we will engage in a close analysis of the music and videos of groups such as the Wonder Girls, Girls' Generation, KARA, T-ara and the discourse that has surrounded their rise to popularity in South Korea in order to deconstruct the notion that contemporary consumer society is making a radical break from more traditional, deeply embedded power structures. We will argue that a set of recurrent tropes in the studied media and marketing presentation of Korean girl groups undercuts claims to a progressive ethos. In particular, as we hope to demonstrate, girl group videos and lyrics often fall into one of three categories: first of all, while girl group singers can express desire in potentially empowering fashion, the viewer is generally constructed as male, and expression of desire is accompanied by a coyness and feigned innocence that returns power to men (Girls' Generation's\" Gee\" and\" Oh\"; T-ara's\" Like the First Time\"; KARA's\" Mister\"). A \u2026",
        "year": 2014,
        "authors": "Stephen Epstein and James Turnbull"
      },
      {
        "title": "Now on my way to meet who? South Korean television, North Korean refugees, and the dilemmas of representation",
        "abstract": "In 2011, the recently established South Korean broadcasting network Channel-A launched Ije mannareo gamnida (Now on My Way to Meet You), a program whose format brings together a group of a dozen or more female talbukja (North Korean refugees) 2 on a weekly basis. These women interact with host Nam Hui-seok, an additional female co-host (or, in the earlier episodes, two), and a panel composed of four male South Korean entertainers. Episodes typically open in a lighthearted manner, with conversation about daily life in North Korea alongside mild flirtation between the Southern male and Northern female participants, often involving song and dance, but climax with a talbuk seuteori, an emotionally harrowing narrative from one of the border-crossers detailing her exodus from North Korea. Via this framework Ije mannareo gamnida attempts to nurture the integration of North Korean refugees into South Korean society; personalization of their plight occurs in conjunction with reminders of a shared Korean identity maintained despite the regime they have fled, which is depicted as cruel, repressive and backward. The show has proven a minor hit within South Korea and received coverage from local and global media (see, eg, Kim 2012; Choi 2012; Noce 2012).The unusual subject matter of Ije mannareo gamnida itself renders the show worthy of analysis; equally significantly, it offers a useful window into attempts to address South Korea\u2019s increasingly diverse society, which now includes a large number of North Koreans, as well as media practice in the face of this demographic shift. Nevertheless, other than journalistic treatment, only a \u2026",
        "year": 2013,
        "authors": "Christopher K Green and Stephen Epstein"
      }
    ],
    "NvKHgzkAAAAJ": [
      {
        "title": "CryptDB: Protecting confidentiality with encrypted query processing",
        "abstract": "Online applications are vulnerable to theft of sensitive information because adversaries can exploit software bugs to gain access to private data, and because curious or malicious administrators may capture and leak data. CryptDB is a system that provides practical and provable confidentiality in the face of these attacks for applications backed by SQL databases. It works by executing SQL queries over encrypted data using a collection of efficient SQL-aware encryption schemes. CryptDB can also chain encryption keys to user passwords, so that a data item can be decrypted only by using the password of one of the users with access to that data. As a result, a database administrator never gets access to decrypted data, and even if all servers are compromised, an adversary cannot decrypt the data of any user who is not logged in. An analysis of a trace of 126 million SQL queries from a production MySQL server \u2026",
        "year": 2011,
        "authors": "Raluca Ada Popa and Catherine MS Redfield and Nickolai Zeldovich and Hari Balakrishnan"
      },
      {
        "title": "Machine learning classification over encrypted data",
        "abstract": "Machine learning classification is used in numerous settings nowadays, such as medical or genomics predictions, spam detection, face recognition, and financial predictions. Due to privacy concerns in some of these applications, it is important that the data and the classifier remain confidential. In this work, we construct three major classification protocols that satisfy this privacy constraint: hyperplane decision, Na\u00efve Bayes, and decision trees. These protocols may also be combined with AdaBoost. They rely on a library of building blocks for constructing classifiers securely, and we demonstrate the versatility of this library by constructing a face detection classifier. Our protocols are efficient, taking milliseconds to a few seconds to perform a classification when running on real medical datasets.",
        "year": 2014,
        "authors": "Raphael Bost and Raluca Ada Popa and Stephen Tu and Shafi Goldwasser"
      },
      {
        "title": "Cloud programming simplified: A berkeley view on serverless computing",
        "abstract": "Serverless cloud computing handles virtually all the system administration operations needed to make it easier for programmers to use the cloud. It provides an interface that greatly simplifies cloud programming, and represents an evolution that parallels the transition from assembly language to high-level programming languages. This paper gives a quick history of cloud computing, including an accounting of the predictions of the 2009 Berkeley View of Cloud Computing paper, explains the motivation for serverless computing, describes applications that stretch the current limits of serverless, and then lists obstacles and research opportunities required for serverless computing to fulfill its full potential. Just as the 2009 paper identified challenges for the cloud and predicted they would be addressed and that cloud use would accelerate, we predict these issues are solvable and that serverless computing will grow to dominate the future of cloud computing.",
        "year": 2019,
        "authors": "Eric Jonas and Johann Schleier-Smith and Vikram Sreekanti and Chia-Che Tsai and Anurag Khandelwal and Qifan Pu and Vaishaal Shankar and Joao Carreira and Karl Krauth and Neeraja Yadwadkar and Joseph E Gonzalez and Raluca Ada Popa and Ion Stoica and David A Patterson"
      }
    ],
    "tDIJwxsAAAAJ": [
      {
        "title": "Narrow and brittle or broad and nimble? Comparing adaptive capacity in simplifying and diversifying farming systems",
        "abstract": "Humanity faces a triple threat of climate change, biodiversity loss, and global food insecurity. In response, increasing the general adaptive capacity of farming systems is essential. We identify two divergent strategies for building adaptive capacity. Simplifying processes seek to narrowly maximize production by shifting the basis of agricultural production toward centralized control of socially and ecologically homogenized systems. Diversifying processes cultivate social-ecological complexity in order to provide multiple ecosystem services, maintain management flexibility, and promote coordinated adaptation across levels. Through five primarily United States focused cases of distinct agricultural challenges\u2014foodborne pathogens, drought, marginal lands, labor availability, and land access and tenure\u2014we compare simplifying and diversifying responses to assess how these pathways differentially enhance or degrade the adaptive capacity of farming systems in the context of the triple threat. These cases show that diversifying processes can weave a form of broad and nimble adaptive capacity that is fundamentally distinct from the narrow and brittle adaptive capacity produced through simplification. We find that while there are structural limitations and tradeoffs to diversifying processes, adaptive capacity can be facilitated by empowering people and enhancing ecosystem functionality to proactively distribute resources and knowledge where needed and to nimbly respond to changing circumstances. Our cases suggest that, in order to garner the most adaptive benefits from diversification, farming systems should balance the pursuit of multiple goals \u2026",
        "year": 2021,
        "authors": "Margiana Petersen-Rockney and Patrick Baur and Aidee Guzman and S Franz Bender and Adam Calo and Federico Castillo and Kathryn De Master and Antoinette Dumont and Kenzo Esquivel and Claire Kremen and James LaChance and Maria Mooshammer and Joanna Ory and Mindy J Price and Yvonne Socolar and Paige Stanley and Alastair Iles and Timothy Bowles"
      },
      {
        "title": "Quantifying direct yield benefits of soil carbon increases from cover cropping",
        "abstract": "Cropland management practices that restore soil organic carbon (SOC) are increasingly presented as climate solutions that also enhance yields. But how often these benefits align at the farm level\u2014the scale of farmers\u2019 decision making\u2014remains uncertain. We examined concurrent SOC and yield responses to cover cropping, including their direct connection, with a global meta-analysis. Cover cropping simultaneously increased yields and SOC in 59.7% of 434 paired observations. Increases in SOC directly increased crop yields in soils with initial SOC concentrations below 11.6\u2009g\u2009kg\u22121; for example, a change from 5\u2009g\u2009kg\u22121 to 6\u2009g\u2009kg\u22121 increased yields by +2.4%. These yield benefits of SOC did not decline as nitrogen inputs increased or when legume cover crops were used, suggesting fertility inputs cannot substitute for SOC effects. Regardless of direct effects of SOC increases on yields, integrating legume \u2026",
        "year": 2023,
        "authors": "Isaac Vendig and Aidee Guzman and Gisel De La Cerda and Kenzo Esquivel and Allegra C Mayer and Lauren Ponisio and Timothy M Bowles"
      },
      {
        "title": "The \u201csweet spot\u201d in the middle: why do mid-scale farms adopt diversification practices at higher rates?",
        "abstract": "In the past few decades, farmers and researchers have firmly established that biologically diversified farming systems improve ecosystem services both on and off the farm, producing economic benefits for farmers and ecological benefits for surrounding landscapes. However, adoption of these practices has been slow, requiring a more nuanced examination of both barriers and opportunities to improve adoption rates. While previous research has demonstrated that both individual and structural factors shape farmers' decisions about whether to adopt diversification practices, this study aims to understand the interaction of these individual and structural factors, and how they relate to farm scale. Based on 20 interviews with organic lettuce growers on the Central Coast of California, as well as 8 interviews with technical assistance providers who work with these growers, we constructed a typology to help elucidate the distinct contexts that shape growers' decisions about diversification practices. This typology, which reflects the structural influence of land rent and supply chains, divides growers into three categories: limited resource, mid-scale diversified, or wholesale. In this economic context, limited resource and wholesale growers both experience significant barriers that constrain the adoption of diversification practices, while some mid-scale diversified growers have found a \u201csweet spot\u201d for managing agroecosystems that can succeed in both economic and ecological terms. The key enabling factors that allow these farmers to choose diversification, however, are not directly related to their farm size, but have more to do with secure land tenure \u2026",
        "year": 2021,
        "authors": "Kenzo Emiliano Esquivel and Liz Carlisle and Alison Ke and Elissa M Olimpi and Patrick Baur and Joanna Ory and Hannah Waterhouse and Alastair Iles and Daniel S Karp and Claire Kremen and Timothy M Bowles"
      }
    ],
    "ZNYYv18AAAAJ": [
      {
        "title": "Fractal assembly of micrometre-scale DNA origami arrays with arbitrary patterns",
        "abstract": "Self-assembled DNA nanostructures enable nanometre-precise patterning that can be used to create programmable molecular machines,,,, and arrays of functional materials,,. DNA origami is particularly versatile in this context because each DNA strand in the origami nanostructure occupies a unique position and can serve as a uniquely addressable pixel. However, the scale of such structures,,, has been limited to about 0.05 square micrometres, hindering applications that demand a larger layout and integration with more conventional patterning methods. Hierarchical multistage assembly of simple sets of tiles, can in principle overcome this limitation, but so far has not been sufficiently robust to enable successful implementation of larger structures using DNA origami tiles. Here we show that by using simple local assembly rules that are modified and applied recursively throughout a hierarchical, multistage \u2026",
        "year": 2017,
        "authors": "Grigory Tikhomirov and Philip Petersen and Lulu Qian"
      },
      {
        "title": "Bioorthogonal cyclization-mediated in situ self-assembly of small-molecule probes for imaging caspase activity in vivo",
        "abstract": "Directed self-assembly of small molecules in living systems could enable a myriad of applications in biology and medicine, and already this has been used widely to synthesize supramolecules and nano/microstructures in solution and in living cells. However, controlling the self-assembly of synthetic small molecules in living animals is challenging because of the complex and dynamic in vivo physiological environment. Here we employ an optimized first-order bioorthogonal cyclization reaction to control the self-assembly of a fluorescent small molecule, and demonstrate its in vivo applicability by imaging caspase-3/7 activity in human tumour xenograft mouse models of chemotherapy. The fluorescent nanoparticles assembled in situ were imaged successfully in both apoptotic cells and tumour tissues using three-dimensional structured illumination microscopy. This strategy combines the advantages offered by small \u2026",
        "year": 2014,
        "authors": "Deju Ye and Adam J Shuhendler and Lina Cui and Ling Tong and Sui Seng Tee and Grigory Tikhomirov and Dean W Felsher and Jianghong Rao"
      },
      {
        "title": "MRI of Tumor-Associated Macrophages with Clinically Applicable Iron Oxide Nanoparticles",
        "abstract": " Purpose: The presence of tumor-associated macrophages (TAM) in breast cancer correlates strongly with poor outcome. The purpose of this study was to develop a clinically applicable, noninvasive diagnostic assay for selective targeting and visualization of TAMs in breast cancer, based on magnetic resonanceI and clinically applicable iron oxide nanoparticles. Experimental Design: F4/80-negative mammary carcinoma cells and F4/80-positive TAMs were incubated with iron oxide nanoparticles and were compared with respect to magnetic resonance signal changes and iron uptake. MMTV-PyMT transgenic mice harboring mammary carcinomas underwent nanoparticle-enhanced magnetic resonance imaging (MRI) up to 1 hour and 24 hours after injection. The tumor enhancement on MRIs was correlated with the presence and location of TAMs and nanoparticles by confocal microscopy \u2026",
        "year": 2011,
        "authors": "Heike E Daldrup-Link and Daniel Golovko and Brian Ruffell and David G DeNardo and Rosalinda Castaneda and Celina Ansari and Jianghong Rao and Grigory A Tikhomirov and Michael F Wendland and Claire Corot and Lisa M Coussens"
      }
    ],
    "e9gUdKwAAAAJ": [
      {
        "title": "BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning",
        "abstract": "Datasets drive vision progress, yet existing driving datasets are impoverished in terms of visual content and supported tasks to study multitask learning for autonomous driving. Researchers are usually constrained to study a small set of problems on one dataset, while real-world computer vision applications require performing tasks of various complexities. We construct BDD100K, the largest driving video dataset with 100K videos and 10 tasks to evaluate the exciting progress of image recognition algorithms on autonomous driving. The dataset possesses geographic, environmental, and weather diversity, which is useful for training models that are less likely to be surprised by new conditions. Based on this diverse dataset, we build a benchmark for heterogeneous multitask learning and study how to solve the tasks together. Our experiments show that special training strategies are needed for existing models to perform such heterogeneous tasks. BDD100K opens the door for future studies in this important venue.",
        "year": 2020,
        "authors": "Fisher Yu and Haofeng Chen and Xin Wang and Wenqi Xian and Yingying Chen and Fangchen Liu and Vashisht Madhavan and Trevor Darrell"
      },
      {
        "title": "Phi-3 technical report: A highly capable language model locally on your phone",
        "abstract": "We introduce phi-3-mini, a 3.8 billion parameter language model trained on 3.3 trillion tokens, whose overall performance, as measured by both academic benchmarks and internal testing, rivals that of models such as Mixtral 8x7B and GPT-3.5 (e.g., phi-3-mini achieves 69% on MMLU and 8.38 on MT-bench), despite being small enough to be deployed on a phone. Our training dataset is a scaled-up version of the one used for phi-2, composed of heavily filtered publicly available web data and synthetic data. The model is also further aligned for robustness, safety, and chat format. We also provide parameter-scaling results with a 7B, 14B models trained for 4.8T tokens, called phi-3-small, phi-3-medium, both significantly more capable than phi-3-mini (e.g., respectively 75%, 78% on MMLU, and 8.7, 8.9 on MT-bench). To enhance multilingual, multimodal, and long-context capabilities, we introduce three models in the phi-3.5 series: phi-3.5-mini, phi-3.5-MoE, and phi-3.5-Vision. The phi-3.5-MoE, a 16 x 3.8B MoE model with 6.6 billion active parameters, achieves superior performance in language reasoning, math, and code tasks compared to other open-source models of similar scale, such as Llama 3.1 and the Mixtral series, and on par with Gemini-1.5-Flash and GPT-4o-mini. Meanwhile, phi-3.5-Vision, a 4.2 billion parameter model derived from phi-3.5-mini, excels in reasoning tasks and is adept at handling both single-image and text prompts, as well as multi-image and text prompts.",
        "year": 2024,
        "authors": "Marah Abdin and Jyoti Aneja and Hany Awadalla and Ahmed Awadallah and Ammar Ahmad Awan and Nguyen Bach and Amit Bahree and Arash Bakhtiari and Jianmin Bao and Harkirat Behl and Alon Benhaim and Misha Bilenko and Johan Bjorck and S\u00e9bastien Bubeck and Martin Cai and Qin Cai and Vishrav Chaudhary and Dong Chen and Dongdong Chen and Weizhu Chen and Yen-Chun Chen and Yi-Ling Chen and Hao Cheng and Parul Chopra and Xiyang Dai and Matthew Dixon and Ronen Eldan and Victor Fragoso and Jianfeng Gao and Mei Gao and Min Gao and Amit Garg and Allie Del Giorno and Abhishek Goswami and Suriya Gunasekar and Emman Haider and Junheng Hao and Russell J Hewett and Wenxiang Hu and Jamie Huynh and Dan Iter and Sam Ade Jacobs and Mojan Javaheripi and Xin Jin and Nikos Karampatziakis and Piero Kauffmann and Mahoud Khademi and Dongwoo Kim and Young Jin Kim and Lev Kurilenko and James R Lee and Yin Tat Lee and Yuanzhi Li and Yunsheng Li and Chen Liang and Lars Liden and Xihui Lin and Zeqi Lin and Ce Liu and Liyuan Liu and Mengchen Liu and Weishung Liu and Xiaodong Liu and Chong Luo and Piyush Madan and Ali Mahmoudzadeh and David Majercak and Matt Mazzola and Caio C\u00e9sar Teodoro Mendes and Arindam Mitra and Hardik Modi and Anh Nguyen and Brandon Norick and Barun Patra and Daniel Perez-Becker and Thomas Portet and Reid Pryzant and Heyang Qin and Marko Radmilac and Liliang Ren and Gustavo de Rosa and Corby Rosset and Sambudha Roy and Olatunji Ruwase and Olli Saarikivi and Amin Saied and Adil Salim and Michael Santacroce and Shital Shah and Ning Shang and Hiteshi Sharma and Yelong Shen and Swadheen Shukla and Xia Song and Masahiro Tanaka and Andrea Tupini and Praneetha Vaddamanu and Chunyu Wang and Guanhua Wang and Lijuan Wang and Shuohang Wang and Xin Wang and Yu Wang and Rachel Ward and Wen Wen and Philipp Witte and Haiping Wu and Xiaoxia Wu and Michael Wyatt and Bin Xiao and Can Xu and Jiahang Xu and Weijian Xu and Jilong Xue and Sonali Yadav and Fan Yang and Jianwei Yang and Yifan Yang and Ziyi Yang and Donghan Yu and Lu Yuan and Chenruidong Zhang and Cyril Zhang and Jianwen Zhang and Li Lyna Zhang and Yi Zhang and Yue Zhang and Yunan Zhang and Xiren Zhou"
      },
      {
        "title": "Few-shot Object Detection via Feature Reweighting",
        "abstract": "Conventional training of a deep CNN based object detector demands a large number of bounding box annotations, which may be unavailable for rare categories. In this work we develop a few-shot object detector that can learn to detect novel objects from only a few annotated examples. Our proposed model leverages fully labeled base classes and quickly adapts to novel classes, using a meta feature learner and a reweighting module within a one-stage detection architecture. The feature learner extracts meta features that are generalizable to detect novel object classes, using training data from base classes with sufficient samples. The reweighting module transforms a few support examples from the novel classes to a global vector that indicates the importance or relevance of meta features for detecting the corresponding objects. These two modules, together with a detection prediction module, are trained end-to-end based on an episodic few-shot learning scheme and a carefully designed loss function. Through extensive experiments we demonstrate that our model outperforms well-established baselines by a large margin for few-shot object detection, on multiple datasets and settings. We also present analysis on various aspects of our proposed model, aiming to provide some inspiration for future few-shot detection works.",
        "year": 2019,
        "authors": "Bingyi Kang and Zhuang Liu and Xin Wang and Fisher Yu and Jiashi Feng and Trevor Darrell"
      }
    ],
    "3yT6IX4AAAAJ": [
      {
        "title": "Guidelines for the use and interpretation of assays for monitoring autophagy (4th edition)1",
        "abstract": "In 2008, we published the first set of guidelines for standardizing research in autophagy. Since then, this topic has received increasing attention, and many scientists have entered the field. Our knowledge base and relevant new technologies have also been expanding. Thus, it is important to formulate on a regular basis updated guidelines for monitoring autophagy in different organisms. Despite numerous reviews, there continues to be confusion regarding acceptable methods to evaluate autophagy, especially in multicellular eukaryotes. Here, we present a set of guidelines for investigators to select and interpret methods to examine autophagy and related processes, and for reviewers to provide realistic and reasonable critiques of reports that are focused on these processes. These guidelines are not meant to be a dogmatic set of rules, because the appropriateness of any assay largely depends on the question \u2026",
        "year": 2021,
        "authors": "Daniel J Klionsky and Amal Kamal Abdel-Aziz and Sara Abdelfatah and Mahmoud Abdellatif and Asghar Abdoli and Steffen Abel and Hagai Abeliovich and Marie H Abildgaard and Yakubu Princely Abudu and Abraham Acevedo-Arozena and Iannis E Adamopoulos and Khosrow Adeli and Timon E Adolph and Annagrazia Adornetto and Elma Aflaki and Galila Agam and Anupam Agarwal and Bharat B Aggarwal and Maria Agnello and Patrizia Agostinis and Javed N Agrewala and Alexander Agrotis and Patricia V Aguilar and S Tariq Ahmad and Zubair M Ahmed and Ulises Ahumada-Castro and Sonja Aits and Shu Aizawa and Yunus Akkoc and Tonia Akoumianaki and Hafize Aysin Akpinar and Ahmed M Al-Abd and Lina Al-Akra and Abeer Al-Gharaibeh and Moulay A Alaoui-Jamali and Simon Alberti and El\u00edsabet Alcocer-G\u00f3mez and Cristiano Alessandri and Muhammad Ali and M Abdul Alim Al-Bari and Saeb Aliwaini and Javad Alizadeh and Eug\u00e8nia Almacellas and Alexandru Almasan and Alicia Alonso and Guillermo D Alonso and Nihal Altan-Bonnet and Dario C Altieri and \u00c9lida MC \u00c1lvarez and Sara Alves and Cristine Alves da Costa and Mazen M Alzaharna and Marialaura Amadio and Consuelo Amantini and Cristina Amaral and Susanna Ambrosio and Amal O Amer and Veena Ammanathan and Zhenyi An and Stig U Andersen and Shaida A Andrabi and Magaiver Andrade-Silva and Allen M Andres and Sabrina Angelini and David Ann and Uche C Anozie and Mohammad Y Ansari and Pedro Antas and Adam Antebi and Zuri\u00f1e Ant\u00f3n and Tahira Anwar and Lionel Apetoh and Nadezda Apostolova and Toshiyuki Araki and Yasuhiro Araki and Kohei Arasaki and Wagner L Ara\u00fajo and Jun Araya and Catherine Arden and Maria-Angeles Ar\u00e9valo and Sandro Arguelles and Esperanza Arias and Jyothi Arikkath and Hirokazu Arimoto and Aileen R Ariosa and Darius Armstrong-James and Laetitia Arnaun\u00e9-Pelloquin and Angeles Aroca and Daniela S Arroyo and Ivica Arsov and Rub\u00e9n Artero and Dalia Maria Lucia Asaro and Michael Aschner and Milad Ashrafizadeh and Osnat Ashur-Fabian and Atanas G Atanasov and Alicia K Au and Patrick Auberger and Holger W Auner and Laure Aurelian and Riccardo Autelli and Laura Avagliano and Yenniffer \u00c1valos and Sanja Aveic and C\u00e9lia Alexandra Aveleira and Tamar Avin-Wittenberg and Yucel Aydin and Scott Ayton and Srinivas Ayyadevara and Maria Azzopardi and Misuzu Baba and Jonathan M Backer and Steven K Backues and Dong-Hun Bae and Ok-Nam Bae and Soo Han Bae and Eric H Baehrecke and Ahruem Baek and Seung-Hoon Baek and Sung Hee Baek and Giacinto Bagetta and Agnieszka Bagniewska-Zadworna and Hua Bai and Jie Bai and Xiyuan Bai and Yidong Bai and Nandadulal Bairagi and Shounak Baksi and Teresa Balbi and Cosima T Baldari and Walter Balduini and Andrea Ballabio and Maria Ballester and Salma Balazadeh and Rena Balzan and Rina Bandopadhyay and Sreeparna Banerjee and Sulagna Banerjee and \u00c1gnes B\u00e1nr\u00e9ti and Yan Bao and Mauricio S Baptista and Alessandra Baracca and Cristiana Barbati and Ariadna Bargiela and Daniela Baril\u00e0 and Peter G Barlow and Sami J Barmada and Esther Barreiro and George E Barreto and Jiri Bartek"
      },
      {
        "title": "Hypoxia\u2014a key regulatory factor in tumour growth",
        "abstract": "Cells undergo a variety of biological responses when placed in hypoxic conditions, including activation of signalling pathways that regulate proliferation, angiogenesis and death. Cancer cells have adapted these pathways, allowing tumours to survive and even grow under hypoxic conditions, and tumour hypoxia is associated with poor prognosis and resistance to radiation therapy. Many elements of the hypoxia-response pathway are therefore good candidates for therapeutic targeting.",
        "year": 2002,
        "authors": "Adrian L Harris"
      }
    ],
    "p0sQC6sAAAAJ": [
      {
        "title": "Spark: Cluster computing with working sets",
        "abstract": "MapReduce and its variants have been highly successful in implementing large-scale data-intensive applications on commodity clusters. However, most of these systems are built around an acyclic data flow model that is not suitable for other popular applications. This paper focuses on one such class of applications: those that reuse a working set of data across multiple parallel operations. This includes many iterative machine learning algorithms, as well as interactive data analysis tools. We propose a new framework called Spark that supports these applications while retaining the scalability and fault tolerance of MapReduce. To achieve these goals, Spark introduces an abstraction called resilient distributed datasets (RDDs). An RDD is a read-only collection of objects partitioned across a set of machines that can be rebuilt if a partition is lost. Spark can outperform Hadoop by 10x in iterative machine learning jobs, and can be used to interactively query a 39 GB dataset with sub-second response time.",
        "year": 2010,
        "authors": "Matei Zaharia and Mosharaf Chowdhury and Michael J Franklin and Scott Shenker and Ion Stoica"
      },
      {
        "title": "Resilient distributed datasets: A {Fault-Tolerant} abstraction for {In-Memory} cluster computing",
        "abstract": "We present Resilient Distributed Datasets (RDDs), a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a fault-tolerant manner. RDDs are motivated by two types of applications that current computing frameworks handle inefficiently: iterative algorithms and interactive data mining tools. In both cases, keeping data in memory can improve performance by an order of magnitude. To achieve fault tolerance efficiently, RDDs provide a restricted form of shared memory, based on coarse-grained transformations rather than fine-grained updates to shared state. However, we show that RDDs are expressive enough to capture a wide class of computations, including recent specialized programming models for iterative jobs, such as Pregel, and new applications that these models do not capture. We have implemented RDDs in a system called Spark, which we evaluate through a variety of user applications and benchmarks.",
        "year": 2012,
        "authors": "Matei Zaharia and Mosharaf Chowdhury and Tathagata Das and Ankur Dave and Justin Ma and Murphy McCauly and Michael J Franklin and Scott Shenker and Ion Stoica"
      },
      {
        "title": "TAG: A tiny aggregation service for ad-hoc sensor networks",
        "abstract": "We present the Tiny AGgregation (TAG) service for aggregation in low-power, distributed, wireless environments. TAG allows users to express simple, declarative queries and have them distributed and executed efficiently in networks of low-power, wireless sensors. We discuss various generic properties of aggregates, and show how those properties affect the performance of our in network approach. We include a performance study demonstrating the advantages of our approach over traditional centralized, out-of-network methods, and discuss a variety of optimizations for improving the performance and fault tolerance of the basic solution.",
        "year": 2002,
        "authors": "Samuel Madden and Michael J Franklin and Joseph M Hellerstein and Wei Hong"
      }
    ],
    "-zaDQ10AAAAJ": [
      {
        "title": "Super learner",
        "abstract": "When trying to learn a model for the prediction of an outcome given a set of covariates, a statistician has many estimation procedures in their toolbox.  A few examples of these candidate learners are: least squares, least angle regression, random forests, and spline regression.  Previous articles (van der Laan and Dudoit (2003); van der Laan et al. (2006); Sinisi et al. (2007)) theoretically validated the use of cross validation to select an optimal learner among many candidate learners.  Motivated by this use of cross validation, we propose a new prediction method for creating a weighted combination of many candidate learners to build the super learner.  This article proposes a fast algorithm for constructing a super learner in prediction which uses V-fold cross-validation to select weights to combine an initial set of candidate learners.  In addition, this paper contains a practical demonstration of the adaptivity of this so \u2026",
        "year": 2007,
        "authors": "Mark J Van der Laan and Eric C Polley and Alan E Hubbard"
      },
      {
        "title": "Targeted learning: causal inference for observational and experimental data",
        "abstract": "The statistics profession is at a unique point in history. The need for valid statistical tools is greater than ever; data sets are massive, often measuring hundreds of thousands of measurements for a single subject. The field is ready to move towards clear objective benchmarks under which tools can be evaluated. Targeted learning allows (1) the full generalization and utilization of cross-validation as an estimator selection tool so that the subjective choices made by humans are now made by the machine, and (2) targeting the fitting of the probability distribution of the data toward the target parameter representing the scientific question of interest.",
        "year": 2011,
        "authors": "Mark van der Laan and Sherri Rose"
      }
    ],
    "euc0GX4AAAAJ": [
      {
        "title": "Tree of thoughts: Deliberate problem solving with large language models",
        "abstract": "Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models\u2019 problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\\% of tasks, our method achieved a success rate of 74\\%. Code repo with all prompts: https://github. com/princeton-nlp/tree-of-thought-llm.",
        "year": 2023,
        "authors": "Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L Griffiths and Yuan Cao and Karthik Narasimhan"
      },
      {
        "title": "React: Synergizing reasoning and acting in language models",
        "abstract": "While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34% and 10% respectively, while being prompted with only one or two in-context examples.",
        "year": 2023,
        "authors": "Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik Narasimhan and Yuan Cao"
      }
    ],
    "ZvX1hXcAAAAJ": [
      {
        "title": "FastSecAgg: Scalable Secure Aggregation for Privacy-Preserving Federated Learning",
        "abstract": "Recent attacks on federated learning demonstrate that keeping the training data on clients' devices does not provide sufficient privacy, as the model parameters shared by clients can leak information about their training data. A 'secure aggregation' protocol enables the server to aggregate clients' models in a privacy-preserving manner. However, existing secure aggregation protocols incur high computation/communication costs, especially when the number of model parameters is larger than the number of clients participating in an iteration -- a typical scenario in federated learning. In this paper, we propose a secure aggregation protocol, FastSecAgg, that is efficient in terms of computation and communication, and robust to client dropouts. The main building block of FastSecAgg is a novel multi-secret sharing scheme, FastShare, based on the Fast Fourier Transform (FFT), which may be of independent interest. FastShare is information-theoretically secure, and achieves a trade-off between the number of secrets, privacy threshold, and dropout tolerance. Riding on the capabilities of FastShare, we prove that FastSecAgg is (i) secure against the server colluding with 'any' subset of some constant fraction (e.g. ) of the clients in the honest-but-curious setting; and (ii) tolerates dropouts of a 'random' subset of some constant fraction (e.g. ) of the clients. FastSecAgg achieves significantly smaller computation cost than existing schemes while achieving the same (orderwise) communication cost. In addition, it guarantees security against adaptive adversaries, which can perform client corruptions dynamically during the execution of the protocol.",
        "year": 2020,
        "authors": "Swanand Kadhe and Nived Rajaraman and O Ozan Koyluoglu and Kannan Ramchandran"
      },
      {
        "title": "Toward the fundamental limits of imitation learning",
        "abstract": "Imitation learning (IL) aims to mimic the behavior of an expert policy in a sequential decision-making problem given only demonstrations. In this paper, we focus on understanding the minimax statistical limits of IL in episodic Markov Decision Processes (MDPs). We first consider the setting where the learner is provided a dataset of  expert trajectories ahead of time, and cannot interact with the MDP. Here, we show that the policy which mimics the expert whenever possible is in expectation  suboptimal compared to the value of the expert, even when the expert plays a stochastic policy. Here  is the state space and  is the length of the episode. Furthermore, we establish a suboptimality lower bound of  which applies even if the expert is constrained to be deterministic, or if the learner is allowed to actively query the expert at visited states while interacting with the MDP for  episodes. To our knowledge, this is the first algorithm with suboptimality having no dependence on the number of actions, under no additional assumptions. We then propose a novel algorithm based on minimum-distance functionals in the setting where the transition model is given and the expert is deterministic. The algorithm is suboptimal by , matching our lower bound up to a  factor, and breaks the  error compounding barrier of IL.",
        "year": 2020,
        "authors": "Nived Rajaraman and Lin Yang and Jiantao Jiao and Kannan Ramchandran"
      },
      {
        "title": "Not just age but age and quality of information",
        "abstract": "A versatile scheduling problem to model a three-way tradeoff between age of information (AoI), quality/distortion, and energy is considered. The considered problem called the age and quality of information (AQI) is to select which packets to transmit at each time slot to minimize a linear combination of the utility driven by quality, the AoI, and the energy transmission cost in an online fashion. AQI problem combines tradeoffs from some important distinct problems, such as AoI with multiple sources, the remote sampling problem with sampling constraint, the classical speed scaling problem among others. The arbitrary/adversarial case input model is considered in the online setting, where the performance metric is the competitive ratio. A greedy algorithm is proposed that is shown to be 2-competitive, independent of all parameters of the problem. For the special case of AQI problem, a maximum weight matching based \u2026",
        "year": 2021,
        "authors": "Nived Rajaraman and Rahul Vaze and Goonwanth Reddy"
      }
    ],
    "0lZoXCUAAAAJ": [
      {
        "title": "Influence and correlation in social networks",
        "abstract": "In many online social systems, social ties between users play an important role in dictating their behavior. One of the ways this can happen is through social influence, the phenomenon that the actions of a user can induce his/her friends to behave in a similar way. In systems where social influence exists, ideas, modes of behavior, or new technologies can diffuse through the network like an epidemic. Therefore, identifying and understanding social influence is of tremendous interest from both analysis and design points of view.This is a difficult task in general, since there are factors such as homophily or unobserved confounding variables that can induce statistical correlation between the actions of friends in a social network. Distinguishing influence from these is essentially the problem of distinguishing correlation from causality, a notoriously hard statistical problem.In this paper we study this problem systematically \u2026",
        "year": 2008,
        "authors": "Aris Anagnostopoulos and Ravi Kumar and Mohammad Mahdian"
      },
      {
        "title": "Greedy Facility Location Algorithms Analyzed using Dual Fitting with Factor-Revealing LP",
        "abstract": "In this article, we will formalize the method of dual fitting and the idea of factor-revealing LP. This combination is used to design and analyze two greedy algorithms for the metric uncapacitated facility location problem. Their approximation factors are 1.861 and 1.61, with running times of O(m log m) and O(n3), respectively, where n is the total number of vertices and m is the number of edges in the underlying complete bipartite graph between cities and facilities. The algorithms are used to improve recent results for several variants of the problem.",
        "year": 2003,
        "authors": "K Jain and M Mahdian and E Markakis and A Saberi and VV Vazirani"
      },
      {
        "title": "A new greedy approach for facility location problems",
        "abstract": "We present a simple and natural greedy algorithm for the metric uncapacitated facility location problem achieving an approximation guarantee of 1.61. We use this algorithm to find better approximation algorithms for the capacitated facility location problem with soft capacities and for a common generalization of the k-median and facility location problems. We also prove a lower bound of 1+2/e on the approximability of the k-median problem. At the end, we present a discussion about the techniques we have used in the analysis of our algorithm, including a computer-aided method for proving bounds on the approximation factor.",
        "year": 2002,
        "authors": "Kamal Jain and Mohammad Mahdian and Amin Saberi"
      }
    ],
    "4mVPFQ8AAAAJ": [
      {
        "title": "Cooperative Inverse Reinforcement Learning",
        "abstract": "For an autonomous system to be helpful to humans and to pose no unwarranted risks, it needs to align its values with those of the humans in its environment in such a way that its actions contribute to the maximization of value for the humans. We propose a formal definition of the value alignment problem as cooperative inverse reinforcement learning (CIRL). A CIRL problem is a cooperative, partial-information game with two agents, human and robot; both are rewarded according to the human\u2019s reward function, but the robot does not initially know what this is. In contrast to classical IRL, where the human is assumed to act optimally in isolation, optimal CIRL solutions produce behaviors such as active teaching, active learning, and communicative actions that are more effective in achieving value alignment. We show that computing optimal joint policies in CIRL games can be reduced to solving a POMDP, prove that optimality in isolation is suboptimal in CIRL, and derive an approximate CIRL algorithm.",
        "year": 2016,
        "authors": "Dylan Hadfield-Menell and Stuart J Russell and Pieter Abbeel and Anca Dragan"
      },
      {
        "title": "Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback",
        "abstract": "Reinforcement learning from human feedback (RLHF) is a technique for training AI systems to align with human goals. RLHF has emerged as the central method used to finetune state-of-the-art large language models (LLMs). Despite this popularity, there has been relatively little public work systematizing its flaws. In this paper, we (1) survey open problems and fundamental limitations of RLHF and related methods; (2) overview techniques to understand, improve, and complement RLHF in practice; and (3) propose auditing and disclosure standards to improve societal oversight of RLHF systems. Our work emphasizes the limitations of RLHF and highlights the importance of a multi-faceted approach to the development of safer AI systems.",
        "year": 2023,
        "authors": "Stephen Casper and Xander Davies and Claudia Shi and Thomas Krendl Gilbert and J\u00e9r\u00e9my Scheurer and Javier Rando and Rachel Freedman and Tomasz Korbak and David Lindner and Pedro Freire and Tony Wang and Samuel Marks and Charbel-Rapha\u00ebl Segerie and Micah Carroll and Andi Peng and Phillip Christoffersen and Mehul Damani and Stewart Slocum and Usman Anwar and Anand Siththaranjan and Max Nadeau and Eric J Michaud and Jacob Pfau and Dmitrii Krasheninnikov and Xin Chen and Lauro Langosco and Peter Hase and Erdem B\u0131y\u0131k and Anca Dragan and David Krueger and Dorsa Sadigh and Dylan Hadfield-Menell"
      },
      {
        "title": "Inverse Reward Design",
        "abstract": "Autonomous agents optimize the reward function we give them. What they don't know is how hard it is for us to design a reward function that actually captures what we want. When designing the reward, we might think of some specific training scenarios, and make sure that the reward will lead to the right behavior in those scenarios. Inevitably, agents encounter new scenarios (eg, new types of terrain) where optimizing that same reward may lead to undesired behavior. Our insight is that reward functions are merely observations about what the designer actually wants, and that they should be interpreted in the context in which they were designed. We introduce inverse reward design (IRD) as the problem of inferring the true objective based on the designed reward and the training MDP. We introduce approximate methods for solving IRD problems, and use their solution to plan risk-averse behavior in test MDPs. Empirical results suggest that this approach can help alleviate negative side effects of misspecified reward functions and mitigate reward hacking.",
        "year": 2017,
        "authors": "Dylan Hadfield-Menell and Smitha Milli and Pieter Abbeel and Stuart J Russell and Anca Dragan"
      }
    ],
    "YAHWbtkAAAAJ": [
      {
        "title": "Tackling climate change with machine learning",
        "abstract": "Climate change is one of the greatest challenges facing humanity, and we, as machine learning (ML) experts, may wonder how we can help. Here we describe how ML can be a powerful tool in reducing greenhouse gas emissions and helping society adapt to a changing climate. From smart grids to disaster management, we identify high impact problems where existing gaps can be filled by ML, in collaboration with other fields. Our recommendations encompass exciting research questions as well as promising business opportunities. We call on the ML community to join the global effort against climate change.",
        "year": 2022,
        "authors": "David Rolnick and Priya L Donti and Lynn H Kaack and Kelly Kochanski and Alexandre Lacoste and Kris Sankaran and Andrew Slavin Ross and Nikola Milojevic-Dupont and Natasha Jaques and Anna Waldman-Brown and Alexandra Sasha Luccioni and Tegan Maharaj and Evan D Sherwin and S Karthik Mukkavilli and Konrad P Kording and Carla P Gomes and Andrew Y Ng and Demis Hassabis and John C Platt and Felix Creutzig and Jennifer Chayes and Yoshua Bengio"
      },
      {
        "title": "Maximizing social influence in nearly optimal time",
        "abstract": "Diffusion is a fundamental graph process, underpinning such phenomena as epidemic disease contagion and the spread of innovation by word-of-mouth. We address the algorithmic problem of finding a set of k initial seed nodes in a network so that the expected size of the resulting cascade is maximized, under the standard independent cascade model of network diffusion. Runtime is a primary consideration for this problem due to the massive size of the relevant input networks.We provide a fast algorithm for the influence maximization problem, obtaining the near-optimal approximation factor of , for any \u220a > 0, in time O((m + n)\u220a\u22123 log n). Our algorithm is runtime-optimal (up to a logarithmic factor) and substantially improves upon the previously best-known algorithms which run in time \u03a9(mnk \u00b7 POLY(\u220a\u22121)). Furthermore, our algorithm can be modified to allow early termination: if it is terminated after O(\u03b2(m + n) logn \u2026",
        "year": 2014,
        "authors": "Christian Borgs and Michael Brautbar and Jennifer Chayes and Brendan Lucier"
      },
      {
        "title": "Entropy-SGD: Biasing gradient descent into wide valleys",
        "abstract": "This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in the sharp valleys. Conceptually, our algorithm resembles two nested loops of SGD where we use Langevin dynamics in the inner loop to compute the gradient of the local entropy before each update of the weights. We show that the new objective has a smoother energy landscape and show improved generalization over SGD using uniform stability, under \u2026",
        "year": 2019,
        "authors": "Pratik Chaudhari and Anna Choromanska and Stefano Soatto and Yann LeCun and Carlo Baldassi and Christian Borgs and Jennifer Chayes and Levent Sagun and Riccardo Zecchina"
      }
    ],
    "-ltRSM0AAAAJ": [
      {
        "title": "Fully convolutional networks for semantic segmentation",
        "abstract": "Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build\" fully convolutional\" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.",
        "year": 2015,
        "authors": "Jonathan Long and Evan Shelhamer and Trevor Darrell"
      },
      {
        "title": "Caffe: Convolutional architecture for fast feature embedding",
        "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community \u2026",
        "year": 2014,
        "authors": "Yangqing Jia and Evan Shelhamer and Jeff Donahue and Sergey Karayev and Jonathan Long and Ross Girshick and Sergio Guadarrama and Trevor Darrell"
      },
      {
        "title": "Fully Convolutional Networks for Semantic Segmentation",
        "abstract": "Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation. Our key insight is to build \u201cfully convolutional\u201d networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to \u2026",
        "year": 2016,
        "authors": "Evan Shelhamer and Jonathan Long and Trevor Darrell"
      }
    ],
    "xRmmtzIAAAAJ": [
      {
        "title": "Design of energy-and cost-efficient massive MIMO arrays",
        "abstract": "Large arrays of radios have been exploited for beamforming and null steering in both radar and communication applications, but cost and form factor limitations have precluded their use in commercial systems. This paper discusses how to build arrays that enable multiuser massive multiple-input-multiple-output (MIMO) and aggressive spatial multiplexing with many users sharing the same spectrum. The focus of the paper is the energy- and cost-efficient realization of these arrays in order to enable new applications. Distributed algorithms for beamforming are proposed, and the optimum array size is considered as a function of the performance of the receiver, transmitter, frequency synthesizer, and signal distribution within the array. The effects of errors such as phase noise and synchronization skew across the array are analyzed. The paper discusses both RF frequencies below 10 GHz, where fully digital techniques \u2026",
        "year": 2015,
        "authors": "Antonio Puglielli and Andrew Townley and Greg LaCaille and Vladimir Milovanovi\u0107 and Pengpeng Lu and Konstantin Trotskovsky and Amy Whitcombe and Nathan Narevsky and Gregory Wright and Thomas Courtade and Elad Alon and Borivoje Nikoli\u0107 and Ali M Niknejad"
      },
      {
        "title": "Multiterminal source coding under logarithmic loss",
        "abstract": "We consider the classical two-encoder multiterminal source coding problem where distortion is measured under logarithmic loss. We provide a single-letter description of the achievable rate distortion region for all discrete memoryless sources with finite alphabets. By doing so, we also give the rate distortion region for the -encoder CEO problem (also under logarithmic loss). Several applications and examples are given.",
        "year": 2013,
        "authors": "Thomas A Courtade and Tsachy Weissman"
      },
      {
        "title": "Soft information for LDPC decoding in flash: Mutual-information optimized quantization",
        "abstract": "High-capacity NAND flash memory can achieve high density storage by using multi-level cells (MLC) to store more than one bit per cell. Although this larger storage capacity is certainly beneficial, the increased density also increases the raw bit error rate (BER), making powerful error correction coding necessary. Traditional flash memories employ simple algebraic codes, such as BCH codes, that can correct a fixed, specified number of errors. This paper investigates the application of low-density parity-check (LDPC) codes which are well known for their ability to approach capacity in the AWGN channel. We obtain soft information for the LDPC decoder by performing multiple cell reads with distinct word-line voltages. The values of the word-line voltages (also called reference voltages) are optimized by maximizing the mutual information between the input and output of the multiple-read channel. Our results show that \u2026",
        "year": 2011,
        "authors": "Jiadong Wang and Thomas Courtade and Hari Shankar and Richard D Wesel"
      }
    ],
    "DwdjBUUAAAAJ": [
      {
        "title": "Squeezeseg: Convolutional Neural Nets with Recurrent CRF for Real-time Road-Object Segmentation from 3D LiDAR Point Cloud",
        "abstract": "We address semantic segmentation of road-objects from 3D LiDAR point clouds. In particular, we wish to detect and categorize instances of interest, such as cars, pedestrians and cyclists. We formulate this problem as a point-wise classification problem, and propose an end-to-end pipeline called SqueezeSeg based on convolutional neural networks (CNN): the CNN takes a transformed LiDAR point cloud as input and directly outputs a point-wise label map, which is then refined by a conditional random field (CRF) implemented as a recurrent layer. Instance-level labels are then obtained by conventional clustering algorithms. Our CNN model is trained on LiDAR point clouds from the KITTI [1] dataset, and our point-wise segmentation labels are derived from 3D bounding boxes from KITTI. To obtain extra training data, we built a LiDAR simulator into Grand Theft Auto V (GTA-V), a popular video game, to synthesize \u2026",
        "year": 2018,
        "authors": "Bichen Wu and Alvin Wan and Xiangyu Yue and Kurt Keutzer"
      },
      {
        "title": "Visual transformers: Where do transformers really belong in vision models?",
        "abstract": "A recent trend in computer vision is to replace convolutions with transformers. However, the performance gain of transformers is attained at a steep cost, requiring GPU years and hundreds of millions of samples for training. This excessive resource usage compensates for a misuse of transformers: Transformers densely model relationships between its inputs--ideal for late stages of a neural network, when concepts are sparse and spatially-distant, but extremely inefficient for early stages of a network, when patterns are redundant and localized. To address these issues, we leverage the respective strengths of both operations, building convolution-transformer hybrids. Critically, in sharp contrast to pixel-space transformers, our Visual Transformer (VT) operates in a semantic token space, judiciously attending to different image parts based on context. Our VTs significantly outperforms baselines: On ImageNet, our VT-ResNets outperform convolution-only ResNet by 4.6 to 7 points and transformer-only ViT-B by 2.6 points with 2.5 times fewer FLOPs, 2.1 times fewer parameters. For semantic segmentation on LIP and COCO-stuff, VT-based feature pyramid networks (FPN) achieve 0.35 points higher mIoU while reducing the FPN module's FLOPs by 6.5 x.",
        "year": 2021,
        "authors": "Bichen Wu and Chenfeng Xu and Xiaoliang Dai and Alvin Wan and Peizhao Zhang and Zhicheng Yan and Masayoshi Tomizuka and Joseph E Gonzalez and Kurt Keutzer and Peter Vajda"
      },
      {
        "title": "Shift: A Zero FLOP, Zero Parameter Alternative to Spatial Convolutions",
        "abstract": "Neural networks rely on convolutions to aggregate spatial information. However, spatial convolutions are expensive in terms of model size and computation, both of which grow quadratically with respect to kernel size. In this paper, we present a parameter-free, FLOP-free\" shift\" operation as an alternative to spatial convolutions. We fuse shifts and point-wise convolutions to construct end-to-end trainable shift-based modules, with a hyperparameter characterizing the tradeoff between accuracy and efficiency. To demonstrate the operation's efficacy, we replace ResNet's 3x3 convolutions with shift-based modules for improved CIFAR-10 and CIFAR-100 accuracy using 60% fewer parameters; we additionally demonstrate the operation's resilience to parameter reduction on ImageNet, outperforming ResNet family members despite having millions fewer parameters. We further design a family of neural networks called ShiftNet, which achieve strong performance on classification, face verification and style transfer while demanding many fewer parameters.",
        "year": 2017,
        "authors": "Bichen Wu and Alvin Wan and Xiangyu Yue and Peter Jin and Sicheng Zhao and Noah Golmant and Amir Gholaminejad and Joseph Gonzalez and Kurt Keutzer"
      }
    ],
    "mqpjAt4AAAAJ": [
      {
        "title": "Decaf: A deep convolutional activation feature for generic visual recognition",
        "abstract": "We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.",
        "year": 2013,
        "authors": "Jeff Donahue and Yangqing Jia and Oriol Vinyals and Judy Hoffman and Ning Zhang and Eric Tzeng and Trevor Darrell"
      },
      {
        "title": "Adversarial discriminative domain adaptation",
        "abstract": "Adversarial learning methods are a promising approach to training robust deep networks, and can generate complex samples across diverse domains. They can also improve recognition despite the presence of domain shift or dataset bias: recent adversarial approaches to unsupervised domain adaptation reduce the difference between the training and test domain distributions and thus improve generalization performance. However, while generative adversarial networks (GANs) show compelling visualizations, they are not optimal on discriminative tasks and can be limited to smaller shifts. On the other hand, discriminative approaches can handle larger domain shifts, but impose tied weights on the model and do not exploit a GAN-based loss. In this work, we first outline a novel generalized framework for adversarial adaptation, which subsumes recent state-of-the-art approaches as special cases, and use this generalized view to better relate prior approaches. We then propose a previously unexplored instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss, which we call Adversarial Discriminative Domain Adaptation (ADDA). We show that ADDA is more effective yet considerably simpler than competing domain-adversarial methods, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results on standard domain adaptation tasks as well as a difficult cross-modality object classification task.",
        "year": 2017,
        "authors": "Eric Tzeng and Judy Hoffman and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Cycada: Cycle-consistent adversarial domain adaptation",
        "abstract": "Domain adaptation is critical for success in new, unseen environments. Adversarial adaptation models have shown tremendous progress towards adapting to new environments by focusing either on discovering domain invariant representations or by mapping between unpaired image domains. While feature space methods are difficult to interpret and sometimes fail to capture pixel-level and low-level domain shifts, image space methods sometimes fail to incorporate high level semantic knowledge relevant for the end task. We propose a model which adapts between domains using both generative image space alignment and latent representation space alignment. Our approach, Cycle-Consistent Adversarial Domain Adaptation (CyCADA), guides transfer between domains according to a specific discriminatively trained task and avoids divergence by enforcing consistency of the relevant semantics before and after adaptation. We evaluate our method on a variety of visual recognition and prediction settings, including digit classification and semantic segmentation of road scenes, advancing state-of-the-art performance for unsupervised adaptation from synthetic to real world driving domains.",
        "year": 2018,
        "authors": "Judy Hoffman and Eric Tzeng and Taesung Park and Jun-Yan Zhu and Phillip Isola and Kate Saenko and Alexei A Efros and Trevor Darrell"
      }
    ],
    "Nn990CkAAAAJ": [
      {
        "title": "On the opportunities and risks of foundation models",
        "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",
        "year": 2021,
        "authors": "Rishi Bommasani and Drew A Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher R\u00e9 and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W Thomas and Florian Tram\u00e8r and Rose E Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang"
      },
      {
        "title": "Understanding black-box predictions via influence functions",
        "abstract": "How can we explain the predictions of a black-box model? In this paper, we use influence functions\u2014a classic technique from robust statistics\u2014to trace a model\u2019s prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks.",
        "year": 2017,
        "authors": "Pang Wei Koh and Percy Liang"
      },
      {
        "title": "Distributionally robust neural networks for group shifts: On the importance of regularization for worst-case generalization",
        "abstract": "Overparameterized neural networks can be highly accurate on average on an i.i.d. test set yet consistently fail on atypical groups of the data (e.g., by learning spurious correlations that hold on average but not in such groups). Distributionally robust optimization (DRO) allows us to learn models that instead minimize the worst-case training loss over a set of pre-defined groups. However, we find that naively applying group DRO to overparameterized neural networks fails: these models can perfectly fit the training data, and any model with vanishing average training loss also already has vanishing worst-case training loss. Instead, the poor worst-case performance arises from poor generalization on some groups. By coupling group DRO models with increased regularization---a stronger-than-typical L2 penalty or early stopping---we achieve substantially higher worst-group accuracies, with 10-40 percentage point improvements on a natural language inference task and two image tasks, while maintaining high average accuracies. Our results suggest that regularization is important for worst-group generalization in the overparameterized regime, even if it is not needed for average generalization. Finally, we introduce a stochastic optimization algorithm, with convergence guarantees, to efficiently train group DRO models.",
        "year": 2019,
        "authors": "Shiori Sagawa* and Pang Wei Koh* and Tatsunori B Hashimoto and Percy Liang"
      }
    ],
    "L-diWvQAAAAJ": [
      {
        "title": "Discovery and refinement of loci associated with lipid levels",
        "abstract": "Levels of low-density lipoprotein (LDL) cholesterol, high-density lipoprotein (HDL) cholesterol, triglycerides and total cholesterol are heritable, modifiable risk factors for coronary artery disease. To identify new loci and refine known loci influencing these lipids, we examined 188,577 individuals using genome-wide and custom genotyping arrays. We identify and annotate 157 loci associated with lipid levels at P < 5 \u00d7 10\u22128, including 62 loci not previously associated with lipid levels in humans. Using dense genotyping in individuals of European, East Asian, South Asian and African ancestry, we narrow association signals in 12 loci. We find that loci associated with blood lipid levels are often associated with cardiovascular and metabolic traits, including coronary artery disease, type 2 diabetes, blood pressure, waist-hip ratio and body mass index. Our results demonstrate the value of using genetic data from individuals \u2026",
        "year": 2013,
        "authors": []
      },
      {
        "title": "Common variants associated with plasma triglycerides and risk for coronary artery disease",
        "abstract": "Triglycerides are transported in plasma by specific triglyceride-rich lipoproteins; in epidemiological studies, increased triglyceride levels correlate with higher risk for coronary artery disease (CAD). However, it is unclear whether this association reflects causal processes. We used 185 common variants recently mapped for plasma lipids (P < 5 \u00d7 10\u22128 for each) to examine the role of triglycerides in risk for CAD. First, we highlight loci associated with both low-density lipoprotein cholesterol (LDL-C) and triglyceride levels, and we show that the direction and magnitude of the associations with both traits are factors in determining CAD risk. Second, we consider loci with only a strong association with triglycerides and show that these loci are also associated with CAD. Finally, in a model accounting for effects on LDL-C and/or high-density lipoprotein cholesterol (HDL-C) levels, the strength of a polymorphism's effect on \u2026",
        "year": 2013,
        "authors": "Ron Do and Cristen J Willer and Ellen M Schmidt and Sebanti Sengupta and Chi Gao and Gina M Peloso and Stefan Gustafsson and Stavroula Kanoni and Andrea Ganna and Jin Chen and Martin L Buchkovich and Samia Mora and Jacques S Beckmann and Jennifer L Bragg-Gresham and Hsing-Yi Chang and Ay\u015fe Demirkan and Heleen M Den Hertog and Louise A Donnelly and Georg B Ehret and T\u00f5nu Esko and Mary F Feitosa and Teresa Ferreira and Krista Fischer and Pierre Fontanillas and Ross M Fraser and Daniel F Freitag and Deepti Gurdasani and Kauko Heikkil\u00e4 and Elina Hypp\u00f6nen and Aaron Isaacs and Anne U Jackson and \u00c5sa Johansson and Toby Johnson and Marika Kaakinen and Johannes Kettunen and Marcus E Kleber and Xiaohui Li and Jian'an Luan and Leo-Pekka Lyytik\u00e4inen and Patrik KE Magnusson and Massimo Mangino and Evelin Mihailov and May E Montasser and Martina M\u00fcller-Nurasyid and Ilja M Nolte and Jeffrey R O'Connell and Cameron D Palmer and Markus Perola and Ann-Kristin Petersen and Serena Sanna and Richa Saxena and Susan K Service and Sonia Shah and Dmitry Shungin and Carlo Sidore and Ci Song and Rona J Strawbridge and Ida Surakka and Toshiko Tanaka and Tanya M Teslovich and Gudmar Thorleifsson and Evita G Van den Herik and Benjamin F Voight and Kelly A Volcik and Lindsay L Waite and Andrew Wong and Ying Wu and Weihua Zhang and Devin Absher and Gershim Asiki and In\u00eas Barroso and Latonya F Been and Jennifer L Bolton and Lori L Bonnycastle and Paolo Brambilla and Mary S Burnett and Giancarlo Cesana and Maria Dimitriou and Alex SF Doney and Angela Doering and Paul Elliott and Stephen E Epstein and Gudmundur Ingi Eyjolfsson and Bruna Gigante and Mark O Goodarzi and Harald Grallert and Martha L Gravito and Christopher J Groves and G\u00f6ran Hallmans and Anna-Liisa Hartikainen and Caroline Hayward and Dena Hernandez and Andrew A Hicks and Hilma Holm and Yi-Jen Hung and Thomas Illig and Michelle R Jones and Pontiano Kaleebu and John JP Kastelein and Kay-Tee Khaw and Eric Kim and Norman Klopp and Pirjo Komulainen and Meena Kumari and Claudia Langenberg and Terho Lehtim\u00e4ki and Shih-Yi Lin and Jaana Lindstr\u00f6m and Ruth JF Loos and Fran\u00e7ois Mach and Wendy L McArdle and Christa Meisinger and Braxton D Mitchell and Gabrielle M\u00fcller and Ramaiah Nagaraja and Narisu Narisu and Tuomo VM Nieminen and Rebecca N Nsubuga and Isleifur Olafsson and Ken K Ong and Aarno Palotie and Theodore Papamarkou and Cristina Pomilla and Anneli Pouta and Daniel J Rader and Muredach P Reilly and Paul M Ridker and Fernando Rivadeneira and Igor Rudan and Aimo Ruokonen and Nilesh Samani and Hubert Scharnagl and Janet Seeley and Kaisa Silander and Alena Stan\u010d\u00e1kov\u00e1 and Kathleen Stirrups and Amy J Swift and Laurence Tiret and Andre G Uitterlinden and L Joost van Pelt and Sailaja Vedantam and Nicholas Wainwright and Cisca Wijmenga and Sarah H Wild and Gonneke Willemsen and Tom Wilsgaard and James F Wilson and Elizabeth H Young and Jing Hua Zhao and Linda S Adair"
      },
      {
        "title": "The African genome variation project shapes medical genetics in Africa",
        "abstract": "Given the importance of Africa to studies of human origins and disease susceptibility, detailed characterization of African genetic diversity is needed. The African Genome Variation Project provides a resource with which to design, implement and interpret genomic studies in sub-Saharan Africa and worldwide. The African Genome Variation Project represents dense genotypes from 1,481 individuals and whole-genome sequences from 320 individuals across sub-Saharan Africa. Using this resource, we find novel evidence of complex, regionally distinct hunter-gatherer and Eurasian admixture across sub-Saharan Africa. We identify new loci under selection, including loci related to malaria susceptibility and hypertension. We show that modern imputation panels (sets of reference genotypes from which unobserved or missing genotypes in study sets can be inferred) can identify association signals at highly \u2026",
        "year": 2015,
        "authors": "Deepti Gurdasani and Tommy Carstensen and Fasil Tekola-Ayele and Luca Pagani and Ioanna Tachmazidou and Konstantinos Hatzikotoulas and Savita Karthikeyan and Louise Iles and Martin O Pollard and Ananyo Choudhury and Graham RS Ritchie and Yali Xue and Jennifer Asimit and Rebecca N Nsubuga and Elizabeth H Young and Cristina Pomilla and Katja Kivinen and Kirk Rockett and Anatoli Kamali and Ayo P Doumatey and Gershim Asiki and Janet Seeley and Fatoumatta Sisay-Joof and Muminatou Jallow and Stephen Tollman and Ephrem Mekonnen and Rosemary Ekong and Tamiru Oljira and Neil Bradman and Kalifa Bojang and Michele Ramsay and Adebowale Adeyemo and Endashaw Bekele and Ayesha Motala and Shane A Norris and Fraser Pirie and Pontiano Kaleebu and Dominic Kwiatkowski and Chris Tyler-Smith and Charles Rotimi and Eleftheria Zeggini and Manjinder S Sandhu"
      }
    ],
    "uFJi3IUAAAAJ": [
      {
        "title": "TAG: A tiny aggregation service for ad-hoc sensor networks",
        "abstract": "We present the Tiny AGgregation (TAG) service for aggregation in low-power, distributed, wireless environments. TAG allows users to express simple, declarative queries and have them distributed and executed efficiently in networks of low-power, wireless sensors. We discuss various generic properties of aggregates, and show how those properties affect the performance of our in network approach. We include a performance study demonstrating the advantages of our approach over traditional centralized, out-of-network methods, and discuss a variety of optimizations for improving the performance and fault tolerance of the basic solution.",
        "year": 2002,
        "authors": "Samuel Madden and Michael J Franklin and Joseph M Hellerstein and Wei Hong"
      },
      {
        "title": "TinyDB: an acquisitional query processing system for sensor networks",
        "abstract": "We discuss the design of an acquisitional query processor for data collection in sensor networks. Acquisitional issues are those that pertain to where, when, and how often data is physically acquired (sampled) and delivered to query processing operators. By focusing on the locations and costs of acquiring data, we are able to significantly reduce power consumption over traditional passive systems that assume the a priori existence of data. We discuss simple extensions to SQL for controlling data acquisition, and show how acquisitional issues influence query optimization, dissemination, and execution. We evaluate these issues in the context of TinyDB, a distributed query processor for smart sensor devices, and show how acquisitional techniques can provide significant reductions in power consumption on our sensor devices.",
        "year": 2005,
        "authors": "Samuel R Madden and Michael J Franklin and Joseph M Hellerstein and Wei Hong"
      },
      {
        "title": "Distributed graphlab: A framework for machine learning in the cloud",
        "abstract": "While high-level data parallel frameworks, like MapReduce, simplify the design and implementation of large-scale data processing systems, they do not naturally or efficiently support many important data mining and machine learning algorithms and can lead to inefficient learning systems. To help fill this critical void, we introduced the GraphLab abstraction which naturally expresses asynchronous, dynamic, graph-parallel computation while ensuring data consistency and achieving a high degree of parallel performance in the shared-memory setting. In this paper, we extend the GraphLab framework to the substantially more challenging distributed setting while preserving strong data consistency guarantees. We develop graph based extensions to pipelined locking and data versioning to reduce network congestion and mitigate the effect of network latency. We also introduce fault tolerance to the GraphLab abstraction using the classic Chandy-Lamport snapshot algorithm and demonstrate how it can be easily implemented by exploiting the GraphLab abstraction itself. Finally, we evaluate our distributed implementation of the GraphLab abstraction on a large Amazon EC2 deployment and show 1-2 orders of magnitude performance gains over Hadoop-based implementations.",
        "year": 2012,
        "authors": "Yucheng Low and Joseph Gonzalez and Aapo Kyrola and Danny Bickson and Carlos Guestrin and Joseph M Hellerstein"
      }
    ],
    "yy0UFOwAAAAJ": [
      {
        "title": "Palm-e: An embodied multimodal language model",
        "abstract": "Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.",
        "year": 2023,
        "authors": "Danny Driess and Fei Xia and Mehdi SM Sajjadi and Corey Lynch and Aakanksha Chowdhery and Ayzaan Wahid and Jonathan Tompson and Quan Vuong and Tianhe Yu and Wenlong Huang and Yevgen Chebotar and Pierre Sermanet and Daniel Duckworth and Sergey Levine and Vincent Vanhoucke and Karol Hausman and Marc Toussaint and Klaus Greff and Andy Zeng and Igor Mordatch and Pete Florence"
      },
      {
        "title": "Do as i can, not as i say: Grounding language in robotic affordances",
        "abstract": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model's \"hands and eyes,\" while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally-extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project's website and the video can be found at https \u2026",
        "year": 2022,
        "authors": "Michael Ahn and Anthony Brohan and Noah Brown and Yevgen Chebotar and Omar Cortes and Byron David and Chelsea Finn and Chuyuan Fu and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Daniel Ho and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Eric Jang and Rosario Jauregui Ruano and Kyle Jeffrey and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Kuang-Huei Lee and Sergey Levine and Yao Lu and Linda Luu and Carolina Parada and Peter Pastor and Jornell Quiambao and Kanishka Rao and Jarek Rettinghouse and Diego Reyes and Pierre Sermanet and Nicolas Sievers and Clayton Tan and Alexander Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Mengyuan Yan and Andy Zeng"
      },
      {
        "title": "Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning",
        "abstract": "Meta-reinforcement learning algorithms can enable robots to acquire new skills much more quickly, by leveraging prior experience to learn how to learn. However, much of the current research on meta-reinforcement learning focuses on task distributions that are very narrow. For example, a commonly used meta-reinforcement learning benchmark uses different running velocities for a simulated robot as different tasks. When policies are meta-trained on such narrow task distributions, they cannot possibly generalize to more quickly acquire entirely new tasks. Therefore, if the aim of these methods is enable faster acquisition of entirely new behaviors, we must evaluate them on task distributions that are sufficiently broad to enable generalization to new behaviors. In this paper, we propose an open-source simulated benchmark for meta-reinforcement learning and multitask learning consisting of 50 distinct robotic manipulation tasks. Our aim is to make it possible to develop algorithms that generalize to accelerate the acquisition of entirely new, held-out tasks. We evaluate 6 state-of-the-art meta-reinforcement learning and multi-task learning algorithms on these tasks. Surprisingly, while each task and its variations (eg, with different object positions) can be learned with reasonable success, these algorithms struggle to learn with multiple tasks at the same time, even with as few as ten distinct training tasks. Our analysis and open-source environments pave the way for future research in multi-task learning and meta-learning that can enable meaningful generalization, thereby unlocking the full potential of these methods. 1.",
        "year": 2020,
        "authors": "Tianhe Yu and Deirdre Quillen and Zhanpeng He and Ryan Julian and Karol Hausman and Chelsea Finn and Sergey Levine"
      }
    ],
    "07qshUgAAAAJ": [
      {
        "title": "A randomized scheduler with probabilistic guarantees of finding bugs",
        "abstract": "This paper presents a randomized scheduler for finding concurrency bugs. Like current stress-testing methods, it repeatedly runs a given test program with supplied inputs. However, it improves on stress-testing by finding buggy schedules more effectively and by quantifying the probability of missing concurrency bugs. Key to its design is the characterization of the depth of a concurrency bug as the minimum number of scheduling constraints required to find it. In a single run of a program with n threads and k steps, our scheduler detects a concurrency bug of depth d with probability at least 1/nkd-1. We hypothesize that in practice, many concurrency bugs (including well-known types such as ordering errors, atomicity violations, and deadlocks) have small bug-depths, and we confirm the efficiency of our schedule randomization by detecting previously unknown and known concurrency bugs in several production-scale \u2026",
        "year": 2010,
        "authors": "Sebastian Burckhardt and Pravesh Kothari and Madanlal Musuvathi and Santosh Nagarakatte"
      },
      {
        "title": "A nearly tight sum-of-squares lower bound for the planted clique problem",
        "abstract": "We prove that with high probability over the choice of a random graph  from the Erdo\u0308s--Re\u0301nyi distribution , the -time degree  sum-of-squares (SOS) semidefinite programming relaxation for the clique problem will give a value of at least  for some constant .  This yields a nearly tight  bound on the value of this program for any degree . Moreover, we introduce a new framework that we call pseudocalibration to construct SOS lower bounds. This framework is  inspired by taking a computational analogue of Bayesian probability theory. It yields a general recipe for constructing  good pseudodistributions (i.e., dual certificates for the SOS semidefinite program)  and sheds further light on the ways in which this hierarchy differs from others.",
        "year": 2019,
        "authors": "Boaz Barak and Samuel Hopkins and Jonathan Kelner and Pravesh K Kothari and Ankur Moitra and Aaron Potechin"
      },
      {
        "title": "Differentially private online learning",
        "abstract": "In this paper, we consider the problem of preserving privacy in the context of online learning. Online learning involves learning from data in real-time, due to which the learned model as well as its predictions are continuously changing. This makes preserving privacy of each data point significantly more challenging as its effect on the learned model can be easily tracked by observing changes in the subsequent predictions. Furthermore, with more and more online systems (eg search engines like Bing, Google etc.) trying to learn their customers\u2019 behavior by leveraging their access to sensitive customer data (through cookies etc.), the problem of privacy preserving online learning has become critical. We study the problem in the framework of online convex programming (OCP)\u2013a popular online learning setting with several theoretical and practical implications\u2013while using differential privacy as the formal measure of privacy. For this problem, we provide a generic framework that can be used to convert any given OCP algorithm into a private OCP algorithm with provable privacy as well as regret guarantees (utility), provided that the given OCP algorithm satisfies the following two criteria: 1) linearly decreasing sensitivity, ie, the effect of the new data points on the learned model decreases linearly, 2) sub-linear regret. We then illustrate our approach by converting two popular OCP algorithms into corresponding differentially private algorithms while guaranteeing\\emph\u00d5 (\u221a T) regret for strongly convex functions. Next, we consider the practically important class of online linear regression problems, for which we generalize the approach by Dwork et al \u2026",
        "year": 2012,
        "authors": "Prateek Jain and Pravesh Kothari and Abhradeep Thakurta"
      }
    ],
    "BgQkdsYAAAAJ": [
      {
        "title": "Bridging offline reinforcement learning and imitation learning: A tale of pessimism",
        "abstract": "Offline (or batch) reinforcement learning (RL) algorithms seek to learn an optimal policy from a fixed dataset without active data collection. Based on the composition of the offline dataset, two main methods are used: imitation learning which is suitable for expert datasets, and vanilla offline RL which often requires uniform coverage datasets. From a practical standpoint, datasets often deviate from these two extremes and the exact data composition is usually unknown. To bridge this gap, we present a new offline RL framework that smoothly interpolates between the two extremes of data composition, hence unifying imitation learning and vanilla offline RL. The new framework is centered around a weak version of the concentrability coefficient that measures the deviation of the behavior policy from the expert policy alone. Under this new framework, we ask: can one develop an algorithm that achieves a minimax optimal rate adaptive to unknown data composition? To address this question, we consider a lower confidence bound (LCB) algorithm developed based on pessimism in the face of uncertainty in offline RL. We study finite-sample properties of LCB as well as information-theoretic limits in multi-armed bandits, contextual bandits, and Markov decision processes (MDPs). Our analysis reveals surprising facts about optimality rates. In particular, in both contextual bandits and RL, LCB achieves a faster rate of  for nearly-expert datasets compared to the usual rate of  in offline RL, where  is the batch dataset sample size. In contextual bandits with at least two contexts, we prove that LCB is adaptively optimal for the entire data composition \u2026",
        "year": 2021,
        "authors": "Paria Rashidinejad and Banghua Zhu and Cong Ma and Jiantao Jiao and Stuart Russell"
      },
      {
        "title": "MADE: Exploration via maximizing deviation from explored regions",
        "abstract": "In online reinforcement learning (RL), efficient exploration remains particularly challenging in high-dimensional environments with sparse rewards. In low-dimensional environments, where tabular parameterization is possible, count-based upper confidence bound (UCB) exploration methods achieve minimax near-optimal rates. However, it remains unclear how to efficiently implement UCB in realistic RL tasks that involve non-linear function approximation. To address this, we propose a new exploration approach via maximizing the deviation of the occupancy of the next policy from the explored regions. We add this term as an adaptive regularizer to the standard RL objective to balance exploration vs. exploitation. We pair the new objective with a provably convergent algorithm, giving rise to a new intrinsic reward that adjusts existing bonuses. The proposed intrinsic reward is easy to implement and combine with other existing RL algorithms to conduct exploration. As a proof of concept, we evaluate the new intrinsic reward on tabular examples across a variety of model-based and model-free algorithms, showing improvements over count-only exploration strategies. When tested on navigation and locomotion tasks from MiniGrid and DeepMind Control Suite benchmarks, our approach significantly improves sample efficiency over state-of-the-art methods.",
        "year": 2021,
        "authors": "Tianjun Zhang* and Paria Rashidinejad* and Jiantao Jiao and Yuandong Tian and Joseph Gonzalez and Stuart Russell"
      },
      {
        "title": "Optimal conservative offline RL with general function approximation via augmented Lagrangian",
        "abstract": "Offline reinforcement learning (RL), which refers to decision-making from a previously-collected dataset of interactions, has received significant attention over the past years. Much effort has focused on improving offline RL practicality by addressing the prevalent issue of partial data coverage through various forms of conservative policy learning. While the majority of algorithms do not have finite-sample guarantees, several provable conservative offline RL algorithms are designed and analyzed within the single-policy concentrability framework that handles partial coverage. Yet, in the nonlinear function approximation setting where confidence intervals are difficult to obtain, existing provable algorithms suffer from computational intractability, prohibitively strong assumptions, and suboptimal statistical rates. In this paper, we leverage the marginalized importance sampling (MIS) formulation of RL and present the first set of offline RL algorithms that are statistically optimal and practical under general function approximation and single-policy concentrability, bypassing the need for uncertainty quantification. We identify that the key to successfully solving the sample-based approximation of the MIS problem is ensuring that certain occupancy validity constraints are nearly satisfied. We enforce these constraints by a novel application of the augmented Lagrangian method and prove the following result: with the MIS formulation, augmented Lagrangian is enough for statistically optimal offline RL. In stark contrast to prior algorithms that induce additional conservatism through methods such as behavior regularization, our approach provably eliminates this need \u2026",
        "year": 2023,
        "authors": "Paria Rashidinejad and Hanlin Zhu and Kunhe Yang and Stuart Russell and Jiantao Jiao"
      }
    ],
    "GUAoEcAAAAAJ": [
      {
        "title": "OpenFlow: enabling innovation in campus networks",
        "abstract": "This whitepaper proposes OpenFlow: a way for researchers to run experimental protocols in the networks they use every day. OpenFlow is based on an Ethernet switch, with an internal flow-table, and a standardized interface to add and remove flow entries. Our goal is to encourage networking vendors to add OpenFlow to their switch products for deployment in college campus backbones and wiring closets. We believe that OpenFlow is a pragmatic compromise: on one hand, it allows researchers to run experiments on heterogeneous switches in a uniform way at line-rate and with high port-density; while on the other hand, vendors do not need to expose the internal workings of their switches. In addition to allowing researchers to evaluate their ideas in real-world traffic settings, OpenFlow could serve as a useful campus component in proposed large-scale testbeds like GENI. Two buildings at Stanford University will \u2026",
        "year": 2008,
        "authors": "Nick McKeown and Tom Anderson and Hari Balakrishnan and Guru Parulkar and Larry Peterson and Jennifer Rexford and Scott Shenker and Jonathan Turner"
      },
      {
        "title": "Spark: Cluster computing with working sets",
        "abstract": "MapReduce and its variants have been highly successful in implementing large-scale data-intensive applications on commodity clusters. However, most of these systems are built around an acyclic data flow model that is not suitable for other popular applications. This paper focuses on one such class of applications: those that reuse a working set of data across multiple parallel operations. This includes many iterative machine learning algorithms, as well as interactive data analysis tools. We propose a new framework called Spark that supports these applications while retaining the scalability and fault tolerance of MapReduce. To achieve these goals, Spark introduces an abstraction called resilient distributed datasets (RDDs). An RDD is a read-only collection of objects partitioned across a set of machines that can be rebuilt if a partition is lost. Spark can outperform Hadoop by 10x in iterative machine learning jobs, and can be used to interactively query a 39 GB dataset with sub-second response time.",
        "year": 2010,
        "authors": "Matei Zaharia and Mosharaf Chowdhury and Michael J Franklin and Scott Shenker and Ion Stoica"
      },
      {
        "title": "A scalable content-addressable network",
        "abstract": "Hash tables - which map \"keys\" onto \"values\" - are an essential building block in modern software systems. We believe a similar functionality would be equally valuable to large distributed systems. In this paper, we introduce the concept of a Content-Addressable Network (CAN) as a distributed infrastructure that provides hash table-like functionality on Internet-like scales. The CAN is scalable, fault-tolerant and completely self-organizing, and we demonstrate its scalability, robustness and low-latency properties through simulation.",
        "year": 2001,
        "authors": "Sylvia Ratnasamy and Paul Francis and Mark Handley and Richard Karp and Scott Shenker"
      }
    ],
    "ZaJEZpYAAAAJ": [
      {
        "title": "On the opportunities and risks of foundation models",
        "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",
        "year": 2021,
        "authors": "Rishi Bommasani and Drew A Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher R\u00e9 and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W Thomas and Florian Tram\u00e8r and Rose E Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang"
      },
      {
        "title": "Open x-embodiment: Robotic learning datasets and rt-x models",
        "abstract": "DSpace at KOASAS: Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nKOASAS menu About KOASAS KAIST Library \uac80\uc0c9 Advanced Search KOASAS About \nKOASAS Open Access Policy Browse Communities & Collections Researchers at KAIST Titles \nSubject By Date rss_1.0 rss_2.0 atom_1.0 sherpa SEARCH DSpace at KOASAS College of \nEngineering(\uacf5\uacfc\ub300\ud559)Kim Jaechul Graduate School of AI(\uae40\uc7ac\ucca0AI\ub300\ud559\uc6d0)AI-Conference \nPapers(\ud559\uc220\ub300\ud68c\ub17c\ubb38) Open X-Embodiment: Robotic Learning Datasets and RT-X Models \nCited 0 time in webofscience Cited 0 time in scopus Hit : 2 Download : 0 Export DC(XML) Excel \nLim, Joseph Jaewhanresearcher Publisher IEEE Issue Date 2024-05-15 Citation IEEE \nInternational Conference on Robotics and Automation URI http://hdl.handle.net/10203/326144 \nAppears in Collection AI-Conference Papers(\ud559\uc220\ub300\ud68c\ub17c\ubb38) Files in This Item There are no files \u2026",
        "year": 2024,
        "authors": "Joseph Jaewhan Lim"
      },
      {
        "title": "Planning for autonomous cars that leverage effects on human actions.",
        "abstract": "Traditionally, autonomous cars make predictions about other drivers\u2019 future trajectories, and plan to stay out of their way. This tends to result in defensive and opaque behaviors. Our key insight is that an autonomous car\u2019s actions will actually affect what other cars will do in response, whether the car is aware of it or not. Our thesis is that we can leverage these responses to plan more efficient and communicative behaviors. We model the interaction between an autonomous car and a human driver as a dynamical system, in which the robot\u2019s actions have immediate consequences on the state of the car, but also on human actions. We model these consequences by approximating the human as an optimal planner, with a reward function that we acquire through Inverse Reinforcement Learning. When the robot plans with this reward function in this dynamical system, it comes up with actions that purposefully change human state: it merges in front of a human to get them to slow down or to reach its own goal faster; it blocks two lanes to get them to switch to a third lane; or it backs up slightly at an intersection to get them to proceed first. Such behaviors arise from the optimization, without relying on hand-coded signaling strategies and without ever explicitly modeling communication. Our user study results suggest that the robot is indeed capable of eliciting desired changes in human state by planning using this dynamical system.",
        "year": 2016,
        "authors": "Dorsa Sadigh and Shankar Sastry and Sanjit A Seshia and Anca D Dragan"
      }
    ],
    "eWRBqsYAAAAJ": [
      {
        "title": "Nonparametric estimation of heterogeneous treatment effects: From theory to learning algorithms",
        "abstract": "The need to evaluate treatment effectiveness is ubiquitous in most of empirical science, and interest in flexibly investigating effect heterogeneity is growing rapidly. To do so, a multitude of model-agnostic, nonparametric meta-learners have been proposed in recent years. Such learners decompose the treatment effect estimation problem into separate sub-problems, each solvable using standard supervised learning methods. Choosing between different meta-learners in a data-driven manner is difficult, as it requires access to counterfactual information. Therefore, with the ultimate goal of building better understanding of the conditions under which some learners can be expected to perform better than others a priori, we theoretically analyze four broad meta-learning strategies which rely on plug-in estimation and pseudo-outcome regression. We highlight how this theoretical reasoning can be used to guide principled algorithm design and translate our analyses into practice by considering a variety of neural network architectures as base-learners for the discussed meta-learning strategies. In a simulation study, we showcase the relative strengths of the learners under different data-generating processes.",
        "year": 2021,
        "authors": "Alicia Curth and Mihaela Van der Schaar"
      },
      {
        "title": "Causal machine learning for predicting treatment outcomes",
        "abstract": "Causal machine learning (ML) offers flexible, data-driven methods for predicting treatment outcomes including efficacy and toxicity, thereby supporting the assessment and safety of drugs. A key benefit of causal ML is that it allows for estimating individualized treatment effects, so that clinical decision-making can be personalized to individual patient profiles. Causal ML can be used in combination with both clinical trial data and real-world data, such as clinical registries and electronic health records, but caution is needed to avoid biased or incorrect predictions. In this Perspective, we discuss the benefits of causal ML (relative to traditional statistical or ML approaches) and outline the key components and steps. Finally, we provide recommendations for the reliable use of causal ML and effective translation into the clinic.",
        "year": 2024,
        "authors": "Stefan Feuerriegel and Dennis Frauen and Valentyn Melnychuk and Jonas Schweisthal and Konstantin Hess and Alicia Curth and Stefan Bauer and Niki Kilbertus and Isaac S Kohane and Mihaela van der Schaar"
      },
      {
        "title": "On Inductive Biases for Heterogeneous Treatment Effect Estimation",
        "abstract": "We investigate how to exploit structural similarities of an individual's potential outcomes (POs) under different treatments to obtain better estimates of conditional average treatment effects in finite samples. Especially when it is unknown whether a treatment has an effect at all, it is natural to hypothesize that the POs are similar--yet, some existing strategies for treatment effect estimation employ regularization schemes that implicitly encourage heterogeneity even when it does not exist and fail to fully make use of shared structure. In this paper, we investigate and compare three end-to-end learning strategies to overcome this problem--based on regularization, reparametrization and a flexible multi-task architecture--each encoding inductive bias favoring shared behavior across POs. To build understanding of their relative strengths, we implement all strategies using neural networks and conduct a wide range of semi-synthetic experiments. We observe that all three approaches can lead to substantial improvements upon numerous baselines and gain insight into performance differences across various experimental settings.",
        "year": 2021,
        "authors": "Alicia Curth and Mihaela van der Schaar"
      }
    ],
    "4Z6vo5QAAAAJ": [
      {
        "title": "Introduction to automata theory, languages, and computation",
        "abstract": "In the preface from the 1979 predecessor to thOR book, Hopcroft and U11man marveled at the fact that the subject of automata had exploded, compared with its state at the time they wrote their first book, in 1969. Truly, the 1979 book contained many topics not found in the earlier work and was about twice its size. If you compare this book with the 1979 book, you will find that, like the automobiles of the 1970's, this book is\" larger on the outside, but smaller on the inside.\" That sounds like a retrograde step, but we are happy with the changes for several reasons. First, in 1979, automata and language theory was still an area of active research. A purpose of that book was to encourage mathematically inclined students to make new contributions to the field. Today, there is little direct research in automata theory (as opposed to its applications), and thus little motivation for us to ret~ n the succinct, highly mathematical tone \u2026",
        "year": 2001,
        "authors": "John E Hopcroft and Rajeev Motwani and Jeffrey D Ullman"
      },
      {
        "title": "The design and analysis of computer algorithms",
        "abstract": "The study of algorithms is at the very heart of computer science. In recent years a number of significant advances in the field of algorithms have been made. These advances have ranged from the development of faster algorithms, such as the fast Fourier transform, to the startling discovery of certain natural problems for which all algorithms are inefficient. These results have kindled considerable interest in the study of algorithms, and the area of algorithm design and analysis has blossomed into a field of intense interest. The intent of this book is to bring together the fundamental results in this area, so the unifying principles and underlying concepts of algorithm design may more easily be taught.",
        "year": 1974,
        "authors": "Alfred V Aho and John E Hopcroft"
      },
      {
        "title": "Data structures and algorithms",
        "abstract": "We have expanded that coverage and have added material on algorithms for external storage and memory management. As a consequence, this book should be suitable as a text for a first course on data structures and algorithms. The only prerequisite we assume is familiarity with some high-level programming language such as Pascal.We have attempted to cover data structures and algorithms in the broader context of solving problems using computers. We use abstract data types informally in the description and implementation of algorithms. Although abstract data types are only starting to appear in widely available programming languages, we feel they are a useful tool in designing programs, no matter what the language.",
        "year": 1983,
        "authors": "John E Hopcroft and Jeffrey D Ullman and Alfred Vaino Aho"
      }
    ],
    "VecEj6kAAAAJ": [
      {
        "title": "Speech synthesis from neural decoding of spoken sentences",
        "abstract": "Technology that translates neural activity into speech would be transformative for people who are unable to communicate as a result of neurological impairments. Decoding speech from neural activity is challenging because speaking requires very precise and rapid multi-dimensional control of vocal tract articulators. Here we designed a neural decoder that explicitly leverages kinematic and sound representations encoded in human cortical activity to synthesize audible speech. Recurrent neural networks first decoded directly recorded cortical activity into representations of articulatory movement, and then transformed these representations into speech acoustics. In closed vocabulary tests, listeners could readily identify and transcribe speech synthesized from cortical activity. Intermediate articulatory dynamics enhanced performance even with limited data. Decoded articulatory representations were highly \u2026",
        "year": 2019,
        "authors": "Gopala K Anumanchipalli and Josh Chartier and Edward F Chang"
      },
      {
        "title": "Neuroprosthesis for decoding speech in a paralyzed person with anarthria",
        "abstract": "Technology to restore the ability to communicate in paralyzed persons who cannot speak has the potential to improve autonomy and quality of life. An approach that decodes words and sentences directly from the cerebral cortical activity of such patients may represent an advancement over existing methods for assisted communication.We implanted a subdural, high-density, multielectrode array over the area of the sensorimotor cortex that controls speech in a person with anarthria (the loss of the ability to articulate speech) and spastic quadriparesis caused by a brain-stem stroke. Over the course of 48 sessions, we recorded 22 hours of cortical activity while the participant attempted to say individual words from a vocabulary set of 50 words. We used deep-learning algorithms to create computational models for the detection and classification of words from patterns in the recorded cortical \u2026",
        "year": 2021,
        "authors": "David A Moses and Sean L Metzger and Jessie R Liu and Gopala K Anumanchipalli and Joseph G Makin and Pengfei F Sun and Josh Chartier and Maximilian E Dougherty and Patricia M Liu and Gary M Abrams and Adelyn Tu-Chan and Karunesh Ganguly and Edward F Chang"
      },
      {
        "title": "A high-performance neuroprosthesis for speech decoding and avatar control",
        "abstract": "Speech neuroprostheses have the potential to restore communication to people living with paralysis, but naturalistic speed and expressivity are elusive. Here we use high-density surface recordings of the speech cortex in a clinical-trial participant with severe limb and vocal paralysis to achieve high-performance real-time decoding across three complementary speech-related output modalities: text, speech audio and facial-avatar animation. We trained and evaluated deep-learning models using neural data collected as the participant attempted to silently speak sentences. For text, we demonstrate accurate and rapid large-vocabulary decoding with a median rate of 78 words per minute and median word error rate of 25%. For speech audio, we demonstrate intelligible and rapid speech synthesis and personalization to the participant\u2019s pre-injury voice. For facial-avatar animation, we demonstrate the control of virtual \u2026",
        "year": 2023,
        "authors": "Sean L Metzger and Kaylo T Littlejohn and Alexander B Silva and David A Moses and Margaret P Seaton and Ran Wang and Maximilian E Dougherty and Jessie R Liu and Peter Wu and Michael A Berger and Inga Zhuravleva and Adelyn Tu-Chan and Karunesh Ganguly and Gopala K Anumanchipalli and Edward F Chang"
      }
    ],
    "d97bGd8AAAAJ": [
      {
        "title": "Unpaired image-to-image translation using cycle-consistent adversarial networks",
        "abstract": "Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G: X-> Y such that the distribution of images from G (X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F: Y-> X and introduce a cycle consistency loss to push F (G (X))~ X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.",
        "year": 2017,
        "authors": "Jun-Yan Zhu and Taesung Park and Phillip Isola and Alexei A Efros"
      },
      {
        "title": "Image-to-image translation with conditional adversarial networks",
        "abstract": "We investigate conditional adversarial networks as a general-purpose solution to image-to-image translation problems. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. We demonstrate that this approach is effective at synthesizing photos from label maps, reconstructing objects from edge maps, and colorizing images, among other tasks. Moreover, since the release of the pix2pix software associated with this paper, hundreds of twitter users have posted their own artistic experiments using our system. As a community, we no longer hand-engineer our mapping functions, and this work suggests we can achieve reasonable results without handengineering our loss functions either.",
        "year": 2017,
        "authors": "Phillip Isola and Jun-Yan Zhu and Tinghui Zhou and Alexei A Efros"
      },
      {
        "title": "The unreasonable effectiveness of deep features as a perceptual metric",
        "abstract": "While it is nearly effortless for humans to quickly assess the perceptual similarity between two images, the underlying processes are thought to be quite complex. Despite this, the most widely used perceptual metrics today, such as PSNR and SSIM, are simple, shallow functions, and fail to account for many nuances of human perception. Recently, the deep learning community has found that features of the VGG network trained on ImageNet classification has been remarkably useful as a training loss for image synthesis. But how perceptual are these so-called``perceptual losses\"? What elements are critical for their success? To answer these questions, we introduce a new dataset of human perceptual similarity judgments. We systematically evaluate deep features across different architectures and tasks and compare them with classic metrics. We find that deep features outperform all previous metrics by large margins on our dataset. More surprisingly, this result is not restricted to ImageNet-trained VGG features, but holds across different deep architectures and levels of supervision (supervised, self-supervised, or even unsupervised). Our results suggest that perceptual similarity is an emergent property shared across deep visual representations.",
        "year": 2018,
        "authors": "Richard Zhang and Phillip Isola and Alexei A Efros and Eli Shechtman and Oliver Wang"
      }
    ],
    "Ch9iRwQAAAAJ": [
      {
        "title": "On the opportunities and risks of foundation models",
        "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",
        "year": 2021,
        "authors": "Rishi Bommasani and Drew A Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher R\u00e9 and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W Thomas and Florian Tram\u00e8r and Rose E Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang"
      },
      {
        "title": "Certified defenses against adversarial examples",
        "abstract": "While neural networks have achieved high accuracy on standard image classification benchmarks, their accuracy drops to nearly zero in the presence of small adversarial perturbations to test inputs. Defenses based on regularization and adversarial training have been proposed, but often followed by new, stronger attacks that defeat these defenses. Can we somehow end this arms race? In this work, we study this problem for neural networks with one hidden layer. We first propose a method based on a semidefinite relaxation that outputs a certificate that for a given network and test input, no attack can force the error to exceed a certain value. Second, as this certificate is differentiable, we jointly optimize it with the network parameters, providing an adaptive regularizer that encourages robustness against all attacks. On MNIST, our approach produces a network and a certificate that no attack that perturbs each pixel by at most \\epsilon = 0.1 can cause more than 35% test error.",
        "year": 2018,
        "authors": "Aditi Raghunathan and Jacob Steinhardt and Percy Liang"
      },
      {
        "title": "Unlabeled data improves adversarial robustness",
        "abstract": "We demonstrate, theoretically and empirically, that adversarial robustness can significantly benefit from semisupervised learning. Theoretically, we revisit the simple Gaussian model of Schmidt et al. that shows a sample complexity gap between standard and robust classification. We prove that unlabeled data bridges this gap: a simple semisupervised learning procedure (self-training) achieves high robust accuracy using the same number of labels required for achieving high standard accuracy. Empirically, we augment CIFAR-10 with 500K unlabeled images sourced from 80 Million Tiny Images and use robust self-training to outperform state-of-the-art robust accuracies by over 5 points in (i)  robustness against several strong attacks via adversarial training and (ii) certified  and  robustness via randomized smoothing. On SVHN, adding the dataset's own extra training set with the labels removed provides gains of 4 to 10 points, within 1 point of the gain from using the extra labels.",
        "year": 2019,
        "authors": "Yair Carmon and Aditi Raghunathan and Ludwig Schmidt and John C Duchi and Percy S Liang"
      }
    ],
    "GHpxNQIAAAAJ": [
      {
        "title": "Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding",
        "abstract": "Modeling textual or visual information with vector representations trained from large language or visual datasets has been successfully explored in recent years. However, tasks such as visual question answering require combining these vector representations with each other. Approaches to multimodal pooling include element-wise product or sum, as well as concatenation of the visual and textual representations. We hypothesize that these methods are not as expressive as an outer product of the visual and textual vectors. As the outer product is typically infeasible due to its high dimensionality, we instead propose utilizing Multimodal Compact Bilinear pooling (MCB) to efficiently and expressively combine multimodal features. We extensively evaluate MCB on the visual question answering and grounding tasks. We consistently show the benefit of MCB over ablations without MCB. For visual question answering, we present an architecture which uses MCB twice, once for predicting attention over spatial features and again to combine the attended representation with the question representation. This model outperforms the state-of-the-art on the Visual7W dataset and the VQA challenge.",
        "year": 2016,
        "authors": "Akira Fukui and Dong Huk Park and Daylen Yang and Anna Rohrbach and Trevor Darrell and Marcus Rohrbach"
      },
      {
        "title": "A Dataset for Movie Description",
        "abstract": "Audio Description (AD) provides linguistic descriptions of movies and allows visually impaired people to follow a movie along with their peers. Such descriptions are by design mainly visual and thus naturally form an interesting data source for computer vision and computational linguistics. In this work we propose a novel dataset which contains transcribed ADs, which are temporally aligned to full length HD movies. In addition we also collected the aligned movie scripts which have been used in prior work and compare the two different sources of descriptions. In total the MPII Movie Description dataset (MPII-MD) contains a parallel corpus of over 68K sentences and video snippets from 94 HD movies. We characterize the dataset by benchmarking different approaches for generating video descriptions. Comparing ADs to scripts, we find that ADs are far more visual and describe precisely what is shown rather than what should happen according to the scripts created prior to movie production.",
        "year": 2015,
        "authors": "Anna Rohrbach and Marcus Rohrbach and Niket Tandon and Bernt Schiele"
      },
      {
        "title": "Object Hallucination in Image Captioning",
        "abstract": "Despite continuously improving performance, contemporary image captioning models are prone to \"hallucinating\" objects that are not actually in a scene. One problem is that standard metrics only measure similarity to ground truth captions and may not fully capture image relevance. In this work, we propose a new image relevance metric to evaluate current models with veridical visual labels and assess their rate of object hallucination. We analyze how captioning model architectures and learning objectives contribute to object hallucination, explore when hallucination is likely due to image misclassification or language priors, and assess how well current sentence metrics capture object hallucination. We investigate these questions on the standard image captioning benchmark, MSCOCO, using a diverse set of models. Our analysis yields several interesting findings, including that models which score best on standard sentence metrics do not always have lower hallucination and that models which hallucinate more tend to make errors driven by language priors.",
        "year": 2018,
        "authors": "Anna Rohrbach and Lisa Anne Hendricks and Kaylee Burns and Trevor Darrell and Kate Saenko"
      }
    ],
    "lH1PdF8AAAAJ": [
      {
        "title": "Meta-learning with differentiable convex optimization",
        "abstract": "Many meta-learning approaches for few-shot learning rely on simple base learners such as nearest-neighbor classifiers. However, even in the few-shot regime, discriminatively trained linear predictors can offer better generalization. We propose to use these predictors as base learners to learn representations for few-shot learning and show they offer better tradeoffs between feature size and performance across a range of few-shot recognition benchmarks. Our objective is to learn feature embeddings that generalize well under a linear classification rule for novel categories. To efficiently solve the objective, we exploit two properties of linear classifiers: implicit differentiation of the optimality conditions of the convex problem and the dual formulation of the optimization problem. This allows us to use high-dimensional embeddings with improved generalization at a modest increase in computational overhead. Our approach, named MetaOptNet, achieves state-of-the-art performance on miniImageNet, tieredImageNet, CIFAR-FS, and FC100 few-shot learning benchmarks.",
        "year": 2019,
        "authors": "Kwonjoon Lee and Subhransu Maji and Avinash Ravichandran and Stefano Soatto"
      },
      {
        "title": "Quick shift and kernel methods for mode seeking",
        "abstract": "We show that the complexity of the recently introduced medoid-shift algorithm in clustering N points is O(N 2), with a small constant, if the underlying distance is Euclidean. This makes medoid shift considerably faster than mean shift, contrarily to what previously believed. We then exploit kernel methods to extend both mean shift and the improved medoid shift to a large family of distances, with complexity bounded by the effective rank of the resulting kernel matrix, and with explicit regularization constraints. Finally, we show that, under certain conditions, medoid shift fails to cluster data points belonging to the same mode, resulting in over-fragmentation. We propose remedies for this problem, by introducing a novel, simple and extremely efficient clustering algorithm, called quick shift, that explicitly trades off under- and over-fragmentation. Like medoid shift, quick shift operates in non-Euclidean spaces \u2026",
        "year": 2008,
        "authors": "Andrea Vedaldi and Stefano Soatto"
      }
    ],
    "rIjeeRsAAAAJ": [
      {
        "title": "ToxiGen: A Large-Scale Machine-Generated Dataset for Adversarial and Implicit Hate Speech Detection",
        "abstract": "Toxic language detection systems often falsely flag text that contains minority group mentions as toxic, as those groups are often the targets of online hate. Such over-reliance on spurious correlations also causes systems to struggle with detecting implicitly toxic language. To help mitigate these issues, we create ToxiGen, a new large-scale and machine-generated dataset of 274k toxic and benign statements about 13 minority groups. We develop a demonstration-based prompting framework and an adversarial classifier-in-the-loop decoding method to generate subtly toxic and benign text with a massive pretrained language model. Controlling machine generation in this way allows ToxiGen to cover implicitly toxic text at a larger scale, and about more demographic groups, than previous resources of human-written text. We conduct a human evaluation on a challenging subset of ToxiGen and find that annotators struggle to distinguish machine-generated text from human-written language. We also find that 94.5% of toxic examples are labeled as hate speech by human annotators. Using three publicly-available datasets, we show that finetuning a toxicity classifier on our data improves its performance on human-written data substantially. We also demonstrate that ToxiGen can be used to fight machine-generated toxicity as finetuning improves the classifier significantly on our evaluation subset. Our code and data can be found at https://github.com/microsoft/ToxiGen.",
        "year": 2022,
        "authors": "Thomas Hartvigsen and Saadia Gabriel and Hamid Palangi and Maarten Sap and Dipankar Ray and Ece Kamar"
      },
      {
        "title": "Aging with GRACE: Lifelong Model Editing with Discrete Key-Value Adaptors",
        "abstract": "Deployed language models decay over time due to shifting inputs, changing user needs, or emergent world-knowledge gaps. When such problems are identified, we want to make targeted edits while avoiding expensive retraining. However, current model editors, which modify such behaviors of pre-trained models, degrade model performance quickly across multiple, sequential edits. We propose GRACE, a\\textit {lifelong} model editing method, which implements spot-fixes on streaming errors of a deployed model, ensuring minimal impact on unrelated inputs. GRACE writes new mappings into a pre-trained model's latent space, creating a discrete, local codebook of edits without altering model weights. This is the first method enabling thousands of sequential edits using only streaming errors. Our experiments on T5, BERT, and GPT models show GRACE's state-of-the-art performance in making and retaining edits, while generalizing to unseen inputs. Our code is available at github. com/thartvigsen/grace.",
        "year": 2023,
        "authors": "Thomas Hartvigsen and Swami Sankaranarayanan and Hamid Palangi and Yoon Kim and Marzyeh Ghassemi"
      },
      {
        "title": "Are Language Models Actually Useful for Time Series Forecasting?",
        "abstract": "Large language models (LLMs) are being applied to time series forecasting. But are language models actually useful for time series? In a series of ablation studies on three recent and popular LLM-based time series forecasting methods, we find that removing the LLM component or replacing it with a basic attention layer does not degrade forecasting performance---in most cases, the results even improve! We also find that despite their significant computational cost, pretrained LLMs do no better than models trained from scratch, do not represent the sequential dependencies in time series, and do not assist in few-shot settings. Additionally, we explore time series encoders and find that patching and attention structures perform similarly to LLM-based forecasters. All resources needed to reproduce our work are available: https://github. com/BennyTMT/LLMsForTimeSeries.",
        "year": 2024,
        "authors": "Mingtian Tan and Mike A Merrill and Vinayak Gupta and Tim Althoff and Thomas Hartvigsen"
      }
    ],
    "kiFd6A8AAAAJ": [
      {
        "title": "Gain: Missing data imputation using generative adversarial nets",
        "abstract": "We propose a novel method for imputing missing data by adapting the well-known Generative Adversarial Nets (GAN) framework. Accordingly, we call our method Generative Adversarial Imputation Nets (GAIN). The generator (G) observes some components of a real data vector, imputes the missing components conditioned on what is actually observed, and outputs a completed vector. The discriminator (D) then takes a completed vector and attempts to determine which components were actually observed and which were imputed. To ensure that D forces G to learn the desired distribution, we provide D with some additional information in the form of a hint vector. The hint reveals to D partial information about the missingness of the original sample, which is used by D to focus its attention on the imputation quality of particular components. This hint ensures that G does in fact learn to generate according to the true data distribution. We tested our method on various datasets and found that GAIN significantly outperforms state-of-the-art imputation methods.",
        "year": 2018,
        "authors": "Jinsung Yoon and James Jordon and Mihaela Van Der Schaar"
      },
      {
        "title": "Time-series generative adversarial networks",
        "abstract": "A good generative model for time-series data should preserve temporal dynamics, in the sense that new sequences respect the original relationships between variables across time. Existing methods that bring generative adversarial networks (GANs) into the sequential setting do not adequately attend to the temporal correlations unique to time-series data. At the same time, supervised models for sequence prediction-which allow finer control over network dynamics-are inherently deterministic. We propose a novel framework for generating realistic time-series data that combines the flexibility of the unsupervised paradigm with the control afforded by supervised training. Through a learned embedding space jointly optimized with both supervised and adversarial objectives, we encourage the network to adhere to the dynamics of the training data during sampling. Empirically, we evaluate the ability of our method to generate realistic samples using a variety of real and synthetic time-series datasets. Qualitatively and quantitatively, we find that the proposed framework consistently and significantly outperforms state-of-the-art benchmarks with respect to measures of similarity and predictive ability.",
        "year": 2019,
        "authors": "Jinsung Yoon and Daniel Jarrett and Mihaela Van der Schaar"
      },
      {
        "title": "Cutpaste: Self-supervised learning for anomaly detection and localization",
        "abstract": "We aim at constructing a high performance model for defect detection that detects unknown anomalous patterns of an image without anomalous data. To this end, we propose a two-stage framework for building anomaly detectors using normal training data only. We first learn self-supervised deep representations and then build a generative one-class classifier on learned representations. We learn representations by classifying normal data from the CutPaste, a simple data augmentation strategy that cuts an image patch and pastes at a random location of a large image. Our empirical study on MVTec anomaly detection dataset demonstrates the proposed algorithm is general to be able to detect various types of real-world defects. We bring the improvement upon previous arts by 3.1 AUCs when learning representations from scratch. By transfer learning on pretrained representations on ImageNet, we achieve a new state-of-the-art 96.6 AUC. Lastly, we extend the framework to learn and extract representations from patches to allow localizing defective areas without annotations during training.",
        "year": 2021,
        "authors": "Chun-Liang Li and Kihyuk Sohn and Jinsung Yoon and Tomas Pfister"
      }
    ],
    "T9To2C0AAAAJ": [
      {
        "title": "Offline reinforcement learning: Tutorial, review, and perspectives on open problems",
        "abstract": "In this tutorial article, we aim to provide the reader with the conceptual tools needed to get started on research on offline reinforcement learning algorithms: reinforcement learning algorithms that utilize previously collected data, without additional online data collection. Offline reinforcement learning algorithms hold tremendous promise for making it possible to turn large datasets into powerful decision making engines. Effective offline reinforcement learning methods would be able to extract policies with the maximum possible utility out of the available data, thereby allowing automation of a wide range of decision-making domains, from healthcare and education to robotics. However, the limitations of current algorithms make this difficult. We will aim to provide the reader with an understanding of these challenges, particularly in the context of modern deep reinforcement learning methods, and describe some potential solutions that have been explored in recent work to mitigate these challenges, along with recent applications, and a discussion of perspectives on open problems in the field.",
        "year": 2020,
        "authors": "Sergey Levine and Aviral Kumar and George Tucker and Justin Fu"
      },
      {
        "title": "D4rl: Datasets for deep data-driven reinforcement learning",
        "abstract": "The offline reinforcement learning (RL) setting (also known as full batch RL), where a policy is learned from a static dataset, is compelling as progress enables RL methods to take advantage of large, previously-collected datasets, much like how the rise of large datasets has fueled results in supervised learning. However, existing online RL benchmarks are not tailored towards the offline setting and existing offline RL benchmarks are restricted to data generated by partially-trained agents, making progress in offline RL difficult to measure. In this work, we introduce benchmarks specifically designed for the offline setting, guided by key properties of datasets relevant to real-world applications of offline RL. With a focus on dataset collection, examples of such properties include: datasets generated via hand-designed controllers and human demonstrators, multitask datasets where an agent performs different tasks in the same environment, and datasets collected with mixtures of policies. By moving beyond simple benchmark tasks and data collected by partially-trained RL agents, we reveal important and unappreciated deficiencies of existing algorithms. To facilitate research, we have released our benchmark tasks and datasets with a comprehensive evaluation of existing algorithms, an evaluation protocol, and open-source examples. This serves as a common starting point for the community to identify shortcomings in existing offline RL methods and a collaborative route for progress in this emerging area.",
        "year": 2020,
        "authors": "Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine"
      },
      {
        "title": "Stabilizing off-policy q-learning via bootstrapping error reduction",
        "abstract": "Off-policy reinforcement learning aims to leverage experience collected from prior policies for sample-efficient learning. However, in practice, commonly used off-policy approximate dynamic programming methods based on Q-learning and actor-critic methods are highly sensitive to the data distribution, and can make only limited progress without collecting additional on-policy data. As a step towards more robust off-policy algorithms, we study the setting where the off-policy experience is fixed and there is no further interaction with the environment. We identify\\emph {bootstrapping error} as a key source of instability in current methods. Bootstrapping error is due to bootstrapping from actions that lie outside of the training data distribution, and it accumulates via the Bellman backup operator. We theoretically analyze bootstrapping error, and demonstrate how carefully constraining action selection in the backup can mitigate it. Based on our analysis, we propose a practical algorithm, bootstrapping error accumulation reduction (BEAR). We demonstrate that BEAR is able to learn robustly from different off-policy distributions, including random data and suboptimal demonstrations, on a range of continuous control tasks.",
        "year": 2019,
        "authors": "Aviral Kumar and Justin Fu and Matthew Soh and George Tucker and Sergey Levine"
      }
    ],
    "yDVn5LEAAAAJ": [
      {
        "title": "Starling-7b: Improving helpfulness and harmlessness with rlaif",
        "abstract": "This paper presents Starling-7B, the current best-performing 7B chat model on Chatbot Arena, along with its training dataset Nectar, a high-quality preference dataset collected by prompting GPT-4 to rank responses. We propose an internal pairwise rating technique, where the model considers all pairings before providing a ranking decision, leveraging the proven pairwise rating capability of LLMs without the cost of individual pairwise calls. The resulting Nectar dataset comprises 182,954 chat prompts, each with seven responses from various models, ranked by GPT-4, equating to 3.8 million high-quality pairwise comparisons. We introduce Starling-RM-7B and Starling-RM-34B, the reward model suites trained with a K-wise preference loss on Nectar, outperforming pairwise counterparts. We benchmark reward model training pipelines across metrics such as human preference, truthfulness, and safety. Using Nectar and our new training pipeline, we fine-tuned Openchat-3.5 to create Starling-LM-7B, achieving significant performance enhancements on MT-Bench, AlpacaEval, and human evaluation metrics. To facilitate research and understanding of RLHF mechanisms, we open-source the Nectar dataset, the reward models, and the language models.",
        "year": 2024,
        "authors": "Banghua Zhu and Evan Frick and Tianhao Wu and Hanlin Zhu and Karthik Ganesan and Wei-Lin Chiang and Jian Zhang and Jiantao Jiao"
      },
      {
        "title": "Guided dialog policy learning: Reward estimation for multi-domain task-oriented dialog",
        "abstract": "Dialog policy decides what and how a task-oriented dialog system will respond, and plays a vital role in delivering effective conversations. Many studies apply Reinforcement Learning to learn a dialog policy with the reward function which requires elaborate design and pre-specified user goals. With the growing needs to handle complex goals across multiple domains, such manually designed reward functions are not affordable to deal with the complexity of real-world tasks. To this end, we propose Guided Dialog Policy Learning, a novel algorithm based on Adversarial Inverse Reinforcement Learning for joint reward estimation and policy optimization in multi-domain task-oriented dialog. The proposed approach estimates the reward signal and infers the user goal in the dialog sessions. The reward estimator evaluates the state-action pairs so that it can guide the dialog policy at each dialog turn. Extensive experiments on a multi-domain dialog dataset show that the dialog policy guided by the learned reward function achieves remarkably higher task success than state-of-the-art baselines.",
        "year": 2019,
        "authors": "Ryuichi Takanobu and Hanlin Zhu and Minlie Huang"
      },
      {
        "title": "Optimal conservative offline rl with general function approximation via augmented lagrangian",
        "abstract": "Offline reinforcement learning (RL), which refers to decision-making from a previously-collected dataset of interactions, has received significant attention over the past years. Much effort has focused on improving offline RL practicality by addressing the prevalent issue of partial data coverage through various forms of conservative policy learning. While the majority of algorithms do not have finite-sample guarantees, several provable conservative offline RL algorithms are designed and analyzed within the single-policy concentrability framework that handles partial coverage. Yet, in the nonlinear function approximation setting where confidence intervals are difficult to obtain, existing provable algorithms suffer from computational intractability, prohibitively strong assumptions, and suboptimal statistical rates. In this paper, we leverage the marginalized importance sampling (MIS) formulation of RL and present the first set of offline RL algorithms that are statistically optimal and practical under general function approximation and single-policy concentrability, bypassing the need for uncertainty quantification. We identify that the key to successfully solving the sample-based approximation of the MIS problem is ensuring that certain occupancy validity constraints are nearly satisfied. We enforce these constraints by a novel application of the augmented Lagrangian method and prove the following result: with the MIS formulation, augmented Lagrangian is enough for statistically optimal offline RL. In stark contrast to prior algorithms that induce additional conservatism through methods such as behavior regularization, our approach provably eliminates this need \u2026",
        "year": 2022,
        "authors": "Paria Rashidinejad and Hanlin Zhu and Kunhe Yang and Stuart Russell and Jiantao Jiao"
      }
    ],
    "84WzBlYAAAAJ": [
      {
        "title": "Advances and open problems in federated learning",
        "abstract": "Federated learning (FL) is a machine learning setting where many clients (eg, mobile devices or whole organizations) collaboratively train a model under the orchestration of a central server (eg, service provider), while keeping the training data decentralized. FL embodies the principles of focused data collection and minimization, and can mitigate many of the systemic privacy risks and costs resulting from traditional, centralized machine learning and data science approaches. Motivated by the explosive growth in FL research, this monograph discusses recent advances and presents an extensive collection of open problems and challenges.",
        "year": 2021,
        "authors": "Peter Kairouz and H Brendan McMahan and Brendan Avent and Aur\u00e9lien Bellet and Mehdi Bennis and Arjun Nitin Bhagoji and Kallista Bonawitz and Zachary Charles and Graham Cormode and Rachel Cummings and Rafael GL D\u2019Oliveira and Hubert Eichner and Salim El Rouayheb and David Evans and Josh Gardner and Zachary Garrett and Adri\u00e0 Gasc\u00f3n and Badih Ghazi and Phillip B Gibbons and Marco Gruteser and Zaid Harchaoui and Chaoyang He and Lie He and Zhouyuan Huo and Ben Hutchinson and Justin Hsu and Martin Jaggi and Tara Javidi and Gauri Joshi and Mikhail Khodak and Jakub Konecn\u00fd and Aleksandra Korolova and Farinaz Koushanfar and Sanmi Koyejo and Tancr\u00e8de Lepoint and Yang Liu and Prateek Mittal and Mehryar Mohri and Richard Nock and Ayfer \u00d6zg\u00fcr and Rasmus Pagh and Hang Qi and Daniel Ramage and Ramesh Raskar and Mariana Raykova and Dawn Song and Weikang Song and Sebastian U Stich and Ziteng Sun and Ananda Theertha Suresh and Florian Tram\u00e8r and Praneeth Vepakomma and Jianyu Wang and Li Xiong and Zheng Xu and Qiang Yang and Felix X Yu and Han Yu and Sen Zhao"
      },
      {
        "title": "Practical techniques for searches on encrypted data",
        "abstract": "It is desirable to store data on data storage servers such as mail servers and file servers in encrypted form to reduce security and privacy risks. But this usually implies that one has to sacrifice functionality for security. For example, if a client wishes to retrieve only documents containing certain words, it was not previously known how to let the data storage server perform the search and answer the query, without loss of data confidentiality. We describe our cryptographic schemes for the problem of searching on encrypted data and provide proofs of security for the resulting crypto systems. Our techniques have a number of crucial advantages. They are provably secure: they provide provable secrecy for encryption, in the sense that the untrusted server cannot learn anything about the plaintext when only given the ciphertext; they provide query isolation for searches, meaning that the untrusted server cannot learn \u2026",
        "year": 2000,
        "authors": "Dawn Xiaoding Song and David Wagner and Adrian Perrig"
      },
      {
        "title": "Measuring massive multitask language understanding",
        "abstract": "We propose a new test to measure a text model's multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have near-random accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model's academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings.",
        "year": 2020,
        "authors": "Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt"
      }
    ],
    "ADkiClQAAAAJ": [
      {
        "title": "Do as i can, not as i say: Grounding language in robotic affordances",
        "abstract": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model\u2019s \u201chands and eyes,\u201d while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project\u2019s website, video, and open source can be \u2026",
        "year": 2023,
        "authors": "Anthony Brohan and Yevgen Chebotar and Chelsea Finn and Karol Hausman and Alexander Herzog and Daniel Ho and Julian Ibarz and Alex Irpan and Eric Jang and Ryan Julian and Dmitry Kalashnikov and Sergey Levine and Yao Lu and Carolina Parada and Kanishka Rao and Pierre Sermanet and Alexander T Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Mengyuan Yan and Noah Brown and Michael Ahn and Omar Cortes and Nicolas Sievers and Clayton Tan and Sichun Xu and Diego Reyes and Jarek Rettinghouse and Jornell Quiambao and Peter Pastor and Linda Luu and Kuang-Huei Lee and Yuheng Kuang and Sally Jesmonth and Nikhil J Joshi and Kyle Jeffrey and Rosario Jauregui Ruano and Jasmine Hsu and Keerthana Gopalakrishnan and Byron David and Andy Zeng and Chuyuan Kelly Fu"
      },
      {
        "title": "Palm-e: An embodied multimodal language model",
        "abstract": "Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.",
        "year": 2023,
        "authors": "Danny Driess and Fei Xia and Mehdi SM Sajjadi and Corey Lynch and Aakanksha Chowdhery and Ayzaan Wahid and Jonathan Tompson and Quan Vuong and Tianhe Yu and Wenlong Huang and Yevgen Chebotar and Pierre Sermanet and Daniel Duckworth and Sergey Levine and Vincent Vanhoucke and Karol Hausman and Marc Toussaint and Klaus Greff and Andy Zeng and Igor Mordatch and Pete Florence"
      },
      {
        "title": "Rt-2: Vision-language-action models transfer web knowledge to robotic control",
        "abstract": "We study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robotic trajectory data and Internet-scale vision-language tasks, such as visual question answering. In contrast to other approaches, we propose a simple, general recipe to achieve this goal: in order to fit both natural language responses and robotic actions into the same format, we express the actions as text tokens and incorporate them directly into the training set of the model in the same way as natural language tokens. We refer to such category of models as vision-language-action models (VLA) and instantiate an example of such a model, which we call RT-2. Our extensive evaluation (6k evaluation trials) shows that our approach leads to performant robotic policies and enables RT-2 to obtain a range of emergent capabilities from Internet-scale training. This includes significantly improved generalization to novel objects, the ability to interpret commands not present in the robot training data (such as placing an object onto a particular number or icon), and the ability to perform rudimentary reasoning in response to user commands (such as picking up the smallest or largest object, or the one closest to another object). We further show that incorporating chain of \u2026",
        "year": 2023,
        "authors": "Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Xi Chen and Krzysztof Choromanski and Tianli Ding and Danny Driess and Avinava Dubey and Chelsea Finn and Pete Florence and Chuyuan Fu and Montse Gonzalez Arenas and Keerthana Gopalakrishnan and Kehang Han and Karol Hausman and Alexander Herzog and Jasmine Hsu and Brian Ichter and Alex Irpan and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Lisa Lee and Tsang-Wei Edward Lee and Sergey Levine and Yao Lu and Henryk Michalewski and Igor Mordatch and Karl Pertsch and Kanishka Rao and Krista Reymann and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Pierre Sermanet and Jaspiar Singh and Anikait Singh and Radu Soricut and Huong Tran and Vincent Vanhoucke and Quan Vuong and Ayzaan Wahid and Stefan Welker and Paul Wohlhart and Jialin Wu and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich"
      }
    ],
    "a4unsk4AAAAJ": [
      {
        "title": "A Deep Learning Mammography-based Model for Improved Breast Cancer Risk Prediction",
        "abstract": "Mammographic density improves the accuracy of breast cancer risk models.                            However, the use of breast density is limited by subjective assessment,                            variation across radiologists, and restricted data. A mammography-based                            deep learning (DL) model may provide more accurate risk prediction.To develop a mammography-based DL breast cancer risk model that is more                            accurate than established clinical breast cancer risk models.This retrospective study included 88 994 consecutive screening mammograms                            in 39 571 women between January 1, 2009, and December 31, 2012. For each                            patient, all examinations were assigned to either training \u2026",
        "year": 2019,
        "authors": "Adam Yala and Constance Lehman and Tal Schuster and Tally Portnoi and Regina Barzilay"
      },
      {
        "title": "Toward robust mammography-based models for breast cancer risk",
        "abstract": "Improved breast cancer risk models enable targeted screening strategies that achieve earlier detection and less screening harm than existing guidelines. To bring deep learning risk models to clinical practice, we need to further refine their accuracy, validate them across diverse populations, and demonstrate their potential to improve clinical workflows. We developed Mirai, a mammography-based deep learning model designed to predict risk at multiple timepoints, leverage potentially missing risk factor information, and produce predictions that are consistent across mammography machines. Mirai was trained on a large dataset from Massachusetts General Hospital (MGH) in the United States and tested on held-out test sets from MGH, Karolinska University Hospital in Sweden, and Chang Gung Memorial Hospital (CGMH) in Taiwan, obtaining C-indices of 0.76 (95% confidence interval, 0.74 to 0.80), 0.81 (0.79 to 0 \u2026",
        "year": 2021,
        "authors": "Adam Yala and Peter G Mikhael and Fredrik Strand and Gigin Lin and Kevin Smith and Yung-Liang Wan and Leslie Lamb and Kevin Hughes and Constance Lehman and Regina Barzilay"
      }
    ],
    "65FCPpwAAAAJ": [
      {
        "title": "R-max-a general polynomial time algorithm for near-optimal reinforcement learning",
        "abstract": "R-MAX is a very simple model-based reinforcement learning algorithm which can attain near-optimal average reward in polynomial time. In R-MAX, the agent always maintains a complete, but possibly inaccurate model of its environment and acts based on the optimal policy derived from this model. The model is initialized in an optimistic fashion: all actions in all states return the maximal possible reward (hence the name). During execution, it is updated based on the agent's observations. R-MAX improves upon several previous algorithms:(1) It is simpler and more general than Kearns and Singh's E^ 3 algorithm, covering zero-sum stochastic games.(2) It has a built-in mechanism for resolving the exploration vs. exploitation dilemma.(3) It formally justifies the``optimism under uncertainty''bias used in many RL algorithms.(4) It is simpler, more general, and more efficient than Brafman and Tennenholtz's LSG algorithm for learning in single controller stochastic games.(5) It generalizes the algorithm by Monderer and Tennenholtz for learning in repeated games.(6) It is the only algorithm for learning in repeated games, to date, which is provably efficient, considerably improving and simplifying previous algorithms by Banos and by Megiddo.",
        "year": 2002,
        "authors": "Ronen I Brafman and Moshe Tennenholtz"
      },
      {
        "title": "On social laws for artificial agent societies: off-line design",
        "abstract": "We are concerned with the utility of social laws in a computational environment, laws which guarantee the successful coexistence of multiple programs and programmers. In this paper we are interested in the off-line design of social laws, where we as designers must decide ahead of time on useful social laws. In the first part of this paper we suggest the use of social laws in the domain of mobile robots, and prove analytic results about the usefulness of this approach in that setting. In the second part of this paper we present a general model of social law in a computational system, and investigate some of its properties. This includes a definition of the basic computational problem involved with the design of multi-agent systems, and an investigation of the automatic synthesis of useful social laws in the framework of a model which refers explicitly to social laws.",
        "year": 1995,
        "authors": "Yoav Shoham and Moshe Tennenholtz"
      },
      {
        "title": "On the synthesis of useful social laws for artificial agent societies",
        "abstract": "We present a general model of social law in a computational system, and investigate some of its properties. The contribution of this paper is twofold. First, we argue that the notion of social law is not epiphenomenal, but rather should be built into the action representation; we then offer such a representation. Second, we investigate the complexity of automatically deriving useful social laws in this model, given descriptions of the agents' capabilities, and the goals they might encounter. We show that in general the problem is NP-complete, and identify precise conditions under which it becomes polynomial.",
        "year": 1992,
        "authors": "Yoav Shoham and Moshe Tennenholtz"
      }
    ],
    "MN9Kfg8AAAAJ": [
      {
        "title": "A critical review of recurrent neural networks for sequence learning",
        "abstract": "Countless learning tasks require dealing with sequential data. Image captioning, speech synthesis, and music generation all require that a model produce outputs that are sequences. In other domains, such as time series prediction, video analysis, and musical information retrieval, a model must learn from inputs that are sequences. Interactive tasks, such as translating natural language, engaging in dialogue, and controlling a robot, often demand both capabilities. Recurrent neural networks (RNNs) are connectionist models that capture the dynamics of sequences via cycles in the network of nodes. Unlike standard feedforward neural networks, recurrent networks retain a state that can represent information from an arbitrarily long context window. Although recurrent neural networks have traditionally been difficult to train, and often contain millions of parameters, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful large-scale learning with them. In recent years, systems based on long short-term memory (LSTM) and bidirectional (BRNN) architectures have demonstrated ground-breaking performance on tasks as varied as image captioning, language translation, and handwriting recognition. In this survey, we review and synthesize the research that over the past three decades first yielded and then made practical these powerful learning models. When appropriate, we reconcile conflicting notation and nomenclature. Our goal is to provide a self-contained explication of the state of the art together with a historical perspective and references to primary research.",
        "year": 2015,
        "authors": "Zachary C Lipton and John Berkowitz and Charles Elkan"
      }
    ],
    "-XCiamcAAAAJ": [
      {
        "title": "Multi-scale context aggregation by dilated convolutions",
        "abstract": "State-of-the-art models for semantic segmentation are based on adaptations of convolutional networks that had originally been designed for image classification. However, dense prediction and image classification are structurally different. In this work, we develop a new convolutional network module that is specifically designed for dense prediction. The presented module uses dilated convolutions to systematically aggregate multi-scale contextual information without losing resolution. The architecture is based on the fact that dilated convolutions support exponential expansion of the receptive field without loss of resolution or coverage. We show that the presented context module increases the accuracy of state-of-the-art semantic segmentation systems. In addition, we examine the adaptation of image classification networks to dense prediction and show that simplifying the adapted network can increase accuracy.",
        "year": 2016,
        "authors": "Fisher Yu and Vladlen Koltun"
      },
      {
        "title": "3d shapenets: A deep representation for volumetric shapes",
        "abstract": "3D shape is a crucial but heavily underutilized cue in today's computer vision systems, mostly due to the lack of a good generic shape representation. With the recent availability of inexpensive 2.5 D depth sensors (eg Microsoft Kinect), it is becoming increasingly important to have a powerful 3D shape representation in the loop. Apart from category recognition, recovering full 3D shapes from view-based 2.5 D depth maps is also a critical part of visual understanding. To this end, we propose to represent a geometric 3D shape as a probability distribution of binary variables on a 3D voxel grid, using a Convolutional Deep Belief Network. Our model, 3D ShapeNets, learns the distribution of complex 3D shapes across different object categories and arbitrary poses from raw CAD data, and discovers hierarchical compositional part representation automatically. It naturally supports joint object recognition and shape completion from 2.5 D depth maps, and it enables active object recognition through view planning. To train our 3D deep learning model, we construct ModelNet-a large-scale 3D CAD model dataset. Extensive experiments show that our 3D deep representation enables significant performance improvement over the-state-of-the-arts in a variety of tasks.",
        "year": 2015,
        "authors": "Zhirong Wu and Shuran Song and Aditya Khosla and Fisher Yu and Linguang Zhang and Xiaoou Tang and Jianxiong Xiao"
      },
      {
        "title": "Shapenet: An information-rich 3d model repository",
        "abstract": "We present ShapeNet: a richly-annotated, large-scale repository of shapes represented by 3D CAD models of objects. ShapeNet contains 3D models from a multitude of semantic categories and organizes them under the WordNet taxonomy. It is a collection of datasets providing many semantic annotations for each 3D model such as consistent rigid alignments, parts and bilateral symmetry planes, physical sizes, keywords, as well as other planned annotations. Annotations are made available through a public web-based interface to enable data visualization of object attributes, promote data-driven geometric analysis, and provide a large-scale quantitative benchmark for research in computer graphics and vision. At the time of this technical report, ShapeNet has indexed more than 3,000,000 models, 220,000 models out of which are classified into 3,135 categories (WordNet synsets). In this report we describe the ShapeNet effort as a whole, provide details for all currently available datasets, and summarize future plans.",
        "year": 2015,
        "authors": "Angel X Chang and Thomas Funkhouser and Leonidas Guibas and Pat Hanrahan and Qixing Huang and Zimo Li and Silvio Savarese and Manolis Savva and Shuran Song and Hao Su and Jianxiong Xiao and Li Yi and Fisher Yu"
      }
    ],
    "4bl7qAgAAAAJ": [
      {
        "title": "CHOMP: Gradient optimization techniques for efficient motion planning",
        "abstract": "Existing high-dimensional motion planning algorithms are simultaneously overpowered and underpowered. In domains sparsely populated by obstacles, the heuristics used by sampling-based planners to navigate \u201cnarrow passages\u201d can be needlessly complex; furthermore, additional post-processing is required to remove the jerky or extraneous motions from the paths that such planners generate. In this paper, we present CHOMP, a novel method for continuous path refinement that uses covariant gradient techniques to improve the quality of sampled trajectories. Our optimization technique both optimizes higher-order dynamics and is able to converge over a wider range of input paths relative to previous path optimization strategies. In particular, we relax the collision-free feasibility prerequisite on input paths required by those strategies. As a result, CHOMP can be used as a standalone motion planner in many \u2026",
        "year": 2009,
        "authors": "Nathan Ratliff and Matt Zucker and J Andrew Bagnell and Siddhartha Srinivasa"
      },
      {
        "title": "Maximum margin planning",
        "abstract": "Imitation learning of sequential, goal-directed behavior by standard supervised techniques is often difficult. We frame learning such behaviors as a maximum margin structured prediction problem over a space of policies. In this approach, we learn mappings from features to cost so an optimal policy in an MDP with these cost mimics the expert's behavior. Further, we demonstrate a simple, provably efficient approach to structured maximum margin learning, based on the subgradient method, that leverages existing fast algorithms for inference. Although the technique is general, it is particularly relevant in problems where A* and dynamic programming approaches make learning policies tractable in problems beyond the limitations of a QP formulation. We demonstrate our approach applied to route planning for outdoor mobile robots, where the behavior a designer wishes a planner to execute is often clear, while \u2026",
        "year": 2006,
        "authors": "Nathan D Ratliff and J Andrew Bagnell and Martin A Zinkevich"
      },
      {
        "title": "Chomp: Covariant hamiltonian optimization for motion planning",
        "abstract": "In this paper, we present CHOMP (covariant Hamiltonian optimization for motion planning), a method for trajectory optimization invariant to reparametrization. CHOMP uses functional gradient techniques to iteratively improve the quality of an initial trajectory, optimizing a functional that trades off between a smoothness and an obstacle avoidance component. CHOMP can be used to locally optimize feasible trajectories, as well as to solve motion planning queries, converging to low-cost trajectories even when initialized with infeasible ones. It uses Hamiltonian Monte Carlo to alleviate the problem of convergence to high-cost local minima (and for probabilistic completeness), and is capable of respecting hard constraints along the trajectory. We present extensive experiments with CHOMP on manipulation and locomotion tasks, using seven-degree-of-freedom manipulators and a rough-terrain quadruped robot.",
        "year": 2013,
        "authors": "Matt Zucker and Nathan Ratliff and Anca D Dragan and Mihail Pivtoraiko and Matthew Klingensmith and Christopher M Dellin and J Andrew Bagnell and Siddhartha S Srinivasa"
      }
    ],
    "nABXo3sAAAAJ": [
      {
        "title": "Decaf: A deep convolutional activation feature for generic visual recognition",
        "abstract": "We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks. Our generic tasks may differ significantly from the originally trained tasks and there may be insufficient labeled or unlabeled data to conventionally train or adapt a deep architecture to the new tasks. We investigate and visualize the semantic clustering of deep convolutional features with respect to a variety of such tasks, including scene recognition, domain adaptation, and fine-grained recognition challenges. We compare the efficacy of relying on various network levels to define a fixed feature, and report novel results that significantly outperform the state-of-the-art on several important vision challenges. We are releasing DeCAF, an open-source implementation of these deep convolutional activation features, along with all associated network parameters to enable vision researchers to be able to conduct experimentation with deep representations across a range of visual concept learning paradigms.",
        "year": 2014,
        "authors": "Jeff Donahue and Yangqing Jia and Oriol Vinyals and Judy Hoffman and Ning Zhang and Eric Tzeng and Trevor Darrell"
      },
      {
        "title": "Adversarial discriminative domain adaptation",
        "abstract": "Adversarial learning methods are a promising approach to training robust deep networks, and can generate complex samples across diverse domains. They can also improve recognition despite the presence of domain shift or dataset bias: recent adversarial approaches to unsupervised domain adaptation reduce the difference between the training and test domain distributions and thus improve generalization performance. However, while generative adversarial networks (GANs) show compelling visualizations, they are not optimal on discriminative tasks and can be limited to smaller shifts. On the other hand, discriminative approaches can handle larger domain shifts, but impose tied weights on the model and do not exploit a GAN-based loss. In this work, we first outline a novel generalized framework for adversarial adaptation, which subsumes recent state-of-the-art approaches as special cases, and use this generalized view to better relate prior approaches. We then propose a previously unexplored instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss, which we call Adversarial Discriminative Domain Adaptation (ADDA). We show that ADDA is more effective yet considerably simpler than competing domain-adversarial methods, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results on standard domain adaptation tasks as well as a difficult cross-modality object classification task.",
        "year": 2017,
        "authors": "Eric Tzeng and Judy Hoffman and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Cycada: Cycle-consistent adversarial domain adaptation",
        "abstract": "Domain adaptation is critical for success in new, unseen environments. Adversarial adaptation models have shown tremendous progress towards adapting to new environments by focusing either on discovering domain invariant representations or by mapping between unpaired image domains. While feature space methods are difficult to interpret and sometimes fail to capture pixel-level and low-level domain shifts, image space methods sometimes fail to incorporate high level semantic knowledge relevant for the end task. We propose a model which adapts between domains using both generative image space alignment and latent representation space alignment. Our approach, Cycle-Consistent Adversarial Domain Adaptation (CyCADA), guides transfer between domains according to a specific discriminatively trained task and avoids divergence by enforcing consistency of the relevant semantics before and after adaptation. We evaluate our method on a variety of visual recognition and prediction settings, including digit classification and semantic segmentation of road scenes, advancing state-of-the-art performance for unsupervised adaptation from synthetic to real world driving domains.",
        "year": 2018,
        "authors": "Judy Hoffman and Eric Tzeng and Taesung Park and Jun-Yan Zhu and Phillip Isola and Kate Saenko and Alexei Efros and Trevor Darrell"
      }
    ],
    "wSstCv0AAAAJ": [
      {
        "title": "Theoretically principled trade-off between robustness and accuracy",
        "abstract": "We identify a trade-off between robustness and accuracy that serves as a guiding principle in the design of defenses against adversarial examples. Although this problem has been widely studied empirically, much remains unknown concerning the theory underlying this trade-off. In this work, we decompose the prediction error for adversarial examples (robust error) as the sum of the natural (classification) error and boundary error, and provide a differentiable upper bound using the theory of classification-calibrated loss, which is shown to be the tightest possible upper bound uniform over all probability distributions and measurable predictors. Inspired by our theoretical analysis, we also design a new defense method, TRADES, to trade adversarial robustness off against accuracy. Our proposed algorithm performs well experimentally in real-world datasets. The methodology is the foundation of our entry to the NeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of 2,000 submissions, surpassing the runner-up approach by 11.41% in terms of mean L_2 perturbation distance.",
        "year": 2019,
        "authors": "Hongyang Zhang and Yaodong Yu and Jiantao Jiao and Eric Xing and Laurent El Ghaoui and Michael Jordan"
      },
      {
        "title": "A closer look at accuracy vs. robustness",
        "abstract": "Current methods for training robust networks lead to a drop in test accuracy, which has led prior works to posit that a robustness-accuracy tradeoff may be inevitable in deep learning. We take a closer look at this phenomenon and first show that real image datasets are actually separated. With this property in mind, we then prove that robustness and accuracy should both be achievable for benchmark datasets through locally Lipschitz functions, and hence, there should be no inherent tradeoff between robustness and accuracy. Through extensive experiments with robustness methods, we argue that the gap between theory and practice arises from two limitations of current methods: either they fail to impose local Lipschitzness or they are insufficiently generalized. We explore combining dropout with robust training methods and obtain better generalization. We conclude that achieving robustness and accuracy in practice may require using methods that impose local Lipschitzness and augmenting them with deep learning generalization techniques.",
        "year": 2020,
        "authors": "Yao-Yuan Yang and Cyrus Rashtchian and Hongyang Zhang and Ruslan Salakhutdinov and Kamalika Chaudhuri"
      },
      {
        "title": "On the applications of robust PCA in image and video processing",
        "abstract": "Robust principal component analysis (RPCA) via decomposition into low-rank plus sparse matrices offers a powerful framework for a large variety of applications such as image processing, video processing, and 3-D computer vision. Indeed, most of the time these applications require to detect sparse outliers from the observed imagery data that can be approximated by a low-rank matrix. Moreover, most of the time experiments show that RPCA with additional spatial and/or temporal constraints often outperforms the state-of-the-art algorithms in these applications. Thus, the aim of this paper is to survey the applications of RPCA in computer vision. In the first part of this paper, we review representative image processing applications as follows: 1) low-level imaging such as image recovery and denoising, image composition, image colorization, image alignment and rectification, multifocus image, and face recognition; 2 \u2026",
        "year": 2018,
        "authors": "Thierry Bouwmans and Sajid Javed and Hongyang Zhang and Zhouchen Lin and Ricardo Otazo"
      }
    ],
    "OFlBL2kAAAAJ": [
      {
        "title": "Bc-z: Zero-shot task generalization with robotic imitation learning",
        "abstract": "In this paper, we study the problem of enabling a vision-based robotic manipulation system to generalize to novel tasks, a long-standing challenge in robot learning. We approach the challenge from an imitation learning perspective, aiming to study how scaling and broadening the data collected can facilitate such generalization. To that end, we develop an interactive and flexible imitation learning system that can learn from both demonstrations and interventions and can be conditioned on different forms of information that convey the task, including pre-trained embeddings of natural language or videos of humans performing the task. When scaling data collection on a real robot to more than 100 distinct tasks, we find that this system can perform 24 unseen manipulation tasks with an average success rate of 44%, without any robot demonstrations for those tasks.",
        "year": 2022,
        "authors": "Eric Jang and Alex Irpan and Mohi Khansari and Daniel Kappler and Frederik Ebert and Corey Lynch and Sergey Levine and Chelsea Finn"
      },
      {
        "title": "Stochastic adversarial video prediction",
        "abstract": "Being able to predict what may happen in the future requires an in-depth understanding of the physical and causal rules that govern the world. A model that is able to do so has a number of appealing applications, from robotic planning to representation learning. However, learning to predict raw future observations, such as frames in a video, is exceedingly challenging -- the ambiguous nature of the problem can cause a naively designed model to average together possible futures into a single, blurry prediction. Recently, this has been addressed by two distinct approaches: (a) latent variational variable models that explicitly model underlying stochasticity and (b) adversarially-trained models that aim to produce naturalistic images. However, a standard latent variable model can struggle to produce realistic results, and a standard adversarially-trained model underutilizes latent variables and fails to produce diverse predictions. We show that these distinct methods are in fact complementary. Combining the two produces predictions that look more realistic to human raters and better cover the range of possible futures. Our method outperforms prior and concurrent work in these aspects.",
        "year": 2018,
        "authors": "Alex X Lee and Richard Zhang and Frederik Ebert and Pieter Abbeel and Chelsea Finn and Sergey Levine"
      },
      {
        "title": "Visual foresight: Model-based deep reinforcement learning for vision-based robotic control",
        "abstract": "Deep reinforcement learning (RL) algorithms can learn complex robotic skills from raw sensory inputs, but have yet to achieve the kind of broad generalization and applicability demonstrated by deep learning methods in supervised domains. We present a deep RL method that is practical for real-world robotics tasks, such as robotic manipulation, and generalizes effectively to never-before-seen tasks and objects. In these settings, ground truth reward signals are typically unavailable, and we therefore propose a self-supervised model-based approach, where a predictive model learns to directly predict the future from raw sensory readings, such as camera images. At test time, we explore three distinct goal specification methods: designated pixels, where a user specifies desired object manipulation tasks by selecting particular pixels in an image and corresponding goal positions, goal images, where the desired goal state is specified with an image, and image classifiers, which define spaces of goal states. Our deep predictive models are trained using data collected autonomously and continuously by a robot interacting with hundreds of objects, without human supervision. We demonstrate that visual MPC can generalize to never-before-seen objects---both rigid and deformable---and solve a range of user-defined object manipulation tasks using the same model.",
        "year": 2018,
        "authors": "Frederik Ebert and Chelsea Finn and Sudeep Dasari and Annie Xie and Alex Lee and Sergey Levine"
      }
    ],
    "MzKvJhAAAAAJ": [
      {
        "title": "Measuring massive multitask language understanding",
        "abstract": "We propose a new test to measure a text model's multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have near-random accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model's academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings.",
        "year": 2020,
        "authors": "Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt"
      },
      {
        "title": "Measuring mathematical problem solving with the math dataset",
        "abstract": "Many intellectual endeavors require mathematical problem solving, but this skill remains beyond the capabilities of computers. To measure this ability in machine learning models, we introduce MATH, a new dataset of 12,500 challenging competition mathematics problems. Each problem in MATH has a full step-by-step solution which can be used to teach models to generate answer derivations and explanations. To facilitate future research and increase accuracy on MATH, we also contribute a large auxiliary pretraining dataset which helps teach models the fundamentals of mathematics. Even though we are able to increase accuracy on MATH, our results show that accuracy remains relatively low, even with enormous Transformer models. Moreover, we find that simply increasing budgets and model parameter counts will be impractical for achieving strong mathematical reasoning if scaling trends continue. While scaling Transformers is automatically solving most other text-based tasks, scaling is not currently solving MATH. To have more traction on mathematical problem solving we will likely need new algorithmic advancements from the broader research community.",
        "year": 2021,
        "authors": "Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt"
      },
      {
        "title": "The many faces of robustness: A critical analysis of out-of-distribution generalization",
        "abstract": "We introduce four new real-world distribution shift datasets consisting of changes in image style, image blurriness, geographic location, camera operation, and more. With our new datasets, we take stock of previously proposed methods for improving out-of-distribution robustness and put them to the test. We find that using larger models and artificial data augmentations can improve robustness on real-world distribution shifts, contrary to claims in prior work. We find improvements in artificial robustness benchmarks can transfer to real-world distribution shifts, contrary to claims in prior work. Motivated by our observation that data augmentations can help with real-world distribution shifts, we also introduce a new data augmentation method which advances the state-of-the-art and outperforms models pretrained with 1000x more labeled data. Overall we find that some methods consistently help with distribution shifts in texture and local image statistics, but these methods do not help with some other distribution shifts like geographic changes. Our results show that future research must study multiple distribution shifts simultaneously, as we demonstrate that no evaluated method consistently improves robustness.",
        "year": 2021,
        "authors": "Dan Hendrycks and Steven Basart and Norman Mu and Saurav Kadavath and Frank Wang and Evan Dorundo and Rahul Desai and Tyler Zhu and Samyak Parajuli and Mike Guo and Dawn Song and Jacob Steinhardt and Justin Gilmer"
      }
    ],
    "UfbuDH8AAAAJ": [
      {
        "title": "Rich feature hierarchies for accurate object detection and semantic segmentation",
        "abstract": "Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012---achieving a mAP of 53.3%. Our approach combines two key insights:(1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www. cs. berkeley. edu/~ rbg/rcnn.",
        "year": 2014,
        "authors": "Ross Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik"
      },
      {
        "title": "Caffe: Convolutional architecture for fast feature embedding",
        "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community \u2026",
        "year": 2014,
        "authors": "Yangqing Jia and Evan Shelhamer and Jeff Donahue and Sergey Karayev and Jonathan Long and Ross Girshick and Sergio Guadarrama and Trevor Darrell"
      },
      {
        "title": "Long-term recurrent convolutional networks for visual recognition and description",
        "abstract": "Models comprised of deep convolutional network layers have dominated recent image interpretation tasks; we investigate whether models which are also compositional, or\" deep\", temporally are effective on tasks involving visual sequences or label sequences. We develop a novel recurrent convolutional architecture suitable for large-scale visual learning which is end-to-end trainable, and demonstrate the value of these models on benchmark video recognition tasks, image to sentence generation problems, and video narration challenges. In contrast to current models which assume a fixed spatio-temporal receptive field or simple temporal averaging for sequential processing, recurrent convolutional models are\" doubly deep\" in that they can be compositional in spatial and temporal\" layers\". Such models may have advantages when target concepts are complex and/or training data are limited. Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. Long-term RNN models are appealing in that they directly can map variable length inputs (ie video frames) to variable length outputs (ie natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent long-term models are directly connected to state-of-the-art visual convnet models and can jointly trained, updating temporal dynamics and convolutional perceptual representations simultaneously. Our results show such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined and/or optimized.",
        "year": 2015,
        "authors": "Jeffrey Donahue and Lisa Anne Hendricks and Sergio Guadarrama and Marcus Rohrbach and Subhashini Venugopalan and Kate Saenko and Trevor Darrell"
      }
    ],
    "8R35rCwAAAAJ": [
      {
        "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
        "abstract": "We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.",
        "year": 2017,
        "authors": "Chelsea Finn and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Trust region policy optimization",
        "abstract": "In this article, we describe a method for optimizing control policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified scheme, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters.",
        "year": 2015,
        "authors": "John Schulman and Sergey Levine and Philipp Moritz and Michael I Jordan and Pieter Abbeel"
      }
    ],
    "LKv32bgAAAAJ": [
      {
        "title": "Measuring massive multitask language understanding",
        "abstract": "We propose a new test to measure a text model's multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have near-random accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model's academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings.",
        "year": 2020,
        "authors": "Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt"
      },
      {
        "title": "Concrete problems in AI safety",
        "abstract": "Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function (\"avoiding side effects\" and \"avoiding reward hacking\"), an objective function that is too expensive to evaluate frequently (\"scalable supervision\"), or undesirable behavior during the learning process (\"safe exploration\" and \"distributional shift\"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.",
        "year": 2016,
        "authors": "Dario Amodei and Chris Olah and Jacob Steinhardt and Paul Christiano and John Schulman and Dan Man\u00e9"
      },
      {
        "title": "Measuring mathematical problem solving with the math dataset",
        "abstract": "Many intellectual endeavors require mathematical problem solving, but this skill remains beyond the capabilities of computers. To measure this ability in machine learning models, we introduce MATH, a new dataset of 12,500 challenging competition mathematics problems. Each problem in MATH has a full step-by-step solution which can be used to teach models to generate answer derivations and explanations. To facilitate future research and increase accuracy on MATH, we also contribute a large auxiliary pretraining dataset which helps teach models the fundamentals of mathematics. Even though we are able to increase accuracy on MATH, our results show that accuracy remains relatively low, even with enormous Transformer models. Moreover, we find that simply increasing budgets and model parameter counts will be impractical for achieving strong mathematical reasoning if scaling trends continue. While scaling Transformers is automatically solving most other text-based tasks, scaling is not currently solving MATH. To have more traction on mathematical problem solving we will likely need new algorithmic advancements from the broader research community.",
        "year": 2021,
        "authors": "Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt"
      }
    ],
    "23ZXZvEAAAAJ": [
      {
        "title": "Analysis of protein-coding genetic variation in 60,706 humans",
        "abstract": "Large-scale reference data sets of human genetic variation are critical for the medical and functional interpretation of DNA sequence changes. Here we describe the aggregation and analysis of high-quality exome (protein-coding region) DNA sequence data for 60,706 individuals of diverse ancestries generated as part of the Exome Aggregation Consortium (ExAC). This catalogue of human genetic diversity contains an average of one variant every eight bases of the exome, and provides direct evidence for the presence of widespread mutational recurrence. We have used this catalogue to calculate objective metrics of pathogenicity for sequence variants, and to identify genes subject to strong selection against various classes of mutation; identifying 3,230 genes with near-complete depletion of predicted protein-truncating variants, with 72% of these genes having no currently established human disease phenotype \u2026",
        "year": 2016,
        "authors": "Monkol Lek and Konrad J Karczewski and Eric V Minikel and Kaitlin E Samocha and Eric Banks and Timothy Fennell and Anne H O\u2019Donnell-Luria and James S Ware and Andrew J Hill and Beryl B Cummings and Taru Tukiainen and Daniel P Birnbaum and Jack A Kosmicki and Laramie E Duncan and Karol Estrada and Fengmei Zhao and James Zou and Emma Pierce-Hoffman and Joanne Berghout and David N Cooper and Nicole Deflaux and Mark DePristo and Ron Do and Jason Flannick and Menachem Fromer and Laura Gauthier and Jackie Goldstein and Namrata Gupta and Daniel Howrigan and Adam Kiezun and Mitja I Kurki and Ami Levy Moonshine and Pradeep Natarajan and Lorena Orozco and Gina M Peloso and Ryan Poplin and Manuel A Rivas and Valentin Ruano-Rubio and Samuel A Rose and Douglas M Ruderfer and Khalid Shakir and Peter D Stenson and Christine Stevens and Brett P Thomas and Grace Tiao and Maria T Tusie-Luna and Ben Weisburd and Hong-Hee Won and Dongmei Yu and David M Altshuler and Diego Ardissino and Michael Boehnke and John Danesh and Stacey Donnelly and Roberto Elosua and Jose C Florez and Stacey B Gabriel and Gad Getz and Stephen J Glatt and Christina M Hultman and Sekar Kathiresan and Markku Laakso and Steven McCarroll and Mark I McCarthy and Dermot McGovern and Ruth McPherson and Benjamin M Neale and Aarno Palotie and Shaun M Purcell and Danish Saleheen and Jeremiah M Scharf and Pamela Sklar and Patrick F Sullivan and Jaakko Tuomilehto and Ming T Tsuang and Hugh C Watkins and James G Wilson and Mark J Daly and Daniel G MacArthur and Exome Aggregation Consortium"
      },
      {
        "title": "Man is to computer programmer as woman is to homemaker? debiasing word embeddings",
        "abstract": "The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is first shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender definition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between the words receptionist and female, while maintaining desired associations such as between the words queen and female. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias.",
        "year": 2016,
        "authors": "Tolga Bolukbasi and Kai-Wei Chang and James Y Zou and Venkatesh Saligrama and Adam T Kalai"
      },
      {
        "title": "Beyond the imitation game: Quantifying and extrapolating the capabilities of language models",
        "abstract": "Language models demonstrate both quantitative improvement and new qualitative capabilities with increasing scale. Despite their potentially transformative impact, these new capabilities are as yet poorly characterized. In order to inform future research, prepare for disruptive new model capabilities, and ameliorate socially harmful effects, it is vital that we understand the present and near-future capabilities and limitations of language models. To address this challenge, we introduce the Beyond the Imitation Game benchmark (BIG-bench). BIG-bench currently consists of 204 tasks, contributed by 450 authors across 132 institutions. Task topics are diverse, drawing problems from linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, software development, and beyond. BIG-bench focuses on tasks that are believed to be beyond the capabilities of current language models. We evaluate the behavior of OpenAI's GPT models, Google-internal dense transformer architectures, and Switch-style sparse transformers on BIG-bench, across model sizes spanning millions to hundreds of billions of parameters. In addition, a team of human expert raters performed all tasks in order to provide a strong baseline. Findings include: model performance and calibration both improve with scale, but are poor in absolute terms (and when compared with rater performance); performance is remarkably similar across model classes, though with benefits from sparsity; tasks that improve gradually and predictably commonly involve a large knowledge or memorization component, whereas tasks that exhibit \"breakthrough\" behavior at \u2026",
        "year": 2022,
        "authors": "Aarohi Srivastava and Abhinav Rastogi and Abhishek Rao and Abu Awal Md Shoeb and Abubakar Abid and Adam Fisch and Adam R Brown and Adam Santoro and Aditya Gupta and Adri\u00e0 Garriga-Alonso and Agnieszka Kluska and Aitor Lewkowycz and Akshat Agarwal and Alethea Power and Alex Ray and Alex Warstadt and Alexander W Kocurek and Ali Safaya and Ali Tazarv and Alice Xiang and Alicia Parrish and Allen Nie and Aman Hussain and Amanda Askell and Amanda Dsouza and Ambrose Slone and Ameet Rahane and Anantharaman S Iyer and Anders Andreassen and Andrea Madotto and Andrea Santilli and Andreas Stuhlm\u00fcller and Andrew Dai and Andrew La and Andrew Lampinen and Andy Zou and Angela Jiang and Angelica Chen and Anh Vuong and Animesh Gupta and Anna Gottardi and Antonio Norelli and Anu Venkatesh and Arash Gholamidavoodi and Arfa Tabassum and Arul Menezes and Arun Kirubarajan and Asher Mullokandov and Ashish Sabharwal and Austin Herrick and Avia Efrat and Aykut Erdem and Ayla Karaka\u015f and B Ryan Roberts and Bao Sheng Loe and Barret Zoph and Bart\u0142omiej Bojanowski and Batuhan \u00d6zyurt and Behnam Hedayatnia and Behnam Neyshabur and Benjamin Inden and Benno Stein and Berk Ekmekci and Bill Yuchen Lin and Blake Howald and Bryan Orinion and Cameron Diao and Cameron Dour and Catherine Stinson and Cedrick Argueta and C\u00e9sar Ferri Ram\u00edrez and Chandan Singh and Charles Rathkopf and Chenlin Meng and Chitta Baral and Chiyu Wu and Chris Callison-Burch and Chris Waites and Christian Voigt and Christopher D Manning and Christopher Potts and Cindy Ramirez and Clara E Rivera and Clemencia Siro and Colin Raffel and Courtney Ashcraft and Cristina Garbacea and Damien Sileo and Dan Garrette and Dan Hendrycks and Dan Kilman and Dan Roth and Daniel Freeman and Daniel Khashabi and Daniel Levy and Daniel Mosegu\u00ed Gonz\u00e1lez and Danielle Perszyk and Danny Hernandez and Danqi Chen and Daphne Ippolito and Dar Gilboa and David Dohan and David Drakard and David Jurgens and Debajyoti Datta and Deep Ganguli and Denis Emelin and Denis Kleyko and Deniz Yuret and Derek Chen and Derek Tam and Dieuwke Hupkes and Diganta Misra and Dilyar Buzan and Dimitri Coelho Mollo and Diyi Yang and Dong-Ho Lee and Dylan Schrader and Ekaterina Shutova and Ekin Dogus Cubuk and Elad Segal and Eleanor Hagerman and Elizabeth Barnes and Elizabeth Donoway and Ellie Pavlick and Emanuele Rodola and Emma Lam and Eric Chu and Eric Tang and Erkut Erdem and Ernie Chang and Ethan A Chi and Ethan Dyer and Ethan Jerzak and Ethan Kim and Eunice Engefu Manyasi and Evgenii Zheltonozhskii and Fanyue Xia and Fatemeh Siar and Fernando Mart\u00ednez-Plumed and Francesca Happ\u00e9 and Francois Chollet and Frieda Rong and Gaurav Mishra and Genta Indra Winata and Gerard de Melo and Germ\u00e1n Kruszewski and Giambattista Parascandolo and Giorgio Mariani and Gloria Wang"
      }
    ],
    "iyDxq0EAAAAJ": [
      {
        "title": "Chatbot arena: An open platform for evaluating llms by human preference",
        "abstract": "Large Language Models (LLMs) have unlocked new capabilities and applications; however, evaluating the alignment with human preferences still poses significant challenges. To address this issue, we introduce Chatbot Arena, an open platform for evaluating LLMs based on human preferences. Our methodology employs a pairwise comparison approach and leverages input from a diverse user base through crowdsourcing. The platform has been operational for several months, amassing over 240K votes. This paper describes the platform, analyzes the data we have collected so far, and explains the tried-and-true statistical methods we are using for efficient and accurate evaluation and ranking of models. We confirm that the crowdsourced questions are sufficiently diverse and discriminating and that the crowd-sourced human votes are in good agreement with those of expert raters. These analyses collectively establish a robust foundation for the credibility of Chatbot Arena. Because of its unique value and openness, Chatbot Arena has emerged as one of the most referenced LLM leaderboards, widely cited by leading LLM developers and companies. The platform is publicly available at https://chat.lmsys.org.",
        "year": 2024,
        "authors": "Wei-Lin Chiang and Lianmin Zheng and Ying Sheng and Anastasios Nikolas Angelopoulos and Tianle Li and Dacheng Li and Banghua Zhu and Hao Zhang and Michael Jordan and Joseph E Gonzalez and Ion Stoica"
      },
      {
        "title": "Bridging offline reinforcement learning and imitation learning: A tale of pessimism",
        "abstract": "Offline (or batch) reinforcement learning (RL) algorithms seek to learn an optimal policy from a fixed dataset without active data collection. Based on the composition of the offline dataset, two main methods are used: imitation learning which is suitable for expert datasets, and vanilla offline RL which often requires uniform coverage datasets. From a practical standpoint, datasets often deviate from these two extremes and the exact data composition is usually unknown. To bridge this gap, we present a new offline RL framework that smoothly interpolates between the two extremes of data composition, hence unifying imitation learning and vanilla offline RL. The new framework is centered around a weak version of the concentrability coefficient that measures the deviation of the behavior policy from the expert policy alone. Under this new framework, we ask: can one develop an algorithm that achieves a minimax optimal rate adaptive to unknown data composition? To address this question, we consider a lower confidence bound (LCB) algorithm developed based on pessimism in the face of uncertainty in offline RL. We study finite-sample properties of LCB as well as information-theoretic limits in multi-armed bandits, contextual bandits, and Markov decision processes (MDPs). Our analysis reveals surprising facts about optimality rates. In particular, in both contextual bandits and RL, LCB achieves a faster rate of  for nearly-expert datasets compared to the usual rate of  in offline RL, where  is the batch dataset sample size. In contextual bandits with at least two contexts, we prove that LCB is adaptively optimal for the entire data composition \u2026",
        "year": 2021,
        "authors": "Paria Rashidinejad and Banghua Zhu and Cong Ma and Jiantao Jiao and Stuart Russell"
      },
      {
        "title": "Principled reinforcement learning with human feedback from pairwise or k-wise comparisons",
        "abstract": "We provide a theoretical framework for Reinforcement Learning with Human Feedback (RLHF). We show that when the underlying true reward is linear, under both Bradley-Terry-Luce (BTL) model (pairwise comparison) and Plackett-Luce (PL) model (-wise comparison), MLE converges under certain semi-norm for the family of linear reward. On the other hand, when training a policy based on the learned reward model, we show that MLE fails while a pessimistic MLE provides policies with good performance under certain coverage assumption. We also show that under the PL model, both the true MLE and a different MLE which splits the -wise comparison into pairwise comparisons converge, while the true MLE is asymptotically more efficient. Our results validate the empirical success of the existing RLHF algorithms, and provide new insights for algorithm design. Our analysis can also be applied for the problem of online RLHF and inverse reinforcement learning.",
        "year": 2023,
        "authors": "Banghua Zhu and Michael Jordan and Jiantao Jiao"
      }
    ],
    "y-8unsgAAAAJ": [
      {
        "title": "Quenched invariance principle for simple random walk on percolation clusters",
        "abstract": "We consider the simple random walk on the (unique) infinite cluster of super-critical bond percolation in \u2124 d  with d\u22652. We prove that, for almost every percolation configuration, the path distribution of the walk converges weakly to that of non-degenerate, isotropic Brownian motion. Our analysis is based on the consideration of a harmonic deformation of the infinite cluster on which the random walk becomes a square-integrable martingale. The size of the deformation, expressed by the so called corrector, is estimated by means of ergodicity arguments.",
        "year": 2007,
        "authors": "Noam Berger and Marek Biskup"
      },
      {
        "title": "Recent progress on the random conductance model",
        "abstract": " Recent progress on the understanding of the Random Conductance Model is reviewed and             commented. A particular emphasis is on the results on the scaling limit of the random             walk among random conductances for almost every realization of the environment,             observations on the behavior of the effective resistance as well as the scaling limit of             certain models of gradient fields with non-convex interactions. The text is an expanded             version of the lecture notes for a course delivered at the 2011 Cornell Summer School on             Probability. ",
        "year": 2011,
        "authors": "Marek Biskup"
      },
      {
        "title": "On the scaling of the chemical distance in long-range percolation models",
        "abstract": "We consider the (unoriented) long-range percolation on \u2124d in dimensions d\u22651, where distinct sites x,y\u2208\u2124d get connected with probability pxy\u2208[0,1]. Assuming pxy=|x\u2212y|\u2212s+o(1) as |x\u2212y|\u2192\u221e, where s>0 and |\u22c5| is a norm distance on \u2124d, and supposing that the resulting random graph contains an infinite connected component C\u221e, we let D(x,y) be the graph distance between x and y measured on C\u221e. Our main result is that, for s\u2208(d,2d), D(x,y)=(log|x\u2212y|)\u0394+o(1),\u2003\u2003x,y\u2208C\u221e, |x\u2212y|\u2192\u221e, where \u0394\u22121 is the binary logarithm of 2d/s and o(1) is a quantity tending to zero in probability as |x\u2212y|\u2192\u221e. Besides its interest for general percolation theory, this result sheds some light on a question that has recently surfaced in the context of \u201csmall-world\u201d phenomena. As part of the proof we also establish tight bounds on the probability that the largest connected component in a finite box contains a positive fraction of all sites in the \u2026",
        "year": 2004,
        "authors": "Marek Biskup"
      }
    ],
    "0mgEF28AAAAJ": [
      {
        "title": "FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search",
        "abstract": "Designing accurate and efficient ConvNets for mobile devices is challenging because the design space is combinatorially large. Due to this, previous neural architecture search (NAS) methods are computationally expensive. ConvNet architecture optimality depends on factors such as input resolution and target devices. However, existing approaches are too resource demanding for case-by-case redesigns. Also, previous work focuses primarily on reducing FLOPs, but FLOP count does not always reflect actual latency. To address these, we propose a differentiable neural architecture search (DNAS) framework that uses gradient-based methods to optimize ConvNet architectures, avoiding enumerating and training individual architectures separately as in previous methods. FBNets (Facebook-Berkeley-Nets), a family of models discovered by DNAS surpass state-of-the-art models both designed manually and generated automatically. FBNet-B achieves 74.1% top-1 accuracy on ImageNet with 295M FLOPs and 23.1 ms latency on a Samsung S8 phone, 2.4 x smaller and 1.5 x faster than MobileNetV2-1.3 with similar accuracy. Despite higher accuracy and lower latency than MnasNet, we estimate FBNet-B's search cost is 420x smaller than MnasNet's, at only 216 GPU-hours. Searched for different resolutions and channel sizes, FBNets achieve 1.5% to 6.4% higher accuracy than MobileNetV2. The smallest FBNet achieves 50.2% accuracy and 2.9 ms latency (345 frames per second) on a Samsung S8. Over a Samsung-optimized FBNet, the iPhone-X-optimized model achieves a 1.4 x speedup on an iPhone X. FBNet models are open-sourced at \u2026",
        "year": 2018,
        "authors": "Bichen Wu and Xiaoliang Dai and Peizhao Zhang and Yanghan Wang and Fei Sun and Yiming Wu and Yuandong Tian and Peter Vajda and Yangqing Jia and Kurt Keutzer"
      },
      {
        "title": "Efficient streaming language models with attention sinks",
        "abstract": "Deploying Large Language Models (LLMs) in streaming applications such as multi-round dialogue, where long interactions are expected, is urgently needed but poses two major challenges. Firstly, during the decoding stage, caching previous tokens' Key and Value states (KV) consumes extensive memory. Secondly, popular LLMs cannot generalize to longer texts than the training sequence length. Window attention, where only the most recent KVs are cached, is a natural approach -- but we show that it fails when the text length surpasses the cache size. We observe an interesting phenomenon, namely attention sink, that keeping the KV of initial tokens will largely recover the performance of window attention. In this paper, we first demonstrate that the emergence of attention sink is due to the strong attention scores towards initial tokens as a \"sink\" even if they are not semantically important. Based on the above analysis, we introduce StreamingLLM, an efficient framework that enables LLMs trained with a finite length attention window to generalize to infinite sequence lengths without any fine-tuning. We show that StreamingLLM can enable Llama-2, MPT, Falcon, and Pythia to perform stable and efficient language modeling with up to 4 million tokens and more. In addition, we discover that adding a placeholder token as a dedicated attention sink during pre-training can further improve streaming deployment. In streaming settings, StreamingLLM outperforms the sliding window recomputation baseline by up to 22.2x speedup. Code and datasets are provided at https://github.com/mit-han-lab/streaming-llm.",
        "year": 2023,
        "authors": "Guangxuan Xiao and Yuandong Tian and Beidi Chen and Song Han and Mike Lewis"
      },
      {
        "title": "H  O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models",
        "abstract": "Large Language Models (LLMs), despite their recent impressive accomplishments, are notably cost-prohibitive to deploy, particularly for applications involving long-content generation, such as dialogue systems and story writing. Often, a large amount of transient state information, referred to as the , is stored in GPU memory in addition to model parameters, scaling linearly with the sequence length and batch size. In this paper, we introduce a novel approach for implementing the  which significantly reduces its memory footprint. Our approach is based on the noteworthy observation that a small portion of tokens contributes most of the value when computing attention scores. We call these tokens Heavy Hitters (). Through a comprehensive investigation, we find that () the emergence of  is natural and strongly correlates with the frequent co-occurrence of tokens in the text, and () removing them results in significant performance degradation. Based on these insights, we propose Heavy Hitter Oracle (), a  eviction policy that dynamically retains a balance of recent and  tokens. We formulate the  eviction as a dynamic submodular problem and prove (under mild assumptions) a theoretical guarantee for our novel eviction algorithm which could help guide future work. We validate the accuracy of our algorithm with OPT, LLaMA, and GPT-NeoX across a wide range of tasks. Our implementation of  with 20\\% heavy hitters improves the throughput over three leading inference systems DeepSpeed Zero-Inference, Hugging Face Accelerate, and FlexGen by up to , , and  on OPT-6.7 B and OPT-30B. With the same \u2026",
        "year": 2023,
        "authors": "Zhenyu Zhang and Ying Sheng and Tianyi Zhou and Tianlong Chen and Lianmin Zheng and Ruisi Cai and Zhao Song and Yuandong Tian and Christopher R\u00e9 and Clark Barrett and Zhangyang Wang and Beidi Chen"
      }
    ],
    "OP6ejqgAAAAJ": [
      {
        "title": "Minimax estimation of functionals of discrete distributions",
        "abstract": "We propose a general methodology for the construction and analysis of essentially minimax estimators for a wide class of functionals of finite dimensional parameters, and elaborate on the case of discrete distributions, where the support size S is unknown and may be comparable with or even much larger than the number of observations n. We treat the respective regions where the functional is nonsmooth and smooth separately. In the nonsmooth regime, we apply an unbiased estimator for the best polynomial approximation of the functional whereas, in the smooth regime, we apply a bias-corrected version of the maximum likelihood estimator (MLE). We illustrate the merit of this approach by thoroughly analyzing the performance of the resulting schemes for estimating two important information measures: 1) the entropy H(P) = \u03a3Si=1 -pi ln pi and 2) F\u03b1(P) = \u03a3Si=1 p\u03b1i, \u03b1 > 0. We obtain the minimax L2 rates for \u2026",
        "year": 2015,
        "authors": "Jiantao Jiao and Kartik Venkat and Yanjun Han and Tsachy Weissman"
      },
      {
        "title": "Justification of logarithmic loss via the benefit of side information",
        "abstract": "We consider a natural measure of relevance: the reduction in optimal prediction risk in the presence of side information. For any given loss function, this relevance measure captures the benefit of side information for performing inference on a random variable under this loss function. When such a measure satisfies a natural data processing property, and the random variable of interest has alphabet size greater than two, we show that it is uniquely characterized by the mutual information, and the corresponding loss function coincides with logarithmic loss. In doing so, our work provides a new characterization of mutual information, and justifies its use as a measure of relevance. When the alphabet is binary, we characterize the only admissible forms the measure of relevance can assume while obeying the specified data processing property. Our results naturally extend to measuring the causal influence between \u2026",
        "year": 2015,
        "authors": "Jiantao Jiao and Thomas A Courtade and Kartik Venkat and Tsachy Weissman"
      },
      {
        "title": "Reference based genome compression",
        "abstract": "DNA sequencing technology has advanced to a point where storage is becoming the central bottleneck in the acquisition and mining of more data. Large amounts of data are vital for genomics research, and generic compression tools, while viable, cannot offer the same savings as approaches tuned to inherent biological properties. We propose an algorithm to compress a target genome given a known reference genome. The proposed algorithm first generates a mapping from the reference to the target genome, and then compresses this mapping with an entropy coder. As an illustration of the performance: applying our algorithm to James Watson's genome with hg18 as a reference, we are able to reduce the 2991 megabyte (MB) genome down to 6.99 MB, while Gzip compresses it to 834.8 MB.",
        "year": 2012,
        "authors": "BG Chern and Idoia Ochoa and Alexandros Manolakos and Albert No and Kartik Venkat and Tsachy Weissman"
      }
    ],
    "AEsPCAUAAAAJ": [
      {
        "title": "Context encoders: Feature learning by inpainting",
        "abstract": "We present an unsupervised visual feature learning algorithm driven by context-based pixel prediction. By analogy with auto-encoders, we propose Context Encoders--a convolutional neural network trained to generate the contents of an arbitrary image region conditioned on its surroundings. In order to succeed at this task, context encoders need to both understand the content of the entire image, as well as produce a plausible hypothesis for the missing part (s). When training context encoders, we have experimented with both a standard pixel-wise reconstruction loss, as well as a reconstruction plus an adversarial loss. The latter produces much sharper results because it can better handle multiple modes in the output. We found that a context encoder learns a representation that captures not just appearance but also the semantics of visual structures. We quantitatively demonstrate the effectiveness of our learned features for CNN pre-training on classification, detection, and segmentation tasks. Furthermore, context encoders can be used for semantic inpainting tasks, either stand-alone or as initialization for non-parametric methods.",
        "year": 2016,
        "authors": "Deepak Pathak and Philipp Krahenbuhl and Jeff Donahue and Trevor Darrell and Alexei A Efros"
      },
      {
        "title": "Curiosity-driven exploration by self-supervised prediction",
        "abstract": "In many real-world scenarios, rewards extrinsic to the agent are extremely sparse, or absent altogether. In such cases, curiosity can serve as an intrinsic reward signal to enable the agent to explore its environment and learn skills that might be useful later in its life. We formulate curiosity as the error in an agent\u2019s ability to predict the consequence of its own actions in a visual feature space learned by a self-supervised inverse dynamics model. Our formulation scales to high-dimensional continuous state spaces like images, bypasses the difficulties of directly predicting pixels, and, critically, ignores the aspects of the environment that cannot affect the agent. The proposed approach is evaluated in two environments: VizDoom and Super Mario Bros. Three broad settings are investigated: 1) sparse extrinsic reward, where curiosity allows for far fewer interactions with the environment to reach the goal; 2) exploration with no extrinsic reward, where curiosity pushes the agent to explore more efficiently; and 3) generalization to unseen scenarios (eg new levels of the same game) where the knowledge gained from earlier experience helps the agent explore new places much faster than starting from scratch.",
        "year": 2017,
        "authors": "Deepak Pathak and Pulkit Agrawal and Alexei A Efros and Trevor Darrell"
      },
      {
        "title": "Toward Multimodal Image-to-Image Translation",
        "abstract": "Many image-to-image translation problems are ambiguous, as a single input image may correspond to multiple possible outputs. In this work, we aim to model a distribution of possible outputs in a conditional generative modeling setting. The ambiguity of the mapping is distilled in a low-dimensional latent vector, which can be randomly sampled at test time. A generator learns to map the given input, combined with this latent code, to the output. We explicitly encourage the connection between output and the latent code to be invertible. This helps prevent a many-to-one mapping from the latent code to the output during training, also known as the problem of mode collapse, and produces more diverse results. We explore several variants of this approach by employing different training objectives, network architectures, and methods of injecting the latent code. Our proposed method encourages bijective consistency between the latent encoding and output modes. We present a systematic comparison of our method and other variants on both perceptual realism and diversity.",
        "year": 2017,
        "authors": "Jun-Yan Zhu and Richard Zhang and Deepak Pathak and Trevor Darrell and Alexei A. Efros and Oliver Wang and Eli Shechtman"
      }
    ],
    "94RFSSsAAAAJ": [
      {
        "title": "{PowerGraph}: Distributed {Graph-Parallel} computation on natural graphs",
        "abstract": "Large-scale graph-structured computation is central to tasks ranging from targeted advertising to natural language processing and has led to the development of several graph-parallel abstractions including Pregel and GraphLab. However, the natural graphs commonly found in the real-world have highly skewed power-law degree distributions, which challenge the assumptions made by these abstractions, limiting performance and scalability.",
        "year": 2012,
        "authors": "Joseph E Gonzalez and Yucheng Low and Haijie Gu and Danny Bickson and Carlos Guestrin"
      },
      {
        "title": "Clipper: A {Low-Latency} online prediction serving system",
        "abstract": "Machine learning is being deployed in a growing number of applications which demand real-time, accurate, and robust predictions under heavy query load. However, most machine learning frameworks and systems only address model training and not deployment.",
        "year": 2017,
        "authors": "Daniel Crankshaw and Xin Wang and Guilio Zhou and Michael J Franklin and Joseph E Gonzalez and Ion Stoica"
      },
      {
        "title": "InferLine: latency-aware provisioning and scaling for prediction serving pipelines",
        "abstract": "Serving ML prediction pipelines spanning multiple models and hardware accelerators is a key challenge in production machine learning. Optimally configuring these pipelines to meet tight end-to-end latency goals is complicated by the interaction between model batch size, the choice of hardware accelerator, and variation in the query arrival process.In this paper we introduce InferLine, a system which provisions and manages the individual stages of prediction pipelines to meet end-to-end tail latency constraints while minimizing cost. InferLine consists of a low-frequency combinatorial planner and a high-frequency auto-scaling tuner. The low-frequency planner leverages stage-wise profiling, discrete event simulation, and constrained combinatorial search to automatically select hardware type, replication, and batching parameters for each stage in the pipeline. The high-frequency tuner uses network calculus to \u2026",
        "year": 2020,
        "authors": "Daniel Crankshaw and Gur-Eyal Sela and Xiangxi Mo and Corey Zumar and Ion Stoica and Joseph Gonzalez and Alexey Tumanov"
      }
    ],
    "VjsNXysAAAAJ": [
      {
        "title": "Reciprocal n-body collision avoidance",
        "abstract": "In this paper, we present a formal approach to reciprocal n-body collision avoidance, where multiple mobile robots need to avoid collisions with each other while moving in a common workspace. In our formulation, each robot acts fully independently, and does not communicate with other robots. Based on the definition of velocity obstacles [5], we derive sufficient conditions for collision-free motion by reducing the problem to solving a low-dimensional linear program. We test our approach on several dense and complex simulation scenarios involving thousands of robots and compute collision-free actions for all of them in only a few milliseconds. To the best of our knowledge, this method is the first that can guarantee local collision-free motion for a large number of robots in a cluttered workspace.",
        "year": 2011,
        "authors": "Jur van den Berg and Stephen J Guy and Ming Lin and Dinesh Manocha"
      },
      {
        "title": "Reciprocal velocity obstacles for real-time multi-agent navigation",
        "abstract": "In this paper, we propose a new concept \u2014 the \u2018Reciprocal Velocity Obstacle\u2019\u2014 for real-time multi-agent navigation. We consider the case in which each agent navigates independently without explicit communication with other agents. Our formulation is an extension of the Velocity Obstacle concept [3], which was introduced for navigation among (passively) moving obstacles. Our approach takes into account the reactive behavior of the other agents by implicitly assuming that the other agents make a similar collision-avoidance reasoning. We show that this method guarantees safe and oscillation-free motions for each of the agents. We apply our concept to navigation of hundreds of agents in densely populated environments containing both static and moving obstacles, and we show that real-time and scalable performance is achieved in such challenging scenarios.",
        "year": 2008,
        "authors": "Jur van den Berg and Ming Lin and Dinesh Manocha"
      },
      {
        "title": "Kinodynamic RRT*: Asymptotically optimal motion planning for robots with linear dynamics",
        "abstract": "We present Kinodynamic RRT*, an incremental sampling-based approach for asymptotically optimal motion planning for robots with linear dynamics. Our approach extends RRT*, which was introduced for holonomic robots [10], by using a fixed-final-state-free-final-time controller that optimally connects any pair of states, where the cost function is expressed as a trade-off between the duration of a trajectory and the expended control effort. Our approach generalizes earlier work on RRT* for kinodynamic systems, as it guarantees asymptotic optimality for any system with controllable linear dynamics, in state spaces of any dimension. In addition, we show that for the rich subclass of systems with a nilpotent dynamics matrix, closed-form solutions for optimal trajectories can be derived, which keeps the computational overhead of our algorithm compared to traditional RRT* at a minimum. We demonstrate the potential of \u2026",
        "year": 2013,
        "authors": "Dustin J Webb and Jur Van Den Berg"
      }
    ],
    "FwxfQosAAAAJ": [
      {
        "title": "Sim-to-real transfer of robotic control with dynamics randomization",
        "abstract": "Simulations are attractive environments for training agents as they provide an abundant source of data and alleviate certain safety concerns during the training process. But the behaviours developed by agents in simulation are often specific to the characteristics of the simulator. Due to modeling error, strategies that are successful in simulation may not transfer to their real world counterparts. In this paper, we demonstrate a simple method to bridge this \u201creality gap\u201d. By randomizing the dynamics of the simulator during training, we are able to develop policies that are capable of adapting to very different dynamics, including ones that differ significantly from the dynamics on which the policies were trained. This adaptivity enables the policies to generalize to the dynamics of the real world without any training on the physical system. Our approach is demonstrated on an object pushing task using a robotic arm. Despite \u2026",
        "year": 2018,
        "authors": "Xue Bin Peng and Marcin Andrychowicz and Wojciech Zaremba and Pieter Abbeel"
      },
      {
        "title": "Deepmimic: Example-guided deep reinforcement learning of physics-based character skills",
        "abstract": "A longstanding goal in character animation is to combine data-driven specification of behavior with a system that can execute a similar behavior in a physical simulation, thus enabling realistic responses to perturbations and environmental variation. We show that well-known reinforcement learning (RL) methods can be adapted to learn robust control policies capable of imitating a broad range of example motion clips, while also learning complex recoveries, adapting to changes in morphology, and accomplishing user-specified goals. Our method handles keyframed motions, highly-dynamic actions such as motion-captured flips and spins, and retargeted motions. By combining a motion-imitation objective with a task objective, we can train characters that react intelligently in interactive settings, e.g., by walking in a desired direction or throwing a ball at a user-specified target. This approach thus combines the \u2026",
        "year": 2018,
        "authors": "Xue Bin Peng and Pieter Abbeel and Sergey Levine and Michiel Van de Panne"
      },
      {
        "title": "Deeploco: Dynamic locomotion skills using hierarchical deep reinforcement learning",
        "abstract": "Learning physics-based locomotion skills is a difficult problem, leading to solutions that typically exploit prior knowledge of various forms. In this paper we aim to learn a variety of environment-aware locomotion skills with a limited amount of prior knowledge. We adopt a two-level hierarchical control framework. First, low-level controllers are learned that operate at a fine timescale and which achieve robust walking gaits that satisfy stepping-target and style objectives. Second, high-level controllers are then learned which plan at the timescale of steps by invoking desired step targets for the low-level controller. The high-level controller makes decisions directly based on high-dimensional inputs, including terrain maps or other suitable representations of the surroundings. Both levels of the control policy are trained using deep reinforcement learning. Results are demonstrated on a simulated 3D biped. Low-level \u2026",
        "year": 2017,
        "authors": "Xue Bin Peng and Glen Berseth and KangKang Yin and Michiel Van De Panne"
      }
    ],
    "aO8KpGcAAAAJ": [
      {
        "title": "Theoretically principled trade-off between robustness and accuracy",
        "abstract": "We identify a trade-off between robustness and accuracy that serves as a guiding principle in the design of defenses against adversarial examples. Although this problem has been widely studied empirically, much remains unknown concerning the theory underlying this trade-off. In this work, we decompose the prediction error for adversarial examples (robust error) as the sum of the natural (classification) error and boundary error, and provide a differentiable upper bound using the theory of classification-calibrated loss, which is shown to be the tightest possible upper bound uniform over all probability distributions and measurable predictors. Inspired by our theoretical analysis, we also design a new defense method, TRADES, to trade adversarial robustness off against accuracy. Our proposed algorithm performs well experimentally in real-world datasets. The methodology is the foundation of our entry to the NeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of 2,000 submissions, surpassing the runner-up approach by 11.41% in terms of mean L_2 perturbation distance.",
        "year": 2019,
        "authors": "Hongyang Zhang and Yaodong Yu and Jiantao Jiao and Eric P Xing and Laurent El Ghaoui and Michael I Jordan"
      },
      {
        "title": "Bridging offline reinforcement learning and imitation learning: A tale of pessimism",
        "abstract": "Offline (or batch) reinforcement learning (RL) algorithms seek to learn an optimal policy from a fixed dataset without active data collection. Based on the composition of the offline dataset, two main methods are used: imitation learning which is suitable for expert datasets, and vanilla offline RL which often requires uniform coverage datasets. From a practical standpoint, datasets often deviate from these two extremes and the exact data composition is usually unknown. To bridge this gap, we present a new offline RL framework that smoothly interpolates between the two extremes of data composition, hence unifying imitation learning and vanilla offline RL. The new framework is centered around a weak version of the concentrability coefficient that measures the deviation of the behavior policy from the expert policy alone. Under this new framework, we ask: can one develop an algorithm that achieves a minimax optimal rate adaptive to unknown data composition? To address this question, we consider a lower confidence bound (LCB) algorithm developed based on pessimism in the face of uncertainty in offline RL. We study finite-sample properties of LCB as well as information-theoretic limits in multi-armed bandits, contextual bandits, and Markov decision processes (MDPs). Our analysis reveals surprising facts about optimality rates. In particular, in both contextual bandits and RL, LCB achieves a faster rate of  for nearly-expert datasets compared to the usual rate of  in offline RL, where  is the batch dataset sample size. In contextual bandits with at least two contexts, we prove that LCB is adaptively optimal for the entire data composition \u2026",
        "year": 2021,
        "authors": "Paria Rashidinejad and Banghua Zhu and Cong Ma and Jiantao Jiao and Stuart Russell"
      },
      {
        "title": "Minimax estimation of functionals of discrete distributions",
        "abstract": "We propose a general methodology for the construction and analysis of essentially minimax estimators for a wide class of functionals of finite dimensional parameters, and elaborate on the case of discrete distributions, where the support size S is unknown and may be comparable with or even much larger than the number of observations n. We treat the respective regions where the functional is nonsmooth and smooth separately. In the nonsmooth regime, we apply an unbiased estimator for the best polynomial approximation of the functional whereas, in the smooth regime, we apply a bias-corrected version of the maximum likelihood estimator (MLE). We illustrate the merit of this approach by thoroughly analyzing the performance of the resulting schemes for estimating two important information measures: 1) the entropy H(P) = \u03a3Si=1 -pi ln pi and 2) F\u03b1(P) = \u03a3Si=1 p\u03b1i, \u03b1 > 0. We obtain the minimax L2 rates for \u2026",
        "year": 2015,
        "authors": "Jiantao Jiao and Kartik Venkat and Yanjun Han and Tsachy Weissman"
      }
    ],
    "3kDtybgAAAAJ": [
      {
        "title": "Long-term Recurrent Convolutional Networks for Visual Recognition and Description",
        "abstract": "Models comprised of deep convolutional network layers have dominated recent image interpretation tasks; we investigate whether models which are also compositional, or\" deep\", temporally are effective on tasks involving visual sequences or label sequences. We develop a novel recurrent convolutional architecture suitable for large-scale visual learning which is end-to-end trainable, and demonstrate the value of these models on benchmark video recognition tasks, image to sentence generation problems, and video narration challenges. In contrast to current models which assume a fixed spatio-temporal receptive field or simple temporal averaging for sequential processing, recurrent convolutional models are\" doubly deep\" in that they can be compositional in spatial and temporal\" layers\". Such models may have advantages when target concepts are complex and/or training data are limited. Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. Long-term RNN models are appealing in that they directly can map variable length inputs (ie video frames) to variable length outputs (ie natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent long-term models are directly connected to state-of-the-art visual convnet models and can jointly trained, updating temporal dynamics and convolutional perceptual representations simultaneously. Our results show such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined and/or optimized.",
        "year": 2017,
        "authors": "Jeff Donahue and Lisa Anne Hendricks and Marcus Rohrbach and Subhashini Venugopalan and Sergio Guadarrama and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Memory Aware Synapses: Learning what (not) to forget",
        "abstract": "Humans can learn in a continuous manner. Old rarely utilized knowledge can be overwritten by new incoming information while important, frequently used knowledge is prevented from being erased. In artificial learning systems, lifelong learning so far has focused mainly on accumulating knowledge over tasks and overcoming catastrophic forgetting. In this paper, we argue that, given the limited model capacity and the unlimited new information to be learned, knowledge has to be preserved or erased selectively. Inspired by neuroplasticity, we propose a novel approach for lifelong learning, coined Memory Aware Synapses (MAS). It computes the importance of the parameters of a neural network in an unsupervised and online manner. Given a new sample which is fed to the network, MAS accumulates an importance measure for each parameter of the network, based on how sensitive the predicted output function is to a change in this parameter. When learning a new task, changes to important parameters can then be penalized, effectively preventing important knowledge related to previous tasks from being overwritten. Further, we show an interesting connection between a local version of our method and Hebb\u2019s rule, which is a model for the learning process in the brain. We test our method on a sequence of object recognition tasks and on the challenging problem of learning an embedding for predicting< subject, predicate, object> triplets. We show state-of-the-art performance and, for the first time, the ability to adapt the importance of the parameters based on unlabeled data towards what the network needs (not) to forget, which may vary \u2026",
        "year": 2018,
        "authors": "Rahaf Aljundi and Francesca Babiloni and Mohamed Elhoseiny and Marcus Rohrbach and Tinne Tuytelaars"
      },
      {
        "title": "Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding",
        "abstract": "Modeling textual or visual information with vector representations trained from large language or visual datasets has been successfully explored in recent years. However, tasks such as visual question answering require combining these vector representations with each other. Approaches to multimodal pooling include element-wise product or sum, as well as concatenation of the visual and textual representations. We hypothesize that these methods are not as expressive as an outer product of the visual and textual vectors. As the outer product is typically infeasible due to its high dimensionality, we instead propose utilizing Multimodal Compact Bilinear pooling (MCB) to efficiently and expressively combine multimodal features. We extensively evaluate MCB on the visual question answering and grounding tasks. We consistently show the benefit of MCB over ablations without MCB. For visual question answering, we present an architecture which uses MCB twice, once for predicting attention over spatial features and again to combine the attended representation with the question representation. This model outperforms the state-of-the-art on the Visual7W dataset and the VQA challenge.",
        "year": 2016,
        "authors": "Akira Fukui and Dong Huk Park and Daylen Yang and Anna Rohrbach and Trevor Darrell and Marcus Rohrbach"
      }
    ],
    "df-THM0AAAAJ": [
      {
        "title": "From crowdsourced data to high-quality benchmarks: Arena-hard and benchbuilder pipeline",
        "abstract": "The rapid evolution of Large Language Models (LLMs) has outpaced the development of model evaluation, highlighting the need for continuous curation of new, challenging benchmarks. However, manual curation of high-quality, human-aligned benchmarks is expensive and time-consuming. To address this, we introduce BenchBuilder, an automated pipeline that leverages LLMs to curate high-quality, open-ended prompts from large, crowd-sourced datasets, enabling continuous benchmark updates without human in the loop. We apply BenchBuilder to datasets such as Chatbot Arena and WildChat-1M, extracting challenging prompts and utilizing LLM-as-a-Judge for automatic model evaluation. To validate benchmark quality, we propose new metrics to measure a benchmark's alignment with human preferences and ability to separate models. We release Arena-Hard-Auto, a benchmark consisting 500 challenging prompts curated by BenchBuilder. Arena-Hard-Auto provides 3x higher separation of model performances compared to MT-Bench and achieves 98.6% correlation with human preference rankings, all at a cost of $20. Our work sets a new framework for the scalable curation of automated benchmarks from extensive data.",
        "year": 2024,
        "authors": "Tianle Li and Wei-Lin Chiang and Evan Frick and Lisa Dunlap and Tianhao Wu and Banghua Zhu and Joseph E Gonzalez and Ion Stoica"
      },
      {
        "title": "Starling-7b: Improving helpfulness and harmlessness with rlaif",
        "abstract": "This paper presents Starling-7B, the current best-performing 7B chat model on Chatbot Arena, along with its training dataset Nectar, a high-quality preference dataset collected by prompting GPT-4 to rank responses. We propose an internal pairwise rating technique, where the model considers all pairings before providing a ranking decision, leveraging the proven pairwise rating capability of LLMs without the cost of individual pairwise calls. The resulting Nectar dataset comprises 182,954 chat prompts, each with seven responses from various models, ranked by GPT-4, equating to 3.8 million high-quality pairwise comparisons. We introduce Starling-RM-7B and Starling-RM-34B, the reward model suites trained with a K-wise preference loss on Nectar, outperforming pairwise counterparts. We benchmark reward model training pipelines across metrics such as human preference, truthfulness, and safety. Using Nectar and our new training pipeline, we fine-tuned Openchat-3.5 to create Starling-LM-7B, achieving significant performance enhancements on MT-Bench, AlpacaEval, and human evaluation metrics. To facilitate research and understanding of RLHF mechanisms, we open-source the Nectar dataset, the reward models, and the language models.",
        "year": 2024,
        "authors": "Banghua Zhu and Evan Frick and Tianhao Wu and Hanlin Zhu and Karthik Ganesan and Wei-Lin Chiang and Jian Zhang and Jiantao Jiao"
      },
      {
        "title": "RouteLLM: Learning to Route LLMs from Preference Data",
        "abstract": "Large language models (LLMs) excel at a wide range of tasks, but choosing the right model often involves balancing performance and cost. Powerful models offer better results but are expensive, while smaller models are more cost-effective but less capable. To address this trade-off, we introduce a training framework for learning efficient router models that dynamically select between a stronger and weaker LLM during inference. Our framework leverages human preference data and employs data augmentation techniques to enhance performance. Evaluations on public benchmarks show that our approach can reduce costs by over 2 times without sacrificing response quality. Moreover, our routers exhibit strong generalization capabilities, maintaining performance even when routing between LLMs not included in training. This highlights the potential of our framework to deliver cost-effective, high-performance LLM solutions.",
        "year": 2024,
        "authors": "Isaac Ong and Amjad Almahairi and Vincent Wu and Wei-Lin Chiang and Tianhao Wu and Joseph E Gonzalez and M Waleed Kadous and Ion Stoica"
      }
    ],
    "_PZKLYUAAAAJ": [
      {
        "title": "Adwords and generalized online matching",
        "abstract": "How does a search engine company decide what ads to display with each query so as to maximize its revenue? This turns out to be a generalization of the online bipartite matching problem. We introduce the notion of a trade-off revealing LP and use it to derive an optimal algorithm achieving a competitive ratio of 1\u22121/e for this problem.",
        "year": 2007,
        "authors": "Aranyak Mehta and Amin Saberi and Umesh Vazirani and Vijay Vazirani"
      },
      {
        "title": "Random walks in peer-to-peer networks",
        "abstract": "We quantify the effectiveness of random walks for searching and construction of unstructured peer-to-peer (P2P) networks. We have identified two cases where the use of random walks for searching achieves better results than flooding: a) when the overlay topology is clustered, and h) when a client re-issues the same query while its horizon does not change much. For construction, we argue that an expander can he maintained dynamically with constant operations per addition. The key technical ingredient of our approach is a deep result of stochastic processes indicating that samples taken from consecutive steps of a random walk can achieve statistical properties similar to independent sampling (if the second eigenvalue of the transition matrix is hounded away from 1, which translates to good expansion of the network; such connectivity is desired, and believed to hold, in every reasonable network and network \u2026",
        "year": 2004,
        "authors": "Christos Gkantsidis and Milena Mihail and Amin Saberi"
      },
      {
        "title": "On approximately fair allocations of indivisible goods",
        "abstract": "We study the problem of fairly allocating a set of indivisible goods to a set of people from an algorithmic perspective. fair division has been a central topic in the economic literature and several concepts of fairness have been suggested. The criterion that we focus on is envy-freeness. In our model, a monotone utility function is associated with every player specifying the value of each subset of the goods for the player. An allocation is envy-free if every player prefers her own share than the share of any other player. When the goods are divisible, envy-free allocations always exist. In the presence of indivisibilities, we show that there exist allocations in which the envy is bounded by the maximum marginal utility, and present a simple algorithm for computing such allocations. We then look at the optimization problem of finding an allocation with minimum possible envy. In the general case the problem is not solvable or \u2026",
        "year": 2004,
        "authors": "Richard J Lipton and Evangelos Markakis and Elchanan Mossel and Amin Saberi"
      }
    ],
    "Op-47sgAAAAJ": [
      {
        "title": "From crowdsourced data to high-quality benchmarks: Arena-hard and benchbuilder pipeline",
        "abstract": "The rapid evolution of Large Language Models (LLMs) has outpaced the development of model evaluation, highlighting the need for continuous curation of new, challenging benchmarks. However, manual curation of high-quality, human-aligned benchmarks is expensive and time-consuming. To address this, we introduce BenchBuilder, an automated pipeline that leverages LLMs to curate high-quality, open-ended prompts from large, crowd-sourced datasets, enabling continuous benchmark updates without human in the loop. We apply BenchBuilder to datasets such as Chatbot Arena and WildChat-1M, extracting challenging prompts and utilizing LLM-as-a-Judge for automatic model evaluation. To validate benchmark quality, we propose new metrics to measure a benchmark's alignment with human preferences and ability to separate models. We release Arena-Hard-Auto, a benchmark consisting 500 challenging prompts curated by BenchBuilder. Arena-Hard-Auto provides 3x higher separation of model performances compared to MT-Bench and achieves 98.6% correlation with human preference rankings, all at a cost of $20. Our work sets a new framework for the scalable curation of automated benchmarks from extensive data.",
        "year": 2024,
        "authors": "Tianle Li and Wei-Lin Chiang and Evan Frick and Lisa Dunlap and Tianhao Wu and Banghua Zhu and Joseph E Gonzalez and Ion Stoica"
      },
      {
        "title": "Starling-7b: Improving llm helpfulness & harmlessness with rlaif",
        "abstract": "publications | Tianhao Wu Tianhao Wu Toggle navigation about blog publications (current) \ncv ctrl k publications 2024 1.Thinking LLMs: General Instruction Following with Thought \nGeneration Tianhao Wu, Janice Lan, Weizhe Yuan , and 3 more authors arXiv preprint arXiv:2410.10630, \n2024 HTML 2.EmbedLLM: Learning Compact Representations of Large Language Models \nRichard Zhuang, Tianhao Wu, Zhaojin Wen , and 3 more authors arXiv preprint arXiv:2410.02223, \n2024 HTML 3.Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge \nTianhao Wu, Weizhe Yuan, Olga Golovneva , and 5 more authors arXiv preprint arXiv:2407.19594, \n2024 HTML 4.From Crowdsourced Data to High-Quality Benchmarks: Arena-Hard and \nBenchBuilder Pipeline Tianle Li, Wei-Lin Chiang, Evan Frick , and 5 more authors arXiv \npreprint arXiv:2406.11939, 2024 HTML 5.RouteLLM: Learning to Route \u2026",
        "year": 2023,
        "authors": "Banghua Zhu and Evan Frick and Tianhao Wu and Hanlin Zhu and Jiantao Jiao"
      }
    ],
    "pvyI8GkAAAAJ": [
      {
        "title": "Long-term recurrent convolutional networks for visual recognition and description",
        "abstract": "Models comprised of deep convolutional network layers have dominated recent image interpretation tasks; we investigate whether models which are also compositional, or\" deep\", temporally are effective on tasks involving visual sequences or label sequences. We develop a novel recurrent convolutional architecture suitable for large-scale visual learning which is end-to-end trainable, and demonstrate the value of these models on benchmark video recognition tasks, image to sentence generation problems, and video narration challenges. In contrast to current models which assume a fixed spatio-temporal receptive field or simple temporal averaging for sequential processing, recurrent convolutional models are\" doubly deep\" in that they can be compositional in spatial and temporal\" layers\". Such models may have advantages when target concepts are complex and/or training data are limited. Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. Long-term RNN models are appealing in that they directly can map variable length inputs (ie video frames) to variable length outputs (ie natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent long-term models are directly connected to state-of-the-art visual convnet models and can jointly trained, updating temporal dynamics and convolutional perceptual representations simultaneously. Our results show such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined and/or optimized.",
        "year": 2015,
        "authors": "Jeffrey Donahue and Lisa Anne Hendricks and Sergio Guadarrama and Marcus Rohrbach and Subhashini Venugopalan and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Gemini: a family of highly capable multimodal models",
        "abstract": "This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.",
        "year": 2023,
        "authors": "Gemini Team and Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M Dai and Anja Hauth and Katie Millican and David Silver and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Jack Krawczyk and Cosmo Du and Ed Chi and Heng-Tze Cheng and Eric Ni and Purvi Shah and Patrick Kane and Betty Chan and Manaal Faruqui and Aliaksei Severyn and Hanzhao Lin and YaGuang Li and Yong Cheng and Abe Ittycheriah and Mahdis Mahdieh and Mia Chen and Pei Sun and Dustin Tran and Sumit Bagri and Balaji Lakshminarayanan and Jeremiah Liu and Andras Orban and Fabian G\u00fcra and Hao Zhou and Xinying Song and Aurelien Boffy and Harish Ganapathy and Steven Zheng and HyunJeong Choe and \u00c1goston Weisz and Tao Zhu and Yifeng Lu and Siddharth Gopal and Jarrod Kahn and Maciej Kula and Jeff Pitman and Rushin Shah and Emanuel Taropa and Majd Al Merey and Martin Baeuml and Zhifeng Chen and Laurent El Shafey and Yujing Zhang and Olcan Sercinoglu and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Ana\u00efs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Gaurav Singh Tomar and Evan Senter and Martin Chadwick and Ilya Kornakov and Nithya Attaluri and I\u00f1aki Iturrate and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Xavier Garcia and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco"
      },
      {
        "title": "Training compute-optimal large language models",
        "abstract": "We investigate the optimal model size and number of tokens for training a transformer language model under a given compute budget. We find that current large language models are significantly undertrained, a consequence of the recent focus on scaling language models whilst keeping the amount of training data constant. By training over 400 language models ranging from 70 million to over 16 billion parameters on 5 to 500 billion tokens, we find that for compute-optimal training, the model size and the number of training tokens should be scaled equally: for every doubling of model size the number of training tokens should also be doubled. We test this hypothesis by training a predicted compute-optimal model, Chinchilla, that uses the same compute budget as Gopher but with 70B parameters and 4 more more data. Chinchilla uniformly and significantly outperforms Gopher (280B), GPT-3 (175B), Jurassic-1 (178B), and Megatron-Turing NLG (530B) on a large range of downstream evaluation tasks. This also means that Chinchilla uses substantially less compute for fine-tuning and inference, greatly facilitating downstream usage. As a highlight, Chinchilla reaches a state-of-the-art average accuracy of 67.5% on the MMLU benchmark, greater than a 7% improvement over Gopher.",
        "year": 2022,
        "authors": "Jordan Hoffmann and Sebastian Borgeaud and Arthur Mensch and Elena Buchatskaya and Trevor Cai and Eliza Rutherford and Diego de Las Casas and Lisa Anne Hendricks and Johannes Welbl and Aidan Clark and Tom Hennigan and Eric Noland and Katie Millican and George van den Driessche and Bogdan Damoc and Aurelia Guy and Simon Osindero and Karen Simonyan and Erich Elsen and Jack W Rae and Oriol Vinyals and Laurent Sifre"
      }
    ],
    "on2DUKoAAAAJ": [
      {
        "title": "Video-based AI for beat-to-beat assessment of cardiac function",
        "abstract": "Accurate assessment of cardiac function is crucial for the diagnosis of cardiovascular disease 1, screening for cardiotoxicity 2 and decisions regarding the clinical management of patients with a critical illness 3. However, human assessment of cardiac function focuses on a limited sampling of cardiac cycles and has considerable inter-observer variability despite years of training 4, 5. Here, to overcome this challenge, we present a video-based deep learning algorithm\u2014EchoNet-Dynamic\u2014that surpasses the performance of human experts in the critical tasks of segmenting the left ventricle, estimating ejection fraction and assessing cardiomyopathy. Trained on echocardiogram videos, our model accurately segments the left ventricle with a Dice similarity coefficient of 0.92, predicts ejection fraction with a mean absolute error of 4.1% and reliably classifies heart failure with reduced ejection fraction (area under the curve \u2026",
        "year": 2020,
        "authors": "David Ouyang and Bryan He and Amirata Ghorbani and Neal Yuan and Joseph Ebinger and Curtis P Langlotz and Paul A Heidenreich and Robert A Harrington and David H Liang and Euan A Ashley and James Y Zou"
      },
      {
        "title": "Deep learning interpretation of echocardiograms",
        "abstract": "Echocardiography uses ultrasound technology to capture high temporal and spatial resolution images of the heart and surrounding structures, and is the most common imaging modality in cardiovascular medicine. Using convolutional neural networks on a large new dataset, we show that deep learning applied to echocardiography can identify local cardiac structures, estimate cardiac function, and predict systemic phenotypes that modify cardiovascular risk but not readily identifiable to human interpretation. Our deep learning model, EchoNet, accurately identified the presence of pacemaker leads (AUC\u2009=\u20090.89), enlarged left atrium (AUC\u2009=\u20090.86), left ventricular hypertrophy (AUC\u2009=\u20090.75), left ventricular end systolic and diastolic volumes (\u2009=\u20090.74 and \u2009=\u20090.70), and ejection fraction (\u2009=\u20090.50), as well as predicted systemic phenotypes of age (\u2009=\u20090.46), sex (AUC\u2009=\u20090.88), weight (\u2009=\u20090.56), and height \u2026",
        "year": 2020,
        "authors": "Amirata Ghorbani and David Ouyang and Abubakar Abid and Bryan He and Jonathan H Chen and Robert A Harrington and David H Liang and Euan A Ashley and James Y Zou"
      },
      {
        "title": "How medical AI devices are evaluated: limitations and recommendations from an analysis of FDA approvals",
        "abstract": "A comprehensive overview of medical AI devices approved by the US Food and Drug Administration sheds new light on limitations of the evaluation process that can mask vulnerabilities of devices when they are deployed on patients.",
        "year": 2021,
        "authors": "Eric Wu and Kevin Wu and Roxana Daneshjou and David Ouyang and Daniel E Ho and James Zou"
      }
    ],
    "k-nF0qgAAAAJ": [
      {
        "title": "Resection of the liver for colorectal carcinoma metastases: a multi-institutional study of indications for resection",
        "abstract": "In an investigation of the indications for hepatic resection in the treatment of colorectal carcinoma metastases, the records of 859 patients who had undergone this procedure were reviewed. This patient group, from 24 institutions, was found to have a 5-year actuarial survival of 33% and a 5-year actuarial disease-free survival of 21%. The only factors that might by themselves be considered contraindications to hepatic resection are the presence of positive hepatic nodes, the presence of resectable extrahepatic metastases, or the presence of four or more metastases. Other factors that had a negative effect on long-term survival were margins of resection on the liver metastases less than or equal to 1 cm (S [5-year actuarial survival = 23%), the presence of positive mesenteric nodes in the primary tumor specimen (S = 23%), and a disease-free interval of less than 1 year (S = 24%). The effect of any one of these factors was not great enough to contraindicate resection. However, combinations of prognostic factors must be considered before resection is recommended. The overall 5-year survival rate for this large series has been very satisfying. Decision making in the future must take into account such factors as number of metastases, extrahepatic involvement, and stage of the primary tumor.",
        "year": 1988,
        "authors": "Kevin S Hughes"
      },
      {
        "title": "Lumpectomy plus tamoxifen with or without irradiation in women age 70 years or older with early breast cancer: long-term follow-up of CALGB 9343",
        "abstract": "To determine whether there is a benefit to adjuvant radiation therapy after breast-conserving surgery and tamoxifen in women age \u2265 70 years with early-stage breast cancer.Between July 1994 and February 1999, 636 women (age \u2265 70 years) who had clinical stage I (T1N0M0 according to TNM classification) estrogen receptor (ER) \u2013positive breast carcinoma treated by lumpectomy were randomly assigned to receive tamoxifen plus radiation therapy (TamRT; 317 women) or tamoxifen alone (Tam; 319 women). Primary end points were time to local or regional recurrence, frequency of mastectomy, breast cancer\u2013specific survival, time to distant metastasis, and overall survival (OS).Median follow-up for treated patients is now 12.6 years. At 10 years, 98% of patients receiving TamRT (95% CI, 96% to 99%) compared with 90% of those receiving Tam (95% CI, 85% to 93 \u2026",
        "year": 2013,
        "authors": "Kevin S Hughes and Lauren A Schnaper and Jennifer R Bellon and Constance T Cirrincione and Donald A Berry and Beryl McCormick and Hyman B Muss and Barbara L Smith and Clifford A Hudis and Eric P Winer and William C Wood"
      },
      {
        "title": "Lumpectomy plus tamoxifen with or without irradiation in women 70 years of age or older with early breast cancer",
        "abstract": "In women 70 years of age or older who have early breast cancer, it is unclear whether lumpectomy plus tamoxifen is as effective as lumpectomy followed by tamoxifen plus radiation therapy.Between July 1994 and February 1999, we randomly assigned 636 women who were 70 years of age or older and who had clinical stage I (T1N0M0 according to the tumor\u2013node\u2013metastasis classification), estrogen-receptor\u2013positive breast carcinoma treated by lumpectomy to receive tamoxifen plus radiation therapy (317 women) or tamoxifen alone (319 women). Primary end points were the time to local or regional recurrence, the frequency of mastectomy for recurrence, breast-cancer\u2013specific survival, the time to distant metastasis, and overall survival.The only significant difference between the two groups was in the rate of local or regional recurrence at five years (1 percent in the group given \u2026",
        "year": 2004,
        "authors": "Kevin S Hughes and Lauren A Schnaper and Donald Berry and Constance Cirrincione and Beryl McCormick and Brenda Shank and Judith Wheeler and Lorraine A Champion and Thomas J Smith and Barbara L Smith and Charles Shapiro and Hyman B Muss and Eric Winer and Clifford Hudis and William Wood and David Sugarbaker and I Craig Henderson and Larry Norton"
      }
    ],
    "pouyVyUAAAAJ": [
      {
        "title": "Squad: 100,000+ questions for machine comprehension of text",
        "abstract": "We present the Stanford Question Answering Dataset (SQuAD), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0%, a significant improvement over a simple baseline (20%). However, human performance (86.8%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at https://stanford-qa.com",
        "year": 2016,
        "authors": "Pranav Rajpurkar and Jian Zhang and Konstantin Lopyrev and Percy Liang"
      },
      {
        "title": "On the opportunities and risks of foundation models",
        "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",
        "year": 2021,
        "authors": "Rishi Bommasani and Drew A Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher R\u00e9 and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W Thomas and Florian Tram\u00e8r and Rose E Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang"
      },
      {
        "title": "Prefix-tuning: Optimizing continuous prompts for generation",
        "abstract": "Fine-tuning is the de facto way to leverage large pretrained language models to perform downstream tasks. However, it modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning for natural language generation tasks, which keeps language model parameters frozen, but optimizes a small continuous task-specific vector (called the prefix). Prefix-tuning draws inspiration from prompting, allowing subsequent tokens to attend to this prefix as if it were \"virtual tokens\". We apply prefix-tuning to GPT-2 for table-to-text generation and to BART for summarization. We find that by learning only 0.1\\% of the parameters, prefix-tuning obtains comparable performance in the full data setting, outperforms fine-tuning in low-data settings, and extrapolates better to examples with topics unseen during training.",
        "year": 2021,
        "authors": "Xiang Lisa Li and Percy Liang"
      }
    ],
    "aC55XVgAAAAJ": [
      {
        "title": "Breast reconstruction following nipple-sparing mastectomy: predictors of complications, reconstruction outcomes, and 5-year trends",
        "abstract": "Background:Nipple-sparing mastectomy is increasingly used for treatment and prevention of breast cancer. Few data exist on risk factors for complications and reconstruction outcomes.Methods:A single-institution retrospective review was performed between 2007 and 2012.Results:Two hundred eighty-five patients underwent 500 nipple-sparing mastectomy procedures for breast cancer (46 percent) or risk reduction (54 percent). The average body mass index was 24, and 6 percent were smokers. The mean follow-up was 2.17 years. Immediate breast reconstruction (reconstruction rate, 98.8 percent) was performed with direct-to-implant (59 percent), tissue expander/implant (38 percent), or autologous (2 percent) reconstruction. Acellular dermal matrix was used in 71 percent and mesh was used in 11 percent. Seventy-seven reconstructions had radiotherapy. Complications included infection (3.3 percent), skin \u2026",
        "year": 2014,
        "authors": "Amy S Colwell and Oren Tessler and Alex M Lin and Eric Liao and Jonathan Winograd and Curtis L Cetrulo and Rong Tang and Barbara L Smith and William G Austen Jr"
      },
      {
        "title": "Increasing eligibility for nipple-sparing mastectomy",
        "abstract": " Eligibility for nipple-sparing mastectomy (NSM) varies widely on the basis of patient and tumor factors.Review of patients undergoing NSM from June 2007 to December 2012 at our institution was performed. Patient and tumor characteristics, complications, and recurrences were collected. NSM from 2007 to 2010 and 2011 to 2012 were compared to assess trends in eligibility and outcomes over time.NSM was performed on 645 breasts in 370 patients. Indications were risk reduction in 330 (51.2 %), invasive cancer in 226 (35.0 %), and ductal carcinoma-in situ in 89 (13.8 %) breasts. Fifty-one (13.8 %) patients had positive lymph nodes. Twenty-seven (7.3 %) patients received neoadjuvant chemotherapy. Forty-eight (7.4 %) breasts had prior radiotherapy. Total nipple necrosis occurred in 11 \u2026",
        "year": 2013,
        "authors": "Suzanne B Coopey and Rong Tang and Lan Lei and Phoebe E Freer and Kari Kansal and Amy S Colwell and Michele A Gadd and Michelle C Specht and William G Austen and Barbara L Smith"
      },
      {
        "title": "Nipple-Sparing Mastectomy in BRCA1/2 Mutation Carriers: An Interim Analysis and Review of the Literature",
        "abstract": " There are few large-scale studies that have examined outcomes for BRCA1/2 carriers who have undergone nipple-sparing mastectomy (NSM). The objective of our study was to examine incidental cancers, operative complications, and locoregional recurrences in BRCA1/2 mutation carriers who underwent NSM for both risk reduction and cancer treatment.This was a retrospective review of pathology results and outcomes of 201 BRCA1/2 carriers from two different institutions who underwent NSM from 2007 to 2014.NSM was performed in 397 breasts of 201 BRCA1/2 carriers. One hundred and twenty-five (62.2 %) patients had a BRCA1 mutation and 76 (37.8 %) had a BRCA2 mutation; 150 (74.6 %) patients underwent NSM for risk reduction and 51 (25.4 %) for cancer. Incidental cancers \u2026",
        "year": 2015,
        "authors": "Katharine Yao and Erik Liederbach and Rong Tang and Lan Lei and Tomasz Czechura and Mark Sisco and Michael Howard and Peter J Hulick and David J Winchester and Suzanne B Coopey and Barbara L Smith"
      }
    ],
    "H3LMjtoAAAAJ": [
      {
        "title": "{PowerGraph}: Distributed {Graph-Parallel} computation on natural graphs",
        "abstract": "Large-scale graph-structured computation is central to tasks ranging from targeted advertising to natural language processing and has led to the development of several graph-parallel abstractions including Pregel and GraphLab. However, the natural graphs commonly found in the real-world have highly skewed power-law degree distributions, which challenge the assumptions made by these abstractions, limiting performance and scalability.",
        "year": 2012,
        "authors": "Joseph E Gonzalez and Yucheng Low and Haijie Gu and Danny Bickson and Carlos Guestrin"
      },
      {
        "title": "Distributed graphlab: A framework for machine learning in the cloud",
        "abstract": "While high-level data parallel frameworks, like MapReduce, simplify the design and implementation of large-scale data processing systems, they do not naturally or efficiently support many important data mining and machine learning algorithms and can lead to inefficient learning systems. To help fill this critical void, we introduced the GraphLab abstraction which naturally expresses asynchronous, dynamic, graph-parallel computation while ensuring data consistency and achieving a high degree of parallel performance in the shared-memory setting. In this paper, we extend the GraphLab framework to the substantially more challenging distributed setting while preserving strong data consistency guarantees. We develop graph based extensions to pipelined locking and data versioning to reduce network congestion and mitigate the effect of network latency. We also introduce fault tolerance to the GraphLab abstraction using the classic Chandy-Lamport snapshot algorithm and demonstrate how it can be easily implemented by exploiting the GraphLab abstraction itself. Finally, we evaluate our distributed implementation of the GraphLab abstraction on a large Amazon EC2 deployment and show 1-2 orders of magnitude performance gains over Hadoop-based implementations.",
        "year": 2012,
        "authors": "Yucheng Low and Joseph Gonzalez and Aapo Kyrola and Danny Bickson and Carlos Guestrin and Joseph M Hellerstein"
      },
      {
        "title": "Graphlab: A new framework for parallel machine learning",
        "abstract": "Designing and implementing efficient, provably correct parallel machine learning (ML) algorithms is challenging. Existing high-level parallel abstractions like MapReduce are insufficiently expressive while low-level tools like MPI and Pthreads leave ML experts repeatedly solving the same design challenges. By targeting common patterns in ML, we developed GraphLab, which improves upon abstractions like MapReduce by compactly expressing asynchronous iterative algorithms with sparse computational dependencies while ensuring data consistency and achieving a high degree of parallel performance. We demonstrate the expressiveness of the GraphLab framework by designing and implementing parallel versions of belief propagation, Gibbs sampling, Co-EM, Lasso and Compressed Sensing. We show that using GraphLab we can achieve excellent parallel performance on large scale real-world problems.",
        "year": 2014,
        "authors": "Yucheng Low and Joseph E Gonzalez and Aapo Kyrola and Danny Bickson and Carlos E Guestrin and Joseph Hellerstein"
      }
    ],
    "1wLVDP4AAAAJ": [
      {
        "title": "Soft actor-critic algorithms and applications",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Diversity is all you need: Learning skills without a reward function",
        "abstract": "Intelligent creatures can explore their environments and learn useful skills without supervision. In this paper, we propose DIAYN ('Diversity is All You Need'), a method for learning useful skills without a reward function. Our proposed method learns skills by maximizing an information theoretic objective using a maximum entropy policy. On a variety of simulated robotic tasks, we show that this simple objective results in the unsupervised emergence of diverse skills, such as walking and jumping. In a number of reinforcement learning benchmark environments, our method is able to learn a skill that solves the benchmark task despite never receiving the true task reward. We show how pretrained skills can provide a good parameter initialization for downstream tasks, and can be composed hierarchically to solve complex, sparse reward tasks. Our results suggest that unsupervised discovery of skills can serve as an effective pretraining mechanism for overcoming challenges of exploration and data efficiency in reinforcement learning.",
        "year": 2018,
        "authors": "Benjamin Eysenbach and Abhishek Gupta and Julian Ibarz and Sergey Levine"
      },
      {
        "title": "Gradient surgery for multi-task learning",
        "abstract": "While deep learning and deep reinforcement learning (RL) systems have demonstrated impressive results in domains such as image classification, game playing, and robotic control, data efficiency remains a major challenge. Multi-task learning has emerged as a promising approach for sharing structure across multiple tasks to enable more efficient learning. However, the multi-task setting presents a number of optimization challenges, making it difficult to realize large efficiency gains compared to learning tasks independently. The reasons why multi-task learning is so challenging compared to single-task learning are not fully understood. In this work, we identify a set of three conditions of the multi-task optimization landscape that cause detrimental gradient interference, and develop a simple yet general approach for avoiding such interference between task gradients. We propose a form of gradient surgery that projects a task's gradient onto the normal plane of the gradient of any other task that has a gradient. On a series of challenging multi-task supervised and multi-task RL problems, this approach leads to substantial gains in efficiency and performance. Further, it is model-agnostic and can be combined with previously-proposed multi-task architectures for enhanced performance.",
        "year": 2020,
        "authors": "Tianhe Yu and Saurabh Kumar and Abhishek Gupta and Sergey Levine and Karol Hausman and Chelsea Finn"
      }
    ],
    "APgaFK0AAAAJ": [
      {
        "title": "Multimodal machine learning: A survey and taxonomy",
        "abstract": "Our experience of the world is multimodal - we see objects, hear sounds, feel texture, smell odors, and taste flavors. Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities. In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together. Multimodal machine learning aims to build models that can process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy. We go beyond the typical early and late fusion categorization and identify broader challenges \u2026",
        "year": 2018,
        "authors": "Tadas Baltru\u0161aitis and Chaitanya Ahuja and Louis-Philippe Morency"
      },
      {
        "title": "Openface: an open source facial behavior analysis toolkit",
        "abstract": "Over the past few years, there has been an increased interest in automatic facial behavior analysis and understanding. We present OpenFace - an open source tool intended for computer vision and machine learning researchers, affective computing community and people interested in building interactive applications based on facial behavior analysis. OpenFace is the first open source tool capable of facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation. The computer vision algorithms which represent the core of OpenFace demonstrate state-of-the-art results in all of the above mentioned tasks. Furthermore, our tool is capable of real-time performance and is able to run from a simple webcam without any specialist hardware. Finally, OpenFace allows for easy integration with other applications and devices through a lightweight messaging system.",
        "year": 2016,
        "authors": "Tadas Baltru\u0161aitis and Peter Robinson and Louis-Philippe Morency"
      },
      {
        "title": "Tensor fusion network for multimodal sentiment analysis",
        "abstract": "Multimodal sentiment analysis is an increasingly popular research area, which extends the conventional language-based definition of sentiment analysis to a multimodal setup where other relevant modalities accompany language. In this paper, we pose the problem of multimodal sentiment analysis as modeling intra-modality and inter-modality dynamics. We introduce a novel model, termed Tensor Fusion Network, which learns both such dynamics end-to-end. The proposed approach is tailored for the volatile nature of spoken language in online videos as well as accompanying gestures and voice. In the experiments, our model outperforms state-of-the-art approaches for both multimodal and unimodal sentiment analysis.",
        "year": 2017,
        "authors": "Amir Zadeh and Minghai Chen and Soujanya Poria and Erik Cambria and Louis-Philippe Morency"
      }
    ],
    "gYiCq88AAAAJ": [
      {
        "title": "Caffe: Convolutional architecture for fast feature embedding",
        "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community \u2026",
        "year": 2014,
        "authors": "Yangqing Jia and Evan Shelhamer and Jeff Donahue and Sergey Karayev and Jonathan Long and Ross Girshick and Sergio Guadarrama and Trevor Darrell"
      },
      {
        "title": "Long-term recurrent convolutional networks for visual recognition and description",
        "abstract": "Models comprised of deep convolutional network layers have dominated recent image interpretation tasks; we investigate whether models which are also compositional, or\" deep\", temporally are effective on tasks involving visual sequences or label sequences. We develop a novel recurrent convolutional architecture suitable for large-scale visual learning which is end-to-end trainable, and demonstrate the value of these models on benchmark video recognition tasks, image to sentence generation problems, and video narration challenges. In contrast to current models which assume a fixed spatio-temporal receptive field or simple temporal averaging for sequential processing, recurrent convolutional models are\" doubly deep\" in that they can be compositional in spatial and temporal\" layers\". Such models may have advantages when target concepts are complex and/or training data are limited. Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. Long-term RNN models are appealing in that they directly can map variable length inputs (ie video frames) to variable length outputs (ie natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent long-term models are directly connected to state-of-the-art visual convnet models and can jointly trained, updating temporal dynamics and convolutional perceptual representations simultaneously. Our results show such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined and/or optimized.",
        "year": 2015,
        "authors": "Jeffrey Donahue and Lisa Anne Hendricks and Sergio Guadarrama and Marcus Rohrbach and Subhashini Venugopalan and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Speed/accuracy trade-offs for modern convolutional object detectors",
        "abstract": "The goal of this paper is to serve as a guide for selecting a detection architecture that achieves the right speed/memory/accuracy balance for a given application and platform. To this end, we investigate various ways to trade accuracy for speed and memory usage in modern convolutional object detection systems. A number of successful systems have been proposed in recent years, but apples-to-apples comparisons are difficult due to different base feature extractors (eg, VGG, Residual Networks), different default image resolutions, as well as different hardware and software platforms. We present a unified implementation of the Faster R-CNN (Ren et al., 2015), R-FCN (Dai et al., 2016) and SSD (Liu et al., 2016) systems, which we view as\" meta-architectures\" and trace out the speed/accuracy trade-off curve created by using alternative feature extractors and varying other critical parameters such as image size within each of these meta-architectures. On one extreme end of this spectrum where speed and memory are critical, we present a detector that achieves real time speeds and can be deployed on a mobile device. On the opposite end in which accuracy is critical, we present a detector that achieves state-of-the-art performance measured on the COCO detection task.",
        "year": 2017,
        "authors": "Jonathan Huang and Vivek Rathod and Chen Sun and Menglong Zhu and Anoop Korattikara and Alireza Fathi and Ian Fischer and Zbigniew Wojna and Yang Song and Sergio Guadarrama and Kevin Murphy"
      }
    ],
    "KgZxzjsAAAAJ": [
      {
        "title": "Robust face recognition via sparse representation",
        "abstract": "We consider the problem of automatically recognizing human faces from frontal views with varying expression and illumination, as well as occlusion and disguise. We cast the recognition problem as one of classifying among multiple linear regression models and argue that new theory from sparse signal representation offers the key to addressing this problem. Based on a sparse representation computed by \\ell^{1}-minimization, we propose a general classification algorithm for (image-based) object recognition. This new framework provides new insights into two crucial issues in face recognition: feature extraction and robustness to occlusion. For feature extraction, we show that if sparsity in the recognition problem is properly harnessed, the choice of features is no longer critical. What is critical, however, is whether the number of features is sufficiently large and whether the sparse representation is correctly \u2026",
        "year": 2008,
        "authors": "John Wright and Allen Y Yang and Arvind Ganesh and S Shankar Sastry and Yi Ma"
      },
      {
        "title": "A mathematical introduction to robotic manipulation",
        "abstract": "A Mathematical Introduction to Robotic Manipulation presents a mathematical formulation of the kinematics, dynamics, and control of robot manipulators. It uses an elegant set of mathematical tools that emphasizes the geometry of robot motion and allows a large class of robotic manipulation problems to be analyzed within a unified framework. The foundation of the book is a derivation of robot kinematics using the product of the exponentials formula. The authors explore the kinematics of open-chain manipulators and multifingered robot hands, present an analysis of the dynamics and control of robot systems, discuss the specification and control of internal forces and internal motions, and address the implications of the nonholonomic nature of rolling contact are addressed, as well. The wealth of information, numerous examples, and exercises make A Mathematical Introduction to Robotic Manipulation valuable as \u2026",
        "year": 2017,
        "authors": "Richard M Murray and Zexiang Li and S Shankar Sastry"
      },
      {
        "title": "Adaptive control: stability, convergence and robustness",
        "abstract": "With a focus on linear, continuous time, single-input, single-output systems, this volume surveys the major results and techniques of analysis in the field of adaptive control. The authors offer a clear, conceptual presentation of adaptive methods, enabling a critical evaluation of these techniques and suggesting avenues of further development. A brief historical overview of adaptive control is followed by a review of mathematical preliminaries and the development of several adaptive identification algorithms. Succeeding chapters examine averaging techniques, the robustness of adaptive schemes, and advanced topics\u2014including the use of prior information and multivariable adaptive control\u2014followed by a concise introduction to the control of a class of nonlinear systems. The treatment is largely self-contained, assuming only some graduate-level background in basic control systems and in linear systems theory.",
        "year": 2011,
        "authors": "Shankar Sastry and Marc Bodson"
      }
    ],
    "b8OxVWUAAAAJ": [
      {
        "title": "Cloud programming simplified: A berkeley view on serverless computing",
        "abstract": "Serverless cloud computing handles virtually all the system administration operations needed to make it easier for programmers to use the cloud. It provides an interface that greatly simplifies cloud programming, and represents an evolution that parallels the transition from assembly language to high-level programming languages. This paper gives a quick history of cloud computing, including an accounting of the predictions of the 2009 Berkeley View of Cloud Computing paper, explains the motivation for serverless computing, describes applications that stretch the current limits of serverless, and then lists obstacles and research opportunities required for serverless computing to fulfill its full potential. Just as the 2009 paper identified challenges for the cloud and predicted they would be addressed and that cloud use would accelerate, we predict these issues are solvable and that serverless computing will grow to dominate the future of cloud computing.",
        "year": 2019,
        "authors": "Eric Jonas and Johann Schleier-Smith and Vikram Sreekanti and Chia-Che Tsai and Anurag Khandelwal and Qifan Pu and Vaishaal Shankar and Joao Carreira and Karl Krauth and Neeraja Yadwadkar and Joseph E Gonzalez and Raluca Ada Popa and Ion Stoica and David A Patterson"
      },
      {
        "title": "Serverless computing: One step forward, two steps back",
        "abstract": "Serverless computing offers the potential to program the cloud in an autoscaling, pay-as-you go manner. In this paper we address critical gaps in first-generation serverless computing, which place its autoscaling potential at odds with dominant trends in modern computing: notably data-centric and distributed computing, but also open source and custom hardware. Put together, these gaps make current serverless offerings a bad fit for cloud innovation and particularly bad for data systems innovation. In addition to pinpointing some of the main shortfalls of current serverless architectures, we raise a set of challenges we believe must be met to unlock the radical potential that the cloud---with its exabytes of storage and millions of cores---should offer to innovative developers.",
        "year": 2018,
        "authors": "Joseph M Hellerstein and Jose Faleiro and Joseph E Gonzalez and Johann Schleier-Smith and Vikram Sreekanti and Alexey Tumanov and Chenggang Wu"
      },
      {
        "title": "Cloudburst: Stateful functions-as-a-service",
        "abstract": "Function-as-a-Service (FaaS) platforms and \"serverless\" cloud computing are becoming increasingly popular. Current FaaS offerings are targeted at stateless functions that do minimal I/O and communication. We argue that the benefits of serverless computing can be extended to a broader range of applications and algorithms. We present the design and implementation of Cloudburst, a stateful FaaS platform that provides familiar Python programming with low-latency mutable state and communication, while maintaining the autoscaling benefits of serverless computing. Cloudburst accomplishes this by leveraging Anna, an autoscaling key-value store, for state sharing and overlay routing combined with mutable caches co-located with function executors for data locality. Performant cache consistency emerges as a key challenge in this architecture. To this end, Cloudburst provides a combination of lattice-encapsulated state and new definitions and protocols for distributed session consistency. Empirical results on benchmarks and diverse applications show that Cloudburst makes stateful functions practical, reducing the state-management overheads of current FaaS platforms by orders of magnitude while also improving the state of the art in serverless consistency.",
        "year": 2020,
        "authors": "Vikram Sreekanti and Chenggang Wu and Xiayue Charles Lin and Johann Schleier-Smith and Jose M Faleiro and Joseph E Gonzalez and Joseph M Hellerstein and Alexey Tumanov"
      }
    ],
    "-gJkPHIAAAAJ": [
      {
        "title": "Gemini: a family of highly capable multimodal models",
        "abstract": "This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.",
        "year": 2023,
        "authors": "Gemini Team and Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M Dai and Anja Hauth and Katie Millican and David Silver and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Jack Krawczyk and Cosmo Du and Ed Chi and Heng-Tze Cheng and Eric Ni and Purvi Shah and Patrick Kane and Betty Chan and Manaal Faruqui and Aliaksei Severyn and Hanzhao Lin and YaGuang Li and Yong Cheng and Abe Ittycheriah and Mahdis Mahdieh and Mia Chen and Pei Sun and Dustin Tran and Sumit Bagri and Balaji Lakshminarayanan and Jeremiah Liu and Andras Orban and Fabian G\u00fcra and Hao Zhou and Xinying Song and Aurelien Boffy and Harish Ganapathy and Steven Zheng and HyunJeong Choe and \u00c1goston Weisz and Tao Zhu and Yifeng Lu and Siddharth Gopal and Jarrod Kahn and Maciej Kula and Jeff Pitman and Rushin Shah and Emanuel Taropa and Majd Al Merey and Martin Baeuml and Zhifeng Chen and Laurent El Shafey and Yujing Zhang and Olcan Sercinoglu and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Ana\u00efs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Gaurav Singh Tomar and Evan Senter and Martin Chadwick and Ilya Kornakov and Nithya Attaluri and I\u00f1aki Iturrate and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Xavier Garcia and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco"
      },
      {
        "title": "Soft actor-critic algorithms and applications",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Offline reinforcement learning: Tutorial, review, and perspectives on open problems",
        "abstract": "In this tutorial article, we aim to provide the reader with the conceptual tools needed to get started on research on offline reinforcement learning algorithms: reinforcement learning algorithms that utilize previously collected data, without additional online data collection. Offline reinforcement learning algorithms hold tremendous promise for making it possible to turn large datasets into powerful decision making engines. Effective offline reinforcement learning methods would be able to extract policies with the maximum possible utility out of the available data, thereby allowing automation of a wide range of decision-making domains, from healthcare and education to robotics. However, the limitations of current algorithms make this difficult. We will aim to provide the reader with an understanding of these challenges, particularly in the context of modern deep reinforcement learning methods, and describe some potential solutions that have been explored in recent work to mitigate these challenges, along with recent applications, and a discussion of perspectives on open problems in the field.",
        "year": 2020,
        "authors": "Sergey Levine and Aviral Kumar and George Tucker and Justin Fu"
      }
    ],
    "Q-v0BgUAAAAJ": [
      {
        "title": "A framework for variation discovery and genotyping using next-generation DNA sequencing data",
        "abstract": "Recent advances in sequencing technology make it possible to comprehensively catalog genetic variation in population samples, creating a foundation for understanding human disease, ancestry and evolution. The amounts of raw data produced are prodigious, and many computational steps are required to translate this output into high-quality variant calls. We present a unified analytic framework to discover and genotype variation among multiple samples simultaneously that achieves sensitive and specific results across five sequencing technologies and three distinct, canonical experimental designs. Our process includes (i) initial read mapping; (ii) local realignment around indels; (iii) base quality score recalibration; (iv) SNP discovery and genotyping to find all potential variants; and (v) machine learning to separate true segregating variation from machine artifacts common to next-generation sequencing \u2026",
        "year": 2011,
        "authors": "Mark A DePristo and Eric Banks and Ryan Poplin and Kiran V Garimella and Jared R Maguire and Christopher Hartl and Anthony A Philippakis and Guillermo Del Angel and Manuel A Rivas and Matt Hanna and Aaron McKenna and Tim J Fennell and Andrew M Kernytsky and Andrey Y Sivachenko and Kristian Cibulskis and Stacey B Gabriel and David Altshuler and Mark J Daly"
      },
      {
        "title": "A map of human genome variation from population scale sequencing",
        "abstract": "The 1000 Genomes Project aims to provide a deep characterisation of human genome sequence variation as a foundation for investigating the relationship between genotype and phenotype. We present results of the pilot phase of the project, designed to develop and compare different strategies for genome wide sequencing with high throughput sequencing platforms. We undertook three projects: low coverage whole genome sequencing of 179 individuals from four populations, high coverage sequencing of two mother-father-child trios, and exon targeted sequencing of 697 individuals from seven populations. We describe the location, allele frequency and local haplotype structure of approximately 15 million SNPs, 1 million short insertions and deletions and 20,000 structural variants, the majority of which were previously undescribed. We show that over 95% of the currently accessible variants found in any \u2026",
        "year": 2010,
        "authors": "1000 Genomes Project Consortium"
      },
      {
        "title": "Diversity and complexity in DNA recognition by transcription factors",
        "abstract": "Sequence preferences of DNA binding proteins are a primary mechanism by which cells interpret the genome. Despite the central importance of these proteins in physiology, development, and evolution, comprehensive DNA binding specificities have been determined experimentally for only a few proteins. Here, we used microarrays containing all 10\u2013base pair sequences to examine the binding specificities of 104 distinct mouse DNA binding proteins representing 22 structural classes. Our results reveal a complex landscape of binding, with virtually every protein analyzed possessing unique preferences. Roughly half of the proteins each recognized multiple distinctly different sequence motifs, challenging our molecular understanding of how proteins interact with their DNA binding sites. This complexity in DNA recognition may be important in gene regulation and in the evolution of transcriptional regulatory networks.",
        "year": 2009,
        "authors": "Gwenael Badis and Michael F Berger and Anthony A Philippakis and Shaheynoor Talukder and Andrew R Gehrke and Savina A Jaeger and Esther T Chan and Genita Metzler and Anastasia Vedenko and Xiaoyu Chen and Hanna Kuznetsov and Chi-Fong Wang and David Coburn and Daniel E Newburger and Quaid Morris and Timothy R Hughes and Martha L Bulyk"
      }
    ],
    "5VaXUQsAAAAJ": [
      {
        "title": "Gemini: a family of highly capable multimodal models",
        "abstract": "This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.",
        "year": 2023,
        "authors": "Gemini Team and Rohan Anil and Sebastian Borgeaud and Yonghui Wu and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M Dai and Anja Hauth and Katie Millican and David Silver and Slav Petrov and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Ana\u00efs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Martin Chadwick and Gaurav Singh Tomar and Xavier Garcia and Evan Senter and Emanuel Taropa and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco and Adri\u00e0 Puigdom\u00e8nech Badia and David Reitter and Mianna Chen and Jenny Brennan and Clara Rivera and Sergey Brin and Shariq Iqbal and Gabriela Surita and Jane Labanowski and Abhi Rao and Stephanie Winkler and Emilio Parisotto and Yiming Gu and Kate Olszewska and Yujing Zhang and Ravi Addanki and Antoine Miech and Annie Louis and Laurent El Shafey and Denis Teplyashin and Geoff Brown and Elliot Catt and Nithya Attaluri and Jan Balaguer and Jackie Xiang and Pidong Wang and Zoe Ashwood and Anton Briukhov and Albert Webson and Sanjay Ganapathy and Smit Sanghavi and Ajay Kannan and Ming-Wei Chang and Axel Stjerngren and Josip Djolonga and Yuting Sun and Ankur Bapna and Matthew Aitchison and Pedram Pejman and Henryk Michalewski and Tianhe Yu and Cindy Wang and Juliette Love and Junwhan Ahn"
      },
      {
        "title": "PaLM-E: An Embodied Multimodal Language Model",
        "abstract": "Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.",
        "year": 2023,
        "authors": "Danny Driess and Fei Xia and Mehdi SM Sajjadi and Corey Lynch and Aakanksha Chowdhery and Brian Ichter and Ayzaan Wahid and Jonathan Tompson and Quan Vuong and Tianhe Yu and Wenlong Huang and Yevgen Chebotar and Pierre Sermanet and Daniel Duckworth and Sergey Levine and Vincent Vanhoucke and Karol Hausman and Marc Toussaint and Klaus Greff and Andy Zeng and Igor Mordatch and Pete Florence"
      },
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien MR Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan"
      }
    ],
    "ijmuZ0wAAAAJ": [
      {
        "title": "Caffe: Convolutional architecture for fast feature embedding",
        "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community \u2026",
        "year": 2014,
        "authors": "Yangqing Jia and Evan Shelhamer and Jeff Donahue and Sergey Karayev and Jonathan Long and Ross Girshick and Sergio Guadarrama and Trevor Darrell"
      },
      {
        "title": "Densenet: Implementing efficient convnet descriptor pyramids",
        "abstract": "Convolutional Neural Networks (CNNs) can provide accurate object classification. They can be extended to perform object detection by iterating over dense or selected proposed object regions. However, the runtime of such detectors scales as the total number and/or area of regions to examine per image, and training such detectors may be prohibitively slow. However, for some CNN classifier topologies, it is possible to share significant work among overlapping regions to be classified. This paper presents DenseNet, an open source system that computes dense, multiscale features from the convolutional layers of a CNN based object classifier. Future work will involve training efficient object detectors with DenseNet feature descriptors.",
        "year": 2014,
        "authors": "Forrest Iandola and Matt Moskewicz and Sergey Karayev and Ross Girshick and Trevor Darrell and Kurt Keutzer"
      },
      {
        "title": "Recognizing image style",
        "abstract": "The style of an image plays a significant role in how it is viewed, but style has received little attention in computer vision research. We describe an approach to predicting style of images, and perform a thorough evaluation of different image features for these tasks. We find that features learned in a multi-layer network generally perform best -- even when trained with object class (not style) labels. Our large-scale learning methods results in the best published performance on an existing dataset of aesthetic ratings and photographic style annotations. We present two novel datasets: 80K Flickr photographs annotated with 20 curated style labels, and 85K paintings annotated with 25 style/genre labels. Our approach shows excellent classification performance on both datasets. We use the learned classifiers to extend traditional tag-based image search to consider stylistic constraints, and demonstrate cross-dataset understanding of style.",
        "year": 2013,
        "authors": "Sergey Karayev and Matthew Trentacoste and Helen Han and Aseem Agarwala and Trevor Darrell and Aaron Hertzmann and Holger Winnemoeller"
      }
    ],
    "x04W_mMAAAAJ": [
      {
        "title": "Imagenet classification with deep convolutional neural networks",
        "abstract": "We trained a large, deep convolutional neural network to classify the 1.3 million high-resolution images in the LSVRC-2010 ImageNet training set into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 39.7\\% and 18.9\\% which is considerably better than the previous state-of-the-art results. The neural network, which has 60 million parameters and 500,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and two globally connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of convolutional nets. To reduce overfitting in the globally connected layers we employed a new regularization method that proved to be very effective.",
        "year": 2012,
        "authors": "Alex Krizhevsky and Ilya Sutskever and Geoffrey E Hinton"
      },
      {
        "title": "Tensorflow: Large-scale machine learning on heterogeneous distributed systems",
        "abstract": "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.",
        "year": 2016,
        "authors": "Mart\u00edn Abadi and Ashish Agarwal and Paul Barham and Eugene Brevdo and Zhifeng Chen and Craig Citro and Greg S Corrado and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Ian Goodfellow and Andrew Harp and Geoffrey Irving and Michael Isard and Yangqing Jia and Rafal J\u00f3zefowicz and Lukasz Kaiser and Manjunath Kudlur and Josh Levenberg and Dan Man\u00e9 and Rajat Monga and Sherry Moore and Derek Murray and Chris Olah and Mike Schuster and Jonathon Shlens and Benoit Steiner and Ilya Sutskever and Kunal Talwar and Paul Tucker and Vincent Vanhoucke and Vijay Vasudevan and Fernanda Viegas and Oriol Vinyals and Pete Warden and Martin Wattenberg and Martin Wicke and Yuan Yu and Xiaoqiang Zheng"
      },
      {
        "title": "Dropout: a simple way to prevent neural networks from overfitting",
        "abstract": "Deep neural nets with a large number of parameters are very powerful machine learning systems. However, overfitting is a serious problem in such networks. Large networks are also slow to use, making it difficult to deal with overfitting by combining the predictions of many different large neural nets at test time. Dropout is a technique for addressing this problem. The key idea is to randomly drop units (along with their connections) from the neural network during training. This prevents units from co-adapting too much. During training, dropout samples from an exponential number of different \"thinned\" networks. At test time, it is easy to approximate the effect of averaging the predictions of all these thinned networks by simply using a single unthinned network that has smaller weights. This significantly reduces overfitting and gives major improvements over other regularization methods. We show that dropout improves \u2026",
        "year": 2014,
        "authors": "Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov"
      }
    ],
    "B96GkdgAAAAJ": [
      {
        "title": "Judging llm-as-a-judge with mt-bench and chatbot arena",
        "abstract": "Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80\\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github. com/lm-sys/FastChat/tree/main/fastchat/llm_judge.",
        "year": 2023,
        "authors": "Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric Xing and Hao Zhang and Joseph E Gonzalez and Ion Stoica"
      },
      {
        "title": "{PowerGraph}: Distributed {Graph-Parallel} computation on natural graphs",
        "abstract": "Large-scale graph-structured computation is central to tasks ranging from targeted advertising to natural language processing and has led to the development of several graph-parallel abstractions including Pregel and GraphLab. However, the natural graphs commonly found in the real-world have highly skewed power-law degree distributions, which challenge the assumptions made by these abstractions, limiting performance and scalability.",
        "year": 2012,
        "authors": "Joseph E Gonzalez and Yucheng Low and Haijie Gu and Danny Bickson and Carlos Guestrin"
      },
      {
        "title": "Apache spark: a unified engine for big data processing",
        "abstract": "This open source computing framework unifies streaming, batch, and interactive big data workloads to unlock new applications.",
        "year": 2016,
        "authors": "Matei Zaharia and Reynold S Xin and Patrick Wendell and Tathagata Das and Michael Armbrust and Ankur Dave and Xiangrui Meng and Josh Rosen and Shivaram Venkataraman and Michael J Franklin and Ali Ghodsi and Joseph Gonzalez and Scott Shenker and Ion Stoica"
      }
    ],
    "DZ3S--MAAAAJ": [
      {
        "title": "Gain: Missing data imputation using generative adversarial nets",
        "abstract": "We propose a novel method for imputing missing data by adapting the well-known Generative Adversarial Nets (GAN) framework. Accordingly, we call our method Generative Adversarial Imputation Nets (GAIN). The generator (G) observes some components of a real data vector, imputes the missing components conditioned on what is actually observed, and outputs a completed vector. The discriminator (D) then takes a completed vector and attempts to determine which components were actually observed and which were imputed. To ensure that D forces G to learn the desired distribution, we provide D with some additional information in the form of a hint vector. The hint reveals to D partial information about the missingness of the original sample, which is used by D to focus its attention on the imputation quality of particular components. This hint ensures that G does in fact learn to generate according to the true data distribution. We tested our method on various datasets and found that GAIN significantly outperforms state-of-the-art imputation methods.",
        "year": 2018,
        "authors": "Jinsung Yoon and James Jordon and Mihaela Schaar"
      },
      {
        "title": "Time-series generative adversarial networks",
        "abstract": "A good generative model for time-series data should preserve temporal dynamics, in the sense that new sequences respect the original relationships between variables across time. Existing methods that bring generative adversarial networks (GANs) into the sequential setting do not adequately attend to the temporal correlations unique to time-series data. At the same time, supervised models for sequence prediction-which allow finer control over network dynamics-are inherently deterministic. We propose a novel framework for generating realistic time-series data that combines the flexibility of the unsupervised paradigm with the control afforded by supervised training. Through a learned embedding space jointly optimized with both supervised and adversarial objectives, we encourage the network to adhere to the dynamics of the training data during sampling. Empirically, we evaluate the ability of our method to generate realistic samples using a variety of real and synthetic time-series datasets. Qualitatively and quantitatively, we find that the proposed framework consistently and significantly outperforms state-of-the-art benchmarks with respect to measures of similarity and predictive ability.",
        "year": 2019,
        "authors": "Jinsung Yoon and Daniel Jarrett and Mihaela Van der Schaar"
      },
      {
        "title": "PATE-GAN: Generating synthetic data with differential privacy guarantees",
        "abstract": "Machine learning has the potential to assist many communities in using the large datasets that are becoming more and more available. Unfortunately, much of that potential is not being realized because it would require sharing data in a way that compromises privacy. In this paper, we investigate a method for ensuring (differential) privacy of the generator of the Generative Adversarial Nets (GAN) framework. The resulting model can be used for generating synthetic data on which algorithms can be trained and validated, and on which competitions can be conducted, without compromising the privacy of the original dataset. Our method modifies the Private Aggregation of Teacher Ensembles (PATE) framework and applies it to GANs. Our modified framework (which we call PATE-GAN) allows us to tightly bound the influence of any individual sample on the model, resulting in tight differential privacy guarantees and thus an improved performance over models with the same guarantees. We also look at measuring the quality of synthetic data from a new angle; we assert that for the synthetic data to be useful for machine learning researchers, the relative performance of two algorithms (trained and tested) on the synthetic dataset should be the same as their relative performance (when trained and tested) on the original dataset. Our experiments, on various datasets, demonstrate that PATE-GAN consistently outperforms the state-of-the-art method with respect to this and other notions of synthetic data quality.",
        "year": 2018,
        "authors": "James Jordon and Jinsung Yoon and Mihaela Van Der Schaar"
      }
    ],
    "-5_ksIkAAAAJ": [
      {
        "title": "Quadrotor helicopter flight dynamics and control: Theory and experiment",
        "abstract": "Quadrotor helicopters are emerging as a popular platform for unmanned aerial vehicle (UAV) research, due to the simplicity of their construction and maintenance, their ability to hover, and their vertical take off and landing (VTOL) capability. Current designs have often considered only nominal operating conditions for vehicle control design. This work seeks to address issues that arise when deviating significantly from the hover flight regime. Aided by well established research for helicopter flight control, three separate aerodynamic effects are investigated as they pertain to quadrotor flight, due to vehicular velocity, angle of attack, and airframe design. They cause moments that affect attitude control, and thrust variation that affects altitude control. Where possible, a theoretical development is first presented, and is then validated through both thrust test stand measurements and vehicle flight tests using the Stanford \u2026",
        "year": 2007,
        "authors": "Gabriel Hoffmann and Haomiao Huang and Steven Waslander and Claire Tomlin"
      },
      {
        "title": "Conflict resolution for air traffic management: A study in multiagent hybrid systems",
        "abstract": "Air traffic management (ATM) of the future allows for the possibility of free flight, in which aircraft choose their own optimal routes, altitudes, and velocities. The safe resolution of trajectory conflicts between aircraft is necessary to the success of such a distributed control system. In this paper, we present a method to synthesize provably safe conflict resolution manoeuvres. The method models the aircraft and the manoeuvre as a hybrid control system and calculates the maximal set of safe initial conditions for each aircraft so that separation is assured in the presence of uncertainties in the actions of the other aircraft. Examples of manoeuvres using both speed and heading changes are worked out in detail.",
        "year": 2002,
        "authors": "Claire Tomlin and George J Pappas and Shankar Sastry"
      },
      {
        "title": "A time-dependent Hamilton-Jacobi formulation of reachable sets for continuous dynamic games",
        "abstract": "We describe and implement an algorithm for computing the set of reachable states of a continuous dynamic game. The algorithm is based on a proof that the reachable set is the zero sublevel set of the viscosity solution of a particular time-dependent Hamilton-Jacobi-Isaacs partial differential equation. While alternative techniques for computing the reachable set have been proposed, the differential game formulation allows treatment of nonlinear systems with inputs and uncertain parameters. Because the time-dependent equation's solution is continuous and defined throughout the state space, methods from the level set literature can be used to generate more accurate approximations than are possible for formulations with potentially discontinuous solutions. A numerical implementation of our formulation is described and has been released on the web. Its correctness is verified through a two vehicle, three \u2026",
        "year": 2005,
        "authors": "Ian M Mitchell and Alexandre M Bayen and Claire J Tomlin"
      }
    ],
    "Dtw3YBoAAAAJ": [
      {
        "title": "How Does Batch Normalization Help Optimization?",
        "abstract": "Batch Normalization (BatchNorm) is a widely adopted technique that enables faster and more stable training of deep neural networks (DNNs). Despite its pervasiveness, the exact reasons for BatchNorm's effectiveness are still poorly understood. The popular belief is that this effectiveness stems from controlling the change of the layers' input distributions during training to reduce the so-called\" internal covariate shift\". In this work, we demonstrate that such distributional stability of layer inputs has little to do with the success of BatchNorm. Instead, we uncover a more fundamental impact of BatchNorm on the training process: it makes the optimization landscape significantly smoother. This smoothness induces a more predictive and stable behavior of the gradients, allowing for faster training.",
        "year": 2018,
        "authors": "Shibani Santurkar and Dimitris Tsipras and Andrew Ilyas and Aleksander Madry"
      },
      {
        "title": "Adversarial examples are not bugs, they are features",
        "abstract": "Adversarial examples have attracted significant attention in machine learning, but the reasons for their existence and pervasiveness remain unclear. We demonstrate that adversarial examples can be directly attributed to the presence of non-robust features: features (derived from patterns in the data distribution) that are highly predictive, yet brittle and (thus) incomprehensible to humans. After capturing these features within a theoretical framework, we establish their widespread existence in standard datasets. Finally, we present a simple setting where we can rigorously tie the phenomena we observe in practice to a {\\em misalignment} between the (human-specified) notion of robustness and the inherent geometry of the data.",
        "year": 2019,
        "authors": "Andrew Ilyas and Shibani Santurkar and Dimitris Tsipras and Logan Engstrom and Brandon Tran and Aleksander Madry"
      },
      {
        "title": "Synthesizing robust adversarial examples",
        "abstract": "Standard methods for generating adversarial examples for neural networks do not consistently fool neural network classifiers in the physical world due to a combination of viewpoint shifts, camera noise, and other natural transformations, limiting their relevance to real-world systems. We demonstrate the existence of robust 3D adversarial objects, and we present the first algorithm for synthesizing examples that are adversarial over a chosen distribution of transformations. We synthesize two-dimensional adversarial images that are robust to noise, distortion, and affine transformation. We apply our algorithm to complex three-dimensional objects, using 3D-printing to manufacture the first physical adversarial objects. Our results demonstrate the existence of 3D adversarial objects in the physical world.",
        "year": 2017,
        "authors": "Anish Athalye and Logan Engstrom and Andrew Ilyas and Kevin Kwok"
      }
    ],
    "K3QJPdMAAAAJ": [
      {
        "title": "Fbnet: Hardware-aware efficient convnet design via differentiable neural architecture search",
        "abstract": "Designing accurate and efficient ConvNets for mobile devices is challenging because the design space is combinatorially large. Due to this, previous neural architecture search (NAS) methods are computationally expensive. ConvNet architecture optimality depends on factors such as input resolution and target devices. However, existing approaches are too resource demanding for case-by-case redesigns. Also, previous work focuses primarily on reducing FLOPs, but FLOP count does not always reflect actual latency. To address these, we propose a differentiable neural architecture search (DNAS) framework that uses gradient-based methods to optimize ConvNet architectures, avoiding enumerating and training individual architectures separately as in previous methods. FBNets (Facebook-Berkeley-Nets), a family of models discovered by DNAS surpass state-of-the-art models both designed manually and generated automatically. FBNet-B achieves 74.1% top-1 accuracy on ImageNet with 295M FLOPs and 23.1 ms latency on a Samsung S8 phone, 2.4 x smaller and 1.5 x faster than MobileNetV2-1.3 with similar accuracy. Despite higher accuracy and lower latency than MnasNet, we estimate FBNet-B's search cost is 420x smaller than MnasNet's, at only 216 GPU-hours. Searched for different resolutions and channel sizes, FBNets achieve 1.5% to 6.4% higher accuracy than MobileNetV2. The smallest FBNet achieves 50.2% accuracy and 2.9 ms latency (345 frames per second) on a Samsung S8. Over a Samsung-optimized FBNet, the iPhone-X-optimized model achieves a 1.4 x speedup on an iPhone X. FBNet models are open-sourced at \u2026",
        "year": 2019,
        "authors": "Bichen Wu and Xiaoliang Dai and Peizhao Zhang and Yanghan Wang and Fei Sun and Yiming Wu and Yuandong Tian and Peter Vajda and Yangqing Jia and Kurt Keutzer"
      },
      {
        "title": "Squeezeseg: Convolutional neural nets with recurrent crf for real-time road-object segmentation from 3d lidar point cloud",
        "abstract": "We address semantic segmentation of road-objects from 3D LiDAR point clouds. In particular, we wish to detect and categorize instances of interest, such as cars, pedestrians and cyclists. We formulate this problem as a point-wise classification problem, and propose an end-to-end pipeline called SqueezeSeg based on convolutional neural networks (CNN): the CNN takes a transformed LiDAR point cloud as input and directly outputs a point-wise label map, which is then refined by a conditional random field (CRF) implemented as a recurrent layer. Instance-level labels are then obtained by conventional clustering algorithms. Our CNN model is trained on LiDAR point clouds from the KITTI [1] dataset, and our point-wise segmentation labels are derived from 3D bounding boxes from KITTI. To obtain extra training data, we built a LiDAR simulator into Grand Theft Auto V (GTA-V), a popular video game, to synthesize \u2026",
        "year": 2018,
        "authors": "Bichen Wu and Alvin Wan and Xiangyu Yue and Kurt Keutzer"
      },
      {
        "title": "Squeezesegv2: Improved model structure and unsupervised domain adaptation for road-object segmentation from a lidar point cloud",
        "abstract": "Earlier work demonstrates the promise of deep-learning-based approaches for point cloud segmentation; however, these approaches need to be improved to be practically useful. To this end, we introduce a new model SqueezeSegV2. With an improved model structure, SqueezeSetV2 is more robust against dropout noises in LiDAR point cloud and therefore achieves significant accuracy improvement. Training models for point cloud segmentation requires large amounts of labeled data, which is expensive to obtain. To sidestep the cost of data collection and annotation, simulators such as GTA-V can be used to create unlimited amounts of labeled, synthetic data. However, due to domain shift, models trained on synthetic data often do not generalize well to the real world. Existing domain-adaptation methods mainly focus on images and most of them cannot be directly applied to point clouds. We address this \u2026",
        "year": 2019,
        "authors": "Bichen Wu and Xuanyu Zhou and Sicheng Zhao and Xiangyu Yue and Kurt Keutzer"
      }
    ],
    "opbZfw0AAAAJ": [
      {
        "title": "Locality-sensitive hashing scheme based on p-stable distributions",
        "abstract": "We present a novel Locality-Sensitive Hashing scheme for the Approximate Nearest Neighbor Problem under lp norm, based on p-stable distributions.Our scheme improves the running time of the earlier algorithm for the case of the lp norm. It also yields the first known provably efficient approximate NN algorithm for the case p<1. We also show that the algorithm finds the exact near neigbhor in O(log n) time for data satisfying certain \"bounded growth\" condition.Unlike earlier schemes, our LSH scheme works directly on points in the Euclidean space without embeddings. Consequently, the resulting query time bound is free of large factors and is simple and easy to implement. Our experiments (on synthetic data sets) show that the our data structure is up to 40 times faster than kd-tree.",
        "year": 2004,
        "authors": "Mayur Datar and Nicole Immorlica and Piotr Indyk and Vahab S Mirrokni"
      },
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien MR Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan"
      },
      {
        "title": "Maximizing non-monotone submodular functions",
        "abstract": "Submodular maximization generalizes many important problems including Max Cut in directed and undirected graphs and hypergraphs, certain constraint satisfaction problems, and maximum facility location problems. Unlike the problem of minimizing submodular functions, the problem of maximizing submodular functions is NP-hard. In this paper, we design the first constant-factor approximation algorithms for maximizing nonnegative (non-monotone) submodular functions. In particular, we give a deterministic local-search -approximation and a randomized -approximation algorithm for maximizing nonnegative submodular functions. We also show that a uniformly random set gives a -approximation. For symmetric submodular functions, we show that a random set gives a -approximation, which can also be achieved by deterministic local search. These algorithms work in the value oracle model, where the submodular function is \u2026",
        "year": 2011,
        "authors": "Uriel Feige and Vahab S Mirrokni and Jan Vondr\u00e1k"
      }
    ],
    "nTiSnwUAAAAJ": [
      {
        "title": "The Human Pangenome Project: a global resource to map genomic diversity",
        "abstract": "The human reference genome is the most widely used resource in human genetics and is due for a major update. Its current structure is a linear composite of merged haplotypes from more than 20 people, with a single individual comprising most of the sequence. It contains biases and errors within a framework that does not represent global human genomic variation. A high-quality reference with global representation of common variants, including single-nucleotide variants, structural variants and functional elements, is needed. The Human Pangenome Reference Consortium aims to create a more sophisticated and complete human reference genome with a graph-based, telomere-to-telomere representation of global genomic diversity. Here we leverage innovations in technology, study design and global partnerships with the goal of constructing the highest-possible quality human pangenome reference. Our goal \u2026",
        "year": 2022,
        "authors": "Ting Wang and Lucinda Antonacci-Fulton and Kerstin Howe and Heather A Lawson and Julian K Lucas and Adam M Phillippy and Alice B Popejoy and Mobin Asri and Caryn Carson and Mark JP Chaisson and Xian Chang and Robert Cook-Deegan and Adam L Felsenfeld and Robert S Fulton and Erik P Garrison and Nanibaa\u2019A Garrison and Tina A Graves-Lindsay and Hanlee Ji and Eimear E Kenny and Barbara A Koenig and Daofeng Li and Tobias Marschall and Joshua F McMichael and Adam M Novak and Deepak Purushotham and Valerie A Schneider and Baergen I Schultz and Michael W Smith and Heidi J Sofia and Tsachy Weissman and Paul Flicek and Heng Li and Karen H Miga and Benedict Paten and Erich D Jarvis and Ira M Hall and Evan E Eichler and David Haussler and Human Pangenome Reference Consortium"
      },
      {
        "title": "Inequalities for the L1 deviation of the empirical distribution",
        "abstract": "We derive bounds on the probability that the L1 distance between the empirical distribution of a sequence of independent identically distributed random variables and the true distribution is more than a specified value. We also derive a generalization of Pinsker\u2019s inequality relating the L1 distance to the divergence.",
        "year": 2003,
        "authors": "Tsachy Weissman and Erik Ordentlich and Gadiel Seroussi and Sergio Verdu and Marcelo J Weinberger"
      },
      {
        "title": "Minimax estimation of functionals of discrete distributions",
        "abstract": "We propose a general methodology for the construction and analysis of essentially minimax estimators for a wide class of functionals of finite dimensional parameters, and elaborate on the case of discrete distributions, where the support size S is unknown and may be comparable with or even much larger than the number of observations n. We treat the respective regions where the functional is nonsmooth and smooth separately. In the nonsmooth regime, we apply an unbiased estimator for the best polynomial approximation of the functional whereas, in the smooth regime, we apply a bias-corrected version of the maximum likelihood estimator (MLE). We illustrate the merit of this approach by thoroughly analyzing the performance of the resulting schemes for estimating two important information measures: 1) the entropy H(P) = \u03a3Si=1 -pi ln pi and 2) F\u03b1(P) = \u03a3Si=1 p\u03b1i, \u03b1 > 0. We obtain the minimax L2 rates for \u2026",
        "year": 2015,
        "authors": "Jiantao Jiao and Kartik Venkat and Yanjun Han and Tsachy Weissman"
      }
    ],
    "vfPE6hgAAAAJ": [
      {
        "title": "Model-agnostic meta-learning for fast adaptation of deep networks",
        "abstract": "We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.",
        "year": 2017,
        "authors": "Chelsea Finn and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "On the opportunities and risks of foundation models",
        "abstract": "AI is undergoing a paradigm shift with the rise of models (e.g., BERT, DALL-E, GPT-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.",
        "year": 2021,
        "authors": "Rishi Bommasani and Drew A Hudson and Ehsan Adeli and Russ Altman and Simran Arora and Sydney von Arx and Michael S Bernstein and Jeannette Bohg and Antoine Bosselut and Emma Brunskill and Erik Brynjolfsson and Shyamal Buch and Dallas Card and Rodrigo Castellon and Niladri Chatterji and Annie Chen and Kathleen Creel and Jared Quincy Davis and Dora Demszky and Chris Donahue and Moussa Doumbouya and Esin Durmus and Stefano Ermon and John Etchemendy and Kawin Ethayarajh and Li Fei-Fei and Chelsea Finn and Trevor Gale and Lauren Gillespie and Karan Goel and Noah Goodman and Shelby Grossman and Neel Guha and Tatsunori Hashimoto and Peter Henderson and John Hewitt and Daniel E Ho and Jenny Hong and Kyle Hsu and Jing Huang and Thomas Icard and Saahil Jain and Dan Jurafsky and Pratyusha Kalluri and Siddharth Karamcheti and Geoff Keeling and Fereshte Khani and Omar Khattab and Pang Wei Koh and Mark Krass and Ranjay Krishna and Rohith Kuditipudi and Ananya Kumar and Faisal Ladhak and Mina Lee and Tony Lee and Jure Leskovec and Isabelle Levent and Xiang Lisa Li and Xuechen Li and Tengyu Ma and Ali Malik and Christopher D Manning and Suvir Mirchandani and Eric Mitchell and Zanele Munyikwa and Suraj Nair and Avanika Narayan and Deepak Narayanan and Ben Newman and Allen Nie and Juan Carlos Niebles and Hamed Nilforoshan and Julian Nyarko and Giray Ogut and Laurel Orr and Isabel Papadimitriou and Joon Sung Park and Chris Piech and Eva Portelance and Christopher Potts and Aditi Raghunathan and Rob Reich and Hongyu Ren and Frieda Rong and Yusuf Roohani and Camilo Ruiz and Jack Ryan and Christopher R\u00e9 and Dorsa Sadigh and Shiori Sagawa and Keshav Santhanam and Andy Shih and Krishnan Srinivasan and Alex Tamkin and Rohan Taori and Armin W Thomas and Florian Tram\u00e8r and Rose E Wang and William Wang and Bohan Wu and Jiajun Wu and Yuhuai Wu and Sang Michael Xie and Michihiro Yasunaga and Jiaxuan You and Matei Zaharia and Michael Zhang and Tianyi Zhang and Xikun Zhang and Yuhui Zhang and Lucia Zheng and Kaitlyn Zhou and Percy Liang"
      },
      {
        "title": "End-to-end training of deep visuomotor policies",
        "abstract": "For spline regressions, it is well known that the choice of knots is crucial for the performance of the estimator. As a general learning framework covering the smoothing splines, learning in a Reproducing Kernel Hilbert Space (RKHS) has a similar issue. However, the selection of training data points for kernel functions in the RKHS representation has not been carefully studied in the literature. In this paper we study quantile regression as an example of learning in a RKHS. In this case, the regular squared norm penalty does not perform training data selection. We propose a data sparsity constraint that imposes thresholding on the kernel function coefficients to achieve a sparse kernel function representation. We demonstrate that the proposed data sparsity method can have competitive prediction performance for certain situations, and have comparable performance in other cases compared to that of the traditional squared norm penalty. Therefore, the data sparsity method can serve as a competitive alternative to the squared norm penalty method. Some theoretical properties of our proposed method using the data sparsity constraint are obtained. Both simulated and real data sets are used to demonstrate the usefulness of our data sparsity constraint.",
        "year": 2016,
        "authors": "Sergey Levine and Chelsea Finn and Trevor Darrell and Pieter Abbeel"
      }
    ],
    "8O8MQEUAAAAJ": [
      {
        "title": "Universally optimal distribution of points on spheres",
        "abstract": "We study configurations of points on the unit sphere that minimize potential energy for a broad class of potential functions (viewed as functions of the squared Euclidean distance between points). Call a configuration sharp if there are  distances between distinct points in it and it is a spherical -design. We prove that every sharp configuration minimizes potential energy for all completely monotonic potential functions. Examples include the minimal vectors of the  and Leech lattices. We also prove the same result for the vertices of the -cell, which do not form a sharp configuration. For most known cases, we prove that they are the unique global minima for energy, as long as the potential function is strictly completely monotonic. For certain potential functions, some of these configurations were previously analyzed by Yudin, Kolushov, and Andreev; we build on their techniques. We also generalize our results \u2026",
        "year": 2007,
        "authors": "Henry Cohn and Abhinav Kumar"
      },
      {
        "title": "The sphere packing problem in dimension 24",
        "abstract": "Computer code for verifying the calculations in this paper is available for download here.",
        "year": 2017,
        "authors": "Henry Cohn and Abhinav Kumar and Stephen D Miller and Danylo Radchenko and Maryna Viazovska"
      },
      {
        "title": "New upper bounds on sphere packings I",
        "abstract": "We develop an analogue for sphere packing of the linear programming bounds for error-correcting codes, and use it to prove upper bounds for the density of sphere packings, which are the best bounds known at least for dimensions 4 through 36. We conjecture that our approach can be used to solve the sphere packing problem in dimensions 8 and 24.",
        "year": 2003,
        "authors": "Henry Cohn and Noam Elkies"
      }
    ],
    "XCZpOcAAAAAJ": [
      {
        "title": "Intriguing properties of neural networks",
        "abstract": "Deep neural networks are highly expressive models that have recently achieved state of the art performance on speech and visual recognition tasks. While their expressiveness is the reason they succeed, it also causes them to learn uninterpretable solutions that could have counter-intuitive properties. In this paper we report two such properties. First, we find that there is no distinction between individual high level units and random linear combinations of high level units, according to various methods of unit analysis. It suggests that it is the space, rather than the individual units, that contains of the semantic information in the high layers of neural networks. Second, we find that deep neural networks learn input-output mappings that are fairly discontinuous to a significant extend. We can cause the network to misclassify an image by applying a certain imperceptible perturbation, which is found by maximizing the network's prediction error. In addition, the specific nature of these perturbations is not a random artifact of learning: the same perturbation can cause a different network, that was trained on a different subset of the dataset, to misclassify the same input.",
        "year": 2013,
        "authors": "Christian Szegedy and Wojciech Zaremba and Ilya Sutskever and Joan Bruna and Dumitru Erhan and Ian Goodfellow and Rob Fergus"
      },
      {
        "title": "Gpt-4 technical report",
        "abstract": "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.",
        "year": 2023,
        "authors": "Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Sim\u00f3n Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and \u0141ukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and \u0141ukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew"
      },
      {
        "title": "Improved techniques for training gans",
        "abstract": "We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: Our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.",
        "year": 2016,
        "authors": "Tim Salimans and Ian Goodfellow and Wojciech Zaremba and Vicki Cheung and Alec Radford and Xi Chen"
      }
    ],
    "LfcroyAAAAAJ": [
      {
        "title": "Recurrent neural networks for multivariate time series with missing values",
        "abstract": "Multivariate time series data in practical applications, such as health care, geoscience, and biology, are characterized by a variety of missing values. In time series prediction and other related tasks, it has been noted that missing values and their missing patterns are often correlated with the target labels, a.k.a., informative missingness. There is very limited work on exploiting the missing patterns for effective imputation and improving prediction performance. In this paper, we develop novel deep learning models, namely GRU-D, as one of the early attempts. GRU-D is based on Gated Recurrent Unit (GRU), a state-of-the-art recurrent neural network. It takes two representations of missing patterns, i.e., masking and time interval, and effectively incorporates them into a deep model architecture so that it not only captures the long-term temporal dependencies in time series, but also utilizes the missing patterns to achieve \u2026",
        "year": 2018,
        "authors": "Zhengping Che and Sanjay Purushotham and Kyunghyun Cho and David Sontag and Yan Liu"
      },
      {
        "title": "Character-aware neural language models",
        "abstract": "We describe a simple neural language model that relies only on character-level inputs. Predictions are still made at the word-level. Our model employs a convolutional neural network (CNN) and a highway net work over characters, whose output is given to a long short-term memory (LSTM) recurrent neural network language model (RNN-LM). On the English Penn Treebank the model is on par with the existing state-of-the-art despite having 60% fewer parameters. On languages with rich morphology (Arabic, Czech, French, German, Spanish, Russian), the model outperforms word-level/morpheme-level LSTM baselines, again with fewer parameters. The results suggest that on many languages, character inputs are sufficient for language modeling. Analysis of word representations obtained from the character composition part of the model reveals that the model is able to encode, from characters only, both semantic and orthographic information.",
        "year": 2016,
        "authors": "Yoon Kim and Yacine Jernite and David Sontag and Alexander M Rush"
      },
      {
        "title": "Estimating individual treatment effect: generalization bounds and algorithms",
        "abstract": "There is intense interest in applying machine learning to problems of causal inference in fields such as healthcare, economics and education. In particular, individual-level causal inference has important applications such as precision medicine. We give a new theoretical analysis and family of algorithms for predicting individual treatment effect (ITE) from observational data, under the assumption known as strong ignorability. The algorithms learn a \u201cbalanced\u201d representation such that the induced treated and control distributions look similar, and we give a novel and intuitive generalization-error bound showing the expected ITE estimation error of a representation is bounded by a sum of the standard generalization-error of that representation and the distance between the treated and control distributions induced by the representation. We use Integral Probability Metrics to measure distances between distributions, deriving explicit bounds for the Wasserstein and Maximum Mean Discrepancy (MMD) distances. Experiments on real and simulated data show the new algorithms match or outperform the state-of-the-art.",
        "year": 2017,
        "authors": "Uri Shalit and Fredrik Johansson and David Sontag"
      }
    ],
    "bh-uRFMAAAAJ": [
      {
        "title": "Fully convolutional networks for semantic segmentation",
        "abstract": "Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, exceed the state-of-the-art in semantic segmentation. Our key insight is to build\" fully convolutional\" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional network achieves state-of-the-art segmentation of PASCAL VOC (20% relative improvement to 62.2% mean IU on 2012), NYUDv2, and SIFT Flow, while inference takes less than one fifth of a second for a typical image.",
        "year": 2015,
        "authors": "Jonathan Long and Evan Shelhamer and Trevor Darrell"
      },
      {
        "title": "Rich feature hierarchies for accurate object detection and semantic segmentation",
        "abstract": "Object detection performance, as measured on the canonical PASCAL VOC dataset, has plateaued in the last few years. The best-performing methods are complex ensemble systems that typically combine multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 30% relative to the previous best result on VOC 2012---achieving a mAP of 53.3%. Our approach combines two key insights:(1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost. Since we combine region proposals with CNNs, we call our method R-CNN: Regions with CNN features. We also present experiments that provide insight into what the network learns, revealing a rich hierarchy of image features. Source code for the complete system is available at http://www. cs. berkeley. edu/~ rbg/rcnn.",
        "year": 2014,
        "authors": "Ross Girshick and Jeff Donahue and Trevor Darrell and Jitendra Malik"
      },
      {
        "title": "Caffe: Convolutional architecture for fast feature embedding",
        "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community \u2026",
        "year": 2014,
        "authors": "Yangqing Jia and Evan Shelhamer and Jeff Donahue and Sergey Karayev and Jonathan Long and Ross Girshick and Sergio Guadarrama and Trevor Darrell"
      }
    ],
    "QWzsNMDsvlIC": [
      {
        "title": "The self-avoiding walk",
        "abstract": "A self-avoiding walk is a path on a lattice that does not visit the same site more than once. In spite of this simple definition, many of the most basic questions about this model are difficult to resolve in a mathematically rigorous fashion. In particular, we do not know much about how far an n step self-avoiding walk typically travels from its starting point, or even how many such walks there are. These and other important questions about the self-avoiding walk remain unsolved in the rigorous mathematical sense, although the physics and chemistry communities have reached consensus on the answers by a variety of nonrigorous methods, including computer simulations. But there has been progress among mathematicians as well, much of it in the last decade, and the primary goal of this book is to give an account of the current state of the art as far as rigorous results are concerned. A second goal of this book is to discuss some of the applications of the self-avoiding walk in physics and chemistry, and to describe some of the nonrigorous methods used in those fields. The model originated in chem istry several decades ago as a model for long-chain polymer molecules. Since then it has become an important model in statistical physics, as it exhibits critical behaviour analogous to that occurring in the Ising model and related systems such as percolation.",
        "year": 2013,
        "authors": "Neal Madras and Gordon Slade"
      },
      {
        "title": "Mean-field critical behaviour for percolation in high dimensions",
        "abstract": "The triangle condition for percolation states that   is finite at the critical point, where \u03c4(x, y) is the probability that the sitesx andy are connected. We use an expansion related to the lace expansion for a self-avoiding walk to prove that the triangle condition is satisfied in two situations: (i) for nearest-neighbour independent bond percolation on thed-dimensional hypercubic lattice, ifd is sufficiently large, and (ii) in more than six dimensions for a class of \u201cspread-out\u201d models of independent bond percolation which are believed to be in the same universality class as the nearest-neighbour model. The class of models in (ii) includes the case where the bond occupation probability is constant for bonds of length less than some large number, and is zero otherwise. In the course of the proof an infrared bound is obtained. The triangle condition is known to imply that various critical exponents take their \u2026",
        "year": 1990,
        "authors": "Takashi Hara and Gordon Slade"
      },
      {
        "title": "Self-avoiding walk in five or more dimensions I. The critical behaviour",
        "abstract": "We use the lace expansion to study the standard self-avoiding walk in thed-dimensional hypercubic lattice, ford\u22675. We prove that the numberc n ofn-step self-avoiding walks satisfiesc  n ~A\u03bc  n , where \u03bc is the connective constant (i.e. \u03b3=1), and that the mean square displacement is asymptotically linear in the number of steps (i.e.v=1/2). A bound is obtained forc n(x), the number ofn-step self-avoiding walks ending atx. The correlation length is shown to diverge asymptotically like (\u03bc\u2212\u2212Z)1/2. The critical two-point function is shown to decay at least as fast as \u22cex\u22ce\u22122, and its Fourier transform is shown to be asymptotic to a multiple ofk \u22122 ask\u21920 (i.e. \u03b7=0). We also prove that the scaling limit is Gaussian, in the sense of convergence in distribution to Brownian motion. The infinite self-avoiding walk is constructed. In this paper we prove these results assuming convergence of the \u2026",
        "year": 1992,
        "authors": "Takashi Hara and Gordon Slade"
      }
    ],
    "VT7peyEAAAAJ": [
      {
        "title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Soft actor-critic algorithms and applications",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Reinforcement learning with deep energy-based policies",
        "abstract": "We propose a method for learning expressive energy-based policies for continuous states and actions, which has been feasible only in tabular domains before. We apply our method to learning maximum entropy policies, resulting into a new algorithm, called soft Q-learning, that expresses the optimal policy via a Boltzmann distribution. We use the recently proposed amortized Stein variational gradient descent to learn a stochastic sampling network that approximates samples from this distribution. The benefits of the proposed algorithm include improved exploration and compositionality that allows transferring skills between tasks, which we confirm in simulated experiments with swimming and walking robots. We also draw a connection to actor-critic methods, which can be viewed performing approximate inference on the corresponding energy-based model.",
        "year": 2017,
        "authors": "Tuomas Haarnoja and Haoran Tang and Pieter Abbeel and Sergey Levine"
      }
    ],
    "9xDADY4AAAAJ": [
      {
        "title": "Long-term recurrent convolutional networks for visual recognition and description",
        "abstract": "Models comprised of deep convolutional network layers have dominated recent image interpretation tasks; we investigate whether models which are also compositional, or\" deep\", temporally are effective on tasks involving visual sequences or label sequences. We develop a novel recurrent convolutional architecture suitable for large-scale visual learning which is end-to-end trainable, and demonstrate the value of these models on benchmark video recognition tasks, image to sentence generation problems, and video narration challenges. In contrast to current models which assume a fixed spatio-temporal receptive field or simple temporal averaging for sequential processing, recurrent convolutional models are\" doubly deep\" in that they can be compositional in spatial and temporal\" layers\". Such models may have advantages when target concepts are complex and/or training data are limited. Learning long-term dependencies is possible when nonlinearities are incorporated into the network state updates. Long-term RNN models are appealing in that they directly can map variable length inputs (ie video frames) to variable length outputs (ie natural language text) and can model complex temporal dynamics; yet they can be optimized with backpropagation. Our recurrent long-term models are directly connected to state-of-the-art visual convnet models and can jointly trained, updating temporal dynamics and convolutional perceptual representations simultaneously. Our results show such models have distinct advantages over state-of-the-art models for recognition or generation which are separately defined and/or optimized.",
        "year": 2015,
        "authors": "Jeffrey Donahue and Lisa Anne Hendricks and Sergio Guadarrama and Marcus Rohrbach and Subhashini Venugopalan and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Adversarial discriminative domain adaptation",
        "abstract": "Adversarial learning methods are a promising approach to training robust deep networks, and can generate complex samples across diverse domains. They can also improve recognition despite the presence of domain shift or dataset bias: recent adversarial approaches to unsupervised domain adaptation reduce the difference between the training and test domain distributions and thus improve generalization performance. However, while generative adversarial networks (GANs) show compelling visualizations, they are not optimal on discriminative tasks and can be limited to smaller shifts. On the other hand, discriminative approaches can handle larger domain shifts, but impose tied weights on the model and do not exploit a GAN-based loss. In this work, we first outline a novel generalized framework for adversarial adaptation, which subsumes recent state-of-the-art approaches as special cases, and use this generalized view to better relate prior approaches. We then propose a previously unexplored instance of our general framework which combines discriminative modeling, untied weight sharing, and a GAN loss, which we call Adversarial Discriminative Domain Adaptation (ADDA). We show that ADDA is more effective yet considerably simpler than competing domain-adversarial methods, and demonstrate the promise of our approach by exceeding state-of-the-art unsupervised adaptation results on standard domain adaptation tasks as well as a difficult cross-modality object classification task.",
        "year": 2017,
        "authors": "Eric Tzeng and Judy Hoffman and Kate Saenko and Trevor Darrell"
      },
      {
        "title": "Deep coral: Correlation alignment for deep domain adaptation",
        "abstract": "Deep neural networks are able to learn powerful representations from large quantities of labeled input data, however they cannot always generalize well across changes in input distributions. Domain adaptation algorithms have been proposed to compensate for the degradation in performance due to domain shift. In this paper, we address the case when the target domain is unlabeled, requiring unsupervised adaptation. CORAL [18] is a simple unsupervised domain adaptation method that aligns the second-order statistics of the source and target distributions with a linear transformation. Here, we extend CORAL to learn a nonlinear transformation that aligns correlations of layer activations in deep neural networks (Deep CORAL). Experiments on standard benchmark datasets show state-of-the-art performance. Our code is available at:                      https://github.com/VisionLearningGroup/CORAL \u2026",
        "year": 2016,
        "authors": "Baochen Sun and Kate Saenko"
      }
    ],
    "W8VIEZgAAAAJ": [
      {
        "title": "Faster R-CNN: Towards real-time object detection with region proposal networks",
        "abstract": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully-convolutional network that simultaneously predicts object bounds and objectness scores at each position. RPNs are trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. With a simple alternating optimization, RPN and Fast R-CNN can be trained to share convolutional features. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007 (73.2% mAP) and 2012 (70.4% mAP) using 300 proposals per image. Code is available at https://github. com/ShaoqingRen/faster_rcnn.",
        "year": 2015,
        "authors": "Shaoqing Ren and Kaiming He and Ross Girshick and Jian Sun"
      },
      {
        "title": "You only look once: Unified, real-time object detection",
        "abstract": "We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.",
        "year": 2016,
        "authors": "Joseph Redmon and Santosh Divvala and Ross Girshick and Ali Farhadi"
      },
      {
        "title": "Microsoft coco: Common objects in context",
        "abstract": "We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding. This is achieved by gathering images of complex everyday scenes containing common objects in their natural context. Objects are labeled using per-instance segmentations to aid in precise object localization. Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old. With a total of 2.5 million labeled instances in 328k images, the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection, instance spotting and instance segmentation. We present a detailed statistical analysis of the dataset in comparison to PASCAL, ImageNet, and SUN. Finally, we provide baseline performance analysis for bounding box and \u2026",
        "year": 2014,
        "authors": "Tsung-Yi Lin and Michael Maire and Serge Belongie and James Hays and Pietro Perona and Deva Ramanan and Piotr Doll\u00e1r and C Lawrence Zitnick"
      }
    ],
    "eurA6WgAAAAJ": [
      {
        "title": "Adversarial attacks on neural network policies",
        "abstract": "Machine learning classifiers are known to be vulnerable to inputs maliciously constructed by adversaries to force misclassification. Such adversarial examples have been extensively studied in the context of computer vision applications. In this work, we show adversarial attacks are also effective when targeting neural network policies in reinforcement learning. Specifically, we show existing adversarial example crafting techniques can be used to significantly degrade test-time performance of trained policies. Our threat model considers adversaries capable of introducing small perturbations to the raw input of the policy. We characterize the degree of vulnerability across tasks and training algorithms, for a subclass of adversarial-example attacks in white-box and black-box settings. Regardless of the learned task or training algorithm, we observe a significant drop in performance, even with small adversarial perturbations that do not interfere with human perception. Videos are available at http://rll.berkeley.edu/adversarial.",
        "year": 2017,
        "authors": "Sandy Huang and Nicolas Papernot and Ian Goodfellow and Yan Duan and Pieter Abbeel"
      },
      {
        "title": "Enabling robots to communicate their objectives",
        "abstract": "The overarching goal of this work is to efficiently enable end-users to correctly anticipate a robot\u2019s behavior in novel situations. And since a robot\u2019s behavior is often a direct result of its underlying objective function, our insight is that end-users need to have an accurate mental model of this objective function in order to understand and predict what the robot will do. While people naturally develop such a mental model over time through observing the robot act, this familiarization process may be lengthy. Our approach reduces this time by having the robot model how people infer objectives from observed behavior, in order to then show those behaviors that are maximally informative. We introduce two factors to define candidate models of human inference, and show that certain models indeed produce example robot behaviors that better enable users to anticipate what it will do in novel situations. Our results \u2026",
        "year": 2017,
        "authors": "Sandy H Huang and David Held and Pieter Abbeel and Anca D. Dragan"
      },
      {
        "title": "Learning agile soccer skills for a bipedal robot with deep reinforcement learning",
        "abstract": "We investigated whether deep reinforcement learning (deep RL) is able to synthesize sophisticated and safe movement skills for a low-cost, miniature humanoid robot that can be composed into complex behavioral strategies. We used deep RL to train a humanoid robot to play a simplified one-versus-one soccer game. The resulting agent exhibits robust and dynamic movement skills, such as rapid fall recovery, walking, turning, and kicking, and it transitions between them in a smooth and efficient manner. It also learned to anticipate ball movements and block opponent shots. The agent\u2019s tactical behavior adapts to specific game contexts in a way that would be impractical to manually design. Our agent was trained in simulation and transferred to real robots zero-shot. A combination of sufficiently high-frequency control, targeted dynamics randomization, and perturbations during training enabled good-quality transfer \u2026",
        "year": 2024,
        "authors": "Tuomas Haarnoja and Ben Moran and Guy Lever and Sandy H Huang and Dhruva Tirumala and Jan Humplik and Markus Wulfmeier and Saran Tunyasuvunakool and Noah Y Siegel and Roland Hafner and Michael Bloesch and Kristian Hartikainen and Arunkumar Byravan and Leonard Hasenclever and Yuval Tassa and Fereshteh Sadeghi and Nathan Batchelor and Federico Casarini and Stefano Saliceti and Charles Game and Neil Sreendra and Kushal Patel and Marlon Gwira and Andrea Huber and Nicole Hurley and Francesco Nori and Raia Hadsell and Nicolas Heess"
      }
    ],
    "odFQXSYAAAAJ": [
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien MR Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan"
      },
      {
        "title": "On the utility of learning about humans for human-AI coordination",
        "abstract": "While we would like agents that can coordinate with humans, current algorithms such as self-play and population-based training create agents that can coordinate with themselves. Agents that assume their partner to be optimal or similar to them can converge to coordination protocols that fail to understand and be understood by humans. To demonstrate this, we introduce a simple environment that requires challenging coordination, based on the popular game Overcooked, and learn a simple model that mimics human play. We evaluate the performance of agents trained via self-play and population-based training. These agents perform very well when paired with themselves, but when paired with our human model, they are significantly worse than agents designed to play with the human model. An experiment with a planning algorithm yields the same conclusion, though only when the human-aware planner is given the exact human model that it is playing with. A user study with real humans shows this pattern as well, though less strongly. Qualitatively, we find that the gains come from having the agent adapt to the human's gameplay. Given this result, we suggest several approaches for designing agents that learn about humans in order to better coordinate with them. Code is available at https://github. com/HumanCompatibleAI/overcooked_ai.",
        "year": 2019,
        "authors": "Micah Carroll and Rohin Shah and Mark K Ho and Tom Griffiths and Sanjit Seshia and Pieter Abbeel and Anca Dragan"
      },
      {
        "title": "Gemma Scope: Open Sparse Autoencoders Everywhere All At Once on Gemma 2",
        "abstract": "Sparse autoencoders (SAEs) are an unsupervised method for learning a sparse decomposition of a neural network's latent representations into seemingly interpretable features. Despite recent excitement about their potential, research applications outside of industry are limited by the high cost of training a comprehensive suite of SAEs. In this work, we introduce Gemma Scope, an open suite of JumpReLU SAEs trained on all layers and sub-layers of Gemma 2 2B and 9B and select layers of Gemma 2 27B base models. We primarily train SAEs on the Gemma 2 pre-trained models, but additionally release SAEs trained on instruction-tuned Gemma 2 9B for comparison. We evaluate the quality of each SAE on standard metrics and release these results. We hope that by releasing these SAE weights, we can help make more ambitious safety and interpretability research easier for the community. Weights and a tutorial can be found at https://huggingface.co/google/gemma-scope and an interactive demo can be found at https://www.neuronpedia.org/gemma-scope",
        "year": 2024,
        "authors": "Tom Lieberum and Senthooran Rajamanoharan and Arthur Conmy and Lewis Smith and Nicolas Sonnerat and Vikrant Varma and J\u00e1nos Kram\u00e1r and Anca Dragan and Rohin Shah and Neel Nanda"
      }
    ],
    "SqFoZNUAAAAJ": [
      {
        "title": "On the spread of viruses on the internet",
        "abstract": "We analyze the contact process on random graphs generated according to the preferential attachment scheme as a model for the spread of viruses in the Internet. We show that any virus with a positive rate of spread from a node to its neighbors has a non-vanishing chance of becoming epidemic. Quantitatively, we discover an interesting dichotomy: for a virus with effective spread rate \u03bb, if the infection starts at a typical vertex, then it develops into an epidemic with probability \u03bb\u0398 (log (1/\u03bb) log log (1/\u03bb)), but on average the epidemic probability is \u03bb\u0398 (1).",
        "year": 2005,
        "authors": "Noam Berger and Christian Borgs and Jennifer Chayes and Amin Saberi"
      },
      {
        "title": "Quenched invariance principle for simple random walk on percolation clusters",
        "abstract": "We consider the simple random walk on the (unique) infinite cluster of super-critical bond percolation in \u2124 d  with d\u22652. We prove that, for almost every percolation configuration, the path distribution of the walk converges weakly to that of non-degenerate, isotropic Brownian motion. Our analysis is based on the consideration of a harmonic deformation of the infinite cluster on which the random walk becomes a square-integrable martingale. The size of the deformation, expressed by the so called corrector, is estimated by means of ergodicity arguments.",
        "year": 2007,
        "authors": "Noam Berger and Marek Biskup"
      },
      {
        "title": "Glauber dynamics on trees and hyperbolic graphs",
        "abstract": "We study continuous time Glauber dynamics for random configurations with local constraints (e.g. proper coloring, Ising and Potts models) on finite graphs with n vertices and of bounded degree. We show that the relaxation time (defined as the reciprocal of the spectral gap |\u03bb1\u2212\u03bb2|) for the dynamics on trees and on planar hyperbolic graphs, is polynomial in n. For these hyperbolic graphs, this yields a general polynomial sampling algorithm for random configurations. We then show that for general graphs, if the relaxation time \u03c42 satisfies \u03c42=O(1), then the correlation coefficient, and the mutual information, between any local function (which depends only on the configuration in a fixed window) and the boundary conditions, decays exponentially in the distance between the window and the boundary. For the Ising model on a regular tree, this condition is sharp.",
        "year": 2005,
        "authors": "Noam Berger and Claire Kenyon and Elchanan Mossel and Yuval Peres"
      }
    ],
    "UnEHCNkAAAAJ": [
      {
        "title": "Maximizing Social Influence in Nearly Optimal Time.",
        "abstract": "Diffusion is a fundamental graph process, underpinning such phenomena as epidemic disease contagion and the spread of innovation by word-of-mouth. We address the algorithmic problem of finding a set of k initial seed nodes in a network so that the expected size of the resulting cascade is maximized, under the standard independent cascade model of network diffusion. Runtime is a primary consideration for this problem due to the massive size of the relevant input networks.We provide a fast algorithm for the influence maximization problem, obtaining the near-optimal approximation factor of , for any \u220a > 0, in time O((m + n)\u220a\u22123 log n). Our algorithm is runtime-optimal (up to a logarithmic factor) and substantially improves upon the previously best-known algorithms which run in time \u03a9(mnk \u00b7 POLY(\u220a\u22121)). Furthermore, our algorithm can be modified to allow early termination: if it is terminated after O(\u03b2(m + n) logn \u2026",
        "year": 2014,
        "authors": "Christian Borgs and Michael Brautbar and Jennifer T Chayes and Brendan Lucier"
      },
      {
        "title": "The power of local information in social networks",
        "abstract": "We study the power of local information algorithms for optimization problems on social and technological networks. We focus on sequential algorithms where the network topology is initially unknown and is revealed only within a local neighborhood of vertices that have been irrevocably added to the output set. This framework models the behavior of an external agent that does not have direct access to the network data, such as a user interacting with an online social network.We study a range of problems under this model of algorithms with local information. When the underlying graph is a preferential attachment network, we show that one can find the root (i.e. initial node) in a polylogarithmic number of steps, using a local algorithm that repeatedly queries the visible node of maximum degree. This addresses an open question of Bollob\u00e1s and Riordan. This result is motivated by its implications: we \u2026",
        "year": 2012,
        "authors": "Christian Borgs and Michael Brautbar and Jennifer Chayes and Sanjeev Khanna and Brendan Lucier"
      },
      {
        "title": "Local algorithms for finding interesting individuals in large networks",
        "abstract": "We initiate the study of local, sublinear time algorithms for finding vertices with extreme topological properties\u2014such as high degree or clustering coefficient\u2014in large social or other networks. We introduce a new model, called the Jump and Crawl model, in which algorithms are permitted only two graph operations. The Jump operation returns a randomly chosen vertex, and is meant to model the ability to discover \u201cnew\u201d vertices via keyword search in the Web, shared hobbies or interests in social networks such as Facebook, and other mechanisms that may return vertices that are distant from all those currently known. The Crawl operation permits an algorithm to explore the neighbors of any currently known vertex, and has clear analogous in many modern networks. We give both upper and lower bounds in the Jump and Crawl model for the problems of finding vertices of high degree and high clustering coefficient. We consider both arbitrary graphs, and specializations in which some common assumptions are made on the global topology (such as power law degree distributions or generation via preferential attachment). We also examine local algorithms for some related vertex or graph properties, and discuss areas for future investigation.",
        "year": 2010,
        "authors": "Michael Brautbar and Michael J Kearns"
      }
    ],
    "DcV-5RAAAAAJ": [
      {
        "title": "Network coding for distributed storage systems",
        "abstract": "Distributed storage systems provide reliable access to data through redundancy spread over individually unreliable nodes. Application scenarios include data centers, peer-to-peer storage systems, and storage in wireless networks. Storing data using an erasure code, in fragments spread across nodes, requires less redundancy than simple replication for the same level of reliability. However, since fragments must be periodically replaced as nodes fail, a key question is how to generate encoded fragments in a distributed way while transferring as little data as possible across the network. For an erasure coded system, a common practice to repair from a single node failure is for a new node to reconstruct the whole encoded data object to generate just one encoded block. We show that this procedure is sub-optimal. We introduce the notion of regenerating codes, which allow a new node to communicate  functions  of \u2026",
        "year": 2010,
        "authors": "Alexandros G Dimakis and P Brighten Godfrey and Yunnan Wu and Martin J Wainwright and Kannan Ramchandran"
      },
      {
        "title": "Byzantine-robust distributed learning: Towards optimal statistical rates",
        "abstract": "In this paper, we develop distributed optimization algorithms that are provably robust against Byzantine failures\u2014arbitrary and potentially adversarial behavior, in distributed computing systems, with a focus on achieving optimal statistical performance. A main result of this work is a sharp analysis of two robust distributed gradient descent algorithms based on median and trimmed mean operations, respectively. We prove statistical error rates for all of strongly convex, non-strongly convex, and smooth non-convex population loss functions. In particular, these algorithms are shown to achieve order-optimal statistical error rates for strongly convex losses. To achieve better communication efficiency, we further propose a median-based distributed algorithm that is provably robust, and uses only one communication round. For strongly convex quadratic loss, we show that this algorithm achieves the same optimal error rate as the robust distributed gradient descent algorithms.",
        "year": 2018,
        "authors": "Dong Yin and Yudong Chen and Ramchandran Kannan and Peter Bartlett"
      },
      {
        "title": "Distributed source coding using syndromes (DISCUS): Design and construction",
        "abstract": "We address the problem of compressing correlated distributed sources, i.e., correlated sources which are not co-located or which cannot cooperate to directly exploit their correlation. We consider the related problem of compressing a source which is correlated with another source that is available only at the decoder. This problem has been studied in the information theory literature under the name of the Slepian-Wolf (1973) source coding problem for the lossless coding case, and as \"rate-distortion with side information\" for the lossy coding case. We provide a constructive practical framework based on algebraic trellis codes dubbed as DIstributed Source Coding Using Syndromes (DISCUS), that can be applicable in a variety of settings. Simulation results are presented for source coding of independent and identically distributed (i.i.d.) Gaussian sources with side information available at the decoder in the form of a \u2026",
        "year": 2003,
        "authors": "S Sandeep Pradhan and Kannan Ramchandran"
      }
    ],
    "CgItEbQAAAAJ": [
      {
        "title": "Making ai forget you: Data deletion in machine learning",
        "abstract": "Intense recent discussions have focused on how to provide individuals with control over when their data can and cannot be used---the EU\u2019s Right To Be Forgotten regulation is an example of this effort. In this paper we initiate a framework studying what to do when it is no longer permissible to deploy models derivative from specific user data. In particular, we formulate the problem of efficiently deleting individual data points from trained machine learning models. For many standard ML models, the only way to completely remove an individual's data is to retrain the whole model from scratch on the remaining data, which is often not computationally practical. We investigate algorithmic principles that enable efficient data deletion in ML. For the specific setting of -means clustering, we propose two provably deletion efficient algorithms which achieve an average of over  improvement in deletion efficiency across 6 datasets, while producing clusters of comparable statistical quality to a canonical -means++ baseline.",
        "year": 2019,
        "authors": "Antonio Ginart and Melody Guan and Gregory Valiant and James Y Zou"
      },
      {
        "title": "What can transformers learn in-context? a case study of simple function classes",
        "abstract": "In-context learning is the ability of a model to condition on a prompt sequence consisting of in-context examples (input-output pairs corresponding to some task) along with a new query input, and generate the corresponding output. Crucially, in-context learning happens only at inference time without any parameter updates to the model. While large language models such as GPT-3 exhibit some ability to perform in-context learning, it is unclear what the relationship is between tasks on which this succeeds and what is present in the training data. To investigate this, we consider the problem of training a model to in-context learn a function class (eg, linear functions): given data derived from some functions in the class, can we train a model (eg, a Transformer) to in-context learn most functions from that class? We show empirically that standard Transformers can be trained from scratch to perform in-context learning of linear functions---that is, the trained model is able to learn unseen linear functions from in-context examples with performance comparable to the optimal least squares estimator. In fact, in-context learning is possible even under two forms of distribution shift:(i) between the training data of the Transformer and inference-time prompts, and (ii) between the in-context examples and the query input during inference. We also show that we can train Transformers to in-context learn more complex function classes: sparse linear functions where the model outperforms least squares and nearly matches the performance of Lasso, and two-layer neural networks where the model performs comparably to neural networks trained on in-context examples \u2026",
        "year": 2022,
        "authors": "Shivam Garg and Dimitris Tsipras and Percy S Liang and Gregory Valiant"
      },
      {
        "title": "Settling the polynomial learnability of mixtures of gaussians",
        "abstract": "Given data drawn from a mixture of multivariate Gaussians, a basic problem is to accurately estimate the mixture parameters. We give an algorithm for this problem that has running time and data requirements polynomial in the dimension and the inverse of the desired accuracy, with provably minimal assumptions on the Gaussians. As a simple consequence of our learning algorithm, we we give the first polynomial time algorithm for proper density estimation for mixtures of k Gaussians that needs no assumptions on the mixture. It was open whether proper density estimation was even statistically possible (with no assumptions) given only polynomially many samples, let alone whether it could be computationally efficient. The building blocks of our algorithm are based on the work (Kalai et al, STOC 2010) that gives an efficient algorithm for learning mixtures of two Gaussians by considering a series of projections down \u2026",
        "year": 2010,
        "authors": "Ankur Moitra and Gregory Valiant"
      }
    ],
    "8fztli4AAAAJ": [
      {
        "title": "Eigentaste: A constant time collaborative filtering algorithm",
        "abstract": "Eigentaste is a collaborative filtering algorithm that uses universal queries to elicit real-valued user ratings on a common set of items and applies principal component analysis (PCA) to the resulting dense subset of the ratings matrix. PCA facilitates dimensionality reduction for offline clustering of users and rapid computation of recommendations. For a database of n users, standard nearest-neighbor techniques require O(n) processing time to compute recommendations, whereas Eigentaste requires O(1) (constant) time. We compare Eigentaste to alternative algorithms using data from Jester, an online joke recommending system.Jester has collected approximately 2,500,000 ratings from 57,000 users. We use the Normalized Mean Absolute Error (NMAE) measure to compare performance of different algorithms. In the Appendix we use Uniform and Normal distribution models to derive analytic \u2026",
        "year": 2001,
        "authors": "Ken Goldberg and Theresa Roeder and Dhruv Gupta and Chris Perkins"
      },
      {
        "title": "Dex-net 2.0: Deep learning to plan robust grasps with synthetic point clouds and analytic grasp metrics",
        "abstract": "To reduce data collection time for deep learning of robust robotic grasp plans, we explore training from a synthetic dataset of 6.7 million point clouds, grasps, and analytic grasp metrics generated from thousands of 3D models from Dex-Net 1.0 in randomized poses on a table. We use the resulting dataset, Dex-Net 2.0, to train a Grasp Quality Convolutional Neural Network (GQ-CNN) model that rapidly predicts the probability of success of grasps from depth images, where grasps are specified as the planar position, angle, and depth of a gripper relative to an RGB-D sensor. Experiments with over 1,000 trials on an ABB YuMi comparing grasp planning methods on singulated objects suggest that a GQ-CNN trained with only synthetic data from Dex-Net 2.0 can be used to plan grasps in 0.8sec with a success rate of 93% on eight known objects with adversarial geometry and is 3x faster than registering point clouds to a precomputed dataset of objects and indexing grasps. The Dex-Net 2.0 grasp planner also has the highest success rate on a dataset of 10 novel rigid objects and achieves 99% precision (one false positive out of 69 grasps classified as robust) on a dataset of 40 novel household objects, some of which are articulated or deformable. Code, datasets, videos, and supplementary material are available at http://berkeleyautomation.github.io/dex-net .",
        "year": 2017,
        "authors": "Jeffrey Mahler and Jacky Liang and Sherdil Niyaz and Michael Laskey and Richard Doan and Xinyu Liu and Juan Aparicio Ojea and Ken Goldberg"
      },
      {
        "title": "RLlib: Abstractions for distributed reinforcement learning",
        "abstract": "Reinforcement learning (RL) algorithms involve the deep nesting of highly irregular computation patterns, each of which typically exhibits opportunities for distributed computation. We argue for distributing RL components in a composable way by adapting algorithms for top-down hierarchical control, thereby encapsulating parallelism and resource requirements within short-running compute tasks. We demonstrate the benefits of this principle through RLlib: a library that provides scalable software primitives for RL. These primitives enable a broad range of algorithms to be implemented with high performance, scalability, and substantial code reuse. RLlib is available as part of the open source Ray project at http://rllib. io/.",
        "year": 2018,
        "authors": "Eric Liang and Richard Liaw and Robert Nishihara and Philipp Moritz and Roy Fox and Ken Goldberg and Joseph Gonzalez and Michael Jordan and Ion Stoica"
      }
    ],
    "Vzr1RukAAAAJ": [
      {
        "title": "Multi-agent actor-critic for mixed cooperative-competitive environments",
        "abstract": "We explore deep reinforcement learning methods for multi-agent domains. We begin by analyzing the difficulty of traditional algorithms in the multi-agent case: Q-learning is challenged by an inherent non-stationarity of the environment, while policy gradient suffers from a variance that increases as the number of agents grows. We then present an adaptation of actor-critic methods that considers action policies of other agents and is able to successfully learn policies that require complex multi-agent coordination. Additionally, we introduce a training regimen utilizing an ensemble of policies for each agent that leads to more robust multi-agent policies. We show the strength of our approach compared to existing methods in cooperative as well as competitive scenarios, where agent populations are able to discover various physical and informational coordination strategies.",
        "year": 2017,
        "authors": "Ryan Lowe and Yi I Wu and Aviv Tamar and Jean Harb and OpenAI Pieter Abbeel and Igor Mordatch"
      },
      {
        "title": "Decision transformer: Reinforcement learning via sequence modeling",
        "abstract": "We introduce a framework that abstracts Reinforcement Learning (RL) as a sequence modeling problem. This allows us to draw upon the simplicity and scalability of the Transformer architecture, and associated advances in language modeling such as GPT-x and BERT. In particular, we present Decision Transformer, an architecture that casts the problem of RL as conditional sequence modeling. Unlike prior approaches to RL that fit value functions or compute policy gradients, Decision Transformer simply outputs the optimal actions by leveraging a causally masked Transformer. By conditioning an autoregressive model on the desired return (reward), past states, and actions, our Decision Transformer model can generate future actions that achieve the desired return. Despite its simplicity, Decision Transformer matches or exceeds the performance of state-of-the-art model-free offline RL baselines on Atari, OpenAI Gym, and Key-to-Door tasks.",
        "year": 2021,
        "authors": "Lili Chen and Kevin Lu and Aravind Rajeswaran and Kimin Lee and Aditya Grover and Misha Laskin and Pieter Abbeel and Aravind Srinivas and Igor Mordatch"
      },
      {
        "title": "Palm-e: An embodied multimodal language model",
        "abstract": "Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.",
        "year": 2023,
        "authors": "Danny Driess and Fei Xia and Mehdi SM Sajjadi and Corey Lynch and Aakanksha Chowdhery and Ayzaan Wahid and Jonathan Tompson and Quan Vuong and Tianhe Yu and Wenlong Huang and Yevgen Chebotar and Pierre Sermanet and Daniel Duckworth and Sergey Levine and Vincent Vanhoucke and Karol Hausman and Marc Toussaint and Klaus Greff and Andy Zeng and Igor Mordatch and Pete Florence"
      }
    ],
    "a5nY-pYAAAAJ": [
      {
        "title": "Viability Theory: New Directions",
        "abstract": "Viability theory designs and develops mathematical and algorithmic methods for investigating the adaptation to viability constraints of evolutions governed by complex systems under uncertainty that are found in many domains involving living beings, from biological evolution to economics, from environmental sciences to financial markets, from control theory and robotics to cognitive sciences. It involves interdisciplinary investigations spanning fields that have traditionally developed in isolation. The purpose of this book is to present an initiation to applications of viability theory, explaining and motivating the main concepts and illustrating them with numerous numerical examples taken from various fields.",
        "year": 2011,
        "authors": "Jean-Pierre Aubin and Alexandre Bayen and Patrick Saint-Pierre"
      },
      {
        "title": "The surprising effectiveness of ppo in cooperative multi-agent games",
        "abstract": "Proximal Policy Optimization (PPO) is a ubiquitous on-policy reinforcement learning algorithm but is significantly less utilized than off-policy learning algorithms in multi-agent settings. This is often due to the belief that PPO is significantly less sample efficient than off-policy methods in multi-agent systems. In this work, we carefully study the performance of PPO in cooperative multi-agent settings. We show that PPO-based multi-agent algorithms achieve surprisingly strong performance in four popular multi-agent testbeds: the particle-world environments, the StarCraft multi-agent challenge, the Hanabi challenge, and Google Research Football, with minimal hyperparameter tuning and without any domain-specific algorithmic modifications or architectures. Importantly, compared to competitive off-policy methods, PPO often achieves competitive or superior results in both final returns and sample efficiency. Finally, through ablation studies, we analyze implementation and hyperparameter factors that are critical to PPO's empirical performance, and give concrete practical suggestions regarding these factors. Our results show that when using these practices, simple PPO-based methods are a strong baseline in cooperative multi-agent reinforcement learning. Source code is released at https://github. com/marlbenchmark/on-policy.",
        "year": 2022,
        "authors": "Chao Yu and Akash Velu and Eugene Vinitsky and Jiaxuan Gao and Yu Wang and Alexandre Bayen and Yi Wu"
      },
      {
        "title": "A time-dependent Hamilton-Jacobi formulation of reachable sets for continuous dynamic games",
        "abstract": "We describe and implement an algorithm for computing the set of reachable states of a continuous dynamic game. The algorithm is based on a proof that the reachable set is the zero sublevel set of the viscosity solution of a particular time-dependent Hamilton-Jacobi-Isaacs partial differential equation. While alternative techniques for computing the reachable set have been proposed, the differential game formulation allows treatment of nonlinear systems with inputs and uncertain parameters. Because the time-dependent equation's solution is continuous and defined throughout the state space, methods from the level set literature can be used to generate more accurate approximations than are possible for formulations with potentially discontinuous solutions. A numerical implementation of our formulation is described and has been released on the web. Its correctness is verified through a two vehicle, three \u2026",
        "year": 2005,
        "authors": "Ian M Mitchell and Alexandre M Bayen and Claire J Tomlin"
      }
    ],
    "QXyvv94AAAAJ": [
      {
        "title": "A five-site model for liquid water and the reproduction of the density anomaly by rigid, nonpolarizable potential functions",
        "abstract": "The ability of simple potential functions to reproduce accurately the density of liquid water from 37 to 100 C at 1 to 10 000 atm has been further explored. The result is the five-site TIP5P model, which yields significantly improved results; the average error in the density over the 100 temperature range from 37.5 to 62.5 C at 1 atm is only 0.006 g cm 3. Classical Monte Carlo statistical mechanics calculations have been performed to optimize the parameters, especially the position of the negative charges along the lone-pair directions. Initial calculations with 216 molecules in the NPT ensemble at 1 atm focused on finding a model that reproduced the shape of the liquid density curve as a function of temperature. Calculations performed for 512 molecules with the final TIP5P model demonstrate that the density maximum near 4 C at 1 atm is reproduced, while high-quality structural and thermodynamic results are \u2026",
        "year": 2000,
        "authors": "Michael W Mahoney and William L Jorgensen"
      },
      {
        "title": "Community structure in large networks: Natural cluster sizes and the absence of large well-defined clusters",
        "abstract": "A large body of work has been devoted to defining and identifying clusters or communities in social and information networks, i.e., in graphs in which the nodes represent underlying social entities and the edges represent some sort of interaction between pairs of nodes. Most such research begins with the premise that a community or a cluster should be thought of as a set of nodes that has more and/or better connections between its members than to the remainder of the network. In this paper, we explore from a novel perspective several questions related to identifying meaningful communities in large social and information networks, and we come to several striking conclusions.Rather than defining a procedure to extract sets of nodes from a graph and then attempting to interpret these sets as \"real\" communities, we employ approximation algorithms for the graph-partitioning problem to characterize as a function of \u2026",
        "year": 2009,
        "authors": "Jure Leskovec and Kevin J Lang and Anirban Dasgupta and Michael W Mahoney"
      },
      {
        "title": "A survey of quantization methods for efficient neural network inference",
        "abstract": "This chapter provides approaches to the problem of quantizing the numerical values in deep Neural Network computations, covering the advantages/disadvantages of current methods. Over the past decade, people have observed significant improvements in the accuracy of Neural Networks (NNs) for a wide range of problems, often achieved by highly over-parameterized models. Achieving efficient, real-time NNs with optimal accuracy requires rethinking the design, training, and deployment of NN models. Model distillation involves training a large model and then using it as a teacher to train a more compact model. Loosely related to NN quantization is work in neuroscience that suggests that the human brain stores information in a discrete/quantized form, rather than in a continuous form. Gray and Neuhoff have written a very nice survey of the history of quantization up to 1998.",
        "year": 2022,
        "authors": "Amir Gholami and Sehoon Kim and Zhen Dong and Zhewei Yao and Michael W Mahoney and Kurt Keutzer"
      }
    ],
    "Wi25oKoAAAAJ": [
      {
        "title": "Ultralight, ultrastiff mechanical metamaterials",
        "abstract": "The mechanical properties of ordinary materials degrade substantially with reduced density because their structural elements bend under applied load. We report a class of microarchitected materials that maintain a nearly constant stiffness per unit mass density, even at ultralow density. This performance derives from a network of nearly isotropic microscale unit cells with high structural connectivity and nanoscale features, whose structural members are designed to carry loads in tension or compression. Production of these microlattices, with polymers, metals, or ceramics as constituent materials, is made possible by projection microstereolithography (an additive micromanufacturing technique) combined with nanoscale coating and postprocessing. We found that these materials exhibit ultrastiff properties across more than three orders of magnitude in density, regardless of the constituent material.",
        "year": 2014,
        "authors": "Xiaoyu Zheng and Howon Lee and Todd H Weisgraber and Maxim Shusteff and Joshua DeOtte and Eric B Duoss and Joshua D Kuntz and Monika M Biener and Qi Ge and Julie A Jackson and Sergei O Kucheyev and Nicholas X Fang and Christopher M Spadaccini"
      },
      {
        "title": "Multiscale metallic metamaterials",
        "abstract": "Materials with three-dimensional micro- and nanoarchitectures exhibit many beneficial mechanical, energy conversion and optical properties. However, these three-dimensional microarchitectures are significantly limited by their scalability. Efforts have only been successful only in demonstrating overall structure sizes of hundreds of micrometres, or contain size-scale gaps of several orders of magnitude. This results in degraded mechanical properties at the macroscale. Here we demonstrate hierarchical metamaterials with disparate three-dimensional features spanning seven orders of magnitude, from nanometres to centimetres. At the macroscale they achieve high tensile elasticity (>20%) not found in their brittle-like metallic constituents, and a near-constant specific strength. Creation of these materials is enabled by a high-resolution, large-area additive manufacturing technique with scalability not achievable by \u2026",
        "year": 2016,
        "authors": "Xiaoyu Zheng and William Smith and Julie Jackson and Bryan Moran and Huachen Cui and Da Chen and Jianchao Ye and Nicholas Fang and Nicholas Rodriguez and Todd Weisgraber and Christopher M Spadaccini"
      },
      {
        "title": "A general method to synthesize and sinter bulk ceramics in seconds",
        "abstract": "Ceramics are an important class of materials with widespread applications because of their high thermal, mechanical, and chemical stability. Computational predictions based on first principles methods can be a valuable tool in accelerating materials discovery to develop improved ceramics. It is essential to experimentally confirm the material properties of such predictions. However, materials screening rates are limited by the long processing times and the poor compositional control from volatile element loss in conventional ceramic sintering techniques. To overcome these limitations, we developed an ultrafast high-temperature sintering (UHS) process for the fabrication of ceramic materials by radiative heating under an inert atmosphere. We provide several examples of the UHS process to demonstrate its potential utility and applications, including advancements in solid-state electrolytes, multicomponent \u2026",
        "year": 2020,
        "authors": "Chengwei Wang and Weiwei Ping and Qiang Bai and Huachen Cui and Ryan Hensleigh and Ruiliu Wang and Alexandra H Brozena and Zhenpeng Xu and Jiaqi Dai and Yong Pei and Chaolun Zheng and Glenn Pastel and Jinlong Gao and Xizheng Wang and Howard Wang and Ji-Cheng Zhao and Bao Yang and Xiaoyu Zheng and Jian Luo and Yifei Mo and Bruce Dunn and Liangbing Hu"
      }
    ],
    "vN-is70AAAAJ": [
      {
        "title": "Chord: A scalable peer-to-peer lookup service for internet applications",
        "abstract": "A fundamental problem that confronts peer-to-peer applications is to efficiently locate the node that stores a particular data item. This paper presents Chord, a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data item pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis, simulations, and experiments show that Chord is scalable, with communication cost and the state maintained by each node scaling logarithmically with the number of Chord nodes.",
        "year": 2001,
        "authors": "Ion Stoica and Robert Morris and David Karger and M Frans Kaashoek and Hari Balakrishnan"
      },
      {
        "title": "A view of cloud computing",
        "abstract": "Clearing the clouds away from the true potential and obstacles posed by this computing capability.",
        "year": 2010,
        "authors": "Michael Armbrust and Armando Fox and Rean Griffith and Anthony D Joseph and Randy Katz and Andy Konwinski and Gunho Lee and David Patterson and Ariel Rabkin and Ion Stoica and Matei Zaharia"
      },
      {
        "title": "Spark: Cluster computing with working sets",
        "abstract": "MapReduce and its variants have been highly successful in implementing large-scale data-intensive applications on commodity clusters. However, most of these systems are built around an acyclic data flow model that is not suitable for other popular applications. This paper focuses on one such class of applications: those that reuse a working set of data across multiple parallel operations. This includes many iterative machine learning algorithms, as well as interactive data analysis tools. We propose a new framework called Spark that supports these applications while retaining the scalability and fault tolerance of MapReduce. To achieve these goals, Spark introduces an abstraction called resilient distributed datasets (RDDs). An RDD is a read-only collection of objects partitioned across a set of machines that can be rebuilt if a partition is lost. Spark can outperform Hadoop by 10x in iterative machine learning jobs, and can be used to interactively query a 39 GB dataset with sub-second response time.",
        "year": 2010,
        "authors": "Matei Zaharia and Mosharaf Chowdhury and Michael J Franklin and Scott Shenker and Ion Stoica"
      }
    ],
    "7OTD-LEAAAAJ": [
      {
        "title": "A ConvNet for the 2020s",
        "abstract": "The\" Roaring 20s\" of visual recognition began with the introduction of Vision Transformers (ViTs), which quickly superseded ConvNets as the state-of-the-art image classification model. A vanilla ViT, on the other hand, faces difficulties when applied to general computer vision tasks such as object detection and semantic segmentation. It is the hierarchical Transformers (eg, Swin Transformers) that reintroduced several ConvNet priors, making Transformers practically viable as a generic vision backbone and demonstrating remarkable performance on a wide variety of vision tasks. However, the effectiveness of such hybrid approaches is still largely credited to the intrinsic superiority of Transformers, rather than the inherent inductive biases of convolutions. In this work, we reexamine the design spaces and test the limits of what a pure ConvNet can achieve. We gradually\" modernize\" a standard ResNet toward the design of a vision Transformer, and discover several key components that contribute to the performance difference along the way. The outcome of this exploration is a family of pure ConvNet models dubbed ConvNeXt. Constructed entirely from standard ConvNet modules, ConvNeXts compete favorably with Transformers in terms of accuracy and scalability, achieving 87.8% ImageNet top-1 accuracy and outperforming Swin Transformers on COCO detection and ADE20K segmentation, while maintaining the simplicity and efficiency of standard ConvNets.",
        "year": 2022,
        "authors": "Zhuang Liu and Hanzi Mao and Chao-Yuan Wu and Christoph Feichtenhofer and Trevor Darrell and Saining Xie"
      },
      {
        "title": "Learning Efficient Convolutional Networks through Network Slimming",
        "abstract": "The deployment of deep convolutional neural networks (CNNs) in many real world applications is largely hindered by their high computational cost. In this paper, we propose a novel learning scheme for CNNs to simultaneously 1) reduce the model size; 2) decrease the run-time memory footprint; and 3) lower the number of computing operations, without compromising accuracy. This is achieved by enforcing channel-level sparsity in the network in a simple but effective way. Different from many existing approaches, the proposed method directly applies to modern CNN architectures, introduces minimum overhead to the training process, and requires no special software/hardware accelerators for the resulting models. We call our approach network slimming, which takes wide and large networks as input models, but during training insignificant channels are automatically identified and pruned afterwards, yielding thin and compact models with comparable accuracy. We empirically demonstrate the effectiveness of our approach with several state-of-the-art CNN models, including VGGNet, ResNet and DenseNet, on various image classification datasets. For VGGNet, a multi-pass version of network slimming gives a 20x reduction in model size and a 5x reduction in computing operations.",
        "year": 2017,
        "authors": "Zhuang Liu and Jianguo Li and Zhiqiang Shen and Gao Huang and Shoumeng Yan and Changshui Zhang"
      }
    ],
    "SaboshYAAAAJ": [
      {
        "title": "Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing",
        "abstract": "We present Resilient Distributed Datasets (RDDs), a distributed memory abstraction that lets programmers perform in-memory computations on large clusters in a fault-tolerant manner. RDDs are motivated by two types of applications that current computing frameworks handle inefficiently: iterative algorithms and interactive data mining tools. In both cases, keeping data in memory can improve performance by an order of magnitude. To achieve fault tolerance efficiently, RDDs provide a restricted form of shared memory, based on coarse-grained transformations rather than fine-grained updates to shared state. However, we show that RDDs are expressive enough to capture a wide class of computations, including recent specialized programming models for iterative jobs, such as Pregel, and new applications that these models do not capture. We have implemented RDDs in a system called Spark, which we evaluate through a variety of user applications and benchmarks.",
        "year": 2012,
        "authors": "Matei Zaharia and Mosharaf Chowdhury and Tathagata Das and Ankur Dave and Justin Ma and Murphy McCauley and Michael J Franklin and Scott Shenker and Ion Stoica"
      },
      {
        "title": "GraphX: Graph Processing in a Distributed Dataflow Framework",
        "abstract": "In pursuit of graph processing performance, the systems community has largely abandoned general-purpose distributed dataflow frameworks in favor of specialized graph processing systems that provide tailored programming abstractions and accelerate the execution of iterative graph algorithms. In this paper we argue that many of the advantages of specialized graph processing systems can be recovered in a modern general-purpose distributed dataflow system. We introduce GraphX, an embedded graph processing framework built on top of Apache Spark, a widely used distributed dataflow system. GraphX presents a familiar composable graph abstraction that is sufficient to express existing graph APIs, yet can be implemented using only a few basic dataflow operators (eg, join, map, group-by). To achieve performance parity with specialized graph systems, GraphX recasts graph-specific optimizations as distributed join optimizations and materialized view maintenance. By leveraging advances in distributed dataflow frameworks, GraphX brings low-cost fault tolerance to graph processing. We evaluate GraphX on real workloads and demonstrate that GraphX achieves an order of magnitude performance gain over the base dataflow framework and matches the performance of specialized graph processing systems while enabling a wider range of computation.",
        "year": 2014,
        "authors": "Joseph E Gonzalez and Reynold S Xin and Ankur Dave and Daniel Crankshaw and Michael J Franklin and Ion Stoica"
      },
      {
        "title": "Apache spark: a unified engine for big data processing",
        "abstract": "This open source computing framework unifies streaming, batch, and interactive big data workloads to unlock new applications.",
        "year": 2016,
        "authors": "Matei Zaharia and Reynold S Xin and Patrick Wendell and Tathagata Das and Michael Armbrust and Ankur Dave and Xiangrui Meng and Josh Rosen and Shivaram Venkataraman and Michael J Franklin and Ali Ghodsi and Joseph Gonzalez and Scott Shenker and Ion Stoica"
      }
    ],
    "62e5CygAAAAJ": [
      {
        "title": "Getting aligned on representational alignment",
        "abstract": "Biological and artificial information processing systems form representations that they can use to categorize, reason, plan, navigate, and make decisions. How can we measure the extent to which the representations formed by these diverse systems agree? Do similarities in representations then translate into similar behavior? How can a system's representations be modified to better match those of another system? These questions pertaining to the study of representational alignment are at the heart of some of the most active research areas in cognitive science, neuroscience, and machine learning. For example, cognitive scientists measure the representational alignment of multiple individuals to identify shared cognitive priors, neuroscientists align fMRI responses from multiple individuals into a shared representational space for group-level analyses, and ML researchers distill knowledge from teacher models into student models by increasing their alignment. Unfortunately, there is limited knowledge transfer between research communities interested in representational alignment, so progress in one field often ends up being rediscovered independently in another. Thus, greater cross-field communication would be advantageous. To improve communication between these fields, we propose a unifying framework that can serve as a common language between researchers studying representational alignment. We survey the literature from all three fields and demonstrate how prior work fits into this framework. Finally, we lay out open problems in representational alignment where progress can benefit all three of these fields. We hope that our work \u2026",
        "year": 2023,
        "authors": "Ilia Sucholutsky and Lukas Muttenthaler and Adrian Weller and Andi Peng and Andreea Bobu and Been Kim and Bradley C Love and Erin Grant and Iris Groen and Jascha Achterberg and Joshua B Tenenbaum and Katherine M Collins and Katherine L Hermann and Kerem Oktar and Klaus Greff and Martin N Hebart and Nori Jacoby and Qiuyi Zhang and Raja Marjieh and Robert Geirhos and Sherol Chen and Simon Kornblith and Sunayana Rane and Talia Konkle and Thomas P O'Connell and Thomas Unterthiner and Andrew K Lampinen and Klaus-Robert M\u00fcller and Mariya Toneva and Thomas L Griffiths"
      },
      {
        "title": "Adapting to continuously shifting domains",
        "abstract": "Domain adaptation typically focuses on adapting a model from a single source domain to a target domain. However, in practice, this paradigm of adapting from one source to one target is limiting, as different aspects of the real world such as illumination and weather conditions vary continuously and cannot be effectively captured by two static domains. Approaches that attempt to tackle this problem by adapting from a single source to many different target domains simultaneously are consistently unable to learn across all domain shifts. Instead, we propose an adaptation method that exploits the continuity between gradually varying domains by adapting in sequence from the source to the most similar target domain. By incrementally adapting while simultaneously efficiently regularizing against prior examples, we obtain a single strong model capable of recognition within all observed domains.",
        "year": 2018,
        "authors": "Andreea Bobu and Eric Tzeng and Judy Hoffman and Trevor Darrell"
      },
      {
        "title": "Less is more: Rethinking probabilistic models of human behavior",
        "abstract": "Robots need models of human behavior for both inferring human goals and preferences, and predicting what people will do. A common model is the Boltzmann noisily-rational decision model, which assumes people approximately optimize a reward function and choose trajectories in proportion to their exponentiated reward. While this model has been successful in a variety of robotics domains, its roots lie in econometrics, and in modeling decisions among different discrete options, each with its own utility or reward. In contrast, human trajectories lie in a continuous space, with continuous-valued features that influence the reward function. We propose that it is time to rethink the Boltzmann model, and design it from the ground up to operate over such trajectory spaces. We introduce a model that explicitly accounts for distances between trajectories, rather than only their rewards. Rather than each trajectory affecting \u2026",
        "year": 2020,
        "authors": "Andreea Bobu and Dexter RR Scobee and Jaime F Fisac and S Shankar Sastry and Anca D Dragan"
      }
    ],
    "6-e-ZBEAAAAJ": [
      {
        "title": "Language models are few-shot learners",
        "abstract": "We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.",
        "year": 2020,
        "authors": "Tom Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared D Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel Ziegler and Jeffrey Wu and Clemens Winter and Chris Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei"
      },
      {
        "title": "Language models are unsupervised multitask learners",
        "abstract": "Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called WebText. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the CoQA dataset-matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, GPT-2, is a 1.5 B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underfits WebText. Samples from the model reflect these improvements and contain coherent paragraphs of text. These findings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.",
        "year": 2019,
        "authors": "Alec Radford and Jeffrey Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever"
      },
      {
        "title": "Evaluating large language models trained on code",
        "abstract": "We introduce Codex, a GPT language model fine-tuned on publicly available code from GitHub, and study its Python code-writing capabilities. A distinct production version of Codex powers GitHub Copilot. On HumanEval, a new evaluation set we release to measure functional correctness for synthesizing programs from docstrings, our model solves 28.8% of the problems, while GPT-3 solves 0% and GPT-J solves 11.4%. Furthermore, we find that repeated sampling from the model is a surprisingly effective strategy for producing working solutions to difficult prompts. Using this method, we solve 70.2% of our problems with 100 samples per problem. Careful investigation of our model reveals its limitations, including difficulty with docstrings describing long chains of operations and with binding operations to variables. Finally, we discuss the potential broader impacts of deploying powerful code generation technologies, covering safety, security, and economics.",
        "year": 2021,
        "authors": "Mark Chen and Jerry Tworek and Heewoo Jun and Qiming Yuan and Henrique Ponde De Oliveira Pinto and Jared Kaplan and Harri Edwards and Yuri Burda and Nicholas Joseph and Greg Brockman and Alex Ray and Raul Puri and Gretchen Krueger and Michael Petrov and Heidy Khlaaf and Girish Sastry and Pamela Mishkin and Brooke Chan and Scott Gray and Nick Ryder and Mikhail Pavlov and Alethea Power and Lukasz Kaiser and Mohammad Bavarian and Clemens Winter and Philippe Tillet and Felipe Petroski Such and Dave Cummings and Matthias Plappert and Fotios Chantzis and Elizabeth Barnes and Ariel Herbert-Voss and William Hebgen Guss and Alex Nichol and Alex Paino and Nikolas Tezak and Jie Tang and Igor Babuschkin and Suchir Balaji and Shantanu Jain and William Saunders and Christopher Hesse and Andrew N Carr and Jan Leike and Josh Achiam and Vedant Misra and Evan Morikawa and Alec Radford and Matthew Knight and Miles Brundage and Mira Murati and Katie Mayer and Peter Welinder and Bob McGrew and Dario Amodei and Sam McCandlish and Ilya Sutskever and Wojciech Zaremba"
      }
    ],
    "fNOReswAAAAJ": [
      {
        "title": "Direct-coupling analysis of residue coevolution captures native contacts across many protein families",
        "abstract": "The similarity in the three-dimensional structures of homologous proteins imposes strong constraints on their sequence variability. It has long been suggested that the resulting correlations among amino acid compositions at different sequence positions can be exploited to infer spatial contacts within the tertiary protein structure. Crucial to this inference is the ability to disentangle direct and indirect correlations, as accomplished by the recently introduced direct-coupling analysis (DCA). Here we develop a computationally efficient implementation of DCA, which allows us to evaluate the accuracy of contact prediction by DCA for a large number of protein domains, based purely on sequence information. DCA is shown to yield a large number of correctly predicted contacts, recapitulating the global structure of the contact map for the majority of the protein domains examined. Furthermore, our analysis captures clear \u2026",
        "year": 2011,
        "authors": "Faruck Morcos and Andrea Pagnani and Bryan Lunt and Arianna Bertolino and Debora S Marks and Chris Sander and Riccardo Zecchina and Jos\u00e9 N Onuchic and Terence Hwa and Martin Weigt"
      },
      {
        "title": "Protein 3D structure computed from evolutionary sequence variation",
        "abstract": "The evolutionary trajectory of a protein through sequence space is constrained by its function. Collections of sequence homologs record the outcomes of millions of evolutionary experiments in which the protein evolves according to these constraints. Deciphering the evolutionary record held in these sequences and exploiting it for predictive and engineering purposes presents a formidable challenge. The potential benefit of solving this challenge is amplified by the advent of inexpensive high-throughput genomic sequencing.In this paper we ask whether we can infer evolutionary constraints from a set of sequence homologs of a protein. The challenge is to distinguish true co-evolution couplings from the noisy set of observed correlations. We address this challenge using a maximum entropy model of the protein sequence, constrained by the statistics of the multiple sequence alignment, to infer residue pair couplings. Surprisingly, we find that the strength of these inferred couplings is an excellent predictor of residue-residue proximity in folded structures. Indeed, the top-scoring residue couplings are sufficiently accurate and well-distributed to define the 3D protein fold with remarkable accuracy.We quantify this observation by computing, from sequence alone, all-atom 3D structures of fifteen test proteins from different fold classes, ranging in size from 50 to 260 residues., including a G-protein coupled receptor. These blinded inferences are de novo, i.e., they do not use homology modeling or sequence-similar fragments from known structures. The co-evolution signals provide sufficient information to determine accurate 3D protein structure to \u2026",
        "year": 2011,
        "authors": "Debora S Marks and Lucy J Colwell and Robert Sheridan and Thomas A Hopf and Andrea Pagnani and Riccardo Zecchina and Chris Sander"
      },
      {
        "title": "Analytic and algorithmic solution of random satisfiability problems",
        "abstract": "We study the satisfiability of random Boolean expressions built from many clauses with K variables per clause (K-satisfiability). Expressions with a ratio \u03b1 of clauses to variables less than a threshold \u03b1c are almost always satisfiable, whereas those with a ratio above this threshold are almost always unsatisfiable. We show the existence of an intermediate phase below \u03b1c, where the proliferation of metastable states is responsible for the onset of complexity in search algorithms. We introduce a class of optimization algorithms that can deal with these metastable states; one such algorithm has been tested successfully on the largest existing benchmark of K-satisfiability.",
        "year": 2002,
        "authors": "Marc M\u00e9zard and Giorgio Parisi and Riccardo Zecchina"
      }
    ],
    "P4nfoKYAAAAJ": [
      {
        "title": "Eigenfaces for recognition",
        "abstract": "We have developed a near-real-time computer system that can locate and track a subject's head, and then recognize the person by comparing characteristics of the face to those of known individuals. The computational approach taken in this system is motivated by both physiology and information theory, as well as by the practical requirements of near-real-time performance and accuracy. Our approach treats the face recognition problem as an intrinsically two-dimensional (2-D) recognition problem rather than requiring recovery of three-dimensional geometry, taking advantage of the fact that faces are normally upright and thus may be described by a small set of 2-D characteristic views. The system functions by projecting face images onto a feature space that spans the significant variations among known face images. The significant features are known as \"eigenfaces,\" because they are the eigenvectors (principal \u2026",
        "year": 1991,
        "authors": "Matthew Turk and Alex Pentland"
      },
      {
        "title": "Face recognition using eigenfaces.",
        "abstract": "We present an approach to thc dctcction and identification of human faces and describe a work-ig, near-real-time face recognition systen whicl\u0131 tracks a subject's head and then recognizes the person by comparing characteristics of the face to those of known individuals. Our approach treats face recognition as a two-dimensional recognition problem, taking advantage of the fact that faces are are normally upright and thus may be described by a small set of 2-D characteristic views. Face images are projected onto a feature space (\u201cface space\u201d) that bcst cncodcs the variation among known face images. The face space is defined by the \u201ceigenfaces\u201d, which are the eigenvectors of the set of faces; they do not necessarily correspond to isolated fea-tures such as eyes, ears, and noses. The framework provides the ability to learn to recognize new faces in an unsupervised manner.",
        "year": 1991,
        "authors": "Matthew A Turk and Alex Pentland"
      },
      {
        "title": "Pfinder: Real-time tracking of the human body",
        "abstract": "Pfinder is a real-time system for tracking people and interpreting their behavior. It runs at 10 Hz on a standard SGI Indy computer, and has performed reliably on thousands of people in many different physical locations. The system uses a multiclass statistical model of color and shape to obtain a 2D representation of head and hands in a wide range of viewing conditions. Pfinder has been successfully used in a wide range of applications including wireless interfaces, video databases, and low-bandwidth coding.",
        "year": 1997,
        "authors": "Christopher Richard  Wren and Ali Azarbayejani and Trevor Darrell and Alex Paul Pentland"
      }
    ],
    "CzOD0S4AAAAJ": [
      {
        "title": "Comprehensive molecular characterization of gastric adenocarcinoma",
        "abstract": "Gastric cancer is a leading cause of cancer deaths, but analysis of its molecular and clinical characteristics has been complicated by histological and aetiological heterogeneity. Here we describe a comprehensive molecular evaluation of 295 primary gastric adenocarcinomas as part of The Cancer Genome Atlas (TCGA) project. We propose a molecular classification dividing gastric cancer into four subtypes: tumours positive for Epstein\u2013Barr virus, which display recurrent PIK3CA mutations, extreme DNA hypermethylation, and amplification of JAK2, CD274 (also known as PD-L1) and PDCD1LG2 (also known as PD-L2); microsatellite unstable tumours, which show elevated mutation rates, including mutations of genes encoding targetable oncogenic signalling proteins; genomically stable tumours, which are enriched for the diffuse histological variant and mutations of RHOA or fusions involving RHO-family GTPase \u2026",
        "year": 2014,
        "authors": "Cancer Genome Atlas Research Network"
      },
      {
        "title": "Genomic classification of cutaneous melanoma",
        "abstract": "We describe the landscape of genomic alterations in cutaneous melanomas through DNA, RNA, and protein-based analysis of 333 primary and/or metastatic melanomas from 331 patients. We establish a framework for genomic classification into one of four subtypes based on the pattern of the most prevalent significantly mutated genes: mutant BRAF, mutant RAS, mutant NF1, and Triple-WT (wild-type). Integrative analysis reveals enrichment of KIT mutations and focal amplifications and complex structural rearrangements as a feature of the Triple-WT subtype. We found no significant outcome correlation with genomic classification, but samples assigned a transcriptomic subclass enriched for immune gene expression associated with lymphocyte infiltrate on pathology review and high LCK protein expression, a T cell marker, were associated with improved patient survival. This clinicopathological and multi \u2026",
        "year": 2015,
        "authors": "Rehan Akbani and Kadir C Akdemir and B Arman Aksoy and Monique Albert and Adrian Ally and Samirkumar B Amin and Harindra Arachchi and Arshi Arora and J Todd Auman and Brenda Ayala and Julien Baboud and Miruna Balasundaram and Saianand Balu and Nandita Barnabas and John Bartlett and Pam Bartlett and Boris C Bastian and Stephen B Baylin and Madhusmita Behera and Dmitry Belyaev and Christopher Benz and Brady Bernard and Rameen Beroukhim and Natalie Bir and Aaron D Black and Tom Bodenheimer and Lori Boice and Genevieve M Boland and Riccardo Bono and Moiz S Bootwalla and Marcus Bosenberg and Jay Bowen and Reanne Bowlby and Christopher A Bristow and Laura Brockway-Lunardi and Denise Brooks and Jakub Brzezinski and Wiam Bshara and Elizabeth Buda and William R Burns and Yaron SN Butterfield and Michael Button and Tiffany Calderone and Giancarlo Antonini Cappellini and Candace Carter and Scott L Carter and Lynn Cherney and Andrew D Cherniack and Aaron Chevalier and Lynda Chin and Juok Cho and Raymond J Cho and Yoon-La Choi and Andy Chu and Sudha Chudamani and Kristian Cibulskis and Giovanni Ciriello and Amanda Clarke and Stephen Coons and Leslie Cope and Daniel Crain and Erin Curley and Ludmila Danilova and Stefania D\u2019Atri and Tanja Davidsen and Michael A Davies and Keith A Delman and John A Demchok and Qixia A Deng and Yonathan Lissanu Deribe and Noreen Dhalla and Rajiv Dhir and Daniel DiCara and Michael Dinikin and Michael Dubina and J Stephen Ebrom and Sophie Egea and Greg Eley and Jay Engel and Jennifer M Eschbacher and Konstantin V Fedosenko and Ina Felau and Timothy Fennell and Martin L Ferguson and Sheila Fisher and Keith T Flaherty and Scott Frazer and Jessica Frick and Victoria Fulidou and Stacey B Gabriel and Jianjiong Gao and Johanna Gardner and Levi A Garraway and Julie M Gastier-Foster and Carmelo Gaudioso and Nils Gehlenborg and Giannicola Genovese and Mark Gerken and Jeffrey E Gershenwald and Gad Getz and Carmen Gomez-Fernandez and Thomas Gribbin and Jonna Grimsby and Benjamin Gross and Ranabir Guin and Tony Gutschner and Angela Hadjipanayis and Ruth Halaban and Benjamin Hanf and David Haussler and Lauren E Haydu and D Neil Hayes and Nicholas K Hayward and David I Heiman and Lynn Herbert and James G Herman and Peter Hersey and Katherine A Hoadley and Eran Hodis and Robert A Holt and Dave SB Hoon and Susan Hoppough and Alan P Hoyle and Franklin W Huang and Mei Huang and Sharon Huang and Carolyn M Hutter and Matthew Ibbs and Lisa Iype and Anders Jacobsen and Valerie Jakrot and Alyssa Janning and William R Jeck and Stuart R Jefferys and Mark A Jensen and Corbin D Jones and Steven JM Jones and Zhenlin Ju and Hojabr Kakavand and Hyojin Kang and Richard F Kefford and Fadlo R Khuri and Jaegil Kim and John M Kirkwood and Joachim Klode and Anil Korkut and Konstanty Korski and Michael Krauthammer and Raju Kucherlapati and Lawrence N Kwong"
      },
      {
        "title": "Integrated genomic characterization of papillary thyroid carcinoma",
        "abstract": "Papillary thyroid carcinoma (PTC) is the most common type of thyroid cancer. Here, we describe the genomic landscape of 496 PTCs. We observed a low frequency of somatic alterations (relative to other carcinomas) and extended the set of known PTC driver alterations to include EIF1AX, PPM1D, and CHEK2 and diverse gene fusions. These discoveries reduced the fraction of PTC cases with unknown oncogenic driver from 25% to 3.5%. Combined analyses of genomic variants, gene expression, and methylation demonstrated that different driver groups lead to different pathologies with distinct signaling and differentiation characteristics. Similarly, we identified distinct molecular subgroups of BRAF-mutant tumors, and multidimensional analyses highlighted a potential involvement of oncomiRs in less-differentiated subgroups. Our results propose a reclassification of thyroid cancers into molecular subtypes that \u2026",
        "year": 2014,
        "authors": "Nishant Agrawal and Rehan Akbani and B Arman Aksoy and Adrian Ally and Harindra Arachchi and Sylvia L Asa and J Todd Auman and Miruna Balasundaram and Saianand Balu and Stephen B Baylin and Madhusmita Behera and Brady Bernard and Rameen Beroukhim and Justin A Bishop and Aaron D Black and Tom Bodenheimer and Lori Boice and Moiz S Bootwalla and Jay Bowen and Reanne Bowlby and Christopher A Bristow and Robin Brookens and Denise Brooks and Robert Bryant and Elizabeth Buda and Yaron SN Butterfield and Tobias Carling and Rebecca Carlsen and Scott L Carter and Sally E Carty and Timothy A Chan and Amy Y Chen and Andrew D Cherniack and Dorothy Cheung and Lynda Chin and Juok Cho and Andy Chu and Eric Chuah and Kristian Cibulskis and Giovanni Ciriello and Amanda Clarke and Gary L Clayman and Leslie Cope and John A Copland and Kyle Covington and Ludmila Danilova and Tanja Davidsen and John A Demchok and Daniel DiCara and Noreen Dhalla and Rajiv Dhir and Sheliann S Dookran and Gideon Dresdner and Jonathan Eldridge and Greg Eley and Adel K El-Naggar and Stephanie Eng and James A Fagin and Timothy Fennell and Robert L Ferris and Sheila Fisher and Scott Frazer and Jessica Frick and Stacey B Gabriel and Ian Ganly and Jianjiong Gao and Levi A Garraway and Julie M Gastier-Foster and Gad Getz and Nils Gehlenborg and Ronald Ghossein and Richard A Gibbs and Thomas J Giordano and Karen Gomez-Hernandez and Jonna Grimsby and Benjamin Gross and Ranabir Guin and Angela Hadjipanayis and Hollie A Harper and D Neil Hayes and David I Heiman and James G Herman and Katherine A Hoadley and Matan Hofree and Robert A Holt and Alan P Hoyle and Franklin W Huang and Mei Huang and Carolyn M Hutter and Trey Ideker and Lisa Iype and Anders Jacobsen and Stuart R Jefferys and Corbin D Jones and Steven JM Jones and Katayoon Kasaian and Electron Kebebew and Fadlo R Khuri and Jaegil Kim and Roger Kramer and Richard Kreisberg and Raju Kucherlapati and David J Kwiatkowski and Marc Ladanyi and Phillip H Lai and Peter W Laird and Eric Lander and Michael S Lawrence and Darlene Lee and Eunjung Lee and Semin Lee and William Lee and Kristen M Leraas and Tara M Lichtenberg and Lee Lichtenstein and Pei Lin and Shiyun Ling and Jinze Liu and Wenbin Liu and Yingchun Liu and Virginia A LiVolsi and Yiling Lu and Yussanne Ma and Harshad S Mahadeshwar and Marco A Marra and Michael Mayo and David G McFadden and Shaowu Meng and Matthew Meyerson and Piotr A Mieczkowski and Michael Miller and Gordon Mills and Richard A Moore and Lisle E Mose and Andrew J Mungall and Bradley A Murray and Yuri E Nikiforov and Michael S Noble and Akinyemi I Ojesina and Taofeek K Owonikoko and Bradley A Ozenberger and Angeliki Pantazi and Michael Parfenov and Peter J Park and Joel S Parker and Evan O Paull and Chandra Sekhar Pedamallu and Charles M Perou and Jan F Prins and Alexei Protopopov"
      }
    ],
    "_1hCq3UAAAAJ": [
      {
        "title": "Locality-sensitive hashing scheme based on p-stable distributions",
        "abstract": "We present a novel Locality-Sensitive Hashing scheme for the Approximate Nearest Neighbor Problem under lp norm, based on p-stable distributions.Our scheme improves the running time of the earlier algorithm for the case of the lp norm. It also yields the first known provably efficient approximate NN algorithm for the case p<1. We also show that the algorithm finds the exact near neigbhor in O(log n) time for data satisfying certain \"bounded growth\" condition.Unlike earlier schemes, our LSH scheme works directly on points in the Euclidean space without embeddings. Consequently, the resulting query time bound is free of large factors and is simple and easy to implement. Our experiments (on synthetic data sets) show that the our data structure is up to 40 times faster than kd-tree.",
        "year": 2004,
        "authors": "Mayur Datar and Nicole Immorlica and Piotr Indyk and Vahab S Mirrokni"
      },
      {
        "title": "Correlation clustering in general weighted graphs",
        "abstract": "We consider the following general correlation-clustering problem [N. Bansal, A. Blum, S. Chawla, Correlation clustering, in: Proc. 43rd Annu. IEEE Symp. on Foundations of Computer Science, Vancouver, Canada, November 2002, pp. 238\u2013250]: given a graph with real nonnegative edge weights and a \u2329+\u232a/\u2329-\u232a edge labelling, partition the vertices into clusters to minimize the total weight of cut \u2329+\u232a edges and uncut \u2329-\u232a edges. Thus, \u2329+\u232a edges with large weights (representing strong correlations between endpoints) encourage those endpoints to belong to a common cluster while \u2329-\u232a edges with large weights encourage the endpoints to belong to different clusters. In contrast to most clustering problems, correlation clustering specifies neither the desired number of clusters nor a distance threshold for clustering; both of these parameters are effectively chosen to be the best possible by the problem definition \u2026",
        "year": 2006,
        "authors": "Erik D Demaine and Dotan Emanuel and Amos Fiat and Nicole Immorlica"
      },
      {
        "title": "Decoupled classifiers for group-fair and efficient machine learning",
        "abstract": "When it is ethical and legal to use a sensitive attribute (such as gender or race) in machine learning systems, the question remains how to do so. We show that the naive application of machine learning algorithms using sensitive attributes leads to an inherent tradeoff in accuracy between groups. We provide a simple and efficient decoupling technique, that can be added on top of any black-box machine learning algorithm, to learn different classifiers for different groups. Transfer learning is used to mitigate the problem of having too little data on any one group.",
        "year": 2018,
        "authors": "Cynthia Dwork and Nicole Immorlica and Adam Tauman Kalai and Max Leiserson"
      }
    ],
    "mnU3HpcAAAAJ": [
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien MR Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan"
      },
      {
        "title": "Ethnic and regional variations in hospital mortality from COVID-19 in Brazil: a cross-sectional observational study",
        "abstract": "Brazil ranks second worldwide in total number of COVID-19 cases and deaths. Understanding the possible socioeconomic and ethnic health inequities is particularly important given the diverse population and fragile political and economic situation. We aimed to characterise the COVID-19 pandemic in Brazil and assess variations in mortality according to region, ethnicity, comorbidities, and symptoms.We conducted a cross-sectional observational study of COVID-19 hospital mortality using data from the SIVEP-Gripe (Sistema de Informa\u00e7\u00e3o de Vigil\u00e2ncia Epidemiol\u00f3gica da Gripe) dataset to characterise the COVID-19 pandemic in Brazil. In the study, we included hospitalised patients who had a positive RT-PCR test for severe acute respiratory syndrome coronavirus 2 and who had ethnicity information in the dataset. Ethnicity of participants was classified according to the five categories used by \u2026",
        "year": 2020,
        "authors": "Pedro Baqui* and Ioana Bica* and Valerio Marra and Ari Ercole and Mihaela van Der Schaar"
      },
      {
        "title": "From real\u2010world patient data to individualized treatment effects using machine learning: current and future methods to address underlying challenges",
        "abstract": "Clinical decision making needs to be supported by evidence that treatments are beneficial to individual patients. Although randomized control trials (RCTs) are the gold standard for testing and introducing new drugs, due to the focus on specific questions with respect to establishing efficacy and safety vs. standard treatment, they do not provide a full characterization of the heterogeneity in the final intended treatment population. Conversely, real\u2010world observational data, such as electronic health records (EHRs), contain large amounts of clinical information about heterogeneous patients and their response to treatments. In this paper, we introduce the main opportunities and challenges in using observational data for training machine learning methods to estimate individualized treatment effects and make treatment recommendations. We describe the modeling choices of the state\u2010of\u2010the\u2010art machine learning \u2026",
        "year": 2021,
        "authors": "Ioana Bica and Ahmed M Alaa and Craig Lambert and Mihaela Van Der Schaar"
      }
    ],
    "ID9QePIAAAAJ": [
      {
        "title": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size",
        "abstract": "Recent research on deep neural networks has focused primarily on improving accuracy. For a given accuracy level, it is typically possible to identify multiple DNN architectures that achieve that accuracy level. With equivalent accuracy, smaller DNN architectures offer at least three advantages: (1) Smaller DNNs require less communication across servers during distributed training. (2) Smaller DNNs require less bandwidth to export a new model from the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on FPGAs and other hardware with limited memory. To provide all of these advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters. Additionally, with model compression techniques we are able to compress SqueezeNet to less than 0.5MB (510x smaller than AlexNet). The SqueezeNet architecture is available for download here: https://github.com/DeepScale/SqueezeNet",
        "year": 2016,
        "authors": "Forrest N Iandola and Song Han and Matthew W Moskewicz and Khalid Ashraf and William J Dally and Kurt Keutzer"
      },
      {
        "title": "The landscape of parallel computing research: A view from berkeley",
        "abstract": "The recent switch to parallel microprocessors is a milestone in the history of computing. Industry has laid out a roadmap for multicore designs that preserves the programming paradigm of the past via binary compatibility and cache coherence. Conventional wisdom is now to double the number of cores on a chip with each silicon generation. A multidisciplinary group of Berkeley researchers met nearly two years to discuss this change. Our view is that this evolutionary approach to parallel hardware and software may work from 2 or 8 processor systems, but is likely to face diminishing returns as 16 and 32 processor systems are realized, just as returns fell with greater instruction-level parallelism. We believe that much can be learned by examining the success of parallelism at the extremes of the computing spectrum, namely embedded computing and high performance computing. This led us to frame the parallel landscape with seven questions, and to recommend the following: \u2022 The overarching goal should be to make it easy to write programs that execute efficiently on highly parallel computing systems \u2022 The target should be 1000s of cores per chip, as these chips are built from processing elements that are the most efficient in MIPS (Million Instructions per Second) per watt, MIPS per area of silicon, and MIPS per development dollar. \u2022 Instead of traditional benchmarks, use 13 \u201cDwarfs\u201d to design and evaluate parallel programming models and architectures. (A dwarf is an algorithmic method that captures a pattern of computation and communication.) \u2022 \u201cAutotuners\u201d should play a larger role than conventional compilers in translating parallel programs \u2026",
        "year": 2006,
        "authors": "Krste Asanovic and Ras Bodik and Bryan Catanzaro and Joseph Gebis and Parry Husbands and Kurt Keutzer and David Patterson and William Plishker and John Shalf and Samuel Webb Williams"
      },
      {
        "title": "Identifying the best machine learning algorithms for brain tumor segmentation, progression assessment, and overall survival prediction in the BRATS challenge",
        "abstract": "Gliomas are the most common primary brain malignancies, with different degrees of aggressiveness, variable prognosis and various heterogeneous histologic sub-regions, i.e., peritumoral edematous/invaded tissue, necrotic core, active and non-enhancing core. This intrinsic heterogeneity is also portrayed in their radio-phenotype, as their sub-regions are depicted by varying intensity profiles disseminated across multi-parametric magnetic resonance imaging (mpMRI) scans, reflecting varying biological properties. Their heterogeneous shape, extent, and location are some of the factors that make these tumors difficult to resect, and in some cases inoperable. The amount of resected tumor is a factor also considered in longitudinal scans, when evaluating the apparent tumor for potential diagnosis of progression. Furthermore, there is mounting evidence that accurate segmentation of the various tumor sub-regions can offer the basis for quantitative image analysis towards prediction of patient overall survival. This study assesses the state-of-the-art machine learning (ML) methods used for brain tumor image analysis in mpMRI scans, during the last seven instances of the International Brain Tumor Segmentation (BraTS) challenge, i.e., 2012-2018. Specifically, we focus on i) evaluating segmentations of the various glioma sub-regions in pre-operative mpMRI scans, ii) assessing potential tumor progression by virtue of longitudinal growth of tumor sub-regions, beyond use of the RECIST/RANO criteria, and iii) predicting the overall survival from pre-operative mpMRI scans of patients that underwent gross total resection. Finally, we investigate the \u2026",
        "year": 2018,
        "authors": "Spyridon Bakas and Mauricio Reyes and Andras Jakab and Stefan Bauer and Markus Rempfler and Alessandro Crimi and Russell Takeshi Shinohara and Christoph Berger and Sung Min Ha and Martin Rozycki and Marcel Prastawa and Esther Alberts and Jana Lipkova and John Freymann and Justin Kirby and Michel Bilello and Hassan Fathallah-Shaykh and Roland Wiest and Jan Kirschke and Benedikt Wiestler and Rivka Colen and Aikaterini Kotrotsou and Pamela Lamontagne and Daniel Marcus and Mikhail Milchenko and Arash Nazeri and Marc-Andre Weber and Abhishek Mahajan and Ujjwal Baid and Elizabeth Gerstner and Dongjin Kwon and Gagan Acharya and Manu Agarwal and Mahbubul Alam and Alberto Albiol and Antonio Albiol and Francisco J Albiol and Varghese Alex and Nigel Allinson and Pedro HA Amorim and Abhijit Amrutkar and Ganesh Anand and Simon Andermatt and Tal Arbel and Pablo Arbelaez and Aaron Avery and Muneeza Azmat and W Bai and Subhashis Banerjee and Bill Barth and Thomas Batchelder and Kayhan Batmanghelich and Enzo Battistella and Andrew Beers and Mikhail Belyaev and Martin Bendszus and Eze Benson and Jose Bernal and Halandur Nagaraja Bharath and George Biros and Sotirios Bisdas and James Brown and Mariano Cabezas and Shilei Cao and Jorge M Cardoso and Eric N Carver and Adri\u00e0 Casamitjana and Laura Silvana Castillo and Marcel Cat\u00e0 and Philippe Cattin and Albert Cerigues and Vinicius S Chagas and Siddhartha Chandra and Yi-Ju Chang and Shiyu Chang and Ken Chang and Joseph Chazalon and Shengcong Chen and Wei Chen and Jefferson W Chen and Zhaolin Chen and Kun Cheng and Ahana Roy Choudhury and Roger Chylla and Albert Cl\u00e9rigues and Steven Colleman and Ramiro German Rodriguez Colmeiro and Marc Combalia and Anthony Costa and Xiaomeng Cui and Zhenzhen Dai and Lutao Dai and Laura Alexandra Daza and Eric Deutsch and Changxing Ding and Chao Dong and Shidu Dong and Wojciech Dudzik and Zach Eaton-Rosen and Gary Egan and Guilherme Escudero and Th\u00e9o Estienne and Richard Everson and Jonathan Fabrizio and Yong Fan and Longwei Fang and Xue Feng and Enzo Ferrante and Lucas Fidon and Martin Fischer and Andrew P French and Naomi Fridman and Huan Fu and David Fuentes and Yaozong Gao and Evan Gates and David Gering and Amir Gholami and Willi Gierke and Ben Glocker and Mingming Gong and Sandra Gonz\u00e1lez-Vill\u00e1 and T Grosges and Yuanfang Guan and Sheng Guo and Sudeep Gupta and Woo-Sup Han and Il Song Han and Konstantin Harmuth and Huiguang He and Aura Hern\u00e1ndez-Sabat\u00e9 and Evelyn Herrmann and Naveen Himthani and Winston Hsu and Cheyu Hsu and Xiaojun Hu and Xiaobin Hu and Yan Hu and Yifan Hu and Rui Hua and Teng-Yi Huang and Weilin Huang and Sabine Van Huffel and Quan Huo and Vivek HV and Khan M Iftekharuddin and Fabian Isensee and Mobarakol Islam and Aaron S Jackson and Sachin R Jambawalikar"
      }
    ],
    "iVLAQysAAAAJ": [
      {
        "title": "Denoising diffusion probabilistic models",
        "abstract": "We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.",
        "year": 2020,
        "authors": "Jonathan Ho and Ajay Jain and Pieter Abbeel"
      },
      {
        "title": "Photorealistic text-to-image diffusion models with deep language understanding",
        "abstract": "We present Imagen, a text-to-image diffusion model with an unprecedented degree of photorealism and a deep level of language understanding. Imagen builds on the power of large transformer language models in understanding text and hinges on the strength of diffusion models in high-fidelity image generation. Our key discovery is that generic large language models (eg, T5), pretrained on text-only corpora, are surprisingly effective at encoding text for image synthesis: increasing the size of the language model in Imagen boosts both sample fidelity and image-text alignment much more than increasing the size of the image diffusion model. Imagen achieves a new state-of-the-art FID score of 7.27 on the COCO dataset, without ever training on COCO, and human raters find Imagen samples to be on par with the COCO data itself in image-text alignment. To assess text-to-image models in greater depth, we introduce DrawBench, a comprehensive and challenging benchmark for text-to-image models. With DrawBench, we compare Imagen with recent methods including VQ-GAN+ CLIP, Latent Diffusion Models, and DALL-E 2, and find that human raters prefer Imagen over other models in side-by-side comparisons, both in terms of sample quality and image-text alignment.",
        "year": 2022,
        "authors": "Chitwan Saharia and William Chan and Saurabh Saxena and Lala Li and Jay Whang and Emily L Denton and Kamyar Ghasemipour and Raphael Gontijo Lopes and Burcu Karagol Ayan and Tim Salimans and Jonathan Ho and David J Fleet and Mohammad Norouzi"
      },
      {
        "title": "Classifier-free diffusion guidance",
        "abstract": "Classifier guidance is a recently introduced method to trade off mode coverage and sample fidelity in conditional diffusion models post training, in the same spirit as low temperature sampling or truncation in other types of generative models. Classifier guidance combines the score estimate of a diffusion model with the gradient of an image classifier and thereby requires training an image classifier separate from the diffusion model. It also raises the question of whether guidance can be performed without a classifier. We show that guidance can be indeed performed by a pure generative model without such a classifier: in what we call classifier-free guidance, we jointly train a conditional and an unconditional diffusion model, and we combine the resulting conditional and unconditional score estimates to attain a trade-off between sample quality and diversity similar to that obtained using classifier guidance.",
        "year": 2022,
        "authors": "Jonathan Ho and Tim Salimans"
      }
    ],
    "PS-TM94AAAAJ": [
      {
        "title": "The dynamics of message passing on dense graphs, with applications to compressed sensing",
        "abstract": "\u201cApproximate message passing\u201d (AMP) algorithms have proved to be effective in reconstructing sparse signals from a small number of incoherent linear measurements. Extensive numerical experiments further showed that their dynamics is accurately tracked by a simple one-dimensional iteration termed state evolution. In this paper, we provide rigorous foundation to state evolution. We prove that indeed it holds asymptotically in the large system limit for sensing matrices with independent and identically distributed Gaussian entries. While our focus is on message passing algorithms for compressed sensing, the analysis extends beyond this setting, to a general class of algorithms on dense graphs. In this context, state evolution plays the role that density evolution has for sparse graphs. The proof technique is fundamentally different from the standard approach to density evolution, in that it copes with a large number \u2026",
        "year": 2011,
        "authors": "Mohsen Bayati and Andrea Montanari"
      },
      {
        "title": "Matrix completion methods for causal panel data models",
        "abstract": "In this article, we study methods for estimating causal effects in settings with panel data, where some units are exposed to a treatment during some periods and the goal is estimating counterfactual (untreated) outcomes for the treated unit/period combinations. We propose a class of matrix completion estimators that uses the observed elements of the matrix of control outcomes corresponding to untreated unit/periods to impute the \u201cmissing\u201d elements of the control outcome matrix, corresponding to treated units/periods. This leads to a matrix that well-approximates the original (incomplete) matrix, but has lower complexity according to the nuclear norm for matrices. We generalize results from the matrix completion literature by allowing the patterns of missing data to have a time series dependency structure that is common in social science applications. We present novel insights concerning the connections between the \u2026",
        "year": 2021,
        "authors": "Susan Athey and Mohsen Bayati and Nikolay Doudchenko and Guido Imbens and Khashayar Khosravi"
      },
      {
        "title": "Online decision making with high-dimensional covariates",
        "abstract": "Big data have enabled decision makers to tailor decisions at the individual level in a variety of domains, such as personalized medicine and online advertising. Doing so involves learning a model of decision rewards conditional on individual-specific covariates. In many practical settings, these covariates are high dimensional; however, typically only a small subset of the observed features are predictive of a decision\u2019s success. We formulate this problem as a K-armed contextual bandit with high-dimensional covariates and present a new efficient bandit algorithm based on the LASSO estimator. We prove that our algorithm\u2019s cumulative expected regret scales at most polylogarithmically in the covariate dimension d; to the best of our knowledge, this is the first such bound for a contextual bandit. The key step in our analysis is proving a new tail inequality that guarantees the convergence of the LASSO estimator despite \u2026",
        "year": 2020,
        "authors": "Hamsa Bastani and Mohsen Bayati"
      }
    ],
    "vtwH6GkAAAAJ": [
      {
        "title": "Denoising diffusion probabilistic models",
        "abstract": "We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN.",
        "year": 2020,
        "authors": "Jonathan Ho and Ajay Jain and Pieter Abbeel"
      },
      {
        "title": "Model-agnostic meta-learning for fast adaptation of deep networks",
        "abstract": "We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.",
        "year": 2017,
        "authors": "Chelsea Finn and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine"
      }
    ],
    "LUe32ToAAAAJ": [
      {
        "title": "Learning robot objectives from physical human interaction",
        "abstract": "When humans and robots work in close proximity, physical interaction is inevitable. Traditionally, robots treat physical interaction as a disturbance, and resume their original behavior after the interaction ends. In contrast, we argue that physical human interaction is informative: it is useful information about how the robot should be doing its task. We formalize learning from such interactions as a dynamical system in which the task objective has parameters that are part of the hidden state, and physical human interactions are observations about these parameters. We derive an online approximation of the robot\u2019s optimal policy in this system, and test it in a user study. The results suggest that learning from physical interaction leads to better robot task performance with less human effort.",
        "year": 2017,
        "authors": "Andrea Bajcsy and Dylan P Losey and Marcia K O\u2019malley and Anca D Dragan"
      },
      {
        "title": "Probabilistically safe robot planning with confidence-based human predictions",
        "abstract": "In order to safely operate around humans, robots can employ predictive models of human motion. Unfortunately, these models cannot capture the full complexity of human behavior and necessarily introduce simplifying assumptions. As a result, predictions may degrade whenever the observed human behavior departs from the assumed structure, which can have negative implications for safety. In this paper, we observe that how \"rational\" human actions appear under a particular model can be viewed as an indicator of that model's ability to describe the human's current motion. By reasoning about this model confidence in a real-time Bayesian framework, we show that the robot can very quickly modulate its predictions to become more uncertain when the model performs poorly. Building on recent work in provably-safe trajectory planning, we leverage these confidence-aware human motion predictions to generate assured autonomous robot motion. Our new analysis combines worst-case tracking error guarantees for the physical robot with probabilistic time-varying human predictions, yielding a quantitative, probabilistic safety certificate. We demonstrate our approach with a quadcopter navigating around a human.",
        "year": 2018,
        "authors": "Jaime F Fisac and Andrea Bajcsy and Sylvia L Herbert and David Fridovich-Keil and Steven Wang and Claire J Tomlin and Anca D Dragan"
      },
      {
        "title": "Confidence-aware motion prediction for real-time collision avoidance1",
        "abstract": "One of the most difficult challenges in robot motion planning is to account for the behavior of other moving agents, such as humans. Commonly, practitioners employ predictive models to reason about where other agents are going to move. Though there has been much recent work in building predictive models, no model is ever perfect: an agent can always move unexpectedly, in a way that is not predicted or not assigned sufficient probability. In such cases, the robot may plan trajectories that appear safe but, in fact, lead to collision. Rather than trust a model\u2019s predictions blindly, we propose that the robot should use the model\u2019s current predictive accuracy to inform the degree of confidence in its future predictions. This model confidence inference allows us to generate probabilistic motion predictions that exploit modeled structure when the structure successfully explains human motion, and degrade gracefully \u2026",
        "year": 2020,
        "authors": "David Fridovich-Keil and Andrea Bajcsy and Jaime F Fisac and Sylvia L Herbert and Steven Wang and Anca D Dragan and Claire J Tomlin"
      }
    ],
    "Hyhp_zUAAAAJ": [
      {
        "title": "Research through design as a method for interaction design research in HCI",
        "abstract": "For years the HCI community has struggled to integrate design in research and practice. While design has gained a strong foothold in practice, it has had much less impact on the HCI research community. In this paper we propose a new model for interaction design research within HCI. Following a research through design approach, designers produce novel integrations of HCI research in an attempt to make the right thing: a product that transforms the world from its current state to a preferred state. This model allows interaction designers to make research contributions based on their strength in addressing under-constrained problems. To formalize this model, we provide a set of four lenses for evaluating the research contribution and a set of three examples to illustrate the benefits of this type of research.",
        "year": 2007,
        "authors": "John Zimmerman and Jodi Forlizzi and Shelley Evenson"
      },
      {
        "title": "Understanding experience in interactive systems",
        "abstract": "Understanding experience is a critical issue for a variety of professions, especially design. To understand experience and the user experience that results from interacting with products, designers conduct situated research activities focused on the interactions between people and products, and the experience that results. This paper attempts to clarify experience in interactive systems. We characterize current approaches to experience from a number of disciplines, and present a framework for designing experience for interactive system. We show how the framework can be applied by members of a multidisciplinary team to understand and generate the kinds of interactions and experiences new product and system designs might offer.",
        "year": 2004,
        "authors": "Jodi Forlizzi and Katja Battarbee"
      },
      {
        "title": "A stage-based model of personal informatics systems",
        "abstract": "People strive to obtain self-knowledge. A class of systems called personal informatics is appearing that help people collect and reflect on personal information. However, there is no comprehensive list of problems that users experience using these systems, and no guidance for making these systems more effective. To address this, we conducted surveys and interviews with people who collect and reflect on personal information. We derived a stage-based model of personal informatics systems composed of five stages (preparation, collection, integration, reflection, and action) and identified barriers in each of the stages. These stages have four essential properties: barriers cascade to later stages; they are iterative; they are user-driven and/or system-driven; and they are uni-faceted or multi-faceted. From these properties, we recommend that personal informatics systems should 1) be designed in a holistic manner \u2026",
        "year": 2010,
        "authors": "Ian Li and Anind Dey and Jodi Forlizzi"
      }
    ],
    "NDyEvlQAAAAJ": [
      {
        "title": "Reference-based analysis of lung single-cell sequencing reveals a transitional profibrotic macrophage",
        "abstract": "Tissue fibrosis is a major cause of mortality that results from the deposition of matrix proteins by an activated mesenchyme. Macrophages accumulate in fibrosis, but the role of specific subgroups in supporting fibrogenesis has not been investigated in vivo. Here, we used single-cell RNA sequencing (scRNA-seq) to characterize the heterogeneity of macrophages in bleomycin-induced lung fibrosis in mice. A novel computational framework for the annotation of scRNA-seq by reference to bulk transcriptomes (SingleR) enabled the subclustering of macrophages and revealed a disease-associated subgroup with a transitional gene expression profile intermediate between monocyte-derived and alveolar macrophages. These CX3CR1+SiglecF+ transitional macrophages localized to the fibrotic niche and had a profibrotic effect in vivo. Human orthologs of genes expressed by the transitional macrophages were \u2026",
        "year": 2019,
        "authors": "Dvir Aran and Agnieszka P Looney and Leqian Liu and Esther Wu and Valerie Fong and Austin Hsu and Suzanna Chak and Ram P Naikawadi and Paul J Wolters and Adam R Abate and Atul J Butte and Mallar Bhattacharya"
      },
      {
        "title": "xCell: digitally portraying the tissue cellular heterogeneity landscape",
        "abstract": "Tissues are complex milieus consisting of numerous cell types. Several recent methods have attempted to enumerate cell subsets from transcriptomes. However, the available methods have used limited sources for training and give only a partial portrayal of the full cellular landscape. Here we present xCell, a novel gene signature-based method, and use it to infer 64 immune and stromal cell types. We harmonized 1822 pure human cell type transcriptomes from various sources and employed a curve fitting approach for linear comparison of cell types and introduced a novel spillover compensation technique for separating them. Using extensive in silico analyses and comparison to cytometry immunophenotyping, we show that xCell outperforms other methods. xCell is available at                    http://xCell.ucsf.edu/                                    .",
        "year": 2017,
        "authors": "Dvir Aran and Zicheng Hu and Atul J Butte"
      },
      {
        "title": "The repertoire of mutational signatures in human cancer",
        "abstract": "Somatic mutations in cancer genomes are caused by multiple mutational processes, each of which generates a characteristic mutational signature. Here, as part of the Pan-Cancer Analysis of Whole Genomes (PCAWG) Consortium of the International Cancer Genome Consortium (ICGC) and The Cancer Genome Atlas (TCGA), we characterized mutational signatures using 84,729,690 somatic mutations from 4,645 whole-genome and 19,184 exome sequences that encompass most types of cancer. We identified 49 single-base-substitution, 11 doublet-base-substitution, 4 clustered-base-substitution and 17 small insertion-and-deletion signatures. The substantial size of our dataset, compared with previous analyses, , , , , , , , , , , \u2013, enabled the discovery of new signatures, the separation of overlapping signatures and the decomposition of signatures into components that may represent associated\u2014but distinct\u2014DNA \u2026",
        "year": 2020,
        "authors": "Ludmil B Alexandrov and Jaegil Kim and Nicholas J Haradhvala and Mi Ni Huang and Alvin Wei Tian Ng and Yang Wu and Arnoud Boot and Kyle R Covington and Dmitry A Gordenin and Erik N Bergstrom and SM Ashiqul Islam and Nuria Lopez-Bigas and Leszek J Klimczak and John R McPherson and Sandro Morganella and Radhakrishnan Sabarinathan and David A Wheeler and Ville Mustonen and Gad Getz and Steven G Rozen and Michael R Stratton"
      }
    ],
    "jERkdhIAAAAJ": [
      {
        "title": "Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning",
        "abstract": "Model-free deep reinforcement learning algorithms have been shown to be capable of learning a wide range of robotic skills, but typically require a very large number of samples to achieve good performance. Model-based algorithms, in principle, can provide for much more efficient learning, but have proven difficult to extend to expressive, high-capacity models such as deep neural networks. In this work, we demonstrate that neural network dynamics models can in fact be combined with model predictive control (MPC) to achieve excellent sample complexity in a model-based reinforcement learning algorithm, producing stable and plausible gaits that accomplish various complex locomotion tasks. We further propose using deep neural network dynamics models to initialize a model-free learner, in order to combine the sample efficiency of model-based approaches with the high task-specific performance of model-free \u2026",
        "year": 2018,
        "authors": "Anusha Nagabandi and Gregory Kahn and Ronald S Fearing and Sergey Levine"
      },
      {
        "title": "Learning deep control policies for autonomous aerial vehicles with mpc-guided policy search",
        "abstract": "Model predictive control (MPC) is an effective method for controlling robotic systems, particularly autonomous aerial vehicles such as quadcopters. However, application of MPC can be computationally demanding, and typically requires estimating the state of the system, which can be challenging in complex, unstructured environments. Reinforcement learning can in principle forego the need for explicit state estimation and acquire a policy that directly maps sensor readings to actions, but is difficult to apply to unstable systems that are liable to fail catastrophically during training before an effective policy has been found. We propose to combine MPC with reinforcement learning in the framework of guided policy search, where MPC is used to generate data at training time, under full state observations provided by an instrumented training environment. This data is used to train a deep neural network policy, which is \u2026",
        "year": 2016,
        "authors": "Tianhao Zhang and Gregory Kahn and Sergey Levine and Pieter Abbeel"
      }
    ],
    "DRnOvU8AAAAJ": [
      {
        "title": "Diversity Is All You Need: Learning Skills without a Reward Function",
        "abstract": "Intelligent creatures can explore their environments and learn useful skills without supervision. In this paper, we propose DIAYN ('Diversity is All You Need'), a method for learning useful skills without a reward function. Our proposed method learns skills by maximizing an information theoretic objective using a maximum entropy policy. On a variety of simulated robotic tasks, we show that this simple objective results in the unsupervised emergence of diverse skills, such as walking and jumping. In a number of reinforcement learning benchmark environments, our method is able to learn a skill that solves the benchmark task despite never receiving the true task reward. We show how pretrained skills can provide a good parameter initialization for downstream tasks, and can be composed hierarchically to solve complex, sparse reward tasks. Our results suggest that unsupervised discovery of skills can serve as an effective pretraining mechanism for overcoming challenges of exploration and data efficiency in reinforcement learning.",
        "year": 2019,
        "authors": "Benjamin Eysenbach and Abhishek Gupta and Julian Ibarz and Sergey Levine"
      },
      {
        "title": "Search on the Replay Buffer: Bridging Planning and Reinforcement Learning",
        "abstract": "The history of learning for control has been an exciting back and forth between two broad classes of algorithms: planning and reinforcement learning. Planning algorithms effectively reason over long horizons, but assume access to a local policy and distance metric over collision-free paths. Reinforcement learning excels at learning policies and relative values of states, but fails to plan over long horizons. Despite the successes of each method on various tasks, long horizon, sparse reward tasks with high-dimensional observations remain exceedingly challenging for both planning and reinforcement learning algorithms. Frustratingly, these sorts of tasks are potentially the most useful, as they are simple to design (a human only need to provide an example goal state) and avoid injecting bias through reward shaping. We introduce a general-purpose control algorithm that combines the strengths of planning and reinforcement learning to effectively solve these tasks. Our main idea is to decompose the task of reaching a distant goal state into a sequence of easier tasks, each of which corresponds to reaching a particular subgoal. We use goal-conditioned RL to learn a policy to reach each waypoint and to learn a distance metric for search. Using graph search over our replay buffer, we can automatically generate this sequence of subgoals, even in image-based environments. Our algorithm, search on the replay buffer (SoRB), enables agents to solve sparse reward tasks over hundreds of steps, and generalizes substantially better than standard RL algorithms.",
        "year": 2019,
        "authors": "Benjamin Eysenbach and Ruslan Salakhutdinov and Sergey Levine"
      },
      {
        "title": "Efficient Exploration via State Marginal Matching",
        "abstract": "Exploration is critical to a reinforcement learning agent's performance in its given environment. Prior exploration methods are often based on using heuristic auxiliary predictions to guide policy behavior, lacking a mathematically-grounded objective with clear properties. In contrast, we recast exploration as a problem of State Marginal Matching (SMM), where we aim to learn a policy for which the state marginal distribution matches a given target state distribution. The target distribution is a uniform distribution in most cases, but can incorporate prior knowledge if available. In effect, SMM amortizes the cost of learning to explore in a given environment. The SMM objective can be viewed as a two-player, zero-sum game between a state density model and a parametric policy, an idea that we use to build an algorithm for optimizing the SMM objective. Using this formalism, we further demonstrate that prior work approximately maximizes the SMM objective, offering an explanation for the success of these methods. On both simulated and real-world tasks, we demonstrate that agents that directly optimize the SMM objective explore faster and adapt more quickly to new tasks as compared to prior exploration methods.",
        "year": 2019,
        "authors": "Lisa Lee and Benjamin Eysenbach and Emilio Parisotto and Eric Xing and Sergey Levine and Ruslan Salakhutdinov"
      }
    ],
    "bZ9oyW8AAAAJ": [
      {
        "title": "Theoretically Principled Trade-off between Robustness and Accuracy",
        "abstract": "We identify a trade-off between robustness and accuracy that serves as a guiding principle in the design of defenses against adversarial examples. Although this problem has been widely studied empirically, much remains unknown concerning the theory underlying this trade-off. In this work, we decompose the prediction error for adversarial examples (robust error) as the sum of the natural (classification) error and boundary error, and provide a differentiable upper bound using the theory of classification-calibrated loss, which is shown to be the tightest possible upper bound uniform over all probability distributions and measurable predictors. Inspired by our theoretical analysis, we also design a new defense method, TRADES, to trade adversarial robustness off against accuracy. Our proposed algorithm performs well experimentally in real-world datasets. The methodology is the foundation of our entry to the NeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of 2,000 submissions, surpassing the runner-up approach by 11.41% in terms of mean L_2 perturbation distance.",
        "year": 2019,
        "authors": "Hongyang Zhang and Yaodong Yu and Jiantao Jiao and Eric P Xing and Laurent El Ghaoui and Michael I Jordan"
      },
      {
        "title": "Rethinking Bias-Variance Trade-off for Generalization of Neural Networks",
        "abstract": "The classical bias-variance trade-off predicts that bias decreases and variance increase with model complexity, leading to a U-shaped risk curve. Recent work calls this into question for neural networks and other over-parameterized models, for which it is often observed that larger models generalize better. We provide a simple explanation of this by measuring the bias and variance of neural networks: while the bias is\\emph {monotonically decreasing} as in the classical theory, the variance is\\emph {unimodal} or bell-shaped: it increases then decreases with the width of the network. We vary the network architecture, loss function, and choice of dataset and confirm that variance unimodality occurs robustly for all models we considered. The risk curve is the sum of the bias and variance curves and displays different qualitative shapes depending on the relative scale of bias and variance, with the double descent in the recent literature as a special case. We corroborate these empirical results with a theoretical analysis of two-layer linear networks with random first layer. Finally, evaluation on out-of-distribution data shows that most of the drop in accuracy comes from increased bias while variance increases by a relatively small amount. Moreover, we find that deeper models decrease bias and increase variance for both in-distribution and out-of-distribution data.",
        "year": 2020,
        "authors": "Zitong Yang and Yaodong Yu and Chong You and Jacob Steinhardt and Yi Ma"
      },
      {
        "title": "Learning Diverse and Discriminative Representations via the Principle of Maximal Coding Rate Reduction",
        "abstract": "To learn intrinsic low-dimensional structures from high-dimensional data that most discriminate between classes, we propose the principle of {\\em Maximal Coding Rate Reduction}(), an information-theoretic measure that maximizes the coding rate difference between the whole dataset and the sum of each individual class. We clarify its relationships with most existing frameworks such as cross-entropy, information bottleneck, information gain, contractive and contrastive learning, and provide theoretical guarantees for learning diverse and discriminative features. The coding rate can be accurately computed from finite samples of degenerate subspace-like distributions and can learn intrinsic representations in supervised, self-supervised, and unsupervised settings in a unified manner. Empirically, the representations learned using this principle alone are significantly more robust to label corruptions in classification than those using cross-entropy, and can lead to state-of-the-art results in clustering mixed data from self-learned invariant features.",
        "year": 2020,
        "authors": "Yaodong Yu and Kwan Ho Ryan Chan and Chong You and Chaobing Song and Yi Ma"
      }
    ],
    "gRxBNZoAAAAJ": [
      {
        "title": "Man is to computer programmer as woman is to homemaker? Debiasing word embeddings",
        "abstract": "The blind application of machine learning runs the risk of amplifying biases present in data. Such a danger is facing us with word embedding, a popular framework to represent text data as vectors which has been used in many machine learning and natural language processing tasks. We show that even word embeddings trained on Google News articles exhibit female/male gender stereotypes to a disturbing extent. This raises concerns because their widespread use, as we describe, often tends to amplify these biases. Geometrically, gender bias is first shown to be captured by a direction in the word embedding. Second, gender neutral words are shown to be linearly separable from gender definition words in the word embedding. Using these properties, we provide a methodology for modifying an embedding to remove gender stereotypes, such as the association between the words receptionist and female, while maintaining desired associations such as between the words queen and female. Using crowd-worker evaluation as well as standard benchmarks, we empirically demonstrate that our algorithms significantly reduce gender bias in embeddings while preserving the its useful properties such as the ability to cluster related concepts and to solve analogy tasks. The resulting embeddings can be used in applications without amplifying gender bias.",
        "year": 2016,
        "authors": "Tolga Bolukbasi and Kai-Wei Chang and James Y Zou and Venkatesh Saligrama and Adam T Kalai"
      },
      {
        "title": "Online convex optimization in the bandit setting: gradient descent without a gradient",
        "abstract": "We consider a the general online convex optimization framework introduced by Zinkevich. In this setting, there is a sequence of convex functions. Each period, we must choose a signle point (from some feasible set) and pay a cost equal to the value of the next function on our chosen point. Zinkevich shows that, if the each function is revealed after the choice is made, then one can achieve vanishingly small regret relative the best single decision chosen in hindsight. We extend this to the bandit setting where we do not find out the entire functions but rather just their value at our chosen point. We show how to get vanishingly small regret in this setting. Our approach uses a simple approximation of the gradient that is computed from evaluating a function at a single (random) point. We show that this estimate is sufficient to mimic Zinkevich's gradient descent online analysis, with access to the gradient (only being able to evaluate the function at a single point).",
        "year": 2005,
        "authors": "Abraham D Flaxman and Adam Tauman Kalai and H Brendan McMahan"
      },
      {
        "title": "Efficient algorithms for online decision problems",
        "abstract": "In an online decision problem, one makes a sequence of decisions without knowledge of the future. Each period, one pays a cost based on the decision and observed state. We give a simple approach for doing nearly as well as the best single decision, where the best is chosen with the benefit of hindsight. A natural idea is to follow the leader, i.e. each period choose the decision which has done best so far. We show that by slightly perturbing the totals and then choosing the best decision, the expected performance is nearly as good as the best decision in hindsight. Our approach, which is very much like Hannan's original game-theoretic approach from the 1950s, yields guarantees competitive with the more modern exponential weighting algorithms like Weighted Majority. More importantly, these follow-the-leader style algorithms extend naturally to a large class of structured online problems for which the \u2026",
        "year": 2005,
        "authors": "Adam Kalai and Santosh Vempala"
      }
    ],
    "mu5Y2rYAAAAJ": [
      {
        "title": "Going deeper with convolutions",
        "abstract": "We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the ImageNet Large-Scale Visual Recognition Challenge 2014 (ILSVRC2014). The main hallmark of this architecture is the improved utilization of the computing resources inside the network. By a carefully crafted design, we increased the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation of this architecture, GoogLeNet, a 22 layers deep network, was used to assess its quality in the context of object detection and classification.",
        "year": 2015,
        "authors": "Christian Szegedy and Wei Liu and Yangqing Jia and Pierre Sermanet and Scott Reed and Dragomir Anguelov and Dumitru Erhan and Vincent Vanhoucke and Andrew Rabinovich"
      },
      {
        "title": "Caffe: Convolutional architecture for fast feature embedding",
        "abstract": "Caffe provides multimedia scientists and practitioners with a clean and modifiable framework for state-of-the-art deep learning algorithms and a collection of reference models. The framework is a BSD-licensed C++ library with Python and MATLAB bindings for training and deploying general-purpose convolutional neural networks and other deep models efficiently on commodity architectures. Caffe fits industry and internet-scale media needs by CUDA GPU computation, processing over 40 million images a day on a single K40 or Titan GPU (approx 2 ms per image). By separating model representation from actual implementation, Caffe allows experimentation and seamless switching among platforms for ease of development and deployment from prototyping machines to cloud environments.Caffe is maintained and developed by the Berkeley Vision and Learning Center (BVLC) with the help of an active community \u2026",
        "year": 2014,
        "authors": "Yangqing Jia and Evan Shelhamer and Jeff Donahue and Sergey Karayev and Jonathan Long and Ross Girshick and Sergio Guadarrama and Trevor Darrell"
      },
      {
        "title": "Tensorflow: Large-scale machine learning on heterogeneous distributed systems",
        "abstract": "TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.",
        "year": 2016,
        "authors": "Mart\u00edn Abadi and Ashish Agarwal and Paul Barham and Eugene Brevdo and Zhifeng Chen and Craig Citro and Greg S Corrado and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Ian Goodfellow and Andrew Harp and Geoffrey Irving and Michael Isard and Yangqing Jia and Rafal J\u00f3zefowicz and Lukasz Kaiser and Manjunath Kudlur and Josh Levenberg and Dan Man\u00e9 and Rajat Monga and Sherry Moore and Derek Murray and Chris Olah and Mike Schuster and Jonathon Shlens and Benoit Steiner and Ilya Sutskever and Kunal Talwar and Paul Tucker and Vincent Vanhoucke and Vijay Vasudevan and Fernanda Viegas and Oriol Vinyals and Pete Warden and Martin Wattenberg and Martin Wicke and Yuan Yu and Xiaoqiang Zheng"
      }
    ],
    "a_dbdxAAAAAJ": [
      {
        "title": "Exact matrix completion via convex optimization",
        "abstract": "Suppose that one observes an incomplete subset of entries selected from a low-rank matrix. When is it possible to complete the matrix and recover the entries that have not been seen? We demonstrate that in very general settings, one can perfectly recover all of the missing entries from most sufficiently large subsets by solving a convex programming problem that finds the matrix with the minimum nuclear norm agreeing with the observed entries. The techniques used in this analysis draw upon parallels in the field of compressed sensing, demonstrating that objects other than signals and images can be perfectly reconstructed from very limited information.",
        "year": 2012,
        "authors": "Emmanuel Candes and Benjamin Recht"
      },
      {
        "title": "Understanding deep learning requires rethinking generalization",
        "abstract": "Despite their massive size, successful deep artificial neural networks can exhibit a remarkably small difference between training and test performance. Conventional wisdom attributes small generalization error either to properties of the model family, or to the regularization techniques used during training. Through extensive systematic experiments, we show how these traditional approaches fail to explain why large neural networks generalize well in practice. Specifically, our experiments establish that state-of-the-art convolutional networks for image classification trained with stochastic gradient methods easily fit a random labeling of the training data. This phenomenon is qualitatively unaffected by explicit regularization, and occurs even if we replace the true images by completely unstructured random noise. We corroborate these experimental findings with a theoretical construction showing that simple depth two neural networks already have perfect finite sample expressivity as soon as the number of parameters exceeds the number of data points as it usually does in practice. We interpret our experimental findings by comparison with traditional models.",
        "year": 2016,
        "authors": "Chiyuan Zhang and Samy Bengio and Moritz Hardt and Benjamin Recht and Oriol Vinyals"
      },
      {
        "title": "Random features for large-scale kernel machines",
        "abstract": "To accelerate the training of kernel machines, we propose to map the input data to a randomized low-dimensional feature space and then apply existing fast linear methods. The features are designed so that the inner products of the transformed data are approximately equal to those in the feature space of a user specified shiftinvariant kernel. We explore two sets of random features, provide convergence bounds on their ability to approximate various radial basis kernels, and show that in large-scale classification and regression tasks linear machine learning algorithms applied to these features outperform state-of-the-art large-scale kernel machines.",
        "year": 2007,
        "authors": "Ali Rahimi and Benjamin Recht"
      }
    ],
    "1O83J5MAAAAJ": [
      {
        "title": "Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Soft actor-critic algorithms and applications",
        "abstract": "Model-free deep reinforcement learning (RL) algorithms have been successfully applied to a range of challenging sequential decision making and control tasks. However, these methods typically suffer from two major challenges: high sample complexity and brittleness to hyperparameters. Both of these challenges limit the applicability of such methods to real-world domains. In this paper, we describe Soft Actor-Critic (SAC), our recently introduced off-policy actor-critic algorithm based on the maximum entropy RL framework. In this framework, the actor aims to simultaneously maximize expected return and entropy. That is, to succeed at the task while acting as randomly as possible. We extend SAC to incorporate a number of modifications that accelerate training and improve stability with respect to the hyperparameters, including a constrained formulation that automatically tunes the temperature hyperparameter. We systematically evaluate SAC on a range of benchmark tasks, as well as real-world challenging tasks such as locomotion for a quadrupedal robot and robotic manipulation with a dexterous hand. With these improvements, SAC achieves state-of-the-art performance, outperforming prior on-policy and off-policy methods in sample-efficiency and asymptotic performance. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving similar performance across different random seeds. These results suggest that SAC is a promising candidate for learning in real-world robotics tasks.",
        "year": 2018,
        "authors": "Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine"
      },
      {
        "title": "Conservative q-learning for offline reinforcement learning",
        "abstract": "Effectively leveraging large, previously collected datasets in reinforcement learn-ing (RL) is a key challenge for large-scale real-world applications. Offline RL algorithms promise to learn effective policies from previously-collected, static datasets without further interaction. However, in practice, offline RL presents a major challenge, and standard off-policy RL methods can fail due to overestimation of values induced by the distributional shift between the dataset and the learned policy, especially when training on complex and multi-modal data distributions. In this paper, we propose conservative Q-learning (CQL), which aims to address these limitations by learning a conservative Q-function such that the expected value of a policy under this Q-function lower-bounds its true value. We theoretically show that CQL produces a lower bound on the value of the current policy and that it can be incorporated into a policy learning procedure with theoretical improvement guarantees. In practice, CQL augments the standard Bellman error objective with a simple Q-value regularizer which is straightforward to implement on top of existing deep Q-learning and actor-critic implementations. On both discrete and continuous control domains, we show that CQL substantially outperforms existing offline RL methods, often learning policies that attain 2-5 times higher final return, especially when learning from complex and multi-modal data distributions.",
        "year": 2020,
        "authors": "Aviral Kumar and Aurick Zhou and George Tucker and Sergey Levine"
      }
    ],
    "itSa94cAAAAJ": [
      {
        "title": "Proximal policy optimization algorithms",
        "abstract": "We propose a new family of policy gradient methods for reinforcement learning, which alternate between sampling data through interaction with the environment, and optimizing a \"surrogate\" objective function using stochastic gradient ascent. Whereas standard policy gradient methods perform one gradient update per data sample, we propose a novel objective function that enables multiple epochs of minibatch updates. The new methods, which we call proximal policy optimization (PPO), have some of the benefits of trust region policy optimization (TRPO), but they are much simpler to implement, more general, and have better sample complexity (empirically). Our experiments test PPO on a collection of benchmark tasks, including simulated robotic locomotion and Atari game playing, and we show that PPO outperforms other online policy gradient methods, and overall strikes a favorable balance between sample complexity, simplicity, and wall-time.",
        "year": 2017,
        "authors": "John Schulman and Filip Wolski and Prafulla Dhariwal and Alec Radford and Oleg Klimov"
      },
      {
        "title": "Training language models to follow instructions with human feedback",
        "abstract": "Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through a language model API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3 B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.",
        "year": 2022,
        "authors": "Long Ouyang and Jeffrey Wu and Xu Jiang and Diogo Almeida and Carroll Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul F Christiano and Jan Leike and Ryan Lowe"
      },
      {
        "title": "Gpt-4 technical report",
        "abstract": "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.",
        "year": 2023,
        "authors": "Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Sim\u00f3n Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and \u0141ukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and \u0141ukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew"
      }
    ],
    "2oy3OXYAAAAJ": [
      {
        "title": "Algorithms for inverse reinforcement learning.",
        "abstract": "This paper addresses the problem of inverse reinforcement learning (IRL) in Markov de-cision processes, that is, the problem of extracting a reward function given observed, optimal behavior. IRL may be useful for apprenticeship learning to acquire skilled behavior, and for ascertaining the reward function being optimized by a natural system. We first characterize the set of all reward func-tions for which a given policy is optimal. We then derive three algorithms for IRL. The first two deal with the case where the entire policy is known; we handle tabulated reward functions on a finite state space and linear functional approximation of the reward function over a potentially infinite state space. The third algorithm deals with the more realistic case in which the policy is known only through a finite set of observed trajectories. In all cases, a key issue is degeneracy-the existence of a large set of reward functions for which the \u2026",
        "year": 2000,
        "authors": "Andrew Y Ng and Stuart Russell"
      },
      {
        "title": "Distance metric learning with application to clustering with side-information",
        "abstract": "Many algorithms rely critically on being given a good metric over their inputs. For instance, data can often be clustered in many \u201cplausible\u201d ways, and if a clustering algorithm such as K-means initially fails to find one that is meaningful to a user, the only recourse may be for the user to manually tweak the metric until sufficiently good clusters are found. For these and other applications requiring good metrics, it is desirable that we provide a more systematic way for users to indicate what they consider \u201csimilar.\u201d For instance, we may ask them to provide examples. In this paper, we present an algorithm that, given examples of similar (and, if desired, dissimilar) pairs of points in \u0432\u0434\u0433, learns a distance metric over \u0432\u0435\u0433 that respects these relationships. Our method is based on posing metric learning as a convex optimization problem, which allows us to give efficient, local-optima-free algorithms. We also demonstrate empirically that the learned metrics can be used to significantly improve clustering performance.",
        "year": 2002,
        "authors": "Eric Xing and Michael Jordan and Stuart J Russell and Andrew Ng"
      }
    ],
    "8-p9CLsAAAAJ": [
      {
        "title": "Motion planning with sequential convex optimization and convex collision checking",
        "abstract": "We present a new optimization-based approach for robotic motion planning among obstacles. Like CHOMP (Covariant Hamiltonian Optimization for Motion Planning), our algorithm can be used to find collision-free trajectories from na\u00efve, straight-line initializations that might be in collision. At the core of our approach are (a) a sequential convex optimization procedure, which penalizes collisions with a hinge loss and increases the penalty coefficients in an outer loop as necessary, and (b) an efficient formulation of the no-collisions constraint that directly considers continuous-time safety Our algorithm is implemented in a software package called TrajOpt.We report results from a series of experiments comparing TrajOpt with CHOMP and randomized planners from OMPL, with regard to planning time and path quality. We consider motion planning for 7 DOF robot arms, 18 DOF full-body robots, statically stable walking \u2026",
        "year": 2014,
        "authors": "John Schulman and Yan Duan and Jonathan Ho and Alex Lee and Ibrahim Awwal and Henry Bradlow and Jia Pan and Sachin Patil and Ken Goldberg and Pieter Abbeel"
      },
      {
        "title": "Finding locally optimal, collision-free trajectories with sequential convex optimization.",
        "abstract": "We present a novel approach for incorporating collision avoidance into trajectory optimization as a method of solving robotic motion planning problems. At the core of our approach are (i) A sequential convex optimization procedure, which penalizes collisions with a hinge loss and increases the penalty coefficients in an outer loop as necessary.(ii) An efficient formulation of the no-collisions constraint that directly considers continuous-time safety and enables the algorithm to reliably solve motion planning problems, including problems involving thin and complex obstacles.We benchmarked our algorithm against several other motion planning algorithms, solving a suite of 7-degree-of-freedom (DOF) arm-planning problems and 18-DOF full-body planning problems. We compared against sampling-based planners from OMPL, and we also compared to CHOMP, a leading approach for trajectory optimization. Our algorithm was faster than the alternatives, solved more problems, and yielded higher quality paths.",
        "year": 2013,
        "authors": "John Schulman and Jonathan Ho and Alex X Lee and Ibrahim Awwal and Henry Bradlow and Pieter Abbeel"
      },
      {
        "title": "Stochastic adversarial video prediction",
        "abstract": "Being able to predict what may happen in the future requires an in-depth understanding of the physical and causal rules that govern the world. A model that is able to do so has a number of appealing applications, from robotic planning to representation learning. However, learning to predict raw future observations, such as frames in a video, is exceedingly challenging -- the ambiguous nature of the problem can cause a naively designed model to average together possible futures into a single, blurry prediction. Recently, this has been addressed by two distinct approaches: (a) latent variational variable models that explicitly model underlying stochasticity and (b) adversarially-trained models that aim to produce naturalistic images. However, a standard latent variable model can struggle to produce realistic results, and a standard adversarially-trained model underutilizes latent variables and fails to produce diverse predictions. We show that these distinct methods are in fact complementary. Combining the two produces predictions that look more realistic to human raters and better cover the range of possible futures. Our method outperforms prior and concurrent work in these aspects.",
        "year": 2018,
        "authors": "Alex X Lee and Richard Zhang and Frederik Ebert and Pieter Abbeel and Chelsea Finn and Sergey Levine"
      }
    ],
    "6dskOSUAAAAJ": [
      {
        "title": "Conditional image synthesis with auxiliary classifier gans",
        "abstract": "In this paper we introduce new methods for the improved training of generative adversarial networks (GANs) for image synthesis. We construct a variant of GANs employing label conditioning that results in  resolution image samples exhibiting global coherence. We expand on previous work for image quality assessment to provide two new analyses for assessing the discriminability and diversity of samples from class-conditional image synthesis models. These analyses demonstrate that high resolution samples provide class information not present in low resolution samples. Across 1000 ImageNet classes,  samples are more than twice as discriminable as artificially resized  samples. In addition, 84.7\\% of the classes have samples exhibiting diversity comparable to real ImageNet data.",
        "year": 2017,
        "authors": "Augustus Odena and Christopher Olah and Jonathon Shlens"
      },
      {
        "title": "Concrete problems in AI safety",
        "abstract": "Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function (\"avoiding side effects\" and \"avoiding reward hacking\"), an objective function that is too expensive to evaluate frequently (\"scalable supervision\"), or undesirable behavior during the learning process (\"safe exploration\" and \"distributional shift\"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.",
        "year": 2016,
        "authors": "Dario Amodei and Chris Olah and Jacob Steinhardt and Paul Christiano and John Schulman and Dan Man\u00e9"
      }
    ],
    "B7oP0bIAAAAJ": [
      {
        "title": "Training language models to follow instructions with human feedback",
        "abstract": "Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through a language model API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3 B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.",
        "year": 2022,
        "authors": "Long Ouyang and Jeffrey Wu and Xu Jiang and Diogo Almeida and Carroll Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul F Christiano and Jan Leike and Ryan Lowe"
      },
      {
        "title": "Deep reinforcement learning from human preferences",
        "abstract": "For sophisticated reinforcement learning (RL) systems to interact usefully with real-world environments, we need to communicate complex goals to these systems. In this work, we explore goals defined in terms of (non-expert) human preferences between pairs of trajectory segments. Our approach separates learning the goal from learning the behavior to achieve it. We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on about 0.1% of our agent's interactions with the environment. This reduces the cost of human oversight far enough that it can be practically applied to state-of-the-art RL systems. To demonstrate the flexibility of our approach, we show that we can successfully train complex novel behaviors with about an hour of human time. These behaviors and environments are considerably more complex than any which have been previously learned from human feedback.",
        "year": 2017,
        "authors": "Paul F Christiano and Jan Leike and Tom Brown and Miljan Martic and Shane Legg and Dario Amodei"
      },
      {
        "title": "Concrete problems in AI safety",
        "abstract": "Rapid progress in machine learning and artificial intelligence (AI) has brought increasing attention to the potential impacts of AI technologies on society. In this paper we discuss one such potential impact: the problem of accidents in machine learning systems, defined as unintended and harmful behavior that may emerge from poor design of real-world AI systems. We present a list of five practical research problems related to accident risk, categorized according to whether the problem originates from having the wrong objective function (\"avoiding side effects\" and \"avoiding reward hacking\"), an objective function that is too expensive to evaluate frequently (\"scalable supervision\"), or undesirable behavior during the learning process (\"safe exploration\" and \"distributional shift\"). We review previous work in these areas as well as suggesting research directions with a focus on relevance to cutting-edge AI systems. Finally, we consider the high-level question of how to think most productively about the safety of forward-looking applications of AI.",
        "year": 2016,
        "authors": "Dario Amodei and Chris Olah and Jacob Steinhardt and Paul Christiano and John Schulman and Dan Man\u00e9"
      }
    ],
    "IcaU830AAAAJ": [
      {
        "title": "Ray: A distributed framework for emerging {AI} applications",
        "abstract": "The next generation of AI applications will continuously interact with the environment and learn from these interactions. These applications impose new and demanding systems requirements, both in terms of performance and flexibility. In this paper, we consider these requirements and present Ray\u2014a distributed system to address them. Ray implements a unified interface that can express both task-parallel and actor-based computations, supported by a single dynamic execution engine. To meet the performance requirements, Ray employs a distributed scheduler and a distributed and fault-tolerant store to manage the system\u2019s control state. In our experiments, we demonstrate scaling beyond 1.8 million tasks per second and better performance than existing specialized systems for several challenging reinforcement learning applications.",
        "year": 2018,
        "authors": "Philipp Moritz and Robert Nishihara and Stephanie Wang and Alexey Tumanov and Richard Liaw and Eric Liang and Melih Elibol and Zongheng Yang and William Paul and Michael I Jordan and Ion Stoica"
      },
      {
        "title": "RLlib: Abstractions for distributed reinforcement learning",
        "abstract": "Reinforcement learning (RL) algorithms involve the deep nesting of highly irregular computation patterns, each of which typically exhibits opportunities for distributed computation. We argue for distributing RL components in a composable way by adapting algorithms for top-down hierarchical control, thereby encapsulating parallelism and resource requirements within short-running compute tasks. We demonstrate the benefits of this principle through RLlib: a library that provides scalable software primitives for RL. These primitives enable a broad range of algorithms to be implemented with high performance, scalability, and substantial code reuse. RLlib is available as part of the open source Ray project at http://rllib. io/.",
        "year": 2018,
        "authors": "Eric Liang and Richard Liaw and Robert Nishihara and Philipp Moritz and Roy Fox and Ken Goldberg and Joseph Gonzalez and Michael Jordan and Ion Stoica"
      },
      {
        "title": "Tune: A research platform for distributed model selection and training",
        "abstract": "Modern machine learning algorithms are increasingly computationally demanding, requiring specialized hardware and distributed computation to achieve high performance in a reasonable time frame. Many hyperparameter search algorithms have been proposed for improving the efficiency of model selection, however their adaptation to the distributed compute environment is often ad-hoc. We propose Tune, a unified framework for model selection and training that provides a narrow-waist interface between training scripts and search algorithms. We show that this interface meets the requirements for a broad range of hyperparameter search algorithms, allows straightforward scaling of search to large clusters, and simplifies algorithm implementation. We demonstrate the implementation of several state-of-the-art hyperparameter search algorithms in Tune. Tune is available at http://ray.readthedocs.io/en/latest/tune.html.",
        "year": 2018,
        "authors": "Richard Liaw and Eric Liang and Robert Nishihara and Philipp Moritz and Joseph E Gonzalez and Ion Stoica"
      }
    ],
    "7t4jbPQAAAAJ": [
      {
        "title": "Reinforcement learning in robotics: A survey",
        "abstract": "Reinforcement learning offers to robotics a framework and set of tools for the design of sophisticated and hard-to-engineer behaviors. Conversely, the challenges of robotic problems provide both inspiration, impact, and validation for developments in reinforcement learning. The relationship between disciplines has sufficient promise to be likened to that between physics and mathematics. In this article, we attempt to strengthen the links between the two research communities by providing a survey of work in reinforcement learning for behavior generation in robots. We highlight both key challenges in robot reinforcement learning as well as notable successes. We discuss how contributions tamed the complexity of the domain and study the role of algorithms, representations, and prior knowledge in achieving these successes. As a result, a particular focus of our paper lies on the choice between model-based and \u2026",
        "year": 2013,
        "authors": "Jens Kober and J Andrew Bagnell and Jan Peters"
      },
      {
        "title": "A reduction of imitation learning and structured prediction to no-regret online learning",
        "abstract": "Sequential prediction problems such as imitation learning, where future observations depend on previous predictions (actions), violate the common iid assumptions made in statistical learning. This leads to poor performance in theory and often in practice. Some recent approaches provide stronger guarantees in this setting, but remain somewhat unsatisfactory as they train either non-stationary or stochastic policies and require a large number of iterations. In this paper, we propose a new iterative algorithm, which trains a stationary deterministic policy, that can be seen as a no regret algorithm in an online learning setting. We show that any such no regret algorithm, combined with additional reduction assumptions, must find a policy with good performance under the distribution of observations it induces in such sequential settings. We demonstrate that this new approach outperforms previous approaches on two challenging imitation learning problems and a benchmark sequence labeling problem.",
        "year": 2011,
        "authors": "St\u00e9phane Ross and Geoffrey Gordon and Drew Bagnell"
      },
      {
        "title": "Maximum entropy inverse reinforcement learning.",
        "abstract": "Recent research has shown the benefit of framing problems of imitation learning as solutions to Markov Decision Problems. This approach reduces learning to the problem of recovering a utility function that makes the behavior induced by a near-optimal policy closely mimic demonstrated behavior. In this work, we develop a probabilistic approach based on the principle of maximum entropy. Our approach provides a well-defined, globally normalized distribution over decision sequences, while providing the same performance guarantees as existing methods.We develop our technique in the context of modeling realworld navigation and driving behaviors where collected data is inherently noisy and imperfect. Our probabilistic approach enables modeling of route preferences as well as a powerful new approach to inferring destinations and routes based on partial trajectories.",
        "year": 2008,
        "authors": "Brian D Ziebart and Andrew L Maas and J Andrew Bagnell and Anind K Dey"
      }
    ],
    "X-Sd3-8AAAAJ": [
      {
        "title": "Sparse local embeddings for extreme multi-label classification",
        "abstract": "The objective in extreme multi-label learning is to train a classifier that can automatically tag a novel data point with the most relevant subset of labels from an extremely large label set. Embedding based approaches make training and prediction tractable by assuming that the training label matrix is low-rank and hence the effective number of labels can be reduced by projecting the high dimensional label vectors onto a low dimensional linear subspace. Still, leading embedding approaches have been unable to deliver high prediction accuracies or scale to large problems as the low rank assumption is violated in most real world applications. This paper develops the SLEEC classifier to address both limitations. The main technical contribution in SLEEC is a formulation for learning a small ensemble of local distance preserving embeddings which can accurately predict infrequently occurring (tail) labels. This allows SLEEC to break free of the traditional low-rank assumption and boost classification accuracy by learning embeddings which preserve pairwise distances between only the nearest label vectors. We conducted extensive experiments on several real-world as well as benchmark data sets and compare our method against state-of-the-art methods for extreme multi-label classification. Experiments reveal that SLEEC can make significantly more accurate predictions then the state-of-the-art methods including both embeddings (by as much as 35%) as well as trees (by as much as 6%). SLEEC can also scale efficiently to data sets with a million labels which are beyond the pale of leading embedding methods.",
        "year": 2015,
        "authors": "Kush Bhatia and Himanshu Jain and Purushottam Kar and Manik Varma and Prateek Jain"
      },
      {
        "title": "Ask me anything: A simple strategy for prompting language models",
        "abstract": "Large language models (LLMs) transfer well to new tasks out-of-the-box simply given a natural language prompt that demonstrates how to perform the task and no additional training. Prompting is a brittle process wherein small modifications to the prompt can cause large variations in the model predictions, and therefore significant effort is dedicated towards designing a painstakingly \"perfect prompt\" for a task. To mitigate the high degree of effort involved in prompt-design, we instead ask whether producing multiple effective, yet imperfect, prompts and aggregating them can lead to a high quality prompting strategy. Our observations motivate our proposed prompting method, ASK ME ANYTHING (AMA). We first develop an understanding of the effective prompt formats, finding that question-answering (QA) prompts, which encourage open-ended generation (\"Who went to the park?\") tend to outperform those that restrict the model outputs (\"John went to the park. Output True or False.\"). Our approach recursively uses the LLM itself to transform task inputs to the effective QA format. We apply the collected prompts to obtain several noisy votes for the input's true label. We find that the prompts can have very different accuracies and complex dependencies and thus propose to use weak supervision, a procedure for combining the noisy predictions, to produce the final predictions for the inputs. We evaluate AMA across open-source model families (e.g., EleutherAI, BLOOM, OPT, and T0) and model sizes (125M-175B parameters), demonstrating an average performance lift of 10.2% over the few-shot baseline. This simple strategy enables the open-source \u2026",
        "year": 2023,
        "authors": "Simran Arora and Avanika Narayan and Mayee F Chen and Laurel Orr and Neel Guha and Kush Bhatia and Ines Chami and Frederic Sala and Christopher R\u00e9"
      },
      {
        "title": "Fastgrnn: A fast, accurate, stable and tiny kilobyte sized gated recurrent neural network",
        "abstract": "This paper develops the FastRNN and FastGRNN algorithms to address the twin RNN limitations of inaccurate training and inefficient prediction. Previous approaches have improved accuracy at the expense of prediction costs making them infeasible for resource-constrained and real-time applications. Unitary RNNs have increased accuracy somewhat by restricting the range of the state transition matrix's singular values but have also increased the model size as they require a larger number of hidden units to make up for the loss in expressive power. Gated RNNs have obtained state-of-the-art accuracies by adding extra parameters thereby resulting in even larger models. FastRNN addresses these limitations by adding a residual connection that does not constrain the range of the singular values explicitly and has only two extra scalar parameters. FastGRNN then extends the residual connection to a gate by reusing the RNN matrices to match state-of-the-art gated RNN accuracies but with a 2-4x smaller model. Enforcing FastGRNN's matrices to be low-rank, sparse and quantized resulted in accurate models that could be up to 35x smaller than leading gated and unitary RNNs. This allowed FastGRNN to accurately recognize the\" Hey Cortana\" wakeword with a 1 KB model and to be deployed on severely resource-constrained IoT microcontrollers too tiny to store other RNN models. FastGRNN's code is available at (https://github. com/Microsoft/EdgeML/).",
        "year": 2018,
        "authors": "Aditya Kusupati and Manish Singh and Kush Bhatia and Ashish Kumar and Prateek Jain and Manik Varma"
      }
    ],
    "_pv1sEcAAAAJ": [
      {
        "title": "Cardiovascular disease risk prediction using automated machine learning: A prospective study of 423,604 UK Biobank participants",
        "abstract": "Identifying people at risk of cardiovascular diseases (CVD) is a cornerstone of preventative cardiology. Risk prediction models currently recommended by clinical guidelines are typically based on a limited number of predictors with sub-optimal performance across all patient groups. Data-driven techniques based on machine learning (ML) might improve the performance of risk predictions by agnostically discovering novel risk predictors and learning the complex interactions between them. We tested (1) whether ML techniques based on a state-of-the-art automated ML framework (AutoPrognosis) could improve CVD risk prediction compared to traditional approaches, and (2) whether considering non-traditional variables could increase the accuracy of CVD risk predictions.Using data on 423,604 participants without CVD at baseline in UK Biobank, we developed a ML-based model for predicting CVD risk based on 473 available variables. Our ML-based model was derived using AutoPrognosis, an algorithmic tool that automatically selects and tunes ensembles of ML modeling pipelines (comprising data imputation, feature processing, classification and calibration algorithms). We compared our model with a well-established risk prediction algorithm based on conventional CVD risk factors (Framingham score), a Cox proportional hazards (PH) model based on familiar risk factors (i.e, age, gender, smoking status, systolic blood pressure, history of diabetes, reception of treatments for hypertension and body mass index), and a Cox PH model based on all of the 473 available variables. Predictive performances were \u2026",
        "year": 2019,
        "authors": "Ahmed M Alaa and Thomas Bolton and Emanuele Di Angelantonio and James HF Rudd and Mihaela Van der Schaar"
      },
      {
        "title": "Bayesian Inference of Individualized Treatment Effects using Multi-task Gaussian Processes",
        "abstract": "Predicated on the increasing abundance of electronic health records, we investigate the problem of inferring individualized treatment effects using observational data. Stemming from the potential outcomes model, we propose a novel multi-task learning framework in which factual and counterfactual outcomes are modeled as the outputs of a function in a vector-valued reproducing kernel Hilbert space (vvRKHS). We develop a nonparametric Bayesian method for learning the treatment effects using a multi-task Gaussian process (GP) with a linear coregionalization kernel as a prior over the vvRKHS. The Bayesian approach allows us to compute individualized measures of confidence in our estimates via pointwise credible intervals, which are crucial for realizing the full potential of precision medicine. The impact of selection bias is alleviated via a risk-based empirical Bayes method for adapting the multi-task GP prior, which jointly minimizes the empirical error in factual outcomes and the uncertainty in (unobserved) counterfactual outcomes. We conduct experiments on observational datasets for an interventional social program applied to premature infants, and a left ventricular assist device applied to cardiac patients wait-listed for a heart transplant. In both experiments, we show that our method significantly outperforms the state-of-the-art.",
        "year": 2017,
        "authors": "Ahmed M Alaa and Mihaela van der Schaar"
      },
      {
        "title": "How faithful is your synthetic data? sample-level metrics for evaluating and auditing generative models",
        "abstract": "Devising domain-and model-agnostic evaluation metrics for generative models is an important and as yet unresolved problem. Most existing metrics, which were tailored solely to the image synthesis setup, exhibit a limited capacity for diagnosing the different modes of failure of generative models across broader application domains. In this paper, we introduce a 3-dimensional evaluation metric,(-Precision, -Recall, Authenticity), that characterizes the fidelity, diversity and generalization performance of any generative model in a domain-agnostic fashion. Our metric unifies statistical divergence measures with precision-recall analysis, enabling sample-and distribution-level diagnoses of model fidelity and diversity. We introduce generalization as an additional, independent dimension (to the fidelity-diversity trade-off) that quantifies the extent to which a model copies training data {\u2014} a crucial performance indicator when modeling sensitive data with requirements on privacy. The three metric components correspond to (interpretable) probabilistic quantities, and are estimated via sample-level binary classification. The sample-level nature of our metric inspires a novel use case which we call model auditing, wherein we judge the quality of individual samples generated by a (black-box) model, discarding low-quality samples and hence improving the overall model performance in a post-hoc manner.",
        "year": 2022,
        "authors": "Ahmed M Alaa and Boris van Breugel and Evgeny Saveliev and Mihaela van der Schaar"
      }
    ],
    "O43_7KUAAAAJ": [
      {
        "title": "Modern baselines for SPARQL semantic parsing",
        "abstract": "In this work, we focus on the task of generating SPARQL queries from natural language questions, which can then be executed on Knowledge Graphs (KGs). We assume that gold entity and relations have been provided, and the remaining task is to arrange them in the right order along with SPARQL vocabulary, and input tokens to produce the correct SPARQL query. Pre-trained Language Models (PLMs) have not been explored in depth on this task so far, so we experiment with BART, T5 and PGNs (Pointer Generator Networks) with BERT embeddings, looking for new baselines in the PLM era for this task, on DBpedia and Wikidata KGs. We show that T5 requires special input tokenisation, but produces state of the art performance on LC-QuAD 1.0 and LC-QuAD 2.0 datasets, and outperforms task-specific models from previous works. Moreover, the methods enable semantic parsing for questions where a part of the \u2026",
        "year": 2022,
        "authors": "Debayan Banerjee and Pranav Ajit Nair* and Jivat Neet Kaur* and Ricardo Usbeck and Chris Biemann"
      },
      {
        "title": "Modeling the data-generating process is necessary for out-of-distribution generalization",
        "abstract": "Recent empirical studies on domain generalization (DG) have shown that DG algorithms that perform well on some distribution shifts fail on others, and no state-of-the-art DG algorithm performs consistently well on all shifts. Moreover, real-world data often has multiple distribution shifts over different attributes; hence we introduce multi-attribute distribution shift datasets and find that the accuracy of existing DG algorithms falls even further. To explain these results, we provide a formal characterization of generalization under multi-attribute shifts using a canonical causal graph. Based on the relationship between spurious attributes and the classification label, we obtain realizations of the canonical causal graph that characterize common distribution shifts and show that each shift entails different independence constraints over observed variables. As a result, we prove that any algorithm based on a single, fixed constraint cannot work well across all shifts, providing theoretical evidence for mixed empirical results on DG algorithms. Based on this insight, we develop Causally Adaptive Constraint Minimization (CACM), an algorithm that uses knowledge about the data-generating process to adaptively identify and apply the correct independence constraints for regularization. Results on fully synthetic, MNIST, small NORB, and Waterbirds datasets, covering binary and multi-valued attributes and labels, show that adaptive dataset-dependent constraints lead to the highest accuracy on unseen domains whereas incorrect constraints fail to do so. Our results demonstrate the importance of modeling the causal relationships inherent in the data-generating process.",
        "year": 2023,
        "authors": "Jivat Neet Kaur and Emre Kiciman and Amit Sharma"
      },
      {
        "title": "LM-CORE: Language models with contextually relevant external knowledge",
        "abstract": "Large transformer-based pre-trained language models have achieved impressive performance on a variety of knowledge-intensive tasks and can capture factual knowledge in their parameters. We argue that storing large amounts of knowledge in the model parameters is sub-optimal given the ever-growing amounts of knowledge and resource requirements. We posit that a more efficient alternative is to provide explicit access to contextually relevant structured knowledge to the model and train it to use that knowledge. We present LM-CORE -- a general framework to achieve this -- that allows \\textit{decoupling} of the language model training from the external knowledge source and allows the latter to be updated without affecting the already trained model. Experimental results show that LM-CORE, having access to external knowledge, achieves significant and robust outperformance over state-of-the-art knowledge-enhanced language models on knowledge probing tasks; can effectively handle knowledge updates; and performs well on two downstream tasks. We also present a thorough error analysis highlighting the successes and failures of LM-CORE.",
        "year": 2022,
        "authors": "Jivat Neet Kaur and Sumit Bhatia and Milan Aggarwal and Rachit Bansal and Balaji Krishnamurthy"
      }
    ],
    "SlZavnIAAAAJ": [
      {
        "title": "Satisfiability Modulo Theories",
        "abstract": "Satisfiability Modulo Theories (SMT) refers to the problem of determining whether a first-order formula is satisfiable with respect to some logical theory. Solvers based on SMT are used as back-end engines in model-checking applications such as bounded, interpolation-based, and predicate-abstraction-based model checking. After a brief illustration of these uses, we survey the predominant techniques for solving SMT problems with an emphasis on the lazy approach, in which a propositional satisfiability (SAT) solver is combined with one or more theory solvers. We discuss the architecture of a lazy SMT solver, give examples of theory solvers, show how to combine such solvers modularly, and mention several extensions of the lazy approach. We also briefly describe the eager approach in which the SMT problem is reduced to a SAT problem. Finally, we discuss how the basic framework for determining \u2026",
        "year": 2021,
        "authors": "Clark Barrett and Roberto Sebastiani and Sanjit A. Seshia and Cesare Tinelli"
      },
      {
        "title": "Introduction to embedded systems: A cyber-physical systems approach",
        "abstract": "An introduction to the engineering principles of embedded systems, with a focus on modeling, design, and analysis of cyber-physical systems. The most visible use of computers and software is processing information for human consumption. The vast majority of computers in use, however, are much less visible. They run the engine, brakes, seatbelts, airbag, and audio system in your car. They digitally encode your voice and construct a radio signal to send it from your cell phone to a base station. They command robots on a factory floor, power generation in a power plant, processes in a chemical plant, and traffic lights in a city. These less visible computers are called embedded systems, and the software they run is called embedded software. The principal challenges in designing and analyzing embedded systems stem from their interaction with physical processes. This book takes a cyber-physical approach to embedded systems, introducing the engineering concepts underlying embedded systems as a technology and as a subject of study. The focus is on modeling, design, and analysis of cyber-physical systems, which integrate computation, networking, and physical processes. The second edition offers two new chapters, several new exercises, and other improvements. The book can be used as a textbook at the advanced undergraduate or introductory graduate level and as a professional reference for practicing engineers and computer scientists. Readers should have some familiarity with machine structures, computer programming, basic discrete mathematics and algorithms, and signals and systems.",
        "year": 2017,
        "authors": "Edward Ashford Lee and Sanjit Arunkumar Seshia"
      },
      {
        "title": "Semantics-aware malware detection",
        "abstract": "A malware detector is a system that attempts to determine whether a program has malicious intent. In order to evade detection, malware writers (hackers) frequently use obfuscation to morph malware. Malware detectors that use a pattern-matching approach (such as commercial virus scanners) are susceptible to obfuscations used by hackers. The fundamental deficiency in the pattern-matching approach to malware detection is that it is purely syntactic and ignores the semantics of instructions. In this paper, we present a malware-detection algorithm that addresses this deficiency by incorporating instruction semantics to detect malicious program traits. Experimental evaluation demonstrates that our malware-detection algorithm can detect variants of malware with a relatively low run-time overhead. Moreover our semantics-aware malware detection algorithm is resilient to common obfuscations used by hackers.",
        "year": 2005,
        "authors": "Mihai Christodorescu and Somesh Jha and Sanjit A Seshia and Dawn Song and Randal E Bryant"
      }
    ],
    "r44N6h8AAAAJ": [
      {
        "title": "Maximizing social influence in nearly optimal time",
        "abstract": "Diffusion is a fundamental graph process, underpinning such phenomena as epidemic disease contagion and the spread of innovation by word-of-mouth. We address the algorithmic problem of finding a set of k initial seed nodes in a network so that the expected size of the resulting cascade is maximized, under the standard independent cascade model of network diffusion. Runtime is a primary consideration for this problem due to the massive size of the relevant input networks.We provide a fast algorithm for the influence maximization problem, obtaining the near-optimal approximation factor of , for any \u220a > 0, in time O((m + n)\u220a\u22123 log n). Our algorithm is runtime-optimal (up to a logarithmic factor) and substantially improves upon the previously best-known algorithms which run in time \u03a9(mnk \u00b7 POLY(\u220a\u22121)). Furthermore, our algorithm can be modified to allow early termination: if it is terminated after O(\u03b2(m + n) logn \u2026",
        "year": 2014,
        "authors": "Christian Borgs and Michael Brautbar and Jennifer Chayes and Brendan Lucier"
      },
      {
        "title": "Combinatorial auctions via posted prices",
        "abstract": "We study anonymous posted price mechanisms for combinatorial auctions in a Bayesian framework. In a posted price mechanism, item prices are posted, then the consumers approach the seller sequentially in an arbitrary order, each purchasing her favorite bundle from among the unsold items at the posted prices. These mechanisms are simple, transparent and trivially dominant strategy incentive compatible (DSIC).We show that when agent preferences are fractionally subadditive (which includes all submodular functions), there always exist prices that, in expectation, obtain at least half of the optimal welfare. Our result is constructive: given black-box access to a combinatorial auction algorithm A, sample access to the prior distribution, and appropriate query access to the sampled valuations, one can compute, in polytime, prices that guarantee at least half of the expected welfare of A. As a corollary, we obtain the \u2026",
        "year": 2014,
        "authors": "Michal Feldman and Nick Gravin and Brendan Lucier"
      },
      {
        "title": "A simple and approximately optimal mechanism for an additive buyer",
        "abstract": "We consider a monopolist seller with n heterogeneous items, facing a single buyer. The buyer has a value for each item drawn independently according to (non-identical) distributions, and her value for a set of items is additive. The seller aims to maximize his revenue.We suggest using the a priori better of two simple pricing methods: selling the items separately, each at its optimal price, and bundling together, in which the entire set of items is sold as one bundle at its optimal price. We show that for any distribution, this mechanism achieves a constant-factor approximation to the optimal revenue. Beyond its simplicity, this is the first computationally tractable mechanism to obtain a constant-factor approximation for this multi-parameter problem. We additionally discuss extensions to multiple buyers and to valuations that are correlated across items.",
        "year": 2020,
        "authors": "Moshe Babaioff and Nicole Immorlica and Brendan Lucier and S Matthew Weinberg"
      }
    ],
    "0bwP0i4AAAAJ": [
      {
        "title": "Immune correlates analysis of the mRNA-1273 COVID-19 vaccine efficacy clinical trial",
        "abstract": "In the coronavirus efficacy (COVE) phase 3 clinical trial, vaccine recipients were assessed for neutralizing and binding antibodies as correlates of risk for COVID-19 disease and as correlates of protection. These immune markers were measured at the time of second vaccination and 4 weeks later, with values reported in standardized World Health Organization international units. All markers were inversely associated with COVID-19 risk and directly associated with vaccine efficacy. Vaccine recipients with postvaccination 50% neutralization titers 10, 100, and 1000 had estimated vaccine efficacies of 78% (95% confidence interval, 54 to 89%), 91% (87 to 94%), and 96% (94 to 98%), respectively. These results help define immune marker correlates of protection and may guide approval decisions for messenger RNA (mRNA) COVID-19 vaccines and other COVID-19 vaccines.",
        "year": 2022,
        "authors": "Peter B Gilbert and David C Montefiori and Adrian B McDermott and Youyi Fong and David Benkeser and Weiping Deng and Honghong Zhou and Christopher R Houchens and Karen Martins and Lakshmi Jayashankar and Flora Castellino and Britta Flach and Bob C Lin and Sarah O\u2019Connell and Charlene McDanal and Amanda Eaton and Marcella Sarzotti-Kelsoe and Yiwen Lu and Chenchen Yu and Bhavesh Borate and Lars WP van der Laan and Nima S Hejazi and Chuong Huynh and Jacqueline Miller and Hana M El Sahly and Lindsey R Baden and Mira Baron and Luis De La Cruz and Cynthia Gay and Spyros Kalams and Colleen F Kelley and Michele P Andrasik and James G Kublin and Lawrence Corey and Kathleen M Neuzil and Lindsay N Carpp and Rolando Pajon and Dean Follmann and Ruben O Donis and Richard A Koup and Immune Assays Team \u00a7 and Moderna and Inc. Team \u00a7 and Coronavirus Vaccine Prevention Network (CoVPN)/Coronavirus Efficacy (COVE) Team \u00a7 and United States Government (USG)/CoVPN Biostatistics Team \u00a7"
      },
      {
        "title": "Immune correlates analysis of the PREVENT-19 COVID-19 vaccine efficacy clinical trial",
        "abstract": "In the PREVENT-19 phase 3 trial of the NVX-CoV2373 vaccine (NCT04611802), anti-spike binding IgG concentration (spike IgG), anti-RBD binding IgG concentration (RBD IgG), and pseudovirus 50% neutralizing antibody titer (nAb ID50) measured two weeks post-dose two are assessed as correlates of risk and as correlates of protection against COVID-19. Analyses are conducted in the U.S. cohort of baseline SARS-CoV-2 negative per-protocol participants using a case-cohort design that measures the markers from all 12 vaccine recipient breakthrough COVID-19 cases starting 7 days post antibody measurement and from 639 vaccine recipient non-cases. All markers are inversely associated with COVID-19 risk and directly associated with vaccine efficacy. In vaccine recipients with nAb ID50 titers of 50, 100, and 7230 international units (IU50)/ml, vaccine efficacy estimates are 75.7% (49.8%, 93.2%), 81.7% (66.3 \u2026",
        "year": 2023,
        "authors": "Youyi Fong and Yunda Huang and David Benkeser and Lindsay N Carpp and Germ\u00e1n \u00c1\u00f1ez and Wayne Woo and Alice McGarry and Lisa M Dunkle and Iksung Cho and Christopher R Houchens and Karen Martins and Lakshmi Jayashankar and Flora Castellino and Christos J Petropoulos and Andrew Leith and Deanne Haugaard and Bill Webb and Yiwen Lu and Chenchen Yu and Bhavesh Borate and Lars WP van der Laan and Nima S Hejazi and April K Randhawa and Michele P Andrasik and James G Kublin and Julia Hutter and Maryam Keshtkar-Jahromi and Tatiana H Beresnev and Lawrence Corey and Kathleen M Neuzil and Dean Follmann and Julie A Ake and Cynthia L Gay and Karen L Kotloff and Richard A Koup and Ruben O Donis and Peter B Gilbert and Immune Assays Team and Coronavirus Vaccine Prevention Network (CoVPN)/2019nCoV-301 Principal Investigators and Study Team and United States Government (USG)/CoVPN Biostatistics Team"
      },
      {
        "title": "Immune correlates analysis of the ENSEMBLE single Ad26. COV2. S dose vaccine efficacy clinical trial",
        "abstract": "Measuring immune correlates of disease acquisition and protection in the context of a clinical trial is a prerequisite for improved vaccine design. We analysed binding and neutralizing antibody measurements 4 weeks post vaccination as correlates of risk of moderate to severe-critical COVID-19 through 83\u2009d post vaccination in the phase 3, double-blind placebo-controlled phase of ENSEMBLE, an international randomized efficacy trial of a single dose of Ad26.COV2.S. We also evaluated correlates of protection in the trial cohort. Of the three antibody immune markers we measured, we found most support for 50% inhibitory dilution (ID50) neutralizing antibody titre as a correlate of risk and of protection. The outcome hazard ratio was 0.49 (95% confidence interval 0.29, 0.81; P\u2009=\u20090.006) per 10-fold increase in ID50; vaccine efficacy was 60% (43%, 72%) at non-quantifiable ID50 (<2.7\u2009IU50\u2009ml\u22121) and increased to \u2026",
        "year": 2022,
        "authors": "Youyi Fong and Adrian B McDermott and David Benkeser and Sanne Roels and Daniel J Stieh and An Vandebosch and Mathieu Le Gars and Griet A Van Roey and Christopher R Houchens and Karen Martins and Lakshmi Jayashankar and Flora Castellino and Obrimpong Amoa-Awua and Manjula Basappa and Britta Flach and Bob C Lin and Christopher Moore and Mursal Naisan and Muhammed Naqvi and Sandeep Narpala and Sarah O\u2019Connell and Allen Mueller and Leo Serebryannyy and Mike Castro and Jennifer Wang and Christos J Petropoulos and Alex Luedtke and Ollivier Hyrien and Yiwen Lu and Chenchen Yu and Bhavesh Borate and Lars WP van Der Laan and Nima S Hejazi and Avi Kenny and Marco Carone and Daniel N Wolfe and Jerald Sadoff and Glenda E Gray and Beatriz Grinsztejn and Paul A Goepfert and Susan J Little and Leonardo Paiva de Sousa and Rebone Maboa and April K Randhawa and Michele P Andrasik and Jenny Hendriks and Carla Truyers and Frank Struyf and Hanneke Schuitemaker and Macaya Douoguih and James G Kublin and Lawrence Corey and Kathleen M Neuzil and Lindsay N Carpp and Dean Follmann and Peter B Gilbert and Richard A Koup and Ruben O Donis and Immune Assays Team and Coronavirus Vaccine Prevention Network (CoVPN)/ENSEMBLE Team and United States Government (USG)/CoVPN Biostatistics Team"
      }
    ],
    "B8wslVsAAAAJ": [
      {
        "title": "Gpt-4 technical report",
        "abstract": "We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.",
        "year": 2023,
        "authors": "Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Sim\u00f3n Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and \u0141ukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and \u0141ukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew"
      },
      {
        "title": "Categorical reparameterization with gumbel-softmax",
        "abstract": "Categorical variables are a natural choice for representing discrete structure in the world. However, stochastic neural networks rarely use categorical latent variables due to the inability to backpropagate through samples. In this work, we present an efficient gradient estimator that replaces the non-differentiable sample from a categorical distribution with a differentiable sample from a novel Gumbel-Softmax distribution. This distribution has the essential property that it can be smoothly annealed into a categorical distribution. We show that our Gumbel-Softmax estimator outperforms state-of-the-art gradient estimators on structured output prediction and unsupervised generative modeling tasks with categorical latent variables, and enables large speedups on semi-supervised classification.",
        "year": 2016,
        "authors": "Eric Jang and Shixiang Gu and Ben Poole"
      },
      {
        "title": "Large language models are zero-shot reasoners",
        "abstract": "Pretrained large language models (LLMs) are widely used in many sub-fields of natural language processing (NLP) and generally known as excellent few-shot learners with task-specific exemplars. Notably, chain of thought (CoT) prompting, a recent technique for eliciting complex multi-step reasoning through step-by-step answer examples, achieved the state-of-the-art performances in arithmetics and symbolic reasoning, difficult system-2 tasks that do not follow the standard scaling laws for LLMs. While these successes are often attributed to LLMs' ability for few-shot learning, we show that LLMs are decent zero-shot reasoners by simply adding``Let's think step by step''before each answer. Experimental results demonstrate that our Zero-shot-CoT, using the same single prompt template, significantly outperforms zero-shot LLM performances on diverse benchmark reasoning tasks including arithmetics (MultiArith, GSM8K, AQUA-RAT, SVAMP), symbolic reasoning (Last Letter, Coin Flip), and other logical reasoning tasks (Date Understanding, Tracking Shuffled Objects), without any hand-crafted few-shot examples, eg increasing the accuracy on MultiArith from 17.7% to 78.7% and GSM8K from 10.4% to 40.7% with large-scale InstructGPT model (text-davinci-002), as well as similar magnitudes of improvements with another off-the-shelf large model, 540B parameter PaLM. The versatility of this single prompt across very diverse reasoning tasks hints at untapped and understudied fundamental zero-shot capabilities of LLMs, suggesting high-level, multi-task broad cognitive capabilities may be extracted by simple prompting. We hope our work not only \u2026",
        "year": 2022,
        "authors": "Takeshi Kojima and Shixiang Shane Gu and Machel Reid and Yutaka Matsuo and Yusuke Iwasawa"
      }
    ],
    "zS3z8UgAAAAJ": [
      {
        "title": "Probing exchange pathways in one-dimensional aggregates with super-resolution microscopy",
        "abstract": "Supramolecular fibers are prominent structures in biology and chemistry. A quantitative understanding of molecular exchange pathways in these one-dimensional aggregates was obtained by a combination of super-resolution stochastic optical reconstruction microscopy and stochastic simulation. The potential of this methodology is demonstrated with a set of well-defined synthetic building blocks that self-assemble into supramolecular fibrils. Previous ensemble measurements hid all molecular phenomena underpinning monomer exchange, but the molecular pathway determined from single-aggregate studies revealed unexpected homogeneous exchange along the polymer backbone. These results pave the way for experimental investigation of the structure and exchange pathways of synthetic and natural supramolecular fibers.",
        "year": 2014,
        "authors": "Lorenzo Albertazzi and Daan Van Der Zwaag and Christianus MA Leenders and Robert Fitzner and Remco W Van Der Hofstad and EW Meijer"
      },
      {
        "title": "Scale-free networks well done",
        "abstract": "We bring rigor to the vibrant activity of detecting power laws in empirical degree distributions in real-world networks. We first provide a rigorous definition of power-law distributions, equivalent to the definition of regularly varying distributions that are widely used in statistics and other fields. This definition allows the distribution to deviate from a pure power law arbitrarily but without affecting the power-law tail exponent. We then identify three estimators of these exponents that are proven to be statistically consistent\u2014that is, converging to the true value of the exponent for any regularly varying distribution\u2014and that satisfy some additional niceness requirements. In contrast to estimators that are currently popular in network science, the estimators considered here are based on fundamental results in extreme value theory, and so are the proofs of their consistency. Finally, we apply these estimators to a representative \u2026",
        "year": 2019,
        "authors": "Ivan Voitalov and Pim Van Der Hoorn and Remco Van Der Hofstad and Dmitri Krioukov"
      }
    ],
    "3XLQbL8AAAAJ": [
      {
        "title": "Linear matrix inequalities in system and control theory",
        "abstract": "The basic topic of this book is solving problems from system and control theory using convex optimization. We show that a wide variety of problems arising in system and control theory can be reduced to a handful of standard convex and quasiconvex optimization problems that involve matrix inequalities. For a few special cases there are \u201canalytic solutions\u201d to these problems, but our main point is that they can be solved numerically in all cases. These standard problems can be solved in polynomial-time (by, e.g., the ellipsoid algorithm of Shor, Nemirovskii, and Yudin), and so are tractable, at least in a theoretical sense. Recently developed interior-point methods for these standard problems have been found to be extremely efficient in practice. Therefore, we consider the original problems from system and control theory as solved.This book is primarily intended for the researcher in system and control theory, but can \u2026",
        "year": 1994,
        "authors": "Stephen Boyd and Laurent El Ghaoui and Eric Feron and Venkataramanan Balakrishnan"
      },
      {
        "title": "Robust optimization",
        "abstract": "To be uncertain is to be uncomfortable, but to be certain is to be ridiculous. Chinese proverb",
        "year": 2009,
        "authors": "Aharon Ben-Tal and Arkadi Nemirovski and Laurent El Ghaoui"
      },
      {
        "title": "Theoretically principled trade-off between robustness and accuracy",
        "abstract": "We identify a trade-off between robustness and accuracy that serves as a guiding principle in the design of defenses against adversarial examples. Although this problem has been widely studied empirically, much remains unknown concerning the theory underlying this trade-off. In this work, we decompose the prediction error for adversarial examples (robust error) as the sum of the natural (classification) error and boundary error, and provide a differentiable upper bound using the theory of classification-calibrated loss, which is shown to be the tightest possible upper bound uniform over all probability distributions and measurable predictors. Inspired by our theoretical analysis, we also design a new defense method, TRADES, to trade adversarial robustness off against accuracy. Our proposed algorithm performs well experimentally in real-world datasets. The methodology is the foundation of our entry to the NeurIPS 2018 Adversarial Vision Challenge in which we won the 1st place out of 2,000 submissions, surpassing the runner-up approach by 11.41% in terms of mean L_2 perturbation distance.",
        "year": 2019,
        "authors": "Hongyang Zhang and Yaodong Yu and Jiantao Jiao and Eric Xing and Laurent El Ghaoui and Michael Jordan"
      }
    ],
    "FFWXLHUAAAAJ": [
      {
        "title": "Trust Region Policy Optimization",
        "abstract": "In this article, we describe a method for optimizing control policies, with guaranteed monotonic improvement. By making several approximations to the theoretically-justified scheme, we develop a practical algorithm, called Trust Region Policy Optimization (TRPO). This algorithm is effective for optimizing large nonlinear policies such as neural networks. Our experiments demonstrate its robust performance on a wide variety of tasks: learning simulated robotic swimming, hopping, and walking gaits; and playing Atari games using images of the screen as input. Despite its approximations that deviate from the theory, TRPO tends to give monotonic improvement, with little tuning of hyperparameters.",
        "year": 2015,
        "authors": "John Schulman and Sergey Levine and Philipp Moritz and Michael I. Jordan and Peter Abbeel"
      },
      {
        "title": "High-dimensional continuous control using generalized advantage estimation",
        "abstract": "Policy gradient methods are an appealing approach in reinforcement learning because they directly optimize the cumulative reward and can straightforwardly be used with nonlinear function approximators such as neural networks. The two main challenges are the large number of samples typically required, and the difficulty of obtaining stable and steady improvement despite the nonstationarity of the incoming data. We address the first challenge by using value functions to substantially reduce the variance of policy gradient estimates at the cost of some bias, with an exponentially-weighted estimator of the advantage function that is analogous to TD(lambda). We address the second challenge by using trust region optimization procedure for both the policy and the value function, which are represented by neural networks. Our approach yields strong empirical results on highly challenging 3D locomotion tasks, learning running gaits for bipedal and quadrupedal simulated robots, and learning a policy for getting the biped to stand up from starting out lying on the ground. In contrast to a body of prior work that uses hand-crafted policy representations, our neural network policies map directly from raw kinematics to joint torques. Our algorithm is fully model-free, and the amount of simulated experience required for the learning tasks on 3D bipeds corresponds to 1-2 weeks of real time.",
        "year": 2015,
        "authors": "John Schulman and Philipp Moritz and Sergey Levine and Michael Jordan and Pieter Abbeel"
      },
      {
        "title": "Ray: A distributed framework for emerging {AI} applications",
        "abstract": "The next generation of AI applications will continuously interact with the environment and learn from these interactions. These applications impose new and demanding systems requirements, both in terms of performance and flexibility. In this paper, we consider these requirements and present Ray\u2014a distributed system to address them. Ray implements a unified interface that can express both task-parallel and actor-based computations, supported by a single dynamic execution engine. To meet the performance requirements, Ray employs a distributed scheduler and a distributed and fault-tolerant store to manage the system\u2019s control state. In our experiments, we demonstrate scaling beyond 1.8 million tasks per second and better performance than existing specialized systems for several challenging reinforcement learning applications.",
        "year": 2018,
        "authors": "Philipp Moritz and Robert Nishihara and Stephanie Wang and Alexey Tumanov and Richard Liaw and Eric Liang and Melih Elibol and Zongheng Yang and William Paul and Michael I Jordan and Ion Stoica"
      }
    ],
    "tsXh_hwAAAAJ": [
      {
        "title": "Inverse reward design",
        "abstract": "Autonomous agents optimize the reward function we give them. What they don't know is how hard it is for us to design a reward function that actually captures what we want. When designing the reward, we might think of some specific training scenarios, and make sure that the reward will lead to the right behavior in those scenarios. Inevitably, agents encounter new scenarios (eg, new types of terrain) where optimizing that same reward may lead to undesired behavior. Our insight is that reward functions are merely observations about what the designer actually wants, and that they should be interpreted in the context in which they were designed. We introduce inverse reward design (IRD) as the problem of inferring the true objective based on the designed reward and the training MDP. We introduce approximate methods for solving IRD problems, and use their solution to plan risk-averse behavior in test MDPs. Empirical results suggest that this approach can help alleviate negative side effects of misspecified reward functions and mitigate reward hacking.",
        "year": 2016,
        "authors": "Dylan Hadfield-Menell and Smitha Milli and Pieter Abbeel and Stuart Russell and Anca Dragan"
      },
      {
        "title": "The Social Cost of Strategic Classification",
        "abstract": "Consequential decision-making typically incentivizes individuals to behave strategically, tailoring their behavior to the specifics of the decision rule. A long line of work has therefore sought to counteract strategic behavior by designing more conservative decision boundaries in an effort to increase robustness to the effects of strategic covariate shift.We show that these efforts benefit the institutional decision maker at the expense of the individuals being classified. Introducing a notion of social burden, we prove that any increase in institutional utility necessarily leads to a corresponding increase in social burden. Moreover, we show that the negative externalities of strategic classification can disproportionately harm disadvantaged groups in the population.Our results highlight that strategy-robustness must be weighed against considerations of social welfare and fairness.",
        "year": 2019,
        "authors": "Smitha Milli and John Miller and Anca D Dragan and Moritz Hardt"
      },
      {
        "title": "Reward-rational (implicit) choice: A unifying formalism for reward learning",
        "abstract": "It is often difficult to hand-specify what the correct reward function is for a task, so researchers have instead aimed to learn reward functions from human behavior or feedback. The types of behavior interpreted as evidence of the reward function have expanded greatly in recent years. We've gone from demonstrations, to comparisons, to reading into the information leaked when the human is pushing the robot away or turning it off. And surely, there is more to come. How will a robot make sense of all these diverse types of behavior? Our key observation is that different types of behavior can be interpreted in a single unifying formalism-as a reward-rational choice that the human is making, often implicitly. We use this formalism to survey prior work through a unifying lens, and discuss its potential use as a recipe for interpreting new sources of information that are yet to be uncovered.",
        "year": 2020,
        "authors": "Hong Jun Jeon and Smitha Milli and Anca D Dragan"
      }
    ],
    "DpLFv4gAAAAJ": [
      {
        "title": "Xgboost: A scalable tree boosting system",
        "abstract": "Tree boosting is a highly effective and widely used machine learning method. In this paper, we describe a scalable end-to-end tree boosting system called XGBoost, which is used widely by data scientists to achieve state-of-the-art results on many machine learning challenges. We propose a novel sparsity-aware algorithm for sparse data and weighted quantile sketch for approximate tree learning. More importantly, we provide insights on cache access patterns, data compression and sharding to build a scalable tree boosting system. By combining these insights, XGBoost scales beyond billions of examples using far fewer resources than existing systems.",
        "year": 2016,
        "authors": "Tianqi Chen and Carlos Guestrin"
      },
      {
        "title": "\" Why should i trust you?\" Explaining the predictions of any classifier",
        "abstract": "Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by \u2026",
        "year": 2016,
        "authors": "Marco Tulio Ribeiro and Sameer Singh and Carlos Guestrin"
      },
      {
        "title": "Cost-effective outbreak detection in networks",
        "abstract": "Given a water distribution network, where should we place sensors toquickly detect contaminants? Or, which blogs should we read to avoid missing important stories?.These seemingly different problems share common structure: Outbreak detection can be modeled as selecting nodes (sensor locations, blogs) in a network, in order to detect the spreading of a virus or information asquickly as possible. We present a general methodology for near optimal sensor placement in these and related problems. We demonstrate that many realistic outbreak detection objectives (e.g., detection likelihood, population affected) exhibit the property of \"submodularity\". We exploit submodularity to develop an efficient algorithm that scales to large problems, achieving near optimal placements, while being 700 times faster than a simple greedy algorithm. We also derive online bounds on the quality of the placements obtained by any \u2026",
        "year": 2007,
        "authors": "Jure Leskovec and Andreas Krause and Carlos Guestrin and Christos Faloutsos and Jeanne VanBriesen and Natalie Glance"
      }
    ],
    "gzpWXPcAAAAJ": [
      {
        "title": "Sources of bias in artificial intelligence that perpetuate healthcare disparities\u2014A global review",
        "abstract": "Background While artificial intelligence (AI) offers possibilities of advanced clinical prediction and decision-making in healthcare, models trained on relatively homogeneous datasets, and populations poorly-representative of underlying diversity, limits generalisability and risks biased AI-based decisions. Here, we describe the landscape of AI in clinical medicine to delineate population and data-source disparities.   Methods We performed a scoping review of clinical papers published in PubMed in 2019 using AI techniques. We assessed differences in dataset country source, clinical specialty, and author nationality, sex, and expertise. A manually tagged subsample of PubMed articles was used to train a model, leveraging transfer-learning techniques (building upon an existing BioBERT model) to predict eligibility for inclusion (original, human, clinical AI literature). Of all eligible articles, database country source and clinical specialty were manually labelled. A BioBERT-based model predicted first/last author expertise. Author nationality was determined using corresponding affiliated institution information using Entrez Direct. And first/last author sex was evaluated using the Gendarize.io API.   Results Our search yielded 30,576 articles, of which 7,314 (23.9%) were eligible for further analysis. Most databases came from the US (40.8%) and China (13.7%). Radiology was the most represented clinical specialty (40.4%), followed by pathology (9.1%). Authors were primarily from either China (24.0%) or the US (18.4%). First and last authors were predominately data experts (i.e., statisticians) (59.6% and 53.9% respectively) rather than clinicians. And the \u2026",
        "year": 2022,
        "authors": "Leo Anthony Celi and Jacqueline Cellini and Marie-Laure Charpignon and Edward Christopher Dee and Franck Dernoncourt and Rene Eber and William Greig Mitchell and Lama Moukheiber and Julian Schirmer and Julia Situ and Joseph Paguio and Joel Park and Judy Gichoya Wawira and Seth Yao"
      },
      {
        "title": "Analysis of discrepancies between pulse oximetry and arterial oxygen saturation measurements by race and ethnicity and association with organ dysfunction and mortality",
        "abstract": "Discrepancies in oxygen saturation measured by pulse oximetry (Spo2), when compared with arterial oxygen saturation (Sao2) measured by arterial blood gas (ABG), may differentially affect patients according to race and ethnicity. However, the association of these disparities with health outcomes is unknown.To examine racial and ethnic discrepancies between Sao2and Spo2measures and their associations with clinical outcomes.This multicenter, retrospective, cross-sectional study included 3 publicly available electronic health record (EHR) databases (ie, the Electronic Intensive Care Unit\u2013Clinical Research Database and Medical Information Mart for Intensive Care III and IV) as well as Emory Healthcare (2014-2021) and Grady Memorial (2014-2020) databases, spanning 215 hospitals and 382 ICUs. From 141\u202f600 hospital encounters with recorded ABG \u2026",
        "year": 2021,
        "authors": "An-Kwok Ian Wong and Marie Charpignon and Han Kim and Christopher Josef and Anne AH De Hond and Jhalique Jane Fojas and Azade Tabaie and Xiaoli Liu and Eduardo Mireles-Cabodevila and Leandro Carvalho and Rishikesan Kamaleswaran and RWMA Madushani and Lasith Adhikari and Andre L Holder and Ewout W Steyerberg and Timothy G Buchman and Mary E Lough and Leo Anthony Celi"
      },
      {
        "title": "Modeling between-population variation in COVID-19 dynamics in Hubei, Lombardy, and New York City",
        "abstract": "As the COVID-19 pandemic continues, formulating targeted policy interventions that are informed by differential severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) transmission dynamics will be of vital importance to national and regional governments. We develop an individual-level model for SARS-CoV-2 transmission that accounts for location-dependent distributions of age, household structure, and comorbidities. We use these distributions together with age-stratified contact matrices to instantiate specific models for Hubei, China; Lombardy, Italy; and New York City, United States. Using data on reported deaths to obtain a posterior distribution over unknown parameters, we infer differences in the progression of the epidemic in the three locations. We also examine the role of transmission due to particular age groups on total infections and deaths. The effect of limiting contacts by a particular age \u2026",
        "year": 2020,
        "authors": "Bryan Wilder and Marie Charpignon and Jackson A Killian and Han-Ching Ou and Aditya Mate and Shahin Jabbari and Andrew Perrault and Angel N Desai and Milind Tambe and Maimuna S Majumder"
      }
    ],
    "HBztuGIAAAAJ": [
      {
        "title": "InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets",
        "abstract": "This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods.",
        "year": 2016,
        "authors": "Xi Chen and Yan Duan and Rein Houthooft and John Schulman and Ilya Sutskever and Pieter Abbeel"
      },
      {
        "title": "Benchmarking Deep Reinforcement Learning for Continuous Control",
        "abstract": "Recently, researchers have made significant progress combining the advances in deep learning for learning feature representations with reinforcement learning. Some notable examples include training agents to play Atari games based on raw pixel data and to acquire advanced manipulation skills using raw sensory inputs. However, it has been difficult to quantify progress in the domain of continuous control due to the lack of a commonly adopted benchmark. In this work, we present a benchmark suite of continuous control tasks, including classic tasks like cart-pole swing-up, tasks with very high state and action dimensionality such as 3D humanoid locomotion, tasks with partial observations, and tasks with hierarchical structure. We report novel findings based on the systematic evaluation of a range of implemented reinforcement learning algorithms. Both the benchmark and reference implementations are released at https://github. com/rllab/rllab in order to facilitate experimental reproducibility and to encourage adoption by other researchers.",
        "year": 2016,
        "authors": "Yan Duan and Xi Chen and Rein Houthooft and John Schulman and Pieter Abbeel"
      },
      {
        "title": "VIME: Variational Information Maximizing Exploration",
        "abstract": "Scalable and effective exploration remains a key challenge in reinforcement learning (RL). While there are methods with optimality guarantees in the setting of discrete state and action spaces, these methods cannot be applied in high-dimensional deep RL scenarios. As such, most contemporary RL relies on simple heuristics such as epsilon-greedy exploration or adding Gaussian noise to the controls. This paper introduces Variational Information Maximizing Exploration (VIME), an exploration strategy based on maximization of information gain about the agent's belief of environment dynamics. We propose a practical implementation, using variational inference in Bayesian neural networks which efficiently handles continuous state and action spaces. VIME modifies the MDP reward function, and can be applied with several different underlying RL algorithms. We demonstrate that VIME achieves significantly better performance compared to heuristic exploration methods across a variety of continuous control tasks and algorithms, including tasks with very sparse rewards.",
        "year": 2016,
        "authors": "Rein Houthooft and Xi Chen and Yan Duan and John Schulman and Filip De Turck and Pieter Abbeel"
      }
    ],
    "l-la0GQAAAAJ": [
      {
        "title": "In-datacenter performance analysis of a tensor processing unit",
        "abstract": "Many architects believe that major improvements in cost-energy-performance must now come from domain-specific hardware. This paper evaluates a custom ASIC---called a Tensor Processing Unit (TPU) --- deployed in datacenters since 2015 that accelerates the inference phase of neural networks (NN). The heart of the TPU is a 65,536 8-bit MAC matrix multiply unit that offers a peak throughput of 92 TeraOps/second (TOPS) and a large (28 MiB) software-managed on-chip memory. The TPU's deterministic execution model is a better match to the 99th-percentile response-time requirement of our NN applications than are the time-varying optimizations of CPUs and GPUs that help average throughput more than guaranteed latency. The lack of such features helps explain why, despite having myriad MACs and a big memory, the TPU is relatively small and low power. We compare the TPU to a server-class Intel \u2026",
        "year": 2017,
        "authors": "Norman P Jouppi and Cliff Young and Nishant Patil and David Patterson and Gaurav Agrawal and Raminder Bajwa and Sarah Bates and Suresh Bhatia and Nan Boden and Al Borchers and Rick Boyle and Pierre-luc Cantin and Clifford Chao and Chris Clark and Jeremy Coriell and Mike Daley and Matt Dau and Jeffrey Dean and Ben Gelb and Tara Vazir Ghaemmaghami and Rajendra Gottipati and William Gulland and Robert Hagmann and C Richard Ho and Doug Hogberg and John Hu and Robert Hundt and Dan Hurt and Julian Ibarz and Aaron Jaffey and Alek Jaworski and Alexander Kaplan and Harshit Khaitan and Daniel Killebrew and Andy Koch and Naveen Kumar and Steve Lacy and James Laudon and James Law and Diemthu Le and Chris Leary and Zhuyuan Liu and Kyle Lucke and Alan Lundin and Gordon MacKean and Adriana Maggiore and Maire Mahony and Kieran Miller and Rahul Nagarajan and Ravi Narayanaswami and Ray Ni and Kathy Nix and Thomas Norrie and Mark Omernick and Narayana Penukonda and Andy Phelps and Jonathan Ross and Matt Ross and Amir Salek and Emad Samadiani and Chris Severn and Gregory Sizikov and Matthew Snelham and Jed Souter and Dan Steinberg and Andy Swing and Mercedes Tan and Gregory Thorson and Bo Tian and Horia Toma and Erick Tuttle and Vijay Vasudevan and Richard Walter and Walter Wang and Eric Wilcox and Doe Hyun Yoon"
      },
      {
        "title": "Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection",
        "abstract": "We describe a learning-based approach to hand-eye coordination for robotic grasping from monocular images. To learn hand-eye coordination for grasping, we trained a large convolutional neural network to predict the probability that task-space motion of the gripper will result in successful grasps, using only monocular camera images independent of camera calibration or the current robot pose. This requires the network to observe the spatial relationship between the gripper and objects in the scene, thus learning hand-eye coordination. We then use this network to servo the gripper in real time to achieve successful grasps. We describe two large-scale experiments that we conducted on two separate robotic platforms. In the first experiment, about 800,000 grasp attempts were collected over the course of two months, using between 6 and 14 robotic manipulators at any given time, with differences in camera \u2026",
        "year": 2018,
        "authors": "Sergey Levine and Peter Pastor and Alex Krizhevsky and Julian Ibarz and Deirdre Quillen"
      },
      {
        "title": "Do as i can, not as i say: Grounding language in robotic affordances",
        "abstract": "Large language models can encode a wealth of semantic knowledge about the world. Such knowledge could be extremely useful to robots aiming to act upon high-level, temporally extended instructions expressed in natural language. However, a significant weakness of language models is that they lack real-world experience, which makes it difficult to leverage them for decision making within a given embodiment. For example, asking a language model to describe how to clean a spill might result in a reasonable narrative, but it may not be applicable to a particular agent, such as a robot, that needs to perform this task in a particular environment. We propose to provide real-world grounding by means of pretrained skills, which are used to constrain the model to propose natural language actions that are both feasible and contextually appropriate. The robot can act as the language model\u2019s \u201chands and eyes,\u201d while the language model supplies high-level semantic knowledge about the task. We show how low-level skills can be combined with large language models so that the language model provides high-level knowledge about the procedures for performing complex and temporally extended instructions, while value functions associated with these skills provide the grounding necessary to connect this knowledge to a particular physical environment. We evaluate our method on a number of real-world robotic tasks, where we show the need for real-world grounding and that this approach is capable of completing long-horizon, abstract, natural language instructions on a mobile manipulator. The project\u2019s website, video, and open source can be \u2026",
        "year": 2023,
        "authors": "Anthony Brohan and Yevgen Chebotar and Chelsea Finn and Karol Hausman and Alexander Herzog and Daniel Ho and Julian Ibarz and Alex Irpan and Eric Jang and Ryan Julian and Dmitry Kalashnikov and Sergey Levine and Yao Lu and Carolina Parada and Kanishka Rao and Pierre Sermanet and Alexander T Toshev and Vincent Vanhoucke and Fei Xia and Ted Xiao and Peng Xu and Mengyuan Yan and Noah Brown and Michael Ahn and Omar Cortes and Nicolas Sievers and Clayton Tan and Sichun Xu and Diego Reyes and Jarek Rettinghouse and Jornell Quiambao and Peter Pastor and Linda Luu and Kuang-Huei Lee and Yuheng Kuang and Sally Jesmonth and Nikhil J Joshi and Kyle Jeffrey and Rosario Jauregui Ruano and Jasmine Hsu and Keerthana Gopalakrishnan and Byron David and Andy Zeng and Chuyuan Kelly Fu"
      }
    ],
    "bLUllHEAAAAJ": [
      {
        "title": "Reading Digits in Natural Images with Unsupervised Feature Learning",
        "abstract": "Detecting and reading text from natural images is a hard computer vision task that is central to a variety of emerging applications. Related problems like document character recognition have been widely studied by computer vision and machine learning researchers and are virtually solved for practical applications like reading handwritten digits. Reliably recognizing characters in more complex scenes like photographs, however, is far more difficult: the best existing methods lag well behind human performance on the same tasks. In this paper we attack the problem of recognizing digits in a real application using unsupervised feature learning methods: reading house numbers from street level photos. To this end, we introduce a new benchmark dataset for research use containing over 600,000 labeled digits cropped from Street View images. We then demonstrate the difficulty of recognizing these digits when the problem is approached with hand-designed features. Finally, we employ variants of two recently proposed unsupervised feature learning methods and find that they are convincingly superior on our benchmarks.",
        "year": 2011,
        "authors": "Yuval Netzer and Tao Wang and Adam Coates and Alessandro Bissacco and Bo Wu and Andrew Y Ng"
      },
      {
        "title": "An analysis of single-layer networks in unsupervised feature learning",
        "abstract": "A great deal of research has focused on algorithms for learning features from unlabeled data. Indeed, much progress has been made on benchmark datasets like NORB and CIFAR-10 by employing increasingly complex unsupervised learning algorithms and deep models. In this paper, however, we show that several simple factors, such as the number of hidden nodes in the model, may be more important to achieving high performance than the learning algorithm or the depth of the model. Specifically, we will apply several off-the-shelf feature learning algorithms (sparse auto-encoders, sparse RBMs, K-means clustering, and Gaussian mixtures) to CIFAR-10, NORB, and STL datasets using only single-layer networks. We then present a detailed analysis of the effect of changes in the model setup: the receptive field size, number of hidden nodes (features), the step-size (\u201cstride\u201d) between extracted features, and the effect of whitening. Our results show that large numbers of hidden nodes and dense feature extraction are critical to achieving high performance-so critical, in fact, that when these parameters are pushed to their limits, we achieve state-of-the-art performance on both CIFAR-10 and NORB using only a single layer of features. More surprisingly, our best performance is based on K-means clustering, which is extremely fast, has no hyper-parameters to tune beyond the model structure itself, and is very easy to implement. Despite the simplicity of our system, we achieve accuracy beyond all previously published results on the CIFAR-10 and NORB datasets (79.6% and 97.2% respectively).",
        "year": 2011,
        "authors": "Adam Coates and Honglak Lee and Andrew Y Ng"
      },
      {
        "title": "Deep speech 2: End-to-end speech recognition in english and mandarin",
        "abstract": "We show that an end-to-end deep learning approach can be used to recognize either English or Mandarin Chinese speech\u2013two vastly different languages. Because it replaces entire pipelines of hand-engineered components with neural networks, end-to-end learning allows us to handle a diverse variety of speech including noisy environments, accents and different languages. Key to our approach is our application of HPC techniques, enabling experiments that previously took weeks to now run in days. This allows us to iterate more quickly to identify superior architectures and algorithms. As a result, in several cases, our system is competitive with the transcription of human workers when benchmarked on standard datasets. Finally, using a technique called Batch Dispatch with GPUs in the data center, we show that our system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale.",
        "year": 2016,
        "authors": "Dario Amodei and Sundaram Ananthanarayanan and Rishita Anubhai and Jingliang Bai and Eric Battenberg and Carl Case and Jared Casper and Bryan Catanzaro and Qiang Cheng and Guoliang Chen and Jie Chen and Jingdong Chen and Zhijie Chen and Mike Chrzanowski and Adam Coates and Greg Diamos and Ke Ding and Niandong Du and Erich Elsen and Jesse Engel and Weiwei Fang and Linxi Fan and Christopher Fougner and Liang Gao and Caixia Gong and Awni Hannun and Tony Han and Lappi Johannes and Bing Jiang and Cai Ju and Billy Jun and Patrick LeGresley and Libby Lin and Junjie Liu and Yang Liu and Weigao Li and Xiangang Li and Dongpeng Ma and Sharan Narang and Andrew Ng and Sherjil Ozair and Yiping Peng and Ryan Prenger and Sheng Qian and Zongfeng Quan and Jonathan Raiman and Vinay Rao and Sanjeev Satheesh and David Seetapun and Shubho Sengupta and Kavya Srinet and Anuroop Sriram and Haiyuan Tang and Liliang Tang and Chong Wang and Jidong Wang and Kaifu Wang and Yi Wang and Zhijian Wang and Zhiqian Wang and Shuang Wu and Likai Wei and Bo Xiao and Wen Xie and Yan Xie and Dani Yogatama and Bin Yuan and Jun Zhan and Zhenyao Zhu"
      }
    ],
    "YLOz1kgAAAAJ": [
      {
        "title": "Deep back-projection networks for super-resolution",
        "abstract": "The feed-forward architectures of recently proposed deep super-resolution networks learn representations of low-resolution inputs, and the non-linear mapping from those to high-resolution output. However, this approach does not fully address the mutual dependencies of low-and high-resolution images. We propose Deep Back-Projection Networks (DBPN), that exploit iterative up-and down-sampling layers, providing an error feedback mechanism for projection errors at each stage. We construct mutually-connected up-and down-sampling stages each of which represents different types of image degradation and high-resolution components. We show that extending this idea to allow concatenation of features across up-and down-sampling stages (Dense DBPN) allows us to reconstruct further improve super-resolution, yielding superior results and in particular establishing new state of the art results for large scaling factors such as 8x across multiple data sets.",
        "year": 2018,
        "authors": "Muhammad Haris and Gregory Shakhnarovich and Norimichi Ukita"
      },
      {
        "title": "Fractalnet: Ultra-deep neural networks without residuals",
        "abstract": "We introduce a design strategy for neural network macro-architecture based on self-similarity. Repeated application of a simple expansion rule generates deep networks whose structural layouts are precisely truncated fractals. These networks contain interacting subpaths of different lengths, but do not include any pass-through or residual connections; every internal signal is transformed by a filter and nonlinearity before being seen by subsequent layers. In experiments, fractal networks match the excellent performance of standard residual networks on both CIFAR and ImageNet classification tasks, thereby demonstrating that residual representations may not be fundamental to the success of extremely deep convolutional neural networks. Rather, the key may be the ability to transition, during training, from effectively shallow to deep. We note similarities with student-teacher behavior and develop drop-path, a natural extension of dropout, to regularize co-adaptation of subpaths in fractal architectures. Such regularization allows extraction of high-performance fixed-depth subnetworks. Additionally, fractal networks exhibit an anytime property: shallow subnetworks provide a quick answer, while deeper subnetworks, with higher latency, provide a more accurate answer.",
        "year": 2017,
        "authors": "Gustav Larsson and Michael Maire and Gregory Shakhnarovich"
      },
      {
        "title": "Learning representations for automatic colorization",
        "abstract": "We develop a fully automatic image colorization system. Our approach leverages recent advances in deep networks, exploiting both low-level and semantic representations. As many scene elements naturally appear according to multimodal color distributions, we train our model to predict per-pixel color histograms. This intermediate output can be used to automatically generate a color image, or further manipulated prior to image formation. On both fully and partially automatic colorization tasks, we outperform existing methods. We also explore colorization as a vehicle for self-supervised visual representation learning.",
        "year": 2016,
        "authors": "Gustav Larsson and Michael Maire and Gregory Shakhnarovich"
      }
    ],
    "yxUduqMAAAAJ": [
      {
        "title": "Latent Dirichlet Allocation",
        "abstract": "We describe latent Dirichlet allocation (LDA), a generative probabilistic model for collections of discrete data such as text corpora. LDA is a three-level hierarchical Bayesian model, in which each item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of text modeling, the topic probabilities provide an explicit representation of a document. We present efficient approximate inference techniques based on variational methods and an EM algorithm for empirical Bayes parameter estimation. We report results in document modeling, text classification, and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic LSI model.",
        "year": 2003,
        "authors": "DM Blei and AY Ng and MI Jordan"
      },
      {
        "title": "On spectral clustering: Analysis and an algorithm",
        "abstract": "Despite many empirical successes of spectral clustering methods (cid: 173) algorithms that cluster points using eigenvectors of matrices de (cid: 173) rived from the data-there are several unresolved issues. First, there are a wide variety of algorithms that use the eigenvectors in slightly different ways. Second, many of these algorithms have no proof that they will actually compute a reasonable clustering. In this paper, we present a simple spectral clustering algorithm that can be implemented using a few lines of Matlab. Using tools from matrix perturbation theory, we analyze the algorithm, and give conditions under which it can be expected to do well. We also show surprisingly good experimental results on a number of challenging clustering problems.",
        "year": 2001,
        "authors": "Andrew Ng and Michael Jordan and Yair Weiss"
      },
      {
        "title": "Machine learning: Trends, perspectives, and prospects",
        "abstract": "Machine learning addresses the question of how to build computers that improve automatically through experience. It is one of today\u2019s most rapidly growing technical fields, lying at the intersection of computer science and statistics, and at the core of artificial intelligence and data science. Recent progress in machine learning has been driven both by the development of new learning algorithms and theory and by the ongoing explosion in the availability of online data and low-cost computation. The adoption of data-intensive machine-learning methods can be found throughout science, technology and commerce, leading to more evidence-based decision-making across many walks of life, including health care, manufacturing, education, financial modeling, policing, and marketing.",
        "year": 2015,
        "authors": "Michael I Jordan and Tom M Mitchell"
      }
    ],
    "m_HQ-WQAAAAJ": [
      {
        "title": "Survey propagation: An algorithm for satisfiability",
        "abstract": "We study the satisfiability of randomly generated formulas formed by M clauses of exactly K literals over N Boolean variables. For a given value of N the problem is known to be most difficult when \u03b1 = M/N is close to the experimental threshold \u03b1c separating the region where almost all formulas are SAT from the region where all formulas are UNSAT. Recent results from a statistical physics analysis suggest that the difficulty is related to the existence of a clustering phenomenon of the solutions when \u03b1 is close to (but smaller than) \u03b1c. We introduce a new type of message passing algorithm which allows to find efficiently a satisfying assignment of the variables in this difficult region. This algorithm is iterative and composed of two main parts. The first is a message\u2010passing procedure which generalizes the usual methods like Sum\u2010Product or Belief Propagation: It passes messages that may be thought of as surveys over \u2026",
        "year": 2005,
        "authors": "Alfredo Braunstein and Marc M\u00e9zard and Riccardo Zecchina"
      },
      {
        "title": "Network dismantling",
        "abstract": "We study the network dismantling problem, which consists of determining a minimal set of vertices in which removal leaves the network broken into connected components of subextensive size. For a large class of random graphs, this problem is tightly connected to the decycling problem (the removal of vertices, leaving the graph acyclic). Exploiting this connection and recent works on epidemic spreading, we present precise predictions for the minimal size of a dismantling set in a large random graph with a prescribed (light-tailed) degree distribution. Building on the statistical mechanics perspective, we propose a three-stage Min-Sum algorithm for efficiently dismantling networks, including heavy-tailed ones for which the dismantling and decycling problems are not equivalent. We also provide additional insights into the dismantling problem, concluding that it is an intrinsically collective problem and that optimal \u2026",
        "year": 2016,
        "authors": "Alfredo Braunstein and Luca Dall\u2019Asta and Guilhem Semerjian and Lenka Zdeborov\u00e1"
      },
      {
        "title": "Bayesian inference of epidemics on networks via belief propagation",
        "abstract": "We study several Bayesian inference problems for irreversible stochastic epidemic models on networks from a statistical physics viewpoint. We derive equations which allow us to accurately compute the posterior distribution of the time evolution of the state of each node given some observations. At difference with most existing methods, we allow very general observation models, including unobserved nodes, state observations made at different or unknown times, and observations of infection times, possibly mixed together. Our method, which is based on the belief propagation algorithm, is efficient, naturally distributed, and exact on trees. As a particular case, we consider the problem of finding the \u201czero patient\u201d of a susceptible-infected-recovered or susceptible-infected epidemic given a snapshot of the state of the network at a later unknown time. Numerical simulations show that our method outperforms previous \u2026",
        "year": 2014,
        "authors": "Fabrizio Altarelli and Alfredo Braunstein and Luca Dall\u2019Asta and Alejandro Lage-Castellanos and Riccardo Zecchina"
      }
    ],
    "7GSWYLQAAAAJ": [
      {
        "title": "SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards",
        "abstract": "Learning to imitate expert behavior from demonstrations can be challenging, especially in environments with high-dimensional, continuous observations and unknown dynamics. Supervised learning methods based on behavioral cloning (BC) suffer from distribution shift: because the agent greedily imitates demonstrated actions, it can drift away from demonstrated states due to error accumulation. Recent methods based on reinforcement learning (RL), such as inverse RL and generative adversarial imitation learning (GAIL), overcome this issue by training an RL agent to match the demonstrations over a long horizon. Since the true reward function for the task is unknown, these methods learn a reward function from the demonstrations, often using complex and brittle approximation techniques that involve adversarial training. We propose a simple alternative that still uses RL, but does not require learning a reward function. The key idea is to provide the agent with an incentive to match the demonstrations over a long horizon, by encouraging it to return to demonstrated states upon encountering new, out-of-distribution states. We accomplish this by giving the agent a constant reward of r=+1 for matching the demonstrated action in a demonstrated state, and a constant reward of r=0 for all other behavior. Our method, which we call soft Q imitation learning (SQIL), can be implemented with a handful of minor modifications to any standard Q-learning or off-policy actor-critic algorithm. Theoretically, we show that SQIL can be interpreted as a regularized variant of BC that uses a sparsity prior to encourage long-horizon imitation. Empirically, we show that \u2026",
        "year": 2019,
        "authors": "Siddharth Reddy and Anca D Dragan and Sergey Levine"
      },
      {
        "title": "Shared Autonomy via Deep Reinforcement Learning",
        "abstract": "In shared autonomy, user input is combined with semi-autonomous control to achieve a common goal. The goal is often unknown ex-ante, so prior work enables agents to infer the goal from user input and assist with the task. Such methods tend to assume some combination of knowledge of the dynamics of the environment, the user's policy given their goal, and the set of possible goals the user might target, which limits their application to real-world scenarios. We propose a deep reinforcement learning framework for model-free shared autonomy that lifts these assumptions. We use human-in-the-loop reinforcement learning with neural network function approximation to learn an end-to-end mapping from environmental observation and user input to agent action values, with task reward as the only form of supervision. This approach poses the challenge of following user commands closely enough to provide the user with real-time action feedback and thereby ensure high-quality user input, but also deviating from the user's actions when they are suboptimal. We balance these two needs by discarding actions whose values fall below some threshold, then selecting the remaining action closest to the user's input. Controlled studies with users (n = 12) and synthetic pilots playing a video game, and a pilot study with users (n = 4) flying a real quadrotor, demonstrate the ability of our algorithm to assist users with real-time control tasks in which the agent cannot directly access the user's private information through observations, but receives a reward signal and user input that both depend on the user's intent. The agent learns to assist the user without \u2026",
        "year": 2018,
        "authors": "Siddharth Reddy and Anca D. Dragan and Sergey Levine"
      },
      {
        "title": "Where Do You Think You're Going?: Inferring Beliefs about Dynamics from Behavior",
        "abstract": "Inferring intent from observed behavior has been studied extensively within the frameworks of Bayesian inverse planning and inverse reinforcement learning. These methods infer a goal or reward function that best explains the actions of the observed agent, typically a human demonstrator. Another agent can use this inferred intent to predict, imitate, or assist the human user. However, a central assumption in inverse reinforcement learning is that the demonstrator is close to optimal. While models of suboptimal behavior exist, they typically assume that suboptimal actions are the result of some type of random noise or a known cognitive bias, like temporal inconsistency. In this paper, we take an alternative approach, and model suboptimal behavior as the result of internal model misspecification: the reason that user actions might deviate from near-optimal actions is that the user has an incorrect set of beliefs about the rules--the dynamics--governing how actions affect the environment. Our insight is that while demonstrated actions may be suboptimal in the real world, they may actually be near-optimal with respect to the user's internal model of the dynamics. By estimating these internal beliefs from observed behavior, we arrive at a new method for inferring intent. We demonstrate in simulation and in a user study with 12 participants that this approach enables us to more accurately model human intent, and can be used in a variety of applications, including offering assistance in a shared autonomy framework and inferring human preferences.",
        "year": 2018,
        "authors": "Siddharth Reddy and Anca D. Dragan and Sergey Levine"
      }
    ],
    "zBUwaGkAAAAJ": [
      {
        "title": "Gemini: a family of highly capable multimodal models",
        "abstract": "This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services including Gemini, Gemini Advanced, Google AI Studio, and Cloud Vertex AI.",
        "year": 2023,
        "authors": "Gemini Team and Rohan Anil and Sebastian Borgeaud and Jean-Baptiste Alayrac and Jiahui Yu and Radu Soricut and Johan Schalkwyk and Andrew M Dai and Anja Hauth and Katie Millican and David Silver and Melvin Johnson and Ioannis Antonoglou and Julian Schrittwieser and Amelia Glaese and Jilin Chen and Emily Pitler and Timothy Lillicrap and Angeliki Lazaridou and Orhan Firat and James Molloy and Michael Isard and Paul R Barham and Tom Hennigan and Benjamin Lee and Fabio Viola and Malcolm Reynolds and Yuanzhong Xu and Ryan Doherty and Eli Collins and Clemens Meyer and Eliza Rutherford and Erica Moreira and Kareem Ayoub and Megha Goel and Jack Krawczyk and Cosmo Du and Ed Chi and Heng-Tze Cheng and Eric Ni and Purvi Shah and Patrick Kane and Betty Chan and Manaal Faruqui and Aliaksei Severyn and Hanzhao Lin and YaGuang Li and Yong Cheng and Abe Ittycheriah and Mahdis Mahdieh and Mia Chen and Pei Sun and Dustin Tran and Sumit Bagri and Balaji Lakshminarayanan and Jeremiah Liu and Andras Orban and Fabian G\u00fcra and Hao Zhou and Xinying Song and Aurelien Boffy and Harish Ganapathy and Steven Zheng and HyunJeong Choe and \u00c1goston Weisz and Tao Zhu and Yifeng Lu and Siddharth Gopal and Jarrod Kahn and Maciej Kula and Jeff Pitman and Rushin Shah and Emanuel Taropa and Majd Al Merey and Martin Baeuml and Zhifeng Chen and Laurent El Shafey and Yujing Zhang and Olcan Sercinoglu and George Tucker and Enrique Piqueras and Maxim Krikun and Iain Barr and Nikolay Savinov and Ivo Danihelka and Becca Roelofs and Ana\u00efs White and Anders Andreassen and Tamara von Glehn and Lakshman Yagati and Mehran Kazemi and Lucas Gonzalez and Misha Khalman and Jakub Sygnowski and Alexandre Frechette and Charlotte Smith and Laura Culp and Lev Proleev and Yi Luan and Xi Chen and James Lottes and Nathan Schucher and Federico Lebron and Alban Rrustemi and Natalie Clay and Phil Crone and Tomas Kocisky and Jeffrey Zhao and Bartek Perz and Dian Yu and Heidi Howard and Adam Bloniarz and Jack W Rae and Han Lu and Laurent Sifre and Marcello Maggioni and Fred Alcober and Dan Garrette and Megan Barnes and Shantanu Thakoor and Jacob Austin and Gabriel Barth-Maron and William Wong and Rishabh Joshi and Rahma Chaabouni and Deeni Fatiha and Arun Ahuja and Gaurav Singh Tomar and Evan Senter and Martin Chadwick and Ilya Kornakov and Nithya Attaluri and I\u00f1aki Iturrate and Ruibo Liu and Yunxuan Li and Sarah Cogan and Jeremy Chen and Chao Jia and Chenjie Gu and Qiao Zhang and Jordan Grimstad and Ale Jakse Hartman and Xavier Garcia and Thanumalayan Sankaranarayana Pillai and Jacob Devlin and Michael Laskin and Diego de Las Casas and Dasha Valter and Connie Tao and Lorenzo Blanco"
      },
      {
        "title": "Offline reinforcement learning: Tutorial, review, and perspectives on open problems",
        "abstract": "In this tutorial article, we aim to provide the reader with the conceptual tools needed to get started on research on offline reinforcement learning algorithms: reinforcement learning algorithms that utilize previously collected data, without additional online data collection. Offline reinforcement learning algorithms hold tremendous promise for making it possible to turn large datasets into powerful decision making engines. Effective offline reinforcement learning methods would be able to extract policies with the maximum possible utility out of the available data, thereby allowing automation of a wide range of decision-making domains, from healthcare and education to robotics. However, the limitations of current algorithms make this difficult. We will aim to provide the reader with an understanding of these challenges, particularly in the context of modern deep reinforcement learning methods, and describe some potential solutions that have been explored in recent work to mitigate these challenges, along with recent applications, and a discussion of perspectives on open problems in the field.",
        "year": 2020,
        "authors": "Sergey Levine and Aviral Kumar and George Tucker and Justin Fu"
      },
      {
        "title": "Conservative q-learning for offline reinforcement learning",
        "abstract": "Effectively leveraging large, previously collected datasets in reinforcement learn-ing (RL) is a key challenge for large-scale real-world applications. Offline RL algorithms promise to learn effective policies from previously-collected, static datasets without further interaction. However, in practice, offline RL presents a major challenge, and standard off-policy RL methods can fail due to overestimation of values induced by the distributional shift between the dataset and the learned policy, especially when training on complex and multi-modal data distributions. In this paper, we propose conservative Q-learning (CQL), which aims to address these limitations by learning a conservative Q-function such that the expected value of a policy under this Q-function lower-bounds its true value. We theoretically show that CQL produces a lower bound on the value of the current policy and that it can be incorporated into a policy learning procedure with theoretical improvement guarantees. In practice, CQL augments the standard Bellman error objective with a simple Q-value regularizer which is straightforward to implement on top of existing deep Q-learning and actor-critic implementations. On both discrete and continuous control domains, we show that CQL substantially outperforms existing offline RL methods, often learning policies that attain 2-5 times higher final return, especially when learning from complex and multi-modal data distributions.",
        "year": 2020,
        "authors": "Aviral Kumar and Aurick Zhou and George Tucker and Sergey Levine"
      }
    ],
    "_tNCgxMAAAAJ": [
      {
        "title": "Provably safe and robust learning-based model predictive control",
        "abstract": "Controller design faces a trade-off between robustness and performance, and the reliability of linear controllers has caused many practitioners to focus on the former. However, there is renewed interest in improving system performance to deal with growing energy constraints. This paper describes a learning-based model predictive control (LBMPC) scheme that provides deterministic guarantees on robustness, while statistical identification tools are used to identify richer models of the system in order to improve performance; the benefits of this framework are that it handles state and input constraints, optimizes system performance with respect to a cost function, and can be designed to use a wide variety of parametric or nonparametric statistical tools. The main insight of LBMPC is that safety and performance can be decoupled under reasonable conditions in an optimization framework by maintaining two models of \u2026",
        "year": 2013,
        "authors": "Anil Aswani and Humberto Gonzalez and S Shankar Sastry and Claire Tomlin"
      },
      {
        "title": "Reducing transient and steady state electricity consumption in HVAC using learning-based model-predictive control",
        "abstract": "Heating, ventilation, and air conditioning (HVAC) systems are an important target for efficiency improvements through new equipment and retrofitting because of their large energy footprint. One type of equipment that is common in homes and some offices is an electrical, single-stage heat pump air conditioner (AC). To study this setup, we have built the Berkeley Retrofitted and Inexpensive HVAC Testbed for Energy Efficiency (BRITE) platform. This platform allows us to actuate an AC unit that controls the room temperature of a computer laboratory on the Berkeley campus that is actively used by students, while sensors record room temperature and AC energy consumption. We build a mathematical model of the temperature dynamics of the room, and combining this model with statistical methods allows us to compute the heating load due to occupants and equipment using only a single temperature sensor. Next, we \u2026",
        "year": 2011,
        "authors": "Anil Aswani and Neal Master and Jay Taneja and David Culler and Claire Tomlin"
      },
      {
        "title": "Expression-level optimization of a multi-enzyme pathway in the absence of a high-throughput assay",
        "abstract": "Engineered metabolic pathways often suffer from flux imbalances that can overburden the cell and accumulate intermediate metabolites, resulting in reduced product titers. One way to alleviate such imbalances is to adjust the expression levels of the constituent enzymes using a combinatorial expression library. Typically, this approach requires high-throughput assays, which are unfortunately unavailable for the vast majority of desirable target compounds. To address this, we applied regression modeling to enable expression optimization using only a small number of measurements. We characterized a set of constitutive promoters in Saccharomyces cerevisiae that spanned a wide range of expression and maintained their relative strengths irrespective of the coding sequence. We used a standardized assembly strategy to construct a combinatorial library and express for the first time in yeast the five-enzyme \u2026",
        "year": 2013,
        "authors": "Michael E Lee and Anil Aswani and Audrey S Han and Claire J Tomlin and John E Dueber"
      }
    ],
    "BsOkXDsAAAAJ": [
      {
        "title": "Offline reinforcement learning with implicit q-learning",
        "abstract": "Offline reinforcement learning requires reconciling two conflicting aims: learning a policy that improves over the behavior policy that collected the dataset, while at the same time minimizing the deviation from the behavior policy so as to avoid errors due to distributional shift. This trade-off is critical, because most current offline reinforcement learning methods need to query the value of unseen actions during training to improve the policy, and therefore need to either constrain these actions to be in-distribution, or else regularize their values. We propose an offline RL method that never needs to evaluate actions outside of the dataset, but still enables the learned policy to improve substantially over the best behavior in the data through generalization. The main insight in our work is that, instead of evaluating unseen actions from the latest policy, we can approximate the policy improvement step implicitly by treating the state value function as a random variable, with randomness determined by the action (while still integrating over the dynamics to avoid excessive optimism), and then taking a state conditional upper expectile of this random variable to estimate the value of the best actions in that state. This leverages the generalization capacity of the function approximator to estimate the value of the best available action at a given state without ever directly querying a Q-function with this unseen action. Our algorithm alternates between fitting this upper expectile value function and backing it up into a Q-function. Then, we extract the policy via advantage-weighted behavioral cloning. We dub our method implicit Q-learning (IQL). IQL demonstrates the state-of \u2026",
        "year": 2021,
        "authors": "Ilya Kostrikov and Ashvin Nair and Sergey Levine"
      },
      {
        "title": "Overcoming exploration in reinforcement learning with demonstrations",
        "abstract": "Exploration in environments with sparse rewards has been a persistent problem in reinforcement learning (RL). Many tasks are natural to specify with a sparse reward, and manually shaping a reward function can result in suboptimal performance. However, finding a non-zero reward is exponentially more difficult with increasing task horizon or action dimensionality. This puts many real-world tasks out of practical reach of RL methods. In this work, we use demonstrations to overcome the exploration problem and successfully learn to perform long-horizon, multi-step robotics tasks with continuous control such as stacking blocks with a robot arm. Our method, which builds on top of Deep Deterministic Policy Gradients and Hindsight Experience Replay, provides an order of magnitude of speedup over RL on simulated robotics tasks. It is simple to implement and makes only the additional assumption that we can collect a \u2026",
        "year": 2017,
        "authors": "Ashvin Nair and Bob McGrew and Marcin Andrychowicz and Wojciech Zaremba and Pieter Abbeel"
      }
    ],
    "IB_jPZ0AAAAJ": [
      {
        "title": "Implicit regularization in nonconvex statistical estimation: Gradient descent converges linearly for phase retrieval, matrix completion, and blind deconvolution",
        "abstract": "Recent years have seen a flurry of activities in designing provably efficient nonconvex optimization procedures for solving statistical estimation problems. For various problems like phase retrieval or low-rank matrix completion, state-of-the-art nonconvex procedures require proper regularization (eg trimming, regularized cost, projection) in order to guarantee fast convergence. When it comes to vanilla procedures such as gradient descent, however, prior theory either recommends highly conservative learning rates to avoid overshooting, or completely lacks performance guarantees. This paper uncovers a striking phenomenon in several nonconvex problems: even in the absence of explicit regularization, gradient descent follows a trajectory staying within a basin that enjoys nice geometry, consisting of points incoherent with the sampling mechanism. This \u201cimplicit regularization\u201d feature allows gradient descent to proceed in a far more aggressive fashion without overshooting, which in turn results in substantial computational savings. Focusing on two statistical estimation problems, ie solving random quadratic systems of equations and low-rank matrix completion, we establish that gradient descent achieves near-optimal statistical and computational guarantees without explicit regularization. As a byproduct, for noisy matrix completion, we demonstrate that gradient descent enables optimal control of both entrywise and spectral-norm errors.",
        "year": 2020,
        "authors": "Cong Ma and Kaizheng Wang and Yuejie Chi and Yuxin Chen"
      },
      {
        "title": "Bridging offline reinforcement learning and imitation learning: A tale of pessimism",
        "abstract": "Offline (or batch) reinforcement learning (RL) algorithms seek to learn an optimal policy from a fixed dataset without active data collection. Based on the composition of the offline dataset, two main methods are used: imitation learning which is suitable for expert datasets, and vanilla offline RL which often requires uniform coverage datasets. From a practical standpoint, datasets often deviate from these two extremes and the exact data composition is usually unknown. To bridge this gap, we present a new offline RL framework that smoothly interpolates between the two extremes of data composition, hence unifying imitation learning and vanilla offline RL. The new framework is centered around a weak version of the concentrability coefficient that measures the deviation of the behavior policy from the expert policy alone. Under this new framework, we ask: can one develop an algorithm that achieves a minimax optimal rate adaptive to unknown data composition? To address this question, we consider a lower confidence bound (LCB) algorithm developed based on pessimism in the face of uncertainty in offline RL. We study finite-sample properties of LCB as well as information-theoretic limits in multi-armed bandits, contextual bandits, and Markov decision processes (MDPs). Our analysis reveals surprising facts about optimality rates. In particular, in both contextual bandits and RL, LCB achieves a faster rate of  for nearly-expert datasets compared to the usual rate of  in offline RL, where  is the batch dataset sample size. In contextual bandits with at least two contexts, we prove that LCB is adaptively optimal for the entire data composition \u2026",
        "year": 2021,
        "authors": "Paria Rashidinejad and Banghua Zhu and Cong Ma and Jiantao Jiao and Stuart Russell"
      },
      {
        "title": "Gradient descent with random initialization: Fast global convergence for nonconvex phase retrieval",
        "abstract": "This paper considers the problem of solving systems of quadratic equations, namely, recovering an object of interest $$\\varvec{x}^{\\natural }\\in {\\mathbb {R}}^{n}$$ from m quadratic equations/samples $$y_{i}=(\\varvec{a}_{i}^{\\top }\\varvec{x}^{\\natural })^{2}, 1\\le i\\le m$$. This problem, also dubbed as phase retrieval, spans multiple domains including physical sciences and machine learning. We investigate the efficacy of gradient descent (or Wirtinger flow) designed for the nonconvex least squares problem. We prove that under Gaussian designs, gradient descent\u2014when randomly initialized\u2014yields an -accurate solution in  iterations given nearly minimal samples, thus achieving near-optimal computational and sample complexities at once. This provides the first global convergence guarantee concerning vanilla gradient descent for phase retrieval, without the need of (i) carefully-designed \u2026",
        "year": 2019,
        "authors": "Yuxin Chen and Yuejie Chi and Jianqing Fan and Cong Ma"
      }
    ],
    "DYUloYkAAAAJ": [
      {
        "title": "Entropy-sgd: Biasing gradient descent into wide valleys",
        "abstract": "This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in the sharp valleys. Conceptually, our algorithm resembles two nested loops of SGD where we use Langevin dynamics in the inner loop to compute the gradient of the local entropy before each update of the weights. We show that the new objective has a smoother energy landscape and show improved generalization over SGD using uniform stability, under \u2026",
        "year": 2019,
        "authors": "Pratik Chaudhari and Anna Choromanska and Stefano Soatto and Yann LeCun and Carlo Baldassi and Christian Borgs and Jennifer Chayes and Levent Sagun and Riccardo Zecchina"
      },
      {
        "title": "Unreasonable effectiveness of learning neural networks: From accessible states and robust ensembles to basic algorithmic schemes",
        "abstract": "In artificial neural networks, learning from data is a computationally demanding task in which a large number of connection weights are iteratively tuned through stochastic-gradient-based heuristic processes over a cost function. It is not well understood how learning occurs in these systems, in particular how they avoid getting trapped in configurations with poor computational performance. Here, we study the difficult case of networks with discrete weights, where the optimization landscape is very rough even for simple architectures, and provide theoretical and numerical evidence of the existence of rare\u2014but extremely dense and accessible\u2014regions of configurations in the network weight space. We define a measure, the robust ensemble (RE), which suppresses trapping by isolated configurations and amplifies the role of these dense regions. We analytically compute the RE in some exactly solvable models and \u2026",
        "year": 2016,
        "authors": "Carlo Baldassi and Christian Borgs and Jennifer T Chayes and Alessandro Ingrosso and Carlo Lucibello and Luca Saglietti and Riccardo Zecchina"
      },
      {
        "title": "Fast and accurate multivariate Gaussian modeling of protein families: predicting residue contacts and protein-interaction partners",
        "abstract": "In the course of evolution, proteins show a remarkable conservation of their three-dimensional structure and their biological function, leading to strong evolutionary constraints on the sequence variability between homologous proteins. Our method aims at extracting such constraints from rapidly accumulating sequence data, and thereby at inferring protein structure and function from sequence information alone. Recently, global statistical inference methods (e.g. direct-coupling analysis, sparse inverse covariance estimation) have achieved a breakthrough towards this aim, and their predictions have been successfully implemented into tertiary and quaternary protein structure prediction methods. However, due to the discrete nature of the underlying variable (amino-acids), exact inference requires exponential time in the protein length, and efficient approximations are needed for practical applicability. Here we propose a very efficient multivariate Gaussian modeling approach as a variant of direct-coupling analysis: the discrete amino-acid variables are replaced by continuous Gaussian random variables. The resulting statistical inference problem is efficiently and exactly solvable. We show that the quality of inference is comparable or superior to the one achieved by mean-field approximations to inference with discrete variables, as done by direct-coupling analysis. This is true for (i) the prediction of residue-residue contacts in proteins, and (ii) the identification of protein-protein interaction partner in bacterial signal transduction. An implementation of our multivariate Gaussian approach is available at the website http://areeweb.polito.it/ricerca/cmp/code.",
        "year": 2014,
        "authors": "Carlo Baldassi and Marco Zamparo and Christoph Feinauer and Andrea Procaccini and Riccardo Zecchina and Martin Weigt and Andrea Pagnani"
      }
    ],
    "UAwKvEsAAAAJ": [
      {
        "title": "Finding scientific topics",
        "abstract": "A first step in identifying the content of a document is determining which topics that document addresses. We describe a generative model for documents, introduced by Blei, Ng, and Jordan [Blei, D. M., Ng, A. Y. & Jordan, M. I. (2003) J. Machine Learn. Res. 3, 993-1022], in which each document is generated by choosing a distribution over topics and then choosing each word in the document from a topic selected according to this distribution. We then present a Markov chain Monte Carlo algorithm for inference in this model. We use this algorithm to analyze abstracts from PNAS by using Bayesian model selection to establish the number of topics. We show that the extracted topics capture meaningful structure in the data, consistent with the class designations provided by the authors of the articles, and outline further applications of this analysis, including identifying \u201chot topics\u201d by examining temporal dynamics and \u2026",
        "year": 2004,
        "authors": "Thomas L Griffiths and Mark Steyvers"
      },
      {
        "title": "Tree of thoughts: Deliberate problem solving with large language models",
        "abstract": "Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models\u2019 problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\\% of tasks, our method achieved a success rate of 74\\%. Code repo with all prompts: https://github. com/princeton-nlp/tree-of-thought-llm.",
        "year": 2023,
        "authors": "Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Tom Griffiths and Yuan Cao and Karthik Narasimhan"
      },
      {
        "title": "Probabilistic topic models",
        "abstract": "Many chapters in this book illustrate that applying a statistical method such as latent semantic analysis (LSA; Landauer & Dumais, 1997; Landauer, Foltz, & Laham, 1998) to large databases can yield insight into human cognition. The LSA approach makes three claims: that semantic information can be derived from a word-document co-occurrence matrix; that dimensionality reduction is an essential part of this derivation; and that words and documents can be represented as points in Euclidean space. This chapter pursues an approach that is consistent with the first two of these claims, but differs in the third, describing a class of statistical models in which the semantic properties of words and documents are expressed in terms of probabilistic topics.",
        "year": 2007,
        "authors": "Mark Steyvers and Tom Griffiths"
      }
    ],
    "xOWBOKQAAAAJ": [
      {
        "title": "A survey of research on cloud robotics and automation",
        "abstract": "The Cloud infrastructure and its extensive set of Internet-accessible resources has potential to provide significant benefits to robots and automation systems. We consider robots and automation systems that rely on data or code from a network to support their operation, i.e., where not all sensing, computation, and memory is integrated into a standalone system. This survey is organized around four potential benefits of the Cloud: 1) Big Data: access to libraries of images, maps, trajectories, and descriptive data; 2) Cloud Computing: access to parallel grid computing on demand for statistical analysis, learning, and motion planning; 3) Collective Robot Learning: robots sharing trajectories, control policies, and outcomes; and 4) Human Computation: use of crowdsourcing to tap human skills for analyzing images and video, classification, learning, and error recovery. The Cloud can also improve robots and automation \u2026",
        "year": 2015,
        "authors": "Ben Kehoe and Sachin Patil and Pieter Abbeel and Ken Goldberg"
      },
      {
        "title": "Motion planning with sequential convex optimization and convex collision checking",
        "abstract": "We present a new optimization-based approach for robotic motion planning among obstacles. Like CHOMP (Covariant Hamiltonian Optimization for Motion Planning), our algorithm can be used to find collision-free trajectories from na\u00efve, straight-line initializations that might be in collision. At the core of our approach are (a) a sequential convex optimization procedure, which penalizes collisions with a hinge loss and increases the penalty coefficients in an outer loop as necessary, and (b) an efficient formulation of the no-collisions constraint that directly considers continuous-time safety Our algorithm is implemented in a software package called TrajOpt.We report results from a series of experiments comparing TrajOpt with CHOMP and randomized planners from OMPL, with regard to planning time and path quality. We consider motion planning for 7 DOF robot arms, 18 DOF full-body robots, statically stable walking \u2026",
        "year": 2014,
        "authors": "John Schulman and Yan Duan and Jonathan Ho and Alex Lee and Ibrahim Awwal and Henry Bradlow and Jia Pan and Sachin Patil and Ken Goldberg and Pieter Abbeel"
      },
      {
        "title": "Motion planning under uncertainty using iterative local optimization in belief space",
        "abstract": "We present a new approach to motion planning under sensing and motion uncertainty by computing a locally optimal solution to a continuous partially observable Markov decision process (POMDP). Our approach represents beliefs (the distributions of the robot\u2019s state estimate) by Gaussian distributions and is applicable to robot systems with non-linear dynamics and observation models. The method follows the general POMDP solution framework in which we approximate the belief dynamics using an extended Kalman filter and represent the value function by a quadratic function that is valid in the vicinity of a nominal trajectory through belief space. Using a belief space variant of iterative LQG (iLQG), our approach iterates with second-order convergence towards a linear control policy over the belief space that is locally optimal with respect to a user-defined cost function. Unlike previous work, our approach does not \u2026",
        "year": 2012,
        "authors": "Jur Van Den Berg and Sachin Patil and Ron Alterovitz"
      }
    ],
    "czyretsAAAAJ": [
      {
        "title": "Gaussian Error Linear Units (GELUs)",
        "abstract": "We propose the Gaussian Error Linear Unit (GELU), a high-performing neural network activation function. The GELU activation function is , where  the standard Gaussian cumulative distribution function. The GELU nonlinearity weights inputs by their value, rather than gates inputs by their sign as in ReLUs (). We perform an empirical evaluation of the GELU nonlinearity against the ReLU and ELU activations and find performance improvements across all considered computer vision, natural language processing, and speech tasks.",
        "year": 2016,
        "authors": "Dan Hendrycks and Kevin Gimpel"
      },
      {
        "title": "Measuring Massive Multitask Language Understanding",
        "abstract": "We propose a new test to measure a text model's multitask accuracy. The test covers 57 tasks including elementary mathematics, US history, computer science, law, and more. To attain high accuracy on this test, models must possess extensive world knowledge and problem solving ability. We find that while most recent models have near random-chance accuracy, the very largest GPT-3 model improves over random chance by almost 20 percentage points on average. However, on every one of the 57 tasks, the best models still need substantial improvements before they can reach expert-level accuracy. Models also have lopsided performance and frequently do not know when they are wrong. Worse, they still have near-random accuracy on some socially important subjects such as morality and law. By comprehensively evaluating the breadth and depth of a model's academic and professional understanding, our test can be used to analyze models across many tasks and to identify important shortcomings.",
        "year": 2020,
        "authors": "Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt"
      },
      {
        "title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations",
        "abstract": "In this paper we establish rigorous benchmarks for image classifier robustness. Our first benchmark, ImageNet-C, standardizes and expands the corruption robustness topic, while showing which classifiers are preferable in safety-critical applications. Then we propose a new dataset called ImageNet-P which enables researchers to benchmark a classifier's robustness to common perturbations. Unlike recent robustness research, this benchmark evaluates performance on common corruptions and perturbations not worst-case adversarial perturbations. We find that there are negligible changes in relative corruption robustness from AlexNet classifiers to ResNet classifiers. Afterward we discover ways to enhance corruption and perturbation robustness. We even find that a bypassed adversarial defense provides substantial common perturbation robustness. Together our benchmarks may aid future work toward networks that robustly generalize.",
        "year": 2019,
        "authors": "Dan Hendrycks and Thomas Dietterich"
      }
    ],
    "CpMjT0YAAAAJ": [
      {
        "title": "NoScope: Optimizing Neural Network Queries over Video at Scale",
        "abstract": "Recent advances in computer vision-in the form of deep neural networks-have made it possible to query increasing volumes of video data with high accuracy. However, neural network inference is computationally expensive at scale: applying a state-of-the-art object detector in real time (i.e., 30+ frames per second) to a single video requires a $4000 GPU. In response, we present NoScope, a system for querying videos that can reduce the cost of neural network video analysis by up to three orders of magnitude via inference-optimized model search. Given a target video, object to detect, and reference neural network, NoScope automatically searches for and trains a sequence, or cascade, of models that preserves the accuracy of the reference network but is specialized to the target video and are therefore far less computationally expensive. NoScope cascades two types of models: specialized models that forego the full generality of the reference model but faithfully mimic its behavior for the target video and object; and difference detectors that highlight temporal differences across frames. We show that the optimal cascade architecture differs across videos and objects, so NoScope uses an efficient cost-based optimizer to search across models and cascades. With this approach, NoScope achieves two to three order of magnitude speed-ups (265-15,500x real-time) on binary classification tasks over fixed-angle webcam and surveillance video while maintaining accuracy within 1-5% of state-of-the-art neural networks.",
        "year": 2017,
        "authors": "Daniel Kang and John Emmons and Firas Abuzaid and Peter Bailis and Matei Zaharia"
      },
      {
        "title": "DAWNBench: An End-to-End Deep Learning Benchmark and Competition",
        "abstract": "Despite considerable research on systems, algorithms and hardware to speed up deep learning workloads, there is no standard means of evaluating end-to-end deep learning performance. Existing benchmarks measure proxy metrics, such as time to process one minibatch of data, that do not indicate whether the system as a whole will produce a high-quality result. In this work, we introduce DAWNBench, a benchmark and competition focused on end-to-end training time to achieve a state-of-the-art accuracy level, as well as inference time with that accuracy. Using time to accuracy as a target metric, we explore how different optimizations, including choice of optimizer, stochastic depth, and multi-GPU training, affect end-to-end training performance. Our results demonstrate that optimizations can interact in non-trivial ways when used in conjunction, producing lower speed-ups and less accurate models. We believe DAWNBench will provide a useful, reproducible means of evaluating the many trade-offs in deep learning systems.",
        "year": 2017,
        "authors": "Cody Coleman and Deepak Narayanan and Daniel Kang and Tian Zhao and Jian Zhang and Luigi Nardi and Peter Bailis and Kunle Olukotun and Chris R\u00e9 and Matei Zaharia"
      },
      {
        "title": "MLPerf Training Benchmark",
        "abstract": "Machine learning is experiencing an explosion of software and hardware solutions, and needs industry-standard performance benchmarks to drive design and enable competitive evaluation. However, machine learning training presents a number of unique challenges to benchmarking that do not exist in other domains:(1) some optimizations that improve training throughput actually increase time to solution,(2) training is stochastic and time to solution has high variance, and (3) the software and hardware systems are so diverse that they cannot be fairly benchmarked with the same binary, code, or even hyperparameters. We present MLPerf, a machine learning benchmark that overcomes these challenges. We quantitatively evaluate the efficacy of MLPerf in driving community progress on performance and scalability across two rounds of results from multiple vendors.",
        "year": 2019,
        "authors": "Peter Mattson and Christine Cheng and Cody Coleman and Greg Diamos and Paulius Micikevicius and David Patterson and Hanlin Tang and Gu-Yeon Wei and Peter Bailis and Victor Bittorf and David Brooks and Dehao Chen and Debojyoti Dutta and Udit Gupta and Kim Hazelwood and Andrew Hock and Xinyuan Huang and Bill Jia and Daniel Kang and David Kanter and Naveen Kumar and Jeffery Liao and Deepak Narayanan and Tayo Oguntebi and Gennady Pekhimenko and Lillian Pentecost and Vijay Janapa Reddi and Taylor Robie and Tom St John and Carole-Jean Wu and Lingjie Xu and Cliff Young and Matei Zaharia"
      }
    ],
    "hdTDzlQAAAAJ": [
      {
        "title": "Minimax estimation of functionals of discrete distributions",
        "abstract": "We propose a general methodology for the construction and analysis of essentially minimax estimators for a wide class of functionals of finite dimensional parameters, and elaborate on the case of discrete distributions, where the support size S is unknown and may be comparable with or even much larger than the number of observations n. We treat the respective regions where the functional is nonsmooth and smooth separately. In the nonsmooth regime, we apply an unbiased estimator for the best polynomial approximation of the functional whereas, in the smooth regime, we apply a bias-corrected version of the maximum likelihood estimator (MLE). We illustrate the merit of this approach by thoroughly analyzing the performance of the resulting schemes for estimating two important information measures: 1) the entropy H(P) = \u03a3Si=1 -pi ln pi and 2) F\u03b1(P) = \u03a3Si=1 p\u03b1i, \u03b1 > 0. We obtain the minimax L2 rates for \u2026",
        "year": 2015,
        "authors": "Jiantao Jiao and Kartik Venkat and Yanjun Han and Tsachy Weissman"
      },
      {
        "title": "Batched multi-armed bandits problem",
        "abstract": "In this paper, we study the multi-armed bandit problem in the batched setting where the employed policy must split data into a small number of batches. While the minimax regret for the two-armed stochastic bandits has been completely characterized in\\cite {perchet2016batched}, the effect of the number of arms on the regret for the multi-armed case is still open. Moreover, the question whether adaptively chosen batch sizes will help to reduce the regret also remains underexplored. In this paper, we propose the BaSE (batched successive elimination) policy to achieve the rate-optimal regrets (within logarithmic factors) for batched multi-armed bandits, with matching lower bounds even if the batch sizes are determined in an adaptive manner.",
        "year": 2019,
        "authors": "Zijun Gao and Yanjun Han and Zhimei Ren and Zhengqing Zhou"
      },
      {
        "title": "Performance limits and geometric properties of array localization",
        "abstract": "Location-aware networks are of great importance and interest in both civil and military applications. This paper determines the localization accuracy of an agent, which is equipped with an antenna array and localizes itself using wireless measurements with anchor nodes, in a far-field environment. In view of the Cram\u00e9r-Rao bound, we first derive the localization information for static scenarios and demonstrate that such information is a weighed sum of Fisher information matrices from each anchor-antenna measurement pair. Each matrix can be further decomposed into two parts: 1) a distance part with intensity proportional to the squared baseband effective bandwidth of the transmitted signal and 2) a direction part with intensity associated with the normalized anchor-antenna visual angle. Moreover, in dynamic scenarios, we show that the Doppler shift contributes additional direction information, with intensity \u2026",
        "year": 2015,
        "authors": "Yanjun Han and Yuan Shen and Xiao-Ping Zhang and Moe Z Win and Huadong Meng"
      }
    ],
    "kppa2vgAAAAJ": [
      {
        "title": "Multi-agent actor-critic for mixed cooperative-competitive environments",
        "abstract": "We explore deep reinforcement learning methods for multi-agent domains. We begin by analyzing the difficulty of traditional algorithms in the multi-agent case: Q-learning is challenged by an inherent non-stationarity of the environment, while policy gradient suffers from a variance that increases as the number of agents grows. We then present an adaptation of actor-critic methods that considers action policies of other agents and is able to successfully learn policies that require complex multi-agent coordination. Additionally, we introduce a training regimen utilizing an ensemble of policies for each agent that leads to more robust multi-agent policies. We show the strength of our approach compared to existing methods in cooperative as well as competitive scenarios, where agent populations are able to discover various physical and informational coordination strategies.",
        "year": 2017,
        "authors": "Ryan Lowe and Yi I Wu and Aviv Tamar and Jean Harb and OpenAI Pieter Abbeel and Igor Mordatch"
      },
      {
        "title": "Constrained policy optimization",
        "abstract": "For many applications of reinforcement learning it can be more convenient to specify both a reward function and constraints, rather than trying to design behavior through the reward function. For example, systems that physically interact with or around humans should satisfy safety constraints. Recent advances in policy search algorithms (Mnih et al., 2016, Schulman et al., 2015, Lillicrap et al., 2016, Levine et al., 2016) have enabled new capabilities in high-dimensional control, but do not consider the constrained setting. We propose Constrained Policy Optimization (CPO), the first general-purpose policy search algorithm for constrained reinforcement learning with guarantees for near-constraint satisfaction at each iteration. Our method allows us to train neural network policies for high-dimensional control while making guarantees about policy behavior all throughout training. Our guarantees are based on a new theoretical result, which is of independent interest: we prove a bound relating the expected returns of two policies to an average divergence between them. We demonstrate the effectiveness of our approach on simulated robot locomotion tasks where the agent must satisfy constraints motivated by safety.",
        "year": 2017,
        "authors": "Joshua Achiam and David Held and Aviv Tamar and Pieter Abbeel"
      },
      {
        "title": "Value iteration networks",
        "abstract": "We introduce the value iteration network (VIN): a fully differentiable neural network with aplanning module'embedded within. VINs can learn to plan, and are suitable for predicting outcomes that involve planning-based reasoning, such as policies for reinforcement learning. Key to our approach is a novel differentiable approximation of the value-iteration algorithm, which can be represented as a convolutional neural network, and trained end-to-end using standard backpropagation. We evaluate VIN based policies on discrete and continuous path-planning domains, and on a natural-language based search task. We show that by learning an explicit planning computation, VIN policies generalize better to new, unseen domains.",
        "year": 2016,
        "authors": "Aviv Tamar and Yi Wu and Garrett Thomas and Sergey Levine and Pieter Abbeel"
      }
    ],
    "I1EvjZsAAAAJ": [
      {
        "title": "A view of cloud computing",
        "abstract": "Clearing the clouds away from the true potential and obstacles posed by this computing capability.",
        "year": 2010,
        "authors": "Michael Armbrust and Armando Fox and Rean Griffith and Anthony D Joseph and Randy Katz and Andy Konwinski and Gunho Lee and David Patterson and Ariel Rabkin and Ion Stoica and Matei Zaharia"
      },
      {
        "title": "Spark: Cluster computing with working sets",
        "abstract": "MapReduce and its variants have been highly successful in implementing large-scale data-intensive applications on commodity clusters. However, most of these systems are built around an acyclic data flow model that is not suitable for other popular applications. This paper focuses on one such class of applications: those that reuse a working set of data across multiple parallel operations. This includes many iterative machine learning algorithms, as well as interactive data analysis tools. We propose a new framework called Spark that supports these applications while retaining the scalability and fault tolerance of MapReduce. To achieve these goals, Spark introduces an abstraction called resilient distributed datasets (RDDs). An RDD is a read-only collection of objects partitioned across a set of machines that can be rebuilt if a partition is lost. Spark can outperform Hadoop by 10x in iterative machine learning jobs, and can be used to interactively query a 39 GB dataset with sub-second response time.",
        "year": 2010,
        "authors": "Matei Zaharia and Mosharaf Chowdhury and Michael J Franklin and Scott Shenker and Ion Stoica"
      },
      {
        "title": "Above the clouds: A berkeley view of cloud computing",
        "abstract": "Cloud Computing, the long-held dream of computing as a utility, has the potential to transform a large part of the IT industry, making software even more attractive as a service and shaping the way IT hardware is designed and purchased. Developers with innovative ideas for new Internet services no longer require the large capital outlays in hardware to deploy their service or the human expense to operate it. They need not be concerned about overprovisioning for a service whose popularity does not meet their predictions, thus wasting costly resources, or underprovisioning for one that becomes wildly popular, thus missing potential customers and revenue. Moreover, companies with large batch-oriented tasks can get results as quickly as their programs can scale, since using 1000 servers for one hour costs no more than using one server for 1000 hours. This elasticity of resources, without paying a premium for large scale, is unprecedented in the history of IT.Cloud Computing refers to both the applications delivered as services over the Internet and the hardware and systems software in the datacenters that provide those services. The services themselves have long been referred to as Software as a Service (SaaS). The datacenter hardware and software is what we will call a Cloud. When a Cloud is made available in a pay-as-you-go manner to the general public, we call it a Public Cloud; the service being sold is Utility Computing. We use the term Private Cloud to refer to internal datacenters of a business or other organization, not made available to the general public. Thus, Cloud Computing is the sum of SaaS and Utility Computing, but does not \u2026",
        "year": 2009,
        "authors": "Michael Armbrust and Armando Fox and Rean Griffith and Anthony D Joseph and Randy H Katz and Andrew Konwinski and Gunho Lee and David A Patterson and Ariel Rabkin and Ion Stoica and Matei Zaharia"
      }
    ],
    "UgHB5oAAAAAJ": [
      {
        "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
        "abstract": "In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvement in next-token prediction and near-perfect retrieval (>99%) up to at least 10M tokens, a generational leap over existing models such as Claude 3.0 (200k) and GPT-4 Turbo (128k). Finally, we highlight real-world use cases, such as Gemini 1.5 collaborating with professionals on completing their tasks achieving 26 to 75% time savings across 10 different job categories, as well as surprising new capabilities of large language models at the frontier; when given a grammar manual for Kalamang, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person who learned from the same content.",
        "year": 2024,
        "authors": "Gemini Team and Petko Georgiev and Ving Ian Lei and Ryan Burnell and Libin Bai and Anmol Gulati and Garrett Tanzer and Damien Vincent and Zhufeng Pan and Shibo Wang and Soroosh Mariooryad and Yifan Ding and Xinyang Geng and Fred Alcober and Roy Frostig and Mark Omernick and Lexi Walker and Cosmin Paduraru and Christina Sorokin and Andrea Tacchetti and Colin Gaffney and Samira Daruki and Olcan Sercinoglu and Zach Gleicher and Juliette Love and Paul Voigtlaender and Rohan Jain and Gabriela Surita and Kareem Mohamed and Rory Blevins and Junwhan Ahn and Tao Zhu and Kornraphop Kawintiranon and Orhan Firat and Yiming Gu and Yujing Zhang and Matthew Rahtz and Manaal Faruqui and Natalie Clay and Justin Gilmer and JD Co-Reyes and Ivo Penchev and Rui Zhu and Nobuyuki Morioka and Kevin Hui and Krishna Haridasan and Victor Campos and Mahdis Mahdieh and Mandy Guo and Samer Hassan and Kevin Kilgour and Arpi Vezer and Heng-Tze Cheng and Raoul de Liedekerke and Siddharth Goyal and Paul Barham and DJ Strouse and Seb Noury and Jonas Adler and Mukund Sundararajan and Sharad Vikram and Dmitry Lepikhin and Michela Paganini and Xavier Garcia and Fan Yang and Dasha Valter and Maja Trebacz and Kiran Vodrahalli and Chulayuth Asawaroengchai and Roman Ring and Norbert Kalb and Livio Baldini Soares and Siddhartha Brahma and David Steiner and Tianhe Yu and Fabian Mentzer and Antoine He and Lucas Gonzalez and Bibo Xu and Raphael Lopez Kaufman and Laurent El Shafey and Junhyuk Oh and Tom Hennigan and George van den Driessche and Seth Odoom and Mario Lucic and Becca Roelofs and Sid Lall and Amit Marathe and Betty Chan and Santiago Ontanon and Luheng He and Denis Teplyashin and Jonathan Lai and Phil Crone and Bogdan Damoc and Lewis Ho and Sebastian Riedel and Karel Lenc and Chih-Kuan Yeh and Aakanksha Chowdhery and Yang Xu and Mehran Kazemi and Ehsan Amid and Anastasia Petrushkina and Kevin Swersky and Ali Khodaei and Gowoon Chen and Chris Larkin and Mario Pinto and Geng Yan and Adria Puigdomenech Badia and Piyush Patil and Steven Hansen and Dave Orr and Sebastien MR Arnold and Jordan Grimstad and Andrew Dai and Sholto Douglas and Rishika Sinha and Vikas Yadav and Xi Chen and Elena Gribovskaya and Jacob Austin and Jeffrey Zhao and Kaushal Patel and Paul Komarek and Sophia Austin and Sebastian Borgeaud and Linda Friso and Abhimanyu Goyal and Ben Caine and Kris Cao and Da-Woon Chung and Matthew Lamm and Gabe Barth-Maron and Thais Kagohara and Kate Olszewska and Mia Chen and Kaushik Shivakumar and Rishabh Agarwal and Harshal Godhia and Ravi Rajwar and Javier Snaider and Xerxes Dotiwalla and Yuan Liu and Aditya Barua and Victor Ungureanu and Yuan Zhang and Bat-Orgil Batsaikhan"
      },
      {
        "title": "Gemma 2: Improving open language models at a practical size",
        "abstract": "In this work, we introduce Gemma 2, a new addition to the Gemma family of lightweight, state-of-the-art open models, ranging in scale from 2 billion to 27 billion parameters. In this new version, we apply several known technical modifications to the Transformer architecture, such as interleaving local-global attentions (Beltagy et al., 2020a) and group-query attention (Ainslie et al., 2023). We also train the 2B and 9B models with knowledge distillation (Hinton et al., 2015) instead of next token prediction. The resulting models deliver the best performance for their size, and even offer competitive alternatives to models that are 2-3 times bigger. We release all our models to the community.",
        "year": 2024,
        "authors": "Gemma Team and Morgane Riviere and Shreya Pathak and Pier Giuseppe Sessa and Cassidy Hardin and Surya Bhupatiraju and L\u00e9onard Hussenot and Thomas Mesnard and Bobak Shahriari and Alexandre Ram\u00e9 and Johan Ferret and Peter Liu and Pouya Tafti and Abe Friesen and Michelle Casbon and Sabela Ramos and Ravin Kumar and Charline Le Lan and Sammy Jerome and Anton Tsitsulin and Nino Vieillard and Piotr Stanczyk and Sertan Girgin and Nikola Momchev and Matt Hoffman and Shantanu Thakoor and Jean-Bastien Grill and Behnam Neyshabur and Olivier Bachem and Alanna Walton and Aliaksei Severyn and Alicia Parrish and Aliya Ahmad and Allen Hutchison and Alvin Abdagic and Amanda Carl and Amy Shen and Andy Brock and Andy Coenen and Anthony Laforge and Antonia Paterson and Ben Bastian and Bilal Piot and Bo Wu and Brandon Royal and Charlie Chen and Chintu Kumar and Chris Perry and Chris Welty and Christopher A Choquette-Choo and Danila Sinopalnikov and David Weinberger and Dimple Vijaykumar and Dominika Rogozi\u0144ska and Dustin Herbison and Elisa Bandy and Emma Wang and Eric Noland and Erica Moreira and Evan Senter and Evgenii Eltyshev and Francesco Visin and Gabriel Rasskin and Gary Wei and Glenn Cameron and Gus Martins and Hadi Hashemi and Hanna Klimczak-Pluci\u0144ska and Harleen Batra and Harsh Dhand and Ivan Nardini and Jacinda Mein and Jack Zhou and James Svensson and Jeff Stanway and Jetha Chan and Jin Peng Zhou and Joana Carrasqueira and Joana Iljazi and Jocelyn Becker and Joe Fernandez and Joost van Amersfoort and Josh Gordon and Josh Lipschultz and Josh Newlan and Ju-yeong Ji and Kareem Mohamed and Kartikeya Badola and Kat Black and Katie Millican and Keelin McDonell and Kelvin Nguyen and Kiranbir Sodhia and Kish Greene and Lars Lowe Sjoesund and Lauren Usui and Laurent Sifre and Lena Heuermann and Leticia Lago and Lilly McNealus and Livio Baldini Soares and Logan Kilpatrick and Lucas Dixon and Luciano Martins and Machel Reid and Manvinder Singh and Mark Iverson and Martin G\u00f6rner and Mat Velloso and Mateo Wirth and Matt Davidow and Matt Miller and Matthew Rahtz and Matthew Watson and Meg Risdal and Mehran Kazemi and Michael Moynihan and Ming Zhang and Minsuk Kahng and Minwoo Park and Mofi Rahman and Mohit Khatwani and Natalie Dao and Nenshad Bardoliwalla and Nesh Devanathan and Neta Dumai and Nilay Chauhan and Oscar Wahltinez and Pankil Botarda and Parker Barnes and Paul Barham and Paul Michel and Pengchong Jin and Petko Georgiev and Phil Culliton and Pradeep Kuppala and Ramona Comanescu and Ramona Merhej and Reena Jana and Reza Ardeshir Rokni and Rishabh Agarwal and Ryan Mullins and Samaneh Saadat and Sara Mc Carthy and Sarah Cogan and Sarah Perrin and S\u00e9bastien MR Arnold and Sebastian Krause and Shengyang Dai and Shruti Garg"
      },
      {
        "title": "Legibility and predictability of robot motion",
        "abstract": "A key requirement for seamless human-robot collaboration is for the robot to make its intentions clear to its human collaborator. A collaborative robot's motion must be legible, or intent-expressive. Legibility is often described in the literature as and effect of predictable, unsurprising, or expected motion. Our central insight is that predictability and legibility are fundamentally different and often contradictory properties of motion. We develop a formalism to mathematically define and distinguish predictability and legibility of motion. We formalize the two based on inferences between trajectories and goals in opposing directions, drawing the analogy to action interpretation in psychology. We then propose mathematical models for these inferences based on optimizing cost, drawing the analogy to the principle of rational action. Our experiments validate our formalism's prediction that predictability and legibility can contradict \u2026",
        "year": 2013,
        "authors": "Anca D Dragan and Kenton CT Lee and Siddhartha S Srinivasa"
      }
    ],
    "NSWI3OwAAAAJ": [
      {
        "title": "Palm-e: An embodied multimodal language model",
        "abstract": "Large language models excel at a wide range of complex tasks. However, enabling general inference in the real world, e.g. for robotics problems, raises the challenge of grounding. We propose embodied language models to directly incorporate real-world continuous sensor modalities into language models and thereby establish the link between words and percepts. Input to our embodied language model are multimodal sentences that interleave visual, continuous state estimation, and textual input encodings. We train these encodings end-to-end, in conjunction with a pre-trained large language model, for multiple embodied tasks including sequential robotic manipulation planning, visual question answering, and captioning. Our evaluations show that PaLM-E, a single large embodied multimodal model, can address a variety of embodied reasoning tasks, from a variety of observation modalities, on multiple embodiments, and further, exhibits positive transfer: the model benefits from diverse joint training across internet-scale language, vision, and visual-language domains. Our largest model with 562B parameters, in addition to being trained on robotics tasks, is a visual-language generalist with state-of-the-art performance on OK-VQA, and retains generalist language capabilities with increasing scale.",
        "year": 2023,
        "authors": "Danny Driess and Fei Xia and Mehdi SM Sajjadi and Corey Lynch and Aakanksha Chowdhery and Ayzaan Wahid and Jonathan Tompson and Quan Vuong and Tianhe Yu and Wenlong Huang and Yevgen Chebotar and Pierre Sermanet and Daniel Duckworth and Sergey Levine and Vincent Vanhoucke and Karol Hausman and Marc Toussaint and Klaus Greff and Andy Zeng and Igor Mordatch and Pete Florence"
      },
      {
        "title": "Rt-1: Robotics transformer for real-world control at scale",
        "abstract": "By transferring knowledge from large, diverse, task-agnostic datasets, modern machine learning models can solve specific downstream tasks either zero-shot or with small task-specific datasets to a high level of performance. While this capability has been demonstrated in other fields such as computer vision, natural language processing or speech recognition, it remains to be shown in robotics, where the generalization capabilities of the models are particularly critical due to the difficulty of collecting real-world robotic data. We argue that one of the keys to the success of such general robotic models lies with open-ended task-agnostic training, combined with high-capacity architectures that can absorb all of the diverse, robotic data. In this paper, we present a model class, dubbed Robotics Transformer, that exhibits promising scalable model properties. We verify our conclusions in a study of different model classes and their ability to generalize as a function of the data size, model size, and data diversity based on a large-scale data collection on real robots performing real-world tasks. The project's website and videos can be found at robotics-transformer1.github.io",
        "year": 2022,
        "authors": "Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Joseph Dabis and Chelsea Finn and Keerthana Gopalakrishnan and Karol Hausman and Alex Herzog and Jasmine Hsu and Julian Ibarz and Brian Ichter and Alex Irpan and Tomas Jackson and Sally Jesmonth and Nikhil J Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Kuang-Huei Lee and Sergey Levine and Yao Lu and Utsav Malla and Deeksha Manjunath and Igor Mordatch and Ofir Nachum and Carolina Parada and Jodilyn Peralta and Emily Perez and Karl Pertsch and Jornell Quiambao and Kanishka Rao and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Kevin Sayed and Jaspiar Singh and Sumedh Sontakke and Austin Stone and Clayton Tan and Huong Tran and Vincent Vanhoucke and Steve Vega and Quan Vuong and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich"
      },
      {
        "title": "Rt-2: Vision-language-action models transfer web knowledge to robotic control",
        "abstract": "We study how vision-language models trained on Internet-scale data can be incorporated directly into end-to-end robotic control to boost generalization and enable emergent semantic reasoning. Our goal is to enable a single end-to-end trained model to both learn to map robot observations to actions and enjoy the benefits of large-scale pretraining on language and vision-language data from the web. To this end, we propose to co-fine-tune state-of-the-art vision-language models on both robotic trajectory data and Internet-scale vision-language tasks, such as visual question answering. In contrast to other approaches, we propose a simple, general recipe to achieve this goal: in order to fit both natural language responses and robotic actions into the same format, we express the actions as text tokens and incorporate them directly into the training set of the model in the same way as natural language tokens. We refer to such category of models as vision-language-action models (VLA) and instantiate an example of such a model, which we call RT-2. Our extensive evaluation (6k evaluation trials) shows that our approach leads to performant robotic policies and enables RT-2 to obtain a range of emergent capabilities from Internet-scale training. This includes significantly improved generalization to novel objects, the ability to interpret commands not present in the robot training data (such as placing an object onto a particular number or icon), and the ability to perform rudimentary reasoning in response to user commands (such as picking up the smallest or largest object, or the one closest to another object). We further show that incorporating chain of \u2026",
        "year": 2023,
        "authors": "Anthony Brohan and Noah Brown and Justice Carbajal and Yevgen Chebotar and Xi Chen and Krzysztof Choromanski and Tianli Ding and Danny Driess and Avinava Dubey and Chelsea Finn and Pete Florence and Chuyuan Fu and Montse Gonzalez Arenas and Keerthana Gopalakrishnan and Kehang Han and Karol Hausman and Alexander Herzog and Jasmine Hsu and Brian Ichter and Alex Irpan and Nikhil Joshi and Ryan Julian and Dmitry Kalashnikov and Yuheng Kuang and Isabel Leal and Lisa Lee and Tsang-Wei Edward Lee and Sergey Levine and Yao Lu and Henryk Michalewski and Igor Mordatch and Karl Pertsch and Kanishka Rao and Krista Reymann and Michael Ryoo and Grecia Salazar and Pannag Sanketi and Pierre Sermanet and Jaspiar Singh and Anikait Singh and Radu Soricut and Huong Tran and Vincent Vanhoucke and Quan Vuong and Ayzaan Wahid and Stefan Welker and Paul Wohlhart and Jialin Wu and Fei Xia and Ted Xiao and Peng Xu and Sichun Xu and Tianhe Yu and Brianna Zitkovich"
      }
    ],
    "fftO_HsAAAAJ": [
      {
        "title": "Recovery rl: Safe reinforcement learning with learned recovery zones",
        "abstract": "Safety remains a central obstacle preventing widespread use of RL in the real world: learning new tasks in uncertain environments requires extensive exploration, but safety requires limiting exploration. We propose Recovery RL, an algorithm which navigates this tradeoff by (1) leveraging offline data to learn about constraint violating zones before policy learning and (2) separating the goals of improving task performance and constraint satisfaction across two policies: a task policy that only optimizes the task reward and a recovery policy that guides the agent to safety when constraint violation is likely. We evaluate Recovery RL on 6 simulation domains, including two contact-rich manipulation tasks and an image-based navigation task, and an image-based obstacle avoidance task on a physical robot. We compare Recovery RL to 5 prior safe RL methods which jointly optimize for task performance and safety via \u2026",
        "year": 2021,
        "authors": "Brijen Thananjeyan and Ashwin Balakrishna and Suraj Nair and Michael Luo and Krishnan Srinivasan and Minho Hwang and Joseph E Gonzalez and Julian Ibarz and Chelsea Finn and Ken Goldberg"
      },
      {
        "title": "Multilateral surgical pattern cutting in 2D orthotropic gauze with deep reinforcement learning policies for tensioning",
        "abstract": "In the Fundamentals of Laparoscopic Surgery (FLS) standard medical training regimen, the Pattern Cutting task requires residents to demonstrate proficiency by maneuvering two tools, surgical scissors and tissue gripper, to accurately cut a circular pattern on surgical gauze suspended at the corners. Accuracy of cutting depends on tensioning, wherein the gripper pinches a point on the gauze in R3 and pulls to induce and maintain tension in the material as cutting proceeds. An automated tensioning policy maps the current state of the gauze to output a direction of pulling as an action. The optimal tensioning policy depends on both the choice of pinch point and cutting trajectory. We explore the problem of learning a tensioning policy conditioned on specific cutting trajectories. Every timestep, we allow the gripper to react to the deformation of the gauze and progress of the cutting trajectory with a translation unit vector \u2026",
        "year": 2017,
        "authors": "Brijen Thananjeyan and Animesh Garg and Sanjay Krishnan and Carolyn Chen and Lauren Miller and Ken Goldberg"
      },
      {
        "title": "Deep imitation learning of sequential fabric smoothing from an algorithmic supervisor",
        "abstract": "Sequential pulling policies to flatten and smooth fabrics have applications from surgery to manufacturing to home tasks such as bed making and folding clothes. Due to the complexity of fabric states and dynamics, we apply deep imitation learning to learn policies that, given color (RGB), depth (D), or combined color-depth (RGBD) images of a rectangular fabric sample, estimate pick points and pull vectors to spread the fabric to maximize coverage. To generate data, we develop a fabric simulator and an algorithmic supervisor that has access to complete state information. We train policies in simulation using domain randomization and dataset aggregation (DAgger) on three tiers of difficulty in the initial randomized configuration. We present results comparing five baseline policies to learned policies and report systematic comparisons of RGB vs D vs RGBD images as inputs. In simulation, learned policies achieve \u2026",
        "year": 2020,
        "authors": "Daniel Seita and Aditya Ganapathi and Ryan Hoque and Minho Hwang and Edward Cen and Ajay Kumar Tanwani and Ashwin Balakrishna and Brijen Thananjeyan and Jeffrey Ichnowski and Nawid Jamali and Katsu Yamane and Soshi Iba and John Canny and Ken Goldberg"
      }
    ],
    "d5y4iKAAAAAJ": [
      {
        "title": "LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action",
        "abstract": "Goal-conditioned policies for robotic navigation can be trained on large, unannotated datasets, providing for good generalization to real-world settings. However, particularly in vision-based settings where specifying goals requires an image, this makes for an unnatural interface. Language provides a more convenient modality for communication with robots, but contemporary methods typically require expensive supervision, in the form of trajectories annotated with language descriptions. We present a system, LM-Nav, for robotic navigation that enjoys the benefits of training on unannotated large datasets of trajectories, while still providing a high-level interface to the user. Instead of utilizing a labeled instruction following dataset, we show that such a system can be constructed entirely out of pre-trained models for navigation (ViNG), image-language association (CLIP), and language modeling (GPT-3), without requiring any fine-tuning or language-annotated robot data. LM-Nav extracts landmarks names from an instruction, grounds them in the world via the image-language model, and then reaches them via the (vision-only) navigation model. We instantiate LM-Nav on a real-world mobile robot and demonstrate long-horizon navigation through complex, outdoor environments from natural language instructions.",
        "year": 2022,
        "authors": "Dhruv Shah and Blazej Osinski and Brian Ichter and Sergey Levine"
      },
      {
        "title": "The Ingredients of Real-World Robotic Reinforcement Learning",
        "abstract": "The success of reinforcement learning for real world robotics has been, in many cases limited to instrumented laboratory scenarios, often requiring arduous human effort and oversight to enable continuous learning. In this work, we discuss the elements that are needed for a robotic learning system that can continually and autonomously improve with data collected in the real world. We propose a particular instantiation of such a system, using dexterous manipulation as our case study. Subsequently, we investigate a number of challenges that come up when learning without instrumentation. In such settings, learning must be feasible without manually designed resets, using only on-board perception, and without hand-engineered reward functions. We propose simple and scalable solutions to these challenges, and then demonstrate the efficacy of our proposed system on a set of dexterous robotic manipulation tasks, providing an in-depth analysis of the challenges associated with this learning paradigm. We demonstrate that our complete system can learn without any human intervention, acquiring a variety of vision-based skills with a real-world three-fingered hand. Results and videos can be found at https://sites.google.com/view/realworld-rl/",
        "year": 2020,
        "authors": "Henry Zhu and Justin Yu and Abhishek Gupta and Dhruv Shah and Kristian Hartikainen and Avi Singh and Vikash Kumar and Sergey Levine"
      }
    ],
    "pzw1-J4AAAAJ": [
      {
        "title": "Model cards for model reporting",
        "abstract": "Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type [15]) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended \u2026",
        "year": 2019,
        "authors": "Margaret Mitchell and Simone Wu and Andrew Zaldivar and Parker Barnes and Lucy Vasserman and Ben Hutchinson and Elena Spitzer and Inioluwa Deborah Raji and Timnit Gebru"
      },
      {
        "title": "Closing the AI Accountability Gap: Defining an End-to-End Framework for Internal Algorithmic Auditing",
        "abstract": "Rising concern for the societal implications of artificial intelligence systems has inspired a wave of academic and journalistic literature in which deployed systems are audited for harm by investigators from outside the organizations deploying the algorithms. However, it remains challenging for practitioners to identify the harmful repercussions of their own systems prior to deployment, and, once deployed, emergent issues can become difficult or impossible to trace back to their source.In this paper, we introduce a framework for algorithmic auditing that supports artificial intelligence system development end-to-end, to be applied throughout the internal organization development life-cycle. Each stage of the audit yields a set of documents that together form an overall audit report, drawing on an organization's values or principles to assess the fit of decisions made throughout the process. The proposed auditing \u2026",
        "year": 2020,
        "authors": "Inioluwa Deborah Raji and Andrew Smart and Rebecca N White and Margaret Mitchell and Timnit Gebru and Ben Hutchinson and Jamila Smith-Loud and Daniel Theron and Parker Barnes"
      },
      {
        "title": "Actionable auditing: Investigating the impact of publicly naming biased performance results of commercial ai products",
        "abstract": "Although algorithmic auditing has emerged as a key strategy to expose systematic biases embedded in software platforms, we struggle to understand the real-world impact of these audits, as scholarship on the impact of algorithmic audits on increasing algorithmic fairness and transparency in commercial systems is nascent. To analyze the impact of publicly naming and disclosing performance results of biased AI systems, we investigate the commercial impact of Gender Shades, the first algorithmic audit of gender and skin type performance disparities in commercial facial analysis models. This paper 1) outlines the audit design and structured disclosure procedure used in the Gender Shades study, 2) presents new performance metrics from targeted companies IBM, Microsoft and Megvii (Face++) on the Pilot Parliaments Benchmark (PPB) as of August 2018, 3) provides performance results on PPB by non-target \u2026",
        "year": 2019,
        "authors": "Inioluwa Deborah Raji and Joy Buolamwini"
      }
    ],
    "EMDboA4AAAAJ": [
      {
        "title": "InfoGAN: Interpretable representation learning by information maximizing generative adversarial nets",
        "abstract": "This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods.",
        "year": 2016,
        "authors": "Xi Chen and Yan Duan and Rein Houthooft and John Schulman and Ilya Sutskever and Pieter Abbeel"
      },
      {
        "title": "Benchmarking deep reinforcement learning for continuous control",
        "abstract": "Recently, researchers have made significant progress combining the advances in deep learning for learning feature representations with reinforcement learning. Some notable examples include training agents to play Atari games based on raw pixel data and to acquire advanced manipulation skills using raw sensory inputs. However, it has been difficult to quantify progress in the domain of continuous control due to the lack of a commonly adopted benchmark. In this work, we present a benchmark suite of continuous control tasks, including classic tasks like cart-pole swing-up, tasks with very high state and action dimensionality such as 3D humanoid locomotion, tasks with partial observations, and tasks with hierarchical structure. We report novel findings based on the systematic evaluation of a range of implemented reinforcement learning algorithms. Both the benchmark and reference implementations are released at https://github. com/rllab/rllab in order to facilitate experimental reproducibility and to encourage adoption by other researchers.",
        "year": 2016,
        "authors": "Yan Duan and Xi Chen and Rein Houthooft and John Schulman and Pieter Abbeel"
      },
      {
        "title": "RL^2: Fast Reinforcement Learning via Slow Reinforcement Learning",
        "abstract": "Deep reinforcement learning (deep RL) has been successful in learning sophisticated behaviors automatically; however, the learning process requires a huge number of trials. In contrast, animals can learn new tasks in just a few trials, benefiting from their prior knowledge about the world. This paper seeks to bridge this gap. Rather than designing a \"fast\" reinforcement learning algorithm, we propose to represent it as a recurrent neural network (RNN) and learn it from data. In our proposed method, RL, the algorithm is encoded in the weights of the RNN, which are learned slowly through a general-purpose (\"slow\") RL algorithm. The RNN receives all information a typical RL algorithm would receive, including observations, actions, rewards, and termination flags; and it retains its state across episodes in a given Markov Decision Process (MDP). The activations of the RNN store the state of the \"fast\" RL algorithm on the current (previously unseen) MDP. We evaluate RL experimentally on both small-scale and large-scale problems. On the small-scale side, we train it to solve randomly generated multi-arm bandit problems and finite MDPs. After RL is trained, its performance on new MDPs is close to human-designed algorithms with optimality guarantees. On the large-scale side, we test RL on a vision-based navigation task and show that it scales up to high-dimensional problems.",
        "year": 2016,
        "authors": "Yan Duan and John Schulman and Xi Chen and Peter L Bartlett and Ilya Sutskever and Pieter Abbeel"
      }
    ],
    "4zybTq4AAAAJ": [
      {
        "title": "QSGD: Communication-Efficient SGD via Gradient Quantization and Encoding",
        "abstract": "Parallel implementations of stochastic gradient descent (SGD) have received significant research attention, thanks to its excellent scalability properties. A fundamental barrier when parallelizing SGD is the high bandwidth cost of communicating gradient updates between nodes; consequently, several lossy compresion heuristics have been proposed, by which nodes only communicate quantized gradients. Although effective in practice, these heuristics do not always guarantee convergence, and it is not clear whether they can be improved. In this paper, we propose Quantized SGD (QSGD), a family of compression schemes for gradient updates which provides convergence guarantees. QSGD allows the user to smoothly trade off\\emph {communication bandwidth} and\\emph {convergence time}: nodes can adjust the number of bits sent per iteration, at the cost of possibly higher variance. We show that this trade-off is inherent, in the sense that improving it past some threshold would violate information-theoretic lower bounds. QSGD guarantees convergence for convex and non-convex objectives, under asynchrony, and can be extended to stochastic variance-reduced techniques. When applied to training deep neural networks for image classification and automated speech recognition, QSGD leads to significant reductions in end-to-end training time. For example, on 16GPUs, we can train the ResNet152 network to full accuracy on ImageNet 1.8 x faster than the full-precision variant.",
        "year": 2017,
        "authors": "Dan Alistarh and Demjan Grubic and Jerry Li and Ryota Tomioka and Milan Vojnovic"
      },
      {
        "title": "Spectral signatures in backdoor attacks",
        "abstract": "A recent line of work has uncovered a new form of data poisoning: so-called backdoor attacks. These attacks are particularly dangerous because they do not affect a network's behavior on typical, benign data. Rather, the network only deviates from its expected output when triggered by an adversary's planted perturbation.",
        "year": 2018,
        "authors": "Brandon Tran and Jerry Li and Aleksander Madry"
      },
      {
        "title": "Provably robust deep learning via adversarially trained smoothed classifiers",
        "abstract": "Recent works have shown the effectiveness of randomized smoothing as a scalable technique for building neural network-based classifiers that are provably robust to -norm adversarial perturbations. In this paper, we employ adversarial training to improve the performance of randomized smoothing. We design an adapted attack for smoothed classifiers, and we show how this attack can be used in an adversarial training setting to boost the provable robustness of smoothed classifiers. We demonstrate through extensive experimentation that our method consistently outperforms all existing provably -robust classifiers by a significant margin on ImageNet and CIFAR-10, establishing the state-of-the-art for provable -defenses. Moreover, we find that pre-training and semi-supervised learning boost adversarially trained smoothed classifiers even further. Our code and trained models are available at http://github. com/Hadisalman/smoothing-adversarial.",
        "year": 2019,
        "authors": "Hadi Salman and Jerry Li and Ilya Razenshteyn and Pengchuan Zhang and Huan Zhang and Sebastien Bubeck and Greg Yang"
      }
    ],
    "RLvsC94AAAAJ": [
      {
        "title": "Language models are few-shot learners",
        "abstract": "We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.",
        "year": 2020,
        "authors": "Tom Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared D Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel Ziegler and Jeffrey Wu and Clemens Winter and Chris Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei"
      },
      {
        "title": "Deep reinforcement learning from human preferences",
        "abstract": "For sophisticated reinforcement learning (RL) systems to interact usefully with real-world environments, we need to communicate complex goals to these systems. In this work, we explore goals defined in terms of (non-expert) human preferences between pairs of trajectory segments. Our approach separates learning the goal from learning the behavior to achieve it. We show that this approach can effectively solve complex RL tasks without access to the reward function, including Atari games and simulated robot locomotion, while providing feedback on about 0.1% of our agent's interactions with the environment. This reduces the cost of human oversight far enough that it can be practically applied to state-of-the-art RL systems. To demonstrate the flexibility of our approach, we show that we can successfully train complex novel behaviors with about an hour of human time. These behaviors and environments are considerably more complex than any which have been previously learned from human feedback.",
        "year": 2017,
        "authors": "Paul F Christiano and Jan Leike and Tom Brown and Miljan Martic and Shane Legg and Dario Amodei"
      },
      {
        "title": "Scaling laws for neural language models",
        "abstract": "We study empirical scaling laws for language model performance on the cross-entropy loss. The loss scales as a power-law with model size, dataset size, and the amount of compute used for training, with some trends spanning more than seven orders of magnitude. Other architectural details such as network width or depth have minimal effects within a wide range. Simple equations govern the dependence of overfitting on model/dataset size and the dependence of training speed on model size. These relationships allow us to determine the optimal allocation of a fixed compute budget. Larger models are significantly more sampleefficient, such that optimally compute-efficient training involves training very large models on a relatively modest amount of data and stopping significantly before convergence.",
        "year": 2020,
        "authors": "Jared Kaplan and Sam McCandlish and Tom Henighan and Tom B Brown and Benjamin Chess and Rewon Child and Scott Gray and Alec Radford and Jeffrey Wu and Dario Amodei"
      }
    ],
    "zX3ba1kAAAAJ": [
      {
        "title": "Similarity estimation techniques from rounding algorithms",
        "abstract": "(MATH) A locality sensitive hashing scheme is a distribution on a family $\\F$ of hash functions operating on a collection of objects, such that for two objects x,y, Prh\u03b5F[h(x) = h(y)] = sim(x,y), where sim(x,y) \u03b5 [0,1] is some similarity function defined on the collection of objects. Such a scheme leads to a compact representation of objects so that similarity of objects can be estimated from their compact sketches, and also leads to efficient algorithms for approximate nearest neighbor search and clustering. Min-wise independent permutations provide an elegant construction of such a locality sensitive hashing scheme for a collection of subsets with the set similarity measure sim(A,B) = \\frac{|A \u2229 B|}{|A \u222a B|}.(MATH) We show that rounding algorithms for LPs and SDPs used in the context of approximation algorithms can be viewed as locality sensitive hashing schemes for several interesting collections of objects. Based on \u2026",
        "year": 2002,
        "authors": "Moses S Charikar"
      },
      {
        "title": "Finding frequent items in data streams",
        "abstract": "We present a 1-pass algorithm for estimating the most frequent items in a data stream using very limited storage space. Our method relies on a novel data structure called a count sketch, which allows us to estimate the frequencies of all the items in the stream. Our algorithm achieves better space bounds than the previous best known algorithms for this problem for many natural distributions on the item frequencies. In addition, our algorithm leads directly to a 2-pass algorithm for the problem of estimating the items with the largest (absolute) change in frequency between two data streams. To our knowledge, this problem has not been previously studied in the literature.",
        "year": 2004,
        "authors": "Moses Charikar and Kevin Chen and Martin Farach-Colton"
      },
      {
        "title": "Min-wise independent permutations",
        "abstract": "We define and study the notion of min-wise independent families of permutations. We say that F\u2286 Sn is min-wise independent if for any set X\u2286[n] and any x\u2208 X, when \u03c0 is chosen at random in F we have",
        "year": 1998,
        "authors": "Andrei Z Broder and Moses Charikar and Alan M Frieze and Michael Mitzenmacher"
      }
    ],
    "B847xq8AAAAJ": [
      {
        "title": "Maximizing social influence in nearly optimal time",
        "abstract": "Diffusion is a fundamental graph process, underpinning such phenomena as epidemic disease contagion and the spread of innovation by word-of-mouth. We address the algorithmic problem of finding a set of k initial seed nodes in a network so that the expected size of the resulting cascade is maximized, under the standard independent cascade model of network diffusion. Runtime is a primary consideration for this problem due to the massive size of the relevant input networks.We provide a fast algorithm for the influence maximization problem, obtaining the near-optimal approximation factor of , for any \u220a > 0, in time O((m + n)\u220a\u22123 log n). Our algorithm is runtime-optimal (up to a logarithmic factor) and substantially improves upon the previously best-known algorithms which run in time \u03a9(mnk \u00b7 POLY(\u220a\u22121)). Furthermore, our algorithm can be modified to allow early termination: if it is terminated after O(\u03b2(m + n) logn \u2026",
        "year": 2014,
        "authors": "Christian Borgs and Michael Brautbar and Jennifer Chayes and Brendan Lucier"
      },
      {
        "title": "Entropy-sgd: Biasing gradient descent into wide valleys",
        "abstract": "This paper proposes a new optimization algorithm called Entropy-SGD for training deep neural networks that is motivated by the local geometry of the energy landscape. Local extrema with low generalization error have a large proportion of almost-zero eigenvalues in the Hessian with very few positive or negative eigenvalues. We leverage upon this observation to construct a local-entropy-based objective function that favors well-generalizable solutions lying in large flat regions of the energy landscape, while avoiding poorly-generalizable solutions located in the sharp valleys. Conceptually, our algorithm resembles two nested loops of SGD where we use Langevin dynamics in the inner loop to compute the gradient of the local entropy before each update of the weights. We show that the new objective has a smoother energy landscape and show improved generalization over SGD using uniform stability, under \u2026",
        "year": 2019,
        "authors": "Pratik Chaudhari and Anna Choromanska and Stefano Soatto and Yann LeCun and Carlo Baldassi and Christian Borgs and Jennifer Chayes and Levent Sagun and Riccardo Zecchina"
      },
      {
        "title": "Convergent sequences of dense graphs I: Subgraph frequencies, metric properties and testing",
        "abstract": "We consider sequences of graphs (Gn) and define various notions of convergence related to these sequences: \u201cleft convergence\u201d defined in terms of the densities of homomorphisms from small graphs into Gn; \u201cright convergence\u201d defined in terms of the densities of homomorphisms from Gn into small graphs; and convergence in a suitably defined metric. In Part I of this series, we show that left convergence is equivalent to convergence in metric, both for simple graphs Gn, and for graphs Gn with nodeweights and edgeweights. One of the main steps here is the introduction of a cut-distance comparing graphs, not necessarily of the same size. We also show how these notions of convergence provide natural formulations of Szemer\u00e9di partitions, sampling and testing of large graphs.",
        "year": 2008,
        "authors": "Christian Borgs and Jennifer T Chayes and L\u00e1szl\u00f3 Lov\u00e1sz and Vera T S\u00f3s and Katalin Vesztergombi"
      }
    ],
    "5pKTRxEAAAAJ": [
      {
        "title": "Distance metric learning with application to clustering with side-information",
        "abstract": "Many algorithms rely critically on being given a good metric over their inputs. For instance, data can often be clustered in many \u201cplausible\u201d ways, and if a clustering algorithm such as K-means initially fails to find one that is meaningful to a user, the only recourse may be for the user to manually tweak the metric until sufficiently good clusters are found. For these and other applications requiring good metrics, it is desirable that we provide a more systematic way for users to indicate what they consider \u201csimilar.\u201d For instance, we may ask them to provide examples. In this paper, we present an algorithm that, given examples of similar (and, if desired, dissimilar) pairs of points in \u0432\u0434\u0433, learns a distance metric over \u0432\u0435\u0433 that respects these relationships. Our method is based on posing metric learning as a convex optimization problem, which allows us to give efficient, local-optima-free algorithms. We also demonstrate empirically that the learned metrics can be used to significantly improve clustering performance.",
        "year": 2002,
        "authors": "Eric Xing and Michael Jordan and Stuart J Russell and Andrew Ng"
      },
      {
        "title": "Judging llm-as-a-judge with mt-bench and chatbot arena",
        "abstract": "Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80\\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github. com/lm-sys/FastChat/tree/main/fastchat/llm_judge.",
        "year": 2023,
        "authors": "Lianmin Zheng and Wei-Lin Chiang and Ying Sheng and Siyuan Zhuang and Zhanghao Wu and Yonghao Zhuang and Zi Lin and Zhuohan Li and Dacheng Li and Eric Xing and Hao Zhang and Joseph E Gonzalez and Ion Stoica"
      }
    ],
    "9yRwkr4AAAAJ": [
      {
        "title": "Challenges with quality of race and ethnicity data in observational databases",
        "abstract": "We sought to assess the quality of race and ethnicity information in observational health databases, including electronic health records (EHRs), and to propose patient self-recording as an improvement strategy.We assessed completeness of race and ethnicity information in large observational health databases in the United States (Healthcare Cost and Utilization Project and Optum Labs), and at a single healthcare system in New York City serving a racially and ethnically diverse population. We compared race and ethnicity data collected via administrative processes with data recorded directly by respondents via paper surveys (National Health and Nutrition Examination Survey and Hospital Consumer Assessment of Healthcare Providers and Systems). Respondent-recorded data were considered the gold standard for the collection of race and \u2026",
        "year": 2019,
        "authors": "Fernanda CG Polubriaginof and Patrick Ryan and Hojjat Salmasian and Andrea Wells Shapiro and Adler Perotte and Monika M Safford and George Hripcsak and Shaun Smith and Nicholas P Tatonetti and David K Vawdrey"
      },
      {
        "title": "The role of chemoprevention in modifying the risk of breast cancer in women with atypical breast lesions",
        "abstract": "Women with atypical ductal hyperplasia (ADH), atypical lobular hyperplasia (ALH), lobular carcinoma in situ (LCIS), and severe ADH are at increased risk of breast cancer, but a systematic quantification of this risk and the efficacy of chemoprevention in the clinical setting is still lacking. The objective of this study is to evaluate a woman\u2019s risk of breast cancer based on atypia type and to determine the effect of chemoprevention in decreasing this risk. Review of 76,333 breast pathology reports from three institutions within Partners Healthcare System, Boston, from 1987 to 2010 using natural language processing was carried out. This approach identified 2,938 women diagnosed with atypical breast lesions. The main outcome of this study is breast cancer occurrence. Of the 2,938 patients with atypical breast lesions, 1,658 were documented to have received no chemoprevention, and 184/1,658 (11.1 \u2026",
        "year": 2012,
        "authors": "Suzanne B Coopey and Emanuele Mazzola and Julliette M Buckley and John Sharko and Ahmet K Belli and Elizabeth MH Kim and Fernanda Polubriaginof and Giovanni Parmigiani and Judy E Garber and Barbara L Smith and Michele A Gadd and Michelle C Specht and Anthony J Guidi and Constance A Roche and Kevin S Hughes"
      },
      {
        "title": "Using machine learning to parse breast pathology reports",
        "abstract": " Extracting information from electronic medical record is a time-consuming and expensive process when done manually. Rule-based and machine learning techniques are two approaches to solving this problem. In this study, we trained a machine learning model on pathology reports to extract pertinent tumor characteristics, which enabled us to create a large database of attribute searchable pathology reports. This database can be used to identify cohorts of patients with characteristics of interest. We collected a total of 91,505 breast pathology reports from three Partners hospitals: Massachusetts General Hospital, Brigham and Women\u2019s Hospital, and Newton-Wellesley Hospital, covering the period from 1978 to 2016. We trained our system with annotations from two datasets, consisting of 6295 and 10,841 manually annotated reports \u2026",
        "year": 2017,
        "authors": "Adam Yala and Regina Barzilay and Laura Salama and Molly Griffin and Grace Sollender and Aditya Bardia and Constance Lehman and Julliette M Buckley and Suzanne B Coopey and Fernanda Polubriaginof and Judy E Garber and Barbara L Smith and Michele A Gadd and Michelle C Specht and Thomas M Gudewicz and Anthony J Guidi and Alphonse Taghian and Kevin S Hughes"
      }
    ]
  }
}